Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_7', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29278
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 14:57:46.817130 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 14:57:46.828912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4102.25
 ---- batch: 020 ----
mean loss: 3945.62
 ---- batch: 030 ----
mean loss: 3998.08
train mean loss: 4010.93
epoch train time: 0:00:12.631687
elapsed time: 0:00:12.646520
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 14:57:59.463706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3926.40
 ---- batch: 020 ----
mean loss: 3833.10
 ---- batch: 030 ----
mean loss: 3794.20
train mean loss: 3840.68
epoch train time: 0:00:00.511593
elapsed time: 0:00:13.158345
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 14:57:59.975609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3676.84
 ---- batch: 020 ----
mean loss: 3593.59
 ---- batch: 030 ----
mean loss: 3534.46
train mean loss: 3578.54
epoch train time: 0:00:00.504838
elapsed time: 0:00:13.663545
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 14:58:00.480768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3400.08
 ---- batch: 020 ----
mean loss: 3314.00
 ---- batch: 030 ----
mean loss: 3294.82
train mean loss: 3331.41
epoch train time: 0:00:00.512933
elapsed time: 0:00:14.176754
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 14:58:00.993983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3150.35
 ---- batch: 020 ----
mean loss: 3090.39
 ---- batch: 030 ----
mean loss: 3155.09
train mean loss: 3120.11
epoch train time: 0:00:00.508398
elapsed time: 0:00:14.685459
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 14:58:01.502691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2987.69
 ---- batch: 020 ----
mean loss: 2922.85
 ---- batch: 030 ----
mean loss: 2900.35
train mean loss: 2926.39
epoch train time: 0:00:00.504632
elapsed time: 0:00:15.190374
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 14:58:02.007593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2824.92
 ---- batch: 020 ----
mean loss: 2745.39
 ---- batch: 030 ----
mean loss: 2695.47
train mean loss: 2743.33
epoch train time: 0:00:00.498415
elapsed time: 0:00:15.689059
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 14:58:02.506277
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2631.72
 ---- batch: 020 ----
mean loss: 2596.03
 ---- batch: 030 ----
mean loss: 2506.84
train mean loss: 2565.61
epoch train time: 0:00:00.519548
elapsed time: 0:00:16.208888
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 14:58:03.026129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2444.50
 ---- batch: 020 ----
mean loss: 2400.15
 ---- batch: 030 ----
mean loss: 2366.12
train mean loss: 2392.19
epoch train time: 0:00:00.509977
elapsed time: 0:00:16.719164
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 14:58:03.536393
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2304.21
 ---- batch: 020 ----
mean loss: 2236.61
 ---- batch: 030 ----
mean loss: 2206.41
train mean loss: 2233.08
epoch train time: 0:00:00.519554
elapsed time: 0:00:17.239042
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 14:58:04.056267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2123.00
 ---- batch: 020 ----
mean loss: 2116.38
 ---- batch: 030 ----
mean loss: 2061.83
train mean loss: 2089.87
epoch train time: 0:00:00.525123
elapsed time: 0:00:17.764455
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 14:58:04.581699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2007.75
 ---- batch: 020 ----
mean loss: 1986.22
 ---- batch: 030 ----
mean loss: 1912.79
train mean loss: 1966.89
epoch train time: 0:00:00.528377
elapsed time: 0:00:18.293125
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 14:58:05.110339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1903.09
 ---- batch: 020 ----
mean loss: 1841.94
 ---- batch: 030 ----
mean loss: 1850.62
train mean loss: 1850.89
epoch train time: 0:00:00.493256
elapsed time: 0:00:18.786691
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 14:58:05.603910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1804.34
 ---- batch: 020 ----
mean loss: 1756.83
 ---- batch: 030 ----
mean loss: 1698.99
train mean loss: 1738.43
epoch train time: 0:00:00.505667
elapsed time: 0:00:19.292692
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 14:58:06.109913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1664.58
 ---- batch: 020 ----
mean loss: 1632.28
 ---- batch: 030 ----
mean loss: 1608.22
train mean loss: 1625.71
epoch train time: 0:00:00.509377
elapsed time: 0:00:19.802336
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 14:58:06.619555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1542.26
 ---- batch: 020 ----
mean loss: 1515.84
 ---- batch: 030 ----
mean loss: 1503.08
train mean loss: 1513.74
epoch train time: 0:00:00.508092
elapsed time: 0:00:20.310704
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 14:58:07.127943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1455.31
 ---- batch: 020 ----
mean loss: 1411.63
 ---- batch: 030 ----
mean loss: 1396.06
train mean loss: 1415.38
epoch train time: 0:00:00.493793
elapsed time: 0:00:20.804780
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 14:58:07.622009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1366.82
 ---- batch: 020 ----
mean loss: 1334.42
 ---- batch: 030 ----
mean loss: 1290.19
train mean loss: 1330.44
epoch train time: 0:00:00.516224
elapsed time: 0:00:21.321299
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 14:58:08.138540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1284.36
 ---- batch: 020 ----
mean loss: 1260.53
 ---- batch: 030 ----
mean loss: 1237.95
train mean loss: 1255.32
epoch train time: 0:00:00.508815
elapsed time: 0:00:21.830421
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 14:58:08.647658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1210.45
 ---- batch: 020 ----
mean loss: 1186.62
 ---- batch: 030 ----
mean loss: 1161.30
train mean loss: 1181.95
epoch train time: 0:00:00.518457
elapsed time: 0:00:22.349159
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 14:58:09.166392
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1121.31
 ---- batch: 020 ----
mean loss: 1121.52
 ---- batch: 030 ----
mean loss: 1104.29
train mean loss: 1116.71
epoch train time: 0:00:00.509353
elapsed time: 0:00:22.858848
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 14:58:09.676072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1071.64
 ---- batch: 020 ----
mean loss: 1080.90
 ---- batch: 030 ----
mean loss: 1048.73
train mean loss: 1057.68
epoch train time: 0:00:00.505058
elapsed time: 0:00:23.364182
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 14:58:10.181405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1032.54
 ---- batch: 020 ----
mean loss: 1005.94
 ---- batch: 030 ----
mean loss: 1001.80
train mean loss: 1005.61
epoch train time: 0:00:00.523704
elapsed time: 0:00:23.888246
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 14:58:10.705462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 956.06
 ---- batch: 020 ----
mean loss: 967.34
 ---- batch: 030 ----
mean loss: 951.81
train mean loss: 950.26
epoch train time: 0:00:00.518383
elapsed time: 0:00:24.406903
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 14:58:11.224122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 932.64
 ---- batch: 020 ----
mean loss: 918.43
 ---- batch: 030 ----
mean loss: 892.40
train mean loss: 907.88
epoch train time: 0:00:00.508143
elapsed time: 0:00:24.915369
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 14:58:11.732592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 865.92
 ---- batch: 020 ----
mean loss: 886.00
 ---- batch: 030 ----
mean loss: 859.25
train mean loss: 866.50
epoch train time: 0:00:00.513772
elapsed time: 0:00:25.429434
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 14:58:12.246657
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 845.29
 ---- batch: 020 ----
mean loss: 834.26
 ---- batch: 030 ----
mean loss: 800.05
train mean loss: 827.66
epoch train time: 0:00:00.519395
elapsed time: 0:00:25.949123
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 14:58:12.766353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 810.02
 ---- batch: 020 ----
mean loss: 793.41
 ---- batch: 030 ----
mean loss: 777.88
train mean loss: 792.84
epoch train time: 0:00:00.512660
elapsed time: 0:00:26.462077
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 14:58:13.279303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 764.62
 ---- batch: 020 ----
mean loss: 777.43
 ---- batch: 030 ----
mean loss: 749.53
train mean loss: 758.67
epoch train time: 0:00:00.512828
elapsed time: 0:00:26.975240
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 14:58:13.792473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 738.22
 ---- batch: 020 ----
mean loss: 727.75
 ---- batch: 030 ----
mean loss: 721.76
train mean loss: 729.56
epoch train time: 0:00:00.507850
elapsed time: 0:00:27.483391
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 14:58:14.300678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 704.82
 ---- batch: 020 ----
mean loss: 693.26
 ---- batch: 030 ----
mean loss: 708.22
train mean loss: 700.19
epoch train time: 0:00:00.527050
elapsed time: 0:00:28.010816
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 14:58:14.828069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 686.72
 ---- batch: 020 ----
mean loss: 682.93
 ---- batch: 030 ----
mean loss: 667.26
train mean loss: 675.86
epoch train time: 0:00:00.519259
elapsed time: 0:00:28.530402
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 14:58:15.347623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 667.14
 ---- batch: 020 ----
mean loss: 649.76
 ---- batch: 030 ----
mean loss: 642.01
train mean loss: 654.75
epoch train time: 0:00:00.510227
elapsed time: 0:00:29.040903
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 14:58:15.858122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 640.16
 ---- batch: 020 ----
mean loss: 640.20
 ---- batch: 030 ----
mean loss: 619.74
train mean loss: 630.42
epoch train time: 0:00:00.497514
elapsed time: 0:00:29.538682
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 14:58:16.355897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 615.97
 ---- batch: 020 ----
mean loss: 621.61
 ---- batch: 030 ----
mean loss: 606.18
train mean loss: 612.81
epoch train time: 0:00:00.504407
elapsed time: 0:00:30.043370
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 14:58:16.860593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 597.85
 ---- batch: 020 ----
mean loss: 591.00
 ---- batch: 030 ----
mean loss: 599.57
train mean loss: 594.31
epoch train time: 0:00:00.507508
elapsed time: 0:00:30.551152
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 14:58:17.368371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 584.34
 ---- batch: 020 ----
mean loss: 577.17
 ---- batch: 030 ----
mean loss: 573.38
train mean loss: 576.03
epoch train time: 0:00:00.505533
elapsed time: 0:00:31.056975
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 14:58:17.874199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 565.46
 ---- batch: 020 ----
mean loss: 558.74
 ---- batch: 030 ----
mean loss: 559.12
train mean loss: 559.88
epoch train time: 0:00:00.508665
elapsed time: 0:00:31.565931
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 14:58:18.383152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.67
 ---- batch: 020 ----
mean loss: 545.33
 ---- batch: 030 ----
mean loss: 535.44
train mean loss: 543.03
epoch train time: 0:00:00.536734
elapsed time: 0:00:32.102938
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 14:58:18.920175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 531.27
 ---- batch: 020 ----
mean loss: 531.88
 ---- batch: 030 ----
mean loss: 533.69
train mean loss: 531.85
epoch train time: 0:00:00.521445
elapsed time: 0:00:32.624722
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 14:58:19.441945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 524.49
 ---- batch: 020 ----
mean loss: 515.03
 ---- batch: 030 ----
mean loss: 521.08
train mean loss: 520.43
epoch train time: 0:00:00.532613
elapsed time: 0:00:33.157638
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 14:58:19.974861
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 515.21
 ---- batch: 020 ----
mean loss: 505.41
 ---- batch: 030 ----
mean loss: 511.55
train mean loss: 509.69
epoch train time: 0:00:00.517841
elapsed time: 0:00:33.675765
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 14:58:20.492995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 504.60
 ---- batch: 020 ----
mean loss: 496.59
 ---- batch: 030 ----
mean loss: 494.14
train mean loss: 498.28
epoch train time: 0:00:00.512901
elapsed time: 0:00:34.189002
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 14:58:21.006298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 491.19
 ---- batch: 020 ----
mean loss: 500.98
 ---- batch: 030 ----
mean loss: 487.76
train mean loss: 491.51
epoch train time: 0:00:00.508494
elapsed time: 0:00:34.697847
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 14:58:21.515066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 478.40
 ---- batch: 020 ----
mean loss: 475.97
 ---- batch: 030 ----
mean loss: 480.27
train mean loss: 479.00
epoch train time: 0:00:00.505415
elapsed time: 0:00:35.203590
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 14:58:22.020811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 474.07
 ---- batch: 020 ----
mean loss: 470.81
 ---- batch: 030 ----
mean loss: 468.04
train mean loss: 472.55
epoch train time: 0:00:00.509863
elapsed time: 0:00:35.713739
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 14:58:22.530958
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 461.27
 ---- batch: 020 ----
mean loss: 466.53
 ---- batch: 030 ----
mean loss: 461.29
train mean loss: 462.66
epoch train time: 0:00:00.516841
elapsed time: 0:00:36.230874
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 14:58:23.048102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 456.11
 ---- batch: 020 ----
mean loss: 460.06
 ---- batch: 030 ----
mean loss: 454.10
train mean loss: 454.40
epoch train time: 0:00:00.499774
elapsed time: 0:00:36.730936
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 14:58:23.548155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 459.13
 ---- batch: 020 ----
mean loss: 449.62
 ---- batch: 030 ----
mean loss: 441.82
train mean loss: 448.53
epoch train time: 0:00:00.508407
elapsed time: 0:00:37.239621
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 14:58:24.056842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 451.51
 ---- batch: 020 ----
mean loss: 440.10
 ---- batch: 030 ----
mean loss: 437.50
train mean loss: 440.74
epoch train time: 0:00:00.512021
elapsed time: 0:00:37.751919
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 14:58:24.569137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 438.20
 ---- batch: 020 ----
mean loss: 436.35
 ---- batch: 030 ----
mean loss: 439.06
train mean loss: 435.99
epoch train time: 0:00:00.514845
elapsed time: 0:00:38.267041
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 14:58:25.084260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 431.66
 ---- batch: 020 ----
mean loss: 421.46
 ---- batch: 030 ----
mean loss: 433.16
train mean loss: 428.88
epoch train time: 0:00:00.511462
elapsed time: 0:00:38.778779
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 14:58:25.596007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 424.30
 ---- batch: 020 ----
mean loss: 426.68
 ---- batch: 030 ----
mean loss: 414.25
train mean loss: 422.26
epoch train time: 0:00:00.513875
elapsed time: 0:00:39.292951
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 14:58:26.110174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.74
 ---- batch: 020 ----
mean loss: 419.37
 ---- batch: 030 ----
mean loss: 419.24
train mean loss: 418.40
epoch train time: 0:00:00.512619
elapsed time: 0:00:39.805852
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 14:58:26.623072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.89
 ---- batch: 020 ----
mean loss: 416.32
 ---- batch: 030 ----
mean loss: 408.91
train mean loss: 412.68
epoch train time: 0:00:00.514281
elapsed time: 0:00:40.320436
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 14:58:27.137684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 413.60
 ---- batch: 020 ----
mean loss: 408.75
 ---- batch: 030 ----
mean loss: 408.24
train mean loss: 408.47
epoch train time: 0:00:00.512958
elapsed time: 0:00:40.833711
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 14:58:27.650954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 402.53
 ---- batch: 020 ----
mean loss: 408.85
 ---- batch: 030 ----
mean loss: 398.29
train mean loss: 402.37
epoch train time: 0:00:00.535304
elapsed time: 0:00:41.369345
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 14:58:28.186570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 402.25
 ---- batch: 020 ----
mean loss: 396.16
 ---- batch: 030 ----
mean loss: 396.82
train mean loss: 397.42
epoch train time: 0:00:00.522726
elapsed time: 0:00:41.892432
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 14:58:28.709693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 390.35
 ---- batch: 020 ----
mean loss: 404.44
 ---- batch: 030 ----
mean loss: 391.91
train mean loss: 393.16
epoch train time: 0:00:00.529243
elapsed time: 0:00:42.422143
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 14:58:29.239401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 396.29
 ---- batch: 020 ----
mean loss: 393.53
 ---- batch: 030 ----
mean loss: 385.09
train mean loss: 390.61
epoch train time: 0:00:00.525420
elapsed time: 0:00:42.947918
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 14:58:29.765140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 391.40
 ---- batch: 020 ----
mean loss: 378.96
 ---- batch: 030 ----
mean loss: 381.85
train mean loss: 385.32
epoch train time: 0:00:00.509581
elapsed time: 0:00:43.457818
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 14:58:30.275040
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 376.05
 ---- batch: 020 ----
mean loss: 376.20
 ---- batch: 030 ----
mean loss: 389.15
train mean loss: 380.68
epoch train time: 0:00:00.513750
elapsed time: 0:00:43.971943
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 14:58:30.789167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 375.32
 ---- batch: 020 ----
mean loss: 380.96
 ---- batch: 030 ----
mean loss: 375.08
train mean loss: 378.90
epoch train time: 0:00:00.522964
elapsed time: 0:00:44.495226
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 14:58:31.312457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.78
 ---- batch: 020 ----
mean loss: 380.33
 ---- batch: 030 ----
mean loss: 372.40
train mean loss: 375.33
epoch train time: 0:00:00.524330
elapsed time: 0:00:45.019932
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 14:58:31.837162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 377.98
 ---- batch: 020 ----
mean loss: 368.75
 ---- batch: 030 ----
mean loss: 374.01
train mean loss: 373.14
epoch train time: 0:00:00.524989
elapsed time: 0:00:45.545230
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 14:58:32.362462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 370.81
 ---- batch: 020 ----
mean loss: 364.96
 ---- batch: 030 ----
mean loss: 370.69
train mean loss: 370.30
epoch train time: 0:00:00.529531
elapsed time: 0:00:46.075109
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 14:58:32.892335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 368.50
 ---- batch: 020 ----
mean loss: 368.77
 ---- batch: 030 ----
mean loss: 364.72
train mean loss: 367.76
epoch train time: 0:00:00.516078
elapsed time: 0:00:46.591548
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 14:58:33.408801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 366.17
 ---- batch: 020 ----
mean loss: 362.22
 ---- batch: 030 ----
mean loss: 367.33
train mean loss: 365.70
epoch train time: 0:00:00.521703
elapsed time: 0:00:47.113662
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 14:58:33.930891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.53
 ---- batch: 020 ----
mean loss: 365.35
 ---- batch: 030 ----
mean loss: 360.47
train mean loss: 361.82
epoch train time: 0:00:00.513898
elapsed time: 0:00:47.627863
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 14:58:34.445096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.70
 ---- batch: 020 ----
mean loss: 359.45
 ---- batch: 030 ----
mean loss: 360.34
train mean loss: 360.74
epoch train time: 0:00:00.528024
elapsed time: 0:00:48.156233
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 14:58:34.973487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.39
 ---- batch: 020 ----
mean loss: 353.42
 ---- batch: 030 ----
mean loss: 361.38
train mean loss: 359.06
epoch train time: 0:00:00.520488
elapsed time: 0:00:48.677159
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 14:58:35.494415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 361.92
 ---- batch: 020 ----
mean loss: 353.38
 ---- batch: 030 ----
mean loss: 350.82
train mean loss: 356.01
epoch train time: 0:00:00.524136
elapsed time: 0:00:49.201713
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 14:58:36.018960
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 355.82
 ---- batch: 020 ----
mean loss: 355.81
 ---- batch: 030 ----
mean loss: 350.83
train mean loss: 353.45
epoch train time: 0:00:00.515304
elapsed time: 0:00:49.717327
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 14:58:36.534549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 352.38
 ---- batch: 020 ----
mean loss: 359.13
 ---- batch: 030 ----
mean loss: 349.26
train mean loss: 352.48
epoch train time: 0:00:00.526554
elapsed time: 0:00:50.244165
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 14:58:37.061400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 352.72
 ---- batch: 020 ----
mean loss: 349.58
 ---- batch: 030 ----
mean loss: 350.51
train mean loss: 350.15
epoch train time: 0:00:00.529497
elapsed time: 0:00:50.773991
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 14:58:37.591234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 347.01
 ---- batch: 020 ----
mean loss: 351.91
 ---- batch: 030 ----
mean loss: 347.01
train mean loss: 348.01
epoch train time: 0:00:00.537773
elapsed time: 0:00:51.312055
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 14:58:38.129273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.98
 ---- batch: 020 ----
mean loss: 342.49
 ---- batch: 030 ----
mean loss: 345.74
train mean loss: 346.87
epoch train time: 0:00:00.509550
elapsed time: 0:00:51.821901
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 14:58:38.639123
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.88
 ---- batch: 020 ----
mean loss: 346.90
 ---- batch: 030 ----
mean loss: 348.94
train mean loss: 345.00
epoch train time: 0:00:00.511782
elapsed time: 0:00:52.333966
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 14:58:39.151203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.58
 ---- batch: 020 ----
mean loss: 336.96
 ---- batch: 030 ----
mean loss: 337.98
train mean loss: 342.94
epoch train time: 0:00:00.510477
elapsed time: 0:00:52.844765
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 14:58:39.661988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 339.39
 ---- batch: 020 ----
mean loss: 342.52
 ---- batch: 030 ----
mean loss: 343.76
train mean loss: 341.87
epoch train time: 0:00:00.551269
elapsed time: 0:00:53.396370
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 14:58:40.213592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 335.08
 ---- batch: 020 ----
mean loss: 336.66
 ---- batch: 030 ----
mean loss: 352.99
train mean loss: 339.98
epoch train time: 0:00:00.516497
elapsed time: 0:00:53.913213
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 14:58:40.730470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 334.04
 ---- batch: 020 ----
mean loss: 342.57
 ---- batch: 030 ----
mean loss: 338.43
train mean loss: 339.70
epoch train time: 0:00:00.516600
elapsed time: 0:00:54.430130
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 14:58:41.247352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 341.92
 ---- batch: 020 ----
mean loss: 335.45
 ---- batch: 030 ----
mean loss: 337.56
train mean loss: 338.40
epoch train time: 0:00:00.516852
elapsed time: 0:00:54.947273
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 14:58:41.764506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.37
 ---- batch: 020 ----
mean loss: 339.06
 ---- batch: 030 ----
mean loss: 334.47
train mean loss: 335.37
epoch train time: 0:00:00.528242
elapsed time: 0:00:55.475843
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 14:58:42.293092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 334.53
 ---- batch: 020 ----
mean loss: 330.62
 ---- batch: 030 ----
mean loss: 335.28
train mean loss: 334.30
epoch train time: 0:00:00.533603
elapsed time: 0:00:56.009770
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 14:58:42.826988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 330.21
 ---- batch: 020 ----
mean loss: 337.50
 ---- batch: 030 ----
mean loss: 331.74
train mean loss: 333.25
epoch train time: 0:00:00.533030
elapsed time: 0:00:56.543159
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 14:58:43.360382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.70
 ---- batch: 020 ----
mean loss: 332.73
 ---- batch: 030 ----
mean loss: 329.82
train mean loss: 331.59
epoch train time: 0:00:00.535762
elapsed time: 0:00:57.079224
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 14:58:43.896458
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 332.69
 ---- batch: 020 ----
mean loss: 339.13
 ---- batch: 030 ----
mean loss: 322.83
train mean loss: 330.41
epoch train time: 0:00:00.524873
elapsed time: 0:00:57.604418
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 14:58:44.421664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 335.14
 ---- batch: 020 ----
mean loss: 325.70
 ---- batch: 030 ----
mean loss: 322.70
train mean loss: 329.15
epoch train time: 0:00:00.531971
elapsed time: 0:00:58.136733
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 14:58:44.953968
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.42
 ---- batch: 020 ----
mean loss: 325.66
 ---- batch: 030 ----
mean loss: 331.60
train mean loss: 328.41
epoch train time: 0:00:00.535053
elapsed time: 0:00:58.672102
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 14:58:45.489320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.53
 ---- batch: 020 ----
mean loss: 328.27
 ---- batch: 030 ----
mean loss: 328.20
train mean loss: 325.74
epoch train time: 0:00:00.524912
elapsed time: 0:00:59.197355
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 14:58:46.014581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.55
 ---- batch: 020 ----
mean loss: 326.52
 ---- batch: 030 ----
mean loss: 329.89
train mean loss: 325.93
epoch train time: 0:00:00.526014
elapsed time: 0:00:59.723700
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 14:58:46.540920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.69
 ---- batch: 020 ----
mean loss: 323.92
 ---- batch: 030 ----
mean loss: 319.92
train mean loss: 323.34
epoch train time: 0:00:00.538282
elapsed time: 0:01:00.262267
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 14:58:47.079497
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.65
 ---- batch: 020 ----
mean loss: 317.99
 ---- batch: 030 ----
mean loss: 325.56
train mean loss: 323.24
epoch train time: 0:00:00.525921
elapsed time: 0:01:00.788526
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 14:58:47.605749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.91
 ---- batch: 020 ----
mean loss: 317.83
 ---- batch: 030 ----
mean loss: 328.00
train mean loss: 322.34
epoch train time: 0:00:00.527513
elapsed time: 0:01:01.316335
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 14:58:48.133551
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.13
 ---- batch: 020 ----
mean loss: 316.56
 ---- batch: 030 ----
mean loss: 324.78
train mean loss: 320.14
epoch train time: 0:00:00.515039
elapsed time: 0:01:01.831659
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 14:58:48.648893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.71
 ---- batch: 020 ----
mean loss: 319.31
 ---- batch: 030 ----
mean loss: 324.44
train mean loss: 319.27
epoch train time: 0:00:00.532568
elapsed time: 0:01:02.364578
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 14:58:49.181826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.17
 ---- batch: 020 ----
mean loss: 314.70
 ---- batch: 030 ----
mean loss: 318.36
train mean loss: 318.29
epoch train time: 0:00:00.528291
elapsed time: 0:01:02.893184
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 14:58:49.710398
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 316.95
 ---- batch: 020 ----
mean loss: 315.57
 ---- batch: 030 ----
mean loss: 315.24
train mean loss: 317.35
epoch train time: 0:00:00.526394
elapsed time: 0:01:03.419850
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 14:58:50.237069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.49
 ---- batch: 020 ----
mean loss: 309.55
 ---- batch: 030 ----
mean loss: 319.98
train mean loss: 315.54
epoch train time: 0:00:00.524362
elapsed time: 0:01:03.944526
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 14:58:50.761775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.43
 ---- batch: 020 ----
mean loss: 317.26
 ---- batch: 030 ----
mean loss: 308.35
train mean loss: 315.96
epoch train time: 0:00:00.523267
elapsed time: 0:01:04.468135
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 14:58:51.285386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.36
 ---- batch: 020 ----
mean loss: 320.08
 ---- batch: 030 ----
mean loss: 314.54
train mean loss: 313.57
epoch train time: 0:00:00.519099
elapsed time: 0:01:04.987580
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 14:58:51.804804
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.94
 ---- batch: 020 ----
mean loss: 314.29
 ---- batch: 030 ----
mean loss: 312.48
train mean loss: 311.68
epoch train time: 0:00:00.516872
elapsed time: 0:01:05.504740
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 14:58:52.321958
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.07
 ---- batch: 020 ----
mean loss: 316.94
 ---- batch: 030 ----
mean loss: 312.13
train mean loss: 311.77
epoch train time: 0:00:00.540591
elapsed time: 0:01:06.045692
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 14:58:52.863075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.66
 ---- batch: 020 ----
mean loss: 315.49
 ---- batch: 030 ----
mean loss: 311.57
train mean loss: 310.13
epoch train time: 0:00:00.509638
elapsed time: 0:01:06.555832
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 14:58:53.373066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 302.75
 ---- batch: 020 ----
mean loss: 311.10
 ---- batch: 030 ----
mean loss: 314.36
train mean loss: 309.15
epoch train time: 0:00:00.520696
elapsed time: 0:01:07.076856
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 14:58:53.894081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.98
 ---- batch: 020 ----
mean loss: 310.72
 ---- batch: 030 ----
mean loss: 309.17
train mean loss: 308.75
epoch train time: 0:00:00.528438
elapsed time: 0:01:07.605637
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 14:58:54.422811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 310.43
 ---- batch: 020 ----
mean loss: 301.02
 ---- batch: 030 ----
mean loss: 311.20
train mean loss: 307.29
epoch train time: 0:00:00.532923
elapsed time: 0:01:08.138802
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 14:58:54.956025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.81
 ---- batch: 020 ----
mean loss: 313.15
 ---- batch: 030 ----
mean loss: 299.77
train mean loss: 305.67
epoch train time: 0:00:00.504439
elapsed time: 0:01:08.643588
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 14:58:55.460808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.70
 ---- batch: 020 ----
mean loss: 299.30
 ---- batch: 030 ----
mean loss: 307.49
train mean loss: 305.08
epoch train time: 0:00:00.516151
elapsed time: 0:01:09.160012
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 14:58:55.977248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 305.59
 ---- batch: 020 ----
mean loss: 304.90
 ---- batch: 030 ----
mean loss: 305.10
train mean loss: 303.74
epoch train time: 0:00:00.517009
elapsed time: 0:01:09.677332
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 14:58:56.494555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.46
 ---- batch: 020 ----
mean loss: 298.83
 ---- batch: 030 ----
mean loss: 305.19
train mean loss: 302.84
epoch train time: 0:00:00.512239
elapsed time: 0:01:10.189846
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 14:58:57.007064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.79
 ---- batch: 020 ----
mean loss: 300.62
 ---- batch: 030 ----
mean loss: 298.34
train mean loss: 302.25
epoch train time: 0:00:00.507670
elapsed time: 0:01:10.697795
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 14:58:57.515086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.96
 ---- batch: 020 ----
mean loss: 301.00
 ---- batch: 030 ----
mean loss: 302.87
train mean loss: 301.31
epoch train time: 0:00:00.513949
elapsed time: 0:01:11.212095
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 14:58:58.029318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.66
 ---- batch: 020 ----
mean loss: 303.54
 ---- batch: 030 ----
mean loss: 306.25
train mean loss: 300.02
epoch train time: 0:00:00.512618
elapsed time: 0:01:11.724994
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 14:58:58.542216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.21
 ---- batch: 020 ----
mean loss: 303.09
 ---- batch: 030 ----
mean loss: 297.23
train mean loss: 299.82
epoch train time: 0:00:00.519035
elapsed time: 0:01:12.244347
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 14:58:59.061540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.75
 ---- batch: 020 ----
mean loss: 300.92
 ---- batch: 030 ----
mean loss: 298.89
train mean loss: 297.60
epoch train time: 0:00:00.518046
elapsed time: 0:01:12.762677
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 14:58:59.579896
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.04
 ---- batch: 020 ----
mean loss: 301.02
 ---- batch: 030 ----
mean loss: 297.84
train mean loss: 296.49
epoch train time: 0:00:00.511881
elapsed time: 0:01:13.274832
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 14:59:00.092051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.21
 ---- batch: 020 ----
mean loss: 298.16
 ---- batch: 030 ----
mean loss: 295.97
train mean loss: 296.19
epoch train time: 0:00:00.509522
elapsed time: 0:01:13.784728
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 14:59:00.601950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.91
 ---- batch: 020 ----
mean loss: 289.76
 ---- batch: 030 ----
mean loss: 295.84
train mean loss: 294.74
epoch train time: 0:00:00.536624
elapsed time: 0:01:14.321657
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 14:59:01.138885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.12
 ---- batch: 020 ----
mean loss: 290.84
 ---- batch: 030 ----
mean loss: 291.40
train mean loss: 293.91
epoch train time: 0:00:00.544058
elapsed time: 0:01:14.866031
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 14:59:01.683263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.93
 ---- batch: 020 ----
mean loss: 293.04
 ---- batch: 030 ----
mean loss: 298.44
train mean loss: 293.61
epoch train time: 0:00:00.519472
elapsed time: 0:01:15.385874
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 14:59:02.203096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 295.61
 ---- batch: 020 ----
mean loss: 291.35
 ---- batch: 030 ----
mean loss: 293.96
train mean loss: 292.04
epoch train time: 0:00:00.523985
elapsed time: 0:01:15.910158
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 14:59:02.727384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.82
 ---- batch: 020 ----
mean loss: 288.59
 ---- batch: 030 ----
mean loss: 292.94
train mean loss: 290.44
epoch train time: 0:00:00.535753
elapsed time: 0:01:16.446233
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 14:59:03.263493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.98
 ---- batch: 020 ----
mean loss: 284.23
 ---- batch: 030 ----
mean loss: 289.40
train mean loss: 289.40
epoch train time: 0:00:00.535318
elapsed time: 0:01:16.981896
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 14:59:03.799170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.74
 ---- batch: 020 ----
mean loss: 284.81
 ---- batch: 030 ----
mean loss: 282.57
train mean loss: 289.44
epoch train time: 0:00:00.526707
elapsed time: 0:01:17.508953
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 14:59:04.326178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.53
 ---- batch: 020 ----
mean loss: 291.54
 ---- batch: 030 ----
mean loss: 288.46
train mean loss: 288.17
epoch train time: 0:00:00.524696
elapsed time: 0:01:18.033994
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 14:59:04.851174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.22
 ---- batch: 020 ----
mean loss: 285.91
 ---- batch: 030 ----
mean loss: 291.70
train mean loss: 287.81
epoch train time: 0:00:00.512077
elapsed time: 0:01:18.546347
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 14:59:05.363569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.12
 ---- batch: 020 ----
mean loss: 288.29
 ---- batch: 030 ----
mean loss: 284.95
train mean loss: 286.09
epoch train time: 0:00:00.521483
elapsed time: 0:01:19.068146
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 14:59:05.885377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.99
 ---- batch: 020 ----
mean loss: 286.10
 ---- batch: 030 ----
mean loss: 285.65
train mean loss: 285.25
epoch train time: 0:00:00.514304
elapsed time: 0:01:19.582744
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 14:59:06.399966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.24
 ---- batch: 020 ----
mean loss: 282.61
 ---- batch: 030 ----
mean loss: 293.51
train mean loss: 284.87
epoch train time: 0:00:00.513975
elapsed time: 0:01:20.097056
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 14:59:06.914281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.65
 ---- batch: 020 ----
mean loss: 290.58
 ---- batch: 030 ----
mean loss: 280.68
train mean loss: 283.60
epoch train time: 0:00:00.509894
elapsed time: 0:01:20.607230
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 14:59:07.424453
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 281.32
 ---- batch: 020 ----
mean loss: 285.64
 ---- batch: 030 ----
mean loss: 285.81
train mean loss: 282.71
epoch train time: 0:00:00.523424
elapsed time: 0:01:21.130941
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 14:59:07.948164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.38
 ---- batch: 020 ----
mean loss: 277.50
 ---- batch: 030 ----
mean loss: 277.05
train mean loss: 281.52
epoch train time: 0:00:00.520445
elapsed time: 0:01:21.651675
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 14:59:08.468899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.19
 ---- batch: 020 ----
mean loss: 277.43
 ---- batch: 030 ----
mean loss: 284.56
train mean loss: 280.96
epoch train time: 0:00:00.516152
elapsed time: 0:01:22.168106
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 14:59:08.985330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.97
 ---- batch: 020 ----
mean loss: 282.15
 ---- batch: 030 ----
mean loss: 285.09
train mean loss: 280.46
epoch train time: 0:00:00.511669
elapsed time: 0:01:22.680062
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 14:59:09.497285
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 285.89
 ---- batch: 020 ----
mean loss: 277.25
 ---- batch: 030 ----
mean loss: 274.53
train mean loss: 279.43
epoch train time: 0:00:00.528776
elapsed time: 0:01:23.209148
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 14:59:10.026402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.95
 ---- batch: 020 ----
mean loss: 276.31
 ---- batch: 030 ----
mean loss: 280.92
train mean loss: 278.17
epoch train time: 0:00:00.528706
elapsed time: 0:01:23.738192
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 14:59:10.555415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.38
 ---- batch: 020 ----
mean loss: 276.17
 ---- batch: 030 ----
mean loss: 279.42
train mean loss: 277.22
epoch train time: 0:00:00.527808
elapsed time: 0:01:24.266293
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 14:59:11.083516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 279.09
 ---- batch: 020 ----
mean loss: 276.22
 ---- batch: 030 ----
mean loss: 271.21
train mean loss: 276.61
epoch train time: 0:00:00.514103
elapsed time: 0:01:24.780673
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 14:59:11.597892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.28
 ---- batch: 020 ----
mean loss: 278.78
 ---- batch: 030 ----
mean loss: 269.80
train mean loss: 275.72
epoch train time: 0:00:00.511217
elapsed time: 0:01:25.292153
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 14:59:12.109366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.84
 ---- batch: 020 ----
mean loss: 273.63
 ---- batch: 030 ----
mean loss: 272.99
train mean loss: 275.23
epoch train time: 0:00:00.522020
elapsed time: 0:01:25.814443
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 14:59:12.631691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.89
 ---- batch: 020 ----
mean loss: 276.30
 ---- batch: 030 ----
mean loss: 274.83
train mean loss: 273.61
epoch train time: 0:00:00.527606
elapsed time: 0:01:26.342439
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 14:59:13.159664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.52
 ---- batch: 020 ----
mean loss: 276.99
 ---- batch: 030 ----
mean loss: 271.25
train mean loss: 272.99
epoch train time: 0:00:00.536561
elapsed time: 0:01:26.879347
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 14:59:13.696571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 272.13
 ---- batch: 020 ----
mean loss: 270.75
 ---- batch: 030 ----
mean loss: 274.37
train mean loss: 271.85
epoch train time: 0:00:00.541559
elapsed time: 0:01:27.421186
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 14:59:14.238405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.39
 ---- batch: 020 ----
mean loss: 275.24
 ---- batch: 030 ----
mean loss: 268.65
train mean loss: 271.71
epoch train time: 0:00:00.527876
elapsed time: 0:01:27.949398
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 14:59:14.766636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 272.99
 ---- batch: 020 ----
mean loss: 272.65
 ---- batch: 030 ----
mean loss: 269.53
train mean loss: 270.26
epoch train time: 0:00:00.519199
elapsed time: 0:01:28.468909
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 14:59:15.286145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.60
 ---- batch: 020 ----
mean loss: 267.99
 ---- batch: 030 ----
mean loss: 268.17
train mean loss: 269.43
epoch train time: 0:00:00.518994
elapsed time: 0:01:28.988204
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 14:59:15.805451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.83
 ---- batch: 020 ----
mean loss: 267.88
 ---- batch: 030 ----
mean loss: 273.36
train mean loss: 268.89
epoch train time: 0:00:00.525165
elapsed time: 0:01:29.513768
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 14:59:16.330945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.21
 ---- batch: 020 ----
mean loss: 264.02
 ---- batch: 030 ----
mean loss: 276.14
train mean loss: 267.54
epoch train time: 0:00:00.527465
elapsed time: 0:01:30.041494
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 14:59:16.858721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.68
 ---- batch: 020 ----
mean loss: 272.70
 ---- batch: 030 ----
mean loss: 264.75
train mean loss: 266.94
epoch train time: 0:00:00.516181
elapsed time: 0:01:30.557985
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 14:59:17.375291
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.63
 ---- batch: 020 ----
mean loss: 270.59
 ---- batch: 030 ----
mean loss: 264.89
train mean loss: 266.46
epoch train time: 0:00:00.519095
elapsed time: 0:01:31.077479
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 14:59:17.894701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.66
 ---- batch: 020 ----
mean loss: 267.06
 ---- batch: 030 ----
mean loss: 258.62
train mean loss: 265.40
epoch train time: 0:00:00.519378
elapsed time: 0:01:31.597162
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 14:59:18.414403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.54
 ---- batch: 020 ----
mean loss: 264.40
 ---- batch: 030 ----
mean loss: 266.86
train mean loss: 264.73
epoch train time: 0:00:00.523788
elapsed time: 0:01:32.121522
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 14:59:18.938781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.77
 ---- batch: 020 ----
mean loss: 265.20
 ---- batch: 030 ----
mean loss: 267.48
train mean loss: 263.96
epoch train time: 0:00:00.505461
elapsed time: 0:01:32.627388
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 14:59:19.444610
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.12
 ---- batch: 020 ----
mean loss: 260.42
 ---- batch: 030 ----
mean loss: 261.41
train mean loss: 263.48
epoch train time: 0:00:00.529412
elapsed time: 0:01:33.157145
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 14:59:19.974381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.33
 ---- batch: 020 ----
mean loss: 263.53
 ---- batch: 030 ----
mean loss: 257.16
train mean loss: 262.39
epoch train time: 0:00:00.517786
elapsed time: 0:01:33.675265
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 14:59:20.492488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.23
 ---- batch: 020 ----
mean loss: 266.76
 ---- batch: 030 ----
mean loss: 260.56
train mean loss: 261.24
epoch train time: 0:00:00.531417
elapsed time: 0:01:34.206981
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 14:59:21.024203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.55
 ---- batch: 020 ----
mean loss: 256.66
 ---- batch: 030 ----
mean loss: 263.03
train mean loss: 260.46
epoch train time: 0:00:00.530531
elapsed time: 0:01:34.737818
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 14:59:21.555042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.46
 ---- batch: 020 ----
mean loss: 259.77
 ---- batch: 030 ----
mean loss: 260.42
train mean loss: 260.55
epoch train time: 0:00:00.520585
elapsed time: 0:01:35.258718
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 14:59:22.075946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.01
 ---- batch: 020 ----
mean loss: 264.48
 ---- batch: 030 ----
mean loss: 257.20
train mean loss: 259.11
epoch train time: 0:00:00.524747
elapsed time: 0:01:35.783763
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 14:59:22.600998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.16
 ---- batch: 020 ----
mean loss: 255.27
 ---- batch: 030 ----
mean loss: 261.90
train mean loss: 257.96
epoch train time: 0:00:00.526689
elapsed time: 0:01:36.310771
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 14:59:23.128008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.65
 ---- batch: 020 ----
mean loss: 258.19
 ---- batch: 030 ----
mean loss: 261.96
train mean loss: 257.78
epoch train time: 0:00:00.515436
elapsed time: 0:01:36.826533
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 14:59:23.643751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.12
 ---- batch: 020 ----
mean loss: 261.69
 ---- batch: 030 ----
mean loss: 256.12
train mean loss: 256.77
epoch train time: 0:00:00.523790
elapsed time: 0:01:37.350627
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 14:59:24.167864
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.11
 ---- batch: 020 ----
mean loss: 260.49
 ---- batch: 030 ----
mean loss: 255.62
train mean loss: 256.36
epoch train time: 0:00:00.512616
elapsed time: 0:01:37.863575
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 14:59:24.680806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.15
 ---- batch: 020 ----
mean loss: 257.10
 ---- batch: 030 ----
mean loss: 251.66
train mean loss: 255.12
epoch train time: 0:00:00.547134
elapsed time: 0:01:38.411008
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 14:59:25.228223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.60
 ---- batch: 020 ----
mean loss: 257.81
 ---- batch: 030 ----
mean loss: 253.58
train mean loss: 254.35
epoch train time: 0:00:00.525947
elapsed time: 0:01:38.937246
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 14:59:25.754479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.54
 ---- batch: 020 ----
mean loss: 249.43
 ---- batch: 030 ----
mean loss: 258.63
train mean loss: 253.71
epoch train time: 0:00:00.512163
elapsed time: 0:01:39.449704
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 14:59:26.266936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.11
 ---- batch: 020 ----
mean loss: 251.88
 ---- batch: 030 ----
mean loss: 252.98
train mean loss: 252.65
epoch train time: 0:00:00.529593
elapsed time: 0:01:39.979624
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 14:59:26.796848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.05
 ---- batch: 020 ----
mean loss: 253.50
 ---- batch: 030 ----
mean loss: 248.00
train mean loss: 252.05
epoch train time: 0:00:00.519902
elapsed time: 0:01:40.499844
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 14:59:27.317066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.72
 ---- batch: 020 ----
mean loss: 252.63
 ---- batch: 030 ----
mean loss: 251.51
train mean loss: 251.60
epoch train time: 0:00:00.525205
elapsed time: 0:01:41.025367
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 14:59:27.842593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.00
 ---- batch: 020 ----
mean loss: 253.81
 ---- batch: 030 ----
mean loss: 254.55
train mean loss: 251.03
epoch train time: 0:00:00.522054
elapsed time: 0:01:41.547722
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 14:59:28.364951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.50
 ---- batch: 020 ----
mean loss: 242.45
 ---- batch: 030 ----
mean loss: 253.90
train mean loss: 250.61
epoch train time: 0:00:00.521828
elapsed time: 0:01:42.069878
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 14:59:28.887101
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.71
 ---- batch: 020 ----
mean loss: 253.89
 ---- batch: 030 ----
mean loss: 243.94
train mean loss: 249.33
epoch train time: 0:00:00.518376
elapsed time: 0:01:42.588695
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 14:59:29.405870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.19
 ---- batch: 020 ----
mean loss: 251.51
 ---- batch: 030 ----
mean loss: 251.14
train mean loss: 248.43
epoch train time: 0:00:00.535179
elapsed time: 0:01:43.124124
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 14:59:29.941361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.40
 ---- batch: 020 ----
mean loss: 247.24
 ---- batch: 030 ----
mean loss: 248.62
train mean loss: 247.97
epoch train time: 0:00:00.515841
elapsed time: 0:01:43.640267
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 14:59:30.457488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.83
 ---- batch: 020 ----
mean loss: 240.54
 ---- batch: 030 ----
mean loss: 254.23
train mean loss: 247.22
epoch train time: 0:00:00.518460
elapsed time: 0:01:44.159021
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 14:59:30.976240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.30
 ---- batch: 020 ----
mean loss: 241.55
 ---- batch: 030 ----
mean loss: 246.97
train mean loss: 246.58
epoch train time: 0:00:00.518208
elapsed time: 0:01:44.677510
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 14:59:31.494753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.06
 ---- batch: 020 ----
mean loss: 254.33
 ---- batch: 030 ----
mean loss: 240.37
train mean loss: 246.05
epoch train time: 0:00:00.527642
elapsed time: 0:01:45.205493
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 14:59:32.022716
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.44
 ---- batch: 020 ----
mean loss: 245.29
 ---- batch: 030 ----
mean loss: 248.88
train mean loss: 245.35
epoch train time: 0:00:00.521008
elapsed time: 0:01:45.726801
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 14:59:32.544022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.03
 ---- batch: 020 ----
mean loss: 246.98
 ---- batch: 030 ----
mean loss: 242.13
train mean loss: 244.40
epoch train time: 0:00:00.518864
elapsed time: 0:01:46.245995
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 14:59:33.063219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.52
 ---- batch: 020 ----
mean loss: 244.45
 ---- batch: 030 ----
mean loss: 244.46
train mean loss: 243.78
epoch train time: 0:00:00.513185
elapsed time: 0:01:46.759473
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 14:59:33.576696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.49
 ---- batch: 020 ----
mean loss: 244.27
 ---- batch: 030 ----
mean loss: 242.67
train mean loss: 243.53
epoch train time: 0:00:00.526614
elapsed time: 0:01:47.286494
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 14:59:34.103734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.75
 ---- batch: 020 ----
mean loss: 239.66
 ---- batch: 030 ----
mean loss: 244.49
train mean loss: 242.69
epoch train time: 0:00:00.523875
elapsed time: 0:01:47.810716
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 14:59:34.627941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.28
 ---- batch: 020 ----
mean loss: 236.55
 ---- batch: 030 ----
mean loss: 240.29
train mean loss: 241.32
epoch train time: 0:00:00.517815
elapsed time: 0:01:48.328829
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 14:59:35.146053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.61
 ---- batch: 020 ----
mean loss: 251.19
 ---- batch: 030 ----
mean loss: 232.45
train mean loss: 241.28
epoch train time: 0:00:00.515306
elapsed time: 0:01:48.844535
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 14:59:35.661762
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.23
 ---- batch: 020 ----
mean loss: 244.98
 ---- batch: 030 ----
mean loss: 238.68
train mean loss: 240.19
epoch train time: 0:00:00.531101
elapsed time: 0:01:49.376016
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 14:59:36.193257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.14
 ---- batch: 020 ----
mean loss: 247.15
 ---- batch: 030 ----
mean loss: 240.56
train mean loss: 240.17
epoch train time: 0:00:00.515755
elapsed time: 0:01:49.892120
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 14:59:36.709345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.33
 ---- batch: 020 ----
mean loss: 233.70
 ---- batch: 030 ----
mean loss: 244.88
train mean loss: 239.02
epoch train time: 0:00:00.515237
elapsed time: 0:01:50.407692
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 14:59:37.224926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.72
 ---- batch: 020 ----
mean loss: 241.43
 ---- batch: 030 ----
mean loss: 242.09
train mean loss: 238.26
epoch train time: 0:00:00.518104
elapsed time: 0:01:50.926227
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 14:59:37.743460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.28
 ---- batch: 020 ----
mean loss: 242.23
 ---- batch: 030 ----
mean loss: 236.55
train mean loss: 237.38
epoch train time: 0:00:00.544717
elapsed time: 0:01:51.471258
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 14:59:38.288522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.85
 ---- batch: 020 ----
mean loss: 237.41
 ---- batch: 030 ----
mean loss: 238.08
train mean loss: 236.87
epoch train time: 0:00:00.522941
elapsed time: 0:01:51.994586
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 14:59:38.811855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.24
 ---- batch: 020 ----
mean loss: 241.72
 ---- batch: 030 ----
mean loss: 230.61
train mean loss: 236.15
epoch train time: 0:00:00.521644
elapsed time: 0:01:52.516669
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 14:59:39.333897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.19
 ---- batch: 020 ----
mean loss: 240.40
 ---- batch: 030 ----
mean loss: 232.31
train mean loss: 235.53
epoch train time: 0:00:00.539505
elapsed time: 0:01:53.056594
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 14:59:39.873829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.37
 ---- batch: 020 ----
mean loss: 240.47
 ---- batch: 030 ----
mean loss: 231.92
train mean loss: 235.06
epoch train time: 0:00:00.530719
elapsed time: 0:01:53.587619
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 14:59:40.404837
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.72
 ---- batch: 020 ----
mean loss: 231.41
 ---- batch: 030 ----
mean loss: 237.26
train mean loss: 234.19
epoch train time: 0:00:00.534316
elapsed time: 0:01:54.122295
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 14:59:40.939529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.34
 ---- batch: 020 ----
mean loss: 232.54
 ---- batch: 030 ----
mean loss: 229.80
train mean loss: 233.21
epoch train time: 0:00:00.522305
elapsed time: 0:01:54.644905
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 14:59:41.462124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.13
 ---- batch: 020 ----
mean loss: 241.27
 ---- batch: 030 ----
mean loss: 231.30
train mean loss: 233.44
epoch train time: 0:00:00.536334
elapsed time: 0:01:55.181532
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 14:59:41.998752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.48
 ---- batch: 020 ----
mean loss: 234.57
 ---- batch: 030 ----
mean loss: 233.09
train mean loss: 232.54
epoch train time: 0:00:00.522974
elapsed time: 0:01:55.704786
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 14:59:42.522007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.37
 ---- batch: 020 ----
mean loss: 231.23
 ---- batch: 030 ----
mean loss: 235.68
train mean loss: 231.88
epoch train time: 0:00:00.526490
elapsed time: 0:01:56.231741
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 14:59:43.049054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.44
 ---- batch: 020 ----
mean loss: 233.10
 ---- batch: 030 ----
mean loss: 232.17
train mean loss: 231.40
epoch train time: 0:00:00.529311
elapsed time: 0:01:56.761482
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 14:59:43.578731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.21
 ---- batch: 020 ----
mean loss: 228.79
 ---- batch: 030 ----
mean loss: 233.92
train mean loss: 230.65
epoch train time: 0:00:00.527734
elapsed time: 0:01:57.289737
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 14:59:44.107751
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.83
 ---- batch: 020 ----
mean loss: 234.26
 ---- batch: 030 ----
mean loss: 234.95
train mean loss: 230.96
epoch train time: 0:00:00.517339
elapsed time: 0:01:57.808188
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 14:59:44.625405
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 236.45
 ---- batch: 020 ----
mean loss: 234.75
 ---- batch: 030 ----
mean loss: 222.50
train mean loss: 231.02
epoch train time: 0:00:00.529955
elapsed time: 0:01:58.338437
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 14:59:45.155676
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.90
 ---- batch: 020 ----
mean loss: 225.23
 ---- batch: 030 ----
mean loss: 236.03
train mean loss: 230.08
epoch train time: 0:00:00.529393
elapsed time: 0:01:58.868170
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 14:59:45.685430
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.76
 ---- batch: 020 ----
mean loss: 230.47
 ---- batch: 030 ----
mean loss: 229.18
train mean loss: 230.42
epoch train time: 0:00:00.538284
elapsed time: 0:01:59.406796
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 14:59:46.224019
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.06
 ---- batch: 020 ----
mean loss: 230.96
 ---- batch: 030 ----
mean loss: 226.43
train mean loss: 230.72
epoch train time: 0:00:00.540463
elapsed time: 0:01:59.947581
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 14:59:46.764806
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.94
 ---- batch: 020 ----
mean loss: 228.58
 ---- batch: 030 ----
mean loss: 235.19
train mean loss: 230.41
epoch train time: 0:00:00.528888
elapsed time: 0:02:00.476772
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 14:59:47.294005
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.54
 ---- batch: 020 ----
mean loss: 229.28
 ---- batch: 030 ----
mean loss: 231.35
train mean loss: 230.57
epoch train time: 0:00:00.530440
elapsed time: 0:02:01.007531
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 14:59:47.824750
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.12
 ---- batch: 020 ----
mean loss: 236.01
 ---- batch: 030 ----
mean loss: 229.99
train mean loss: 230.13
epoch train time: 0:00:00.519757
elapsed time: 0:02:01.527563
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 14:59:48.344783
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.56
 ---- batch: 020 ----
mean loss: 227.21
 ---- batch: 030 ----
mean loss: 236.12
train mean loss: 230.32
epoch train time: 0:00:00.518740
elapsed time: 0:02:02.046610
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 14:59:48.863832
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 225.97
 ---- batch: 020 ----
mean loss: 231.86
 ---- batch: 030 ----
mean loss: 235.35
train mean loss: 230.15
epoch train time: 0:00:00.520160
elapsed time: 0:02:02.567075
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 14:59:49.384299
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.77
 ---- batch: 020 ----
mean loss: 235.64
 ---- batch: 030 ----
mean loss: 230.48
train mean loss: 230.00
epoch train time: 0:00:00.533771
elapsed time: 0:02:03.101185
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 14:59:49.918409
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 239.46
 ---- batch: 020 ----
mean loss: 226.09
 ---- batch: 030 ----
mean loss: 224.71
train mean loss: 230.10
epoch train time: 0:00:00.522275
elapsed time: 0:02:03.623739
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 14:59:50.440986
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.88
 ---- batch: 020 ----
mean loss: 229.50
 ---- batch: 030 ----
mean loss: 226.22
train mean loss: 230.39
epoch train time: 0:00:00.519062
elapsed time: 0:02:04.143113
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 14:59:50.960336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.69
 ---- batch: 020 ----
mean loss: 228.19
 ---- batch: 030 ----
mean loss: 229.27
train mean loss: 229.61
epoch train time: 0:00:00.520423
elapsed time: 0:02:04.663831
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 14:59:51.481053
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.83
 ---- batch: 020 ----
mean loss: 231.43
 ---- batch: 030 ----
mean loss: 227.74
train mean loss: 229.82
epoch train time: 0:00:00.521624
elapsed time: 0:02:05.185780
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 14:59:52.003013
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.86
 ---- batch: 020 ----
mean loss: 226.48
 ---- batch: 030 ----
mean loss: 232.21
train mean loss: 229.95
epoch train time: 0:00:00.519313
elapsed time: 0:02:05.705394
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 14:59:52.522643
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.58
 ---- batch: 020 ----
mean loss: 225.75
 ---- batch: 030 ----
mean loss: 229.49
train mean loss: 230.23
epoch train time: 0:00:00.526584
elapsed time: 0:02:06.232313
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 14:59:53.049538
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 230.18
 ---- batch: 020 ----
mean loss: 229.94
 ---- batch: 030 ----
mean loss: 230.94
train mean loss: 229.61
epoch train time: 0:00:00.525272
elapsed time: 0:02:06.757924
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 14:59:53.575145
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 230.45
 ---- batch: 020 ----
mean loss: 231.09
 ---- batch: 030 ----
mean loss: 226.15
train mean loss: 229.70
epoch train time: 0:00:00.528270
elapsed time: 0:02:07.286479
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 14:59:54.103702
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.65
 ---- batch: 020 ----
mean loss: 232.24
 ---- batch: 030 ----
mean loss: 230.41
train mean loss: 230.04
epoch train time: 0:00:00.518097
elapsed time: 0:02:07.804866
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 14:59:54.622092
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 234.27
 ---- batch: 020 ----
mean loss: 222.78
 ---- batch: 030 ----
mean loss: 229.40
train mean loss: 229.25
epoch train time: 0:00:00.513535
elapsed time: 0:02:08.318701
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 14:59:55.135912
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.93
 ---- batch: 020 ----
mean loss: 229.85
 ---- batch: 030 ----
mean loss: 229.91
train mean loss: 229.48
epoch train time: 0:00:00.507517
elapsed time: 0:02:08.826513
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 14:59:55.643732
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.62
 ---- batch: 020 ----
mean loss: 230.47
 ---- batch: 030 ----
mean loss: 231.75
train mean loss: 229.63
epoch train time: 0:00:00.508537
elapsed time: 0:02:09.335325
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 14:59:56.152563
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.44
 ---- batch: 020 ----
mean loss: 231.62
 ---- batch: 030 ----
mean loss: 227.98
train mean loss: 229.40
epoch train time: 0:00:00.510069
elapsed time: 0:02:09.845689
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 14:59:56.662910
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.21
 ---- batch: 020 ----
mean loss: 228.96
 ---- batch: 030 ----
mean loss: 226.82
train mean loss: 228.65
epoch train time: 0:00:00.535527
elapsed time: 0:02:10.381511
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 14:59:57.198734
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.62
 ---- batch: 020 ----
mean loss: 230.79
 ---- batch: 030 ----
mean loss: 227.65
train mean loss: 228.87
epoch train time: 0:00:00.518861
elapsed time: 0:02:10.900686
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 14:59:57.717911
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 224.56
 ---- batch: 020 ----
mean loss: 233.34
 ---- batch: 030 ----
mean loss: 228.42
train mean loss: 229.38
epoch train time: 0:00:00.520704
elapsed time: 0:02:11.421675
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 14:59:58.238907
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 225.97
 ---- batch: 020 ----
mean loss: 228.13
 ---- batch: 030 ----
mean loss: 227.77
train mean loss: 229.04
epoch train time: 0:00:00.522465
elapsed time: 0:02:11.944439
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 14:59:58.761689
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.57
 ---- batch: 020 ----
mean loss: 235.50
 ---- batch: 030 ----
mean loss: 223.82
train mean loss: 228.87
epoch train time: 0:00:00.533528
elapsed time: 0:02:12.478597
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 14:59:59.295837
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 233.00
 ---- batch: 020 ----
mean loss: 223.31
 ---- batch: 030 ----
mean loss: 231.07
train mean loss: 228.67
epoch train time: 0:00:00.528791
elapsed time: 0:02:13.007738
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 14:59:59.824997
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.05
 ---- batch: 020 ----
mean loss: 228.24
 ---- batch: 030 ----
mean loss: 232.44
train mean loss: 228.89
epoch train time: 0:00:00.514237
elapsed time: 0:02:13.522300
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:00:00.339535
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.28
 ---- batch: 020 ----
mean loss: 233.90
 ---- batch: 030 ----
mean loss: 230.22
train mean loss: 228.80
epoch train time: 0:00:00.515792
elapsed time: 0:02:14.038481
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:00:00.855655
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.39
 ---- batch: 020 ----
mean loss: 226.07
 ---- batch: 030 ----
mean loss: 228.88
train mean loss: 228.93
epoch train time: 0:00:00.523091
elapsed time: 0:02:14.561849
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:00:01.379073
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.90
 ---- batch: 020 ----
mean loss: 226.52
 ---- batch: 030 ----
mean loss: 228.83
train mean loss: 228.34
epoch train time: 0:00:00.517237
elapsed time: 0:02:15.079374
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:00:01.896595
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.54
 ---- batch: 020 ----
mean loss: 230.39
 ---- batch: 030 ----
mean loss: 225.89
train mean loss: 228.55
epoch train time: 0:00:00.521468
elapsed time: 0:02:15.601131
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:00:02.418353
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.06
 ---- batch: 020 ----
mean loss: 233.67
 ---- batch: 030 ----
mean loss: 228.16
train mean loss: 228.38
epoch train time: 0:00:00.521875
elapsed time: 0:02:16.123323
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:00:02.940584
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 233.65
 ---- batch: 020 ----
mean loss: 228.78
 ---- batch: 030 ----
mean loss: 223.33
train mean loss: 228.74
epoch train time: 0:00:00.520613
elapsed time: 0:02:16.644277
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:00:03.461511
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.01
 ---- batch: 020 ----
mean loss: 234.09
 ---- batch: 030 ----
mean loss: 226.30
train mean loss: 228.24
epoch train time: 0:00:00.523535
elapsed time: 0:02:17.168113
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:00:03.985337
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.86
 ---- batch: 020 ----
mean loss: 226.17
 ---- batch: 030 ----
mean loss: 229.30
train mean loss: 227.67
epoch train time: 0:00:00.524673
elapsed time: 0:02:17.693085
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:00:04.510311
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 234.73
 ---- batch: 020 ----
mean loss: 226.75
 ---- batch: 030 ----
mean loss: 225.15
train mean loss: 228.07
epoch train time: 0:00:00.516093
elapsed time: 0:02:18.209474
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:00:05.026696
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.97
 ---- batch: 020 ----
mean loss: 224.67
 ---- batch: 030 ----
mean loss: 231.07
train mean loss: 228.52
epoch train time: 0:00:00.562502
elapsed time: 0:02:18.772257
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:00:05.589489
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.43
 ---- batch: 020 ----
mean loss: 233.04
 ---- batch: 030 ----
mean loss: 225.66
train mean loss: 227.73
epoch train time: 0:00:00.517125
elapsed time: 0:02:19.289664
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:00:06.106882
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.39
 ---- batch: 020 ----
mean loss: 228.63
 ---- batch: 030 ----
mean loss: 221.91
train mean loss: 228.28
epoch train time: 0:00:00.510922
elapsed time: 0:02:19.800861
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:00:06.618122
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.69
 ---- batch: 020 ----
mean loss: 222.86
 ---- batch: 030 ----
mean loss: 228.11
train mean loss: 227.83
epoch train time: 0:00:00.525389
elapsed time: 0:02:20.326571
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:00:07.143789
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.18
 ---- batch: 020 ----
mean loss: 234.11
 ---- batch: 030 ----
mean loss: 224.60
train mean loss: 228.30
epoch train time: 0:00:00.508254
elapsed time: 0:02:20.835112
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:00:07.652331
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.45
 ---- batch: 020 ----
mean loss: 230.74
 ---- batch: 030 ----
mean loss: 222.10
train mean loss: 228.08
epoch train time: 0:00:00.516519
elapsed time: 0:02:21.351932
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:00:08.169155
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.27
 ---- batch: 020 ----
mean loss: 226.07
 ---- batch: 030 ----
mean loss: 229.86
train mean loss: 227.86
epoch train time: 0:00:00.511573
elapsed time: 0:02:21.863817
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:00:08.681064
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.67
 ---- batch: 020 ----
mean loss: 224.89
 ---- batch: 030 ----
mean loss: 230.00
train mean loss: 227.54
epoch train time: 0:00:00.525467
elapsed time: 0:02:22.393188
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_7/checkpoint.pth.tar
**** end time: 2019-09-27 15:00:09.210335 ****
