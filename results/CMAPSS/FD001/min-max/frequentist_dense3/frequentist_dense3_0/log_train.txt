Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_0', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 31998
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 16:51:57.431500 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:51:57.434803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4148.19
 ---- batch: 020 ----
mean loss: 3913.98
 ---- batch: 030 ----
mean loss: 3900.17
train mean loss: 3968.62
epoch train time: 0:00:12.506127
elapsed time: 0:00:12.511827
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:52:09.943365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3796.63
 ---- batch: 020 ----
mean loss: 3709.51
 ---- batch: 030 ----
mean loss: 3688.45
train mean loss: 3726.00
epoch train time: 0:00:00.173007
elapsed time: 0:00:12.684968
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:52:10.116529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3617.10
 ---- batch: 020 ----
mean loss: 3560.10
 ---- batch: 030 ----
mean loss: 3533.04
train mean loss: 3554.69
epoch train time: 0:00:00.171761
elapsed time: 0:00:12.856874
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:52:10.288443
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3433.14
 ---- batch: 020 ----
mean loss: 3369.10
 ---- batch: 030 ----
mean loss: 3365.39
train mean loss: 3387.41
epoch train time: 0:00:00.169755
elapsed time: 0:00:13.026797
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:52:10.458343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3234.66
 ---- batch: 020 ----
mean loss: 3185.94
 ---- batch: 030 ----
mean loss: 3266.96
train mean loss: 3219.52
epoch train time: 0:00:00.172280
elapsed time: 0:00:13.199214
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:52:10.630752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3116.98
 ---- batch: 020 ----
mean loss: 3052.35
 ---- batch: 030 ----
mean loss: 3040.15
train mean loss: 3059.44
epoch train time: 0:00:00.179346
elapsed time: 0:00:13.378696
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:52:10.810252
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2971.30
 ---- batch: 020 ----
mean loss: 2896.12
 ---- batch: 030 ----
mean loss: 2845.08
train mean loss: 2893.61
epoch train time: 0:00:00.176107
elapsed time: 0:00:13.554973
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:52:10.986515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2793.29
 ---- batch: 020 ----
mean loss: 2775.30
 ---- batch: 030 ----
mean loss: 2686.82
train mean loss: 2743.13
epoch train time: 0:00:00.171484
elapsed time: 0:00:13.726589
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:52:11.158135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2649.68
 ---- batch: 020 ----
mean loss: 2615.11
 ---- batch: 030 ----
mean loss: 2584.19
train mean loss: 2607.20
epoch train time: 0:00:00.172747
elapsed time: 0:00:13.899469
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:52:11.331017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2536.48
 ---- batch: 020 ----
mean loss: 2476.85
 ---- batch: 030 ----
mean loss: 2455.27
train mean loss: 2476.88
epoch train time: 0:00:00.172802
elapsed time: 0:00:14.072420
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:52:11.503963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2385.52
 ---- batch: 020 ----
mean loss: 2379.92
 ---- batch: 030 ----
mean loss: 2325.50
train mean loss: 2354.12
epoch train time: 0:00:00.174364
elapsed time: 0:00:14.246923
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:52:11.678471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2274.84
 ---- batch: 020 ----
mean loss: 2265.11
 ---- batch: 030 ----
mean loss: 2195.42
train mean loss: 2244.42
epoch train time: 0:00:00.172699
elapsed time: 0:00:14.419756
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:52:11.851304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2185.71
 ---- batch: 020 ----
mean loss: 2131.55
 ---- batch: 030 ----
mean loss: 2139.23
train mean loss: 2138.19
epoch train time: 0:00:00.174063
elapsed time: 0:00:14.593988
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:52:12.025538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2108.89
 ---- batch: 020 ----
mean loss: 2055.53
 ---- batch: 030 ----
mean loss: 1996.43
train mean loss: 2039.28
epoch train time: 0:00:00.170239
elapsed time: 0:00:14.764363
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:52:12.195911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1974.78
 ---- batch: 020 ----
mean loss: 1954.96
 ---- batch: 030 ----
mean loss: 1925.35
train mean loss: 1945.11
epoch train time: 0:00:00.172554
elapsed time: 0:00:14.937090
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:52:12.368675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1874.30
 ---- batch: 020 ----
mean loss: 1849.81
 ---- batch: 030 ----
mean loss: 1840.24
train mean loss: 1849.72
epoch train time: 0:00:00.172283
elapsed time: 0:00:15.109617
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:52:12.541183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1791.90
 ---- batch: 020 ----
mean loss: 1756.01
 ---- batch: 030 ----
mean loss: 1739.18
train mean loss: 1757.19
epoch train time: 0:00:00.179621
elapsed time: 0:00:15.289393
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:52:12.720943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1705.31
 ---- batch: 020 ----
mean loss: 1673.51
 ---- batch: 030 ----
mean loss: 1621.72
train mean loss: 1666.84
epoch train time: 0:00:00.175861
elapsed time: 0:00:15.465387
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:52:12.896934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1614.41
 ---- batch: 020 ----
mean loss: 1589.92
 ---- batch: 030 ----
mean loss: 1548.51
train mean loss: 1577.63
epoch train time: 0:00:00.169933
elapsed time: 0:00:15.635460
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:52:13.067024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1530.43
 ---- batch: 020 ----
mean loss: 1495.15
 ---- batch: 030 ----
mean loss: 1473.96
train mean loss: 1494.29
epoch train time: 0:00:00.171040
elapsed time: 0:00:15.806652
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:52:13.238200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1427.12
 ---- batch: 020 ----
mean loss: 1420.58
 ---- batch: 030 ----
mean loss: 1400.84
train mean loss: 1417.66
epoch train time: 0:00:00.172292
elapsed time: 0:00:15.979078
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:52:13.410627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1358.01
 ---- batch: 020 ----
mean loss: 1377.97
 ---- batch: 030 ----
mean loss: 1329.26
train mean loss: 1343.74
epoch train time: 0:00:00.172873
elapsed time: 0:00:16.152103
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:52:13.583652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1309.59
 ---- batch: 020 ----
mean loss: 1280.11
 ---- batch: 030 ----
mean loss: 1263.65
train mean loss: 1274.32
epoch train time: 0:00:00.174347
elapsed time: 0:00:16.326587
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:52:13.758134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1214.93
 ---- batch: 020 ----
mean loss: 1229.76
 ---- batch: 030 ----
mean loss: 1213.26
train mean loss: 1207.78
epoch train time: 0:00:00.171067
elapsed time: 0:00:16.497787
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:52:13.929335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1179.76
 ---- batch: 020 ----
mean loss: 1165.46
 ---- batch: 030 ----
mean loss: 1120.24
train mean loss: 1144.43
epoch train time: 0:00:00.172054
elapsed time: 0:00:16.669991
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:52:14.101538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1091.06
 ---- batch: 020 ----
mean loss: 1106.77
 ---- batch: 030 ----
mean loss: 1076.83
train mean loss: 1084.87
epoch train time: 0:00:00.172523
elapsed time: 0:00:16.842649
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:52:14.274196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1050.90
 ---- batch: 020 ----
mean loss: 1038.58
 ---- batch: 030 ----
mean loss: 993.15
train mean loss: 1027.83
epoch train time: 0:00:00.174421
elapsed time: 0:00:17.017202
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:52:14.448749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 997.38
 ---- batch: 020 ----
mean loss: 978.73
 ---- batch: 030 ----
mean loss: 948.18
train mean loss: 970.76
epoch train time: 0:00:00.175282
elapsed time: 0:00:17.192615
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:52:14.624183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 925.11
 ---- batch: 020 ----
mean loss: 944.92
 ---- batch: 030 ----
mean loss: 902.19
train mean loss: 917.49
epoch train time: 0:00:00.172595
elapsed time: 0:00:17.365366
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:52:14.796914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 881.25
 ---- batch: 020 ----
mean loss: 868.38
 ---- batch: 030 ----
mean loss: 855.46
train mean loss: 866.88
epoch train time: 0:00:00.172977
elapsed time: 0:00:17.538488
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:52:14.970062
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 831.46
 ---- batch: 020 ----
mean loss: 804.80
 ---- batch: 030 ----
mean loss: 833.54
train mean loss: 819.06
epoch train time: 0:00:00.168981
elapsed time: 0:00:17.707628
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:52:15.139188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 788.15
 ---- batch: 020 ----
mean loss: 782.25
 ---- batch: 030 ----
mean loss: 760.18
train mean loss: 771.78
epoch train time: 0:00:00.171493
elapsed time: 0:00:17.879265
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:52:15.310811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 748.55
 ---- batch: 020 ----
mean loss: 726.62
 ---- batch: 030 ----
mean loss: 709.18
train mean loss: 729.76
epoch train time: 0:00:00.169996
elapsed time: 0:00:18.049406
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:52:15.480946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 705.43
 ---- batch: 020 ----
mean loss: 708.53
 ---- batch: 030 ----
mean loss: 672.87
train mean loss: 689.91
epoch train time: 0:00:00.168189
elapsed time: 0:00:18.217744
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:52:15.649289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 659.44
 ---- batch: 020 ----
mean loss: 658.20
 ---- batch: 030 ----
mean loss: 646.22
train mean loss: 652.26
epoch train time: 0:00:00.174935
elapsed time: 0:00:18.392836
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:52:15.824391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 623.26
 ---- batch: 020 ----
mean loss: 614.99
 ---- batch: 030 ----
mean loss: 624.59
train mean loss: 617.96
epoch train time: 0:00:00.172363
elapsed time: 0:00:18.565343
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:52:15.996889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 597.11
 ---- batch: 020 ----
mean loss: 585.63
 ---- batch: 030 ----
mean loss: 575.35
train mean loss: 583.58
epoch train time: 0:00:00.170662
elapsed time: 0:00:18.736136
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:52:16.167697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 563.34
 ---- batch: 020 ----
mean loss: 549.99
 ---- batch: 030 ----
mean loss: 548.33
train mean loss: 552.44
epoch train time: 0:00:00.174013
elapsed time: 0:00:18.910298
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:52:16.341846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 542.60
 ---- batch: 020 ----
mean loss: 527.11
 ---- batch: 030 ----
mean loss: 513.90
train mean loss: 523.05
epoch train time: 0:00:00.171952
elapsed time: 0:00:19.082405
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:52:16.513947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 505.57
 ---- batch: 020 ----
mean loss: 488.93
 ---- batch: 030 ----
mean loss: 493.46
train mean loss: 495.23
epoch train time: 0:00:00.174027
elapsed time: 0:00:19.256589
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:52:16.688180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 482.92
 ---- batch: 020 ----
mean loss: 456.95
 ---- batch: 030 ----
mean loss: 466.75
train mean loss: 469.53
epoch train time: 0:00:00.176100
elapsed time: 0:00:19.432880
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:52:16.864429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 448.29
 ---- batch: 020 ----
mean loss: 440.20
 ---- batch: 030 ----
mean loss: 450.86
train mean loss: 444.33
epoch train time: 0:00:00.171743
elapsed time: 0:00:19.604760
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:52:17.036311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 439.40
 ---- batch: 020 ----
mean loss: 422.89
 ---- batch: 030 ----
mean loss: 404.41
train mean loss: 421.25
epoch train time: 0:00:00.172050
elapsed time: 0:00:19.776948
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:52:17.208528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 401.29
 ---- batch: 020 ----
mean loss: 404.47
 ---- batch: 030 ----
mean loss: 395.03
train mean loss: 399.71
epoch train time: 0:00:00.174565
elapsed time: 0:00:19.951681
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:52:17.383229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 387.01
 ---- batch: 020 ----
mean loss: 374.67
 ---- batch: 030 ----
mean loss: 377.56
train mean loss: 378.82
epoch train time: 0:00:00.174141
elapsed time: 0:00:20.125957
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:52:17.557504
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 367.36
 ---- batch: 020 ----
mean loss: 352.63
 ---- batch: 030 ----
mean loss: 354.67
train mean loss: 359.59
epoch train time: 0:00:00.173543
elapsed time: 0:00:20.299632
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:52:17.731195
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 340.03
 ---- batch: 020 ----
mean loss: 349.14
 ---- batch: 030 ----
mean loss: 338.74
train mean loss: 340.88
epoch train time: 0:00:00.172692
elapsed time: 0:00:20.472501
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:52:17.904048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.53
 ---- batch: 020 ----
mean loss: 325.62
 ---- batch: 030 ----
mean loss: 327.67
train mean loss: 324.00
epoch train time: 0:00:00.169179
elapsed time: 0:00:20.641843
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:52:18.073390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 314.35
 ---- batch: 020 ----
mean loss: 307.99
 ---- batch: 030 ----
mean loss: 306.75
train mean loss: 308.45
epoch train time: 0:00:00.173317
elapsed time: 0:00:20.815325
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:52:18.246873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.57
 ---- batch: 020 ----
mean loss: 297.69
 ---- batch: 030 ----
mean loss: 286.62
train mean loss: 293.38
epoch train time: 0:00:00.173855
elapsed time: 0:00:20.989314
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:52:18.420862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.16
 ---- batch: 020 ----
mean loss: 274.49
 ---- batch: 030 ----
mean loss: 280.70
train mean loss: 279.10
epoch train time: 0:00:00.169773
elapsed time: 0:00:21.159221
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:52:18.590769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.44
 ---- batch: 020 ----
mean loss: 267.19
 ---- batch: 030 ----
mean loss: 261.04
train mean loss: 266.01
epoch train time: 0:00:00.169009
elapsed time: 0:00:21.328362
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:52:18.759921
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.00
 ---- batch: 020 ----
mean loss: 249.89
 ---- batch: 030 ----
mean loss: 251.10
train mean loss: 252.89
epoch train time: 0:00:00.168592
elapsed time: 0:00:21.497098
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:52:18.928645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.94
 ---- batch: 020 ----
mean loss: 246.75
 ---- batch: 030 ----
mean loss: 237.60
train mean loss: 241.60
epoch train time: 0:00:00.171394
elapsed time: 0:00:21.668624
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:52:19.100170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.75
 ---- batch: 020 ----
mean loss: 227.02
 ---- batch: 030 ----
mean loss: 230.98
train mean loss: 230.81
epoch train time: 0:00:00.170364
elapsed time: 0:00:21.839116
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:52:19.270660
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.36
 ---- batch: 020 ----
mean loss: 222.45
 ---- batch: 030 ----
mean loss: 214.70
train mean loss: 220.86
epoch train time: 0:00:00.172583
elapsed time: 0:00:22.011834
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:52:19.443381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.60
 ---- batch: 020 ----
mean loss: 217.17
 ---- batch: 030 ----
mean loss: 206.98
train mean loss: 211.32
epoch train time: 0:00:00.174197
elapsed time: 0:00:22.186184
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:52:19.617768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.98
 ---- batch: 020 ----
mean loss: 199.89
 ---- batch: 030 ----
mean loss: 205.22
train mean loss: 202.59
epoch train time: 0:00:00.180361
elapsed time: 0:00:22.366716
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:52:19.798265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.12
 ---- batch: 020 ----
mean loss: 195.35
 ---- batch: 030 ----
mean loss: 193.69
train mean loss: 194.30
epoch train time: 0:00:00.175779
elapsed time: 0:00:22.542677
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:52:19.974237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.79
 ---- batch: 020 ----
mean loss: 186.34
 ---- batch: 030 ----
mean loss: 182.75
train mean loss: 186.37
epoch train time: 0:00:00.170406
elapsed time: 0:00:22.713230
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:52:20.144777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.19
 ---- batch: 020 ----
mean loss: 179.18
 ---- batch: 030 ----
mean loss: 179.17
train mean loss: 179.68
epoch train time: 0:00:00.168852
elapsed time: 0:00:22.882216
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:52:20.313764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.86
 ---- batch: 020 ----
mean loss: 171.85
 ---- batch: 030 ----
mean loss: 176.56
train mean loss: 172.88
epoch train time: 0:00:00.167210
elapsed time: 0:00:23.049559
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:52:20.481135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.72
 ---- batch: 020 ----
mean loss: 167.42
 ---- batch: 030 ----
mean loss: 162.48
train mean loss: 166.56
epoch train time: 0:00:00.175158
elapsed time: 0:00:23.225155
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:52:20.656726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.87
 ---- batch: 020 ----
mean loss: 162.90
 ---- batch: 030 ----
mean loss: 160.79
train mean loss: 160.58
epoch train time: 0:00:00.185113
elapsed time: 0:00:23.410439
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:52:20.841989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.29
 ---- batch: 020 ----
mean loss: 154.25
 ---- batch: 030 ----
mean loss: 155.05
train mean loss: 155.27
epoch train time: 0:00:00.171883
elapsed time: 0:00:23.582459
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:52:21.014006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.29
 ---- batch: 020 ----
mean loss: 150.49
 ---- batch: 030 ----
mean loss: 151.81
train mean loss: 150.23
epoch train time: 0:00:00.169910
elapsed time: 0:00:23.752501
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:52:21.184047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.44
 ---- batch: 020 ----
mean loss: 147.82
 ---- batch: 030 ----
mean loss: 143.49
train mean loss: 145.52
epoch train time: 0:00:00.172179
elapsed time: 0:00:23.924810
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:52:21.356357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.58
 ---- batch: 020 ----
mean loss: 140.64
 ---- batch: 030 ----
mean loss: 141.62
train mean loss: 141.52
epoch train time: 0:00:00.172842
elapsed time: 0:00:24.097782
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:52:21.529329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.48
 ---- batch: 020 ----
mean loss: 136.02
 ---- batch: 030 ----
mean loss: 132.55
train mean loss: 137.05
epoch train time: 0:00:00.173618
elapsed time: 0:00:24.271531
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:52:21.703093
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.68
 ---- batch: 020 ----
mean loss: 131.41
 ---- batch: 030 ----
mean loss: 133.75
train mean loss: 133.37
epoch train time: 0:00:00.176000
elapsed time: 0:00:24.447681
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:52:21.879248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.36
 ---- batch: 020 ----
mean loss: 131.43
 ---- batch: 030 ----
mean loss: 128.70
train mean loss: 129.63
epoch train time: 0:00:00.171930
elapsed time: 0:00:24.619777
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:52:22.051338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.02
 ---- batch: 020 ----
mean loss: 126.11
 ---- batch: 030 ----
mean loss: 124.22
train mean loss: 126.49
epoch train time: 0:00:00.170637
elapsed time: 0:00:24.790588
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:52:22.222182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.68
 ---- batch: 020 ----
mean loss: 123.13
 ---- batch: 030 ----
mean loss: 124.28
train mean loss: 123.23
epoch train time: 0:00:00.173724
elapsed time: 0:00:24.964510
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:52:22.396057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.78
 ---- batch: 020 ----
mean loss: 121.11
 ---- batch: 030 ----
mean loss: 119.75
train mean loss: 120.27
epoch train time: 0:00:00.172210
elapsed time: 0:00:25.136850
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:52:22.568395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.91
 ---- batch: 020 ----
mean loss: 118.87
 ---- batch: 030 ----
mean loss: 116.81
train mean loss: 117.30
epoch train time: 0:00:00.179452
elapsed time: 0:00:25.316450
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:52:22.748007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.42
 ---- batch: 020 ----
mean loss: 114.29
 ---- batch: 030 ----
mean loss: 116.16
train mean loss: 114.67
epoch train time: 0:00:00.176118
elapsed time: 0:00:25.492778
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:52:22.924327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.04
 ---- batch: 020 ----
mean loss: 111.19
 ---- batch: 030 ----
mean loss: 107.97
train mean loss: 112.02
epoch train time: 0:00:00.172687
elapsed time: 0:00:25.665602
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:52:23.097159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.78
 ---- batch: 020 ----
mean loss: 108.53
 ---- batch: 030 ----
mean loss: 110.60
train mean loss: 109.60
epoch train time: 0:00:00.174468
elapsed time: 0:00:25.840217
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:52:23.271766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.73
 ---- batch: 020 ----
mean loss: 106.36
 ---- batch: 030 ----
mean loss: 109.75
train mean loss: 107.58
epoch train time: 0:00:00.173413
elapsed time: 0:00:26.013763
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:52:23.445312
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.11
 ---- batch: 020 ----
mean loss: 107.60
 ---- batch: 030 ----
mean loss: 105.80
train mean loss: 105.52
epoch train time: 0:00:00.170581
elapsed time: 0:00:26.184483
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:52:23.616031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.51
 ---- batch: 020 ----
mean loss: 101.59
 ---- batch: 030 ----
mean loss: 101.60
train mean loss: 103.12
epoch train time: 0:00:00.175766
elapsed time: 0:00:26.360384
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:52:23.791943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.86
 ---- batch: 020 ----
mean loss: 103.17
 ---- batch: 030 ----
mean loss: 102.16
train mean loss: 101.24
epoch train time: 0:00:00.180969
elapsed time: 0:00:26.541500
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:52:23.973047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.67
 ---- batch: 020 ----
mean loss: 101.99
 ---- batch: 030 ----
mean loss: 96.70
train mean loss: 99.55
epoch train time: 0:00:00.172956
elapsed time: 0:00:26.714614
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:52:24.146154
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.49
 ---- batch: 020 ----
mean loss: 95.65
 ---- batch: 030 ----
mean loss: 99.07
train mean loss: 97.96
epoch train time: 0:00:00.172235
elapsed time: 0:00:26.887004
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:52:24.318566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.35
 ---- batch: 020 ----
mean loss: 99.67
 ---- batch: 030 ----
mean loss: 96.43
train mean loss: 96.41
epoch train time: 0:00:00.173477
elapsed time: 0:00:27.060632
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:52:24.492180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.06
 ---- batch: 020 ----
mean loss: 96.19
 ---- batch: 030 ----
mean loss: 93.75
train mean loss: 94.71
epoch train time: 0:00:00.176006
elapsed time: 0:00:27.236799
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:52:24.668375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.63
 ---- batch: 020 ----
mean loss: 93.95
 ---- batch: 030 ----
mean loss: 97.36
train mean loss: 94.25
epoch train time: 0:00:00.187980
elapsed time: 0:00:27.424974
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:52:24.856531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.21
 ---- batch: 020 ----
mean loss: 93.77
 ---- batch: 030 ----
mean loss: 88.71
train mean loss: 92.40
epoch train time: 0:00:00.176824
elapsed time: 0:00:27.601952
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:52:25.033503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.90
 ---- batch: 020 ----
mean loss: 88.13
 ---- batch: 030 ----
mean loss: 90.95
train mean loss: 91.06
epoch train time: 0:00:00.172671
elapsed time: 0:00:27.774761
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:52:25.206307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.33
 ---- batch: 020 ----
mean loss: 87.85
 ---- batch: 030 ----
mean loss: 91.62
train mean loss: 90.10
epoch train time: 0:00:00.171458
elapsed time: 0:00:27.946354
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:52:25.377902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.08
 ---- batch: 020 ----
mean loss: 88.88
 ---- batch: 030 ----
mean loss: 88.77
train mean loss: 88.61
epoch train time: 0:00:00.170529
elapsed time: 0:00:28.117026
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:52:25.548574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.90
 ---- batch: 020 ----
mean loss: 88.94
 ---- batch: 030 ----
mean loss: 87.54
train mean loss: 87.55
epoch train time: 0:00:00.170624
elapsed time: 0:00:28.287799
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:52:25.719346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.52
 ---- batch: 020 ----
mean loss: 87.01
 ---- batch: 030 ----
mean loss: 87.47
train mean loss: 87.55
epoch train time: 0:00:00.174567
elapsed time: 0:00:28.462501
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:52:25.894064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.18
 ---- batch: 020 ----
mean loss: 85.09
 ---- batch: 030 ----
mean loss: 86.64
train mean loss: 85.42
epoch train time: 0:00:00.176059
elapsed time: 0:00:28.638714
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:52:26.070262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.84
 ---- batch: 020 ----
mean loss: 84.51
 ---- batch: 030 ----
mean loss: 85.73
train mean loss: 85.06
epoch train time: 0:00:00.175295
elapsed time: 0:00:28.814180
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:52:26.245766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.61
 ---- batch: 020 ----
mean loss: 80.97
 ---- batch: 030 ----
mean loss: 85.90
train mean loss: 84.01
epoch train time: 0:00:00.172017
elapsed time: 0:00:28.986370
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:52:26.417926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.12
 ---- batch: 020 ----
mean loss: 83.45
 ---- batch: 030 ----
mean loss: 84.80
train mean loss: 82.94
epoch train time: 0:00:00.172161
elapsed time: 0:00:29.158674
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:52:26.590222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.52
 ---- batch: 020 ----
mean loss: 82.92
 ---- batch: 030 ----
mean loss: 83.04
train mean loss: 82.89
epoch train time: 0:00:00.183785
elapsed time: 0:00:29.342595
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:52:26.774160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.87
 ---- batch: 020 ----
mean loss: 81.01
 ---- batch: 030 ----
mean loss: 80.94
train mean loss: 81.59
epoch train time: 0:00:00.173635
elapsed time: 0:00:29.516384
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:52:26.947985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.82
 ---- batch: 020 ----
mean loss: 81.67
 ---- batch: 030 ----
mean loss: 78.77
train mean loss: 81.30
epoch train time: 0:00:00.170168
elapsed time: 0:00:29.686737
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:52:27.118284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.90
 ---- batch: 020 ----
mean loss: 80.12
 ---- batch: 030 ----
mean loss: 77.58
train mean loss: 80.13
epoch train time: 0:00:00.169079
elapsed time: 0:00:29.855953
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:52:27.287503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.79
 ---- batch: 020 ----
mean loss: 78.19
 ---- batch: 030 ----
mean loss: 79.57
train mean loss: 80.13
epoch train time: 0:00:00.171646
elapsed time: 0:00:30.027735
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:52:27.459283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.16
 ---- batch: 020 ----
mean loss: 81.62
 ---- batch: 030 ----
mean loss: 77.82
train mean loss: 79.62
epoch train time: 0:00:00.185789
elapsed time: 0:00:30.213671
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:52:27.645215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.80
 ---- batch: 020 ----
mean loss: 80.32
 ---- batch: 030 ----
mean loss: 77.39
train mean loss: 79.35
epoch train time: 0:00:00.174651
elapsed time: 0:00:30.388456
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:52:27.820004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.19
 ---- batch: 020 ----
mean loss: 76.88
 ---- batch: 030 ----
mean loss: 77.20
train mean loss: 78.94
epoch train time: 0:00:00.171895
elapsed time: 0:00:30.560489
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:52:27.992037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.82
 ---- batch: 020 ----
mean loss: 78.91
 ---- batch: 030 ----
mean loss: 79.04
train mean loss: 78.06
epoch train time: 0:00:00.175091
elapsed time: 0:00:30.735722
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:52:28.167275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.08
 ---- batch: 020 ----
mean loss: 78.31
 ---- batch: 030 ----
mean loss: 76.02
train mean loss: 77.22
epoch train time: 0:00:00.174080
elapsed time: 0:00:30.910588
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:52:28.342141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.03
 ---- batch: 020 ----
mean loss: 76.36
 ---- batch: 030 ----
mean loss: 78.14
train mean loss: 76.54
epoch train time: 0:00:00.176750
elapsed time: 0:00:31.087482
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:52:28.519033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.32
 ---- batch: 020 ----
mean loss: 77.07
 ---- batch: 030 ----
mean loss: 71.83
train mean loss: 75.68
epoch train time: 0:00:00.178887
elapsed time: 0:00:31.266518
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:52:28.698075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.58
 ---- batch: 020 ----
mean loss: 76.39
 ---- batch: 030 ----
mean loss: 76.56
train mean loss: 75.84
epoch train time: 0:00:00.183962
elapsed time: 0:00:31.450627
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:52:28.882190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.87
 ---- batch: 020 ----
mean loss: 74.89
 ---- batch: 030 ----
mean loss: 77.08
train mean loss: 75.09
epoch train time: 0:00:00.171076
elapsed time: 0:00:31.621854
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:52:29.053435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.63
 ---- batch: 020 ----
mean loss: 74.03
 ---- batch: 030 ----
mean loss: 73.13
train mean loss: 75.00
epoch train time: 0:00:00.174128
elapsed time: 0:00:31.796149
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:52:29.227727
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.95
 ---- batch: 020 ----
mean loss: 74.97
 ---- batch: 030 ----
mean loss: 73.51
train mean loss: 74.16
epoch train time: 0:00:00.172755
elapsed time: 0:00:31.969069
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:52:29.400617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.22
 ---- batch: 020 ----
mean loss: 70.31
 ---- batch: 030 ----
mean loss: 75.33
train mean loss: 73.62
epoch train time: 0:00:00.174676
elapsed time: 0:00:32.143880
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:52:29.575452
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.79
 ---- batch: 020 ----
mean loss: 71.67
 ---- batch: 030 ----
mean loss: 74.78
train mean loss: 73.30
epoch train time: 0:00:00.173733
elapsed time: 0:00:32.317773
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:52:29.749321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.58
 ---- batch: 020 ----
mean loss: 71.70
 ---- batch: 030 ----
mean loss: 74.76
train mean loss: 73.41
epoch train time: 0:00:00.177851
elapsed time: 0:00:32.495759
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:52:29.927307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.64
 ---- batch: 020 ----
mean loss: 72.37
 ---- batch: 030 ----
mean loss: 74.37
train mean loss: 73.04
epoch train time: 0:00:00.169752
elapsed time: 0:00:32.665664
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:52:30.097213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.49
 ---- batch: 020 ----
mean loss: 72.52
 ---- batch: 030 ----
mean loss: 73.70
train mean loss: 72.68
epoch train time: 0:00:00.167018
elapsed time: 0:00:32.832818
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:52:30.264365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.46
 ---- batch: 020 ----
mean loss: 70.05
 ---- batch: 030 ----
mean loss: 73.17
train mean loss: 71.74
epoch train time: 0:00:00.168563
elapsed time: 0:00:33.001514
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:52:30.433060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.48
 ---- batch: 020 ----
mean loss: 72.56
 ---- batch: 030 ----
mean loss: 73.13
train mean loss: 72.31
epoch train time: 0:00:00.167287
elapsed time: 0:00:33.168933
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:52:30.600480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.08
 ---- batch: 020 ----
mean loss: 71.43
 ---- batch: 030 ----
mean loss: 69.87
train mean loss: 71.29
epoch train time: 0:00:00.170980
elapsed time: 0:00:33.340049
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:52:30.771597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.43
 ---- batch: 020 ----
mean loss: 68.99
 ---- batch: 030 ----
mean loss: 72.47
train mean loss: 70.02
epoch train time: 0:00:00.183388
elapsed time: 0:00:33.523572
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:52:30.955119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.35
 ---- batch: 020 ----
mean loss: 70.23
 ---- batch: 030 ----
mean loss: 69.45
train mean loss: 69.69
epoch train time: 0:00:00.167989
elapsed time: 0:00:33.691694
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:52:31.123241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.11
 ---- batch: 020 ----
mean loss: 68.89
 ---- batch: 030 ----
mean loss: 69.22
train mean loss: 69.19
epoch train time: 0:00:00.170321
elapsed time: 0:00:33.862169
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:52:31.293720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.38
 ---- batch: 020 ----
mean loss: 66.62
 ---- batch: 030 ----
mean loss: 70.91
train mean loss: 69.25
epoch train time: 0:00:00.169101
elapsed time: 0:00:34.031412
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:52:31.462975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.50
 ---- batch: 020 ----
mean loss: 66.34
 ---- batch: 030 ----
mean loss: 67.17
train mean loss: 68.69
epoch train time: 0:00:00.171752
elapsed time: 0:00:34.203308
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:52:31.634886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.18
 ---- batch: 020 ----
mean loss: 68.30
 ---- batch: 030 ----
mean loss: 69.46
train mean loss: 68.62
epoch train time: 0:00:00.177062
elapsed time: 0:00:34.380547
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:52:31.812085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.97
 ---- batch: 020 ----
mean loss: 67.40
 ---- batch: 030 ----
mean loss: 68.84
train mean loss: 68.13
epoch train time: 0:00:00.171988
elapsed time: 0:00:34.552657
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:52:31.984205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.40
 ---- batch: 020 ----
mean loss: 67.61
 ---- batch: 030 ----
mean loss: 66.70
train mean loss: 67.51
epoch train time: 0:00:00.174321
elapsed time: 0:00:34.727111
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:52:32.158658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.77
 ---- batch: 020 ----
mean loss: 68.70
 ---- batch: 030 ----
mean loss: 65.17
train mean loss: 67.04
epoch train time: 0:00:00.173723
elapsed time: 0:00:34.900992
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:52:32.332555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.79
 ---- batch: 020 ----
mean loss: 67.08
 ---- batch: 030 ----
mean loss: 65.27
train mean loss: 67.20
epoch train time: 0:00:00.170737
elapsed time: 0:00:35.071901
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:52:32.503450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.76
 ---- batch: 020 ----
mean loss: 66.22
 ---- batch: 030 ----
mean loss: 65.58
train mean loss: 66.06
epoch train time: 0:00:00.170217
elapsed time: 0:00:35.242255
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:52:32.673803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.18
 ---- batch: 020 ----
mean loss: 68.55
 ---- batch: 030 ----
mean loss: 63.88
train mean loss: 66.09
epoch train time: 0:00:00.172568
elapsed time: 0:00:35.415001
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:52:32.846564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.16
 ---- batch: 020 ----
mean loss: 66.05
 ---- batch: 030 ----
mean loss: 67.17
train mean loss: 66.31
epoch train time: 0:00:00.175642
elapsed time: 0:00:35.590793
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:52:33.022341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.84
 ---- batch: 020 ----
mean loss: 65.64
 ---- batch: 030 ----
mean loss: 65.64
train mean loss: 65.36
epoch train time: 0:00:00.174202
elapsed time: 0:00:35.765130
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:52:33.196677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.68
 ---- batch: 020 ----
mean loss: 64.28
 ---- batch: 030 ----
mean loss: 65.49
train mean loss: 65.06
epoch train time: 0:00:00.174950
elapsed time: 0:00:35.940215
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:52:33.371764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.98
 ---- batch: 020 ----
mean loss: 65.45
 ---- batch: 030 ----
mean loss: 62.58
train mean loss: 65.14
epoch train time: 0:00:00.172617
elapsed time: 0:00:36.112967
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:52:33.544515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.81
 ---- batch: 020 ----
mean loss: 67.31
 ---- batch: 030 ----
mean loss: 61.73
train mean loss: 65.26
epoch train time: 0:00:00.175763
elapsed time: 0:00:36.288865
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:52:33.720425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.05
 ---- batch: 020 ----
mean loss: 68.23
 ---- batch: 030 ----
mean loss: 65.46
train mean loss: 66.22
epoch train time: 0:00:00.174680
elapsed time: 0:00:36.463715
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:52:33.895319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.40
 ---- batch: 020 ----
mean loss: 65.56
 ---- batch: 030 ----
mean loss: 63.96
train mean loss: 64.01
epoch train time: 0:00:00.177425
elapsed time: 0:00:36.641334
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:52:34.072883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.97
 ---- batch: 020 ----
mean loss: 64.89
 ---- batch: 030 ----
mean loss: 67.22
train mean loss: 64.99
epoch train time: 0:00:00.174928
elapsed time: 0:00:36.816399
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:52:34.247947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.09
 ---- batch: 020 ----
mean loss: 64.90
 ---- batch: 030 ----
mean loss: 64.63
train mean loss: 64.62
epoch train time: 0:00:00.175496
elapsed time: 0:00:36.992030
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:52:34.423579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.95
 ---- batch: 020 ----
mean loss: 64.01
 ---- batch: 030 ----
mean loss: 64.40
train mean loss: 63.47
epoch train time: 0:00:00.175682
elapsed time: 0:00:37.167849
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:52:34.599397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.42
 ---- batch: 020 ----
mean loss: 62.43
 ---- batch: 030 ----
mean loss: 64.49
train mean loss: 63.05
epoch train time: 0:00:00.178519
elapsed time: 0:00:37.346500
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:52:34.778044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.13
 ---- batch: 020 ----
mean loss: 62.09
 ---- batch: 030 ----
mean loss: 63.29
train mean loss: 62.74
epoch train time: 0:00:00.170970
elapsed time: 0:00:37.517617
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:52:34.949209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.55
 ---- batch: 020 ----
mean loss: 63.90
 ---- batch: 030 ----
mean loss: 60.44
train mean loss: 63.06
epoch train time: 0:00:00.171245
elapsed time: 0:00:37.689047
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:52:35.120609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.39
 ---- batch: 020 ----
mean loss: 64.88
 ---- batch: 030 ----
mean loss: 61.10
train mean loss: 62.56
epoch train time: 0:00:00.166916
elapsed time: 0:00:37.856148
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:52:35.287735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.70
 ---- batch: 020 ----
mean loss: 62.27
 ---- batch: 030 ----
mean loss: 63.47
train mean loss: 62.23
epoch train time: 0:00:00.172928
elapsed time: 0:00:38.029248
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:52:35.460797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.13
 ---- batch: 020 ----
mean loss: 64.42
 ---- batch: 030 ----
mean loss: 62.21
train mean loss: 62.88
epoch train time: 0:00:00.170490
elapsed time: 0:00:38.199883
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:52:35.631421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.10
 ---- batch: 020 ----
mean loss: 63.17
 ---- batch: 030 ----
mean loss: 61.22
train mean loss: 62.99
epoch train time: 0:00:00.179327
elapsed time: 0:00:38.379353
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:52:35.810909
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.13
 ---- batch: 020 ----
mean loss: 62.23
 ---- batch: 030 ----
mean loss: 60.32
train mean loss: 61.41
epoch train time: 0:00:00.174544
elapsed time: 0:00:38.554041
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:52:35.985590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.47
 ---- batch: 020 ----
mean loss: 61.09
 ---- batch: 030 ----
mean loss: 65.48
train mean loss: 62.09
epoch train time: 0:00:00.169600
elapsed time: 0:00:38.723782
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:52:36.155353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.27
 ---- batch: 020 ----
mean loss: 62.87
 ---- batch: 030 ----
mean loss: 59.18
train mean loss: 61.24
epoch train time: 0:00:00.175951
elapsed time: 0:00:38.899890
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:52:36.331438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.41
 ---- batch: 020 ----
mean loss: 60.58
 ---- batch: 030 ----
mean loss: 63.54
train mean loss: 61.35
epoch train time: 0:00:00.175728
elapsed time: 0:00:39.075751
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:52:36.507310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.46
 ---- batch: 020 ----
mean loss: 64.65
 ---- batch: 030 ----
mean loss: 61.31
train mean loss: 62.23
epoch train time: 0:00:00.177265
elapsed time: 0:00:39.253163
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:52:36.684710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.81
 ---- batch: 020 ----
mean loss: 60.72
 ---- batch: 030 ----
mean loss: 63.17
train mean loss: 60.68
epoch train time: 0:00:00.177071
elapsed time: 0:00:39.430372
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:52:36.861920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.05
 ---- batch: 020 ----
mean loss: 59.95
 ---- batch: 030 ----
mean loss: 60.04
train mean loss: 60.53
epoch train time: 0:00:00.173817
elapsed time: 0:00:39.604322
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:52:37.035869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.90
 ---- batch: 020 ----
mean loss: 62.05
 ---- batch: 030 ----
mean loss: 61.48
train mean loss: 61.76
epoch train time: 0:00:00.180142
elapsed time: 0:00:39.784596
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:52:37.216162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.64
 ---- batch: 020 ----
mean loss: 61.80
 ---- batch: 030 ----
mean loss: 58.26
train mean loss: 60.01
epoch train time: 0:00:00.176865
elapsed time: 0:00:39.961610
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:52:37.393158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.03
 ---- batch: 020 ----
mean loss: 58.63
 ---- batch: 030 ----
mean loss: 58.55
train mean loss: 59.80
epoch train time: 0:00:00.173939
elapsed time: 0:00:40.135680
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:52:37.567224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.16
 ---- batch: 020 ----
mean loss: 58.36
 ---- batch: 030 ----
mean loss: 63.32
train mean loss: 60.63
epoch train time: 0:00:00.176016
elapsed time: 0:00:40.311827
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:52:37.743373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.60
 ---- batch: 020 ----
mean loss: 58.69
 ---- batch: 030 ----
mean loss: 58.80
train mean loss: 60.31
epoch train time: 0:00:00.175162
elapsed time: 0:00:40.487120
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:52:37.918667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.19
 ---- batch: 020 ----
mean loss: 59.19
 ---- batch: 030 ----
mean loss: 61.25
train mean loss: 59.51
epoch train time: 0:00:00.170748
elapsed time: 0:00:40.658001
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:52:38.089546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.66
 ---- batch: 020 ----
mean loss: 59.47
 ---- batch: 030 ----
mean loss: 58.15
train mean loss: 59.22
epoch train time: 0:00:00.169006
elapsed time: 0:00:40.827138
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:52:38.258684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.44
 ---- batch: 020 ----
mean loss: 58.34
 ---- batch: 030 ----
mean loss: 58.36
train mean loss: 59.16
epoch train time: 0:00:00.168506
elapsed time: 0:00:40.995774
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:52:38.427321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.76
 ---- batch: 020 ----
mean loss: 57.00
 ---- batch: 030 ----
mean loss: 60.40
train mean loss: 58.63
epoch train time: 0:00:00.168148
elapsed time: 0:00:41.164055
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:52:38.595623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.76
 ---- batch: 020 ----
mean loss: 57.62
 ---- batch: 030 ----
mean loss: 58.16
train mean loss: 58.71
epoch train time: 0:00:00.171157
elapsed time: 0:00:41.335364
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:52:38.766910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.22
 ---- batch: 020 ----
mean loss: 59.18
 ---- batch: 030 ----
mean loss: 60.85
train mean loss: 60.30
epoch train time: 0:00:00.182719
elapsed time: 0:00:41.518221
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:52:38.949769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.29
 ---- batch: 020 ----
mean loss: 57.59
 ---- batch: 030 ----
mean loss: 57.17
train mean loss: 58.62
epoch train time: 0:00:00.176027
elapsed time: 0:00:41.694386
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:52:39.125935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.19
 ---- batch: 020 ----
mean loss: 60.62
 ---- batch: 030 ----
mean loss: 58.50
train mean loss: 58.27
epoch train time: 0:00:00.176223
elapsed time: 0:00:41.870748
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:52:39.302295
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.13
 ---- batch: 020 ----
mean loss: 59.09
 ---- batch: 030 ----
mean loss: 58.08
train mean loss: 58.36
epoch train time: 0:00:00.176515
elapsed time: 0:00:42.047397
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:52:39.478947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.23
 ---- batch: 020 ----
mean loss: 59.09
 ---- batch: 030 ----
mean loss: 58.06
train mean loss: 59.30
epoch train time: 0:00:00.175617
elapsed time: 0:00:42.223156
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:52:39.654704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.76
 ---- batch: 020 ----
mean loss: 55.92
 ---- batch: 030 ----
mean loss: 58.77
train mean loss: 57.99
epoch train time: 0:00:00.186616
elapsed time: 0:00:42.409908
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:52:39.841460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.25
 ---- batch: 020 ----
mean loss: 58.81
 ---- batch: 030 ----
mean loss: 57.73
train mean loss: 57.72
epoch train time: 0:00:00.176853
elapsed time: 0:00:42.586915
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:52:40.018455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.44
 ---- batch: 020 ----
mean loss: 58.95
 ---- batch: 030 ----
mean loss: 59.12
train mean loss: 57.37
epoch train time: 0:00:00.175498
elapsed time: 0:00:42.762544
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:52:40.194093
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.37
 ---- batch: 020 ----
mean loss: 56.50
 ---- batch: 030 ----
mean loss: 57.74
train mean loss: 57.60
epoch train time: 0:00:00.175349
elapsed time: 0:00:42.938030
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:52:40.369578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.30
 ---- batch: 020 ----
mean loss: 55.92
 ---- batch: 030 ----
mean loss: 58.94
train mean loss: 57.45
epoch train time: 0:00:00.177673
elapsed time: 0:00:43.115838
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:52:40.547386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.88
 ---- batch: 020 ----
mean loss: 56.49
 ---- batch: 030 ----
mean loss: 59.85
train mean loss: 57.90
epoch train time: 0:00:00.179997
elapsed time: 0:00:43.295970
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:52:40.727518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.34
 ---- batch: 020 ----
mean loss: 56.55
 ---- batch: 030 ----
mean loss: 56.19
train mean loss: 56.40
epoch train time: 0:00:00.173261
elapsed time: 0:00:43.469366
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:52:40.900914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.53
 ---- batch: 020 ----
mean loss: 55.28
 ---- batch: 030 ----
mean loss: 56.68
train mean loss: 56.47
epoch train time: 0:00:00.174119
elapsed time: 0:00:43.643619
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:52:41.075218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.12
 ---- batch: 020 ----
mean loss: 56.98
 ---- batch: 030 ----
mean loss: 56.32
train mean loss: 55.97
epoch train time: 0:00:00.174782
elapsed time: 0:00:43.818598
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:52:41.250146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.61
 ---- batch: 020 ----
mean loss: 59.10
 ---- batch: 030 ----
mean loss: 57.28
train mean loss: 56.85
epoch train time: 0:00:00.175501
elapsed time: 0:00:43.994236
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:52:41.425782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.44
 ---- batch: 020 ----
mean loss: 58.55
 ---- batch: 030 ----
mean loss: 55.19
train mean loss: 55.43
epoch train time: 0:00:00.175461
elapsed time: 0:00:44.169829
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:52:41.601377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.10
 ---- batch: 020 ----
mean loss: 55.98
 ---- batch: 030 ----
mean loss: 57.86
train mean loss: 55.92
epoch train time: 0:00:00.174560
elapsed time: 0:00:44.344523
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:52:41.776069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.80
 ---- batch: 020 ----
mean loss: 55.76
 ---- batch: 030 ----
mean loss: 55.68
train mean loss: 55.21
epoch train time: 0:00:00.176085
elapsed time: 0:00:44.520742
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:52:41.952289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.21
 ---- batch: 020 ----
mean loss: 54.89
 ---- batch: 030 ----
mean loss: 55.10
train mean loss: 55.64
epoch train time: 0:00:00.174421
elapsed time: 0:00:44.695297
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:52:42.126845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.00
 ---- batch: 020 ----
mean loss: 57.24
 ---- batch: 030 ----
mean loss: 55.69
train mean loss: 57.11
epoch train time: 0:00:00.176466
elapsed time: 0:00:44.871897
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:52:42.303460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.51
 ---- batch: 020 ----
mean loss: 55.03
 ---- batch: 030 ----
mean loss: 57.62
train mean loss: 55.45
epoch train time: 0:00:00.175229
elapsed time: 0:00:45.047275
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:52:42.478821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.14
 ---- batch: 020 ----
mean loss: 54.20
 ---- batch: 030 ----
mean loss: 54.55
train mean loss: 54.44
epoch train time: 0:00:00.172855
elapsed time: 0:00:45.220264
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:52:42.651811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.85
 ---- batch: 020 ----
mean loss: 53.01
 ---- batch: 030 ----
mean loss: 55.37
train mean loss: 54.04
epoch train time: 0:00:00.185454
elapsed time: 0:00:45.405854
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:52:42.837403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.41
 ---- batch: 020 ----
mean loss: 53.44
 ---- batch: 030 ----
mean loss: 53.55
train mean loss: 54.20
epoch train time: 0:00:00.177094
elapsed time: 0:00:45.583088
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:52:43.014638
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.56
 ---- batch: 020 ----
mean loss: 52.48
 ---- batch: 030 ----
mean loss: 54.49
train mean loss: 53.66
epoch train time: 0:00:00.177818
elapsed time: 0:00:45.761045
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:52:43.192605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.34
 ---- batch: 020 ----
mean loss: 53.23
 ---- batch: 030 ----
mean loss: 56.07
train mean loss: 53.90
epoch train time: 0:00:00.181859
elapsed time: 0:00:45.943670
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:52:43.375300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.57
 ---- batch: 020 ----
mean loss: 54.81
 ---- batch: 030 ----
mean loss: 54.34
train mean loss: 54.21
epoch train time: 0:00:00.186656
elapsed time: 0:00:46.130554
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:52:43.562110
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.22
 ---- batch: 020 ----
mean loss: 53.35
 ---- batch: 030 ----
mean loss: 55.36
train mean loss: 54.07
epoch train time: 0:00:00.181341
elapsed time: 0:00:46.312069
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:52:43.743632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.02
 ---- batch: 020 ----
mean loss: 56.88
 ---- batch: 030 ----
mean loss: 56.10
train mean loss: 56.53
epoch train time: 0:00:00.176381
elapsed time: 0:00:46.488600
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:52:43.920148
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.22
 ---- batch: 020 ----
mean loss: 56.69
 ---- batch: 030 ----
mean loss: 50.81
train mean loss: 54.15
epoch train time: 0:00:00.176203
elapsed time: 0:00:46.664939
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:52:44.096488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.54
 ---- batch: 020 ----
mean loss: 53.71
 ---- batch: 030 ----
mean loss: 51.81
train mean loss: 52.91
epoch train time: 0:00:00.176891
elapsed time: 0:00:46.841975
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:52:44.273523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.90
 ---- batch: 020 ----
mean loss: 53.18
 ---- batch: 030 ----
mean loss: 53.45
train mean loss: 52.63
epoch train time: 0:00:00.174548
elapsed time: 0:00:47.016664
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:52:44.448212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.02
 ---- batch: 020 ----
mean loss: 50.42
 ---- batch: 030 ----
mean loss: 54.78
train mean loss: 53.41
epoch train time: 0:00:00.173270
elapsed time: 0:00:47.190067
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:52:44.621637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.93
 ---- batch: 020 ----
mean loss: 52.22
 ---- batch: 030 ----
mean loss: 53.17
train mean loss: 53.06
epoch train time: 0:00:00.172149
elapsed time: 0:00:47.362376
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:52:44.793925
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.65
 ---- batch: 020 ----
mean loss: 52.58
 ---- batch: 030 ----
mean loss: 53.24
train mean loss: 51.49
epoch train time: 0:00:00.173222
elapsed time: 0:00:47.535746
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:52:44.967284
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.38
 ---- batch: 020 ----
mean loss: 51.88
 ---- batch: 030 ----
mean loss: 51.14
train mean loss: 51.22
epoch train time: 0:00:00.173259
elapsed time: 0:00:47.709131
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:52:45.140679
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.81
 ---- batch: 020 ----
mean loss: 49.64
 ---- batch: 030 ----
mean loss: 51.17
train mean loss: 51.36
epoch train time: 0:00:00.175022
elapsed time: 0:00:47.884289
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:52:45.315836
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.44
 ---- batch: 020 ----
mean loss: 49.22
 ---- batch: 030 ----
mean loss: 51.57
train mean loss: 51.08
epoch train time: 0:00:00.174216
elapsed time: 0:00:48.058640
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:52:45.490186
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.45
 ---- batch: 020 ----
mean loss: 52.08
 ---- batch: 030 ----
mean loss: 50.35
train mean loss: 51.20
epoch train time: 0:00:00.170586
elapsed time: 0:00:48.229360
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:52:45.660908
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.22
 ---- batch: 020 ----
mean loss: 51.14
 ---- batch: 030 ----
mean loss: 51.43
train mean loss: 51.06
epoch train time: 0:00:00.178673
elapsed time: 0:00:48.408173
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:52:45.839740
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.78
 ---- batch: 020 ----
mean loss: 51.16
 ---- batch: 030 ----
mean loss: 51.00
train mean loss: 51.09
epoch train time: 0:00:00.175746
elapsed time: 0:00:48.584081
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:52:46.015630
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.47
 ---- batch: 020 ----
mean loss: 50.05
 ---- batch: 030 ----
mean loss: 50.14
train mean loss: 51.14
epoch train time: 0:00:00.175418
elapsed time: 0:00:48.759634
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:52:46.191181
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.16
 ---- batch: 020 ----
mean loss: 51.05
 ---- batch: 030 ----
mean loss: 50.01
train mean loss: 50.94
epoch train time: 0:00:00.168233
elapsed time: 0:00:48.928013
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:52:46.359558
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.76
 ---- batch: 020 ----
mean loss: 51.03
 ---- batch: 030 ----
mean loss: 51.92
train mean loss: 51.16
epoch train time: 0:00:00.163863
elapsed time: 0:00:49.092029
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:52:46.523577
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.65
 ---- batch: 020 ----
mean loss: 49.65
 ---- batch: 030 ----
mean loss: 49.42
train mean loss: 50.85
epoch train time: 0:00:00.181086
elapsed time: 0:00:49.273253
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:52:46.704801
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.06
 ---- batch: 020 ----
mean loss: 51.41
 ---- batch: 030 ----
mean loss: 51.48
train mean loss: 50.98
epoch train time: 0:00:00.178152
elapsed time: 0:00:49.451540
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:52:46.883087
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.78
 ---- batch: 020 ----
mean loss: 48.69
 ---- batch: 030 ----
mean loss: 51.50
train mean loss: 51.03
epoch train time: 0:00:00.167891
elapsed time: 0:00:49.619564
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:52:47.051111
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.24
 ---- batch: 020 ----
mean loss: 51.47
 ---- batch: 030 ----
mean loss: 50.29
train mean loss: 51.06
epoch train time: 0:00:00.171672
elapsed time: 0:00:49.791386
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:52:47.222932
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.31
 ---- batch: 020 ----
mean loss: 50.73
 ---- batch: 030 ----
mean loss: 53.90
train mean loss: 50.81
epoch train time: 0:00:00.169797
elapsed time: 0:00:49.961316
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:52:47.392865
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.39
 ---- batch: 020 ----
mean loss: 51.55
 ---- batch: 030 ----
mean loss: 50.14
train mean loss: 50.96
epoch train time: 0:00:00.166361
elapsed time: 0:00:50.127812
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:52:47.559358
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.88
 ---- batch: 020 ----
mean loss: 52.20
 ---- batch: 030 ----
mean loss: 52.19
train mean loss: 50.82
epoch train time: 0:00:00.170006
elapsed time: 0:00:50.297951
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:52:47.729497
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.17
 ---- batch: 020 ----
mean loss: 51.38
 ---- batch: 030 ----
mean loss: 49.08
train mean loss: 50.91
epoch train time: 0:00:00.168927
elapsed time: 0:00:50.467012
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:52:47.898559
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.55
 ---- batch: 020 ----
mean loss: 52.00
 ---- batch: 030 ----
mean loss: 50.81
train mean loss: 50.83
epoch train time: 0:00:00.168598
elapsed time: 0:00:50.635743
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:52:48.067291
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.71
 ---- batch: 020 ----
mean loss: 51.05
 ---- batch: 030 ----
mean loss: 53.65
train mean loss: 50.89
epoch train time: 0:00:00.165702
elapsed time: 0:00:50.801578
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:52:48.233142
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.02
 ---- batch: 020 ----
mean loss: 50.70
 ---- batch: 030 ----
mean loss: 52.11
train mean loss: 50.77
epoch train time: 0:00:00.166994
elapsed time: 0:00:50.968723
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:52:48.400271
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.11
 ---- batch: 020 ----
mean loss: 50.98
 ---- batch: 030 ----
mean loss: 50.71
train mean loss: 50.89
epoch train time: 0:00:00.166817
elapsed time: 0:00:51.135692
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:52:48.567243
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.19
 ---- batch: 020 ----
mean loss: 49.60
 ---- batch: 030 ----
mean loss: 53.00
train mean loss: 50.71
epoch train time: 0:00:00.177119
elapsed time: 0:00:51.312962
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:52:48.744512
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.19
 ---- batch: 020 ----
mean loss: 48.87
 ---- batch: 030 ----
mean loss: 51.54
train mean loss: 50.79
epoch train time: 0:00:00.175958
elapsed time: 0:00:51.489064
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:52:48.920612
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.74
 ---- batch: 020 ----
mean loss: 49.74
 ---- batch: 030 ----
mean loss: 50.72
train mean loss: 50.75
epoch train time: 0:00:00.184133
elapsed time: 0:00:51.673349
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:52:49.104908
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.94
 ---- batch: 020 ----
mean loss: 50.67
 ---- batch: 030 ----
mean loss: 49.36
train mean loss: 50.65
epoch train time: 0:00:00.170138
elapsed time: 0:00:51.843647
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:52:49.275197
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.40
 ---- batch: 020 ----
mean loss: 53.19
 ---- batch: 030 ----
mean loss: 49.38
train mean loss: 50.66
epoch train time: 0:00:00.166149
elapsed time: 0:00:52.009941
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:52:49.441490
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.02
 ---- batch: 020 ----
mean loss: 50.34
 ---- batch: 030 ----
mean loss: 50.47
train mean loss: 50.70
epoch train time: 0:00:00.164834
elapsed time: 0:00:52.174912
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:52:49.606458
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.26
 ---- batch: 020 ----
mean loss: 49.73
 ---- batch: 030 ----
mean loss: 50.73
train mean loss: 50.49
epoch train time: 0:00:00.168737
elapsed time: 0:00:52.343785
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:52:49.775333
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.88
 ---- batch: 020 ----
mean loss: 52.33
 ---- batch: 030 ----
mean loss: 50.21
train mean loss: 50.68
epoch train time: 0:00:00.169533
elapsed time: 0:00:52.513454
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:52:49.945003
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.13
 ---- batch: 020 ----
mean loss: 50.16
 ---- batch: 030 ----
mean loss: 50.23
train mean loss: 50.52
epoch train time: 0:00:00.167374
elapsed time: 0:00:52.680964
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:52:50.112512
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.56
 ---- batch: 020 ----
mean loss: 52.09
 ---- batch: 030 ----
mean loss: 49.14
train mean loss: 50.41
epoch train time: 0:00:00.167121
elapsed time: 0:00:52.848221
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:52:50.279770
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.63
 ---- batch: 020 ----
mean loss: 50.19
 ---- batch: 030 ----
mean loss: 49.50
train mean loss: 50.52
epoch train time: 0:00:00.168132
elapsed time: 0:00:53.016502
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:52:50.448060
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.73
 ---- batch: 020 ----
mean loss: 50.73
 ---- batch: 030 ----
mean loss: 48.85
train mean loss: 50.66
epoch train time: 0:00:00.168374
elapsed time: 0:00:53.185035
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:52:50.616580
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.09
 ---- batch: 020 ----
mean loss: 50.93
 ---- batch: 030 ----
mean loss: 48.78
train mean loss: 50.49
epoch train time: 0:00:00.168646
elapsed time: 0:00:53.353814
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:52:50.785360
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.38
 ---- batch: 020 ----
mean loss: 49.68
 ---- batch: 030 ----
mean loss: 50.57
train mean loss: 50.43
epoch train time: 0:00:00.167387
elapsed time: 0:00:53.521335
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:52:50.952884
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.48
 ---- batch: 020 ----
mean loss: 50.08
 ---- batch: 030 ----
mean loss: 49.79
train mean loss: 50.50
epoch train time: 0:00:00.168187
elapsed time: 0:00:53.689658
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:52:51.121207
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.27
 ---- batch: 020 ----
mean loss: 49.67
 ---- batch: 030 ----
mean loss: 50.17
train mean loss: 50.40
epoch train time: 0:00:00.167084
elapsed time: 0:00:53.856876
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:52:51.288434
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.36
 ---- batch: 020 ----
mean loss: 49.74
 ---- batch: 030 ----
mean loss: 49.17
train mean loss: 50.41
epoch train time: 0:00:00.166360
elapsed time: 0:00:54.023381
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:52:51.454946
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.16
 ---- batch: 020 ----
mean loss: 50.59
 ---- batch: 030 ----
mean loss: 50.60
train mean loss: 50.56
epoch train time: 0:00:00.168741
elapsed time: 0:00:54.192290
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:52:51.623836
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.38
 ---- batch: 020 ----
mean loss: 49.22
 ---- batch: 030 ----
mean loss: 52.53
train mean loss: 50.32
epoch train time: 0:00:00.167059
elapsed time: 0:00:54.359490
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:52:51.791036
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.74
 ---- batch: 020 ----
mean loss: 49.90
 ---- batch: 030 ----
mean loss: 49.95
train mean loss: 50.37
epoch train time: 0:00:00.167408
elapsed time: 0:00:54.527030
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:52:51.958576
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.54
 ---- batch: 020 ----
mean loss: 50.14
 ---- batch: 030 ----
mean loss: 48.98
train mean loss: 50.26
epoch train time: 0:00:00.172193
elapsed time: 0:00:54.699357
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:52:52.130904
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.59
 ---- batch: 020 ----
mean loss: 51.51
 ---- batch: 030 ----
mean loss: 51.19
train mean loss: 50.21
epoch train time: 0:00:00.165330
elapsed time: 0:00:54.864821
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:52:52.296368
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.76
 ---- batch: 020 ----
mean loss: 49.76
 ---- batch: 030 ----
mean loss: 51.52
train mean loss: 50.25
epoch train time: 0:00:00.164707
elapsed time: 0:00:55.029659
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:52:52.461206
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.34
 ---- batch: 020 ----
mean loss: 49.25
 ---- batch: 030 ----
mean loss: 49.48
train mean loss: 50.18
epoch train time: 0:00:00.167193
elapsed time: 0:00:55.196984
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:52:52.628531
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.66
 ---- batch: 020 ----
mean loss: 49.81
 ---- batch: 030 ----
mean loss: 49.89
train mean loss: 50.20
epoch train time: 0:00:00.168923
elapsed time: 0:00:55.366043
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:52:52.797630
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.64
 ---- batch: 020 ----
mean loss: 50.14
 ---- batch: 030 ----
mean loss: 46.47
train mean loss: 50.27
epoch train time: 0:00:00.168520
elapsed time: 0:00:55.534738
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:52:52.966284
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.56
 ---- batch: 020 ----
mean loss: 51.46
 ---- batch: 030 ----
mean loss: 51.05
train mean loss: 50.37
epoch train time: 0:00:00.171467
elapsed time: 0:00:55.709717
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_0/checkpoint.pth.tar
**** end time: 2019-09-27 16:52:53.141233 ****
