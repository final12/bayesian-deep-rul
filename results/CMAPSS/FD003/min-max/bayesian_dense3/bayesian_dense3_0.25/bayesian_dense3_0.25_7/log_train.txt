Namespace(batch_size=512, dataset='CMAPSS/FD003', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_7', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.25, resume=False, step_size=200, visualize_step=50)
pid: 23791
use_cuda: True
Dataset: CMAPSS/FD003
Building BayesianDense3...
Done.
**** start time: 2019-10-01 14:48:31.855189 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-10-01 14:48:31.864535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4748.99
train mean loss: 4731.45
epoch train time: 0:00:03.933160
elapsed time: 0:00:03.948883
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-10-01 14:48:35.804116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4612.13
train mean loss: 4585.81
epoch train time: 0:00:00.178467
elapsed time: 0:00:04.127477
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-10-01 14:48:35.982722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4387.89
train mean loss: 4388.11
epoch train time: 0:00:00.174213
elapsed time: 0:00:04.301827
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-10-01 14:48:36.157057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4156.48
train mean loss: 4170.15
epoch train time: 0:00:00.173233
elapsed time: 0:00:04.475190
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-10-01 14:48:36.330457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3981.14
train mean loss: 3948.27
epoch train time: 0:00:00.174959
elapsed time: 0:00:04.650302
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-10-01 14:48:36.505537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3775.12
train mean loss: 3777.73
epoch train time: 0:00:00.171638
elapsed time: 0:00:04.822063
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-10-01 14:48:36.677311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3605.98
train mean loss: 3610.02
epoch train time: 0:00:00.179619
elapsed time: 0:00:05.001827
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-10-01 14:48:36.857066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3477.93
train mean loss: 3465.12
epoch train time: 0:00:00.181795
elapsed time: 0:00:05.183754
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-10-01 14:48:37.039016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3333.27
train mean loss: 3318.38
epoch train time: 0:00:00.177476
elapsed time: 0:00:05.361381
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-10-01 14:48:37.216613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3210.08
train mean loss: 3219.73
epoch train time: 0:00:00.178242
elapsed time: 0:00:05.539740
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-10-01 14:48:37.394996
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3101.38
train mean loss: 3106.18
epoch train time: 0:00:00.179240
elapsed time: 0:00:05.719141
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-10-01 14:48:37.574389
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3013.80
train mean loss: 2999.30
epoch train time: 0:00:00.179839
elapsed time: 0:00:05.899133
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-10-01 14:48:37.754385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2923.71
train mean loss: 2910.80
epoch train time: 0:00:00.188449
elapsed time: 0:00:06.087727
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-10-01 14:48:37.942959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2851.27
train mean loss: 2834.29
epoch train time: 0:00:00.179045
elapsed time: 0:00:06.266903
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-10-01 14:48:38.122139
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2772.91
train mean loss: 2777.58
epoch train time: 0:00:00.176004
elapsed time: 0:00:06.443043
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-10-01 14:48:38.298278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2705.16
train mean loss: 2703.93
epoch train time: 0:00:00.175887
elapsed time: 0:00:06.619087
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-10-01 14:48:38.474330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2668.47
train mean loss: 2652.58
epoch train time: 0:00:00.174130
elapsed time: 0:00:06.793351
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-10-01 14:48:38.648585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2600.91
train mean loss: 2602.04
epoch train time: 0:00:00.177509
elapsed time: 0:00:06.970996
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-10-01 14:48:38.826232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2562.19
train mean loss: 2553.52
epoch train time: 0:00:00.177601
elapsed time: 0:00:07.148724
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-10-01 14:48:39.003959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2506.16
train mean loss: 2497.06
epoch train time: 0:00:00.174522
elapsed time: 0:00:07.323363
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-10-01 14:48:39.178591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2446.52
train mean loss: 2458.69
epoch train time: 0:00:00.173192
elapsed time: 0:00:07.496671
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-10-01 14:48:39.351903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2421.22
train mean loss: 2409.64
epoch train time: 0:00:00.178317
elapsed time: 0:00:07.675121
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-10-01 14:48:39.530353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2388.95
train mean loss: 2382.18
epoch train time: 0:00:00.182507
elapsed time: 0:00:07.857785
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-10-01 14:48:39.713026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2337.95
train mean loss: 2338.04
epoch train time: 0:00:00.179528
elapsed time: 0:00:08.037476
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-10-01 14:48:39.892761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2303.99
train mean loss: 2299.51
epoch train time: 0:00:00.180232
elapsed time: 0:00:08.217883
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-10-01 14:48:40.073115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2263.03
train mean loss: 2254.72
epoch train time: 0:00:00.176064
elapsed time: 0:00:08.394068
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-10-01 14:48:40.249323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2227.97
train mean loss: 2218.70
epoch train time: 0:00:00.173620
elapsed time: 0:00:08.567833
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-10-01 14:48:40.423064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2180.72
train mean loss: 2175.55
epoch train time: 0:00:00.174172
elapsed time: 0:00:08.742125
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-10-01 14:48:40.597356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2154.33
train mean loss: 2153.92
epoch train time: 0:00:00.177309
elapsed time: 0:00:08.919555
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-10-01 14:48:40.774788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2112.11
train mean loss: 2124.57
epoch train time: 0:00:00.181498
elapsed time: 0:00:09.101201
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-10-01 14:48:40.956449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2082.89
train mean loss: 2093.02
epoch train time: 0:00:00.176930
elapsed time: 0:00:09.278272
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-10-01 14:48:41.133503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2050.80
train mean loss: 2053.50
epoch train time: 0:00:00.170663
elapsed time: 0:00:09.449063
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-10-01 14:48:41.304298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2007.62
train mean loss: 2010.80
epoch train time: 0:00:00.174889
elapsed time: 0:00:09.624073
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-10-01 14:48:41.479304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1994.29
train mean loss: 1993.34
epoch train time: 0:00:00.175930
elapsed time: 0:00:09.800135
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-10-01 14:48:41.655369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1970.71
train mean loss: 1968.11
epoch train time: 0:00:00.180628
elapsed time: 0:00:09.980887
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-10-01 14:48:41.836121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1916.29
train mean loss: 1922.11
epoch train time: 0:00:00.177672
elapsed time: 0:00:10.158697
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-10-01 14:48:42.013935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1896.81
train mean loss: 1893.40
epoch train time: 0:00:00.180529
elapsed time: 0:00:10.339357
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-10-01 14:48:42.194590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1864.83
train mean loss: 1868.87
epoch train time: 0:00:00.177912
elapsed time: 0:00:10.517390
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-10-01 14:48:42.372623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1846.47
train mean loss: 1846.29
epoch train time: 0:00:00.179051
elapsed time: 0:00:10.696568
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-10-01 14:48:42.551801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1819.45
train mean loss: 1833.76
epoch train time: 0:00:00.178403
elapsed time: 0:00:10.875097
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-10-01 14:48:42.730331
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1783.63
train mean loss: 1790.37
epoch train time: 0:00:00.190824
elapsed time: 0:00:11.066064
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-10-01 14:48:42.921298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1768.33
train mean loss: 1769.17
epoch train time: 0:00:00.178573
elapsed time: 0:00:11.244773
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-10-01 14:48:43.100005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1725.76
train mean loss: 1732.43
epoch train time: 0:00:00.177713
elapsed time: 0:00:11.422626
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-10-01 14:48:43.277859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1729.45
train mean loss: 1719.69
epoch train time: 0:00:00.178047
elapsed time: 0:00:11.600798
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-10-01 14:48:43.456055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1678.63
train mean loss: 1688.21
epoch train time: 0:00:00.177044
elapsed time: 0:00:11.777986
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-10-01 14:48:43.633219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1649.08
train mean loss: 1656.88
epoch train time: 0:00:00.177990
elapsed time: 0:00:11.956112
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-10-01 14:48:43.811346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1627.16
train mean loss: 1625.46
epoch train time: 0:00:00.196474
elapsed time: 0:00:12.152718
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-10-01 14:48:44.007961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1601.76
train mean loss: 1597.10
epoch train time: 0:00:00.180367
elapsed time: 0:00:12.333217
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-10-01 14:48:44.188458
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1567.39
train mean loss: 1574.57
epoch train time: 0:00:00.176756
elapsed time: 0:00:12.510117
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-10-01 14:48:44.365349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1550.14
train mean loss: 1548.11
epoch train time: 0:00:00.179250
elapsed time: 0:00:12.689484
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-10-01 14:48:44.544715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1513.49
train mean loss: 1520.79
epoch train time: 0:00:00.179267
elapsed time: 0:00:12.868874
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-10-01 14:48:44.724111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1489.63
train mean loss: 1494.58
epoch train time: 0:00:00.180264
elapsed time: 0:00:13.049271
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-10-01 14:48:44.904505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1473.08
train mean loss: 1466.64
epoch train time: 0:00:00.191291
elapsed time: 0:00:13.240681
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-10-01 14:48:45.095914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1449.04
train mean loss: 1445.61
epoch train time: 0:00:00.179699
elapsed time: 0:00:13.420503
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-10-01 14:48:45.275753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1420.87
train mean loss: 1416.79
epoch train time: 0:00:00.177675
elapsed time: 0:00:13.598321
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-10-01 14:48:45.453557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1391.46
train mean loss: 1400.47
epoch train time: 0:00:00.179002
elapsed time: 0:00:13.777460
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-10-01 14:48:45.632693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1377.18
train mean loss: 1380.04
epoch train time: 0:00:00.178720
elapsed time: 0:00:13.956319
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-10-01 14:48:45.811554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1362.99
train mean loss: 1359.61
epoch train time: 0:00:00.179246
elapsed time: 0:00:14.135701
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-10-01 14:48:45.990975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1329.60
train mean loss: 1327.41
epoch train time: 0:00:00.179573
elapsed time: 0:00:14.315446
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-10-01 14:48:46.170694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1308.72
train mean loss: 1313.81
epoch train time: 0:00:00.181310
elapsed time: 0:00:14.496923
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-10-01 14:48:46.352172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1282.03
train mean loss: 1284.73
epoch train time: 0:00:00.179281
elapsed time: 0:00:14.676342
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-10-01 14:48:46.531589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1269.40
train mean loss: 1264.02
epoch train time: 0:00:00.178013
elapsed time: 0:00:14.854492
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-10-01 14:48:46.709740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1242.73
train mean loss: 1248.15
epoch train time: 0:00:00.184060
elapsed time: 0:00:15.038713
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-10-01 14:48:46.893956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1227.29
train mean loss: 1224.94
epoch train time: 0:00:00.183955
elapsed time: 0:00:15.222813
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-10-01 14:48:47.078076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1212.74
train mean loss: 1211.88
epoch train time: 0:00:00.186360
elapsed time: 0:00:15.409329
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-10-01 14:48:47.264562
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1181.88
train mean loss: 1188.85
epoch train time: 0:00:00.180461
elapsed time: 0:00:15.589929
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-10-01 14:48:47.445160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1174.90
train mean loss: 1165.73
epoch train time: 0:00:00.179137
elapsed time: 0:00:15.769185
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-10-01 14:48:47.624428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1147.51
train mean loss: 1146.00
epoch train time: 0:00:00.181158
elapsed time: 0:00:15.950479
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-10-01 14:48:47.805711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1125.30
train mean loss: 1127.93
epoch train time: 0:00:00.176932
elapsed time: 0:00:16.127527
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-10-01 14:48:47.982759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1110.15
train mean loss: 1107.35
epoch train time: 0:00:00.172841
elapsed time: 0:00:16.300483
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-10-01 14:48:48.155711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1089.77
train mean loss: 1087.45
epoch train time: 0:00:00.177037
elapsed time: 0:00:16.477648
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-10-01 14:48:48.332883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1071.86
train mean loss: 1076.73
epoch train time: 0:00:00.177565
elapsed time: 0:00:16.655339
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-10-01 14:48:48.510574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1053.15
train mean loss: 1053.16
epoch train time: 0:00:00.174834
elapsed time: 0:00:16.830298
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-10-01 14:48:48.685526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1040.57
train mean loss: 1040.13
epoch train time: 0:00:00.184614
elapsed time: 0:00:17.015031
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-10-01 14:48:48.870264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1024.13
train mean loss: 1018.07
epoch train time: 0:00:00.174568
elapsed time: 0:00:17.189719
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-10-01 14:48:49.044951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1004.32
train mean loss: 1001.82
epoch train time: 0:00:00.174045
elapsed time: 0:00:17.363881
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-10-01 14:48:49.219111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 990.70
train mean loss: 983.57
epoch train time: 0:00:00.174725
elapsed time: 0:00:17.538730
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-10-01 14:48:49.393962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 958.60
train mean loss: 957.26
epoch train time: 0:00:00.175614
elapsed time: 0:00:17.714462
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-10-01 14:48:49.569719
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 957.81
train mean loss: 957.47
epoch train time: 0:00:00.173915
elapsed time: 0:00:17.888524
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-10-01 14:48:49.743755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.30
train mean loss: 931.98
epoch train time: 0:00:00.184855
elapsed time: 0:00:18.073514
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-10-01 14:48:49.928747
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 922.35
train mean loss: 921.85
epoch train time: 0:00:00.177575
elapsed time: 0:00:18.251243
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-10-01 14:48:50.106495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 915.00
train mean loss: 909.49
epoch train time: 0:00:00.178986
elapsed time: 0:00:18.430369
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-10-01 14:48:50.285601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 898.35
train mean loss: 894.54
epoch train time: 0:00:00.180015
elapsed time: 0:00:18.610509
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-10-01 14:48:50.465744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 892.53
train mean loss: 888.26
epoch train time: 0:00:00.178662
elapsed time: 0:00:18.789297
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-10-01 14:48:50.644555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 857.00
train mean loss: 863.18
epoch train time: 0:00:00.178243
elapsed time: 0:00:18.967694
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-10-01 14:48:50.822926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 845.45
train mean loss: 848.46
epoch train time: 0:00:00.195077
elapsed time: 0:00:19.162899
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-10-01 14:48:51.018133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 834.54
train mean loss: 836.47
epoch train time: 0:00:00.177275
elapsed time: 0:00:19.340330
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-10-01 14:48:51.195574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 834.95
train mean loss: 830.79
epoch train time: 0:00:00.181519
elapsed time: 0:00:19.521984
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-10-01 14:48:51.377217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 811.11
train mean loss: 809.18
epoch train time: 0:00:00.179613
elapsed time: 0:00:19.701722
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-10-01 14:48:51.556957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 793.98
train mean loss: 797.26
epoch train time: 0:00:00.177286
elapsed time: 0:00:19.879148
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-10-01 14:48:51.734382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 792.38
train mean loss: 785.05
epoch train time: 0:00:00.192548
elapsed time: 0:00:20.071825
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-10-01 14:48:51.927060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 769.40
train mean loss: 771.42
epoch train time: 0:00:00.180211
elapsed time: 0:00:20.252166
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-10-01 14:48:52.107402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 761.67
train mean loss: 758.26
epoch train time: 0:00:00.178818
elapsed time: 0:00:20.431131
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-10-01 14:48:52.286379
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 746.90
train mean loss: 744.15
epoch train time: 0:00:00.180609
elapsed time: 0:00:20.611882
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-10-01 14:48:52.467136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 731.23
train mean loss: 732.01
epoch train time: 0:00:00.178426
elapsed time: 0:00:20.790464
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-10-01 14:48:52.645701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 729.07
train mean loss: 721.72
epoch train time: 0:00:00.179957
elapsed time: 0:00:20.970550
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-10-01 14:48:52.825807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 707.12
train mean loss: 706.12
epoch train time: 0:00:00.189992
elapsed time: 0:00:21.160691
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-10-01 14:48:53.015925
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 693.17
train mean loss: 698.97
epoch train time: 0:00:00.178861
elapsed time: 0:00:21.339674
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-10-01 14:48:53.194916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 678.10
train mean loss: 680.83
epoch train time: 0:00:00.178559
elapsed time: 0:00:21.518361
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-10-01 14:48:53.373609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 671.06
train mean loss: 669.55
epoch train time: 0:00:00.183397
elapsed time: 0:00:21.701901
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-10-01 14:48:53.557134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 659.44
train mean loss: 658.46
epoch train time: 0:00:00.188561
elapsed time: 0:00:21.890613
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-10-01 14:48:53.745851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 644.94
train mean loss: 649.39
epoch train time: 0:00:00.178359
elapsed time: 0:00:22.069127
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-10-01 14:48:53.924361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 642.09
train mean loss: 641.28
epoch train time: 0:00:00.175619
elapsed time: 0:00:22.244869
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-10-01 14:48:54.100101
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 624.34
train mean loss: 629.17
epoch train time: 0:00:00.180641
elapsed time: 0:00:22.425633
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-10-01 14:48:54.280867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 625.78
train mean loss: 625.21
epoch train time: 0:00:00.179764
elapsed time: 0:00:22.605535
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-10-01 14:48:54.460780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 601.72
train mean loss: 600.05
epoch train time: 0:00:00.180669
elapsed time: 0:00:22.786342
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-10-01 14:48:54.641577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 592.18
train mean loss: 594.70
epoch train time: 0:00:00.182731
elapsed time: 0:00:22.969221
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-10-01 14:48:54.824448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 577.80
train mean loss: 577.92
epoch train time: 0:00:00.176520
elapsed time: 0:00:23.145868
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-10-01 14:48:55.001103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 578.33
train mean loss: 575.63
epoch train time: 0:00:00.174935
elapsed time: 0:00:23.320938
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-10-01 14:48:55.176170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 564.81
train mean loss: 562.82
epoch train time: 0:00:00.174971
elapsed time: 0:00:23.496043
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-10-01 14:48:55.351273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 561.87
train mean loss: 561.29
epoch train time: 0:00:00.179600
elapsed time: 0:00:23.675781
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-10-01 14:48:55.531013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 549.54
train mean loss: 555.32
epoch train time: 0:00:00.183814
elapsed time: 0:00:23.859721
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-10-01 14:48:55.714968
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 544.79
train mean loss: 545.18
epoch train time: 0:00:00.197516
elapsed time: 0:00:24.057379
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-10-01 14:48:55.912652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 532.53
train mean loss: 531.45
epoch train time: 0:00:00.181496
elapsed time: 0:00:24.239043
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-10-01 14:48:56.094279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 528.98
train mean loss: 528.85
epoch train time: 0:00:00.180421
elapsed time: 0:00:24.419592
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-10-01 14:48:56.274827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 516.49
train mean loss: 515.39
epoch train time: 0:00:00.178140
elapsed time: 0:00:24.597863
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-10-01 14:48:56.453097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 506.42
train mean loss: 502.44
epoch train time: 0:00:00.184080
elapsed time: 0:00:24.782074
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-10-01 14:48:56.637325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 495.64
train mean loss: 495.51
epoch train time: 0:00:00.182070
elapsed time: 0:00:24.964293
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-10-01 14:48:56.819528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 488.59
train mean loss: 488.83
epoch train time: 0:00:00.181852
elapsed time: 0:00:25.146315
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-10-01 14:48:57.001550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 486.79
train mean loss: 483.07
epoch train time: 0:00:00.180242
elapsed time: 0:00:25.326681
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-10-01 14:48:57.181912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 481.18
train mean loss: 477.77
epoch train time: 0:00:00.177534
elapsed time: 0:00:25.504369
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-10-01 14:48:57.359631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.82
train mean loss: 469.51
epoch train time: 0:00:00.180703
elapsed time: 0:00:25.685227
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-10-01 14:48:57.540477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 455.27
train mean loss: 453.62
epoch train time: 0:00:00.183440
elapsed time: 0:00:25.868810
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-10-01 14:48:57.724054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 453.19
train mean loss: 451.36
epoch train time: 0:00:00.175163
elapsed time: 0:00:26.044109
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-10-01 14:48:57.899340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 443.66
train mean loss: 446.16
epoch train time: 0:00:00.171473
elapsed time: 0:00:26.215695
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-10-01 14:48:58.070940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 436.16
train mean loss: 439.99
epoch train time: 0:00:00.174037
elapsed time: 0:00:26.389865
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-10-01 14:48:58.245099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 436.93
train mean loss: 436.48
epoch train time: 0:00:00.168290
elapsed time: 0:00:26.558327
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-10-01 14:48:58.413552
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 425.32
train mean loss: 427.33
epoch train time: 0:00:00.172689
elapsed time: 0:00:26.731132
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-10-01 14:48:58.586364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 411.16
train mean loss: 414.71
epoch train time: 0:00:00.179864
elapsed time: 0:00:26.911121
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-10-01 14:48:58.766355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 407.27
train mean loss: 406.21
epoch train time: 0:00:00.173511
elapsed time: 0:00:27.084759
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-10-01 14:48:58.939990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 402.71
train mean loss: 405.25
epoch train time: 0:00:00.173459
elapsed time: 0:00:27.258338
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-10-01 14:48:59.113570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 404.67
train mean loss: 402.23
epoch train time: 0:00:00.173511
elapsed time: 0:00:27.431969
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-10-01 14:48:59.287204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 395.15
train mean loss: 390.70
epoch train time: 0:00:00.173843
elapsed time: 0:00:27.605939
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-10-01 14:48:59.461174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 382.58
train mean loss: 384.50
epoch train time: 0:00:00.174289
elapsed time: 0:00:27.780370
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-10-01 14:48:59.635606
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 378.32
train mean loss: 377.46
epoch train time: 0:00:00.176349
elapsed time: 0:00:27.956844
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-10-01 14:48:59.812087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 376.26
train mean loss: 374.65
epoch train time: 0:00:00.181071
elapsed time: 0:00:28.138064
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-10-01 14:48:59.993318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.22
train mean loss: 364.40
epoch train time: 0:00:00.181918
elapsed time: 0:00:28.320131
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-10-01 14:49:00.175375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.03
train mean loss: 367.58
epoch train time: 0:00:00.179414
elapsed time: 0:00:28.499675
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-10-01 14:49:00.354909
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 353.50
train mean loss: 353.03
epoch train time: 0:00:00.179545
elapsed time: 0:00:28.679341
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-10-01 14:49:00.534573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.69
train mean loss: 348.17
epoch train time: 0:00:00.182345
elapsed time: 0:00:28.861810
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-10-01 14:49:00.717046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.23
train mean loss: 347.63
epoch train time: 0:00:00.179362
elapsed time: 0:00:29.041303
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-10-01 14:49:00.896538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 343.19
train mean loss: 341.31
epoch train time: 0:00:00.177708
elapsed time: 0:00:29.219153
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-10-01 14:49:01.074385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 332.96
train mean loss: 334.07
epoch train time: 0:00:00.180335
elapsed time: 0:00:29.399612
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-10-01 14:49:01.254845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.56
train mean loss: 333.21
epoch train time: 0:00:00.177939
elapsed time: 0:00:29.577670
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-10-01 14:49:01.432901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.62
train mean loss: 327.01
epoch train time: 0:00:00.179987
elapsed time: 0:00:29.757778
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-10-01 14:49:01.613013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.21
train mean loss: 320.44
epoch train time: 0:00:00.195578
elapsed time: 0:00:29.953528
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-10-01 14:49:01.808786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.21
train mean loss: 317.44
epoch train time: 0:00:00.183294
elapsed time: 0:00:30.136989
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-10-01 14:49:01.992224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.02
train mean loss: 314.30
epoch train time: 0:00:00.177024
elapsed time: 0:00:30.314138
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-10-01 14:49:02.169372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 307.42
train mean loss: 307.47
epoch train time: 0:00:00.175110
elapsed time: 0:00:30.489407
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-10-01 14:49:02.344663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.46
train mean loss: 300.16
epoch train time: 0:00:00.183988
elapsed time: 0:00:30.673575
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-10-01 14:49:02.528808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.57
train mean loss: 299.30
epoch train time: 0:00:00.178400
elapsed time: 0:00:30.852106
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-10-01 14:49:02.707346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.71
train mean loss: 295.65
epoch train time: 0:00:00.182602
elapsed time: 0:00:31.034871
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-10-01 14:49:02.890103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.91
train mean loss: 288.81
epoch train time: 0:00:00.178335
elapsed time: 0:00:31.213332
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-10-01 14:49:03.068565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.30
train mean loss: 285.03
epoch train time: 0:00:00.177694
elapsed time: 0:00:31.391144
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-10-01 14:49:03.246389
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.90
train mean loss: 280.32
epoch train time: 0:00:00.174168
elapsed time: 0:00:31.565446
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-10-01 14:49:03.420678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.79
train mean loss: 277.51
epoch train time: 0:00:00.177688
elapsed time: 0:00:31.743253
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-10-01 14:49:03.598500
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 272.55
train mean loss: 272.54
epoch train time: 0:00:00.179388
elapsed time: 0:00:31.922784
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-10-01 14:49:03.778032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.35
train mean loss: 260.65
epoch train time: 0:00:00.195973
elapsed time: 0:00:32.118899
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-10-01 14:49:03.974131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.88
train mean loss: 265.07
epoch train time: 0:00:00.177969
elapsed time: 0:00:32.296986
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-10-01 14:49:04.152233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.61
train mean loss: 258.97
epoch train time: 0:00:00.172337
elapsed time: 0:00:32.469447
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-10-01 14:49:04.324676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.47
train mean loss: 252.03
epoch train time: 0:00:00.178848
elapsed time: 0:00:32.648419
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-10-01 14:49:04.503658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.74
train mean loss: 250.90
epoch train time: 0:00:00.177197
elapsed time: 0:00:32.825773
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-10-01 14:49:04.681022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.26
train mean loss: 245.14
epoch train time: 0:00:00.182080
elapsed time: 0:00:33.007992
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-10-01 14:49:04.863224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.51
train mean loss: 249.52
epoch train time: 0:00:00.176106
elapsed time: 0:00:33.184243
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-10-01 14:49:05.039476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.01
train mean loss: 243.70
epoch train time: 0:00:00.171595
elapsed time: 0:00:33.355957
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-10-01 14:49:05.211190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.80
train mean loss: 243.48
epoch train time: 0:00:00.168648
elapsed time: 0:00:33.524717
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-10-01 14:49:05.379944
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.48
train mean loss: 237.47
epoch train time: 0:00:00.179657
elapsed time: 0:00:33.704486
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-10-01 14:49:05.559716
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.84
train mean loss: 234.32
epoch train time: 0:00:00.178240
elapsed time: 0:00:33.882851
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-10-01 14:49:05.738085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.84
train mean loss: 229.74
epoch train time: 0:00:00.179578
elapsed time: 0:00:34.062555
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-10-01 14:49:05.917815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.51
train mean loss: 228.87
epoch train time: 0:00:00.176216
elapsed time: 0:00:34.238918
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-10-01 14:49:06.094147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.00
train mean loss: 220.48
epoch train time: 0:00:00.175650
elapsed time: 0:00:34.414686
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-10-01 14:49:06.269919
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.85
train mean loss: 220.78
epoch train time: 0:00:00.176044
elapsed time: 0:00:34.590869
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-10-01 14:49:06.446137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.24
train mean loss: 220.14
epoch train time: 0:00:00.175959
elapsed time: 0:00:34.766994
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-10-01 14:49:06.622226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.94
train mean loss: 215.71
epoch train time: 0:00:00.178383
elapsed time: 0:00:34.945511
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-10-01 14:49:06.800736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.35
train mean loss: 210.02
epoch train time: 0:00:00.183985
elapsed time: 0:00:35.129616
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-10-01 14:49:06.984850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.55
train mean loss: 206.10
epoch train time: 0:00:00.180216
elapsed time: 0:00:35.309971
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-10-01 14:49:07.165261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.18
train mean loss: 205.16
epoch train time: 0:00:00.178237
elapsed time: 0:00:35.488389
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-10-01 14:49:07.343621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.40
train mean loss: 198.71
epoch train time: 0:00:00.180166
elapsed time: 0:00:35.668685
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-10-01 14:49:07.523918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.56
train mean loss: 197.87
epoch train time: 0:00:00.190578
elapsed time: 0:00:35.859393
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-10-01 14:49:07.714635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 200.77
train mean loss: 199.04
epoch train time: 0:00:00.184223
elapsed time: 0:00:36.043749
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-10-01 14:49:07.898982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.10
train mean loss: 195.05
epoch train time: 0:00:00.180751
elapsed time: 0:00:36.224668
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-10-01 14:49:08.079903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.88
train mean loss: 188.53
epoch train time: 0:00:00.175055
elapsed time: 0:00:36.399875
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-10-01 14:49:08.255105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.31
train mean loss: 190.87
epoch train time: 0:00:00.174230
elapsed time: 0:00:36.574229
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-10-01 14:49:08.429465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.95
train mean loss: 184.47
epoch train time: 0:00:00.174478
elapsed time: 0:00:36.748825
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-10-01 14:49:08.604053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.05
train mean loss: 183.64
epoch train time: 0:00:00.177136
elapsed time: 0:00:36.926090
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-10-01 14:49:08.781328
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.54
train mean loss: 187.75
epoch train time: 0:00:00.182379
elapsed time: 0:00:37.108611
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-10-01 14:49:08.963848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.55
train mean loss: 178.00
epoch train time: 0:00:00.177263
elapsed time: 0:00:37.286002
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-10-01 14:49:09.141233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.98
train mean loss: 178.54
epoch train time: 0:00:00.176420
elapsed time: 0:00:37.462543
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-10-01 14:49:09.317805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.57
train mean loss: 176.65
epoch train time: 0:00:00.180918
elapsed time: 0:00:37.643621
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-10-01 14:49:09.498851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.73
train mean loss: 173.99
epoch train time: 0:00:00.178808
elapsed time: 0:00:37.822562
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-10-01 14:49:09.677822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.09
train mean loss: 172.76
epoch train time: 0:00:00.178196
elapsed time: 0:00:38.000922
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-10-01 14:49:09.856172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.53
train mean loss: 168.07
epoch train time: 0:00:00.180072
elapsed time: 0:00:38.181151
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-10-01 14:49:10.036396
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.24
train mean loss: 168.42
epoch train time: 0:00:00.176849
elapsed time: 0:00:38.358129
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-10-01 14:49:10.213385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.59
train mean loss: 163.61
epoch train time: 0:00:00.173769
elapsed time: 0:00:38.532036
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-10-01 14:49:10.387280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.17
train mean loss: 163.43
epoch train time: 0:00:00.177150
elapsed time: 0:00:38.709322
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-10-01 14:49:10.564556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.02
train mean loss: 161.73
epoch train time: 0:00:00.178842
elapsed time: 0:00:38.888290
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-10-01 14:49:10.743523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.23
train mean loss: 160.90
epoch train time: 0:00:00.182205
elapsed time: 0:00:39.070663
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-10-01 14:49:10.925912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.31
train mean loss: 161.19
epoch train time: 0:00:00.181169
elapsed time: 0:00:39.251972
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-10-01 14:49:11.107206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.76
train mean loss: 154.76
epoch train time: 0:00:00.177395
elapsed time: 0:00:39.429493
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-10-01 14:49:11.284728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.25
train mean loss: 152.61
epoch train time: 0:00:00.174434
elapsed time: 0:00:39.604080
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-10-01 14:49:11.459348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.54
train mean loss: 152.08
epoch train time: 0:00:00.185603
elapsed time: 0:00:39.789843
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-10-01 14:49:11.645079
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.71
train mean loss: 154.42
epoch train time: 0:00:00.179241
elapsed time: 0:00:39.969218
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-10-01 14:49:11.824451
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.84
train mean loss: 152.51
epoch train time: 0:00:00.179005
elapsed time: 0:00:40.148354
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-10-01 14:49:12.003587
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.80
train mean loss: 151.02
epoch train time: 0:00:00.179787
elapsed time: 0:00:40.328267
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-10-01 14:49:12.183503
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.45
train mean loss: 151.45
epoch train time: 0:00:00.175715
elapsed time: 0:00:40.504133
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-10-01 14:49:12.359381
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.13
train mean loss: 150.40
epoch train time: 0:00:00.180566
elapsed time: 0:00:40.684841
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-10-01 14:49:12.540076
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 149.36
train mean loss: 149.56
epoch train time: 0:00:00.183296
elapsed time: 0:00:40.868266
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-10-01 14:49:12.723503
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.80
train mean loss: 145.14
epoch train time: 0:00:00.181639
elapsed time: 0:00:41.050033
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-10-01 14:49:12.905294
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 148.96
train mean loss: 149.46
epoch train time: 0:00:00.181437
elapsed time: 0:00:41.231639
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-10-01 14:49:13.086894
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.24
train mean loss: 150.68
epoch train time: 0:00:00.183508
elapsed time: 0:00:41.415309
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-10-01 14:49:13.270773
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.11
train mean loss: 149.13
epoch train time: 0:00:00.177755
elapsed time: 0:00:41.593415
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-10-01 14:49:13.448647
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 146.12
train mean loss: 146.46
epoch train time: 0:00:00.176532
elapsed time: 0:00:41.770123
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-10-01 14:49:13.625369
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 148.65
train mean loss: 149.18
epoch train time: 0:00:00.179670
elapsed time: 0:00:41.949945
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-10-01 14:49:13.805193
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 149.44
train mean loss: 149.48
epoch train time: 0:00:00.174953
elapsed time: 0:00:42.125062
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-10-01 14:49:13.980292
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 148.88
train mean loss: 149.22
epoch train time: 0:00:00.175293
elapsed time: 0:00:42.300478
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-10-01 14:49:14.155709
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 147.85
train mean loss: 147.88
epoch train time: 0:00:00.170963
elapsed time: 0:00:42.471548
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-10-01 14:49:14.326776
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.66
train mean loss: 150.18
epoch train time: 0:00:00.173969
elapsed time: 0:00:42.645650
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-10-01 14:49:14.500910
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 147.62
train mean loss: 148.93
epoch train time: 0:00:00.173769
elapsed time: 0:00:42.819579
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-10-01 14:49:14.674815
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 147.91
train mean loss: 148.42
epoch train time: 0:00:00.185272
elapsed time: 0:00:43.004981
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-10-01 14:49:14.860214
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 147.18
train mean loss: 146.29
epoch train time: 0:00:00.174440
elapsed time: 0:00:43.179541
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-10-01 14:49:15.034811
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.86
train mean loss: 149.10
epoch train time: 0:00:00.173900
elapsed time: 0:00:43.353601
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-10-01 14:49:15.208832
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 147.19
train mean loss: 147.94
epoch train time: 0:00:00.170789
elapsed time: 0:00:43.524497
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-10-01 14:49:15.379723
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.67
train mean loss: 145.90
epoch train time: 0:00:00.170602
elapsed time: 0:00:43.695222
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-10-01 14:49:15.550453
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 147.73
train mean loss: 147.22
epoch train time: 0:00:00.177335
elapsed time: 0:00:43.873378
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-10-01 14:49:15.728636
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.50
train mean loss: 146.06
epoch train time: 0:00:00.194126
elapsed time: 0:00:44.067668
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-10-01 14:49:15.922898
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.28
train mean loss: 148.82
epoch train time: 0:00:00.173183
elapsed time: 0:00:44.241009
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-10-01 14:49:16.096241
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 147.02
train mean loss: 146.57
epoch train time: 0:00:00.173919
elapsed time: 0:00:44.415051
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-10-01 14:49:16.270299
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.74
train mean loss: 143.92
epoch train time: 0:00:00.173838
elapsed time: 0:00:44.589027
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-10-01 14:49:16.444258
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.41
train mean loss: 145.11
epoch train time: 0:00:00.172719
elapsed time: 0:00:44.761863
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-10-01 14:49:16.617092
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.40
train mean loss: 146.10
epoch train time: 0:00:00.182141
elapsed time: 0:00:44.944179
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-10-01 14:49:16.799411
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.77
train mean loss: 144.24
epoch train time: 0:00:00.178331
elapsed time: 0:00:45.122689
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-10-01 14:49:16.977953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.58
train mean loss: 143.68
epoch train time: 0:00:00.177211
elapsed time: 0:00:45.300054
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-10-01 14:49:17.155321
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 146.03
train mean loss: 144.71
epoch train time: 0:00:00.177772
elapsed time: 0:00:45.477980
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-10-01 14:49:17.333213
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 146.53
train mean loss: 147.63
epoch train time: 0:00:00.177445
elapsed time: 0:00:45.655558
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-10-01 14:49:17.510806
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.00
train mean loss: 144.07
epoch train time: 0:00:00.176797
elapsed time: 0:00:45.832515
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-10-01 14:49:17.687762
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 146.44
train mean loss: 145.79
epoch train time: 0:00:00.188570
elapsed time: 0:00:46.021252
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-10-01 14:49:17.876517
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.31
train mean loss: 140.35
epoch train time: 0:00:00.178401
elapsed time: 0:00:46.199810
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-10-01 14:49:18.055044
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.73
train mean loss: 143.11
epoch train time: 0:00:00.177229
elapsed time: 0:00:46.377177
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-10-01 14:49:18.232411
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.48
train mean loss: 143.87
epoch train time: 0:00:00.179000
elapsed time: 0:00:46.556306
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-10-01 14:49:18.411542
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.21
train mean loss: 143.04
epoch train time: 0:00:00.177457
elapsed time: 0:00:46.733880
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-10-01 14:49:18.589109
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.96
train mean loss: 145.33
epoch train time: 0:00:00.178652
elapsed time: 0:00:46.912652
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-10-01 14:49:18.767884
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.30
train mean loss: 142.05
epoch train time: 0:00:00.176081
elapsed time: 0:00:47.088848
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-10-01 14:49:18.944120
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.81
train mean loss: 142.15
epoch train time: 0:00:00.178823
elapsed time: 0:00:47.267834
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-10-01 14:49:19.123068
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.72
train mean loss: 143.46
epoch train time: 0:00:00.176791
elapsed time: 0:00:47.444752
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-10-01 14:49:19.299986
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.80
train mean loss: 144.48
epoch train time: 0:00:00.180583
elapsed time: 0:00:47.625460
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-10-01 14:49:19.480694
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.86
train mean loss: 143.46
epoch train time: 0:00:00.174813
elapsed time: 0:00:47.800389
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-10-01 14:49:19.655634
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.04
train mean loss: 141.33
epoch train time: 0:00:00.177970
elapsed time: 0:00:47.978506
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-10-01 14:49:19.833738
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.82
train mean loss: 142.07
epoch train time: 0:00:00.177766
elapsed time: 0:00:48.156398
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-10-01 14:49:20.011630
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.81
train mean loss: 144.39
epoch train time: 0:00:00.177214
elapsed time: 0:00:48.333730
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-10-01 14:49:20.188961
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.16
train mean loss: 140.73
epoch train time: 0:00:00.178628
elapsed time: 0:00:48.519895
checkpoint saved in file: log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_7/checkpoint.pth.tar
**** end time: 2019-10-01 14:49:20.375116 ****
