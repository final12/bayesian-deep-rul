Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_4', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29813
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:17:44.561519 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:17:44.571654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3912.27
 ---- batch: 020 ----
mean loss: 3566.50
 ---- batch: 030 ----
mean loss: 3404.87
train mean loss: 3577.51
epoch train time: 0:00:13.328676
elapsed time: 0:00:13.345537
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:17:57.907103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3103.62
 ---- batch: 020 ----
mean loss: 2912.66
 ---- batch: 030 ----
mean loss: 2788.18
train mean loss: 2902.98
epoch train time: 0:00:00.597954
elapsed time: 0:00:13.943830
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:17:58.505441
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2601.60
 ---- batch: 020 ----
mean loss: 2490.06
 ---- batch: 030 ----
mean loss: 2405.39
train mean loss: 2472.00
epoch train time: 0:00:00.618668
elapsed time: 0:00:14.562814
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:17:59.124445
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2267.19
 ---- batch: 020 ----
mean loss: 2184.62
 ---- batch: 030 ----
mean loss: 2160.50
train mean loss: 2197.18
epoch train time: 0:00:00.607733
elapsed time: 0:00:15.170912
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:17:59.732529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2054.31
 ---- batch: 020 ----
mean loss: 2011.69
 ---- batch: 030 ----
mean loss: 2055.60
train mean loss: 2029.74
epoch train time: 0:00:00.594449
elapsed time: 0:00:15.765687
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:18:00.327304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1943.15
 ---- batch: 020 ----
mean loss: 1912.17
 ---- batch: 030 ----
mean loss: 1889.40
train mean loss: 1914.58
epoch train time: 0:00:00.589263
elapsed time: 0:00:16.355340
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:18:00.916970
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1867.29
 ---- batch: 020 ----
mean loss: 1811.64
 ---- batch: 030 ----
mean loss: 1788.21
train mean loss: 1818.00
epoch train time: 0:00:00.587552
elapsed time: 0:00:16.943225
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:18:01.504842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1760.30
 ---- batch: 020 ----
mean loss: 1761.68
 ---- batch: 030 ----
mean loss: 1691.30
train mean loss: 1731.38
epoch train time: 0:00:00.600461
elapsed time: 0:00:17.544024
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:18:02.105669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1681.30
 ---- batch: 020 ----
mean loss: 1660.02
 ---- batch: 030 ----
mean loss: 1632.45
train mean loss: 1652.50
epoch train time: 0:00:00.596464
elapsed time: 0:00:18.140884
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:18:02.702503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1617.74
 ---- batch: 020 ----
mean loss: 1578.11
 ---- batch: 030 ----
mean loss: 1560.43
train mean loss: 1577.06
epoch train time: 0:00:00.599367
elapsed time: 0:00:18.740610
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:18:03.302276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1517.23
 ---- batch: 020 ----
mean loss: 1509.75
 ---- batch: 030 ----
mean loss: 1480.55
train mean loss: 1497.90
epoch train time: 0:00:00.599267
elapsed time: 0:00:19.340297
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:18:03.901918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1456.55
 ---- batch: 020 ----
mean loss: 1450.77
 ---- batch: 030 ----
mean loss: 1388.34
train mean loss: 1431.23
epoch train time: 0:00:00.601984
elapsed time: 0:00:19.942610
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:18:04.504229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1396.41
 ---- batch: 020 ----
mean loss: 1347.20
 ---- batch: 030 ----
mean loss: 1360.59
train mean loss: 1360.83
epoch train time: 0:00:00.601273
elapsed time: 0:00:20.544237
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:18:05.105861
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1351.83
 ---- batch: 020 ----
mean loss: 1298.62
 ---- batch: 030 ----
mean loss: 1261.22
train mean loss: 1293.84
epoch train time: 0:00:00.609323
elapsed time: 0:00:21.153964
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:18:05.715597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1244.29
 ---- batch: 020 ----
mean loss: 1235.75
 ---- batch: 030 ----
mean loss: 1212.01
train mean loss: 1228.15
epoch train time: 0:00:00.600538
elapsed time: 0:00:21.754864
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:18:06.316490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1184.15
 ---- batch: 020 ----
mean loss: 1163.93
 ---- batch: 030 ----
mean loss: 1155.81
train mean loss: 1163.33
epoch train time: 0:00:00.588961
elapsed time: 0:00:22.344168
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:18:06.905797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1124.67
 ---- batch: 020 ----
mean loss: 1120.01
 ---- batch: 030 ----
mean loss: 1096.38
train mean loss: 1109.36
epoch train time: 0:00:00.600536
elapsed time: 0:00:22.945071
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:18:07.506706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1080.40
 ---- batch: 020 ----
mean loss: 1068.67
 ---- batch: 030 ----
mean loss: 1031.34
train mean loss: 1061.16
epoch train time: 0:00:00.618159
elapsed time: 0:00:23.563902
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:18:08.125535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1033.04
 ---- batch: 020 ----
mean loss: 1002.00
 ---- batch: 030 ----
mean loss: 993.49
train mean loss: 1005.78
epoch train time: 0:00:00.611837
elapsed time: 0:00:24.176133
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:18:08.737755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 985.55
 ---- batch: 020 ----
mean loss: 964.70
 ---- batch: 030 ----
mean loss: 951.27
train mean loss: 959.29
epoch train time: 0:00:00.585459
elapsed time: 0:00:24.761914
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:18:09.323566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 918.12
 ---- batch: 020 ----
mean loss: 918.88
 ---- batch: 030 ----
mean loss: 897.72
train mean loss: 914.43
epoch train time: 0:00:00.591121
elapsed time: 0:00:25.353438
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:18:09.915066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 879.26
 ---- batch: 020 ----
mean loss: 898.16
 ---- batch: 030 ----
mean loss: 865.63
train mean loss: 872.89
epoch train time: 0:00:00.584592
elapsed time: 0:00:25.938395
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:18:10.500011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 853.57
 ---- batch: 020 ----
mean loss: 836.53
 ---- batch: 030 ----
mean loss: 820.56
train mean loss: 831.45
epoch train time: 0:00:00.589814
elapsed time: 0:00:26.528578
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:18:11.090190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 795.78
 ---- batch: 020 ----
mean loss: 793.90
 ---- batch: 030 ----
mean loss: 790.84
train mean loss: 788.27
epoch train time: 0:00:00.586628
elapsed time: 0:00:27.115547
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:18:11.677181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 771.67
 ---- batch: 020 ----
mean loss: 759.81
 ---- batch: 030 ----
mean loss: 733.82
train mean loss: 749.47
epoch train time: 0:00:00.610925
elapsed time: 0:00:27.726816
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:18:12.288439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 720.13
 ---- batch: 020 ----
mean loss: 733.12
 ---- batch: 030 ----
mean loss: 718.14
train mean loss: 718.51
epoch train time: 0:00:00.587135
elapsed time: 0:00:28.314287
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:18:12.875902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 705.14
 ---- batch: 020 ----
mean loss: 685.64
 ---- batch: 030 ----
mean loss: 663.81
train mean loss: 686.59
epoch train time: 0:00:00.590582
elapsed time: 0:00:28.905218
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:18:13.466836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 663.76
 ---- batch: 020 ----
mean loss: 661.93
 ---- batch: 030 ----
mean loss: 634.72
train mean loss: 650.23
epoch train time: 0:00:00.600110
elapsed time: 0:00:29.505697
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:18:14.067358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 622.02
 ---- batch: 020 ----
mean loss: 637.65
 ---- batch: 030 ----
mean loss: 607.37
train mean loss: 618.93
epoch train time: 0:00:00.592532
elapsed time: 0:00:30.098601
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:18:14.660218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 595.97
 ---- batch: 020 ----
mean loss: 592.91
 ---- batch: 030 ----
mean loss: 583.03
train mean loss: 591.28
epoch train time: 0:00:00.588152
elapsed time: 0:00:30.687083
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:18:15.248733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 576.27
 ---- batch: 020 ----
mean loss: 554.85
 ---- batch: 030 ----
mean loss: 575.30
train mean loss: 566.12
epoch train time: 0:00:00.601741
elapsed time: 0:00:31.289239
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:18:15.850854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 551.20
 ---- batch: 020 ----
mean loss: 543.18
 ---- batch: 030 ----
mean loss: 537.36
train mean loss: 541.30
epoch train time: 0:00:00.596451
elapsed time: 0:00:31.886060
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:18:16.447677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 534.40
 ---- batch: 020 ----
mean loss: 515.36
 ---- batch: 030 ----
mean loss: 500.32
train mean loss: 517.75
epoch train time: 0:00:00.611099
elapsed time: 0:00:32.497559
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:18:17.059208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 502.81
 ---- batch: 020 ----
mean loss: 504.39
 ---- batch: 030 ----
mean loss: 481.67
train mean loss: 492.81
epoch train time: 0:00:00.598851
elapsed time: 0:00:33.096786
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:18:17.658403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 475.66
 ---- batch: 020 ----
mean loss: 482.65
 ---- batch: 030 ----
mean loss: 466.58
train mean loss: 472.68
epoch train time: 0:00:00.598836
elapsed time: 0:00:33.696119
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:18:18.257789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 453.46
 ---- batch: 020 ----
mean loss: 442.80
 ---- batch: 030 ----
mean loss: 456.26
train mean loss: 448.65
epoch train time: 0:00:00.590514
elapsed time: 0:00:34.287026
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:18:18.848643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 436.55
 ---- batch: 020 ----
mean loss: 435.08
 ---- batch: 030 ----
mean loss: 427.69
train mean loss: 431.15
epoch train time: 0:00:00.605831
elapsed time: 0:00:34.893252
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:18:19.454879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.69
 ---- batch: 020 ----
mean loss: 413.21
 ---- batch: 030 ----
mean loss: 410.76
train mean loss: 413.35
epoch train time: 0:00:00.600225
elapsed time: 0:00:35.493887
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:18:20.055513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 411.30
 ---- batch: 020 ----
mean loss: 397.21
 ---- batch: 030 ----
mean loss: 391.12
train mean loss: 396.84
epoch train time: 0:00:00.588930
elapsed time: 0:00:36.083162
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:18:20.644780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 382.58
 ---- batch: 020 ----
mean loss: 374.57
 ---- batch: 030 ----
mean loss: 375.37
train mean loss: 378.06
epoch train time: 0:00:00.597129
elapsed time: 0:00:36.680663
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:18:21.242283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.79
 ---- batch: 020 ----
mean loss: 351.90
 ---- batch: 030 ----
mean loss: 362.53
train mean loss: 363.17
epoch train time: 0:00:00.602033
elapsed time: 0:00:37.283026
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:18:21.844643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 352.44
 ---- batch: 020 ----
mean loss: 341.28
 ---- batch: 030 ----
mean loss: 352.20
train mean loss: 347.37
epoch train time: 0:00:00.598542
elapsed time: 0:00:37.881980
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:18:22.443631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 346.06
 ---- batch: 020 ----
mean loss: 336.04
 ---- batch: 030 ----
mean loss: 316.80
train mean loss: 333.04
epoch train time: 0:00:00.602814
elapsed time: 0:00:38.485221
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:18:23.046855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.13
 ---- batch: 020 ----
mean loss: 323.32
 ---- batch: 030 ----
mean loss: 314.65
train mean loss: 319.86
epoch train time: 0:00:00.593690
elapsed time: 0:00:39.079248
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:18:23.640883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 304.05
 ---- batch: 020 ----
mean loss: 306.34
 ---- batch: 030 ----
mean loss: 304.07
train mean loss: 304.32
epoch train time: 0:00:00.595371
elapsed time: 0:00:39.675027
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:18:24.236653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.47
 ---- batch: 020 ----
mean loss: 285.06
 ---- batch: 030 ----
mean loss: 291.39
train mean loss: 292.75
epoch train time: 0:00:00.601859
elapsed time: 0:00:40.277266
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:18:24.838882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.95
 ---- batch: 020 ----
mean loss: 287.45
 ---- batch: 030 ----
mean loss: 277.15
train mean loss: 279.23
epoch train time: 0:00:00.591613
elapsed time: 0:00:40.869254
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:18:25.430907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.79
 ---- batch: 020 ----
mean loss: 271.12
 ---- batch: 030 ----
mean loss: 273.58
train mean loss: 270.07
epoch train time: 0:00:00.588582
elapsed time: 0:00:41.458227
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:18:26.019848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.30
 ---- batch: 020 ----
mean loss: 256.76
 ---- batch: 030 ----
mean loss: 258.46
train mean loss: 261.41
epoch train time: 0:00:00.603218
elapsed time: 0:00:42.061811
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:18:26.623433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.16
 ---- batch: 020 ----
mean loss: 252.61
 ---- batch: 030 ----
mean loss: 249.48
train mean loss: 251.64
epoch train time: 0:00:00.609285
elapsed time: 0:00:42.671422
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:18:27.233046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.11
 ---- batch: 020 ----
mean loss: 243.46
 ---- batch: 030 ----
mean loss: 244.97
train mean loss: 243.87
epoch train time: 0:00:00.606543
elapsed time: 0:00:43.278317
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:18:27.839951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.69
 ---- batch: 020 ----
mean loss: 235.33
 ---- batch: 030 ----
mean loss: 228.22
train mean loss: 234.22
epoch train time: 0:00:00.590148
elapsed time: 0:00:43.868984
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:18:28.430666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.26
 ---- batch: 020 ----
mean loss: 224.28
 ---- batch: 030 ----
mean loss: 221.61
train mean loss: 224.54
epoch train time: 0:00:00.607238
elapsed time: 0:00:44.476718
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:18:29.038343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.79
 ---- batch: 020 ----
mean loss: 221.52
 ---- batch: 030 ----
mean loss: 213.63
train mean loss: 217.82
epoch train time: 0:00:00.599480
elapsed time: 0:00:45.076577
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:18:29.638200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.33
 ---- batch: 020 ----
mean loss: 208.50
 ---- batch: 030 ----
mean loss: 209.63
train mean loss: 209.09
epoch train time: 0:00:00.611548
elapsed time: 0:00:45.688478
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:18:30.250108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.27
 ---- batch: 020 ----
mean loss: 201.95
 ---- batch: 030 ----
mean loss: 199.05
train mean loss: 203.88
epoch train time: 0:00:00.597407
elapsed time: 0:00:46.286242
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:18:30.847862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 201.28
 ---- batch: 020 ----
mean loss: 205.59
 ---- batch: 030 ----
mean loss: 196.89
train mean loss: 199.90
epoch train time: 0:00:00.608953
elapsed time: 0:00:46.895591
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:18:31.457234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.99
 ---- batch: 020 ----
mean loss: 191.79
 ---- batch: 030 ----
mean loss: 193.69
train mean loss: 192.43
epoch train time: 0:00:00.614191
elapsed time: 0:00:47.510185
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:18:32.071812
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.48
 ---- batch: 020 ----
mean loss: 183.22
 ---- batch: 030 ----
mean loss: 185.57
train mean loss: 184.01
epoch train time: 0:00:00.618089
elapsed time: 0:00:48.128646
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:18:32.690275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.71
 ---- batch: 020 ----
mean loss: 178.47
 ---- batch: 030 ----
mean loss: 180.57
train mean loss: 180.93
epoch train time: 0:00:00.606519
elapsed time: 0:00:48.735567
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:18:33.297235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.68
 ---- batch: 020 ----
mean loss: 174.97
 ---- batch: 030 ----
mean loss: 175.48
train mean loss: 174.66
epoch train time: 0:00:00.621490
elapsed time: 0:00:49.357523
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:18:33.919177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.69
 ---- batch: 020 ----
mean loss: 171.37
 ---- batch: 030 ----
mean loss: 177.10
train mean loss: 172.56
epoch train time: 0:00:00.596298
elapsed time: 0:00:49.954216
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:18:34.515856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.67
 ---- batch: 020 ----
mean loss: 163.77
 ---- batch: 030 ----
mean loss: 165.00
train mean loss: 166.74
epoch train time: 0:00:00.612035
elapsed time: 0:00:50.566641
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:18:35.128266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.99
 ---- batch: 020 ----
mean loss: 167.45
 ---- batch: 030 ----
mean loss: 161.91
train mean loss: 163.74
epoch train time: 0:00:00.605032
elapsed time: 0:00:51.172026
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:18:35.733715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.84
 ---- batch: 020 ----
mean loss: 156.97
 ---- batch: 030 ----
mean loss: 158.98
train mean loss: 159.15
epoch train time: 0:00:00.604639
elapsed time: 0:00:51.777108
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:18:36.338729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.62
 ---- batch: 020 ----
mean loss: 152.97
 ---- batch: 030 ----
mean loss: 153.48
train mean loss: 153.32
epoch train time: 0:00:00.616369
elapsed time: 0:00:52.393879
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:18:36.955519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.71
 ---- batch: 020 ----
mean loss: 150.81
 ---- batch: 030 ----
mean loss: 149.91
train mean loss: 150.44
epoch train time: 0:00:00.592203
elapsed time: 0:00:52.986477
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:18:37.548133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.63
 ---- batch: 020 ----
mean loss: 145.60
 ---- batch: 030 ----
mean loss: 149.42
train mean loss: 147.30
epoch train time: 0:00:00.589823
elapsed time: 0:00:53.576677
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:18:38.138301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.65
 ---- batch: 020 ----
mean loss: 143.52
 ---- batch: 030 ----
mean loss: 143.04
train mean loss: 145.23
epoch train time: 0:00:00.599573
elapsed time: 0:00:54.176651
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:18:38.738284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.80
 ---- batch: 020 ----
mean loss: 141.78
 ---- batch: 030 ----
mean loss: 142.13
train mean loss: 142.80
epoch train time: 0:00:00.615837
elapsed time: 0:00:54.792890
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:18:39.354514
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.57
 ---- batch: 020 ----
mean loss: 139.45
 ---- batch: 030 ----
mean loss: 137.59
train mean loss: 137.11
epoch train time: 0:00:00.608312
elapsed time: 0:00:55.401559
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:18:39.963214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.28
 ---- batch: 020 ----
mean loss: 132.79
 ---- batch: 030 ----
mean loss: 136.35
train mean loss: 135.50
epoch train time: 0:00:00.596208
elapsed time: 0:00:55.998147
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:18:40.559772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.75
 ---- batch: 020 ----
mean loss: 130.92
 ---- batch: 030 ----
mean loss: 133.81
train mean loss: 131.79
epoch train time: 0:00:00.613349
elapsed time: 0:00:56.611874
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:18:41.173505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.51
 ---- batch: 020 ----
mean loss: 131.04
 ---- batch: 030 ----
mean loss: 129.53
train mean loss: 131.42
epoch train time: 0:00:00.621006
elapsed time: 0:00:57.233334
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:18:41.794955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.28
 ---- batch: 020 ----
mean loss: 127.75
 ---- batch: 030 ----
mean loss: 126.18
train mean loss: 127.79
epoch train time: 0:00:00.611550
elapsed time: 0:00:57.845234
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:18:42.406876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.66
 ---- batch: 020 ----
mean loss: 125.75
 ---- batch: 030 ----
mean loss: 128.43
train mean loss: 127.18
epoch train time: 0:00:00.606973
elapsed time: 0:00:58.452644
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:18:43.014300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.69
 ---- batch: 020 ----
mean loss: 121.24
 ---- batch: 030 ----
mean loss: 118.53
train mean loss: 121.82
epoch train time: 0:00:00.610126
elapsed time: 0:00:59.063182
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:18:43.624815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.84
 ---- batch: 020 ----
mean loss: 117.62
 ---- batch: 030 ----
mean loss: 124.33
train mean loss: 121.01
epoch train time: 0:00:00.626974
elapsed time: 0:00:59.690589
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:18:44.252221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.91
 ---- batch: 020 ----
mean loss: 119.33
 ---- batch: 030 ----
mean loss: 123.69
train mean loss: 119.43
epoch train time: 0:00:00.603318
elapsed time: 0:01:00.294299
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:18:44.855972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.90
 ---- batch: 020 ----
mean loss: 119.86
 ---- batch: 030 ----
mean loss: 117.31
train mean loss: 116.88
epoch train time: 0:00:00.616911
elapsed time: 0:01:00.911669
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:18:45.473299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.30
 ---- batch: 020 ----
mean loss: 116.15
 ---- batch: 030 ----
mean loss: 114.76
train mean loss: 116.77
epoch train time: 0:00:00.603828
elapsed time: 0:01:01.515883
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:18:46.077519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.16
 ---- batch: 020 ----
mean loss: 114.19
 ---- batch: 030 ----
mean loss: 112.63
train mean loss: 112.89
epoch train time: 0:00:00.602310
elapsed time: 0:01:02.118584
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:18:46.680209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.86
 ---- batch: 020 ----
mean loss: 116.42
 ---- batch: 030 ----
mean loss: 110.13
train mean loss: 113.16
epoch train time: 0:00:00.609145
elapsed time: 0:01:02.728183
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:18:47.289890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.57
 ---- batch: 020 ----
mean loss: 108.99
 ---- batch: 030 ----
mean loss: 108.43
train mean loss: 109.40
epoch train time: 0:00:00.606266
elapsed time: 0:01:03.334905
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:18:47.896545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.81
 ---- batch: 020 ----
mean loss: 110.78
 ---- batch: 030 ----
mean loss: 111.22
train mean loss: 109.07
epoch train time: 0:00:00.603208
elapsed time: 0:01:03.938493
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:18:48.500116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.84
 ---- batch: 020 ----
mean loss: 111.48
 ---- batch: 030 ----
mean loss: 104.90
train mean loss: 106.78
epoch train time: 0:00:00.624319
elapsed time: 0:01:04.563203
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:18:49.124830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.78
 ---- batch: 020 ----
mean loss: 105.26
 ---- batch: 030 ----
mean loss: 109.20
train mean loss: 106.56
epoch train time: 0:00:00.614024
elapsed time: 0:01:05.177615
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:18:49.739236
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.10
 ---- batch: 020 ----
mean loss: 107.71
 ---- batch: 030 ----
mean loss: 100.98
train mean loss: 104.86
epoch train time: 0:00:00.606774
elapsed time: 0:01:05.784769
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:18:50.346419
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.73
 ---- batch: 020 ----
mean loss: 101.56
 ---- batch: 030 ----
mean loss: 103.41
train mean loss: 102.70
epoch train time: 0:00:00.602461
elapsed time: 0:01:06.387666
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:18:50.949284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.69
 ---- batch: 020 ----
mean loss: 97.90
 ---- batch: 030 ----
mean loss: 103.68
train mean loss: 100.86
epoch train time: 0:00:00.593254
elapsed time: 0:01:06.981285
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:18:51.542905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.01
 ---- batch: 020 ----
mean loss: 100.77
 ---- batch: 030 ----
mean loss: 101.81
train mean loss: 100.94
epoch train time: 0:00:00.620011
elapsed time: 0:01:07.601639
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:18:52.163256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.23
 ---- batch: 020 ----
mean loss: 98.47
 ---- batch: 030 ----
mean loss: 98.98
train mean loss: 98.40
epoch train time: 0:00:00.609778
elapsed time: 0:01:08.211771
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:18:52.773400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.49
 ---- batch: 020 ----
mean loss: 97.53
 ---- batch: 030 ----
mean loss: 96.28
train mean loss: 98.59
epoch train time: 0:00:00.607342
elapsed time: 0:01:08.819633
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:18:53.381279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.27
 ---- batch: 020 ----
mean loss: 97.58
 ---- batch: 030 ----
mean loss: 96.14
train mean loss: 96.00
epoch train time: 0:00:00.603627
elapsed time: 0:01:09.423690
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:18:53.985311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.88
 ---- batch: 020 ----
mean loss: 95.96
 ---- batch: 030 ----
mean loss: 96.90
train mean loss: 97.03
epoch train time: 0:00:00.604342
elapsed time: 0:01:10.028484
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:18:54.590124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.76
 ---- batch: 020 ----
mean loss: 89.86
 ---- batch: 030 ----
mean loss: 97.73
train mean loss: 94.75
epoch train time: 0:00:00.628749
elapsed time: 0:01:10.657615
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:18:55.219238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.63
 ---- batch: 020 ----
mean loss: 94.70
 ---- batch: 030 ----
mean loss: 94.12
train mean loss: 93.26
epoch train time: 0:00:00.614055
elapsed time: 0:01:11.272158
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:18:55.833806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.93
 ---- batch: 020 ----
mean loss: 95.95
 ---- batch: 030 ----
mean loss: 92.70
train mean loss: 93.94
epoch train time: 0:00:00.608762
elapsed time: 0:01:11.881402
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:18:56.443056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.43
 ---- batch: 020 ----
mean loss: 92.70
 ---- batch: 030 ----
mean loss: 90.46
train mean loss: 92.72
epoch train time: 0:00:00.601929
elapsed time: 0:01:12.483770
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:18:57.045417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.64
 ---- batch: 020 ----
mean loss: 92.52
 ---- batch: 030 ----
mean loss: 88.07
train mean loss: 90.75
epoch train time: 0:00:00.599119
elapsed time: 0:01:13.083343
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:18:57.644974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.49
 ---- batch: 020 ----
mean loss: 90.71
 ---- batch: 030 ----
mean loss: 87.21
train mean loss: 90.66
epoch train time: 0:00:00.597158
elapsed time: 0:01:13.680944
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:18:58.242563
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.12
 ---- batch: 020 ----
mean loss: 86.67
 ---- batch: 030 ----
mean loss: 89.41
train mean loss: 89.17
epoch train time: 0:00:00.594289
elapsed time: 0:01:14.275595
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:18:58.837219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.73
 ---- batch: 020 ----
mean loss: 91.41
 ---- batch: 030 ----
mean loss: 86.37
train mean loss: 88.91
epoch train time: 0:00:00.586181
elapsed time: 0:01:14.862130
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:18:59.423768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.61
 ---- batch: 020 ----
mean loss: 89.35
 ---- batch: 030 ----
mean loss: 85.32
train mean loss: 87.51
epoch train time: 0:00:00.608117
elapsed time: 0:01:15.470630
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:19:00.032255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.87
 ---- batch: 020 ----
mean loss: 86.33
 ---- batch: 030 ----
mean loss: 84.92
train mean loss: 87.40
epoch train time: 0:00:00.603362
elapsed time: 0:01:16.074327
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:19:00.635950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.85
 ---- batch: 020 ----
mean loss: 85.38
 ---- batch: 030 ----
mean loss: 86.49
train mean loss: 85.41
epoch train time: 0:00:00.592416
elapsed time: 0:01:16.667083
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:19:01.228707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.28
 ---- batch: 020 ----
mean loss: 85.11
 ---- batch: 030 ----
mean loss: 83.91
train mean loss: 85.54
epoch train time: 0:00:00.590584
elapsed time: 0:01:17.258153
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:19:01.819718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.85
 ---- batch: 020 ----
mean loss: 84.39
 ---- batch: 030 ----
mean loss: 85.68
train mean loss: 83.56
epoch train time: 0:00:00.593843
elapsed time: 0:01:17.852382
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:19:02.414042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.38
 ---- batch: 020 ----
mean loss: 84.39
 ---- batch: 030 ----
mean loss: 79.69
train mean loss: 83.21
epoch train time: 0:00:00.603512
elapsed time: 0:01:18.456328
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:19:03.017990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.78
 ---- batch: 020 ----
mean loss: 83.01
 ---- batch: 030 ----
mean loss: 82.75
train mean loss: 83.07
epoch train time: 0:00:00.607036
elapsed time: 0:01:19.063756
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:19:03.625391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.06
 ---- batch: 020 ----
mean loss: 82.40
 ---- batch: 030 ----
mean loss: 84.80
train mean loss: 82.77
epoch train time: 0:00:00.620590
elapsed time: 0:01:19.684727
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:19:04.246369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.91
 ---- batch: 020 ----
mean loss: 82.14
 ---- batch: 030 ----
mean loss: 79.68
train mean loss: 81.73
epoch train time: 0:00:00.605750
elapsed time: 0:01:20.290861
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:19:04.852485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.54
 ---- batch: 020 ----
mean loss: 79.58
 ---- batch: 030 ----
mean loss: 79.66
train mean loss: 79.90
epoch train time: 0:00:00.590218
elapsed time: 0:01:20.881406
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:19:05.443017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.20
 ---- batch: 020 ----
mean loss: 78.58
 ---- batch: 030 ----
mean loss: 81.76
train mean loss: 80.51
epoch train time: 0:00:00.607012
elapsed time: 0:01:21.488764
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:19:06.050388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.65
 ---- batch: 020 ----
mean loss: 78.28
 ---- batch: 030 ----
mean loss: 80.27
train mean loss: 79.13
epoch train time: 0:00:00.610995
elapsed time: 0:01:22.100126
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:19:06.661754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.89
 ---- batch: 020 ----
mean loss: 79.84
 ---- batch: 030 ----
mean loss: 80.21
train mean loss: 79.38
epoch train time: 0:00:00.615689
elapsed time: 0:01:22.716208
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:19:07.277833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.33
 ---- batch: 020 ----
mean loss: 79.32
 ---- batch: 030 ----
mean loss: 79.05
train mean loss: 78.42
epoch train time: 0:00:00.603607
elapsed time: 0:01:23.320194
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:19:07.881814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.35
 ---- batch: 020 ----
mean loss: 78.54
 ---- batch: 030 ----
mean loss: 80.57
train mean loss: 78.55
epoch train time: 0:00:00.592779
elapsed time: 0:01:23.913291
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:19:08.474912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.81
 ---- batch: 020 ----
mean loss: 78.46
 ---- batch: 030 ----
mean loss: 78.35
train mean loss: 78.13
epoch train time: 0:00:00.603587
elapsed time: 0:01:24.517260
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:19:09.078885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.94
 ---- batch: 020 ----
mean loss: 75.95
 ---- batch: 030 ----
mean loss: 76.73
train mean loss: 76.56
epoch train time: 0:00:00.607914
elapsed time: 0:01:25.125569
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:19:09.687190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.84
 ---- batch: 020 ----
mean loss: 75.97
 ---- batch: 030 ----
mean loss: 72.89
train mean loss: 75.35
epoch train time: 0:00:00.616834
elapsed time: 0:01:25.742746
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:19:10.304369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.81
 ---- batch: 020 ----
mean loss: 75.65
 ---- batch: 030 ----
mean loss: 76.50
train mean loss: 74.89
epoch train time: 0:00:00.608081
elapsed time: 0:01:26.351215
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:19:10.912844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.83
 ---- batch: 020 ----
mean loss: 75.21
 ---- batch: 030 ----
mean loss: 72.96
train mean loss: 74.44
epoch train time: 0:00:00.619449
elapsed time: 0:01:26.971043
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:19:11.532696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.17
 ---- batch: 020 ----
mean loss: 72.11
 ---- batch: 030 ----
mean loss: 73.63
train mean loss: 73.07
epoch train time: 0:00:00.615773
elapsed time: 0:01:27.587449
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:19:12.149096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.05
 ---- batch: 020 ----
mean loss: 72.54
 ---- batch: 030 ----
mean loss: 73.79
train mean loss: 72.98
epoch train time: 0:00:00.607666
elapsed time: 0:01:28.195532
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:19:12.757186
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.19
 ---- batch: 020 ----
mean loss: 71.90
 ---- batch: 030 ----
mean loss: 74.25
train mean loss: 73.93
epoch train time: 0:00:00.608339
elapsed time: 0:01:28.804263
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:19:13.365900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.82
 ---- batch: 020 ----
mean loss: 71.08
 ---- batch: 030 ----
mean loss: 72.03
train mean loss: 71.47
epoch train time: 0:00:00.597042
elapsed time: 0:01:29.401734
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:19:13.963313
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.89
 ---- batch: 020 ----
mean loss: 71.93
 ---- batch: 030 ----
mean loss: 71.72
train mean loss: 71.18
epoch train time: 0:00:00.600739
elapsed time: 0:01:30.002772
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:19:14.564401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.44
 ---- batch: 020 ----
mean loss: 69.71
 ---- batch: 030 ----
mean loss: 70.14
train mean loss: 70.72
epoch train time: 0:00:00.611256
elapsed time: 0:01:30.614382
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:19:15.176019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.02
 ---- batch: 020 ----
mean loss: 74.44
 ---- batch: 030 ----
mean loss: 69.97
train mean loss: 70.63
epoch train time: 0:00:00.603696
elapsed time: 0:01:31.218577
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:19:15.780204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.95
 ---- batch: 020 ----
mean loss: 69.73
 ---- batch: 030 ----
mean loss: 68.45
train mean loss: 69.36
epoch train time: 0:00:00.595689
elapsed time: 0:01:31.814597
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:19:16.376220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.52
 ---- batch: 020 ----
mean loss: 67.07
 ---- batch: 030 ----
mean loss: 68.20
train mean loss: 68.00
epoch train time: 0:00:00.609292
elapsed time: 0:01:32.424281
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:19:16.985922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.14
 ---- batch: 020 ----
mean loss: 69.63
 ---- batch: 030 ----
mean loss: 66.17
train mean loss: 68.39
epoch train time: 0:00:00.586273
elapsed time: 0:01:33.010909
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:19:17.572537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.56
 ---- batch: 020 ----
mean loss: 67.93
 ---- batch: 030 ----
mean loss: 69.51
train mean loss: 68.34
epoch train time: 0:00:00.620425
elapsed time: 0:01:33.631753
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:19:18.193367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.35
 ---- batch: 020 ----
mean loss: 67.86
 ---- batch: 030 ----
mean loss: 66.89
train mean loss: 67.46
epoch train time: 0:00:00.598405
elapsed time: 0:01:34.230527
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:19:18.792152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.98
 ---- batch: 020 ----
mean loss: 66.20
 ---- batch: 030 ----
mean loss: 69.13
train mean loss: 67.84
epoch train time: 0:00:00.600883
elapsed time: 0:01:34.831785
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:19:19.393404
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.81
 ---- batch: 020 ----
mean loss: 66.68
 ---- batch: 030 ----
mean loss: 64.20
train mean loss: 66.47
epoch train time: 0:00:00.602032
elapsed time: 0:01:35.434149
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:19:19.995766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.42
 ---- batch: 020 ----
mean loss: 68.43
 ---- batch: 030 ----
mean loss: 64.78
train mean loss: 67.06
epoch train time: 0:00:00.587457
elapsed time: 0:01:36.021943
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:19:20.583564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.68
 ---- batch: 020 ----
mean loss: 67.54
 ---- batch: 030 ----
mean loss: 65.63
train mean loss: 66.20
epoch train time: 0:00:00.606334
elapsed time: 0:01:36.628648
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:19:21.190297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.96
 ---- batch: 020 ----
mean loss: 66.20
 ---- batch: 030 ----
mean loss: 63.65
train mean loss: 64.20
epoch train time: 0:00:00.597583
elapsed time: 0:01:37.226590
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:19:21.788206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.98
 ---- batch: 020 ----
mean loss: 62.65
 ---- batch: 030 ----
mean loss: 67.04
train mean loss: 64.09
epoch train time: 0:00:00.600957
elapsed time: 0:01:37.827896
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:19:22.389516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.69
 ---- batch: 020 ----
mean loss: 63.04
 ---- batch: 030 ----
mean loss: 63.59
train mean loss: 63.95
epoch train time: 0:00:00.599082
elapsed time: 0:01:38.427352
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:19:22.988971
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.58
 ---- batch: 020 ----
mean loss: 62.70
 ---- batch: 030 ----
mean loss: 66.51
train mean loss: 63.07
epoch train time: 0:00:00.614425
elapsed time: 0:01:39.042152
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:19:23.603772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.52
 ---- batch: 020 ----
mean loss: 61.41
 ---- batch: 030 ----
mean loss: 63.53
train mean loss: 62.48
epoch train time: 0:00:00.625357
elapsed time: 0:01:39.667905
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:19:24.229529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.68
 ---- batch: 020 ----
mean loss: 61.33
 ---- batch: 030 ----
mean loss: 60.65
train mean loss: 61.66
epoch train time: 0:00:00.631942
elapsed time: 0:01:40.300291
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:19:24.861965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.83
 ---- batch: 020 ----
mean loss: 62.01
 ---- batch: 030 ----
mean loss: 59.59
train mean loss: 61.38
epoch train time: 0:00:00.626227
elapsed time: 0:01:40.926972
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:19:25.488591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.75
 ---- batch: 020 ----
mean loss: 63.33
 ---- batch: 030 ----
mean loss: 58.67
train mean loss: 59.94
epoch train time: 0:00:00.615638
elapsed time: 0:01:41.542984
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:19:26.104615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.25
 ---- batch: 020 ----
mean loss: 59.85
 ---- batch: 030 ----
mean loss: 60.37
train mean loss: 59.69
epoch train time: 0:00:00.615977
elapsed time: 0:01:42.159400
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:19:26.721039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.43
 ---- batch: 020 ----
mean loss: 59.43
 ---- batch: 030 ----
mean loss: 57.56
train mean loss: 59.51
epoch train time: 0:00:00.629753
elapsed time: 0:01:42.789598
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:19:27.351162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.40
 ---- batch: 020 ----
mean loss: 58.68
 ---- batch: 030 ----
mean loss: 58.88
train mean loss: 59.41
epoch train time: 0:00:00.628715
elapsed time: 0:01:43.418730
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:19:27.980347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.07
 ---- batch: 020 ----
mean loss: 58.56
 ---- batch: 030 ----
mean loss: 57.73
train mean loss: 58.16
epoch train time: 0:00:00.622044
elapsed time: 0:01:44.041147
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:19:28.602772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.28
 ---- batch: 020 ----
mean loss: 56.38
 ---- batch: 030 ----
mean loss: 62.29
train mean loss: 57.97
epoch train time: 0:00:00.607853
elapsed time: 0:01:44.649367
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:19:29.211035
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.27
 ---- batch: 020 ----
mean loss: 60.29
 ---- batch: 030 ----
mean loss: 55.37
train mean loss: 57.69
epoch train time: 0:00:00.626115
elapsed time: 0:01:45.275890
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:19:29.837521
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.08
 ---- batch: 020 ----
mean loss: 57.23
 ---- batch: 030 ----
mean loss: 58.16
train mean loss: 56.70
epoch train time: 0:00:00.613269
elapsed time: 0:01:45.889546
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:19:30.451166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.23
 ---- batch: 020 ----
mean loss: 58.20
 ---- batch: 030 ----
mean loss: 54.88
train mean loss: 56.48
epoch train time: 0:00:00.620386
elapsed time: 0:01:46.510320
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:19:31.071962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.26
 ---- batch: 020 ----
mean loss: 55.46
 ---- batch: 030 ----
mean loss: 57.72
train mean loss: 54.97
epoch train time: 0:00:00.616911
elapsed time: 0:01:47.127637
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:19:31.689266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.51
 ---- batch: 020 ----
mean loss: 54.84
 ---- batch: 030 ----
mean loss: 55.73
train mean loss: 55.24
epoch train time: 0:00:00.632306
elapsed time: 0:01:47.760392
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:19:32.322029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.29
 ---- batch: 020 ----
mean loss: 54.39
 ---- batch: 030 ----
mean loss: 55.63
train mean loss: 54.94
epoch train time: 0:00:00.621730
elapsed time: 0:01:48.382535
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:19:32.944166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.70
 ---- batch: 020 ----
mean loss: 56.17
 ---- batch: 030 ----
mean loss: 52.94
train mean loss: 54.25
epoch train time: 0:00:00.599765
elapsed time: 0:01:48.982649
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:19:33.544273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.56
 ---- batch: 020 ----
mean loss: 52.65
 ---- batch: 030 ----
mean loss: 51.47
train mean loss: 53.57
epoch train time: 0:00:00.612278
elapsed time: 0:01:49.595259
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:19:34.156883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.98
 ---- batch: 020 ----
mean loss: 52.97
 ---- batch: 030 ----
mean loss: 56.08
train mean loss: 54.13
epoch train time: 0:00:00.612059
elapsed time: 0:01:50.207743
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:19:34.769368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.50
 ---- batch: 020 ----
mean loss: 51.69
 ---- batch: 030 ----
mean loss: 50.20
train mean loss: 52.37
epoch train time: 0:00:00.591235
elapsed time: 0:01:50.799376
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:19:35.361006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.19
 ---- batch: 020 ----
mean loss: 52.55
 ---- batch: 030 ----
mean loss: 54.81
train mean loss: 52.85
epoch train time: 0:00:00.584806
elapsed time: 0:01:51.384580
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:19:35.946203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.18
 ---- batch: 020 ----
mean loss: 51.69
 ---- batch: 030 ----
mean loss: 49.95
train mean loss: 51.86
epoch train time: 0:00:00.592199
elapsed time: 0:01:51.977151
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:19:36.538772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.67
 ---- batch: 020 ----
mean loss: 49.56
 ---- batch: 030 ----
mean loss: 52.72
train mean loss: 51.11
epoch train time: 0:00:00.602852
elapsed time: 0:01:52.580350
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:19:37.141994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.46
 ---- batch: 020 ----
mean loss: 48.35
 ---- batch: 030 ----
mean loss: 52.11
train mean loss: 51.04
epoch train time: 0:00:00.618331
elapsed time: 0:01:53.199029
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:19:37.760694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.51
 ---- batch: 020 ----
mean loss: 49.52
 ---- batch: 030 ----
mean loss: 50.98
train mean loss: 51.04
epoch train time: 0:00:00.600163
elapsed time: 0:01:53.799558
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:19:38.361178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.55
 ---- batch: 020 ----
mean loss: 48.88
 ---- batch: 030 ----
mean loss: 50.42
train mean loss: 50.70
epoch train time: 0:00:00.621141
elapsed time: 0:01:54.421033
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:19:38.982658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.60
 ---- batch: 020 ----
mean loss: 49.56
 ---- batch: 030 ----
mean loss: 47.01
train mean loss: 49.39
epoch train time: 0:00:00.596772
elapsed time: 0:01:55.018270
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:19:39.579915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.87
 ---- batch: 020 ----
mean loss: 50.09
 ---- batch: 030 ----
mean loss: 48.45
train mean loss: 48.45
epoch train time: 0:00:00.590958
elapsed time: 0:01:55.609597
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:19:40.171235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.09
 ---- batch: 020 ----
mean loss: 48.50
 ---- batch: 030 ----
mean loss: 48.57
train mean loss: 47.97
epoch train time: 0:00:00.597064
elapsed time: 0:01:56.207051
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:19:40.768674
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.47
 ---- batch: 020 ----
mean loss: 47.78
 ---- batch: 030 ----
mean loss: 47.33
train mean loss: 48.18
epoch train time: 0:00:00.606247
elapsed time: 0:01:56.813678
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:19:41.375306
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.92
 ---- batch: 020 ----
mean loss: 46.94
 ---- batch: 030 ----
mean loss: 46.85
train mean loss: 48.05
epoch train time: 0:00:00.622799
elapsed time: 0:01:57.436879
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:19:41.998516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.58
 ---- batch: 020 ----
mean loss: 46.39
 ---- batch: 030 ----
mean loss: 46.32
train mean loss: 46.71
epoch train time: 0:00:00.599747
elapsed time: 0:01:58.037171
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:19:42.598740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.03
 ---- batch: 020 ----
mean loss: 47.88
 ---- batch: 030 ----
mean loss: 47.08
train mean loss: 46.75
epoch train time: 0:00:00.593813
elapsed time: 0:01:58.631283
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:19:43.192898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.93
 ---- batch: 020 ----
mean loss: 46.26
 ---- batch: 030 ----
mean loss: 47.28
train mean loss: 46.16
epoch train time: 0:00:00.585932
elapsed time: 0:01:59.217596
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:19:43.779226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.69
 ---- batch: 020 ----
mean loss: 44.65
 ---- batch: 030 ----
mean loss: 45.62
train mean loss: 45.68
epoch train time: 0:00:00.602995
elapsed time: 0:01:59.821020
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:19:44.382647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.63
 ---- batch: 020 ----
mean loss: 44.21
 ---- batch: 030 ----
mean loss: 46.80
train mean loss: 45.20
epoch train time: 0:00:00.601921
elapsed time: 0:02:00.423284
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:19:44.984929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.63
 ---- batch: 020 ----
mean loss: 45.11
 ---- batch: 030 ----
mean loss: 44.49
train mean loss: 44.50
epoch train time: 0:00:00.590359
elapsed time: 0:02:01.014018
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:19:45.575644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.24
 ---- batch: 020 ----
mean loss: 43.49
 ---- batch: 030 ----
mean loss: 45.14
train mean loss: 44.11
epoch train time: 0:00:00.610037
elapsed time: 0:02:01.624429
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:19:46.186092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.43
 ---- batch: 020 ----
mean loss: 44.56
 ---- batch: 030 ----
mean loss: 43.91
train mean loss: 43.65
epoch train time: 0:00:00.606508
elapsed time: 0:02:02.231366
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:19:46.792992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.63
 ---- batch: 020 ----
mean loss: 46.28
 ---- batch: 030 ----
mean loss: 45.77
train mean loss: 45.07
epoch train time: 0:00:00.603979
elapsed time: 0:02:02.835699
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:19:47.397327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.39
 ---- batch: 020 ----
mean loss: 44.50
 ---- batch: 030 ----
mean loss: 42.46
train mean loss: 42.56
epoch train time: 0:00:00.602345
elapsed time: 0:02:03.438419
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:19:48.000044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.51
 ---- batch: 020 ----
mean loss: 42.04
 ---- batch: 030 ----
mean loss: 45.44
train mean loss: 42.76
epoch train time: 0:00:00.611988
elapsed time: 0:02:04.050762
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:19:48.612388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.70
 ---- batch: 020 ----
mean loss: 42.14
 ---- batch: 030 ----
mean loss: 40.94
train mean loss: 41.85
epoch train time: 0:00:00.597240
elapsed time: 0:02:04.648366
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:19:49.209992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.43
 ---- batch: 020 ----
mean loss: 41.77
 ---- batch: 030 ----
mean loss: 40.80
train mean loss: 41.64
epoch train time: 0:00:00.598674
elapsed time: 0:02:05.247527
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:19:49.809170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.89
 ---- batch: 020 ----
mean loss: 42.94
 ---- batch: 030 ----
mean loss: 41.17
train mean loss: 42.46
epoch train time: 0:00:00.601981
elapsed time: 0:02:05.849955
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:19:50.411580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.17
 ---- batch: 020 ----
mean loss: 41.98
 ---- batch: 030 ----
mean loss: 43.15
train mean loss: 41.22
epoch train time: 0:00:00.626284
elapsed time: 0:02:06.476660
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:19:51.038289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.40
 ---- batch: 020 ----
mean loss: 39.31
 ---- batch: 030 ----
mean loss: 40.41
train mean loss: 40.34
epoch train time: 0:00:00.603728
elapsed time: 0:02:07.080823
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:19:51.642478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.03
 ---- batch: 020 ----
mean loss: 39.29
 ---- batch: 030 ----
mean loss: 40.75
train mean loss: 39.90
epoch train time: 0:00:00.609729
elapsed time: 0:02:07.690988
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:19:52.252601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.03
 ---- batch: 020 ----
mean loss: 39.81
 ---- batch: 030 ----
mean loss: 40.98
train mean loss: 40.51
epoch train time: 0:00:00.595732
elapsed time: 0:02:08.287129
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:19:52.848751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.51
 ---- batch: 020 ----
mean loss: 38.33
 ---- batch: 030 ----
mean loss: 41.36
train mean loss: 39.97
epoch train time: 0:00:00.612354
elapsed time: 0:02:08.899868
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:19:53.461488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.22
 ---- batch: 020 ----
mean loss: 36.85
 ---- batch: 030 ----
mean loss: 41.90
train mean loss: 38.93
epoch train time: 0:00:00.628616
elapsed time: 0:02:09.528855
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:19:54.090485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.75
 ---- batch: 020 ----
mean loss: 41.11
 ---- batch: 030 ----
mean loss: 39.08
train mean loss: 39.46
epoch train time: 0:00:00.600952
elapsed time: 0:02:10.130177
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:19:54.691876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.17
 ---- batch: 020 ----
mean loss: 38.40
 ---- batch: 030 ----
mean loss: 39.10
train mean loss: 38.57
epoch train time: 0:00:00.613044
elapsed time: 0:02:10.743694
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:19:55.305312
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.20
 ---- batch: 020 ----
mean loss: 38.71
 ---- batch: 030 ----
mean loss: 37.62
train mean loss: 38.44
epoch train time: 0:00:00.597438
elapsed time: 0:02:11.341496
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:19:55.903140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.44
 ---- batch: 020 ----
mean loss: 38.67
 ---- batch: 030 ----
mean loss: 36.76
train mean loss: 37.37
epoch train time: 0:00:00.589916
elapsed time: 0:02:11.931784
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:19:56.493403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.33
 ---- batch: 020 ----
mean loss: 37.16
 ---- batch: 030 ----
mean loss: 37.43
train mean loss: 37.50
epoch train time: 0:00:00.599836
elapsed time: 0:02:12.532046
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:19:57.093691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 35.97
 ---- batch: 020 ----
mean loss: 38.98
 ---- batch: 030 ----
mean loss: 35.36
train mean loss: 36.69
epoch train time: 0:00:00.616159
elapsed time: 0:02:13.148678
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:19:57.710326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.15
 ---- batch: 020 ----
mean loss: 35.11
 ---- batch: 030 ----
mean loss: 37.73
train mean loss: 36.76
epoch train time: 0:00:00.620271
elapsed time: 0:02:13.769364
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:19:58.331014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.86
 ---- batch: 020 ----
mean loss: 36.02
 ---- batch: 030 ----
mean loss: 38.49
train mean loss: 36.71
epoch train time: 0:00:00.615552
elapsed time: 0:02:14.385314
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:19:58.946953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.05
 ---- batch: 020 ----
mean loss: 36.26
 ---- batch: 030 ----
mean loss: 36.31
train mean loss: 35.42
epoch train time: 0:00:00.588600
elapsed time: 0:02:14.974379
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:19:59.535942
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.05
 ---- batch: 020 ----
mean loss: 36.63
 ---- batch: 030 ----
mean loss: 34.16
train mean loss: 35.29
epoch train time: 0:00:00.603075
elapsed time: 0:02:15.577752
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:20:00.139372
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.18
 ---- batch: 020 ----
mean loss: 33.91
 ---- batch: 030 ----
mean loss: 36.35
train mean loss: 35.28
epoch train time: 0:00:00.589628
elapsed time: 0:02:16.167797
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:20:00.729430
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.16
 ---- batch: 020 ----
mean loss: 33.98
 ---- batch: 030 ----
mean loss: 37.39
train mean loss: 35.52
epoch train time: 0:00:00.608582
elapsed time: 0:02:16.776831
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:20:01.338453
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.86
 ---- batch: 020 ----
mean loss: 35.53
 ---- batch: 030 ----
mean loss: 34.03
train mean loss: 35.03
epoch train time: 0:00:00.601209
elapsed time: 0:02:17.378391
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:20:01.940022
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.10
 ---- batch: 020 ----
mean loss: 33.87
 ---- batch: 030 ----
mean loss: 35.49
train mean loss: 34.83
epoch train time: 0:00:00.597929
elapsed time: 0:02:17.976746
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:20:02.538387
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.56
 ---- batch: 020 ----
mean loss: 34.61
 ---- batch: 030 ----
mean loss: 35.14
train mean loss: 34.93
epoch train time: 0:00:00.611719
elapsed time: 0:02:18.588843
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:20:03.150466
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.43
 ---- batch: 020 ----
mean loss: 35.29
 ---- batch: 030 ----
mean loss: 35.45
train mean loss: 35.19
epoch train time: 0:00:00.597826
elapsed time: 0:02:19.187052
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:20:03.748678
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.00
 ---- batch: 020 ----
mean loss: 35.07
 ---- batch: 030 ----
mean loss: 34.98
train mean loss: 34.74
epoch train time: 0:00:00.604837
elapsed time: 0:02:19.792361
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:20:04.353993
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.31
 ---- batch: 020 ----
mean loss: 34.25
 ---- batch: 030 ----
mean loss: 36.19
train mean loss: 34.87
epoch train time: 0:00:00.610536
elapsed time: 0:02:20.403317
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:20:04.964976
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.34
 ---- batch: 020 ----
mean loss: 34.54
 ---- batch: 030 ----
mean loss: 33.70
train mean loss: 35.38
epoch train time: 0:00:00.594558
elapsed time: 0:02:20.998302
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:20:05.559924
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.99
 ---- batch: 020 ----
mean loss: 35.53
 ---- batch: 030 ----
mean loss: 35.43
train mean loss: 34.78
epoch train time: 0:00:00.606826
elapsed time: 0:02:21.605466
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:20:06.167091
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.63
 ---- batch: 020 ----
mean loss: 33.75
 ---- batch: 030 ----
mean loss: 35.60
train mean loss: 34.93
epoch train time: 0:00:00.601143
elapsed time: 0:02:22.207046
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:20:06.768668
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.03
 ---- batch: 020 ----
mean loss: 36.35
 ---- batch: 030 ----
mean loss: 33.95
train mean loss: 34.99
epoch train time: 0:00:00.606130
elapsed time: 0:02:22.813542
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:20:07.375184
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.29
 ---- batch: 020 ----
mean loss: 34.65
 ---- batch: 030 ----
mean loss: 36.79
train mean loss: 34.81
epoch train time: 0:00:00.607419
elapsed time: 0:02:23.421317
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:20:07.982968
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.13
 ---- batch: 020 ----
mean loss: 35.54
 ---- batch: 030 ----
mean loss: 33.25
train mean loss: 34.98
epoch train time: 0:00:00.603509
elapsed time: 0:02:24.025227
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:20:08.586855
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.77
 ---- batch: 020 ----
mean loss: 34.24
 ---- batch: 030 ----
mean loss: 36.42
train mean loss: 34.77
epoch train time: 0:00:00.596662
elapsed time: 0:02:24.622250
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:20:09.183871
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.51
 ---- batch: 020 ----
mean loss: 36.06
 ---- batch: 030 ----
mean loss: 33.15
train mean loss: 34.90
epoch train time: 0:00:00.597789
elapsed time: 0:02:25.220413
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:20:09.782032
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.14
 ---- batch: 020 ----
mean loss: 35.56
 ---- batch: 030 ----
mean loss: 34.76
train mean loss: 34.80
epoch train time: 0:00:00.615970
elapsed time: 0:02:25.836726
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:20:10.398348
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.31
 ---- batch: 020 ----
mean loss: 34.96
 ---- batch: 030 ----
mean loss: 35.70
train mean loss: 34.40
epoch train time: 0:00:00.614643
elapsed time: 0:02:26.451707
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:20:11.013349
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.44
 ---- batch: 020 ----
mean loss: 34.72
 ---- batch: 030 ----
mean loss: 35.26
train mean loss: 35.04
epoch train time: 0:00:00.599937
elapsed time: 0:02:27.052030
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:20:11.613690
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.24
 ---- batch: 020 ----
mean loss: 34.98
 ---- batch: 030 ----
mean loss: 34.23
train mean loss: 34.60
epoch train time: 0:00:00.599966
elapsed time: 0:02:27.652373
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:20:12.214008
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.54
 ---- batch: 020 ----
mean loss: 33.98
 ---- batch: 030 ----
mean loss: 36.65
train mean loss: 34.81
epoch train time: 0:00:00.598149
elapsed time: 0:02:28.250940
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:20:12.812567
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.35
 ---- batch: 020 ----
mean loss: 34.35
 ---- batch: 030 ----
mean loss: 35.09
train mean loss: 34.27
epoch train time: 0:00:00.586862
elapsed time: 0:02:28.838143
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:20:13.399761
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.26
 ---- batch: 020 ----
mean loss: 34.16
 ---- batch: 030 ----
mean loss: 34.49
train mean loss: 34.61
epoch train time: 0:00:00.601100
elapsed time: 0:02:29.439640
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:20:14.001272
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.74
 ---- batch: 020 ----
mean loss: 34.10
 ---- batch: 030 ----
mean loss: 32.58
train mean loss: 34.58
epoch train time: 0:00:00.598891
elapsed time: 0:02:30.038909
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:20:14.600538
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.01
 ---- batch: 020 ----
mean loss: 34.78
 ---- batch: 030 ----
mean loss: 34.55
train mean loss: 34.18
epoch train time: 0:00:00.599885
elapsed time: 0:02:30.639198
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:20:15.200852
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.01
 ---- batch: 020 ----
mean loss: 34.27
 ---- batch: 030 ----
mean loss: 34.19
train mean loss: 34.37
epoch train time: 0:00:00.591672
elapsed time: 0:02:31.231277
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:20:15.792895
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.97
 ---- batch: 020 ----
mean loss: 33.80
 ---- batch: 030 ----
mean loss: 34.38
train mean loss: 34.09
epoch train time: 0:00:00.600080
elapsed time: 0:02:31.831690
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:20:16.393319
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.23
 ---- batch: 020 ----
mean loss: 35.22
 ---- batch: 030 ----
mean loss: 32.40
train mean loss: 33.88
epoch train time: 0:00:00.598476
elapsed time: 0:02:32.430567
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:20:16.992188
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.32
 ---- batch: 020 ----
mean loss: 33.84
 ---- batch: 030 ----
mean loss: 34.21
train mean loss: 34.03
epoch train time: 0:00:00.594079
elapsed time: 0:02:33.024988
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:20:17.586629
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.43
 ---- batch: 020 ----
mean loss: 35.41
 ---- batch: 030 ----
mean loss: 33.36
train mean loss: 33.93
epoch train time: 0:00:00.598822
elapsed time: 0:02:33.624176
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:20:18.185814
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.83
 ---- batch: 020 ----
mean loss: 33.49
 ---- batch: 030 ----
mean loss: 34.64
train mean loss: 34.15
epoch train time: 0:00:00.597173
elapsed time: 0:02:34.221780
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:20:18.783344
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.65
 ---- batch: 020 ----
mean loss: 34.62
 ---- batch: 030 ----
mean loss: 32.24
train mean loss: 33.62
epoch train time: 0:00:00.586942
elapsed time: 0:02:34.809029
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:20:19.370718
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.99
 ---- batch: 020 ----
mean loss: 34.54
 ---- batch: 030 ----
mean loss: 33.70
train mean loss: 34.18
epoch train time: 0:00:00.596766
elapsed time: 0:02:35.406205
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:20:19.967825
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.07
 ---- batch: 020 ----
mean loss: 32.69
 ---- batch: 030 ----
mean loss: 33.91
train mean loss: 33.68
epoch train time: 0:00:00.599497
elapsed time: 0:02:36.006231
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:20:20.567862
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.18
 ---- batch: 020 ----
mean loss: 33.55
 ---- batch: 030 ----
mean loss: 34.22
train mean loss: 33.76
epoch train time: 0:00:00.597500
elapsed time: 0:02:36.604104
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:20:21.165733
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.39
 ---- batch: 020 ----
mean loss: 33.20
 ---- batch: 030 ----
mean loss: 33.99
train mean loss: 33.99
epoch train time: 0:00:00.600340
elapsed time: 0:02:37.204844
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:20:21.766467
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.63
 ---- batch: 020 ----
mean loss: 33.37
 ---- batch: 030 ----
mean loss: 33.40
train mean loss: 33.84
epoch train time: 0:00:00.593577
elapsed time: 0:02:37.798811
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:20:22.360432
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.34
 ---- batch: 020 ----
mean loss: 34.52
 ---- batch: 030 ----
mean loss: 33.02
train mean loss: 34.11
epoch train time: 0:00:00.593300
elapsed time: 0:02:38.392505
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:20:22.954128
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.94
 ---- batch: 020 ----
mean loss: 33.07
 ---- batch: 030 ----
mean loss: 36.02
train mean loss: 33.97
epoch train time: 0:00:00.627136
elapsed time: 0:02:39.019990
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:20:23.581648
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.83
 ---- batch: 020 ----
mean loss: 34.03
 ---- batch: 030 ----
mean loss: 33.06
train mean loss: 33.76
epoch train time: 0:00:00.605153
elapsed time: 0:02:39.625521
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:20:24.187134
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.63
 ---- batch: 020 ----
mean loss: 34.38
 ---- batch: 030 ----
mean loss: 32.82
train mean loss: 33.49
epoch train time: 0:00:00.597551
elapsed time: 0:02:40.223498
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:20:24.785120
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.68
 ---- batch: 020 ----
mean loss: 34.15
 ---- batch: 030 ----
mean loss: 34.99
train mean loss: 33.88
epoch train time: 0:00:00.598837
elapsed time: 0:02:40.822705
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:20:25.384326
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.03
 ---- batch: 020 ----
mean loss: 33.66
 ---- batch: 030 ----
mean loss: 33.81
train mean loss: 33.75
epoch train time: 0:00:00.597021
elapsed time: 0:02:41.420119
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:20:25.981743
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.43
 ---- batch: 020 ----
mean loss: 32.85
 ---- batch: 030 ----
mean loss: 34.20
train mean loss: 34.04
epoch train time: 0:00:00.596339
elapsed time: 0:02:42.016806
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:20:26.578427
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.64
 ---- batch: 020 ----
mean loss: 31.53
 ---- batch: 030 ----
mean loss: 33.22
train mean loss: 33.42
epoch train time: 0:00:00.638991
elapsed time: 0:02:42.656170
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:20:27.217870
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.42
 ---- batch: 020 ----
mean loss: 33.99
 ---- batch: 030 ----
mean loss: 31.61
train mean loss: 33.55
epoch train time: 0:00:00.601333
elapsed time: 0:02:43.258002
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:20:27.819635
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.04
 ---- batch: 020 ----
mean loss: 34.56
 ---- batch: 030 ----
mean loss: 34.65
train mean loss: 33.64
epoch train time: 0:00:00.597610
elapsed time: 0:02:43.863356
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_4/checkpoint.pth.tar
**** end time: 2019-09-27 15:20:28.424909 ****
