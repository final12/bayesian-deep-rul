Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_3', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29727
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:14:46.417012 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:14:46.426760
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3999.70
 ---- batch: 020 ----
mean loss: 3670.69
 ---- batch: 030 ----
mean loss: 3516.54
train mean loss: 3673.80
epoch train time: 0:00:13.087162
elapsed time: 0:00:13.103315
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:14:59.520368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3185.18
 ---- batch: 020 ----
mean loss: 2975.47
 ---- batch: 030 ----
mean loss: 2858.05
train mean loss: 2974.02
epoch train time: 0:00:00.590788
elapsed time: 0:00:13.694404
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:15:00.111549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2664.25
 ---- batch: 020 ----
mean loss: 2547.46
 ---- batch: 030 ----
mean loss: 2485.77
train mean loss: 2545.80
epoch train time: 0:00:00.593107
elapsed time: 0:00:14.287901
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:15:00.705035
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2374.12
 ---- batch: 020 ----
mean loss: 2296.22
 ---- batch: 030 ----
mean loss: 2284.06
train mean loss: 2310.30
epoch train time: 0:00:00.581093
elapsed time: 0:00:14.869367
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:15:01.286478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2164.24
 ---- batch: 020 ----
mean loss: 2126.82
 ---- batch: 030 ----
mean loss: 2166.85
train mean loss: 2143.09
epoch train time: 0:00:00.578354
elapsed time: 0:00:15.448065
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:15:01.865238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2049.41
 ---- batch: 020 ----
mean loss: 1993.03
 ---- batch: 030 ----
mean loss: 1976.08
train mean loss: 1998.18
epoch train time: 0:00:00.582620
elapsed time: 0:00:16.031126
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:15:02.448256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1930.02
 ---- batch: 020 ----
mean loss: 1877.88
 ---- batch: 030 ----
mean loss: 1842.86
train mean loss: 1878.51
epoch train time: 0:00:00.589624
elapsed time: 0:00:16.621165
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:15:03.038284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1821.14
 ---- batch: 020 ----
mean loss: 1804.33
 ---- batch: 030 ----
mean loss: 1731.44
train mean loss: 1778.36
epoch train time: 0:00:00.586162
elapsed time: 0:00:17.207655
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:15:03.624768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1713.64
 ---- batch: 020 ----
mean loss: 1685.07
 ---- batch: 030 ----
mean loss: 1658.41
train mean loss: 1680.68
epoch train time: 0:00:00.588789
elapsed time: 0:00:17.796800
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:15:04.213918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1646.79
 ---- batch: 020 ----
mean loss: 1592.13
 ---- batch: 030 ----
mean loss: 1576.00
train mean loss: 1594.75
epoch train time: 0:00:00.592671
elapsed time: 0:00:18.389835
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:15:04.806974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1532.58
 ---- batch: 020 ----
mean loss: 1542.60
 ---- batch: 030 ----
mean loss: 1486.15
train mean loss: 1516.70
epoch train time: 0:00:00.582926
elapsed time: 0:00:18.973158
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:15:05.390273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1456.86
 ---- batch: 020 ----
mean loss: 1453.17
 ---- batch: 030 ----
mean loss: 1399.59
train mean loss: 1438.85
epoch train time: 0:00:00.604994
elapsed time: 0:00:19.578561
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:15:05.995688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1414.46
 ---- batch: 020 ----
mean loss: 1368.16
 ---- batch: 030 ----
mean loss: 1368.54
train mean loss: 1374.22
epoch train time: 0:00:00.588168
elapsed time: 0:00:20.167074
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:15:06.584209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1352.76
 ---- batch: 020 ----
mean loss: 1314.16
 ---- batch: 030 ----
mean loss: 1273.12
train mean loss: 1302.65
epoch train time: 0:00:00.599616
elapsed time: 0:00:20.767049
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:15:07.184158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1259.92
 ---- batch: 020 ----
mean loss: 1253.08
 ---- batch: 030 ----
mean loss: 1226.19
train mean loss: 1241.85
epoch train time: 0:00:00.573621
elapsed time: 0:00:21.341054
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:15:07.758219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1196.11
 ---- batch: 020 ----
mean loss: 1175.78
 ---- batch: 030 ----
mean loss: 1170.57
train mean loss: 1177.84
epoch train time: 0:00:00.577838
elapsed time: 0:00:21.919326
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:15:08.336485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1131.67
 ---- batch: 020 ----
mean loss: 1112.37
 ---- batch: 030 ----
mean loss: 1104.19
train mean loss: 1112.75
epoch train time: 0:00:00.584666
elapsed time: 0:00:22.504450
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:15:08.921591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1073.28
 ---- batch: 020 ----
mean loss: 1057.49
 ---- batch: 030 ----
mean loss: 1027.02
train mean loss: 1053.33
epoch train time: 0:00:00.590657
elapsed time: 0:00:23.095578
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:15:09.512699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1023.77
 ---- batch: 020 ----
mean loss: 1009.19
 ---- batch: 030 ----
mean loss: 974.12
train mean loss: 998.12
epoch train time: 0:00:00.591591
elapsed time: 0:00:23.687593
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:15:10.104754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 966.90
 ---- batch: 020 ----
mean loss: 951.55
 ---- batch: 030 ----
mean loss: 943.99
train mean loss: 948.60
epoch train time: 0:00:00.597338
elapsed time: 0:00:24.285374
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:15:10.702506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.48
 ---- batch: 020 ----
mean loss: 904.65
 ---- batch: 030 ----
mean loss: 894.64
train mean loss: 901.19
epoch train time: 0:00:00.581356
elapsed time: 0:00:24.867117
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:15:11.284249
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 861.84
 ---- batch: 020 ----
mean loss: 876.51
 ---- batch: 030 ----
mean loss: 843.90
train mean loss: 853.95
epoch train time: 0:00:00.590655
elapsed time: 0:00:25.458188
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:15:11.875309
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 826.46
 ---- batch: 020 ----
mean loss: 809.40
 ---- batch: 030 ----
mean loss: 808.73
train mean loss: 808.29
epoch train time: 0:00:00.577574
elapsed time: 0:00:26.036089
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:15:12.453222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 775.56
 ---- batch: 020 ----
mean loss: 785.92
 ---- batch: 030 ----
mean loss: 776.15
train mean loss: 771.16
epoch train time: 0:00:00.596654
elapsed time: 0:00:26.633274
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:15:13.050579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 751.22
 ---- batch: 020 ----
mean loss: 740.90
 ---- batch: 030 ----
mean loss: 713.21
train mean loss: 728.45
epoch train time: 0:00:00.604595
elapsed time: 0:00:27.238545
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:15:13.655701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 700.59
 ---- batch: 020 ----
mean loss: 714.26
 ---- batch: 030 ----
mean loss: 688.80
train mean loss: 696.10
epoch train time: 0:00:00.601550
elapsed time: 0:00:27.840511
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:15:14.257654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 673.90
 ---- batch: 020 ----
mean loss: 664.21
 ---- batch: 030 ----
mean loss: 636.63
train mean loss: 659.85
epoch train time: 0:00:00.610674
elapsed time: 0:00:28.451621
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:15:14.868739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 642.42
 ---- batch: 020 ----
mean loss: 634.72
 ---- batch: 030 ----
mean loss: 618.71
train mean loss: 628.80
epoch train time: 0:00:00.593768
elapsed time: 0:00:29.045834
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:15:15.462961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 594.19
 ---- batch: 020 ----
mean loss: 607.78
 ---- batch: 030 ----
mean loss: 585.13
train mean loss: 591.08
epoch train time: 0:00:00.585569
elapsed time: 0:00:29.631740
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:15:16.048857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 570.12
 ---- batch: 020 ----
mean loss: 571.58
 ---- batch: 030 ----
mean loss: 560.84
train mean loss: 565.44
epoch train time: 0:00:00.588189
elapsed time: 0:00:30.220336
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:15:16.637453
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 544.85
 ---- batch: 020 ----
mean loss: 531.55
 ---- batch: 030 ----
mean loss: 547.07
train mean loss: 538.86
epoch train time: 0:00:00.590482
elapsed time: 0:00:30.811235
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:15:17.228353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 521.01
 ---- batch: 020 ----
mean loss: 524.16
 ---- batch: 030 ----
mean loss: 507.96
train mean loss: 513.41
epoch train time: 0:00:00.577244
elapsed time: 0:00:31.388894
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:15:17.806029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 499.99
 ---- batch: 020 ----
mean loss: 478.65
 ---- batch: 030 ----
mean loss: 474.66
train mean loss: 486.45
epoch train time: 0:00:00.590565
elapsed time: 0:00:31.979849
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:15:18.396978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 475.61
 ---- batch: 020 ----
mean loss: 476.95
 ---- batch: 030 ----
mean loss: 452.65
train mean loss: 464.34
epoch train time: 0:00:00.584491
elapsed time: 0:00:32.564726
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:15:18.981844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 445.31
 ---- batch: 020 ----
mean loss: 444.05
 ---- batch: 030 ----
mean loss: 441.77
train mean loss: 443.32
epoch train time: 0:00:00.571660
elapsed time: 0:00:33.136773
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:15:19.553893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 424.30
 ---- batch: 020 ----
mean loss: 419.29
 ---- batch: 030 ----
mean loss: 426.96
train mean loss: 421.79
epoch train time: 0:00:00.584481
elapsed time: 0:00:33.721702
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:15:20.138824
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 412.35
 ---- batch: 020 ----
mean loss: 409.07
 ---- batch: 030 ----
mean loss: 396.44
train mean loss: 403.70
epoch train time: 0:00:00.580138
elapsed time: 0:00:34.302234
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:15:20.719351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 387.64
 ---- batch: 020 ----
mean loss: 382.19
 ---- batch: 030 ----
mean loss: 378.16
train mean loss: 381.67
epoch train time: 0:00:00.596583
elapsed time: 0:00:34.899192
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:15:21.316342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 379.10
 ---- batch: 020 ----
mean loss: 367.54
 ---- batch: 030 ----
mean loss: 360.49
train mean loss: 367.24
epoch train time: 0:00:00.610277
elapsed time: 0:00:35.509873
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:15:21.927012
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 357.21
 ---- batch: 020 ----
mean loss: 346.12
 ---- batch: 030 ----
mean loss: 345.13
train mean loss: 349.14
epoch train time: 0:00:00.585514
elapsed time: 0:00:36.095781
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:15:22.512902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 341.78
 ---- batch: 020 ----
mean loss: 323.86
 ---- batch: 030 ----
mean loss: 332.54
train mean loss: 333.30
epoch train time: 0:00:00.603803
elapsed time: 0:00:36.699940
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:15:23.117091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.85
 ---- batch: 020 ----
mean loss: 314.67
 ---- batch: 030 ----
mean loss: 323.50
train mean loss: 318.13
epoch train time: 0:00:00.585362
elapsed time: 0:00:37.285708
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:15:23.702859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.80
 ---- batch: 020 ----
mean loss: 305.81
 ---- batch: 030 ----
mean loss: 298.57
train mean loss: 306.54
epoch train time: 0:00:00.584411
elapsed time: 0:00:37.870482
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:15:24.287601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.89
 ---- batch: 020 ----
mean loss: 296.43
 ---- batch: 030 ----
mean loss: 285.47
train mean loss: 290.97
epoch train time: 0:00:00.587893
elapsed time: 0:00:38.458725
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:15:24.875838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.38
 ---- batch: 020 ----
mean loss: 277.42
 ---- batch: 030 ----
mean loss: 278.61
train mean loss: 279.60
epoch train time: 0:00:00.578692
elapsed time: 0:00:39.037752
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:15:25.454858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.82
 ---- batch: 020 ----
mean loss: 263.42
 ---- batch: 030 ----
mean loss: 265.10
train mean loss: 268.78
epoch train time: 0:00:00.578660
elapsed time: 0:00:39.616853
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:15:26.033977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.44
 ---- batch: 020 ----
mean loss: 262.56
 ---- batch: 030 ----
mean loss: 254.74
train mean loss: 256.52
epoch train time: 0:00:00.581862
elapsed time: 0:00:40.199115
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:15:26.616246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.71
 ---- batch: 020 ----
mean loss: 249.42
 ---- batch: 030 ----
mean loss: 254.94
train mean loss: 248.79
epoch train time: 0:00:00.589991
elapsed time: 0:00:40.789463
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:15:27.206613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.32
 ---- batch: 020 ----
mean loss: 236.01
 ---- batch: 030 ----
mean loss: 242.22
train mean loss: 239.41
epoch train time: 0:00:00.604954
elapsed time: 0:00:41.394834
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:15:27.811957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.96
 ---- batch: 020 ----
mean loss: 232.48
 ---- batch: 030 ----
mean loss: 223.07
train mean loss: 228.82
epoch train time: 0:00:00.571557
elapsed time: 0:00:41.966799
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:15:28.383920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.81
 ---- batch: 020 ----
mean loss: 215.06
 ---- batch: 030 ----
mean loss: 217.85
train mean loss: 218.83
epoch train time: 0:00:00.588480
elapsed time: 0:00:42.555619
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:15:28.972738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.49
 ---- batch: 020 ----
mean loss: 218.18
 ---- batch: 030 ----
mean loss: 207.42
train mean loss: 212.83
epoch train time: 0:00:00.583623
elapsed time: 0:00:43.139657
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:15:29.556794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.02
 ---- batch: 020 ----
mean loss: 201.39
 ---- batch: 030 ----
mean loss: 200.56
train mean loss: 202.65
epoch train time: 0:00:00.588676
elapsed time: 0:00:43.728708
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:15:30.145830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 194.04
 ---- batch: 020 ----
mean loss: 203.42
 ---- batch: 030 ----
mean loss: 197.52
train mean loss: 197.63
epoch train time: 0:00:00.583695
elapsed time: 0:00:44.312844
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:15:30.730014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.33
 ---- batch: 020 ----
mean loss: 189.57
 ---- batch: 030 ----
mean loss: 192.50
train mean loss: 192.01
epoch train time: 0:00:00.575861
elapsed time: 0:00:44.889090
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:15:31.306205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.35
 ---- batch: 020 ----
mean loss: 183.61
 ---- batch: 030 ----
mean loss: 179.01
train mean loss: 184.00
epoch train time: 0:00:00.600012
elapsed time: 0:00:45.489460
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:15:31.906573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.96
 ---- batch: 020 ----
mean loss: 183.36
 ---- batch: 030 ----
mean loss: 176.93
train mean loss: 179.41
epoch train time: 0:00:00.569550
elapsed time: 0:00:46.059384
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:15:32.476532
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.14
 ---- batch: 020 ----
mean loss: 173.21
 ---- batch: 030 ----
mean loss: 176.01
train mean loss: 174.44
epoch train time: 0:00:00.579501
elapsed time: 0:00:46.639272
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:15:33.056415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.73
 ---- batch: 020 ----
mean loss: 169.71
 ---- batch: 030 ----
mean loss: 169.57
train mean loss: 168.08
epoch train time: 0:00:00.572826
elapsed time: 0:00:47.212458
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:15:33.629575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.65
 ---- batch: 020 ----
mean loss: 163.15
 ---- batch: 030 ----
mean loss: 161.93
train mean loss: 163.16
epoch train time: 0:00:00.591822
elapsed time: 0:00:47.804701
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:15:34.221843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.11
 ---- batch: 020 ----
mean loss: 162.12
 ---- batch: 030 ----
mean loss: 159.53
train mean loss: 161.47
epoch train time: 0:00:00.601473
elapsed time: 0:00:48.406570
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:15:34.823698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.11
 ---- batch: 020 ----
mean loss: 154.31
 ---- batch: 030 ----
mean loss: 156.69
train mean loss: 155.05
epoch train time: 0:00:00.604909
elapsed time: 0:00:49.011953
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:15:35.429115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.54
 ---- batch: 020 ----
mean loss: 151.25
 ---- batch: 030 ----
mean loss: 146.07
train mean loss: 150.69
epoch train time: 0:00:00.682285
elapsed time: 0:00:49.694829
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:15:36.111972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.48
 ---- batch: 020 ----
mean loss: 149.04
 ---- batch: 030 ----
mean loss: 144.43
train mean loss: 146.17
epoch train time: 0:00:00.591426
elapsed time: 0:00:50.286773
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:15:36.703906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.24
 ---- batch: 020 ----
mean loss: 143.10
 ---- batch: 030 ----
mean loss: 139.19
train mean loss: 142.10
epoch train time: 0:00:00.581325
elapsed time: 0:00:50.868467
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:15:37.285592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.93
 ---- batch: 020 ----
mean loss: 140.30
 ---- batch: 030 ----
mean loss: 141.44
train mean loss: 139.49
epoch train time: 0:00:00.603214
elapsed time: 0:00:51.472110
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:15:37.889283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.71
 ---- batch: 020 ----
mean loss: 138.29
 ---- batch: 030 ----
mean loss: 131.57
train mean loss: 133.97
epoch train time: 0:00:00.589424
elapsed time: 0:00:52.061948
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:15:38.479067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.23
 ---- batch: 020 ----
mean loss: 134.34
 ---- batch: 030 ----
mean loss: 133.55
train mean loss: 133.85
epoch train time: 0:00:00.587631
elapsed time: 0:00:52.649934
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:15:39.067057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.18
 ---- batch: 020 ----
mean loss: 130.59
 ---- batch: 030 ----
mean loss: 125.99
train mean loss: 130.11
epoch train time: 0:00:00.572317
elapsed time: 0:00:53.222587
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:15:39.639706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.90
 ---- batch: 020 ----
mean loss: 127.65
 ---- batch: 030 ----
mean loss: 128.16
train mean loss: 128.57
epoch train time: 0:00:00.579536
elapsed time: 0:00:53.802457
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:15:40.219580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.69
 ---- batch: 020 ----
mean loss: 126.27
 ---- batch: 030 ----
mean loss: 124.58
train mean loss: 123.80
epoch train time: 0:00:00.616645
elapsed time: 0:00:54.419559
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:15:40.836694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.10
 ---- batch: 020 ----
mean loss: 121.21
 ---- batch: 030 ----
mean loss: 119.14
train mean loss: 122.52
epoch train time: 0:00:00.580275
elapsed time: 0:00:55.000226
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:15:41.417344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.42
 ---- batch: 020 ----
mean loss: 119.86
 ---- batch: 030 ----
mean loss: 122.15
train mean loss: 120.61
epoch train time: 0:00:00.584209
elapsed time: 0:00:55.584825
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:15:42.001959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.12
 ---- batch: 020 ----
mean loss: 118.44
 ---- batch: 030 ----
mean loss: 118.25
train mean loss: 118.04
epoch train time: 0:00:00.587999
elapsed time: 0:00:56.173236
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:15:42.590354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.71
 ---- batch: 020 ----
mean loss: 117.26
 ---- batch: 030 ----
mean loss: 113.94
train mean loss: 115.30
epoch train time: 0:00:00.585304
elapsed time: 0:00:56.758963
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:15:43.176092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.34
 ---- batch: 020 ----
mean loss: 113.63
 ---- batch: 030 ----
mean loss: 113.79
train mean loss: 113.34
epoch train time: 0:00:00.576054
elapsed time: 0:00:57.335513
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:15:43.752635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.53
 ---- batch: 020 ----
mean loss: 108.60
 ---- batch: 030 ----
mean loss: 110.86
train mean loss: 111.68
epoch train time: 0:00:00.588305
elapsed time: 0:00:57.924217
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:15:44.341360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.33
 ---- batch: 020 ----
mean loss: 107.42
 ---- batch: 030 ----
mean loss: 110.06
train mean loss: 108.70
epoch train time: 0:00:00.582906
elapsed time: 0:00:58.507542
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:15:44.924661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.51
 ---- batch: 020 ----
mean loss: 108.82
 ---- batch: 030 ----
mean loss: 110.86
train mean loss: 108.33
epoch train time: 0:00:00.579719
elapsed time: 0:00:59.087668
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:15:45.504802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.72
 ---- batch: 020 ----
mean loss: 108.88
 ---- batch: 030 ----
mean loss: 105.83
train mean loss: 106.44
epoch train time: 0:00:00.584799
elapsed time: 0:00:59.672884
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:15:46.090025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.65
 ---- batch: 020 ----
mean loss: 104.69
 ---- batch: 030 ----
mean loss: 106.98
train mean loss: 105.93
epoch train time: 0:00:00.578584
elapsed time: 0:01:00.251871
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:15:46.668987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.48
 ---- batch: 020 ----
mean loss: 107.29
 ---- batch: 030 ----
mean loss: 106.27
train mean loss: 104.89
epoch train time: 0:00:00.626049
elapsed time: 0:01:00.878421
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:15:47.295610
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.86
 ---- batch: 020 ----
mean loss: 105.28
 ---- batch: 030 ----
mean loss: 98.45
train mean loss: 102.77
epoch train time: 0:00:00.592269
elapsed time: 0:01:01.471105
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:15:47.888240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.25
 ---- batch: 020 ----
mean loss: 98.83
 ---- batch: 030 ----
mean loss: 101.37
train mean loss: 101.36
epoch train time: 0:00:00.587365
elapsed time: 0:01:02.058840
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:15:48.475952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.45
 ---- batch: 020 ----
mean loss: 101.49
 ---- batch: 030 ----
mean loss: 100.24
train mean loss: 99.29
epoch train time: 0:00:00.596992
elapsed time: 0:01:02.656170
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:15:49.073322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.17
 ---- batch: 020 ----
mean loss: 99.40
 ---- batch: 030 ----
mean loss: 95.79
train mean loss: 97.70
epoch train time: 0:00:00.598372
elapsed time: 0:01:03.254951
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:15:49.672068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.74
 ---- batch: 020 ----
mean loss: 96.85
 ---- batch: 030 ----
mean loss: 101.05
train mean loss: 97.82
epoch train time: 0:00:00.601462
elapsed time: 0:01:03.856767
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:15:50.273882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.32
 ---- batch: 020 ----
mean loss: 95.95
 ---- batch: 030 ----
mean loss: 92.34
train mean loss: 95.34
epoch train time: 0:00:00.591045
elapsed time: 0:01:04.448193
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:15:50.865302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.27
 ---- batch: 020 ----
mean loss: 94.26
 ---- batch: 030 ----
mean loss: 96.56
train mean loss: 96.95
epoch train time: 0:00:00.583755
elapsed time: 0:01:05.032320
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:15:51.449448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.03
 ---- batch: 020 ----
mean loss: 92.46
 ---- batch: 030 ----
mean loss: 96.34
train mean loss: 94.48
epoch train time: 0:00:00.620091
elapsed time: 0:01:05.652820
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:15:52.069937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.38
 ---- batch: 020 ----
mean loss: 95.78
 ---- batch: 030 ----
mean loss: 94.22
train mean loss: 93.81
epoch train time: 0:00:00.589409
elapsed time: 0:01:06.242584
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:15:52.659699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.49
 ---- batch: 020 ----
mean loss: 95.14
 ---- batch: 030 ----
mean loss: 91.95
train mean loss: 92.79
epoch train time: 0:00:00.584782
elapsed time: 0:01:06.827709
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:15:53.244823
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.46
 ---- batch: 020 ----
mean loss: 90.21
 ---- batch: 030 ----
mean loss: 90.77
train mean loss: 91.70
epoch train time: 0:00:00.577472
elapsed time: 0:01:07.405577
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:15:53.822719
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.98
 ---- batch: 020 ----
mean loss: 88.89
 ---- batch: 030 ----
mean loss: 92.88
train mean loss: 90.51
epoch train time: 0:00:00.591093
elapsed time: 0:01:07.997053
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:15:54.414178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.17
 ---- batch: 020 ----
mean loss: 88.85
 ---- batch: 030 ----
mean loss: 90.86
train mean loss: 89.64
epoch train time: 0:00:00.583830
elapsed time: 0:01:08.581253
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:15:54.998368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.16
 ---- batch: 020 ----
mean loss: 85.29
 ---- batch: 030 ----
mean loss: 91.53
train mean loss: 88.85
epoch train time: 0:00:00.586127
elapsed time: 0:01:09.167748
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:15:55.584879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.63
 ---- batch: 020 ----
mean loss: 88.71
 ---- batch: 030 ----
mean loss: 89.90
train mean loss: 87.39
epoch train time: 0:00:00.590969
elapsed time: 0:01:09.759134
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:15:56.176281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.69
 ---- batch: 020 ----
mean loss: 88.52
 ---- batch: 030 ----
mean loss: 87.06
train mean loss: 86.92
epoch train time: 0:00:00.602488
elapsed time: 0:01:10.362043
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:15:56.779158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.81
 ---- batch: 020 ----
mean loss: 86.16
 ---- batch: 030 ----
mean loss: 86.23
train mean loss: 85.61
epoch train time: 0:00:00.590194
elapsed time: 0:01:10.952624
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:15:57.369745
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.62
 ---- batch: 020 ----
mean loss: 86.04
 ---- batch: 030 ----
mean loss: 81.83
train mean loss: 85.31
epoch train time: 0:00:00.588745
elapsed time: 0:01:11.541717
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:15:57.958836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.65
 ---- batch: 020 ----
mean loss: 86.26
 ---- batch: 030 ----
mean loss: 78.41
train mean loss: 84.20
epoch train time: 0:00:00.593361
elapsed time: 0:01:12.135455
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:15:58.552574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.63
 ---- batch: 020 ----
mean loss: 83.49
 ---- batch: 030 ----
mean loss: 81.85
train mean loss: 83.17
epoch train time: 0:00:00.587967
elapsed time: 0:01:12.723744
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:15:59.140893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.27
 ---- batch: 020 ----
mean loss: 82.97
 ---- batch: 030 ----
mean loss: 81.24
train mean loss: 82.03
epoch train time: 0:00:00.599812
elapsed time: 0:01:13.323976
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:15:59.741111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.83
 ---- batch: 020 ----
mean loss: 84.52
 ---- batch: 030 ----
mean loss: 80.24
train mean loss: 82.40
epoch train time: 0:00:00.600585
elapsed time: 0:01:13.924946
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:16:00.342104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.70
 ---- batch: 020 ----
mean loss: 79.34
 ---- batch: 030 ----
mean loss: 79.94
train mean loss: 81.19
epoch train time: 0:00:00.601800
elapsed time: 0:01:14.527180
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:16:00.944308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.20
 ---- batch: 020 ----
mean loss: 79.10
 ---- batch: 030 ----
mean loss: 80.69
train mean loss: 79.51
epoch train time: 0:00:00.584279
elapsed time: 0:01:15.111835
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:16:01.528979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.24
 ---- batch: 020 ----
mean loss: 81.89
 ---- batch: 030 ----
mean loss: 78.72
train mean loss: 81.12
epoch train time: 0:00:00.592374
elapsed time: 0:01:15.704728
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:16:02.121793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.44
 ---- batch: 020 ----
mean loss: 78.51
 ---- batch: 030 ----
mean loss: 81.92
train mean loss: 80.15
epoch train time: 0:00:00.571419
elapsed time: 0:01:16.276560
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:16:02.693739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.41
 ---- batch: 020 ----
mean loss: 78.96
 ---- batch: 030 ----
mean loss: 77.22
train mean loss: 79.11
epoch train time: 0:00:00.604758
elapsed time: 0:01:16.882014
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:16:03.299168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.52
 ---- batch: 020 ----
mean loss: 79.06
 ---- batch: 030 ----
mean loss: 76.20
train mean loss: 77.51
epoch train time: 0:00:00.588691
elapsed time: 0:01:17.471144
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:16:03.888273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.80
 ---- batch: 020 ----
mean loss: 76.43
 ---- batch: 030 ----
mean loss: 79.01
train mean loss: 76.92
epoch train time: 0:00:00.577922
elapsed time: 0:01:18.049535
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:16:04.466654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.62
 ---- batch: 020 ----
mean loss: 75.24
 ---- batch: 030 ----
mean loss: 75.14
train mean loss: 76.55
epoch train time: 0:00:00.597374
elapsed time: 0:01:18.647344
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:16:05.064468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.34
 ---- batch: 020 ----
mean loss: 76.15
 ---- batch: 030 ----
mean loss: 75.83
train mean loss: 76.21
epoch train time: 0:00:00.587353
elapsed time: 0:01:19.235139
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:16:05.652284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.53
 ---- batch: 020 ----
mean loss: 75.36
 ---- batch: 030 ----
mean loss: 77.14
train mean loss: 76.67
epoch train time: 0:00:00.583698
elapsed time: 0:01:19.819249
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:16:06.236368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.52
 ---- batch: 020 ----
mean loss: 74.14
 ---- batch: 030 ----
mean loss: 77.55
train mean loss: 75.91
epoch train time: 0:00:00.591735
elapsed time: 0:01:20.411429
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:16:06.828582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.75
 ---- batch: 020 ----
mean loss: 74.88
 ---- batch: 030 ----
mean loss: 75.29
train mean loss: 75.02
epoch train time: 0:00:00.609960
elapsed time: 0:01:21.021794
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:16:07.438915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.62
 ---- batch: 020 ----
mean loss: 74.82
 ---- batch: 030 ----
mean loss: 74.44
train mean loss: 73.81
epoch train time: 0:00:00.606536
elapsed time: 0:01:21.628792
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:16:08.045917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.98
 ---- batch: 020 ----
mean loss: 74.67
 ---- batch: 030 ----
mean loss: 76.55
train mean loss: 74.10
epoch train time: 0:00:00.607268
elapsed time: 0:01:22.236488
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:16:08.653623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.41
 ---- batch: 020 ----
mean loss: 72.61
 ---- batch: 030 ----
mean loss: 74.25
train mean loss: 73.47
epoch train time: 0:00:00.614535
elapsed time: 0:01:22.851422
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:16:09.268547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.05
 ---- batch: 020 ----
mean loss: 72.40
 ---- batch: 030 ----
mean loss: 74.54
train mean loss: 73.24
epoch train time: 0:00:00.568709
elapsed time: 0:01:23.420552
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:16:09.837702
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.80
 ---- batch: 020 ----
mean loss: 72.53
 ---- batch: 030 ----
mean loss: 70.95
train mean loss: 71.92
epoch train time: 0:00:00.585477
elapsed time: 0:01:24.006442
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:16:10.423558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.84
 ---- batch: 020 ----
mean loss: 69.41
 ---- batch: 030 ----
mean loss: 73.86
train mean loss: 71.07
epoch train time: 0:00:00.587298
elapsed time: 0:01:24.594146
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:16:11.011278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.35
 ---- batch: 020 ----
mean loss: 70.80
 ---- batch: 030 ----
mean loss: 70.48
train mean loss: 71.12
epoch train time: 0:00:00.601853
elapsed time: 0:01:25.196703
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:16:11.613838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.99
 ---- batch: 020 ----
mean loss: 70.56
 ---- batch: 030 ----
mean loss: 68.96
train mean loss: 70.06
epoch train time: 0:00:00.591739
elapsed time: 0:01:25.788868
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:16:12.205985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.34
 ---- batch: 020 ----
mean loss: 67.75
 ---- batch: 030 ----
mean loss: 70.43
train mean loss: 69.52
epoch train time: 0:00:00.575347
elapsed time: 0:01:26.364618
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:16:12.781751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.75
 ---- batch: 020 ----
mean loss: 67.03
 ---- batch: 030 ----
mean loss: 69.04
train mean loss: 69.46
epoch train time: 0:00:00.586168
elapsed time: 0:01:26.951225
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:16:13.368349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.85
 ---- batch: 020 ----
mean loss: 67.35
 ---- batch: 030 ----
mean loss: 71.76
train mean loss: 69.06
epoch train time: 0:00:00.573718
elapsed time: 0:01:27.525379
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:16:13.942449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.77
 ---- batch: 020 ----
mean loss: 68.49
 ---- batch: 030 ----
mean loss: 67.54
train mean loss: 67.84
epoch train time: 0:00:00.580142
elapsed time: 0:01:28.105864
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:16:14.522993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.60
 ---- batch: 020 ----
mean loss: 68.86
 ---- batch: 030 ----
mean loss: 67.79
train mean loss: 68.65
epoch train time: 0:00:00.588617
elapsed time: 0:01:28.694892
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:16:15.112027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.67
 ---- batch: 020 ----
mean loss: 67.50
 ---- batch: 030 ----
mean loss: 68.34
train mean loss: 66.86
epoch train time: 0:00:00.579656
elapsed time: 0:01:29.274959
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:16:15.692079
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.77
 ---- batch: 020 ----
mean loss: 66.36
 ---- batch: 030 ----
mean loss: 65.51
train mean loss: 67.09
epoch train time: 0:00:00.581049
elapsed time: 0:01:29.856387
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:16:16.273511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.68
 ---- batch: 020 ----
mean loss: 65.49
 ---- batch: 030 ----
mean loss: 66.04
train mean loss: 65.80
epoch train time: 0:00:00.610660
elapsed time: 0:01:30.467444
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:16:16.884570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.63
 ---- batch: 020 ----
mean loss: 67.41
 ---- batch: 030 ----
mean loss: 63.42
train mean loss: 65.82
epoch train time: 0:00:00.588316
elapsed time: 0:01:31.056129
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:16:17.473247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.57
 ---- batch: 020 ----
mean loss: 65.47
 ---- batch: 030 ----
mean loss: 66.72
train mean loss: 65.61
epoch train time: 0:00:00.580275
elapsed time: 0:01:31.636900
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:16:18.054054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.73
 ---- batch: 020 ----
mean loss: 63.98
 ---- batch: 030 ----
mean loss: 63.21
train mean loss: 63.95
epoch train time: 0:00:00.582023
elapsed time: 0:01:32.219354
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:16:18.636478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.98
 ---- batch: 020 ----
mean loss: 62.39
 ---- batch: 030 ----
mean loss: 64.67
train mean loss: 64.18
epoch train time: 0:00:00.582289
elapsed time: 0:01:32.802108
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:16:19.219220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.70
 ---- batch: 020 ----
mean loss: 64.81
 ---- batch: 030 ----
mean loss: 62.69
train mean loss: 64.39
epoch train time: 0:00:00.581098
elapsed time: 0:01:33.383592
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:16:19.800712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.60
 ---- batch: 020 ----
mean loss: 63.32
 ---- batch: 030 ----
mean loss: 59.69
train mean loss: 62.71
epoch train time: 0:00:00.605436
elapsed time: 0:01:33.989426
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:16:20.406558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.03
 ---- batch: 020 ----
mean loss: 63.98
 ---- batch: 030 ----
mean loss: 63.70
train mean loss: 63.09
epoch train time: 0:00:00.598293
elapsed time: 0:01:34.588165
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:16:21.005283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.26
 ---- batch: 020 ----
mean loss: 64.78
 ---- batch: 030 ----
mean loss: 62.08
train mean loss: 62.61
epoch train time: 0:00:00.579035
elapsed time: 0:01:35.167655
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:16:21.584773
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.44
 ---- batch: 020 ----
mean loss: 58.87
 ---- batch: 030 ----
mean loss: 64.16
train mean loss: 62.49
epoch train time: 0:00:00.597789
elapsed time: 0:01:35.765865
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:16:22.182977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.01
 ---- batch: 020 ----
mean loss: 61.56
 ---- batch: 030 ----
mean loss: 63.32
train mean loss: 61.63
epoch train time: 0:00:00.597061
elapsed time: 0:01:36.363334
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:16:22.780534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.06
 ---- batch: 020 ----
mean loss: 61.49
 ---- batch: 030 ----
mean loss: 63.82
train mean loss: 61.50
epoch train time: 0:00:00.580093
elapsed time: 0:01:36.943886
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:16:23.361003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.80
 ---- batch: 020 ----
mean loss: 58.95
 ---- batch: 030 ----
mean loss: 59.41
train mean loss: 59.42
epoch train time: 0:00:00.586935
elapsed time: 0:01:37.531241
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:16:23.948361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.37
 ---- batch: 020 ----
mean loss: 59.07
 ---- batch: 030 ----
mean loss: 59.08
train mean loss: 59.48
epoch train time: 0:00:00.583745
elapsed time: 0:01:38.115421
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:16:24.532549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.75
 ---- batch: 020 ----
mean loss: 61.35
 ---- batch: 030 ----
mean loss: 58.22
train mean loss: 60.35
epoch train time: 0:00:00.602556
elapsed time: 0:01:38.718494
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:16:25.135640
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.57
 ---- batch: 020 ----
mean loss: 61.45
 ---- batch: 030 ----
mean loss: 55.69
train mean loss: 58.78
epoch train time: 0:00:00.590416
elapsed time: 0:01:39.309326
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:16:25.726444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.33
 ---- batch: 020 ----
mean loss: 58.00
 ---- batch: 030 ----
mean loss: 58.87
train mean loss: 58.15
epoch train time: 0:00:00.574090
elapsed time: 0:01:39.883876
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:16:26.301062
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.83
 ---- batch: 020 ----
mean loss: 58.90
 ---- batch: 030 ----
mean loss: 57.39
train mean loss: 58.25
epoch train time: 0:00:00.581276
elapsed time: 0:01:40.465693
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:16:26.882751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.75
 ---- batch: 020 ----
mean loss: 58.01
 ---- batch: 030 ----
mean loss: 59.29
train mean loss: 58.75
epoch train time: 0:00:00.596104
elapsed time: 0:01:41.062146
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:16:27.479266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.62
 ---- batch: 020 ----
mean loss: 56.51
 ---- batch: 030 ----
mean loss: 55.24
train mean loss: 56.19
epoch train time: 0:00:00.600092
elapsed time: 0:01:41.662692
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:16:28.079818
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.82
 ---- batch: 020 ----
mean loss: 56.46
 ---- batch: 030 ----
mean loss: 59.79
train mean loss: 56.50
epoch train time: 0:00:00.610780
elapsed time: 0:01:42.274089
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:16:28.691219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.05
 ---- batch: 020 ----
mean loss: 59.00
 ---- batch: 030 ----
mean loss: 54.40
train mean loss: 56.27
epoch train time: 0:00:00.591012
elapsed time: 0:01:42.865551
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:16:29.282670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.54
 ---- batch: 020 ----
mean loss: 54.57
 ---- batch: 030 ----
mean loss: 56.54
train mean loss: 55.94
epoch train time: 0:00:00.581490
elapsed time: 0:01:43.447456
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:16:29.864585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.82
 ---- batch: 020 ----
mean loss: 56.01
 ---- batch: 030 ----
mean loss: 55.28
train mean loss: 55.22
epoch train time: 0:00:00.585907
elapsed time: 0:01:44.033740
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:16:30.450870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.49
 ---- batch: 020 ----
mean loss: 54.47
 ---- batch: 030 ----
mean loss: 56.15
train mean loss: 54.25
epoch train time: 0:00:00.592341
elapsed time: 0:01:44.626543
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:16:31.043665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.06
 ---- batch: 020 ----
mean loss: 52.00
 ---- batch: 030 ----
mean loss: 52.48
train mean loss: 53.40
epoch train time: 0:00:00.597099
elapsed time: 0:01:45.224012
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:16:31.641132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.71
 ---- batch: 020 ----
mean loss: 53.23
 ---- batch: 030 ----
mean loss: 53.50
train mean loss: 53.57
epoch train time: 0:00:00.602148
elapsed time: 0:01:45.826686
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:16:32.243811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.46
 ---- batch: 020 ----
mean loss: 54.27
 ---- batch: 030 ----
mean loss: 51.36
train mean loss: 52.55
epoch train time: 0:00:00.601684
elapsed time: 0:01:46.428904
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:16:32.846057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.32
 ---- batch: 020 ----
mean loss: 51.55
 ---- batch: 030 ----
mean loss: 51.58
train mean loss: 52.62
epoch train time: 0:00:00.594691
elapsed time: 0:01:47.023964
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:16:33.441083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.42
 ---- batch: 020 ----
mean loss: 50.73
 ---- batch: 030 ----
mean loss: 52.71
train mean loss: 51.91
epoch train time: 0:00:00.626317
elapsed time: 0:01:47.650684
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:16:34.067828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.91
 ---- batch: 020 ----
mean loss: 49.31
 ---- batch: 030 ----
mean loss: 50.19
train mean loss: 51.20
epoch train time: 0:00:00.603190
elapsed time: 0:01:48.254312
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:16:34.671503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.01
 ---- batch: 020 ----
mean loss: 51.05
 ---- batch: 030 ----
mean loss: 51.85
train mean loss: 50.74
epoch train time: 0:00:00.605169
elapsed time: 0:01:48.859899
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:16:35.277032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.07
 ---- batch: 020 ----
mean loss: 50.75
 ---- batch: 030 ----
mean loss: 48.76
train mean loss: 50.42
epoch train time: 0:00:00.611085
elapsed time: 0:01:49.471394
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:16:35.888539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.96
 ---- batch: 020 ----
mean loss: 48.11
 ---- batch: 030 ----
mean loss: 50.78
train mean loss: 50.03
epoch train time: 0:00:00.587438
elapsed time: 0:01:50.059215
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:16:36.476332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.84
 ---- batch: 020 ----
mean loss: 49.72
 ---- batch: 030 ----
mean loss: 50.31
train mean loss: 49.55
epoch train time: 0:00:00.625918
elapsed time: 0:01:50.685504
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:16:37.102624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.51
 ---- batch: 020 ----
mean loss: 45.89
 ---- batch: 030 ----
mean loss: 49.26
train mean loss: 48.39
epoch train time: 0:00:00.595898
elapsed time: 0:01:51.281781
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:16:37.698901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.30
 ---- batch: 020 ----
mean loss: 51.46
 ---- batch: 030 ----
mean loss: 51.99
train mean loss: 51.30
epoch train time: 0:00:00.576829
elapsed time: 0:01:51.859061
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:16:38.276188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.37
 ---- batch: 020 ----
mean loss: 49.54
 ---- batch: 030 ----
mean loss: 49.08
train mean loss: 49.65
epoch train time: 0:00:00.583054
elapsed time: 0:01:52.442603
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:16:38.859771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.90
 ---- batch: 020 ----
mean loss: 47.39
 ---- batch: 030 ----
mean loss: 47.16
train mean loss: 47.35
epoch train time: 0:00:00.603986
elapsed time: 0:01:53.047006
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:16:39.464139
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.25
 ---- batch: 020 ----
mean loss: 46.66
 ---- batch: 030 ----
mean loss: 47.97
train mean loss: 47.33
epoch train time: 0:00:00.606218
elapsed time: 0:01:53.653593
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:16:40.070725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.54
 ---- batch: 020 ----
mean loss: 48.29
 ---- batch: 030 ----
mean loss: 45.76
train mean loss: 47.62
epoch train time: 0:00:00.578437
elapsed time: 0:01:54.232375
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:16:40.649491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.99
 ---- batch: 020 ----
mean loss: 46.29
 ---- batch: 030 ----
mean loss: 46.90
train mean loss: 46.65
epoch train time: 0:00:00.595896
elapsed time: 0:01:54.828716
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:16:41.245898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.54
 ---- batch: 020 ----
mean loss: 46.85
 ---- batch: 030 ----
mean loss: 47.13
train mean loss: 46.64
epoch train time: 0:00:00.604173
elapsed time: 0:01:55.433493
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:16:41.850549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.39
 ---- batch: 020 ----
mean loss: 46.21
 ---- batch: 030 ----
mean loss: 47.79
train mean loss: 46.08
epoch train time: 0:00:00.594532
elapsed time: 0:01:56.028316
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:16:42.445462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.37
 ---- batch: 020 ----
mean loss: 46.95
 ---- batch: 030 ----
mean loss: 46.67
train mean loss: 46.90
epoch train time: 0:00:00.592826
elapsed time: 0:01:56.621505
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:16:43.038622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.90
 ---- batch: 020 ----
mean loss: 44.41
 ---- batch: 030 ----
mean loss: 45.92
train mean loss: 45.06
epoch train time: 0:00:00.582641
elapsed time: 0:01:57.204480
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:16:43.621595
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.46
 ---- batch: 020 ----
mean loss: 46.64
 ---- batch: 030 ----
mean loss: 46.80
train mean loss: 45.21
epoch train time: 0:00:00.583399
elapsed time: 0:01:57.788278
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:16:44.205390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.31
 ---- batch: 020 ----
mean loss: 44.33
 ---- batch: 030 ----
mean loss: 43.72
train mean loss: 44.38
epoch train time: 0:00:00.583619
elapsed time: 0:01:58.372269
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:16:44.789391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.02
 ---- batch: 020 ----
mean loss: 40.81
 ---- batch: 030 ----
mean loss: 43.31
train mean loss: 42.91
epoch train time: 0:00:00.579654
elapsed time: 0:01:58.952264
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:16:45.369373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.80
 ---- batch: 020 ----
mean loss: 42.60
 ---- batch: 030 ----
mean loss: 42.93
train mean loss: 43.24
epoch train time: 0:00:00.591585
elapsed time: 0:01:59.544207
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:16:45.961341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.13
 ---- batch: 020 ----
mean loss: 44.07
 ---- batch: 030 ----
mean loss: 41.58
train mean loss: 42.95
epoch train time: 0:00:00.591792
elapsed time: 0:02:00.136468
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:16:46.553632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.51
 ---- batch: 020 ----
mean loss: 45.50
 ---- batch: 030 ----
mean loss: 41.96
train mean loss: 42.71
epoch train time: 0:00:00.593413
elapsed time: 0:02:00.730320
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:16:47.147464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.37
 ---- batch: 020 ----
mean loss: 42.72
 ---- batch: 030 ----
mean loss: 44.86
train mean loss: 42.88
epoch train time: 0:00:00.582943
elapsed time: 0:02:01.313658
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:16:47.730785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.88
 ---- batch: 020 ----
mean loss: 42.69
 ---- batch: 030 ----
mean loss: 39.93
train mean loss: 41.55
epoch train time: 0:00:00.595834
elapsed time: 0:02:01.909877
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:16:48.327013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.44
 ---- batch: 020 ----
mean loss: 42.10
 ---- batch: 030 ----
mean loss: 40.42
train mean loss: 41.84
epoch train time: 0:00:00.592078
elapsed time: 0:02:02.502332
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:16:48.919451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.83
 ---- batch: 020 ----
mean loss: 40.72
 ---- batch: 030 ----
mean loss: 42.30
train mean loss: 41.43
epoch train time: 0:00:00.604794
elapsed time: 0:02:03.107480
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:16:49.524605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.30
 ---- batch: 020 ----
mean loss: 40.58
 ---- batch: 030 ----
mean loss: 42.87
train mean loss: 41.25
epoch train time: 0:00:00.611107
elapsed time: 0:02:03.718984
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:16:50.136128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.03
 ---- batch: 020 ----
mean loss: 40.08
 ---- batch: 030 ----
mean loss: 40.81
train mean loss: 40.37
epoch train time: 0:00:00.595391
elapsed time: 0:02:04.314742
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:16:50.731881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.20
 ---- batch: 020 ----
mean loss: 39.58
 ---- batch: 030 ----
mean loss: 40.34
train mean loss: 39.87
epoch train time: 0:00:00.599351
elapsed time: 0:02:04.914462
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:16:51.331579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.31
 ---- batch: 020 ----
mean loss: 40.61
 ---- batch: 030 ----
mean loss: 38.89
train mean loss: 40.00
epoch train time: 0:00:00.588351
elapsed time: 0:02:05.503199
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:16:51.920315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.68
 ---- batch: 020 ----
mean loss: 39.91
 ---- batch: 030 ----
mean loss: 41.04
train mean loss: 39.80
epoch train time: 0:00:00.581881
elapsed time: 0:02:06.085427
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:16:52.502537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.43
 ---- batch: 020 ----
mean loss: 37.39
 ---- batch: 030 ----
mean loss: 40.43
train mean loss: 38.63
epoch train time: 0:00:00.608580
elapsed time: 0:02:06.694333
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:16:53.111446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.31
 ---- batch: 020 ----
mean loss: 40.46
 ---- batch: 030 ----
mean loss: 37.97
train mean loss: 39.00
epoch train time: 0:00:00.587389
elapsed time: 0:02:07.282069
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:16:53.699226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.03
 ---- batch: 020 ----
mean loss: 37.40
 ---- batch: 030 ----
mean loss: 38.81
train mean loss: 38.44
epoch train time: 0:00:00.591363
elapsed time: 0:02:07.873852
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:16:54.290970
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.23
 ---- batch: 020 ----
mean loss: 39.45
 ---- batch: 030 ----
mean loss: 37.80
train mean loss: 38.65
epoch train time: 0:00:00.592699
elapsed time: 0:02:08.466891
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:16:54.884003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.98
 ---- batch: 020 ----
mean loss: 38.69
 ---- batch: 030 ----
mean loss: 35.83
train mean loss: 37.17
epoch train time: 0:00:00.582000
elapsed time: 0:02:09.049212
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:16:55.466325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.99
 ---- batch: 020 ----
mean loss: 38.03
 ---- batch: 030 ----
mean loss: 37.54
train mean loss: 37.28
epoch train time: 0:00:00.598232
elapsed time: 0:02:09.647782
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:16:56.064903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.12
 ---- batch: 020 ----
mean loss: 38.15
 ---- batch: 030 ----
mean loss: 36.31
train mean loss: 36.93
epoch train time: 0:00:00.592598
elapsed time: 0:02:10.240769
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:16:56.657950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.50
 ---- batch: 020 ----
mean loss: 35.63
 ---- batch: 030 ----
mean loss: 37.55
train mean loss: 36.92
epoch train time: 0:00:00.587046
elapsed time: 0:02:10.828225
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:16:57.245341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.38
 ---- batch: 020 ----
mean loss: 34.30
 ---- batch: 030 ----
mean loss: 37.85
train mean loss: 36.81
epoch train time: 0:00:00.582261
elapsed time: 0:02:11.410898
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:16:57.828014
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.42
 ---- batch: 020 ----
mean loss: 37.82
 ---- batch: 030 ----
mean loss: 37.70
train mean loss: 37.03
epoch train time: 0:00:00.579817
elapsed time: 0:02:11.991204
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:16:58.408291
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.79
 ---- batch: 020 ----
mean loss: 36.85
 ---- batch: 030 ----
mean loss: 33.44
train mean loss: 35.23
epoch train time: 0:00:00.584842
elapsed time: 0:02:12.576374
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:16:58.993490
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.82
 ---- batch: 020 ----
mean loss: 35.07
 ---- batch: 030 ----
mean loss: 34.71
train mean loss: 35.45
epoch train time: 0:00:00.581077
elapsed time: 0:02:13.157788
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:16:59.574906
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.42
 ---- batch: 020 ----
mean loss: 34.69
 ---- batch: 030 ----
mean loss: 36.13
train mean loss: 35.35
epoch train time: 0:00:00.593554
elapsed time: 0:02:13.751711
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:17:00.168828
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.35
 ---- batch: 020 ----
mean loss: 35.54
 ---- batch: 030 ----
mean loss: 34.43
train mean loss: 35.31
epoch train time: 0:00:00.596677
elapsed time: 0:02:14.348791
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:17:00.765908
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.34
 ---- batch: 020 ----
mean loss: 34.82
 ---- batch: 030 ----
mean loss: 35.95
train mean loss: 35.04
epoch train time: 0:00:00.594025
elapsed time: 0:02:14.943156
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:17:01.360273
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.75
 ---- batch: 020 ----
mean loss: 35.60
 ---- batch: 030 ----
mean loss: 34.37
train mean loss: 34.94
epoch train time: 0:00:00.596277
elapsed time: 0:02:15.539784
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:17:01.956937
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.43
 ---- batch: 020 ----
mean loss: 35.29
 ---- batch: 030 ----
mean loss: 34.49
train mean loss: 34.74
epoch train time: 0:00:00.589653
elapsed time: 0:02:16.129859
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:17:02.546982
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.13
 ---- batch: 020 ----
mean loss: 35.45
 ---- batch: 030 ----
mean loss: 34.39
train mean loss: 35.05
epoch train time: 0:00:00.605878
elapsed time: 0:02:16.736091
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:17:03.153207
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.69
 ---- batch: 020 ----
mean loss: 34.68
 ---- batch: 030 ----
mean loss: 35.50
train mean loss: 34.85
epoch train time: 0:00:00.611641
elapsed time: 0:02:17.348158
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:17:03.765276
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.05
 ---- batch: 020 ----
mean loss: 34.21
 ---- batch: 030 ----
mean loss: 33.42
train mean loss: 34.71
epoch train time: 0:00:00.597140
elapsed time: 0:02:17.945881
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:17:04.363006
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.81
 ---- batch: 020 ----
mean loss: 36.16
 ---- batch: 030 ----
mean loss: 34.66
train mean loss: 34.80
epoch train time: 0:00:00.593356
elapsed time: 0:02:18.539580
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:17:04.956698
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.54
 ---- batch: 020 ----
mean loss: 32.23
 ---- batch: 030 ----
mean loss: 34.55
train mean loss: 34.58
epoch train time: 0:00:00.591046
elapsed time: 0:02:19.130991
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:17:05.548102
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.02
 ---- batch: 020 ----
mean loss: 35.43
 ---- batch: 030 ----
mean loss: 34.42
train mean loss: 34.74
epoch train time: 0:00:00.585732
elapsed time: 0:02:19.717078
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:17:06.134189
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.55
 ---- batch: 020 ----
mean loss: 33.99
 ---- batch: 030 ----
mean loss: 36.06
train mean loss: 34.57
epoch train time: 0:00:00.576849
elapsed time: 0:02:20.294259
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:17:06.711390
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.53
 ---- batch: 020 ----
mean loss: 34.99
 ---- batch: 030 ----
mean loss: 33.16
train mean loss: 34.67
epoch train time: 0:00:00.595143
elapsed time: 0:02:20.889750
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:17:07.306859
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.42
 ---- batch: 020 ----
mean loss: 34.32
 ---- batch: 030 ----
mean loss: 36.05
train mean loss: 34.61
epoch train time: 0:00:00.590946
elapsed time: 0:02:21.481069
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:17:07.898208
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.57
 ---- batch: 020 ----
mean loss: 35.71
 ---- batch: 030 ----
mean loss: 32.46
train mean loss: 34.68
epoch train time: 0:00:00.586051
elapsed time: 0:02:22.067476
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:17:08.484602
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.02
 ---- batch: 020 ----
mean loss: 36.48
 ---- batch: 030 ----
mean loss: 34.07
train mean loss: 34.53
epoch train time: 0:00:00.594445
elapsed time: 0:02:22.662285
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:17:09.079395
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.19
 ---- batch: 020 ----
mean loss: 34.07
 ---- batch: 030 ----
mean loss: 36.05
train mean loss: 34.57
epoch train time: 0:00:00.579116
elapsed time: 0:02:23.241724
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:17:09.658838
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.11
 ---- batch: 020 ----
mean loss: 33.82
 ---- batch: 030 ----
mean loss: 35.60
train mean loss: 34.47
epoch train time: 0:00:00.594394
elapsed time: 0:02:23.836457
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:17:10.253577
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.26
 ---- batch: 020 ----
mean loss: 34.41
 ---- batch: 030 ----
mean loss: 34.29
train mean loss: 34.61
epoch train time: 0:00:00.593364
elapsed time: 0:02:24.430234
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:17:10.847394
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.17
 ---- batch: 020 ----
mean loss: 33.85
 ---- batch: 030 ----
mean loss: 36.07
train mean loss: 34.18
epoch train time: 0:00:00.603294
elapsed time: 0:02:25.033915
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:17:11.451062
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.05
 ---- batch: 020 ----
mean loss: 33.08
 ---- batch: 030 ----
mean loss: 35.65
train mean loss: 34.23
epoch train time: 0:00:00.596987
elapsed time: 0:02:25.631283
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:17:12.048399
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.99
 ---- batch: 020 ----
mean loss: 33.49
 ---- batch: 030 ----
mean loss: 33.70
train mean loss: 34.45
epoch train time: 0:00:00.586175
elapsed time: 0:02:26.217796
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:17:12.634943
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.13
 ---- batch: 020 ----
mean loss: 33.63
 ---- batch: 030 ----
mean loss: 32.95
train mean loss: 34.44
epoch train time: 0:00:00.602014
elapsed time: 0:02:26.820291
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:17:13.237411
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.61
 ---- batch: 020 ----
mean loss: 34.67
 ---- batch: 030 ----
mean loss: 34.49
train mean loss: 34.72
epoch train time: 0:00:00.593520
elapsed time: 0:02:27.414208
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:17:13.831336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.42
 ---- batch: 020 ----
mean loss: 33.09
 ---- batch: 030 ----
mean loss: 34.43
train mean loss: 34.22
epoch train time: 0:00:00.593186
elapsed time: 0:02:28.007758
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:17:14.424878
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.17
 ---- batch: 020 ----
mean loss: 34.50
 ---- batch: 030 ----
mean loss: 34.99
train mean loss: 34.34
epoch train time: 0:00:00.591893
elapsed time: 0:02:28.600052
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:17:15.017189
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.88
 ---- batch: 020 ----
mean loss: 35.14
 ---- batch: 030 ----
mean loss: 33.60
train mean loss: 34.14
epoch train time: 0:00:00.582394
elapsed time: 0:02:29.182839
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:17:15.599995
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.70
 ---- batch: 020 ----
mean loss: 33.47
 ---- batch: 030 ----
mean loss: 34.13
train mean loss: 34.37
epoch train time: 0:00:00.587817
elapsed time: 0:02:29.771140
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:17:16.188276
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.90
 ---- batch: 020 ----
mean loss: 34.82
 ---- batch: 030 ----
mean loss: 33.34
train mean loss: 33.69
epoch train time: 0:00:00.590884
elapsed time: 0:02:30.362473
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:17:16.779612
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.00
 ---- batch: 020 ----
mean loss: 32.94
 ---- batch: 030 ----
mean loss: 33.18
train mean loss: 33.98
epoch train time: 0:00:00.595960
elapsed time: 0:02:30.958891
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:17:17.375962
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.59
 ---- batch: 020 ----
mean loss: 34.76
 ---- batch: 030 ----
mean loss: 33.07
train mean loss: 33.81
epoch train time: 0:00:00.595422
elapsed time: 0:02:31.554685
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:17:17.971851
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.79
 ---- batch: 020 ----
mean loss: 33.11
 ---- batch: 030 ----
mean loss: 34.19
train mean loss: 33.68
epoch train time: 0:00:00.596844
elapsed time: 0:02:32.152014
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:17:18.569149
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.50
 ---- batch: 020 ----
mean loss: 32.99
 ---- batch: 030 ----
mean loss: 34.93
train mean loss: 33.97
epoch train time: 0:00:00.594249
elapsed time: 0:02:32.746643
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:17:19.163765
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.39
 ---- batch: 020 ----
mean loss: 33.90
 ---- batch: 030 ----
mean loss: 32.54
train mean loss: 33.89
epoch train time: 0:00:00.614158
elapsed time: 0:02:33.361239
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:17:19.778367
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.93
 ---- batch: 020 ----
mean loss: 33.30
 ---- batch: 030 ----
mean loss: 33.91
train mean loss: 33.93
epoch train time: 0:00:00.595419
elapsed time: 0:02:33.957079
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:17:20.374231
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.50
 ---- batch: 020 ----
mean loss: 34.51
 ---- batch: 030 ----
mean loss: 32.36
train mean loss: 34.17
epoch train time: 0:00:00.593229
elapsed time: 0:02:34.550703
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:17:20.967859
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.49
 ---- batch: 020 ----
mean loss: 34.34
 ---- batch: 030 ----
mean loss: 33.64
train mean loss: 34.11
epoch train time: 0:00:00.600478
elapsed time: 0:02:35.151581
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:17:21.568703
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.41
 ---- batch: 020 ----
mean loss: 33.94
 ---- batch: 030 ----
mean loss: 33.89
train mean loss: 33.67
epoch train time: 0:00:00.613571
elapsed time: 0:02:35.765502
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:17:22.182653
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.87
 ---- batch: 020 ----
mean loss: 33.00
 ---- batch: 030 ----
mean loss: 33.21
train mean loss: 33.41
epoch train time: 0:00:00.615394
elapsed time: 0:02:36.381317
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:17:22.798489
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.61
 ---- batch: 020 ----
mean loss: 34.98
 ---- batch: 030 ----
mean loss: 33.00
train mean loss: 33.54
epoch train time: 0:00:00.595103
elapsed time: 0:02:36.976901
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:17:23.394073
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.93
 ---- batch: 020 ----
mean loss: 34.52
 ---- batch: 030 ----
mean loss: 34.63
train mean loss: 33.87
epoch train time: 0:00:00.607049
elapsed time: 0:02:37.584367
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:17:24.001504
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.99
 ---- batch: 020 ----
mean loss: 33.95
 ---- batch: 030 ----
mean loss: 32.57
train mean loss: 33.36
epoch train time: 0:00:00.585532
elapsed time: 0:02:38.170359
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:17:24.587471
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.35
 ---- batch: 020 ----
mean loss: 32.53
 ---- batch: 030 ----
mean loss: 34.50
train mean loss: 33.54
epoch train time: 0:00:00.598437
elapsed time: 0:02:38.769150
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:17:25.186275
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.04
 ---- batch: 020 ----
mean loss: 32.13
 ---- batch: 030 ----
mean loss: 33.32
train mean loss: 33.31
epoch train time: 0:00:00.597581
elapsed time: 0:02:39.367113
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:17:25.784244
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.67
 ---- batch: 020 ----
mean loss: 33.84
 ---- batch: 030 ----
mean loss: 32.12
train mean loss: 33.70
epoch train time: 0:00:00.598887
elapsed time: 0:02:39.966387
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:17:26.383508
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.80
 ---- batch: 020 ----
mean loss: 33.73
 ---- batch: 030 ----
mean loss: 34.74
train mean loss: 33.31
epoch train time: 0:00:00.611302
elapsed time: 0:02:40.585990
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_3/checkpoint.pth.tar
**** end time: 2019-09-27 15:17:27.003024 ****
