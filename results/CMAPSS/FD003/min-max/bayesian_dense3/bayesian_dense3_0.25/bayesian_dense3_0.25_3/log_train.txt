Namespace(batch_size=512, dataset='CMAPSS/FD003', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_3', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.25, resume=False, step_size=200, visualize_step=50)
pid: 23494
use_cuda: True
Dataset: CMAPSS/FD003
Building BayesianDense3...
Done.
**** start time: 2019-10-01 14:43:58.898025 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-10-01 14:43:58.907617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4626.70
train mean loss: 4606.26
epoch train time: 0:00:03.852157
elapsed time: 0:00:03.867891
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-10-01 14:44:02.765951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4341.12
train mean loss: 4310.89
epoch train time: 0:00:00.172198
elapsed time: 0:00:04.040240
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-10-01 14:44:02.938343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4012.46
train mean loss: 4008.00
epoch train time: 0:00:00.167666
elapsed time: 0:00:04.208059
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-10-01 14:44:03.106127
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3729.93
train mean loss: 3739.45
epoch train time: 0:00:00.167040
elapsed time: 0:00:04.375215
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-10-01 14:44:03.273293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3551.35
train mean loss: 3522.37
epoch train time: 0:00:00.166240
elapsed time: 0:00:04.541645
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-10-01 14:44:03.439712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3351.77
train mean loss: 3354.95
epoch train time: 0:00:00.173327
elapsed time: 0:00:04.715097
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-10-01 14:44:03.613169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3211.19
train mean loss: 3214.60
epoch train time: 0:00:00.179759
elapsed time: 0:00:04.894980
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-10-01 14:44:03.793061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3099.45
train mean loss: 3087.84
epoch train time: 0:00:00.170874
elapsed time: 0:00:05.066003
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-10-01 14:44:03.964074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2991.32
train mean loss: 2978.19
epoch train time: 0:00:00.169349
elapsed time: 0:00:05.235476
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-10-01 14:44:04.133543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2883.21
train mean loss: 2892.55
epoch train time: 0:00:00.166572
elapsed time: 0:00:05.402162
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-10-01 14:44:04.300229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2809.84
train mean loss: 2815.07
epoch train time: 0:00:00.168424
elapsed time: 0:00:05.570699
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-10-01 14:44:04.468790
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2757.84
train mean loss: 2746.87
epoch train time: 0:00:00.170654
elapsed time: 0:00:05.741501
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-10-01 14:44:04.639572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2684.30
train mean loss: 2676.13
epoch train time: 0:00:00.174518
elapsed time: 0:00:05.916144
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-10-01 14:44:04.814212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2632.72
train mean loss: 2621.44
epoch train time: 0:00:00.169780
elapsed time: 0:00:06.086036
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-10-01 14:44:04.984100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2571.64
train mean loss: 2577.67
epoch train time: 0:00:00.167267
elapsed time: 0:00:06.253434
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-10-01 14:44:05.151504
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2534.12
train mean loss: 2531.25
epoch train time: 0:00:00.167500
elapsed time: 0:00:06.421064
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-10-01 14:44:05.319163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2486.36
train mean loss: 2476.80
epoch train time: 0:00:00.166950
elapsed time: 0:00:06.588169
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-10-01 14:44:05.486237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2446.53
train mean loss: 2448.34
epoch train time: 0:00:00.172658
elapsed time: 0:00:06.760981
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-10-01 14:44:05.659052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2408.26
train mean loss: 2406.74
epoch train time: 0:00:00.170011
elapsed time: 0:00:06.931116
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-10-01 14:44:05.829184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2375.24
train mean loss: 2362.62
epoch train time: 0:00:00.168532
elapsed time: 0:00:07.099802
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-10-01 14:44:05.997887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2327.41
train mean loss: 2342.05
epoch train time: 0:00:00.169554
elapsed time: 0:00:07.269495
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-10-01 14:44:06.167565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2307.28
train mean loss: 2294.72
epoch train time: 0:00:00.167359
elapsed time: 0:00:07.436995
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-10-01 14:44:06.335064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2267.63
train mean loss: 2260.38
epoch train time: 0:00:00.167481
elapsed time: 0:00:07.604595
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-10-01 14:44:06.502662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2228.60
train mean loss: 2227.37
epoch train time: 0:00:00.171622
elapsed time: 0:00:07.776349
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-10-01 14:44:06.674417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2205.07
train mean loss: 2203.23
epoch train time: 0:00:00.177119
elapsed time: 0:00:07.953594
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-10-01 14:44:06.851680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2166.05
train mean loss: 2157.04
epoch train time: 0:00:00.171736
elapsed time: 0:00:08.125477
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-10-01 14:44:07.023564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2148.67
train mean loss: 2139.65
epoch train time: 0:00:00.169442
elapsed time: 0:00:08.295059
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-10-01 14:44:07.193143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2109.64
train mean loss: 2102.48
epoch train time: 0:00:00.167176
elapsed time: 0:00:08.462373
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-10-01 14:44:07.360437
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2068.54
train mean loss: 2075.79
epoch train time: 0:00:00.168325
elapsed time: 0:00:08.630816
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-10-01 14:44:07.528885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2048.45
train mean loss: 2063.43
epoch train time: 0:00:00.172371
elapsed time: 0:00:08.803355
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-10-01 14:44:07.701429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2029.25
train mean loss: 2036.38
epoch train time: 0:00:00.168775
elapsed time: 0:00:08.972259
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-10-01 14:44:07.870326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1983.58
train mean loss: 1984.82
epoch train time: 0:00:00.170147
elapsed time: 0:00:09.142535
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-10-01 14:44:08.040604
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1973.02
train mean loss: 1974.80
epoch train time: 0:00:00.169249
elapsed time: 0:00:09.311910
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-10-01 14:44:08.209978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1937.30
train mean loss: 1938.03
epoch train time: 0:00:00.172210
elapsed time: 0:00:09.484242
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-10-01 14:44:08.382310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1919.34
train mean loss: 1915.46
epoch train time: 0:00:00.170342
elapsed time: 0:00:09.654715
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-10-01 14:44:08.552796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1885.87
train mean loss: 1889.13
epoch train time: 0:00:00.178362
elapsed time: 0:00:09.833223
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-10-01 14:44:08.731296
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1866.85
train mean loss: 1864.90
epoch train time: 0:00:00.173490
elapsed time: 0:00:10.006841
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-10-01 14:44:08.904909
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1834.22
train mean loss: 1843.40
epoch train time: 0:00:00.172723
elapsed time: 0:00:10.179681
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-10-01 14:44:09.077784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1819.96
train mean loss: 1819.28
epoch train time: 0:00:00.174454
elapsed time: 0:00:10.354291
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-10-01 14:44:09.252370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1783.22
train mean loss: 1796.19
epoch train time: 0:00:00.170455
elapsed time: 0:00:10.524887
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-10-01 14:44:09.422956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1756.96
train mean loss: 1762.85
epoch train time: 0:00:00.170168
elapsed time: 0:00:10.695180
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-10-01 14:44:09.593278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1743.84
train mean loss: 1748.05
epoch train time: 0:00:00.182849
elapsed time: 0:00:10.878191
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-10-01 14:44:09.776300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1720.84
train mean loss: 1725.69
epoch train time: 0:00:00.166838
elapsed time: 0:00:11.045190
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-10-01 14:44:09.943278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1696.87
train mean loss: 1686.05
epoch train time: 0:00:00.164112
elapsed time: 0:00:11.209436
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-10-01 14:44:10.107500
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1658.99
train mean loss: 1665.44
epoch train time: 0:00:00.163160
elapsed time: 0:00:11.372707
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-10-01 14:44:10.270771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1630.74
train mean loss: 1638.67
epoch train time: 0:00:00.167067
elapsed time: 0:00:11.539895
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-10-01 14:44:10.437962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1611.02
train mean loss: 1606.86
epoch train time: 0:00:00.168524
elapsed time: 0:00:11.708578
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-10-01 14:44:10.606661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1586.16
train mean loss: 1584.08
epoch train time: 0:00:00.185992
elapsed time: 0:00:11.894708
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-10-01 14:44:10.792802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1557.33
train mean loss: 1563.81
epoch train time: 0:00:00.170680
elapsed time: 0:00:12.065528
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-10-01 14:44:10.963613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1531.81
train mean loss: 1528.81
epoch train time: 0:00:00.168029
elapsed time: 0:00:12.233708
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-10-01 14:44:11.131775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1512.50
train mean loss: 1517.65
epoch train time: 0:00:00.168659
elapsed time: 0:00:12.402478
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-10-01 14:44:11.300548
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1489.29
train mean loss: 1491.66
epoch train time: 0:00:00.172854
elapsed time: 0:00:12.575456
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-10-01 14:44:11.473525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1475.98
train mean loss: 1470.02
epoch train time: 0:00:00.170603
elapsed time: 0:00:12.746180
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-10-01 14:44:11.644247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1438.57
train mean loss: 1436.90
epoch train time: 0:00:00.180199
elapsed time: 0:00:12.926502
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-10-01 14:44:11.824569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1429.44
train mean loss: 1423.13
epoch train time: 0:00:00.184708
elapsed time: 0:00:13.111335
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-10-01 14:44:12.009406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1397.65
train mean loss: 1406.55
epoch train time: 0:00:00.168810
elapsed time: 0:00:13.280277
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-10-01 14:44:12.178342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1389.58
train mean loss: 1390.25
epoch train time: 0:00:00.168104
elapsed time: 0:00:13.448493
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-10-01 14:44:12.346578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1373.24
train mean loss: 1368.69
epoch train time: 0:00:00.188470
elapsed time: 0:00:13.637101
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-10-01 14:44:12.535166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1341.44
train mean loss: 1338.11
epoch train time: 0:00:00.169630
elapsed time: 0:00:13.806875
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-10-01 14:44:12.704945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1324.21
train mean loss: 1330.37
epoch train time: 0:00:00.169464
elapsed time: 0:00:13.976466
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-10-01 14:44:12.874549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1297.10
train mean loss: 1301.26
epoch train time: 0:00:00.167746
elapsed time: 0:00:14.144376
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-10-01 14:44:13.042447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1280.66
train mean loss: 1273.17
epoch train time: 0:00:00.166341
elapsed time: 0:00:14.310835
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-10-01 14:44:13.208912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1268.40
train mean loss: 1275.59
epoch train time: 0:00:00.167629
elapsed time: 0:00:14.478602
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-10-01 14:44:13.376672
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1247.04
train mean loss: 1245.27
epoch train time: 0:00:00.168125
elapsed time: 0:00:14.646850
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-10-01 14:44:13.544917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1229.22
train mean loss: 1232.64
epoch train time: 0:00:00.179060
elapsed time: 0:00:14.826052
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-10-01 14:44:13.724129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1211.94
train mean loss: 1220.08
epoch train time: 0:00:00.177240
elapsed time: 0:00:15.003441
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-10-01 14:44:13.901510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1195.53
train mean loss: 1190.39
epoch train time: 0:00:00.164428
elapsed time: 0:00:15.168594
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-10-01 14:44:14.066672
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1173.17
train mean loss: 1170.24
epoch train time: 0:00:00.163892
elapsed time: 0:00:15.332606
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-10-01 14:44:14.230669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1152.22
train mean loss: 1155.14
epoch train time: 0:00:00.162367
elapsed time: 0:00:15.495095
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-10-01 14:44:14.393161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1151.79
train mean loss: 1146.62
epoch train time: 0:00:00.164956
elapsed time: 0:00:15.660163
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-10-01 14:44:14.558226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1128.66
train mean loss: 1126.59
epoch train time: 0:00:00.169874
elapsed time: 0:00:15.830151
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-10-01 14:44:14.728217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1110.67
train mean loss: 1115.05
epoch train time: 0:00:00.177954
elapsed time: 0:00:16.008237
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-10-01 14:44:14.906311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1096.19
train mean loss: 1094.89
epoch train time: 0:00:00.171405
elapsed time: 0:00:16.179798
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-10-01 14:44:15.077870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1073.52
train mean loss: 1076.32
epoch train time: 0:00:00.170510
elapsed time: 0:00:16.350438
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-10-01 14:44:15.248534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1058.41
train mean loss: 1055.97
epoch train time: 0:00:00.169190
elapsed time: 0:00:16.519815
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-10-01 14:44:15.417901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1047.55
train mean loss: 1047.06
epoch train time: 0:00:00.169182
elapsed time: 0:00:16.689133
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-10-01 14:44:15.587198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1034.53
train mean loss: 1029.19
epoch train time: 0:00:00.171905
elapsed time: 0:00:16.861165
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-10-01 14:44:15.759230
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1014.68
train mean loss: 1012.66
epoch train time: 0:00:00.173942
elapsed time: 0:00:17.035234
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-10-01 14:44:15.933303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 988.44
train mean loss: 991.08
epoch train time: 0:00:00.168980
elapsed time: 0:00:17.204583
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-10-01 14:44:16.102667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 992.92
train mean loss: 983.18
epoch train time: 0:00:00.170502
elapsed time: 0:00:17.375232
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-10-01 14:44:16.273303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 969.51
train mean loss: 971.22
epoch train time: 0:00:00.171862
elapsed time: 0:00:17.547232
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-10-01 14:44:16.445313
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.50
train mean loss: 957.06
epoch train time: 0:00:00.169215
elapsed time: 0:00:17.716602
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-10-01 14:44:16.614674
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 942.38
train mean loss: 940.43
epoch train time: 0:00:00.172540
elapsed time: 0:00:17.889269
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-10-01 14:44:16.787336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 925.32
train mean loss: 922.47
epoch train time: 0:00:00.175831
elapsed time: 0:00:18.065270
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-10-01 14:44:16.963371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 900.91
train mean loss: 907.82
epoch train time: 0:00:00.175959
elapsed time: 0:00:18.241391
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-10-01 14:44:17.139460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 893.53
train mean loss: 895.32
epoch train time: 0:00:00.171009
elapsed time: 0:00:18.412539
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-10-01 14:44:17.310617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 882.99
train mean loss: 887.06
epoch train time: 0:00:00.177525
elapsed time: 0:00:18.590200
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-10-01 14:44:17.488268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 862.43
train mean loss: 858.83
epoch train time: 0:00:00.175778
elapsed time: 0:00:18.766123
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-10-01 14:44:17.664203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 848.13
train mean loss: 846.19
epoch train time: 0:00:00.189818
elapsed time: 0:00:18.956080
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-10-01 14:44:17.854149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 835.39
train mean loss: 838.49
epoch train time: 0:00:00.182759
elapsed time: 0:00:19.138981
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-10-01 14:44:18.037056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 834.15
train mean loss: 825.58
epoch train time: 0:00:00.170282
elapsed time: 0:00:19.309385
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-10-01 14:44:18.207451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 808.38
train mean loss: 810.32
epoch train time: 0:00:00.167240
elapsed time: 0:00:19.476740
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-10-01 14:44:18.374808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 800.82
train mean loss: 799.10
epoch train time: 0:00:00.172136
elapsed time: 0:00:19.649002
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-10-01 14:44:18.547086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 783.97
train mean loss: 780.20
epoch train time: 0:00:00.170123
elapsed time: 0:00:19.819285
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-10-01 14:44:18.717352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 756.92
train mean loss: 756.67
epoch train time: 0:00:00.170272
elapsed time: 0:00:19.989684
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-10-01 14:44:18.887750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 756.50
train mean loss: 748.10
epoch train time: 0:00:00.170981
elapsed time: 0:00:20.160806
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-10-01 14:44:19.058873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 740.03
train mean loss: 740.03
epoch train time: 0:00:00.171955
elapsed time: 0:00:20.332879
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-10-01 14:44:19.230945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 722.94
train mean loss: 731.66
epoch train time: 0:00:00.167593
elapsed time: 0:00:20.500591
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-10-01 14:44:19.398675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 710.01
train mean loss: 710.27
epoch train time: 0:00:00.167469
elapsed time: 0:00:20.668190
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-10-01 14:44:19.566256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 710.30
train mean loss: 705.62
epoch train time: 0:00:00.177640
elapsed time: 0:00:20.845964
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-10-01 14:44:19.744039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 692.22
train mean loss: 690.38
epoch train time: 0:00:00.174326
elapsed time: 0:00:21.020429
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-10-01 14:44:19.918495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 677.16
train mean loss: 680.63
epoch train time: 0:00:00.174239
elapsed time: 0:00:21.194800
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-10-01 14:44:20.092871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 670.22
train mean loss: 667.90
epoch train time: 0:00:00.170089
elapsed time: 0:00:21.365005
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-10-01 14:44:20.263072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 654.32
train mean loss: 658.72
epoch train time: 0:00:00.167776
elapsed time: 0:00:21.532899
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-10-01 14:44:20.430966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 644.12
train mean loss: 641.54
epoch train time: 0:00:00.168085
elapsed time: 0:00:21.701097
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-10-01 14:44:20.599165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 639.88
train mean loss: 637.83
epoch train time: 0:00:00.174508
elapsed time: 0:00:21.875753
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-10-01 14:44:20.773828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 628.24
train mean loss: 627.64
epoch train time: 0:00:00.170450
elapsed time: 0:00:22.046344
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-10-01 14:44:20.944405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 615.43
train mean loss: 615.05
epoch train time: 0:00:00.170024
elapsed time: 0:00:22.216484
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-10-01 14:44:21.114554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 606.65
train mean loss: 603.15
epoch train time: 0:00:00.168109
elapsed time: 0:00:22.384750
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-10-01 14:44:21.282834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 598.26
train mean loss: 594.37
epoch train time: 0:00:00.169348
elapsed time: 0:00:22.554242
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-10-01 14:44:21.452308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 588.46
train mean loss: 587.41
epoch train time: 0:00:00.169617
elapsed time: 0:00:22.723983
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-10-01 14:44:21.622052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 576.47
train mean loss: 584.27
epoch train time: 0:00:00.170290
elapsed time: 0:00:22.894440
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-10-01 14:44:21.792523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 569.09
train mean loss: 567.58
epoch train time: 0:00:00.173268
elapsed time: 0:00:23.067848
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-10-01 14:44:21.965933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 560.77
train mean loss: 560.88
epoch train time: 0:00:00.168195
elapsed time: 0:00:23.236187
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-10-01 14:44:22.134254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 555.45
train mean loss: 553.89
epoch train time: 0:00:00.165417
elapsed time: 0:00:23.401717
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-10-01 14:44:22.299793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 539.49
train mean loss: 538.34
epoch train time: 0:00:00.165514
elapsed time: 0:00:23.567360
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-10-01 14:44:22.465426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 534.82
train mean loss: 531.22
epoch train time: 0:00:00.169925
elapsed time: 0:00:23.737406
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-10-01 14:44:22.635474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 524.43
train mean loss: 524.52
epoch train time: 0:00:00.169753
elapsed time: 0:00:23.907323
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-10-01 14:44:22.805414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 515.45
train mean loss: 518.76
epoch train time: 0:00:00.177958
elapsed time: 0:00:24.085421
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-10-01 14:44:22.983486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 509.89
train mean loss: 506.25
epoch train time: 0:00:00.171153
elapsed time: 0:00:24.256697
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-10-01 14:44:23.154776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 507.06
train mean loss: 501.04
epoch train time: 0:00:00.170513
elapsed time: 0:00:24.427354
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-10-01 14:44:23.325420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 499.74
train mean loss: 497.87
epoch train time: 0:00:00.171023
elapsed time: 0:00:24.598498
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-10-01 14:44:23.496565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 486.06
train mean loss: 483.72
epoch train time: 0:00:00.173532
elapsed time: 0:00:24.772152
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-10-01 14:44:23.670221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 478.31
train mean loss: 479.36
epoch train time: 0:00:00.170890
elapsed time: 0:00:24.943165
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-10-01 14:44:23.841251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.54
train mean loss: 470.91
epoch train time: 0:00:00.167548
elapsed time: 0:00:25.110878
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-10-01 14:44:24.008963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 455.48
train mean loss: 460.17
epoch train time: 0:00:00.169256
elapsed time: 0:00:25.280277
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-10-01 14:44:24.178347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 454.99
train mean loss: 455.60
epoch train time: 0:00:00.173665
elapsed time: 0:00:25.454140
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-10-01 14:44:24.352269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 447.93
train mean loss: 448.75
epoch train time: 0:00:00.168288
elapsed time: 0:00:25.622620
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-10-01 14:44:24.520685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 443.88
train mean loss: 446.10
epoch train time: 0:00:00.169465
elapsed time: 0:00:25.792229
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-10-01 14:44:24.690299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 433.86
train mean loss: 433.71
epoch train time: 0:00:00.170315
elapsed time: 0:00:25.962664
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-10-01 14:44:24.860748
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 426.97
train mean loss: 426.80
epoch train time: 0:00:00.166310
elapsed time: 0:00:26.129103
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-10-01 14:44:25.027167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 420.26
train mean loss: 420.59
epoch train time: 0:00:00.165345
elapsed time: 0:00:26.294558
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-10-01 14:44:25.192622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.68
train mean loss: 414.50
epoch train time: 0:00:00.167817
elapsed time: 0:00:26.462493
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-10-01 14:44:25.360621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 412.94
train mean loss: 414.00
epoch train time: 0:00:00.186396
elapsed time: 0:00:26.649069
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-10-01 14:44:25.547137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 401.07
train mean loss: 400.53
epoch train time: 0:00:00.183121
elapsed time: 0:00:26.832338
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-10-01 14:44:25.730414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 396.11
train mean loss: 395.07
epoch train time: 0:00:00.179042
elapsed time: 0:00:27.011524
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-10-01 14:44:25.909594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 392.68
train mean loss: 390.02
epoch train time: 0:00:00.167253
elapsed time: 0:00:27.178895
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-10-01 14:44:26.076960
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.87
train mean loss: 378.42
epoch train time: 0:00:00.167138
elapsed time: 0:00:27.346156
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-10-01 14:44:26.244229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 379.73
train mean loss: 378.66
epoch train time: 0:00:00.168570
elapsed time: 0:00:27.514854
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-10-01 14:44:26.412922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.97
train mean loss: 372.08
epoch train time: 0:00:00.167067
elapsed time: 0:00:27.682067
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-10-01 14:44:26.580133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.07
train mean loss: 364.46
epoch train time: 0:00:00.168783
elapsed time: 0:00:27.850968
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-10-01 14:44:26.749033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 363.61
train mean loss: 362.06
epoch train time: 0:00:00.167668
elapsed time: 0:00:28.018788
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-10-01 14:44:26.916902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.11
train mean loss: 351.93
epoch train time: 0:00:00.167681
elapsed time: 0:00:28.186660
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-10-01 14:44:27.084728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 349.60
train mean loss: 351.86
epoch train time: 0:00:00.166753
elapsed time: 0:00:28.353535
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-10-01 14:44:27.251603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 343.95
train mean loss: 344.58
epoch train time: 0:00:00.167920
elapsed time: 0:00:28.521579
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-10-01 14:44:27.419655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 334.99
train mean loss: 333.52
epoch train time: 0:00:00.169142
elapsed time: 0:00:28.690864
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-10-01 14:44:27.588928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 333.09
train mean loss: 334.98
epoch train time: 0:00:00.188752
elapsed time: 0:00:28.879755
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-10-01 14:44:27.777825
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.38
train mean loss: 330.26
epoch train time: 0:00:00.182428
elapsed time: 0:00:29.062318
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-10-01 14:44:27.960405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.43
train mean loss: 324.96
epoch train time: 0:00:00.169222
elapsed time: 0:00:29.231697
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-10-01 14:44:28.129777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.82
train mean loss: 323.88
epoch train time: 0:00:00.170378
elapsed time: 0:00:29.402207
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-10-01 14:44:28.300274
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.12
train mean loss: 311.64
epoch train time: 0:00:00.173238
elapsed time: 0:00:29.575592
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-10-01 14:44:28.473676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 310.77
train mean loss: 309.38
epoch train time: 0:00:00.169239
elapsed time: 0:00:29.744998
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-10-01 14:44:28.643066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.62
train mean loss: 307.25
epoch train time: 0:00:00.173756
elapsed time: 0:00:29.918878
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-10-01 14:44:28.816947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 302.14
train mean loss: 300.02
epoch train time: 0:00:00.167190
elapsed time: 0:00:30.086181
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-10-01 14:44:28.984246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.17
train mean loss: 297.00
epoch train time: 0:00:00.165114
elapsed time: 0:00:30.251421
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-10-01 14:44:29.149489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.65
train mean loss: 291.59
epoch train time: 0:00:00.163427
elapsed time: 0:00:30.414983
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-10-01 14:44:29.313044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 285.24
train mean loss: 285.15
epoch train time: 0:00:00.173857
elapsed time: 0:00:30.588954
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-10-01 14:44:29.487021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.23
train mean loss: 285.85
epoch train time: 0:00:00.167986
elapsed time: 0:00:30.757063
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-10-01 14:44:29.655133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.75
train mean loss: 282.72
epoch train time: 0:00:00.188715
elapsed time: 0:00:30.945917
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-10-01 14:44:29.843980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.49
train mean loss: 279.28
epoch train time: 0:00:00.177717
elapsed time: 0:00:31.123775
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-10-01 14:44:30.021856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.88
train mean loss: 274.94
epoch train time: 0:00:00.165020
elapsed time: 0:00:31.288929
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-10-01 14:44:30.186993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.21
train mean loss: 270.72
epoch train time: 0:00:00.160972
elapsed time: 0:00:31.450002
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-10-01 14:44:30.348063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.30
train mean loss: 263.66
epoch train time: 0:00:00.168580
elapsed time: 0:00:31.618702
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-10-01 14:44:30.516770
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.02
train mean loss: 265.00
epoch train time: 0:00:00.173228
elapsed time: 0:00:31.792071
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-10-01 14:44:30.690158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.05
train mean loss: 258.42
epoch train time: 0:00:00.178392
elapsed time: 0:00:31.970603
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-10-01 14:44:30.868670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.71
train mean loss: 251.52
epoch train time: 0:00:00.170888
elapsed time: 0:00:32.141607
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-10-01 14:44:31.039675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.14
train mean loss: 250.89
epoch train time: 0:00:00.173312
elapsed time: 0:00:32.315059
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-10-01 14:44:31.213159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.46
train mean loss: 244.08
epoch train time: 0:00:00.169730
elapsed time: 0:00:32.484940
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-10-01 14:44:31.383014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.74
train mean loss: 242.09
epoch train time: 0:00:00.175423
elapsed time: 0:00:32.660510
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-10-01 14:44:31.558579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.83
train mean loss: 240.14
epoch train time: 0:00:00.177167
elapsed time: 0:00:32.837799
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-10-01 14:44:31.735865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.06
train mean loss: 236.45
epoch train time: 0:00:00.171770
elapsed time: 0:00:33.009747
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-10-01 14:44:31.907830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.81
train mean loss: 235.96
epoch train time: 0:00:00.171588
elapsed time: 0:00:33.181492
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-10-01 14:44:32.079560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.89
train mean loss: 232.27
epoch train time: 0:00:00.169463
elapsed time: 0:00:33.351084
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-10-01 14:44:32.249148
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.94
train mean loss: 230.01
epoch train time: 0:00:00.170480
elapsed time: 0:00:33.521701
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-10-01 14:44:32.419778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.57
train mean loss: 225.70
epoch train time: 0:00:00.178584
elapsed time: 0:00:33.700418
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-10-01 14:44:32.598486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.60
train mean loss: 224.13
epoch train time: 0:00:00.189498
elapsed time: 0:00:33.890086
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-10-01 14:44:32.788170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.91
train mean loss: 218.41
epoch train time: 0:00:00.180071
elapsed time: 0:00:34.070307
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-10-01 14:44:32.968382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.16
train mean loss: 216.05
epoch train time: 0:00:00.175845
elapsed time: 0:00:34.246283
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-10-01 14:44:33.144351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.61
train mean loss: 210.69
epoch train time: 0:00:00.169528
elapsed time: 0:00:34.415932
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-10-01 14:44:33.314001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.39
train mean loss: 212.24
epoch train time: 0:00:00.171383
elapsed time: 0:00:34.587462
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-10-01 14:44:33.485539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.43
train mean loss: 207.11
epoch train time: 0:00:00.174337
elapsed time: 0:00:34.761931
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-10-01 14:44:33.660001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.58
train mean loss: 204.67
epoch train time: 0:00:00.171118
elapsed time: 0:00:34.933200
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-10-01 14:44:33.831279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.22
train mean loss: 201.86
epoch train time: 0:00:00.170614
elapsed time: 0:00:35.103940
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-10-01 14:44:34.002015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.08
train mean loss: 196.41
epoch train time: 0:00:00.169676
elapsed time: 0:00:35.273742
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-10-01 14:44:34.171808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.68
train mean loss: 198.32
epoch train time: 0:00:00.167696
elapsed time: 0:00:35.441567
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-10-01 14:44:34.339648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.71
train mean loss: 189.10
epoch train time: 0:00:00.169507
elapsed time: 0:00:35.611206
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-10-01 14:44:34.509272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.30
train mean loss: 190.71
epoch train time: 0:00:00.175418
elapsed time: 0:00:35.786748
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-10-01 14:44:34.684817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.71
train mean loss: 187.13
epoch train time: 0:00:00.175395
elapsed time: 0:00:35.962276
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-10-01 14:44:34.860348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.50
train mean loss: 184.60
epoch train time: 0:00:00.176230
elapsed time: 0:00:36.138634
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-10-01 14:44:35.036708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.50
train mean loss: 183.88
epoch train time: 0:00:00.181161
elapsed time: 0:00:36.319963
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-10-01 14:44:35.218051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.87
train mean loss: 181.59
epoch train time: 0:00:00.177040
elapsed time: 0:00:36.497149
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-10-01 14:44:35.395220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.99
train mean loss: 181.69
epoch train time: 0:00:00.175203
elapsed time: 0:00:36.672498
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-10-01 14:44:35.570571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.72
train mean loss: 176.65
epoch train time: 0:00:00.189874
elapsed time: 0:00:36.862514
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-10-01 14:44:35.760594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.97
train mean loss: 174.38
epoch train time: 0:00:00.177134
elapsed time: 0:00:37.039816
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-10-01 14:44:35.937888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.74
train mean loss: 171.45
epoch train time: 0:00:00.173269
elapsed time: 0:00:37.213251
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-10-01 14:44:36.111360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.22
train mean loss: 173.68
epoch train time: 0:00:00.169147
elapsed time: 0:00:37.382569
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-10-01 14:44:36.280633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.21
train mean loss: 171.23
epoch train time: 0:00:00.173773
elapsed time: 0:00:37.556480
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-10-01 14:44:36.454566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.54
train mean loss: 166.47
epoch train time: 0:00:00.172570
elapsed time: 0:00:37.729239
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-10-01 14:44:36.627326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.80
train mean loss: 162.23
epoch train time: 0:00:00.180066
elapsed time: 0:00:37.909453
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-10-01 14:44:36.807527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.92
train mean loss: 164.88
epoch train time: 0:00:00.177878
elapsed time: 0:00:38.087458
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-10-01 14:44:36.985525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.63
train mean loss: 161.98
epoch train time: 0:00:00.171854
elapsed time: 0:00:38.259430
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-10-01 14:44:37.157501
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 161.58
train mean loss: 160.65
epoch train time: 0:00:00.166965
elapsed time: 0:00:38.426524
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-10-01 14:44:37.324582
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.78
train mean loss: 158.25
epoch train time: 0:00:00.169833
elapsed time: 0:00:38.596466
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-10-01 14:44:37.494548
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 162.95
train mean loss: 161.46
epoch train time: 0:00:00.172852
elapsed time: 0:00:38.769458
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-10-01 14:44:37.667553
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.26
train mean loss: 157.31
epoch train time: 0:00:00.170347
elapsed time: 0:00:38.939955
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-10-01 14:44:37.838023
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 159.52
train mean loss: 158.80
epoch train time: 0:00:00.169279
elapsed time: 0:00:39.109353
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-10-01 14:44:38.007427
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.66
train mean loss: 157.81
epoch train time: 0:00:00.168563
elapsed time: 0:00:39.278062
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-10-01 14:44:38.176136
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 159.75
train mean loss: 158.75
epoch train time: 0:00:00.173946
elapsed time: 0:00:39.452141
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-10-01 14:44:38.350211
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.69
train mean loss: 158.47
epoch train time: 0:00:00.170316
elapsed time: 0:00:39.622577
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-10-01 14:44:38.520645
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 155.08
train mean loss: 155.88
epoch train time: 0:00:00.174822
elapsed time: 0:00:39.797552
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-10-01 14:44:38.695623
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 158.22
train mean loss: 157.51
epoch train time: 0:00:00.182493
elapsed time: 0:00:39.980185
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-10-01 14:44:38.878253
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.46
train mean loss: 157.15
epoch train time: 0:00:00.172786
elapsed time: 0:00:40.153097
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-10-01 14:44:39.051169
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.00
train mean loss: 156.41
epoch train time: 0:00:00.178085
elapsed time: 0:00:40.331313
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-10-01 14:44:39.229399
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.70
train mean loss: 156.94
epoch train time: 0:00:00.182985
elapsed time: 0:00:40.514457
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-10-01 14:44:39.412525
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.50
train mean loss: 156.86
epoch train time: 0:00:00.176962
elapsed time: 0:00:40.691560
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-10-01 14:44:39.589628
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.42
train mean loss: 157.00
epoch train time: 0:00:00.181137
elapsed time: 0:00:40.872827
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-10-01 14:44:39.770895
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.84
train mean loss: 157.08
epoch train time: 0:00:00.173176
elapsed time: 0:00:41.046130
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-10-01 14:44:39.944200
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.24
train mean loss: 156.78
epoch train time: 0:00:00.170902
elapsed time: 0:00:41.217152
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-10-01 14:44:40.115217
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 155.26
train mean loss: 155.49
epoch train time: 0:00:00.171211
elapsed time: 0:00:41.388477
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-10-01 14:44:40.286543
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.52
train mean loss: 156.14
epoch train time: 0:00:00.170124
elapsed time: 0:00:41.558722
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-10-01 14:44:40.456788
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 159.87
train mean loss: 158.01
epoch train time: 0:00:00.190908
elapsed time: 0:00:41.749761
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-10-01 14:44:40.647830
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.24
train mean loss: 156.03
epoch train time: 0:00:00.192181
elapsed time: 0:00:41.942069
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-10-01 14:44:40.840154
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.49
train mean loss: 154.10
epoch train time: 0:00:00.174394
elapsed time: 0:00:42.116611
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-10-01 14:44:41.014683
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.02
train mean loss: 154.14
epoch train time: 0:00:00.175188
elapsed time: 0:00:42.291923
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-10-01 14:44:41.189994
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.46
train mean loss: 155.50
epoch train time: 0:00:00.169952
elapsed time: 0:00:42.461999
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-10-01 14:44:41.360070
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.00
train mean loss: 152.78
epoch train time: 0:00:00.171927
elapsed time: 0:00:42.634054
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-10-01 14:44:41.532122
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.98
train mean loss: 156.82
epoch train time: 0:00:00.170990
elapsed time: 0:00:42.805183
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-10-01 14:44:41.703254
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.38
train mean loss: 153.70
epoch train time: 0:00:00.175783
elapsed time: 0:00:42.981092
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-10-01 14:44:41.879158
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 155.17
train mean loss: 154.35
epoch train time: 0:00:00.174924
elapsed time: 0:00:43.156184
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-10-01 14:44:42.054253
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 155.11
train mean loss: 154.89
epoch train time: 0:00:00.170155
elapsed time: 0:00:43.326460
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-10-01 14:44:42.224528
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 153.00
train mean loss: 153.96
epoch train time: 0:00:00.169414
elapsed time: 0:00:43.496022
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-10-01 14:44:42.394099
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.52
train mean loss: 151.13
epoch train time: 0:00:00.176185
elapsed time: 0:00:43.672341
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-10-01 14:44:42.570408
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 155.13
train mean loss: 153.29
epoch train time: 0:00:00.174465
elapsed time: 0:00:43.846953
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-10-01 14:44:42.745025
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.31
train mean loss: 152.09
epoch train time: 0:00:00.183564
elapsed time: 0:00:44.030668
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-10-01 14:44:42.928729
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 153.35
train mean loss: 152.77
epoch train time: 0:00:00.169658
elapsed time: 0:00:44.200444
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-10-01 14:44:43.098512
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.14
train mean loss: 153.51
epoch train time: 0:00:00.165758
elapsed time: 0:00:44.366323
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-10-01 14:44:43.264419
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 153.20
train mean loss: 153.30
epoch train time: 0:00:00.166916
elapsed time: 0:00:44.533390
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-10-01 14:44:43.431460
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 154.62
train mean loss: 152.44
epoch train time: 0:00:00.168694
elapsed time: 0:00:44.702204
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-10-01 14:44:43.600296
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.48
train mean loss: 151.98
epoch train time: 0:00:00.168848
elapsed time: 0:00:44.871207
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-10-01 14:44:43.769275
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 155.60
train mean loss: 152.97
epoch train time: 0:00:00.171952
elapsed time: 0:00:45.043286
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-10-01 14:44:43.941381
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.99
train mean loss: 151.48
epoch train time: 0:00:00.167193
elapsed time: 0:00:45.210626
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-10-01 14:44:44.108709
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 152.01
train mean loss: 151.96
epoch train time: 0:00:00.165491
elapsed time: 0:00:45.376243
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-10-01 14:44:44.274307
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 152.65
train mean loss: 152.95
epoch train time: 0:00:00.164680
elapsed time: 0:00:45.541034
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-10-01 14:44:44.439101
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 148.56
train mean loss: 148.35
epoch train time: 0:00:00.167297
elapsed time: 0:00:45.708447
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-10-01 14:44:44.606513
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 152.31
train mean loss: 152.98
epoch train time: 0:00:00.169254
elapsed time: 0:00:45.877836
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-10-01 14:44:44.775905
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.91
train mean loss: 150.19
epoch train time: 0:00:00.170892
elapsed time: 0:00:46.048852
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-10-01 14:44:44.946919
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 152.06
train mean loss: 151.63
epoch train time: 0:00:00.168216
elapsed time: 0:00:46.217186
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-10-01 14:44:45.115251
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.93
train mean loss: 150.17
epoch train time: 0:00:00.164374
elapsed time: 0:00:46.381676
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-10-01 14:44:45.279742
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 149.96
train mean loss: 151.15
epoch train time: 0:00:00.168350
elapsed time: 0:00:46.550157
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-10-01 14:44:45.448224
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 150.39
train mean loss: 150.60
epoch train time: 0:00:00.171120
elapsed time: 0:00:46.729627
checkpoint saved in file: log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_3/checkpoint.pth.tar
**** end time: 2019-10-01 14:44:45.627671 ****
