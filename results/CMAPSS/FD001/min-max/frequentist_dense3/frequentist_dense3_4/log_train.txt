Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_4', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32207
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 16:56:45.620072 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:56:45.623418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4144.85
 ---- batch: 020 ----
mean loss: 3919.70
 ---- batch: 030 ----
mean loss: 3907.90
train mean loss: 3972.09
epoch train time: 0:00:12.461281
elapsed time: 0:00:12.467079
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:56:58.087188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3793.91
 ---- batch: 020 ----
mean loss: 3695.71
 ---- batch: 030 ----
mean loss: 3663.22
train mean loss: 3709.28
epoch train time: 0:00:00.172901
elapsed time: 0:00:12.640102
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:56:58.260254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3576.89
 ---- batch: 020 ----
mean loss: 3512.51
 ---- batch: 030 ----
mean loss: 3480.02
train mean loss: 3506.47
epoch train time: 0:00:00.166947
elapsed time: 0:00:12.807229
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:56:58.427343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3374.08
 ---- batch: 020 ----
mean loss: 3305.98
 ---- batch: 030 ----
mean loss: 3299.64
train mean loss: 3324.11
epoch train time: 0:00:00.171802
elapsed time: 0:00:12.979191
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:56:58.599327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3167.98
 ---- batch: 020 ----
mean loss: 3116.16
 ---- batch: 030 ----
mean loss: 3191.60
train mean loss: 3148.10
epoch train time: 0:00:00.173848
elapsed time: 0:00:13.153223
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:56:58.773338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3039.75
 ---- batch: 020 ----
mean loss: 2977.92
 ---- batch: 030 ----
mean loss: 2969.19
train mean loss: 2986.05
epoch train time: 0:00:00.175814
elapsed time: 0:00:13.329180
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:56:58.949300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2902.83
 ---- batch: 020 ----
mean loss: 2828.26
 ---- batch: 030 ----
mean loss: 2777.40
train mean loss: 2825.49
epoch train time: 0:00:00.172257
elapsed time: 0:00:13.501613
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:56:59.121736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2722.83
 ---- batch: 020 ----
mean loss: 2702.52
 ---- batch: 030 ----
mean loss: 2612.90
train mean loss: 2670.24
epoch train time: 0:00:00.170838
elapsed time: 0:00:13.672587
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:56:59.292704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2573.12
 ---- batch: 020 ----
mean loss: 2537.17
 ---- batch: 030 ----
mean loss: 2506.35
train mean loss: 2529.66
epoch train time: 0:00:00.174513
elapsed time: 0:00:13.847247
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:56:59.467362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2458.84
 ---- batch: 020 ----
mean loss: 2398.28
 ---- batch: 030 ----
mean loss: 2373.39
train mean loss: 2397.06
epoch train time: 0:00:00.177003
elapsed time: 0:00:14.024388
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:56:59.644503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2298.80
 ---- batch: 020 ----
mean loss: 2286.07
 ---- batch: 030 ----
mean loss: 2224.96
train mean loss: 2258.74
epoch train time: 0:00:00.176843
elapsed time: 0:00:14.201421
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:56:59.821592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2165.04
 ---- batch: 020 ----
mean loss: 2148.68
 ---- batch: 030 ----
mean loss: 2075.55
train mean loss: 2127.53
epoch train time: 0:00:00.174124
elapsed time: 0:00:14.375735
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:56:59.995858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2056.33
 ---- batch: 020 ----
mean loss: 1998.43
 ---- batch: 030 ----
mean loss: 1999.24
train mean loss: 2003.16
epoch train time: 0:00:00.173291
elapsed time: 0:00:14.549162
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:57:00.169281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1960.81
 ---- batch: 020 ----
mean loss: 1903.58
 ---- batch: 030 ----
mean loss: 1841.37
train mean loss: 1886.84
epoch train time: 0:00:00.178184
elapsed time: 0:00:14.727497
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:57:00.347618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1812.19
 ---- batch: 020 ----
mean loss: 1789.75
 ---- batch: 030 ----
mean loss: 1758.06
train mean loss: 1779.48
epoch train time: 0:00:00.183698
elapsed time: 0:00:14.911370
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:57:00.531486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1704.48
 ---- batch: 020 ----
mean loss: 1677.22
 ---- batch: 030 ----
mean loss: 1664.67
train mean loss: 1676.56
epoch train time: 0:00:00.173794
elapsed time: 0:00:15.085302
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:57:00.705435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1614.62
 ---- batch: 020 ----
mean loss: 1578.98
 ---- batch: 030 ----
mean loss: 1559.71
train mean loss: 1578.80
epoch train time: 0:00:00.174338
elapsed time: 0:00:15.259793
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:57:00.879912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1522.84
 ---- batch: 020 ----
mean loss: 1491.76
 ---- batch: 030 ----
mean loss: 1440.35
train mean loss: 1484.38
epoch train time: 0:00:00.173506
elapsed time: 0:00:15.433468
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:57:01.053584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1429.78
 ---- batch: 020 ----
mean loss: 1405.00
 ---- batch: 030 ----
mean loss: 1365.23
train mean loss: 1393.17
epoch train time: 0:00:00.171867
elapsed time: 0:00:15.605472
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:57:01.225584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1344.50
 ---- batch: 020 ----
mean loss: 1310.61
 ---- batch: 030 ----
mean loss: 1289.20
train mean loss: 1308.96
epoch train time: 0:00:00.170492
elapsed time: 0:00:15.776092
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:57:01.396212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1242.43
 ---- batch: 020 ----
mean loss: 1236.26
 ---- batch: 030 ----
mean loss: 1215.26
train mean loss: 1232.31
epoch train time: 0:00:00.175847
elapsed time: 0:00:15.952074
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:57:01.572198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1173.74
 ---- batch: 020 ----
mean loss: 1190.89
 ---- batch: 030 ----
mean loss: 1144.06
train mean loss: 1159.14
epoch train time: 0:00:00.173175
elapsed time: 0:00:16.125416
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:57:01.745537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1124.31
 ---- batch: 020 ----
mean loss: 1096.70
 ---- batch: 030 ----
mean loss: 1079.83
train mean loss: 1090.87
epoch train time: 0:00:00.178083
elapsed time: 0:00:16.303645
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:57:01.923782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1033.87
 ---- batch: 020 ----
mean loss: 1046.39
 ---- batch: 030 ----
mean loss: 1029.68
train mean loss: 1026.18
epoch train time: 0:00:00.178238
elapsed time: 0:00:16.482103
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:57:02.102260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 998.64
 ---- batch: 020 ----
mean loss: 984.44
 ---- batch: 030 ----
mean loss: 943.48
train mean loss: 965.89
epoch train time: 0:00:00.174860
elapsed time: 0:00:16.657137
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:57:02.277302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 917.59
 ---- batch: 020 ----
mean loss: 929.51
 ---- batch: 030 ----
mean loss: 901.99
train mean loss: 910.28
epoch train time: 0:00:00.174927
elapsed time: 0:00:16.832267
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:57:02.452386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 878.58
 ---- batch: 020 ----
mean loss: 867.47
 ---- batch: 030 ----
mean loss: 827.02
train mean loss: 857.67
epoch train time: 0:00:00.175942
elapsed time: 0:00:17.008344
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:57:02.628475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 830.14
 ---- batch: 020 ----
mean loss: 812.55
 ---- batch: 030 ----
mean loss: 786.26
train mean loss: 806.00
epoch train time: 0:00:00.170439
elapsed time: 0:00:17.178930
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:57:02.799050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 765.54
 ---- batch: 020 ----
mean loss: 782.48
 ---- batch: 030 ----
mean loss: 744.80
train mean loss: 758.52
epoch train time: 0:00:00.179119
elapsed time: 0:00:17.358206
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:57:02.978327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 726.69
 ---- batch: 020 ----
mean loss: 715.97
 ---- batch: 030 ----
mean loss: 705.02
train mean loss: 714.64
epoch train time: 0:00:00.176065
elapsed time: 0:00:17.534412
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:57:03.154523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 684.13
 ---- batch: 020 ----
mean loss: 661.96
 ---- batch: 030 ----
mean loss: 685.58
train mean loss: 673.56
epoch train time: 0:00:00.169102
elapsed time: 0:00:17.703664
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:57:03.323778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 647.30
 ---- batch: 020 ----
mean loss: 641.69
 ---- batch: 030 ----
mean loss: 622.67
train mean loss: 632.89
epoch train time: 0:00:00.174652
elapsed time: 0:00:17.878472
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:57:03.498592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 612.62
 ---- batch: 020 ----
mean loss: 594.08
 ---- batch: 030 ----
mean loss: 578.98
train mean loss: 596.57
epoch train time: 0:00:00.175685
elapsed time: 0:00:18.054324
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:57:03.674470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 574.94
 ---- batch: 020 ----
mean loss: 576.91
 ---- batch: 030 ----
mean loss: 549.09
train mean loss: 562.15
epoch train time: 0:00:00.179112
elapsed time: 0:00:18.233629
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:57:03.853758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 535.14
 ---- batch: 020 ----
mean loss: 535.45
 ---- batch: 030 ----
mean loss: 524.21
train mean loss: 529.59
epoch train time: 0:00:00.181772
elapsed time: 0:00:18.415550
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:57:04.035671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 505.00
 ---- batch: 020 ----
mean loss: 497.53
 ---- batch: 030 ----
mean loss: 504.75
train mean loss: 499.86
epoch train time: 0:00:00.175599
elapsed time: 0:00:18.591290
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:57:04.211411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 481.59
 ---- batch: 020 ----
mean loss: 471.95
 ---- batch: 030 ----
mean loss: 463.71
train mean loss: 470.32
epoch train time: 0:00:00.174145
elapsed time: 0:00:18.765633
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:57:04.385758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 452.86
 ---- batch: 020 ----
mean loss: 441.77
 ---- batch: 030 ----
mean loss: 440.14
train mean loss: 443.68
epoch train time: 0:00:00.176487
elapsed time: 0:00:18.942262
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:57:04.562411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 434.16
 ---- batch: 020 ----
mean loss: 421.92
 ---- batch: 030 ----
mean loss: 411.52
train mean loss: 418.68
epoch train time: 0:00:00.180555
elapsed time: 0:00:19.122982
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:57:04.743102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.96
 ---- batch: 020 ----
mean loss: 390.16
 ---- batch: 030 ----
mean loss: 392.86
train mean loss: 394.94
epoch train time: 0:00:00.174750
elapsed time: 0:00:19.297869
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:57:04.917990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 385.03
 ---- batch: 020 ----
mean loss: 363.26
 ---- batch: 030 ----
mean loss: 370.93
train mean loss: 373.39
epoch train time: 0:00:00.175980
elapsed time: 0:00:19.473990
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:57:05.094113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 355.89
 ---- batch: 020 ----
mean loss: 348.77
 ---- batch: 030 ----
mean loss: 357.29
train mean loss: 352.23
epoch train time: 0:00:00.171051
elapsed time: 0:00:19.645179
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:57:05.265299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 347.77
 ---- batch: 020 ----
mean loss: 334.05
 ---- batch: 030 ----
mean loss: 319.58
train mean loss: 332.96
epoch train time: 0:00:00.170765
elapsed time: 0:00:19.816091
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:57:05.436206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 316.51
 ---- batch: 020 ----
mean loss: 318.55
 ---- batch: 030 ----
mean loss: 311.85
train mean loss: 315.07
epoch train time: 0:00:00.171408
elapsed time: 0:00:19.987629
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:57:05.607750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.78
 ---- batch: 020 ----
mean loss: 294.63
 ---- batch: 030 ----
mean loss: 296.87
train mean loss: 297.81
epoch train time: 0:00:00.175437
elapsed time: 0:00:20.163206
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:57:05.783327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.77
 ---- batch: 020 ----
mean loss: 277.22
 ---- batch: 030 ----
mean loss: 278.34
train mean loss: 282.18
epoch train time: 0:00:00.176196
elapsed time: 0:00:20.339587
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:57:05.959708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.59
 ---- batch: 020 ----
mean loss: 273.50
 ---- batch: 030 ----
mean loss: 264.30
train mean loss: 266.89
epoch train time: 0:00:00.174578
elapsed time: 0:00:20.514322
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:57:06.134443
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.53
 ---- batch: 020 ----
mean loss: 254.23
 ---- batch: 030 ----
mean loss: 255.72
train mean loss: 253.35
epoch train time: 0:00:00.173342
elapsed time: 0:00:20.687813
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:57:06.307934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.47
 ---- batch: 020 ----
mean loss: 239.69
 ---- batch: 030 ----
mean loss: 241.30
train mean loss: 240.91
epoch train time: 0:00:00.175220
elapsed time: 0:00:20.863182
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:57:06.483304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.05
 ---- batch: 020 ----
mean loss: 232.10
 ---- batch: 030 ----
mean loss: 224.85
train mean loss: 229.02
epoch train time: 0:00:00.175074
elapsed time: 0:00:21.038405
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:57:06.658527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.84
 ---- batch: 020 ----
mean loss: 214.29
 ---- batch: 030 ----
mean loss: 218.56
train mean loss: 217.92
epoch train time: 0:00:00.174198
elapsed time: 0:00:21.212819
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:57:06.832992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.78
 ---- batch: 020 ----
mean loss: 208.71
 ---- batch: 030 ----
mean loss: 203.59
train mean loss: 207.84
epoch train time: 0:00:00.174943
elapsed time: 0:00:21.387954
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:57:07.008075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.40
 ---- batch: 020 ----
mean loss: 196.02
 ---- batch: 030 ----
mean loss: 196.48
train mean loss: 197.83
epoch train time: 0:00:00.172354
elapsed time: 0:00:21.560444
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:57:07.180564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.94
 ---- batch: 020 ----
mean loss: 194.18
 ---- batch: 030 ----
mean loss: 186.63
train mean loss: 189.33
epoch train time: 0:00:00.176305
elapsed time: 0:00:21.736888
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:57:07.357008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.74
 ---- batch: 020 ----
mean loss: 177.95
 ---- batch: 030 ----
mean loss: 180.72
train mean loss: 180.98
epoch train time: 0:00:00.173210
elapsed time: 0:00:21.910233
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:57:07.530353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.38
 ---- batch: 020 ----
mean loss: 174.52
 ---- batch: 030 ----
mean loss: 169.30
train mean loss: 173.51
epoch train time: 0:00:00.171945
elapsed time: 0:00:22.082316
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:57:07.702436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.77
 ---- batch: 020 ----
mean loss: 170.73
 ---- batch: 030 ----
mean loss: 163.93
train mean loss: 166.33
epoch train time: 0:00:00.173247
elapsed time: 0:00:22.255703
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:57:07.875825
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.59
 ---- batch: 020 ----
mean loss: 158.51
 ---- batch: 030 ----
mean loss: 161.81
train mean loss: 159.84
epoch train time: 0:00:00.175794
elapsed time: 0:00:22.431670
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:57:08.051791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.71
 ---- batch: 020 ----
mean loss: 154.63
 ---- batch: 030 ----
mean loss: 153.85
train mean loss: 153.73
epoch train time: 0:00:00.176226
elapsed time: 0:00:22.608036
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:57:08.228168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.35
 ---- batch: 020 ----
mean loss: 147.14
 ---- batch: 030 ----
mean loss: 145.51
train mean loss: 147.82
epoch train time: 0:00:00.174214
elapsed time: 0:00:22.782398
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:57:08.402519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.57
 ---- batch: 020 ----
mean loss: 141.81
 ---- batch: 030 ----
mean loss: 142.21
train mean loss: 142.78
epoch train time: 0:00:00.176137
elapsed time: 0:00:22.958674
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:57:08.578795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.40
 ---- batch: 020 ----
mean loss: 137.59
 ---- batch: 030 ----
mean loss: 140.56
train mean loss: 138.16
epoch train time: 0:00:00.175279
elapsed time: 0:00:23.134100
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:57:08.754221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.00
 ---- batch: 020 ----
mean loss: 135.44
 ---- batch: 030 ----
mean loss: 129.85
train mean loss: 133.61
epoch train time: 0:00:00.175106
elapsed time: 0:00:23.309346
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:57:08.929468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.93
 ---- batch: 020 ----
mean loss: 129.97
 ---- batch: 030 ----
mean loss: 129.25
train mean loss: 128.80
epoch train time: 0:00:00.180923
elapsed time: 0:00:23.490422
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:57:09.110558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.16
 ---- batch: 020 ----
mean loss: 123.99
 ---- batch: 030 ----
mean loss: 124.21
train mean loss: 124.97
epoch train time: 0:00:00.178693
elapsed time: 0:00:23.669278
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:57:09.289427
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.23
 ---- batch: 020 ----
mean loss: 121.31
 ---- batch: 030 ----
mean loss: 121.80
train mean loss: 121.19
epoch train time: 0:00:00.182615
elapsed time: 0:00:23.852059
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:57:09.472181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.14
 ---- batch: 020 ----
mean loss: 118.60
 ---- batch: 030 ----
mean loss: 115.92
train mean loss: 117.79
epoch train time: 0:00:00.173947
elapsed time: 0:00:24.026146
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:57:09.646267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.62
 ---- batch: 020 ----
mean loss: 114.53
 ---- batch: 030 ----
mean loss: 115.15
train mean loss: 114.93
epoch train time: 0:00:00.173108
elapsed time: 0:00:24.199392
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:57:09.819512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.03
 ---- batch: 020 ----
mean loss: 110.21
 ---- batch: 030 ----
mean loss: 107.98
train mean loss: 111.48
epoch train time: 0:00:00.174554
elapsed time: 0:00:24.374082
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:57:09.994202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.30
 ---- batch: 020 ----
mean loss: 107.27
 ---- batch: 030 ----
mean loss: 108.66
train mean loss: 108.88
epoch train time: 0:00:00.171435
elapsed time: 0:00:24.545655
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:57:10.165773
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.34
 ---- batch: 020 ----
mean loss: 108.18
 ---- batch: 030 ----
mean loss: 105.55
train mean loss: 106.14
epoch train time: 0:00:00.168898
elapsed time: 0:00:24.714685
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:57:10.334834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.52
 ---- batch: 020 ----
mean loss: 104.78
 ---- batch: 030 ----
mean loss: 101.74
train mean loss: 104.46
epoch train time: 0:00:00.168150
elapsed time: 0:00:24.882997
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:57:10.503117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.35
 ---- batch: 020 ----
mean loss: 101.90
 ---- batch: 030 ----
mean loss: 103.56
train mean loss: 101.45
epoch train time: 0:00:00.169365
elapsed time: 0:00:25.052498
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:57:10.672618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.95
 ---- batch: 020 ----
mean loss: 101.41
 ---- batch: 030 ----
mean loss: 98.62
train mean loss: 99.08
epoch train time: 0:00:00.171136
elapsed time: 0:00:25.223768
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:57:10.843888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.87
 ---- batch: 020 ----
mean loss: 99.90
 ---- batch: 030 ----
mean loss: 97.50
train mean loss: 97.72
epoch train time: 0:00:00.174718
elapsed time: 0:00:25.398622
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:57:11.018743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.71
 ---- batch: 020 ----
mean loss: 94.34
 ---- batch: 030 ----
mean loss: 97.30
train mean loss: 95.76
epoch train time: 0:00:00.173151
elapsed time: 0:00:25.571911
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:57:11.192049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.94
 ---- batch: 020 ----
mean loss: 92.87
 ---- batch: 030 ----
mean loss: 90.09
train mean loss: 93.84
epoch train time: 0:00:00.170329
elapsed time: 0:00:25.742407
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:57:11.362529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.23
 ---- batch: 020 ----
mean loss: 91.76
 ---- batch: 030 ----
mean loss: 92.90
train mean loss: 92.13
epoch train time: 0:00:00.177967
elapsed time: 0:00:25.920510
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:57:11.540631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.05
 ---- batch: 020 ----
mean loss: 89.77
 ---- batch: 030 ----
mean loss: 92.64
train mean loss: 91.03
epoch train time: 0:00:00.170450
elapsed time: 0:00:26.091111
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:57:11.711249
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.81
 ---- batch: 020 ----
mean loss: 88.67
 ---- batch: 030 ----
mean loss: 89.85
train mean loss: 89.35
epoch train time: 0:00:00.179324
elapsed time: 0:00:26.270589
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:57:11.890709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.18
 ---- batch: 020 ----
mean loss: 86.04
 ---- batch: 030 ----
mean loss: 86.78
train mean loss: 88.02
epoch train time: 0:00:00.173359
elapsed time: 0:00:26.444085
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:57:12.064205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.23
 ---- batch: 020 ----
mean loss: 87.54
 ---- batch: 030 ----
mean loss: 88.35
train mean loss: 86.75
epoch train time: 0:00:00.173136
elapsed time: 0:00:26.617357
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:57:12.237506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.32
 ---- batch: 020 ----
mean loss: 87.60
 ---- batch: 030 ----
mean loss: 83.14
train mean loss: 85.54
epoch train time: 0:00:00.168927
elapsed time: 0:00:26.786448
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:57:12.406569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.95
 ---- batch: 020 ----
mean loss: 82.17
 ---- batch: 030 ----
mean loss: 84.07
train mean loss: 84.28
epoch train time: 0:00:00.169323
elapsed time: 0:00:26.955911
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:57:12.576023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.72
 ---- batch: 020 ----
mean loss: 84.88
 ---- batch: 030 ----
mean loss: 84.17
train mean loss: 83.33
epoch train time: 0:00:00.176725
elapsed time: 0:00:27.132777
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:57:12.752891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.79
 ---- batch: 020 ----
mean loss: 84.15
 ---- batch: 030 ----
mean loss: 80.67
train mean loss: 82.31
epoch train time: 0:00:00.173937
elapsed time: 0:00:27.306879
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:57:12.926998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.61
 ---- batch: 020 ----
mean loss: 80.93
 ---- batch: 030 ----
mean loss: 86.16
train mean loss: 82.19
epoch train time: 0:00:00.175014
elapsed time: 0:00:27.482047
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:57:13.102167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.33
 ---- batch: 020 ----
mean loss: 81.52
 ---- batch: 030 ----
mean loss: 77.91
train mean loss: 81.06
epoch train time: 0:00:00.173681
elapsed time: 0:00:27.655896
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:57:13.276026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.35
 ---- batch: 020 ----
mean loss: 76.69
 ---- batch: 030 ----
mean loss: 80.60
train mean loss: 79.86
epoch train time: 0:00:00.174219
elapsed time: 0:00:27.830264
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:57:13.450386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.48
 ---- batch: 020 ----
mean loss: 77.27
 ---- batch: 030 ----
mean loss: 79.98
train mean loss: 79.34
epoch train time: 0:00:00.173833
elapsed time: 0:00:28.004247
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:57:13.624463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.88
 ---- batch: 020 ----
mean loss: 79.08
 ---- batch: 030 ----
mean loss: 78.95
train mean loss: 78.59
epoch train time: 0:00:00.176181
elapsed time: 0:00:28.180666
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:57:13.800789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.26
 ---- batch: 020 ----
mean loss: 79.84
 ---- batch: 030 ----
mean loss: 78.09
train mean loss: 77.75
epoch train time: 0:00:00.180983
elapsed time: 0:00:28.361790
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:57:13.981937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.27
 ---- batch: 020 ----
mean loss: 76.82
 ---- batch: 030 ----
mean loss: 79.27
train mean loss: 78.43
epoch train time: 0:00:00.176518
elapsed time: 0:00:28.538474
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:57:14.158596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.04
 ---- batch: 020 ----
mean loss: 76.09
 ---- batch: 030 ----
mean loss: 78.26
train mean loss: 76.93
epoch train time: 0:00:00.173027
elapsed time: 0:00:28.711661
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:57:14.331785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.09
 ---- batch: 020 ----
mean loss: 75.97
 ---- batch: 030 ----
mean loss: 76.25
train mean loss: 76.58
epoch train time: 0:00:00.174530
elapsed time: 0:00:28.886341
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:57:14.506465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.10
 ---- batch: 020 ----
mean loss: 73.61
 ---- batch: 030 ----
mean loss: 77.46
train mean loss: 75.93
epoch train time: 0:00:00.172850
elapsed time: 0:00:29.059333
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:57:14.679454
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.59
 ---- batch: 020 ----
mean loss: 76.24
 ---- batch: 030 ----
mean loss: 77.54
train mean loss: 75.13
epoch train time: 0:00:00.175566
elapsed time: 0:00:29.235036
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:57:14.855174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.34
 ---- batch: 020 ----
mean loss: 76.47
 ---- batch: 030 ----
mean loss: 76.82
train mean loss: 75.46
epoch train time: 0:00:00.174660
elapsed time: 0:00:29.409864
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:57:15.029988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.19
 ---- batch: 020 ----
mean loss: 74.94
 ---- batch: 030 ----
mean loss: 73.72
train mean loss: 74.64
epoch train time: 0:00:00.171551
elapsed time: 0:00:29.581579
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:57:15.201705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.02
 ---- batch: 020 ----
mean loss: 73.15
 ---- batch: 030 ----
mean loss: 71.18
train mean loss: 74.17
epoch train time: 0:00:00.175506
elapsed time: 0:00:29.757257
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:57:15.377377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.44
 ---- batch: 020 ----
mean loss: 73.43
 ---- batch: 030 ----
mean loss: 70.57
train mean loss: 73.69
epoch train time: 0:00:00.173544
elapsed time: 0:00:29.930941
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:57:15.551063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.14
 ---- batch: 020 ----
mean loss: 72.66
 ---- batch: 030 ----
mean loss: 72.90
train mean loss: 73.47
epoch train time: 0:00:00.179430
elapsed time: 0:00:30.110509
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:57:15.730631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.99
 ---- batch: 020 ----
mean loss: 75.35
 ---- batch: 030 ----
mean loss: 71.97
train mean loss: 73.03
epoch train time: 0:00:00.179501
elapsed time: 0:00:30.290156
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:57:15.910281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.43
 ---- batch: 020 ----
mean loss: 74.31
 ---- batch: 030 ----
mean loss: 72.48
train mean loss: 73.13
epoch train time: 0:00:00.178040
elapsed time: 0:00:30.468384
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:57:16.088536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.94
 ---- batch: 020 ----
mean loss: 70.43
 ---- batch: 030 ----
mean loss: 70.14
train mean loss: 72.76
epoch train time: 0:00:00.175771
elapsed time: 0:00:30.644327
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:57:16.264450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.50
 ---- batch: 020 ----
mean loss: 71.87
 ---- batch: 030 ----
mean loss: 73.52
train mean loss: 72.15
epoch train time: 0:00:00.176833
elapsed time: 0:00:30.821299
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:57:16.441457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.52
 ---- batch: 020 ----
mean loss: 71.97
 ---- batch: 030 ----
mean loss: 69.76
train mean loss: 71.69
epoch train time: 0:00:00.176304
elapsed time: 0:00:30.997791
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:57:16.617903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.82
 ---- batch: 020 ----
mean loss: 71.39
 ---- batch: 030 ----
mean loss: 72.87
train mean loss: 71.08
epoch train time: 0:00:00.181291
elapsed time: 0:00:31.179215
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:57:16.799343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.65
 ---- batch: 020 ----
mean loss: 70.88
 ---- batch: 030 ----
mean loss: 68.18
train mean loss: 70.63
epoch train time: 0:00:00.185557
elapsed time: 0:00:31.364919
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:57:16.985041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.16
 ---- batch: 020 ----
mean loss: 70.85
 ---- batch: 030 ----
mean loss: 72.02
train mean loss: 70.94
epoch train time: 0:00:00.175780
elapsed time: 0:00:31.540839
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:57:17.160958
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.63
 ---- batch: 020 ----
mean loss: 69.77
 ---- batch: 030 ----
mean loss: 71.96
train mean loss: 70.56
epoch train time: 0:00:00.175296
elapsed time: 0:00:31.716273
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:57:17.336394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.60
 ---- batch: 020 ----
mean loss: 68.98
 ---- batch: 030 ----
mean loss: 68.68
train mean loss: 70.07
epoch train time: 0:00:00.173029
elapsed time: 0:00:31.889451
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:57:17.509573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.68
 ---- batch: 020 ----
mean loss: 70.37
 ---- batch: 030 ----
mean loss: 70.40
train mean loss: 69.68
epoch train time: 0:00:00.170451
elapsed time: 0:00:32.060062
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:57:17.680194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.69
 ---- batch: 020 ----
mean loss: 67.60
 ---- batch: 030 ----
mean loss: 70.26
train mean loss: 69.44
epoch train time: 0:00:00.184947
elapsed time: 0:00:32.245159
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:57:17.865281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.95
 ---- batch: 020 ----
mean loss: 67.31
 ---- batch: 030 ----
mean loss: 70.47
train mean loss: 69.33
epoch train time: 0:00:00.175931
elapsed time: 0:00:32.421229
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:57:18.041350
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.07
 ---- batch: 020 ----
mean loss: 68.52
 ---- batch: 030 ----
mean loss: 70.60
train mean loss: 69.84
epoch train time: 0:00:00.172744
elapsed time: 0:00:32.594141
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:57:18.214274
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.46
 ---- batch: 020 ----
mean loss: 68.74
 ---- batch: 030 ----
mean loss: 70.29
train mean loss: 68.71
epoch train time: 0:00:00.172463
elapsed time: 0:00:32.766781
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:57:18.386917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.99
 ---- batch: 020 ----
mean loss: 67.78
 ---- batch: 030 ----
mean loss: 69.45
train mean loss: 68.44
epoch train time: 0:00:00.173453
elapsed time: 0:00:32.940387
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:57:18.560508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.73
 ---- batch: 020 ----
mean loss: 66.80
 ---- batch: 030 ----
mean loss: 68.98
train mean loss: 68.00
epoch train time: 0:00:00.177237
elapsed time: 0:00:33.117767
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:57:18.737897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.06
 ---- batch: 020 ----
mean loss: 67.83
 ---- batch: 030 ----
mean loss: 69.00
train mean loss: 68.09
epoch train time: 0:00:00.179381
elapsed time: 0:00:33.297299
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:57:18.917439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.78
 ---- batch: 020 ----
mean loss: 68.46
 ---- batch: 030 ----
mean loss: 65.35
train mean loss: 67.87
epoch train time: 0:00:00.184287
elapsed time: 0:00:33.481744
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:57:19.101865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.63
 ---- batch: 020 ----
mean loss: 66.23
 ---- batch: 030 ----
mean loss: 68.79
train mean loss: 66.83
epoch train time: 0:00:00.176752
elapsed time: 0:00:33.658642
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:57:19.278772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.47
 ---- batch: 020 ----
mean loss: 67.35
 ---- batch: 030 ----
mean loss: 66.84
train mean loss: 66.70
epoch train time: 0:00:00.183485
elapsed time: 0:00:33.842278
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:57:19.462400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.43
 ---- batch: 020 ----
mean loss: 65.76
 ---- batch: 030 ----
mean loss: 66.18
train mean loss: 66.35
epoch train time: 0:00:00.172774
elapsed time: 0:00:34.015191
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:57:19.635310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.63
 ---- batch: 020 ----
mean loss: 64.62
 ---- batch: 030 ----
mean loss: 67.60
train mean loss: 66.65
epoch train time: 0:00:00.175884
elapsed time: 0:00:34.191212
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:57:19.811333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.35
 ---- batch: 020 ----
mean loss: 64.13
 ---- batch: 030 ----
mean loss: 64.94
train mean loss: 66.21
epoch train time: 0:00:00.182726
elapsed time: 0:00:34.374090
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:57:19.994214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.00
 ---- batch: 020 ----
mean loss: 65.25
 ---- batch: 030 ----
mean loss: 66.96
train mean loss: 65.78
epoch train time: 0:00:00.173633
elapsed time: 0:00:34.547873
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:57:20.167982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.59
 ---- batch: 020 ----
mean loss: 65.47
 ---- batch: 030 ----
mean loss: 66.34
train mean loss: 65.76
epoch train time: 0:00:00.169465
elapsed time: 0:00:34.717470
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:57:20.337589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.96
 ---- batch: 020 ----
mean loss: 65.60
 ---- batch: 030 ----
mean loss: 64.23
train mean loss: 65.43
epoch train time: 0:00:00.170463
elapsed time: 0:00:34.888067
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:57:20.508187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.33
 ---- batch: 020 ----
mean loss: 66.44
 ---- batch: 030 ----
mean loss: 64.30
train mean loss: 65.05
epoch train time: 0:00:00.174444
elapsed time: 0:00:35.062674
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:57:20.682816
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.29
 ---- batch: 020 ----
mean loss: 64.65
 ---- batch: 030 ----
mean loss: 64.80
train mean loss: 65.79
epoch train time: 0:00:00.177427
elapsed time: 0:00:35.240261
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:57:20.860381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.68
 ---- batch: 020 ----
mean loss: 64.77
 ---- batch: 030 ----
mean loss: 65.48
train mean loss: 64.78
epoch train time: 0:00:00.183288
elapsed time: 0:00:35.423690
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:57:21.043811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.56
 ---- batch: 020 ----
mean loss: 66.61
 ---- batch: 030 ----
mean loss: 62.88
train mean loss: 64.87
epoch train time: 0:00:00.175823
elapsed time: 0:00:35.599651
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:57:21.219789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.44
 ---- batch: 020 ----
mean loss: 64.49
 ---- batch: 030 ----
mean loss: 65.48
train mean loss: 65.04
epoch train time: 0:00:00.174545
elapsed time: 0:00:35.774359
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:57:21.394481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.43
 ---- batch: 020 ----
mean loss: 64.00
 ---- batch: 030 ----
mean loss: 64.79
train mean loss: 64.14
epoch train time: 0:00:00.174087
elapsed time: 0:00:35.948583
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:57:21.568703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.57
 ---- batch: 020 ----
mean loss: 62.56
 ---- batch: 030 ----
mean loss: 65.14
train mean loss: 64.20
epoch train time: 0:00:00.176195
elapsed time: 0:00:36.124927
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:57:21.745050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.07
 ---- batch: 020 ----
mean loss: 64.23
 ---- batch: 030 ----
mean loss: 61.92
train mean loss: 64.01
epoch train time: 0:00:00.177375
elapsed time: 0:00:36.302487
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:57:21.922638
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.28
 ---- batch: 020 ----
mean loss: 65.63
 ---- batch: 030 ----
mean loss: 61.41
train mean loss: 64.04
epoch train time: 0:00:00.179257
elapsed time: 0:00:36.481915
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:57:22.102037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.68
 ---- batch: 020 ----
mean loss: 66.70
 ---- batch: 030 ----
mean loss: 63.70
train mean loss: 64.22
epoch train time: 0:00:00.176093
elapsed time: 0:00:36.658149
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:57:22.278270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.59
 ---- batch: 020 ----
mean loss: 65.32
 ---- batch: 030 ----
mean loss: 63.81
train mean loss: 63.46
epoch train time: 0:00:00.175068
elapsed time: 0:00:36.833355
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:57:22.453476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.59
 ---- batch: 020 ----
mean loss: 63.16
 ---- batch: 030 ----
mean loss: 66.40
train mean loss: 64.25
epoch train time: 0:00:00.173873
elapsed time: 0:00:37.007380
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:57:22.627502
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.58
 ---- batch: 020 ----
mean loss: 64.75
 ---- batch: 030 ----
mean loss: 64.06
train mean loss: 64.11
epoch train time: 0:00:00.174475
elapsed time: 0:00:37.182002
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:57:22.802124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.86
 ---- batch: 020 ----
mean loss: 63.36
 ---- batch: 030 ----
mean loss: 65.11
train mean loss: 63.32
epoch train time: 0:00:00.176265
elapsed time: 0:00:37.358425
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:57:22.978545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.88
 ---- batch: 020 ----
mean loss: 62.19
 ---- batch: 030 ----
mean loss: 63.91
train mean loss: 62.78
epoch train time: 0:00:00.180426
elapsed time: 0:00:37.538990
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:57:23.159112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.49
 ---- batch: 020 ----
mean loss: 61.39
 ---- batch: 030 ----
mean loss: 62.76
train mean loss: 62.44
epoch train time: 0:00:00.173424
elapsed time: 0:00:37.712585
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:57:23.332722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.96
 ---- batch: 020 ----
mean loss: 63.32
 ---- batch: 030 ----
mean loss: 60.92
train mean loss: 63.12
epoch train time: 0:00:00.172628
elapsed time: 0:00:37.885382
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:57:23.505502
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.15
 ---- batch: 020 ----
mean loss: 65.47
 ---- batch: 030 ----
mean loss: 61.42
train mean loss: 62.65
epoch train time: 0:00:00.172916
elapsed time: 0:00:38.058444
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:57:23.678612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.90
 ---- batch: 020 ----
mean loss: 62.36
 ---- batch: 030 ----
mean loss: 62.33
train mean loss: 62.11
epoch train time: 0:00:00.180785
elapsed time: 0:00:38.239422
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:57:23.859565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.45
 ---- batch: 020 ----
mean loss: 64.66
 ---- batch: 030 ----
mean loss: 62.29
train mean loss: 63.39
epoch train time: 0:00:00.187115
elapsed time: 0:00:38.426716
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:57:24.046834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.12
 ---- batch: 020 ----
mean loss: 62.99
 ---- batch: 030 ----
mean loss: 61.78
train mean loss: 62.81
epoch train time: 0:00:00.175558
elapsed time: 0:00:38.602410
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:57:24.222532
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.74
 ---- batch: 020 ----
mean loss: 62.24
 ---- batch: 030 ----
mean loss: 60.81
train mean loss: 61.82
epoch train time: 0:00:00.172835
elapsed time: 0:00:38.775386
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:57:24.395508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.48
 ---- batch: 020 ----
mean loss: 61.35
 ---- batch: 030 ----
mean loss: 66.10
train mean loss: 62.08
epoch train time: 0:00:00.173006
elapsed time: 0:00:38.948533
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:57:24.568653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.08
 ---- batch: 020 ----
mean loss: 63.78
 ---- batch: 030 ----
mean loss: 59.28
train mean loss: 61.62
epoch train time: 0:00:00.177441
elapsed time: 0:00:39.126111
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:57:24.746231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.99
 ---- batch: 020 ----
mean loss: 61.59
 ---- batch: 030 ----
mean loss: 62.77
train mean loss: 61.23
epoch train time: 0:00:00.195162
elapsed time: 0:00:39.321427
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:57:24.941561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.80
 ---- batch: 020 ----
mean loss: 63.84
 ---- batch: 030 ----
mean loss: 61.21
train mean loss: 61.84
epoch train time: 0:00:00.177242
elapsed time: 0:00:39.498853
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:57:25.118973
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.27
 ---- batch: 020 ----
mean loss: 61.64
 ---- batch: 030 ----
mean loss: 63.64
train mean loss: 60.95
epoch train time: 0:00:00.177353
elapsed time: 0:00:39.676344
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:57:25.296464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.22
 ---- batch: 020 ----
mean loss: 60.13
 ---- batch: 030 ----
mean loss: 60.81
train mean loss: 60.99
epoch train time: 0:00:00.175343
elapsed time: 0:00:39.851824
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:57:25.471946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.73
 ---- batch: 020 ----
mean loss: 61.12
 ---- batch: 030 ----
mean loss: 61.87
train mean loss: 61.54
epoch train time: 0:00:00.175231
elapsed time: 0:00:40.027194
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:57:25.647315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.02
 ---- batch: 020 ----
mean loss: 62.58
 ---- batch: 030 ----
mean loss: 59.30
train mean loss: 60.71
epoch train time: 0:00:00.183369
elapsed time: 0:00:40.210710
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:57:25.830838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.89
 ---- batch: 020 ----
mean loss: 59.00
 ---- batch: 030 ----
mean loss: 58.76
train mean loss: 60.33
epoch train time: 0:00:00.175871
elapsed time: 0:00:40.386805
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:57:26.006934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.11
 ---- batch: 020 ----
mean loss: 58.76
 ---- batch: 030 ----
mean loss: 63.88
train mean loss: 61.15
epoch train time: 0:00:00.174320
elapsed time: 0:00:40.561270
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:57:26.181406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.99
 ---- batch: 020 ----
mean loss: 58.74
 ---- batch: 030 ----
mean loss: 59.00
train mean loss: 60.48
epoch train time: 0:00:00.170240
elapsed time: 0:00:40.731661
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:57:26.351780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.63
 ---- batch: 020 ----
mean loss: 60.40
 ---- batch: 030 ----
mean loss: 61.98
train mean loss: 60.25
epoch train time: 0:00:00.173190
elapsed time: 0:00:40.904988
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:57:26.525125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.91
 ---- batch: 020 ----
mean loss: 60.32
 ---- batch: 030 ----
mean loss: 58.73
train mean loss: 59.89
epoch train time: 0:00:00.174880
elapsed time: 0:00:41.080023
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:57:26.700143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.35
 ---- batch: 020 ----
mean loss: 59.00
 ---- batch: 030 ----
mean loss: 58.88
train mean loss: 59.90
epoch train time: 0:00:00.176540
elapsed time: 0:00:41.256707
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:57:26.876829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.67
 ---- batch: 020 ----
mean loss: 56.58
 ---- batch: 030 ----
mean loss: 62.07
train mean loss: 59.54
epoch train time: 0:00:00.177081
elapsed time: 0:00:41.433964
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:57:27.054085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.54
 ---- batch: 020 ----
mean loss: 59.24
 ---- batch: 030 ----
mean loss: 57.91
train mean loss: 59.77
epoch train time: 0:00:00.172342
elapsed time: 0:00:41.606458
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:57:27.226577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.43
 ---- batch: 020 ----
mean loss: 59.38
 ---- batch: 030 ----
mean loss: 61.82
train mean loss: 61.02
epoch train time: 0:00:00.172762
elapsed time: 0:00:41.779355
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:57:27.399477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.23
 ---- batch: 020 ----
mean loss: 58.62
 ---- batch: 030 ----
mean loss: 58.26
train mean loss: 59.57
epoch train time: 0:00:00.174010
elapsed time: 0:00:41.953506
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:57:27.573652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.14
 ---- batch: 020 ----
mean loss: 60.93
 ---- batch: 030 ----
mean loss: 58.31
train mean loss: 59.05
epoch train time: 0:00:00.170411
elapsed time: 0:00:42.124088
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:57:27.744210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.50
 ---- batch: 020 ----
mean loss: 58.81
 ---- batch: 030 ----
mean loss: 59.35
train mean loss: 59.12
epoch train time: 0:00:00.177551
elapsed time: 0:00:42.301781
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:57:27.921901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.02
 ---- batch: 020 ----
mean loss: 60.29
 ---- batch: 030 ----
mean loss: 58.84
train mean loss: 60.18
epoch train time: 0:00:00.175491
elapsed time: 0:00:42.477426
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:57:28.097548
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.06
 ---- batch: 020 ----
mean loss: 56.83
 ---- batch: 030 ----
mean loss: 58.94
train mean loss: 58.78
epoch train time: 0:00:00.172598
elapsed time: 0:00:42.650178
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:57:28.270298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.04
 ---- batch: 020 ----
mean loss: 59.97
 ---- batch: 030 ----
mean loss: 59.09
train mean loss: 58.92
epoch train time: 0:00:00.171119
elapsed time: 0:00:42.821448
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:57:28.441579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.88
 ---- batch: 020 ----
mean loss: 59.79
 ---- batch: 030 ----
mean loss: 59.72
train mean loss: 58.26
epoch train time: 0:00:00.172406
elapsed time: 0:00:42.994003
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:57:28.614138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.36
 ---- batch: 020 ----
mean loss: 57.55
 ---- batch: 030 ----
mean loss: 58.95
train mean loss: 58.67
epoch train time: 0:00:00.181779
elapsed time: 0:00:43.175947
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:57:28.796068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.33
 ---- batch: 020 ----
mean loss: 57.53
 ---- batch: 030 ----
mean loss: 60.15
train mean loss: 58.61
epoch train time: 0:00:00.190361
elapsed time: 0:00:43.366476
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:57:28.986613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.89
 ---- batch: 020 ----
mean loss: 57.54
 ---- batch: 030 ----
mean loss: 60.80
train mean loss: 58.58
epoch train time: 0:00:00.175353
elapsed time: 0:00:43.541990
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:57:29.162113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.72
 ---- batch: 020 ----
mean loss: 58.13
 ---- batch: 030 ----
mean loss: 56.30
train mean loss: 57.43
epoch train time: 0:00:00.176580
elapsed time: 0:00:43.718711
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:57:29.338831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.06
 ---- batch: 020 ----
mean loss: 57.21
 ---- batch: 030 ----
mean loss: 57.51
train mean loss: 57.64
epoch train time: 0:00:00.175396
elapsed time: 0:00:43.894245
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:57:29.514375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.76
 ---- batch: 020 ----
mean loss: 57.61
 ---- batch: 030 ----
mean loss: 57.28
train mean loss: 56.97
epoch train time: 0:00:00.174177
elapsed time: 0:00:44.068572
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:57:29.688693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.52
 ---- batch: 020 ----
mean loss: 61.07
 ---- batch: 030 ----
mean loss: 58.33
train mean loss: 58.20
epoch train time: 0:00:00.176991
elapsed time: 0:00:44.245724
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:57:29.865854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.72
 ---- batch: 020 ----
mean loss: 60.04
 ---- batch: 030 ----
mean loss: 56.09
train mean loss: 56.94
epoch train time: 0:00:00.177343
elapsed time: 0:00:44.423215
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:57:30.043336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.42
 ---- batch: 020 ----
mean loss: 56.99
 ---- batch: 030 ----
mean loss: 59.28
train mean loss: 57.27
epoch train time: 0:00:00.175010
elapsed time: 0:00:44.598363
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:57:30.218485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.35
 ---- batch: 020 ----
mean loss: 56.76
 ---- batch: 030 ----
mean loss: 57.20
train mean loss: 56.41
epoch train time: 0:00:00.178187
elapsed time: 0:00:44.776689
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:57:30.396815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.29
 ---- batch: 020 ----
mean loss: 56.78
 ---- batch: 030 ----
mean loss: 57.07
train mean loss: 57.32
epoch train time: 0:00:00.174498
elapsed time: 0:00:44.951329
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:57:30.571451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.95
 ---- batch: 020 ----
mean loss: 58.81
 ---- batch: 030 ----
mean loss: 57.72
train mean loss: 58.75
epoch train time: 0:00:00.174011
elapsed time: 0:00:45.125477
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:57:30.745599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.12
 ---- batch: 020 ----
mean loss: 55.71
 ---- batch: 030 ----
mean loss: 59.26
train mean loss: 56.71
epoch train time: 0:00:00.174354
elapsed time: 0:00:45.299973
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:57:30.920116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.15
 ---- batch: 020 ----
mean loss: 55.35
 ---- batch: 030 ----
mean loss: 56.09
train mean loss: 56.06
epoch train time: 0:00:00.174874
elapsed time: 0:00:45.475031
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:57:31.095167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.37
 ---- batch: 020 ----
mean loss: 55.12
 ---- batch: 030 ----
mean loss: 56.86
train mean loss: 56.02
epoch train time: 0:00:00.172626
elapsed time: 0:00:45.647825
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:57:31.267951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.06
 ---- batch: 020 ----
mean loss: 54.66
 ---- batch: 030 ----
mean loss: 55.40
train mean loss: 55.50
epoch train time: 0:00:00.174314
elapsed time: 0:00:45.822279
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:57:31.442468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.01
 ---- batch: 020 ----
mean loss: 54.06
 ---- batch: 030 ----
mean loss: 55.99
train mean loss: 55.31
epoch train time: 0:00:00.176809
elapsed time: 0:00:45.999293
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:57:31.619414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.55
 ---- batch: 020 ----
mean loss: 54.67
 ---- batch: 030 ----
mean loss: 57.89
train mean loss: 55.41
epoch train time: 0:00:00.175226
elapsed time: 0:00:46.174675
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:57:31.794814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.14
 ---- batch: 020 ----
mean loss: 57.22
 ---- batch: 030 ----
mean loss: 55.69
train mean loss: 55.69
epoch train time: 0:00:00.176254
elapsed time: 0:00:46.351083
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:57:31.971202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.87
 ---- batch: 020 ----
mean loss: 55.31
 ---- batch: 030 ----
mean loss: 56.18
train mean loss: 55.41
epoch train time: 0:00:00.171967
elapsed time: 0:00:46.523180
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:57:32.143315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.37
 ---- batch: 020 ----
mean loss: 56.85
 ---- batch: 030 ----
mean loss: 55.71
train mean loss: 56.30
epoch train time: 0:00:00.168462
elapsed time: 0:00:46.691790
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:57:32.311910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.88
 ---- batch: 020 ----
mean loss: 57.39
 ---- batch: 030 ----
mean loss: 52.26
train mean loss: 55.08
epoch train time: 0:00:00.170184
elapsed time: 0:00:46.862115
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:57:32.482266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.23
 ---- batch: 020 ----
mean loss: 55.75
 ---- batch: 030 ----
mean loss: 53.76
train mean loss: 54.63
epoch train time: 0:00:00.172291
elapsed time: 0:00:47.034571
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:57:32.654691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.82
 ---- batch: 020 ----
mean loss: 54.96
 ---- batch: 030 ----
mean loss: 54.26
train mean loss: 54.15
epoch train time: 0:00:00.180016
elapsed time: 0:00:47.214729
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:57:32.834851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.18
 ---- batch: 020 ----
mean loss: 51.56
 ---- batch: 030 ----
mean loss: 55.82
train mean loss: 54.62
epoch train time: 0:00:00.180680
elapsed time: 0:00:47.395549
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:57:33.015671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.09
 ---- batch: 020 ----
mean loss: 53.68
 ---- batch: 030 ----
mean loss: 55.89
train mean loss: 54.75
epoch train time: 0:00:00.175547
elapsed time: 0:00:47.571232
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:57:33.191353
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.44
 ---- batch: 020 ----
mean loss: 54.30
 ---- batch: 030 ----
mean loss: 54.51
train mean loss: 53.02
epoch train time: 0:00:00.175499
elapsed time: 0:00:47.746888
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:57:33.367034
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.62
 ---- batch: 020 ----
mean loss: 53.35
 ---- batch: 030 ----
mean loss: 52.78
train mean loss: 52.85
epoch train time: 0:00:00.174126
elapsed time: 0:00:47.921176
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:57:33.541310
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.10
 ---- batch: 020 ----
mean loss: 51.13
 ---- batch: 030 ----
mean loss: 53.76
train mean loss: 52.94
epoch train time: 0:00:00.173684
elapsed time: 0:00:48.095016
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:57:33.715153
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.83
 ---- batch: 020 ----
mean loss: 50.96
 ---- batch: 030 ----
mean loss: 53.14
train mean loss: 52.76
epoch train time: 0:00:00.176913
elapsed time: 0:00:48.272127
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:57:33.892250
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.76
 ---- batch: 020 ----
mean loss: 53.49
 ---- batch: 030 ----
mean loss: 52.13
train mean loss: 52.86
epoch train time: 0:00:00.179327
elapsed time: 0:00:48.451611
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:57:34.071732
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.43
 ---- batch: 020 ----
mean loss: 52.95
 ---- batch: 030 ----
mean loss: 52.45
train mean loss: 52.69
epoch train time: 0:00:00.175213
elapsed time: 0:00:48.627003
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:57:34.247173
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.28
 ---- batch: 020 ----
mean loss: 52.76
 ---- batch: 030 ----
mean loss: 52.66
train mean loss: 52.72
epoch train time: 0:00:00.174146
elapsed time: 0:00:48.801354
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:57:34.421476
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.84
 ---- batch: 020 ----
mean loss: 51.91
 ---- batch: 030 ----
mean loss: 51.81
train mean loss: 52.73
epoch train time: 0:00:00.177808
elapsed time: 0:00:48.979301
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:57:34.599437
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.10
 ---- batch: 020 ----
mean loss: 52.79
 ---- batch: 030 ----
mean loss: 51.83
train mean loss: 52.58
epoch train time: 0:00:00.172411
elapsed time: 0:00:49.151867
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:57:34.771988
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.53
 ---- batch: 020 ----
mean loss: 52.79
 ---- batch: 030 ----
mean loss: 54.08
train mean loss: 52.75
epoch train time: 0:00:00.176998
elapsed time: 0:00:49.329034
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:57:34.949169
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.57
 ---- batch: 020 ----
mean loss: 51.36
 ---- batch: 030 ----
mean loss: 50.65
train mean loss: 52.48
epoch train time: 0:00:00.177244
elapsed time: 0:00:49.506434
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:57:35.126568
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.71
 ---- batch: 020 ----
mean loss: 54.43
 ---- batch: 030 ----
mean loss: 52.65
train mean loss: 52.59
epoch train time: 0:00:00.175334
elapsed time: 0:00:49.681940
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:57:35.302062
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.53
 ---- batch: 020 ----
mean loss: 50.35
 ---- batch: 030 ----
mean loss: 53.15
train mean loss: 52.65
epoch train time: 0:00:00.175717
elapsed time: 0:00:49.857797
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:57:35.477933
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.75
 ---- batch: 020 ----
mean loss: 53.01
 ---- batch: 030 ----
mean loss: 51.33
train mean loss: 52.64
epoch train time: 0:00:00.176593
elapsed time: 0:00:50.034543
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:57:35.654680
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.18
 ---- batch: 020 ----
mean loss: 51.55
 ---- batch: 030 ----
mean loss: 55.72
train mean loss: 52.39
epoch train time: 0:00:00.177422
elapsed time: 0:00:50.212130
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:57:35.832258
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.33
 ---- batch: 020 ----
mean loss: 53.24
 ---- batch: 030 ----
mean loss: 50.97
train mean loss: 52.63
epoch train time: 0:00:00.177681
elapsed time: 0:00:50.389962
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:57:36.010084
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.68
 ---- batch: 020 ----
mean loss: 54.07
 ---- batch: 030 ----
mean loss: 53.94
train mean loss: 52.41
epoch train time: 0:00:00.179925
elapsed time: 0:00:50.570031
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:57:36.190152
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.15
 ---- batch: 020 ----
mean loss: 53.10
 ---- batch: 030 ----
mean loss: 50.17
train mean loss: 52.50
epoch train time: 0:00:00.171718
elapsed time: 0:00:50.741891
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:57:36.362012
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.33
 ---- batch: 020 ----
mean loss: 52.74
 ---- batch: 030 ----
mean loss: 53.14
train mean loss: 52.45
epoch train time: 0:00:00.173279
elapsed time: 0:00:50.915313
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:57:36.535431
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.57
 ---- batch: 020 ----
mean loss: 52.69
 ---- batch: 030 ----
mean loss: 54.74
train mean loss: 52.49
epoch train time: 0:00:00.179927
elapsed time: 0:00:51.095378
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:57:36.715502
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.66
 ---- batch: 020 ----
mean loss: 52.06
 ---- batch: 030 ----
mean loss: 53.86
train mean loss: 52.37
epoch train time: 0:00:00.174003
elapsed time: 0:00:51.269521
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:57:36.889667
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.43
 ---- batch: 020 ----
mean loss: 53.08
 ---- batch: 030 ----
mean loss: 51.81
train mean loss: 52.44
epoch train time: 0:00:00.173850
elapsed time: 0:00:51.443532
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:57:37.063651
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.44
 ---- batch: 020 ----
mean loss: 50.98
 ---- batch: 030 ----
mean loss: 55.23
train mean loss: 52.36
epoch train time: 0:00:00.172525
elapsed time: 0:00:51.616191
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:57:37.236311
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.81
 ---- batch: 020 ----
mean loss: 51.19
 ---- batch: 030 ----
mean loss: 52.08
train mean loss: 52.33
epoch train time: 0:00:00.173373
elapsed time: 0:00:51.789704
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:57:37.409897
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.20
 ---- batch: 020 ----
mean loss: 51.21
 ---- batch: 030 ----
mean loss: 52.90
train mean loss: 52.28
epoch train time: 0:00:00.177691
elapsed time: 0:00:51.967603
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:57:37.587723
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.02
 ---- batch: 020 ----
mean loss: 51.52
 ---- batch: 030 ----
mean loss: 50.55
train mean loss: 52.19
epoch train time: 0:00:00.184007
elapsed time: 0:00:52.151755
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:57:37.771878
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.23
 ---- batch: 020 ----
mean loss: 54.22
 ---- batch: 030 ----
mean loss: 51.12
train mean loss: 52.22
epoch train time: 0:00:00.176764
elapsed time: 0:00:52.328661
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:57:37.948781
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.56
 ---- batch: 020 ----
mean loss: 52.28
 ---- batch: 030 ----
mean loss: 51.89
train mean loss: 52.20
epoch train time: 0:00:00.176809
elapsed time: 0:00:52.505633
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:57:38.125788
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.70
 ---- batch: 020 ----
mean loss: 51.05
 ---- batch: 030 ----
mean loss: 52.06
train mean loss: 52.01
epoch train time: 0:00:00.184256
elapsed time: 0:00:52.690064
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:57:38.310185
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.52
 ---- batch: 020 ----
mean loss: 53.96
 ---- batch: 030 ----
mean loss: 51.62
train mean loss: 52.21
epoch train time: 0:00:00.172551
elapsed time: 0:00:52.862764
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:57:38.482890
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.22
 ---- batch: 020 ----
mean loss: 51.44
 ---- batch: 030 ----
mean loss: 51.60
train mean loss: 52.10
epoch train time: 0:00:00.187912
elapsed time: 0:00:53.050829
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:57:38.670956
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.60
 ---- batch: 020 ----
mean loss: 54.06
 ---- batch: 030 ----
mean loss: 50.73
train mean loss: 51.95
epoch train time: 0:00:00.176067
elapsed time: 0:00:53.227051
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:57:38.847181
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.26
 ---- batch: 020 ----
mean loss: 51.70
 ---- batch: 030 ----
mean loss: 51.12
train mean loss: 52.06
epoch train time: 0:00:00.178982
elapsed time: 0:00:53.406210
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:57:39.026318
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.84
 ---- batch: 020 ----
mean loss: 53.07
 ---- batch: 030 ----
mean loss: 50.11
train mean loss: 52.16
epoch train time: 0:00:00.174135
elapsed time: 0:00:53.580469
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:57:39.200588
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.72
 ---- batch: 020 ----
mean loss: 52.15
 ---- batch: 030 ----
mean loss: 50.55
train mean loss: 51.95
epoch train time: 0:00:00.169470
elapsed time: 0:00:53.750076
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:57:39.370197
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.05
 ---- batch: 020 ----
mean loss: 51.06
 ---- batch: 030 ----
mean loss: 52.03
train mean loss: 51.94
epoch train time: 0:00:00.171490
elapsed time: 0:00:53.921703
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:57:39.541822
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.61
 ---- batch: 020 ----
mean loss: 51.99
 ---- batch: 030 ----
mean loss: 51.23
train mean loss: 51.89
epoch train time: 0:00:00.171086
elapsed time: 0:00:54.092971
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:57:39.713092
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.63
 ---- batch: 020 ----
mean loss: 51.61
 ---- batch: 030 ----
mean loss: 51.45
train mean loss: 51.85
epoch train time: 0:00:00.169858
elapsed time: 0:00:54.262968
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:57:39.883088
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.08
 ---- batch: 020 ----
mean loss: 51.91
 ---- batch: 030 ----
mean loss: 50.09
train mean loss: 51.92
epoch train time: 0:00:00.170429
elapsed time: 0:00:54.433555
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:57:40.053694
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.40
 ---- batch: 020 ----
mean loss: 52.79
 ---- batch: 030 ----
mean loss: 51.11
train mean loss: 52.05
epoch train time: 0:00:00.170283
elapsed time: 0:00:54.603992
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:57:40.224110
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.36
 ---- batch: 020 ----
mean loss: 50.71
 ---- batch: 030 ----
mean loss: 53.34
train mean loss: 51.83
epoch train time: 0:00:00.176866
elapsed time: 0:00:54.781002
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:57:40.401133
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.58
 ---- batch: 020 ----
mean loss: 52.42
 ---- batch: 030 ----
mean loss: 50.46
train mean loss: 51.82
epoch train time: 0:00:00.182408
elapsed time: 0:00:54.963558
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:57:40.583696
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.76
 ---- batch: 020 ----
mean loss: 52.06
 ---- batch: 030 ----
mean loss: 51.53
train mean loss: 51.75
epoch train time: 0:00:00.174314
elapsed time: 0:00:55.138028
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:57:40.758149
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.03
 ---- batch: 020 ----
mean loss: 51.83
 ---- batch: 030 ----
mean loss: 52.44
train mean loss: 51.69
epoch train time: 0:00:00.178373
elapsed time: 0:00:55.316539
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:57:40.936670
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.02
 ---- batch: 020 ----
mean loss: 52.25
 ---- batch: 030 ----
mean loss: 52.19
train mean loss: 51.62
epoch train time: 0:00:00.177533
elapsed time: 0:00:55.494221
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:57:41.114342
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.35
 ---- batch: 020 ----
mean loss: 50.93
 ---- batch: 030 ----
mean loss: 51.24
train mean loss: 51.59
epoch train time: 0:00:00.173407
elapsed time: 0:00:55.667765
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:57:41.287886
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.68
 ---- batch: 020 ----
mean loss: 50.40
 ---- batch: 030 ----
mean loss: 51.05
train mean loss: 51.54
epoch train time: 0:00:00.170730
elapsed time: 0:00:55.838632
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:57:41.458753
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.75
 ---- batch: 020 ----
mean loss: 51.32
 ---- batch: 030 ----
mean loss: 48.21
train mean loss: 51.82
epoch train time: 0:00:00.175291
elapsed time: 0:00:56.014063
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:57:41.634199
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.27
 ---- batch: 020 ----
mean loss: 52.09
 ---- batch: 030 ----
mean loss: 53.52
train mean loss: 51.82
epoch train time: 0:00:00.171828
elapsed time: 0:00:56.189306
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_4/checkpoint.pth.tar
**** end time: 2019-09-27 16:57:41.809394 ****
