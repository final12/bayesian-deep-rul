Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_7', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30032
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:26:41.766553 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:26:41.778215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3877.06
 ---- batch: 020 ----
mean loss: 3563.62
 ---- batch: 030 ----
mean loss: 3462.50
train mean loss: 3594.21
epoch train time: 0:00:12.951117
elapsed time: 0:00:12.969621
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:26:54.736215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3211.04
 ---- batch: 020 ----
mean loss: 3050.17
 ---- batch: 030 ----
mean loss: 2961.42
train mean loss: 3049.46
epoch train time: 0:00:00.603068
elapsed time: 0:00:13.572980
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:26:55.339658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2787.73
 ---- batch: 020 ----
mean loss: 2665.20
 ---- batch: 030 ----
mean loss: 2615.30
train mean loss: 2664.32
epoch train time: 0:00:00.610230
elapsed time: 0:00:14.183640
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:26:55.950386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2456.84
 ---- batch: 020 ----
mean loss: 2373.75
 ---- batch: 030 ----
mean loss: 2343.90
train mean loss: 2381.32
epoch train time: 0:00:00.592311
elapsed time: 0:00:14.776396
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:26:56.543046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2215.66
 ---- batch: 020 ----
mean loss: 2143.22
 ---- batch: 030 ----
mean loss: 2186.81
train mean loss: 2171.39
epoch train time: 0:00:00.586616
elapsed time: 0:00:15.363360
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:26:57.130056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2056.70
 ---- batch: 020 ----
mean loss: 2001.17
 ---- batch: 030 ----
mean loss: 1985.44
train mean loss: 2007.78
epoch train time: 0:00:00.579282
elapsed time: 0:00:15.943025
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:26:57.709698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1929.65
 ---- batch: 020 ----
mean loss: 1868.73
 ---- batch: 030 ----
mean loss: 1828.69
train mean loss: 1869.14
epoch train time: 0:00:00.580593
elapsed time: 0:00:16.524010
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:26:58.290666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1786.48
 ---- batch: 020 ----
mean loss: 1768.03
 ---- batch: 030 ----
mean loss: 1701.80
train mean loss: 1745.98
epoch train time: 0:00:00.598040
elapsed time: 0:00:17.122466
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:26:58.889114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1667.35
 ---- batch: 020 ----
mean loss: 1642.91
 ---- batch: 030 ----
mean loss: 1627.38
train mean loss: 1638.47
epoch train time: 0:00:00.585406
elapsed time: 0:00:17.708230
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:26:59.474881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1582.31
 ---- batch: 020 ----
mean loss: 1545.46
 ---- batch: 030 ----
mean loss: 1517.15
train mean loss: 1538.42
epoch train time: 0:00:00.597761
elapsed time: 0:00:18.306399
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:27:00.073056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1467.01
 ---- batch: 020 ----
mean loss: 1477.76
 ---- batch: 030 ----
mean loss: 1430.68
train mean loss: 1450.11
epoch train time: 0:00:00.581955
elapsed time: 0:00:18.888732
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:27:00.655387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1393.04
 ---- batch: 020 ----
mean loss: 1389.31
 ---- batch: 030 ----
mean loss: 1344.52
train mean loss: 1375.07
epoch train time: 0:00:00.595350
elapsed time: 0:00:19.484480
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:27:01.251136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1328.74
 ---- batch: 020 ----
mean loss: 1289.13
 ---- batch: 030 ----
mean loss: 1298.92
train mean loss: 1295.64
epoch train time: 0:00:00.603905
elapsed time: 0:00:20.088827
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:27:01.855483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1276.50
 ---- batch: 020 ----
mean loss: 1230.22
 ---- batch: 030 ----
mean loss: 1185.94
train mean loss: 1220.83
epoch train time: 0:00:00.589150
elapsed time: 0:00:20.678355
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:27:02.445009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1172.25
 ---- batch: 020 ----
mean loss: 1155.61
 ---- batch: 030 ----
mean loss: 1131.32
train mean loss: 1148.95
epoch train time: 0:00:00.596760
elapsed time: 0:00:21.275475
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:27:03.042127
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1104.28
 ---- batch: 020 ----
mean loss: 1083.70
 ---- batch: 030 ----
mean loss: 1073.01
train mean loss: 1082.57
epoch train time: 0:00:00.595560
elapsed time: 0:00:21.871388
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:27:03.638047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1046.09
 ---- batch: 020 ----
mean loss: 1019.07
 ---- batch: 030 ----
mean loss: 1006.83
train mean loss: 1020.47
epoch train time: 0:00:00.601164
elapsed time: 0:00:22.472915
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:27:04.239568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 981.29
 ---- batch: 020 ----
mean loss: 968.20
 ---- batch: 030 ----
mean loss: 930.45
train mean loss: 959.73
epoch train time: 0:00:00.612826
elapsed time: 0:00:23.086204
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:27:04.852894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.84
 ---- batch: 020 ----
mean loss: 910.29
 ---- batch: 030 ----
mean loss: 883.82
train mean loss: 901.51
epoch train time: 0:00:00.579465
elapsed time: 0:00:23.666042
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:27:05.432693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 873.25
 ---- batch: 020 ----
mean loss: 850.31
 ---- batch: 030 ----
mean loss: 841.53
train mean loss: 853.07
epoch train time: 0:00:00.591365
elapsed time: 0:00:24.257769
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:27:06.024420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 813.76
 ---- batch: 020 ----
mean loss: 816.43
 ---- batch: 030 ----
mean loss: 794.26
train mean loss: 807.07
epoch train time: 0:00:00.625416
elapsed time: 0:00:24.883555
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:27:06.650209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 767.61
 ---- batch: 020 ----
mean loss: 780.84
 ---- batch: 030 ----
mean loss: 750.71
train mean loss: 757.94
epoch train time: 0:00:00.615049
elapsed time: 0:00:25.498983
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:27:07.265666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 737.81
 ---- batch: 020 ----
mean loss: 722.09
 ---- batch: 030 ----
mean loss: 709.05
train mean loss: 716.29
epoch train time: 0:00:00.595355
elapsed time: 0:00:26.094717
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:27:07.861368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 680.95
 ---- batch: 020 ----
mean loss: 696.89
 ---- batch: 030 ----
mean loss: 683.67
train mean loss: 680.98
epoch train time: 0:00:00.581534
elapsed time: 0:00:26.676588
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:27:08.443261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 656.47
 ---- batch: 020 ----
mean loss: 655.16
 ---- batch: 030 ----
mean loss: 621.91
train mean loss: 639.34
epoch train time: 0:00:00.596464
elapsed time: 0:00:27.273521
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:27:09.040183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 607.50
 ---- batch: 020 ----
mean loss: 624.02
 ---- batch: 030 ----
mean loss: 604.21
train mean loss: 609.07
epoch train time: 0:00:00.589715
elapsed time: 0:00:27.863676
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:27:09.630333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 587.50
 ---- batch: 020 ----
mean loss: 586.12
 ---- batch: 030 ----
mean loss: 554.82
train mean loss: 574.84
epoch train time: 0:00:00.616022
elapsed time: 0:00:28.480209
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:27:10.246877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 555.78
 ---- batch: 020 ----
mean loss: 546.98
 ---- batch: 030 ----
mean loss: 533.44
train mean loss: 541.93
epoch train time: 0:00:00.610622
elapsed time: 0:00:29.091241
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:27:10.857896
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 518.78
 ---- batch: 020 ----
mean loss: 538.56
 ---- batch: 030 ----
mean loss: 505.42
train mean loss: 516.69
epoch train time: 0:00:00.603608
elapsed time: 0:00:29.695229
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:27:11.461890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 489.44
 ---- batch: 020 ----
mean loss: 488.51
 ---- batch: 030 ----
mean loss: 480.09
train mean loss: 486.38
epoch train time: 0:00:00.599365
elapsed time: 0:00:30.295010
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:27:12.061683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.02
 ---- batch: 020 ----
mean loss: 453.12
 ---- batch: 030 ----
mean loss: 468.84
train mean loss: 462.07
epoch train time: 0:00:00.595350
elapsed time: 0:00:30.890803
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:27:12.657455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 449.12
 ---- batch: 020 ----
mean loss: 436.85
 ---- batch: 030 ----
mean loss: 435.27
train mean loss: 436.94
epoch train time: 0:00:00.612888
elapsed time: 0:00:31.504161
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:27:13.270848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 422.90
 ---- batch: 020 ----
mean loss: 413.48
 ---- batch: 030 ----
mean loss: 404.40
train mean loss: 415.77
epoch train time: 0:00:00.607245
elapsed time: 0:00:32.111841
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:27:13.878502
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 400.18
 ---- batch: 020 ----
mean loss: 404.33
 ---- batch: 030 ----
mean loss: 389.22
train mean loss: 394.63
epoch train time: 0:00:00.586367
elapsed time: 0:00:32.698566
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:27:14.465222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 375.77
 ---- batch: 020 ----
mean loss: 381.28
 ---- batch: 030 ----
mean loss: 372.54
train mean loss: 374.93
epoch train time: 0:00:00.614965
elapsed time: 0:00:33.313959
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:27:15.080633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 359.93
 ---- batch: 020 ----
mean loss: 356.08
 ---- batch: 030 ----
mean loss: 362.10
train mean loss: 356.91
epoch train time: 0:00:00.603028
elapsed time: 0:00:33.917483
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:27:15.684207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 349.73
 ---- batch: 020 ----
mean loss: 342.17
 ---- batch: 030 ----
mean loss: 335.21
train mean loss: 341.15
epoch train time: 0:00:00.607981
elapsed time: 0:00:34.525850
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:27:16.292511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.12
 ---- batch: 020 ----
mean loss: 322.10
 ---- batch: 030 ----
mean loss: 322.04
train mean loss: 322.68
epoch train time: 0:00:00.593976
elapsed time: 0:00:35.120279
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:27:16.886940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.65
 ---- batch: 020 ----
mean loss: 306.49
 ---- batch: 030 ----
mean loss: 302.30
train mean loss: 305.86
epoch train time: 0:00:00.583888
elapsed time: 0:00:35.704505
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:27:17.471160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.77
 ---- batch: 020 ----
mean loss: 291.03
 ---- batch: 030 ----
mean loss: 290.96
train mean loss: 293.97
epoch train time: 0:00:00.596925
elapsed time: 0:00:36.301800
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:27:18.068457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.50
 ---- batch: 020 ----
mean loss: 273.58
 ---- batch: 030 ----
mean loss: 278.05
train mean loss: 280.49
epoch train time: 0:00:00.601432
elapsed time: 0:00:36.903631
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:27:18.670316
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.62
 ---- batch: 020 ----
mean loss: 264.94
 ---- batch: 030 ----
mean loss: 271.60
train mean loss: 267.83
epoch train time: 0:00:00.595575
elapsed time: 0:00:37.499596
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:27:19.266267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.65
 ---- batch: 020 ----
mean loss: 258.23
 ---- batch: 030 ----
mean loss: 246.47
train mean loss: 256.68
epoch train time: 0:00:00.587185
elapsed time: 0:00:38.087168
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:27:19.853849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.76
 ---- batch: 020 ----
mean loss: 245.97
 ---- batch: 030 ----
mean loss: 246.74
train mean loss: 245.85
epoch train time: 0:00:00.606644
elapsed time: 0:00:38.694239
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:27:20.460895
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.45
 ---- batch: 020 ----
mean loss: 230.92
 ---- batch: 030 ----
mean loss: 235.03
train mean loss: 234.91
epoch train time: 0:00:00.593806
elapsed time: 0:00:39.288424
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:27:21.055103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.84
 ---- batch: 020 ----
mean loss: 220.38
 ---- batch: 030 ----
mean loss: 223.03
train mean loss: 225.08
epoch train time: 0:00:00.588372
elapsed time: 0:00:39.877150
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:27:21.643805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.52
 ---- batch: 020 ----
mean loss: 218.98
 ---- batch: 030 ----
mean loss: 214.49
train mean loss: 214.89
epoch train time: 0:00:00.594434
elapsed time: 0:00:40.471961
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:27:22.238643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.10
 ---- batch: 020 ----
mean loss: 207.29
 ---- batch: 030 ----
mean loss: 208.15
train mean loss: 207.69
epoch train time: 0:00:00.593584
elapsed time: 0:00:41.065910
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:27:22.832583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.22
 ---- batch: 020 ----
mean loss: 199.40
 ---- batch: 030 ----
mean loss: 202.06
train mean loss: 199.78
epoch train time: 0:00:00.599426
elapsed time: 0:00:41.665685
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:27:23.432334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.34
 ---- batch: 020 ----
mean loss: 194.22
 ---- batch: 030 ----
mean loss: 191.97
train mean loss: 192.42
epoch train time: 0:00:00.586378
elapsed time: 0:00:42.252437
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:27:24.019092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.18
 ---- batch: 020 ----
mean loss: 184.60
 ---- batch: 030 ----
mean loss: 185.62
train mean loss: 185.43
epoch train time: 0:00:00.586156
elapsed time: 0:00:42.838915
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:27:24.605567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.69
 ---- batch: 020 ----
mean loss: 184.03
 ---- batch: 030 ----
mean loss: 176.56
train mean loss: 179.55
epoch train time: 0:00:00.599581
elapsed time: 0:00:43.438878
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:27:25.205539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.59
 ---- batch: 020 ----
mean loss: 173.44
 ---- batch: 030 ----
mean loss: 173.72
train mean loss: 173.73
epoch train time: 0:00:00.590678
elapsed time: 0:00:44.029935
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:27:25.796593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.00
 ---- batch: 020 ----
mean loss: 170.84
 ---- batch: 030 ----
mean loss: 166.70
train mean loss: 167.57
epoch train time: 0:00:00.593552
elapsed time: 0:00:44.623824
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:27:26.390479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.35
 ---- batch: 020 ----
mean loss: 161.61
 ---- batch: 030 ----
mean loss: 162.54
train mean loss: 162.55
epoch train time: 0:00:00.589470
elapsed time: 0:00:45.213667
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:27:26.980353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.34
 ---- batch: 020 ----
mean loss: 158.12
 ---- batch: 030 ----
mean loss: 153.44
train mean loss: 158.12
epoch train time: 0:00:00.601956
elapsed time: 0:00:45.816102
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:27:27.583013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.78
 ---- batch: 020 ----
mean loss: 155.62
 ---- batch: 030 ----
mean loss: 150.42
train mean loss: 152.43
epoch train time: 0:00:00.601558
elapsed time: 0:00:46.418352
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:27:28.185054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.93
 ---- batch: 020 ----
mean loss: 146.88
 ---- batch: 030 ----
mean loss: 152.17
train mean loss: 148.37
epoch train time: 0:00:00.583251
elapsed time: 0:00:47.002000
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:27:28.768661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.62
 ---- batch: 020 ----
mean loss: 147.53
 ---- batch: 030 ----
mean loss: 146.74
train mean loss: 145.63
epoch train time: 0:00:00.592889
elapsed time: 0:00:47.595283
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:27:29.361967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.75
 ---- batch: 020 ----
mean loss: 138.09
 ---- batch: 030 ----
mean loss: 142.59
train mean loss: 141.39
epoch train time: 0:00:00.614181
elapsed time: 0:00:48.209816
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:27:29.976487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.72
 ---- batch: 020 ----
mean loss: 136.35
 ---- batch: 030 ----
mean loss: 135.69
train mean loss: 137.63
epoch train time: 0:00:00.582440
elapsed time: 0:00:48.792659
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:27:30.559349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.46
 ---- batch: 020 ----
mean loss: 131.12
 ---- batch: 030 ----
mean loss: 134.66
train mean loss: 133.47
epoch train time: 0:00:00.584323
elapsed time: 0:00:49.377454
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:27:31.144126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.03
 ---- batch: 020 ----
mean loss: 132.22
 ---- batch: 030 ----
mean loss: 127.21
train mean loss: 130.27
epoch train time: 0:00:00.581859
elapsed time: 0:00:49.959672
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:27:31.726324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.95
 ---- batch: 020 ----
mean loss: 128.94
 ---- batch: 030 ----
mean loss: 127.91
train mean loss: 127.63
epoch train time: 0:00:00.583753
elapsed time: 0:00:50.543806
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:27:32.310470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.34
 ---- batch: 020 ----
mean loss: 125.48
 ---- batch: 030 ----
mean loss: 123.81
train mean loss: 125.23
epoch train time: 0:00:00.585080
elapsed time: 0:00:51.129247
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:27:32.895904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.60
 ---- batch: 020 ----
mean loss: 122.28
 ---- batch: 030 ----
mean loss: 124.28
train mean loss: 123.18
epoch train time: 0:00:00.580436
elapsed time: 0:00:51.710004
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:27:33.476662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.60
 ---- batch: 020 ----
mean loss: 120.09
 ---- batch: 030 ----
mean loss: 118.27
train mean loss: 120.70
epoch train time: 0:00:00.577094
elapsed time: 0:00:52.287469
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:27:34.054124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.41
 ---- batch: 020 ----
mean loss: 116.77
 ---- batch: 030 ----
mean loss: 119.03
train mean loss: 118.19
epoch train time: 0:00:00.584131
elapsed time: 0:00:52.871945
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:27:34.638602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.11
 ---- batch: 020 ----
mean loss: 112.66
 ---- batch: 030 ----
mean loss: 114.66
train mean loss: 115.49
epoch train time: 0:00:00.604903
elapsed time: 0:00:53.477207
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:27:35.243868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.14
 ---- batch: 020 ----
mean loss: 110.61
 ---- batch: 030 ----
mean loss: 113.88
train mean loss: 113.15
epoch train time: 0:00:00.603516
elapsed time: 0:00:54.081080
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:27:35.847749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.39
 ---- batch: 020 ----
mean loss: 110.27
 ---- batch: 030 ----
mean loss: 109.89
train mean loss: 111.18
epoch train time: 0:00:00.590664
elapsed time: 0:00:54.672097
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:27:36.438771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.57
 ---- batch: 020 ----
mean loss: 110.00
 ---- batch: 030 ----
mean loss: 110.49
train mean loss: 110.54
epoch train time: 0:00:00.621569
elapsed time: 0:00:55.294069
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:27:37.060755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.85
 ---- batch: 020 ----
mean loss: 109.51
 ---- batch: 030 ----
mean loss: 107.74
train mean loss: 107.48
epoch train time: 0:00:00.598886
elapsed time: 0:00:55.893361
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:27:37.660032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.31
 ---- batch: 020 ----
mean loss: 108.55
 ---- batch: 030 ----
mean loss: 102.42
train mean loss: 105.66
epoch train time: 0:00:00.592636
elapsed time: 0:00:56.486392
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:27:38.253064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.14
 ---- batch: 020 ----
mean loss: 103.48
 ---- batch: 030 ----
mean loss: 105.30
train mean loss: 103.20
epoch train time: 0:00:00.605677
elapsed time: 0:00:57.092503
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:27:38.859168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.25
 ---- batch: 020 ----
mean loss: 101.18
 ---- batch: 030 ----
mean loss: 105.02
train mean loss: 102.22
epoch train time: 0:00:00.587030
elapsed time: 0:00:57.679919
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:27:39.446570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.96
 ---- batch: 020 ----
mean loss: 97.66
 ---- batch: 030 ----
mean loss: 97.13
train mean loss: 99.71
epoch train time: 0:00:00.596638
elapsed time: 0:00:58.276898
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:27:40.043573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.87
 ---- batch: 020 ----
mean loss: 97.13
 ---- batch: 030 ----
mean loss: 99.00
train mean loss: 99.24
epoch train time: 0:00:00.586571
elapsed time: 0:00:58.863839
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:27:40.630499
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.15
 ---- batch: 020 ----
mean loss: 95.64
 ---- batch: 030 ----
mean loss: 102.34
train mean loss: 98.48
epoch train time: 0:00:00.590084
elapsed time: 0:00:59.454270
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:27:41.220924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.05
 ---- batch: 020 ----
mean loss: 100.56
 ---- batch: 030 ----
mean loss: 98.88
train mean loss: 98.21
epoch train time: 0:00:00.603698
elapsed time: 0:01:00.058333
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:27:41.825018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.03
 ---- batch: 020 ----
mean loss: 93.73
 ---- batch: 030 ----
mean loss: 96.08
train mean loss: 95.59
epoch train time: 0:00:00.592562
elapsed time: 0:01:00.651295
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:27:42.417966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.36
 ---- batch: 020 ----
mean loss: 96.49
 ---- batch: 030 ----
mean loss: 93.77
train mean loss: 94.31
epoch train time: 0:00:00.596425
elapsed time: 0:01:01.248103
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:27:43.014763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.57
 ---- batch: 020 ----
mean loss: 98.93
 ---- batch: 030 ----
mean loss: 92.21
train mean loss: 95.91
epoch train time: 0:00:00.604111
elapsed time: 0:01:01.852575
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:27:43.619246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.34
 ---- batch: 020 ----
mean loss: 89.55
 ---- batch: 030 ----
mean loss: 90.33
train mean loss: 91.78
epoch train time: 0:00:00.621991
elapsed time: 0:01:02.474957
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:27:44.241629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.97
 ---- batch: 020 ----
mean loss: 95.75
 ---- batch: 030 ----
mean loss: 90.51
train mean loss: 91.63
epoch train time: 0:00:00.602178
elapsed time: 0:01:03.077607
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:27:44.844308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.86
 ---- batch: 020 ----
mean loss: 91.79
 ---- batch: 030 ----
mean loss: 89.46
train mean loss: 90.95
epoch train time: 0:00:00.591995
elapsed time: 0:01:03.669993
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:27:45.436663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.72
 ---- batch: 020 ----
mean loss: 90.11
 ---- batch: 030 ----
mean loss: 94.33
train mean loss: 90.66
epoch train time: 0:00:00.598148
elapsed time: 0:01:04.268507
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:27:46.035189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.25
 ---- batch: 020 ----
mean loss: 90.47
 ---- batch: 030 ----
mean loss: 86.79
train mean loss: 89.41
epoch train time: 0:00:00.601268
elapsed time: 0:01:04.870169
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:27:46.636830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.63
 ---- batch: 020 ----
mean loss: 83.38
 ---- batch: 030 ----
mean loss: 86.25
train mean loss: 86.98
epoch train time: 0:00:00.595298
elapsed time: 0:01:05.465826
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:27:47.232512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.66
 ---- batch: 020 ----
mean loss: 83.74
 ---- batch: 030 ----
mean loss: 87.88
train mean loss: 86.81
epoch train time: 0:00:00.583835
elapsed time: 0:01:06.050058
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:27:47.816704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.76
 ---- batch: 020 ----
mean loss: 86.19
 ---- batch: 030 ----
mean loss: 87.85
train mean loss: 87.18
epoch train time: 0:00:00.583428
elapsed time: 0:01:06.633816
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:27:48.400468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.05
 ---- batch: 020 ----
mean loss: 87.23
 ---- batch: 030 ----
mean loss: 87.24
train mean loss: 86.94
epoch train time: 0:00:00.595863
elapsed time: 0:01:07.230009
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:27:48.996664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.63
 ---- batch: 020 ----
mean loss: 83.74
 ---- batch: 030 ----
mean loss: 84.23
train mean loss: 84.87
epoch train time: 0:00:00.585572
elapsed time: 0:01:07.815927
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:27:49.582575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.87
 ---- batch: 020 ----
mean loss: 83.28
 ---- batch: 030 ----
mean loss: 84.65
train mean loss: 83.34
epoch train time: 0:00:00.594099
elapsed time: 0:01:08.410344
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:27:50.177026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.97
 ---- batch: 020 ----
mean loss: 82.71
 ---- batch: 030 ----
mean loss: 83.79
train mean loss: 83.43
epoch train time: 0:00:00.594144
elapsed time: 0:01:09.004893
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:27:50.771549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.40
 ---- batch: 020 ----
mean loss: 79.03
 ---- batch: 030 ----
mean loss: 86.33
train mean loss: 82.89
epoch train time: 0:00:00.577793
elapsed time: 0:01:09.583024
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:27:51.349701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.21
 ---- batch: 020 ----
mean loss: 84.67
 ---- batch: 030 ----
mean loss: 83.42
train mean loss: 82.46
epoch train time: 0:00:00.605245
elapsed time: 0:01:10.188636
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:27:51.955287
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.00
 ---- batch: 020 ----
mean loss: 83.73
 ---- batch: 030 ----
mean loss: 82.49
train mean loss: 82.29
epoch train time: 0:00:00.604128
elapsed time: 0:01:10.793126
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:27:52.559775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.64
 ---- batch: 020 ----
mean loss: 81.41
 ---- batch: 030 ----
mean loss: 81.38
train mean loss: 81.93
epoch train time: 0:00:00.594376
elapsed time: 0:01:11.387829
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:27:53.154487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.81
 ---- batch: 020 ----
mean loss: 79.45
 ---- batch: 030 ----
mean loss: 77.86
train mean loss: 80.52
epoch train time: 0:00:00.598587
elapsed time: 0:01:11.986756
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:27:53.753421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.13
 ---- batch: 020 ----
mean loss: 78.98
 ---- batch: 030 ----
mean loss: 77.11
train mean loss: 79.39
epoch train time: 0:00:00.593824
elapsed time: 0:01:12.580923
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:27:54.347575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.60
 ---- batch: 020 ----
mean loss: 76.76
 ---- batch: 030 ----
mean loss: 78.02
train mean loss: 78.29
epoch train time: 0:00:00.591932
elapsed time: 0:01:13.173172
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:27:54.939822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.52
 ---- batch: 020 ----
mean loss: 81.03
 ---- batch: 030 ----
mean loss: 76.11
train mean loss: 78.20
epoch train time: 0:00:00.590544
elapsed time: 0:01:13.764389
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:27:55.531057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.83
 ---- batch: 020 ----
mean loss: 81.33
 ---- batch: 030 ----
mean loss: 74.78
train mean loss: 78.25
epoch train time: 0:00:00.593512
elapsed time: 0:01:14.358277
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:27:56.124931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.31
 ---- batch: 020 ----
mean loss: 76.12
 ---- batch: 030 ----
mean loss: 75.05
train mean loss: 77.22
epoch train time: 0:00:00.599935
elapsed time: 0:01:14.958631
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:27:56.725283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.46
 ---- batch: 020 ----
mean loss: 76.08
 ---- batch: 030 ----
mean loss: 78.76
train mean loss: 76.65
epoch train time: 0:00:00.589054
elapsed time: 0:01:15.548006
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:27:57.314666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.91
 ---- batch: 020 ----
mean loss: 75.17
 ---- batch: 030 ----
mean loss: 75.17
train mean loss: 76.29
epoch train time: 0:00:00.593105
elapsed time: 0:01:16.141541
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:27:57.908148
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.44
 ---- batch: 020 ----
mean loss: 75.13
 ---- batch: 030 ----
mean loss: 75.83
train mean loss: 74.79
epoch train time: 0:00:00.602287
elapsed time: 0:01:16.744123
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:27:58.510795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.52
 ---- batch: 020 ----
mean loss: 76.14
 ---- batch: 030 ----
mean loss: 71.13
train mean loss: 75.03
epoch train time: 0:00:00.587874
elapsed time: 0:01:17.332365
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:27:59.099018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.77
 ---- batch: 020 ----
mean loss: 73.26
 ---- batch: 030 ----
mean loss: 73.67
train mean loss: 73.80
epoch train time: 0:00:00.585154
elapsed time: 0:01:17.917922
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:27:59.684575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.18
 ---- batch: 020 ----
mean loss: 74.07
 ---- batch: 030 ----
mean loss: 76.28
train mean loss: 74.49
epoch train time: 0:00:00.619531
elapsed time: 0:01:18.537840
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:28:00.304509
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.79
 ---- batch: 020 ----
mean loss: 73.58
 ---- batch: 030 ----
mean loss: 70.72
train mean loss: 73.23
epoch train time: 0:00:00.613585
elapsed time: 0:01:19.151865
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:28:00.918566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.42
 ---- batch: 020 ----
mean loss: 73.65
 ---- batch: 030 ----
mean loss: 72.79
train mean loss: 73.19
epoch train time: 0:00:00.581681
elapsed time: 0:01:19.733919
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:28:01.500600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.06
 ---- batch: 020 ----
mean loss: 70.93
 ---- batch: 030 ----
mean loss: 73.15
train mean loss: 72.46
epoch train time: 0:00:00.606548
elapsed time: 0:01:20.340840
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:28:02.107495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.49
 ---- batch: 020 ----
mean loss: 71.88
 ---- batch: 030 ----
mean loss: 74.52
train mean loss: 72.79
epoch train time: 0:00:00.612147
elapsed time: 0:01:20.953384
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:28:02.720051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.73
 ---- batch: 020 ----
mean loss: 73.44
 ---- batch: 030 ----
mean loss: 69.98
train mean loss: 71.44
epoch train time: 0:00:00.611082
elapsed time: 0:01:21.564829
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:28:03.331487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.24
 ---- batch: 020 ----
mean loss: 71.33
 ---- batch: 030 ----
mean loss: 71.44
train mean loss: 70.58
epoch train time: 0:00:00.597858
elapsed time: 0:01:22.163115
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:28:03.929831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.72
 ---- batch: 020 ----
mean loss: 70.23
 ---- batch: 030 ----
mean loss: 73.53
train mean loss: 71.46
epoch train time: 0:00:00.587969
elapsed time: 0:01:22.751573
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:28:04.518234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.11
 ---- batch: 020 ----
mean loss: 69.97
 ---- batch: 030 ----
mean loss: 71.50
train mean loss: 70.47
epoch train time: 0:00:00.594598
elapsed time: 0:01:23.346623
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:28:05.113279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.44
 ---- batch: 020 ----
mean loss: 69.71
 ---- batch: 030 ----
mean loss: 70.63
train mean loss: 69.75
epoch train time: 0:00:00.601283
elapsed time: 0:01:23.948323
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:28:05.714976
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.46
 ---- batch: 020 ----
mean loss: 69.94
 ---- batch: 030 ----
mean loss: 68.66
train mean loss: 69.30
epoch train time: 0:00:00.595809
elapsed time: 0:01:24.544507
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:28:06.311165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.30
 ---- batch: 020 ----
mean loss: 67.72
 ---- batch: 030 ----
mean loss: 69.31
train mean loss: 67.85
epoch train time: 0:00:00.588985
elapsed time: 0:01:25.133844
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:28:06.900505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.64
 ---- batch: 020 ----
mean loss: 68.03
 ---- batch: 030 ----
mean loss: 66.05
train mean loss: 67.63
epoch train time: 0:00:00.591750
elapsed time: 0:01:25.725965
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:28:07.492694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.25
 ---- batch: 020 ----
mean loss: 66.44
 ---- batch: 030 ----
mean loss: 67.13
train mean loss: 67.42
epoch train time: 0:00:00.592547
elapsed time: 0:01:26.318993
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:28:08.085678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.55
 ---- batch: 020 ----
mean loss: 65.52
 ---- batch: 030 ----
mean loss: 68.96
train mean loss: 67.14
epoch train time: 0:00:00.607370
elapsed time: 0:01:26.926811
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:28:08.693484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.46
 ---- batch: 020 ----
mean loss: 65.35
 ---- batch: 030 ----
mean loss: 65.40
train mean loss: 66.72
epoch train time: 0:00:00.613342
elapsed time: 0:01:27.540533
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:28:09.307200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.73
 ---- batch: 020 ----
mean loss: 65.76
 ---- batch: 030 ----
mean loss: 67.50
train mean loss: 66.45
epoch train time: 0:00:00.598453
elapsed time: 0:01:28.139419
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:28:09.906044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.29
 ---- batch: 020 ----
mean loss: 64.78
 ---- batch: 030 ----
mean loss: 66.07
train mean loss: 65.97
epoch train time: 0:00:00.595681
elapsed time: 0:01:28.735435
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:28:10.502107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.39
 ---- batch: 020 ----
mean loss: 65.47
 ---- batch: 030 ----
mean loss: 62.32
train mean loss: 64.67
epoch train time: 0:00:00.590766
elapsed time: 0:01:29.326556
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:28:11.093216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.76
 ---- batch: 020 ----
mean loss: 67.18
 ---- batch: 030 ----
mean loss: 64.66
train mean loss: 64.45
epoch train time: 0:00:00.581174
elapsed time: 0:01:29.908106
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:28:11.674766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.15
 ---- batch: 020 ----
mean loss: 64.69
 ---- batch: 030 ----
mean loss: 62.56
train mean loss: 63.84
epoch train time: 0:00:00.604009
elapsed time: 0:01:30.512538
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:28:12.279201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.28
 ---- batch: 020 ----
mean loss: 62.40
 ---- batch: 030 ----
mean loss: 64.61
train mean loss: 63.29
epoch train time: 0:00:00.600503
elapsed time: 0:01:31.113441
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:28:12.880102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.30
 ---- batch: 020 ----
mean loss: 64.55
 ---- batch: 030 ----
mean loss: 60.70
train mean loss: 62.32
epoch train time: 0:00:00.601823
elapsed time: 0:01:31.715653
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:28:13.482308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.77
 ---- batch: 020 ----
mean loss: 61.72
 ---- batch: 030 ----
mean loss: 64.52
train mean loss: 62.43
epoch train time: 0:00:00.592956
elapsed time: 0:01:32.308967
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:28:14.075635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.09
 ---- batch: 020 ----
mean loss: 61.42
 ---- batch: 030 ----
mean loss: 61.85
train mean loss: 61.65
epoch train time: 0:00:00.588461
elapsed time: 0:01:32.897827
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:28:14.664489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.05
 ---- batch: 020 ----
mean loss: 60.74
 ---- batch: 030 ----
mean loss: 62.09
train mean loss: 61.14
epoch train time: 0:00:00.601091
elapsed time: 0:01:33.499293
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:28:15.265985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.85
 ---- batch: 020 ----
mean loss: 61.05
 ---- batch: 030 ----
mean loss: 58.02
train mean loss: 60.95
epoch train time: 0:00:00.600533
elapsed time: 0:01:34.100276
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:28:15.866933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.76
 ---- batch: 020 ----
mean loss: 63.66
 ---- batch: 030 ----
mean loss: 58.17
train mean loss: 60.79
epoch train time: 0:00:00.586004
elapsed time: 0:01:34.686646
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:28:16.453303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.08
 ---- batch: 020 ----
mean loss: 62.39
 ---- batch: 030 ----
mean loss: 58.71
train mean loss: 60.36
epoch train time: 0:00:00.606535
elapsed time: 0:01:35.293519
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:28:17.060189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.18
 ---- batch: 020 ----
mean loss: 60.69
 ---- batch: 030 ----
mean loss: 59.86
train mean loss: 60.09
epoch train time: 0:00:00.582067
elapsed time: 0:01:35.876003
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:28:17.642661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.69
 ---- batch: 020 ----
mean loss: 58.97
 ---- batch: 030 ----
mean loss: 61.28
train mean loss: 60.01
epoch train time: 0:00:00.617299
elapsed time: 0:01:36.493650
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:28:18.260324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.62
 ---- batch: 020 ----
mean loss: 60.31
 ---- batch: 030 ----
mean loss: 59.05
train mean loss: 59.66
epoch train time: 0:00:00.598912
elapsed time: 0:01:37.092977
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:28:18.859636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.11
 ---- batch: 020 ----
mean loss: 57.70
 ---- batch: 030 ----
mean loss: 60.19
train mean loss: 58.73
epoch train time: 0:00:00.583573
elapsed time: 0:01:37.676982
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:28:19.443627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.41
 ---- batch: 020 ----
mean loss: 56.60
 ---- batch: 030 ----
mean loss: 59.01
train mean loss: 57.31
epoch train time: 0:00:00.595013
elapsed time: 0:01:38.272349
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:28:20.039002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.21
 ---- batch: 020 ----
mean loss: 57.35
 ---- batch: 030 ----
mean loss: 55.75
train mean loss: 57.38
epoch train time: 0:00:00.585003
elapsed time: 0:01:38.857692
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:28:20.624342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.63
 ---- batch: 020 ----
mean loss: 57.86
 ---- batch: 030 ----
mean loss: 56.26
train mean loss: 57.36
epoch train time: 0:00:00.583852
elapsed time: 0:01:39.441964
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:28:21.208627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.36
 ---- batch: 020 ----
mean loss: 59.29
 ---- batch: 030 ----
mean loss: 55.76
train mean loss: 57.22
epoch train time: 0:00:00.599177
elapsed time: 0:01:40.041566
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:28:21.808237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.91
 ---- batch: 020 ----
mean loss: 55.36
 ---- batch: 030 ----
mean loss: 56.57
train mean loss: 56.16
epoch train time: 0:00:00.600285
elapsed time: 0:01:40.642282
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:28:22.408958
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.94
 ---- batch: 020 ----
mean loss: 57.93
 ---- batch: 030 ----
mean loss: 54.57
train mean loss: 56.07
epoch train time: 0:00:00.592931
elapsed time: 0:01:41.235672
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:28:23.002272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.50
 ---- batch: 020 ----
mean loss: 55.57
 ---- batch: 030 ----
mean loss: 54.13
train mean loss: 55.59
epoch train time: 0:00:00.595856
elapsed time: 0:01:41.831876
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:28:23.598532
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.30
 ---- batch: 020 ----
mean loss: 54.58
 ---- batch: 030 ----
mean loss: 54.62
train mean loss: 55.41
epoch train time: 0:00:00.615730
elapsed time: 0:01:42.447956
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:28:24.214607
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.03
 ---- batch: 020 ----
mean loss: 53.71
 ---- batch: 030 ----
mean loss: 58.31
train mean loss: 55.28
epoch train time: 0:00:00.593288
elapsed time: 0:01:43.041673
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:28:24.808330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.87
 ---- batch: 020 ----
mean loss: 57.09
 ---- batch: 030 ----
mean loss: 52.46
train mean loss: 54.62
epoch train time: 0:00:00.611601
elapsed time: 0:01:43.653727
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:28:25.420388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.26
 ---- batch: 020 ----
mean loss: 53.89
 ---- batch: 030 ----
mean loss: 55.51
train mean loss: 53.89
epoch train time: 0:00:00.616448
elapsed time: 0:01:44.270640
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:28:26.037321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.66
 ---- batch: 020 ----
mean loss: 55.86
 ---- batch: 030 ----
mean loss: 53.62
train mean loss: 54.28
epoch train time: 0:00:00.600421
elapsed time: 0:01:44.871498
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:28:26.638164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.28
 ---- batch: 020 ----
mean loss: 51.24
 ---- batch: 030 ----
mean loss: 54.41
train mean loss: 52.14
epoch train time: 0:00:00.604774
elapsed time: 0:01:45.476664
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:28:27.243336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.76
 ---- batch: 020 ----
mean loss: 52.53
 ---- batch: 030 ----
mean loss: 52.22
train mean loss: 52.51
epoch train time: 0:00:00.621378
elapsed time: 0:01:46.098493
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:28:27.865146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.03
 ---- batch: 020 ----
mean loss: 52.52
 ---- batch: 030 ----
mean loss: 50.62
train mean loss: 51.98
epoch train time: 0:00:00.579425
elapsed time: 0:01:46.678347
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:28:28.445083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.60
 ---- batch: 020 ----
mean loss: 52.59
 ---- batch: 030 ----
mean loss: 51.25
train mean loss: 51.31
epoch train time: 0:00:00.603032
elapsed time: 0:01:47.281936
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:28:29.048654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.12
 ---- batch: 020 ----
mean loss: 50.29
 ---- batch: 030 ----
mean loss: 48.82
train mean loss: 50.64
epoch train time: 0:00:00.613787
elapsed time: 0:01:47.896175
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:28:29.662841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.05
 ---- batch: 020 ----
mean loss: 50.22
 ---- batch: 030 ----
mean loss: 52.49
train mean loss: 51.26
epoch train time: 0:00:00.603153
elapsed time: 0:01:48.499687
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:28:30.266344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.06
 ---- batch: 020 ----
mean loss: 49.77
 ---- batch: 030 ----
mean loss: 49.39
train mean loss: 50.95
epoch train time: 0:00:00.594432
elapsed time: 0:01:49.094569
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:28:30.861269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.60
 ---- batch: 020 ----
mean loss: 51.45
 ---- batch: 030 ----
mean loss: 51.50
train mean loss: 50.52
epoch train time: 0:00:00.588236
elapsed time: 0:01:49.683258
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:28:31.449917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.61
 ---- batch: 020 ----
mean loss: 49.17
 ---- batch: 030 ----
mean loss: 48.08
train mean loss: 49.17
epoch train time: 0:00:00.609520
elapsed time: 0:01:50.293191
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:28:32.059858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.59
 ---- batch: 020 ----
mean loss: 48.63
 ---- batch: 030 ----
mean loss: 48.70
train mean loss: 48.94
epoch train time: 0:00:00.612435
elapsed time: 0:01:50.906051
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:28:32.672722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.98
 ---- batch: 020 ----
mean loss: 46.99
 ---- batch: 030 ----
mean loss: 49.00
train mean loss: 47.89
epoch train time: 0:00:00.594484
elapsed time: 0:01:51.500880
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:28:33.267537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.84
 ---- batch: 020 ----
mean loss: 47.89
 ---- batch: 030 ----
mean loss: 47.57
train mean loss: 48.22
epoch train time: 0:00:00.592207
elapsed time: 0:01:52.093455
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:28:33.860121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.56
 ---- batch: 020 ----
mean loss: 47.59
 ---- batch: 030 ----
mean loss: 48.72
train mean loss: 48.36
epoch train time: 0:00:00.586120
elapsed time: 0:01:52.679923
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:28:34.446623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.98
 ---- batch: 020 ----
mean loss: 46.23
 ---- batch: 030 ----
mean loss: 48.11
train mean loss: 47.81
epoch train time: 0:00:00.594828
elapsed time: 0:01:53.275169
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:28:35.041849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.63
 ---- batch: 020 ----
mean loss: 49.13
 ---- batch: 030 ----
mean loss: 47.27
train mean loss: 47.12
epoch train time: 0:00:00.578628
elapsed time: 0:01:53.854159
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:28:35.620810
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.88
 ---- batch: 020 ----
mean loss: 46.33
 ---- batch: 030 ----
mean loss: 47.57
train mean loss: 46.39
epoch train time: 0:00:00.584275
elapsed time: 0:01:54.438829
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:28:36.205487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.57
 ---- batch: 020 ----
mean loss: 46.71
 ---- batch: 030 ----
mean loss: 44.78
train mean loss: 46.67
epoch train time: 0:00:00.577772
elapsed time: 0:01:55.016936
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:28:36.783590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.15
 ---- batch: 020 ----
mean loss: 45.32
 ---- batch: 030 ----
mean loss: 44.93
train mean loss: 45.69
epoch train time: 0:00:00.571828
elapsed time: 0:01:55.589090
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:28:37.355747
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.73
 ---- batch: 020 ----
mean loss: 47.54
 ---- batch: 030 ----
mean loss: 45.38
train mean loss: 45.72
epoch train time: 0:00:00.575796
elapsed time: 0:01:56.165327
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:28:37.931960
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.70
 ---- batch: 020 ----
mean loss: 45.94
 ---- batch: 030 ----
mean loss: 46.42
train mean loss: 44.93
epoch train time: 0:00:00.575093
elapsed time: 0:01:56.740745
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:28:38.507414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.67
 ---- batch: 020 ----
mean loss: 46.17
 ---- batch: 030 ----
mean loss: 45.23
train mean loss: 45.64
epoch train time: 0:00:00.596471
elapsed time: 0:01:57.337567
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:28:39.104228
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.64
 ---- batch: 020 ----
mean loss: 43.59
 ---- batch: 030 ----
mean loss: 45.81
train mean loss: 44.97
epoch train time: 0:00:00.584567
elapsed time: 0:01:57.922509
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:28:39.689182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.60
 ---- batch: 020 ----
mean loss: 42.87
 ---- batch: 030 ----
mean loss: 46.04
train mean loss: 44.13
epoch train time: 0:00:00.588713
elapsed time: 0:01:58.511563
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:28:40.278222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.66
 ---- batch: 020 ----
mean loss: 42.35
 ---- batch: 030 ----
mean loss: 43.19
train mean loss: 43.05
epoch train time: 0:00:00.572890
elapsed time: 0:01:59.084856
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:28:40.851505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.82
 ---- batch: 020 ----
mean loss: 43.01
 ---- batch: 030 ----
mean loss: 45.72
train mean loss: 44.03
epoch train time: 0:00:00.574276
elapsed time: 0:01:59.659436
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:28:41.426096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.08
 ---- batch: 020 ----
mean loss: 42.60
 ---- batch: 030 ----
mean loss: 42.70
train mean loss: 42.67
epoch train time: 0:00:00.572699
elapsed time: 0:02:00.232464
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:28:41.999131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.95
 ---- batch: 020 ----
mean loss: 45.61
 ---- batch: 030 ----
mean loss: 43.78
train mean loss: 43.58
epoch train time: 0:00:00.574158
elapsed time: 0:02:00.806938
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:28:42.573635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.99
 ---- batch: 020 ----
mean loss: 44.39
 ---- batch: 030 ----
mean loss: 42.03
train mean loss: 42.26
epoch train time: 0:00:00.589152
elapsed time: 0:02:01.396481
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:28:43.163175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.47
 ---- batch: 020 ----
mean loss: 42.79
 ---- batch: 030 ----
mean loss: 44.67
train mean loss: 42.59
epoch train time: 0:00:00.596490
elapsed time: 0:02:01.993391
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:28:43.760052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.50
 ---- batch: 020 ----
mean loss: 42.61
 ---- batch: 030 ----
mean loss: 40.14
train mean loss: 41.26
epoch train time: 0:00:00.591339
elapsed time: 0:02:02.585058
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:28:44.351722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.93
 ---- batch: 020 ----
mean loss: 40.66
 ---- batch: 030 ----
mean loss: 39.83
train mean loss: 41.04
epoch train time: 0:00:00.578899
elapsed time: 0:02:03.164419
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:28:44.931092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.33
 ---- batch: 020 ----
mean loss: 41.96
 ---- batch: 030 ----
mean loss: 39.85
train mean loss: 41.53
epoch train time: 0:00:00.582955
elapsed time: 0:02:03.747717
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:28:45.514375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.89
 ---- batch: 020 ----
mean loss: 40.07
 ---- batch: 030 ----
mean loss: 42.77
train mean loss: 40.55
epoch train time: 0:00:00.583358
elapsed time: 0:02:04.331421
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:28:46.098067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.13
 ---- batch: 020 ----
mean loss: 40.39
 ---- batch: 030 ----
mean loss: 38.71
train mean loss: 39.61
epoch train time: 0:00:00.594038
elapsed time: 0:02:04.925772
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:28:46.692429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.22
 ---- batch: 020 ----
mean loss: 38.35
 ---- batch: 030 ----
mean loss: 40.46
train mean loss: 39.25
epoch train time: 0:00:00.586225
elapsed time: 0:02:05.512347
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:28:47.279024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.45
 ---- batch: 020 ----
mean loss: 38.51
 ---- batch: 030 ----
mean loss: 39.77
train mean loss: 39.41
epoch train time: 0:00:00.622263
elapsed time: 0:02:06.134956
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:28:47.901664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.77
 ---- batch: 020 ----
mean loss: 37.48
 ---- batch: 030 ----
mean loss: 41.10
train mean loss: 39.16
epoch train time: 0:00:00.584431
elapsed time: 0:02:06.719790
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:28:48.486463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.20
 ---- batch: 020 ----
mean loss: 36.59
 ---- batch: 030 ----
mean loss: 40.83
train mean loss: 38.52
epoch train time: 0:00:00.583293
elapsed time: 0:02:07.303468
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:28:49.070147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.98
 ---- batch: 020 ----
mean loss: 39.54
 ---- batch: 030 ----
mean loss: 37.72
train mean loss: 38.31
epoch train time: 0:00:00.581177
elapsed time: 0:02:07.885025
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:28:49.651688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.40
 ---- batch: 020 ----
mean loss: 37.04
 ---- batch: 030 ----
mean loss: 38.29
train mean loss: 37.99
epoch train time: 0:00:00.592105
elapsed time: 0:02:08.477476
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:28:50.244152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.73
 ---- batch: 020 ----
mean loss: 38.12
 ---- batch: 030 ----
mean loss: 38.02
train mean loss: 38.01
epoch train time: 0:00:00.594978
elapsed time: 0:02:09.072836
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:28:50.839516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.62
 ---- batch: 020 ----
mean loss: 38.73
 ---- batch: 030 ----
mean loss: 35.69
train mean loss: 36.79
epoch train time: 0:00:00.579778
elapsed time: 0:02:09.652998
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:28:51.419650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.42
 ---- batch: 020 ----
mean loss: 37.42
 ---- batch: 030 ----
mean loss: 37.28
train mean loss: 37.01
epoch train time: 0:00:00.585433
elapsed time: 0:02:10.238740
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:28:52.005402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 35.98
 ---- batch: 020 ----
mean loss: 38.33
 ---- batch: 030 ----
mean loss: 36.61
train mean loss: 36.94
epoch train time: 0:00:00.581239
elapsed time: 0:02:10.820351
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:28:52.587014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.82
 ---- batch: 020 ----
mean loss: 34.80
 ---- batch: 030 ----
mean loss: 37.00
train mean loss: 36.53
epoch train time: 0:00:00.586846
elapsed time: 0:02:11.407521
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:28:53.174171
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.57
 ---- batch: 020 ----
mean loss: 34.99
 ---- batch: 030 ----
mean loss: 36.21
train mean loss: 36.12
epoch train time: 0:00:00.598226
elapsed time: 0:02:12.006093
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:28:53.772765
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.37
 ---- batch: 020 ----
mean loss: 36.25
 ---- batch: 030 ----
mean loss: 36.78
train mean loss: 35.51
epoch train time: 0:00:00.578697
elapsed time: 0:02:12.585236
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:28:54.351829
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.49
 ---- batch: 020 ----
mean loss: 36.09
 ---- batch: 030 ----
mean loss: 34.04
train mean loss: 34.98
epoch train time: 0:00:00.584131
elapsed time: 0:02:13.169621
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:28:54.936266
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.63
 ---- batch: 020 ----
mean loss: 33.58
 ---- batch: 030 ----
mean loss: 34.27
train mean loss: 34.92
epoch train time: 0:00:00.593780
elapsed time: 0:02:13.763754
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:28:55.530408
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.66
 ---- batch: 020 ----
mean loss: 35.14
 ---- batch: 030 ----
mean loss: 35.41
train mean loss: 34.80
epoch train time: 0:00:00.605884
elapsed time: 0:02:14.369958
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:28:56.136611
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.01
 ---- batch: 020 ----
mean loss: 35.29
 ---- batch: 030 ----
mean loss: 34.28
train mean loss: 34.88
epoch train time: 0:00:00.600597
elapsed time: 0:02:14.970929
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:28:56.737586
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.06
 ---- batch: 020 ----
mean loss: 35.00
 ---- batch: 030 ----
mean loss: 35.46
train mean loss: 35.01
epoch train time: 0:00:00.570908
elapsed time: 0:02:15.542164
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:28:57.308872
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.59
 ---- batch: 020 ----
mean loss: 34.10
 ---- batch: 030 ----
mean loss: 35.18
train mean loss: 34.77
epoch train time: 0:00:00.580984
elapsed time: 0:02:16.123519
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:28:57.890168
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.79
 ---- batch: 020 ----
mean loss: 35.86
 ---- batch: 030 ----
mean loss: 34.05
train mean loss: 34.77
epoch train time: 0:00:00.583135
elapsed time: 0:02:16.706980
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:28:58.473675
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.96
 ---- batch: 020 ----
mean loss: 34.69
 ---- batch: 030 ----
mean loss: 33.84
train mean loss: 34.86
epoch train time: 0:00:00.582780
elapsed time: 0:02:17.290117
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:28:59.056762
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.94
 ---- batch: 020 ----
mean loss: 35.09
 ---- batch: 030 ----
mean loss: 34.97
train mean loss: 35.18
epoch train time: 0:00:00.586569
elapsed time: 0:02:17.876996
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:28:59.643647
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.54
 ---- batch: 020 ----
mean loss: 35.33
 ---- batch: 030 ----
mean loss: 33.78
train mean loss: 34.87
epoch train time: 0:00:00.582278
elapsed time: 0:02:18.459606
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:29:00.226263
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.72
 ---- batch: 020 ----
mean loss: 35.53
 ---- batch: 030 ----
mean loss: 35.02
train mean loss: 34.80
epoch train time: 0:00:00.580565
elapsed time: 0:02:19.040551
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:29:00.807259
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.24
 ---- batch: 020 ----
mean loss: 33.35
 ---- batch: 030 ----
mean loss: 34.78
train mean loss: 34.61
epoch train time: 0:00:00.586075
elapsed time: 0:02:19.626981
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:29:01.393669
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.81
 ---- batch: 020 ----
mean loss: 35.58
 ---- batch: 030 ----
mean loss: 34.61
train mean loss: 34.84
epoch train time: 0:00:00.582984
elapsed time: 0:02:20.210310
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:29:01.976961
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.70
 ---- batch: 020 ----
mean loss: 34.60
 ---- batch: 030 ----
mean loss: 36.14
train mean loss: 34.64
epoch train time: 0:00:00.584703
elapsed time: 0:02:20.795335
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:29:02.562010
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.81
 ---- batch: 020 ----
mean loss: 34.30
 ---- batch: 030 ----
mean loss: 34.60
train mean loss: 34.61
epoch train time: 0:00:00.588857
elapsed time: 0:02:21.384530
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:29:03.151178
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.32
 ---- batch: 020 ----
mean loss: 34.44
 ---- batch: 030 ----
mean loss: 36.85
train mean loss: 34.46
epoch train time: 0:00:00.589180
elapsed time: 0:02:21.974039
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:29:03.740695
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.56
 ---- batch: 020 ----
mean loss: 35.18
 ---- batch: 030 ----
mean loss: 32.19
train mean loss: 34.34
epoch train time: 0:00:00.607120
elapsed time: 0:02:22.581567
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:29:04.348236
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.88
 ---- batch: 020 ----
mean loss: 36.05
 ---- batch: 030 ----
mean loss: 33.21
train mean loss: 34.24
epoch train time: 0:00:00.593425
elapsed time: 0:02:23.175425
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:29:04.942102
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.85
 ---- batch: 020 ----
mean loss: 34.89
 ---- batch: 030 ----
mean loss: 34.68
train mean loss: 34.59
epoch train time: 0:00:00.588931
elapsed time: 0:02:23.764765
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:29:05.531436
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.71
 ---- batch: 020 ----
mean loss: 33.71
 ---- batch: 030 ----
mean loss: 35.00
train mean loss: 34.25
epoch train time: 0:00:00.586257
elapsed time: 0:02:24.351377
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:29:06.118117
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.89
 ---- batch: 020 ----
mean loss: 35.54
 ---- batch: 030 ----
mean loss: 34.24
train mean loss: 34.39
epoch train time: 0:00:00.584349
elapsed time: 0:02:24.936135
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:29:06.702841
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.90
 ---- batch: 020 ----
mean loss: 33.01
 ---- batch: 030 ----
mean loss: 35.87
train mean loss: 34.36
epoch train time: 0:00:00.595483
elapsed time: 0:02:25.532001
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:29:07.298668
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.05
 ---- batch: 020 ----
mean loss: 33.37
 ---- batch: 030 ----
mean loss: 35.10
train mean loss: 34.47
epoch train time: 0:00:00.588854
elapsed time: 0:02:26.121231
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:29:07.887882
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.54
 ---- batch: 020 ----
mean loss: 34.15
 ---- batch: 030 ----
mean loss: 33.04
train mean loss: 34.35
epoch train time: 0:00:00.584741
elapsed time: 0:02:26.706313
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:29:08.472974
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.15
 ---- batch: 020 ----
mean loss: 34.10
 ---- batch: 030 ----
mean loss: 31.76
train mean loss: 34.06
epoch train time: 0:00:00.583896
elapsed time: 0:02:27.290527
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:29:09.057177
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.32
 ---- batch: 020 ----
mean loss: 34.82
 ---- batch: 030 ----
mean loss: 33.13
train mean loss: 34.15
epoch train time: 0:00:00.586838
elapsed time: 0:02:27.877715
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:29:09.644400
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.70
 ---- batch: 020 ----
mean loss: 33.52
 ---- batch: 030 ----
mean loss: 33.86
train mean loss: 34.24
epoch train time: 0:00:00.578221
elapsed time: 0:02:28.456281
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:29:10.222938
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.76
 ---- batch: 020 ----
mean loss: 33.60
 ---- batch: 030 ----
mean loss: 34.56
train mean loss: 34.14
epoch train time: 0:00:00.583292
elapsed time: 0:02:29.039921
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:29:10.806583
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.99
 ---- batch: 020 ----
mean loss: 35.26
 ---- batch: 030 ----
mean loss: 33.69
train mean loss: 34.32
epoch train time: 0:00:00.571900
elapsed time: 0:02:29.612157
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:29:11.378809
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.83
 ---- batch: 020 ----
mean loss: 33.22
 ---- batch: 030 ----
mean loss: 33.98
train mean loss: 33.85
epoch train time: 0:00:00.578103
elapsed time: 0:02:30.190838
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:29:11.957494
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.60
 ---- batch: 020 ----
mean loss: 34.69
 ---- batch: 030 ----
mean loss: 33.53
train mean loss: 34.05
epoch train time: 0:00:00.584180
elapsed time: 0:02:30.775358
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:29:12.542014
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.80
 ---- batch: 020 ----
mean loss: 32.44
 ---- batch: 030 ----
mean loss: 33.94
train mean loss: 34.06
epoch train time: 0:00:00.586809
elapsed time: 0:02:31.362542
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:29:13.129135
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.27
 ---- batch: 020 ----
mean loss: 35.30
 ---- batch: 030 ----
mean loss: 32.49
train mean loss: 34.08
epoch train time: 0:00:00.584447
elapsed time: 0:02:31.947302
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:29:13.713973
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.54
 ---- batch: 020 ----
mean loss: 33.81
 ---- batch: 030 ----
mean loss: 33.31
train mean loss: 34.09
epoch train time: 0:00:00.588117
elapsed time: 0:02:32.535781
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:29:14.302459
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.49
 ---- batch: 020 ----
mean loss: 33.71
 ---- batch: 030 ----
mean loss: 34.41
train mean loss: 33.89
epoch train time: 0:00:00.602105
elapsed time: 0:02:33.138239
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:29:14.904956
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.01
 ---- batch: 020 ----
mean loss: 33.79
 ---- batch: 030 ----
mean loss: 33.41
train mean loss: 33.83
epoch train time: 0:00:00.583056
elapsed time: 0:02:33.721685
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:29:15.488344
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.02
 ---- batch: 020 ----
mean loss: 33.33
 ---- batch: 030 ----
mean loss: 34.10
train mean loss: 33.42
epoch train time: 0:00:00.585676
elapsed time: 0:02:34.307706
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:29:16.074410
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.38
 ---- batch: 020 ----
mean loss: 32.82
 ---- batch: 030 ----
mean loss: 32.58
train mean loss: 33.84
epoch train time: 0:00:00.585286
elapsed time: 0:02:34.893409
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:29:16.660069
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.51
 ---- batch: 020 ----
mean loss: 34.24
 ---- batch: 030 ----
mean loss: 32.91
train mean loss: 33.92
epoch train time: 0:00:00.612634
elapsed time: 0:02:35.506376
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:29:17.273038
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.29
 ---- batch: 020 ----
mean loss: 32.60
 ---- batch: 030 ----
mean loss: 34.39
train mean loss: 33.23
epoch train time: 0:00:00.605962
elapsed time: 0:02:36.112666
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:29:17.879331
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.44
 ---- batch: 020 ----
mean loss: 32.95
 ---- batch: 030 ----
mean loss: 33.27
train mean loss: 33.78
epoch train time: 0:00:00.584085
elapsed time: 0:02:36.697120
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:29:18.463772
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.36
 ---- batch: 020 ----
mean loss: 34.76
 ---- batch: 030 ----
mean loss: 33.24
train mean loss: 33.69
epoch train time: 0:00:00.602525
elapsed time: 0:02:37.300044
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:29:19.066704
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.48
 ---- batch: 020 ----
mean loss: 34.98
 ---- batch: 030 ----
mean loss: 34.58
train mean loss: 33.88
epoch train time: 0:00:00.585718
elapsed time: 0:02:37.886147
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:29:19.652805
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.07
 ---- batch: 020 ----
mean loss: 34.33
 ---- batch: 030 ----
mean loss: 34.37
train mean loss: 33.91
epoch train time: 0:00:00.585035
elapsed time: 0:02:38.471519
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:29:20.238172
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.75
 ---- batch: 020 ----
mean loss: 32.11
 ---- batch: 030 ----
mean loss: 33.67
train mean loss: 33.30
epoch train time: 0:00:00.576952
elapsed time: 0:02:39.048859
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:29:20.815523
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.20
 ---- batch: 020 ----
mean loss: 32.01
 ---- batch: 030 ----
mean loss: 33.54
train mean loss: 33.43
epoch train time: 0:00:00.579382
elapsed time: 0:02:39.628593
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:29:21.395260
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.55
 ---- batch: 020 ----
mean loss: 33.24
 ---- batch: 030 ----
mean loss: 31.89
train mean loss: 33.54
epoch train time: 0:00:00.595714
elapsed time: 0:02:40.224637
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:29:21.991293
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.21
 ---- batch: 020 ----
mean loss: 34.29
 ---- batch: 030 ----
mean loss: 34.06
train mean loss: 33.42
epoch train time: 0:00:00.585099
elapsed time: 0:02:40.817994
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_7/checkpoint.pth.tar
**** end time: 2019-09-27 15:29:22.584565 ****
