Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_5', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29883
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:20:45.684270 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:20:45.693885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4013.01
 ---- batch: 020 ----
mean loss: 3671.70
 ---- batch: 030 ----
mean loss: 3499.64
train mean loss: 3673.32
epoch train time: 0:00:13.048122
elapsed time: 0:00:13.064950
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:20:58.749265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3173.54
 ---- batch: 020 ----
mean loss: 2963.16
 ---- batch: 030 ----
mean loss: 2830.53
train mean loss: 2955.24
epoch train time: 0:00:00.580707
elapsed time: 0:00:13.646012
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:20:59.330432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2627.33
 ---- batch: 020 ----
mean loss: 2496.21
 ---- batch: 030 ----
mean loss: 2418.28
train mean loss: 2485.49
epoch train time: 0:00:00.593317
elapsed time: 0:00:14.239728
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:20:59.924105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2273.30
 ---- batch: 020 ----
mean loss: 2181.24
 ---- batch: 030 ----
mean loss: 2139.37
train mean loss: 2186.61
epoch train time: 0:00:00.577123
elapsed time: 0:00:14.817263
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:21:00.501657
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2005.88
 ---- batch: 020 ----
mean loss: 1948.20
 ---- batch: 030 ----
mean loss: 1987.07
train mean loss: 1968.87
epoch train time: 0:00:00.590785
elapsed time: 0:00:15.408460
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:21:01.092836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1859.04
 ---- batch: 020 ----
mean loss: 1816.22
 ---- batch: 030 ----
mean loss: 1790.18
train mean loss: 1813.79
epoch train time: 0:00:00.583272
elapsed time: 0:00:15.992141
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:21:01.676522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1748.97
 ---- batch: 020 ----
mean loss: 1683.27
 ---- batch: 030 ----
mean loss: 1652.50
train mean loss: 1687.78
epoch train time: 0:00:00.596032
elapsed time: 0:00:16.588552
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:21:02.272927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1606.30
 ---- batch: 020 ----
mean loss: 1595.45
 ---- batch: 030 ----
mean loss: 1529.99
train mean loss: 1570.56
epoch train time: 0:00:00.596350
elapsed time: 0:00:17.185310
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:21:02.869688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1507.12
 ---- batch: 020 ----
mean loss: 1474.67
 ---- batch: 030 ----
mean loss: 1452.06
train mean loss: 1472.59
epoch train time: 0:00:00.596778
elapsed time: 0:00:17.782448
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:21:03.466861
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1433.18
 ---- batch: 020 ----
mean loss: 1379.17
 ---- batch: 030 ----
mean loss: 1359.72
train mean loss: 1383.43
epoch train time: 0:00:00.605274
elapsed time: 0:00:18.388142
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:21:04.072517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1321.19
 ---- batch: 020 ----
mean loss: 1327.15
 ---- batch: 030 ----
mean loss: 1282.74
train mean loss: 1305.07
epoch train time: 0:00:00.579865
elapsed time: 0:00:18.968353
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:21:04.652747
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1251.42
 ---- batch: 020 ----
mean loss: 1244.62
 ---- batch: 030 ----
mean loss: 1200.62
train mean loss: 1232.02
epoch train time: 0:00:00.594258
elapsed time: 0:00:19.563018
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:21:05.247397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1189.59
 ---- batch: 020 ----
mean loss: 1157.21
 ---- batch: 030 ----
mean loss: 1158.56
train mean loss: 1160.28
epoch train time: 0:00:00.607826
elapsed time: 0:00:20.171255
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:21:05.855634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1137.93
 ---- batch: 020 ----
mean loss: 1104.93
 ---- batch: 030 ----
mean loss: 1066.01
train mean loss: 1094.21
epoch train time: 0:00:00.580421
elapsed time: 0:00:20.752029
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:21:06.436400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1045.27
 ---- batch: 020 ----
mean loss: 1042.33
 ---- batch: 030 ----
mean loss: 1017.23
train mean loss: 1030.85
epoch train time: 0:00:00.594219
elapsed time: 0:00:21.346624
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:21:07.031018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 985.46
 ---- batch: 020 ----
mean loss: 972.18
 ---- batch: 030 ----
mean loss: 963.39
train mean loss: 969.70
epoch train time: 0:00:00.594699
elapsed time: 0:00:21.941730
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:21:07.626131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 930.86
 ---- batch: 020 ----
mean loss: 910.44
 ---- batch: 030 ----
mean loss: 904.49
train mean loss: 911.05
epoch train time: 0:00:00.609976
elapsed time: 0:00:22.552102
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:21:08.236477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 882.65
 ---- batch: 020 ----
mean loss: 863.53
 ---- batch: 030 ----
mean loss: 835.23
train mean loss: 860.48
epoch train time: 0:00:00.597649
elapsed time: 0:00:23.150259
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:21:08.834642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 828.25
 ---- batch: 020 ----
mean loss: 810.24
 ---- batch: 030 ----
mean loss: 786.19
train mean loss: 804.73
epoch train time: 0:00:00.580883
elapsed time: 0:00:23.731569
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:21:09.415947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 777.18
 ---- batch: 020 ----
mean loss: 756.88
 ---- batch: 030 ----
mean loss: 749.93
train mean loss: 757.75
epoch train time: 0:00:00.594521
elapsed time: 0:00:24.326464
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:21:10.010842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 713.41
 ---- batch: 020 ----
mean loss: 720.34
 ---- batch: 030 ----
mean loss: 703.80
train mean loss: 713.10
epoch train time: 0:00:00.597096
elapsed time: 0:00:24.923924
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:21:10.608308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 683.61
 ---- batch: 020 ----
mean loss: 688.96
 ---- batch: 030 ----
mean loss: 659.58
train mean loss: 671.05
epoch train time: 0:00:00.598311
elapsed time: 0:00:25.522592
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:21:11.206984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 651.67
 ---- batch: 020 ----
mean loss: 637.12
 ---- batch: 030 ----
mean loss: 626.32
train mean loss: 632.37
epoch train time: 0:00:00.591625
elapsed time: 0:00:26.114664
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:21:11.799051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 600.36
 ---- batch: 020 ----
mean loss: 616.11
 ---- batch: 030 ----
mean loss: 600.23
train mean loss: 599.42
epoch train time: 0:00:00.597024
elapsed time: 0:00:26.712154
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:21:12.396534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 580.25
 ---- batch: 020 ----
mean loss: 570.49
 ---- batch: 030 ----
mean loss: 548.79
train mean loss: 561.85
epoch train time: 0:00:00.597024
elapsed time: 0:00:27.309611
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:21:12.993999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 532.74
 ---- batch: 020 ----
mean loss: 546.24
 ---- batch: 030 ----
mean loss: 526.28
train mean loss: 531.29
epoch train time: 0:00:00.583337
elapsed time: 0:00:27.893406
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:21:13.577814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 515.58
 ---- batch: 020 ----
mean loss: 511.25
 ---- batch: 030 ----
mean loss: 491.21
train mean loss: 505.33
epoch train time: 0:00:00.616289
elapsed time: 0:00:28.510070
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:21:14.194463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 487.08
 ---- batch: 020 ----
mean loss: 472.19
 ---- batch: 030 ----
mean loss: 464.38
train mean loss: 472.37
epoch train time: 0:00:00.594941
elapsed time: 0:00:29.105432
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:21:14.789809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 449.29
 ---- batch: 020 ----
mean loss: 459.81
 ---- batch: 030 ----
mean loss: 435.31
train mean loss: 444.99
epoch train time: 0:00:00.591424
elapsed time: 0:00:29.697206
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:21:15.381585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 428.99
 ---- batch: 020 ----
mean loss: 426.44
 ---- batch: 030 ----
mean loss: 421.95
train mean loss: 425.18
epoch train time: 0:00:00.592095
elapsed time: 0:00:30.289672
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:21:15.974050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.11
 ---- batch: 020 ----
mean loss: 390.39
 ---- batch: 030 ----
mean loss: 408.52
train mean loss: 398.96
epoch train time: 0:00:00.589455
elapsed time: 0:00:30.879564
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:21:16.563939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 384.67
 ---- batch: 020 ----
mean loss: 383.98
 ---- batch: 030 ----
mean loss: 372.94
train mean loss: 377.61
epoch train time: 0:00:00.613148
elapsed time: 0:00:31.493061
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:21:17.177430
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.43
 ---- batch: 020 ----
mean loss: 357.65
 ---- batch: 030 ----
mean loss: 346.58
train mean loss: 357.35
epoch train time: 0:00:00.581480
elapsed time: 0:00:32.074954
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:21:17.759329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 349.96
 ---- batch: 020 ----
mean loss: 348.53
 ---- batch: 030 ----
mean loss: 336.33
train mean loss: 341.52
epoch train time: 0:00:00.604494
elapsed time: 0:00:32.679804
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:21:18.364175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 326.95
 ---- batch: 020 ----
mean loss: 326.91
 ---- batch: 030 ----
mean loss: 320.18
train mean loss: 323.39
epoch train time: 0:00:00.594883
elapsed time: 0:00:33.275272
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:21:18.959688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.26
 ---- batch: 020 ----
mean loss: 302.20
 ---- batch: 030 ----
mean loss: 307.55
train mean loss: 306.30
epoch train time: 0:00:00.593214
elapsed time: 0:00:33.868911
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:21:19.553280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.80
 ---- batch: 020 ----
mean loss: 293.27
 ---- batch: 030 ----
mean loss: 291.31
train mean loss: 292.72
epoch train time: 0:00:00.587272
elapsed time: 0:00:34.456604
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:21:20.140988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.94
 ---- batch: 020 ----
mean loss: 276.37
 ---- batch: 030 ----
mean loss: 272.30
train mean loss: 275.33
epoch train time: 0:00:00.600402
elapsed time: 0:00:35.057420
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:21:20.741832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.48
 ---- batch: 020 ----
mean loss: 263.50
 ---- batch: 030 ----
mean loss: 262.25
train mean loss: 262.48
epoch train time: 0:00:00.581426
elapsed time: 0:00:35.639236
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:21:21.323620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.40
 ---- batch: 020 ----
mean loss: 248.60
 ---- batch: 030 ----
mean loss: 250.01
train mean loss: 250.88
epoch train time: 0:00:00.588603
elapsed time: 0:00:36.228205
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:21:21.912580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.54
 ---- batch: 020 ----
mean loss: 236.21
 ---- batch: 030 ----
mean loss: 240.13
train mean loss: 240.92
epoch train time: 0:00:00.596410
elapsed time: 0:00:36.824985
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:21:22.509359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.98
 ---- batch: 020 ----
mean loss: 226.17
 ---- batch: 030 ----
mean loss: 232.23
train mean loss: 230.11
epoch train time: 0:00:00.604209
elapsed time: 0:00:37.429553
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:21:23.113936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.54
 ---- batch: 020 ----
mean loss: 220.81
 ---- batch: 030 ----
mean loss: 213.20
train mean loss: 219.88
epoch train time: 0:00:00.587456
elapsed time: 0:00:38.017457
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:21:23.701830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.41
 ---- batch: 020 ----
mean loss: 212.32
 ---- batch: 030 ----
mean loss: 209.46
train mean loss: 210.42
epoch train time: 0:00:00.605384
elapsed time: 0:00:38.623192
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:21:24.307612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.62
 ---- batch: 020 ----
mean loss: 200.65
 ---- batch: 030 ----
mean loss: 199.09
train mean loss: 201.50
epoch train time: 0:00:00.593735
elapsed time: 0:00:39.217382
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:21:24.901800
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.21
 ---- batch: 020 ----
mean loss: 192.43
 ---- batch: 030 ----
mean loss: 193.47
train mean loss: 194.59
epoch train time: 0:00:00.587101
elapsed time: 0:00:39.804865
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:21:25.489237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.33
 ---- batch: 020 ----
mean loss: 191.95
 ---- batch: 030 ----
mean loss: 186.46
train mean loss: 186.59
epoch train time: 0:00:00.593575
elapsed time: 0:00:40.398773
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:21:26.083152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.03
 ---- batch: 020 ----
mean loss: 179.25
 ---- batch: 030 ----
mean loss: 179.13
train mean loss: 179.27
epoch train time: 0:00:00.592568
elapsed time: 0:00:40.991746
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:21:26.676140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.69
 ---- batch: 020 ----
mean loss: 174.67
 ---- batch: 030 ----
mean loss: 175.21
train mean loss: 174.15
epoch train time: 0:00:00.586906
elapsed time: 0:00:41.579013
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:21:27.263388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.33
 ---- batch: 020 ----
mean loss: 169.93
 ---- batch: 030 ----
mean loss: 165.81
train mean loss: 166.83
epoch train time: 0:00:00.602465
elapsed time: 0:00:42.181838
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:21:27.866219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.23
 ---- batch: 020 ----
mean loss: 158.92
 ---- batch: 030 ----
mean loss: 162.12
train mean loss: 161.62
epoch train time: 0:00:00.592098
elapsed time: 0:00:42.774284
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:21:28.458658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.89
 ---- batch: 020 ----
mean loss: 155.51
 ---- batch: 030 ----
mean loss: 154.68
train mean loss: 156.76
epoch train time: 0:00:00.603507
elapsed time: 0:00:43.378185
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:21:29.062559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.62
 ---- batch: 020 ----
mean loss: 152.01
 ---- batch: 030 ----
mean loss: 151.04
train mean loss: 151.63
epoch train time: 0:00:00.578809
elapsed time: 0:00:43.957359
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:21:29.641753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.10
 ---- batch: 020 ----
mean loss: 150.94
 ---- batch: 030 ----
mean loss: 145.73
train mean loss: 147.26
epoch train time: 0:00:00.585520
elapsed time: 0:00:44.543328
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:21:30.227727
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.65
 ---- batch: 020 ----
mean loss: 143.76
 ---- batch: 030 ----
mean loss: 139.62
train mean loss: 142.86
epoch train time: 0:00:00.582378
elapsed time: 0:00:45.126098
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:21:30.810499
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.38
 ---- batch: 020 ----
mean loss: 140.86
 ---- batch: 030 ----
mean loss: 135.70
train mean loss: 139.41
epoch train time: 0:00:00.580661
elapsed time: 0:00:45.707117
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:21:31.391494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.79
 ---- batch: 020 ----
mean loss: 136.37
 ---- batch: 030 ----
mean loss: 133.96
train mean loss: 134.92
epoch train time: 0:00:00.581947
elapsed time: 0:00:46.289439
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:21:31.973816
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.55
 ---- batch: 020 ----
mean loss: 130.27
 ---- batch: 030 ----
mean loss: 131.46
train mean loss: 130.91
epoch train time: 0:00:00.589317
elapsed time: 0:00:46.879127
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:21:32.563503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.74
 ---- batch: 020 ----
mean loss: 130.38
 ---- batch: 030 ----
mean loss: 130.92
train mean loss: 129.13
epoch train time: 0:00:00.594823
elapsed time: 0:00:47.474341
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:21:33.158721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.20
 ---- batch: 020 ----
mean loss: 120.31
 ---- batch: 030 ----
mean loss: 127.56
train mean loss: 125.54
epoch train time: 0:00:00.600281
elapsed time: 0:00:48.074993
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:21:33.759381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.60
 ---- batch: 020 ----
mean loss: 122.96
 ---- batch: 030 ----
mean loss: 122.23
train mean loss: 122.83
epoch train time: 0:00:00.606130
elapsed time: 0:00:48.681583
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:21:34.365963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.57
 ---- batch: 020 ----
mean loss: 117.98
 ---- batch: 030 ----
mean loss: 121.69
train mean loss: 119.53
epoch train time: 0:00:00.598992
elapsed time: 0:00:49.280954
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:21:34.965362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.71
 ---- batch: 020 ----
mean loss: 116.77
 ---- batch: 030 ----
mean loss: 115.84
train mean loss: 117.18
epoch train time: 0:00:00.575041
elapsed time: 0:00:49.856428
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:21:35.540793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.22
 ---- batch: 020 ----
mean loss: 115.85
 ---- batch: 030 ----
mean loss: 115.94
train mean loss: 115.84
epoch train time: 0:00:00.590629
elapsed time: 0:00:50.447418
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:21:36.131798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.27
 ---- batch: 020 ----
mean loss: 112.27
 ---- batch: 030 ----
mean loss: 113.82
train mean loss: 113.87
epoch train time: 0:00:00.607440
elapsed time: 0:00:51.055227
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:21:36.739603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.02
 ---- batch: 020 ----
mean loss: 111.85
 ---- batch: 030 ----
mean loss: 112.05
train mean loss: 111.72
epoch train time: 0:00:00.580804
elapsed time: 0:00:51.636360
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:21:37.320734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.36
 ---- batch: 020 ----
mean loss: 109.53
 ---- batch: 030 ----
mean loss: 106.78
train mean loss: 108.90
epoch train time: 0:00:00.606106
elapsed time: 0:00:52.242967
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:21:37.927387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.27
 ---- batch: 020 ----
mean loss: 108.48
 ---- batch: 030 ----
mean loss: 109.18
train mean loss: 109.34
epoch train time: 0:00:00.591742
elapsed time: 0:00:52.835130
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:21:38.519524
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.14
 ---- batch: 020 ----
mean loss: 103.71
 ---- batch: 030 ----
mean loss: 103.24
train mean loss: 106.10
epoch train time: 0:00:00.590749
elapsed time: 0:00:53.426302
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:21:39.110714
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.50
 ---- batch: 020 ----
mean loss: 104.17
 ---- batch: 030 ----
mean loss: 102.88
train mean loss: 104.60
epoch train time: 0:00:00.575861
elapsed time: 0:00:54.002575
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:21:39.686947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.95
 ---- batch: 020 ----
mean loss: 103.45
 ---- batch: 030 ----
mean loss: 101.95
train mean loss: 101.57
epoch train time: 0:00:00.593503
elapsed time: 0:00:54.596416
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:21:40.280820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.70
 ---- batch: 020 ----
mean loss: 101.39
 ---- batch: 030 ----
mean loss: 99.41
train mean loss: 100.79
epoch train time: 0:00:00.613280
elapsed time: 0:00:55.210150
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:21:40.894533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.44
 ---- batch: 020 ----
mean loss: 99.12
 ---- batch: 030 ----
mean loss: 102.15
train mean loss: 99.47
epoch train time: 0:00:00.590815
elapsed time: 0:00:55.801288
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:21:41.485675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.96
 ---- batch: 020 ----
mean loss: 101.35
 ---- batch: 030 ----
mean loss: 99.05
train mean loss: 98.63
epoch train time: 0:00:00.592242
elapsed time: 0:00:56.393979
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:21:42.078376
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.05
 ---- batch: 020 ----
mean loss: 98.63
 ---- batch: 030 ----
mean loss: 97.86
train mean loss: 97.29
epoch train time: 0:00:00.600481
elapsed time: 0:00:56.994915
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:21:42.679334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.32
 ---- batch: 020 ----
mean loss: 96.43
 ---- batch: 030 ----
mean loss: 98.52
train mean loss: 96.29
epoch train time: 0:00:00.596860
elapsed time: 0:00:57.592216
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:21:43.276624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.45
 ---- batch: 020 ----
mean loss: 93.24
 ---- batch: 030 ----
mean loss: 93.01
train mean loss: 94.72
epoch train time: 0:00:00.588871
elapsed time: 0:00:58.181502
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:21:43.865888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.99
 ---- batch: 020 ----
mean loss: 91.64
 ---- batch: 030 ----
mean loss: 94.87
train mean loss: 93.48
epoch train time: 0:00:00.597007
elapsed time: 0:00:58.778889
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:21:44.463272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.73
 ---- batch: 020 ----
mean loss: 90.53
 ---- batch: 030 ----
mean loss: 97.93
train mean loss: 93.70
epoch train time: 0:00:00.599122
elapsed time: 0:00:59.378399
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:21:45.062776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.76
 ---- batch: 020 ----
mean loss: 92.07
 ---- batch: 030 ----
mean loss: 92.18
train mean loss: 91.94
epoch train time: 0:00:00.577400
elapsed time: 0:00:59.956150
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:21:45.640543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.02
 ---- batch: 020 ----
mean loss: 87.11
 ---- batch: 030 ----
mean loss: 88.83
train mean loss: 90.20
epoch train time: 0:00:00.580082
elapsed time: 0:01:00.536617
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:21:46.220990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.33
 ---- batch: 020 ----
mean loss: 92.74
 ---- batch: 030 ----
mean loss: 92.35
train mean loss: 90.55
epoch train time: 0:00:00.611579
elapsed time: 0:01:01.148626
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:21:46.833052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.16
 ---- batch: 020 ----
mean loss: 93.75
 ---- batch: 030 ----
mean loss: 85.69
train mean loss: 89.49
epoch train time: 0:00:00.589650
elapsed time: 0:01:01.738687
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:21:47.423066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.53
 ---- batch: 020 ----
mean loss: 84.63
 ---- batch: 030 ----
mean loss: 88.53
train mean loss: 87.52
epoch train time: 0:00:00.595782
elapsed time: 0:01:02.334866
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:21:48.019242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.97
 ---- batch: 020 ----
mean loss: 91.51
 ---- batch: 030 ----
mean loss: 86.72
train mean loss: 87.51
epoch train time: 0:00:00.590661
elapsed time: 0:01:02.925857
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:21:48.610229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.92
 ---- batch: 020 ----
mean loss: 88.01
 ---- batch: 030 ----
mean loss: 84.55
train mean loss: 86.11
epoch train time: 0:00:00.583650
elapsed time: 0:01:03.509858
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:21:49.194233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.07
 ---- batch: 020 ----
mean loss: 86.53
 ---- batch: 030 ----
mean loss: 87.85
train mean loss: 86.62
epoch train time: 0:00:00.589625
elapsed time: 0:01:04.099843
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:21:49.784222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.18
 ---- batch: 020 ----
mean loss: 85.79
 ---- batch: 030 ----
mean loss: 84.00
train mean loss: 85.23
epoch train time: 0:00:00.586662
elapsed time: 0:01:04.686852
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:21:50.371230
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.10
 ---- batch: 020 ----
mean loss: 81.92
 ---- batch: 030 ----
mean loss: 83.73
train mean loss: 84.41
epoch train time: 0:00:00.591450
elapsed time: 0:01:05.278688
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:21:50.963084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.91
 ---- batch: 020 ----
mean loss: 83.71
 ---- batch: 030 ----
mean loss: 85.66
train mean loss: 85.22
epoch train time: 0:00:00.596812
elapsed time: 0:01:05.875891
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:21:51.560269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.95
 ---- batch: 020 ----
mean loss: 84.19
 ---- batch: 030 ----
mean loss: 84.04
train mean loss: 83.44
epoch train time: 0:00:00.597816
elapsed time: 0:01:06.474044
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:21:52.158415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.52
 ---- batch: 020 ----
mean loss: 84.42
 ---- batch: 030 ----
mean loss: 84.03
train mean loss: 82.90
epoch train time: 0:00:00.585381
elapsed time: 0:01:07.059783
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:21:52.744161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.75
 ---- batch: 020 ----
mean loss: 81.61
 ---- batch: 030 ----
mean loss: 82.91
train mean loss: 82.80
epoch train time: 0:00:00.580836
elapsed time: 0:01:07.640972
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:21:53.325344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.10
 ---- batch: 020 ----
mean loss: 81.65
 ---- batch: 030 ----
mean loss: 80.62
train mean loss: 80.54
epoch train time: 0:00:00.584348
elapsed time: 0:01:08.225674
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:21:53.910050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.38
 ---- batch: 020 ----
mean loss: 80.40
 ---- batch: 030 ----
mean loss: 80.76
train mean loss: 80.75
epoch train time: 0:00:00.587261
elapsed time: 0:01:08.813312
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:21:54.497726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.01
 ---- batch: 020 ----
mean loss: 76.34
 ---- batch: 030 ----
mean loss: 82.20
train mean loss: 79.77
epoch train time: 0:00:00.586549
elapsed time: 0:01:09.400249
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:21:55.084632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.03
 ---- batch: 020 ----
mean loss: 78.39
 ---- batch: 030 ----
mean loss: 81.41
train mean loss: 78.97
epoch train time: 0:00:00.578364
elapsed time: 0:01:09.978974
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:21:55.663349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.06
 ---- batch: 020 ----
mean loss: 79.81
 ---- batch: 030 ----
mean loss: 79.78
train mean loss: 79.15
epoch train time: 0:00:00.598316
elapsed time: 0:01:10.577636
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:21:56.262013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.00
 ---- batch: 020 ----
mean loss: 79.19
 ---- batch: 030 ----
mean loss: 78.19
train mean loss: 78.65
epoch train time: 0:00:00.589061
elapsed time: 0:01:11.167107
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:21:56.851498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.50
 ---- batch: 020 ----
mean loss: 79.17
 ---- batch: 030 ----
mean loss: 74.42
train mean loss: 77.85
epoch train time: 0:00:00.589453
elapsed time: 0:01:11.756914
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:21:57.441289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.12
 ---- batch: 020 ----
mean loss: 78.68
 ---- batch: 030 ----
mean loss: 73.85
train mean loss: 77.26
epoch train time: 0:00:00.609126
elapsed time: 0:01:12.366479
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:21:58.050879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.62
 ---- batch: 020 ----
mean loss: 76.85
 ---- batch: 030 ----
mean loss: 75.34
train mean loss: 76.45
epoch train time: 0:00:00.583542
elapsed time: 0:01:12.950421
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:21:58.634794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.50
 ---- batch: 020 ----
mean loss: 77.63
 ---- batch: 030 ----
mean loss: 73.39
train mean loss: 75.46
epoch train time: 0:00:00.592326
elapsed time: 0:01:13.543079
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:21:59.227469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.38
 ---- batch: 020 ----
mean loss: 77.82
 ---- batch: 030 ----
mean loss: 73.73
train mean loss: 75.97
epoch train time: 0:00:00.592721
elapsed time: 0:01:14.136164
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:21:59.820537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.75
 ---- batch: 020 ----
mean loss: 73.73
 ---- batch: 030 ----
mean loss: 74.25
train mean loss: 76.26
epoch train time: 0:00:00.597764
elapsed time: 0:01:14.734260
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:22:00.418651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.04
 ---- batch: 020 ----
mean loss: 72.56
 ---- batch: 030 ----
mean loss: 76.38
train mean loss: 73.90
epoch train time: 0:00:00.600030
elapsed time: 0:01:15.334655
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:22:01.019034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.66
 ---- batch: 020 ----
mean loss: 75.80
 ---- batch: 030 ----
mean loss: 72.94
train mean loss: 74.67
epoch train time: 0:00:00.592943
elapsed time: 0:01:15.927995
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:22:01.612309
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.20
 ---- batch: 020 ----
mean loss: 73.32
 ---- batch: 030 ----
mean loss: 74.40
train mean loss: 73.17
epoch train time: 0:00:00.599533
elapsed time: 0:01:16.527862
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:22:02.212239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.15
 ---- batch: 020 ----
mean loss: 73.38
 ---- batch: 030 ----
mean loss: 69.93
train mean loss: 72.45
epoch train time: 0:00:00.589747
elapsed time: 0:01:17.118006
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:22:02.802405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.51
 ---- batch: 020 ----
mean loss: 72.77
 ---- batch: 030 ----
mean loss: 71.86
train mean loss: 72.43
epoch train time: 0:00:00.594719
elapsed time: 0:01:17.713114
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:22:03.397510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.51
 ---- batch: 020 ----
mean loss: 70.95
 ---- batch: 030 ----
mean loss: 75.17
train mean loss: 72.31
epoch train time: 0:00:00.584215
elapsed time: 0:01:18.297683
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:22:03.982056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.72
 ---- batch: 020 ----
mean loss: 71.21
 ---- batch: 030 ----
mean loss: 70.07
train mean loss: 71.74
epoch train time: 0:00:00.605662
elapsed time: 0:01:18.903841
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:22:04.588235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.50
 ---- batch: 020 ----
mean loss: 71.27
 ---- batch: 030 ----
mean loss: 70.71
train mean loss: 71.36
epoch train time: 0:00:00.625339
elapsed time: 0:01:19.529634
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:22:05.214011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.02
 ---- batch: 020 ----
mean loss: 68.82
 ---- batch: 030 ----
mean loss: 70.24
train mean loss: 70.00
epoch train time: 0:00:00.599080
elapsed time: 0:01:20.129164
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:22:05.813548
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.91
 ---- batch: 020 ----
mean loss: 67.99
 ---- batch: 030 ----
mean loss: 71.74
train mean loss: 70.28
epoch train time: 0:00:00.582041
elapsed time: 0:01:20.711569
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:22:06.395945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.20
 ---- batch: 020 ----
mean loss: 68.98
 ---- batch: 030 ----
mean loss: 71.26
train mean loss: 69.95
epoch train time: 0:00:00.605602
elapsed time: 0:01:21.317594
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:22:07.001968
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.95
 ---- batch: 020 ----
mean loss: 69.89
 ---- batch: 030 ----
mean loss: 70.00
train mean loss: 68.96
epoch train time: 0:00:00.585512
elapsed time: 0:01:21.903470
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:22:07.587901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.02
 ---- batch: 020 ----
mean loss: 68.92
 ---- batch: 030 ----
mean loss: 70.61
train mean loss: 68.88
epoch train time: 0:00:00.601870
elapsed time: 0:01:22.505798
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:22:08.190177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.89
 ---- batch: 020 ----
mean loss: 66.35
 ---- batch: 030 ----
mean loss: 69.32
train mean loss: 68.22
epoch train time: 0:00:00.597386
elapsed time: 0:01:23.103657
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:22:08.788046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.86
 ---- batch: 020 ----
mean loss: 67.38
 ---- batch: 030 ----
mean loss: 68.42
train mean loss: 67.76
epoch train time: 0:00:00.582824
elapsed time: 0:01:23.686869
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:22:09.371242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.57
 ---- batch: 020 ----
mean loss: 68.00
 ---- batch: 030 ----
mean loss: 65.19
train mean loss: 67.09
epoch train time: 0:00:00.597369
elapsed time: 0:01:24.284598
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:22:09.968991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.51
 ---- batch: 020 ----
mean loss: 65.95
 ---- batch: 030 ----
mean loss: 68.93
train mean loss: 66.48
epoch train time: 0:00:00.589131
elapsed time: 0:01:24.874106
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:22:10.558476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.32
 ---- batch: 020 ----
mean loss: 67.20
 ---- batch: 030 ----
mean loss: 64.73
train mean loss: 66.12
epoch train time: 0:00:00.601887
elapsed time: 0:01:25.476315
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:22:11.160694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.84
 ---- batch: 020 ----
mean loss: 65.47
 ---- batch: 030 ----
mean loss: 64.80
train mean loss: 65.41
epoch train time: 0:00:00.585639
elapsed time: 0:01:26.062389
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:22:11.746772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.17
 ---- batch: 020 ----
mean loss: 63.63
 ---- batch: 030 ----
mean loss: 65.70
train mean loss: 65.10
epoch train time: 0:00:00.596540
elapsed time: 0:01:26.659313
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:22:12.343692
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.96
 ---- batch: 020 ----
mean loss: 63.94
 ---- batch: 030 ----
mean loss: 62.97
train mean loss: 64.54
epoch train time: 0:00:00.590185
elapsed time: 0:01:27.249848
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:22:12.934210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.13
 ---- batch: 020 ----
mean loss: 62.95
 ---- batch: 030 ----
mean loss: 65.39
train mean loss: 63.99
epoch train time: 0:00:00.579103
elapsed time: 0:01:27.829398
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:22:13.513733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.24
 ---- batch: 020 ----
mean loss: 62.67
 ---- batch: 030 ----
mean loss: 62.83
train mean loss: 63.37
epoch train time: 0:00:00.592453
elapsed time: 0:01:28.422220
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:22:14.106600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.28
 ---- batch: 020 ----
mean loss: 62.83
 ---- batch: 030 ----
mean loss: 63.96
train mean loss: 63.97
epoch train time: 0:00:00.595307
elapsed time: 0:01:29.017943
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:22:14.702314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.80
 ---- batch: 020 ----
mean loss: 65.77
 ---- batch: 030 ----
mean loss: 63.87
train mean loss: 62.99
epoch train time: 0:00:00.601347
elapsed time: 0:01:29.619627
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:22:15.304038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.72
 ---- batch: 020 ----
mean loss: 61.57
 ---- batch: 030 ----
mean loss: 61.63
train mean loss: 62.07
epoch train time: 0:00:00.593727
elapsed time: 0:01:30.213755
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:22:15.898131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.19
 ---- batch: 020 ----
mean loss: 60.14
 ---- batch: 030 ----
mean loss: 62.03
train mean loss: 61.19
epoch train time: 0:00:00.581434
elapsed time: 0:01:30.795541
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:22:16.479935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.62
 ---- batch: 020 ----
mean loss: 63.24
 ---- batch: 030 ----
mean loss: 59.59
train mean loss: 61.66
epoch train time: 0:00:00.586441
elapsed time: 0:01:31.382368
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:22:17.066749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.14
 ---- batch: 020 ----
mean loss: 61.62
 ---- batch: 030 ----
mean loss: 60.78
train mean loss: 60.92
epoch train time: 0:00:00.588465
elapsed time: 0:01:31.971212
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:22:17.655596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.20
 ---- batch: 020 ----
mean loss: 60.63
 ---- batch: 030 ----
mean loss: 59.78
train mean loss: 60.14
epoch train time: 0:00:00.594917
elapsed time: 0:01:32.566597
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:22:18.250987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.15
 ---- batch: 020 ----
mean loss: 58.54
 ---- batch: 030 ----
mean loss: 61.68
train mean loss: 60.26
epoch train time: 0:00:00.595264
elapsed time: 0:01:33.162358
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:22:18.846740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.35
 ---- batch: 020 ----
mean loss: 60.16
 ---- batch: 030 ----
mean loss: 55.30
train mean loss: 59.07
epoch train time: 0:00:00.593644
elapsed time: 0:01:33.756445
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:22:19.440861
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.30
 ---- batch: 020 ----
mean loss: 59.91
 ---- batch: 030 ----
mean loss: 54.72
train mean loss: 58.53
epoch train time: 0:00:00.588572
elapsed time: 0:01:34.345417
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:22:20.029801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.08
 ---- batch: 020 ----
mean loss: 60.99
 ---- batch: 030 ----
mean loss: 57.63
train mean loss: 58.53
epoch train time: 0:00:00.580944
elapsed time: 0:01:34.926751
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:22:20.611133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.83
 ---- batch: 020 ----
mean loss: 58.83
 ---- batch: 030 ----
mean loss: 58.19
train mean loss: 57.71
epoch train time: 0:00:00.597333
elapsed time: 0:01:35.524502
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:22:21.208932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.04
 ---- batch: 020 ----
mean loss: 55.92
 ---- batch: 030 ----
mean loss: 59.93
train mean loss: 57.41
epoch train time: 0:00:00.615038
elapsed time: 0:01:36.139987
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:22:21.824362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.57
 ---- batch: 020 ----
mean loss: 57.30
 ---- batch: 030 ----
mean loss: 59.23
train mean loss: 57.96
epoch train time: 0:00:00.594258
elapsed time: 0:01:36.734697
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:22:22.419074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.74
 ---- batch: 020 ----
mean loss: 56.49
 ---- batch: 030 ----
mean loss: 59.03
train mean loss: 56.42
epoch train time: 0:00:00.597942
elapsed time: 0:01:37.333050
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:22:23.017426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.27
 ---- batch: 020 ----
mean loss: 54.34
 ---- batch: 030 ----
mean loss: 56.87
train mean loss: 55.42
epoch train time: 0:00:00.603633
elapsed time: 0:01:37.937046
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:22:23.621482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.37
 ---- batch: 020 ----
mean loss: 53.91
 ---- batch: 030 ----
mean loss: 54.52
train mean loss: 54.36
epoch train time: 0:00:00.622599
elapsed time: 0:01:38.560136
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:22:24.244511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.74
 ---- batch: 020 ----
mean loss: 55.94
 ---- batch: 030 ----
mean loss: 52.17
train mean loss: 54.95
epoch train time: 0:00:00.589343
elapsed time: 0:01:39.149953
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:22:24.834325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.23
 ---- batch: 020 ----
mean loss: 55.79
 ---- batch: 030 ----
mean loss: 53.35
train mean loss: 53.76
epoch train time: 0:00:00.593100
elapsed time: 0:01:39.743454
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:22:25.427827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.28
 ---- batch: 020 ----
mean loss: 54.12
 ---- batch: 030 ----
mean loss: 54.78
train mean loss: 53.51
epoch train time: 0:00:00.594292
elapsed time: 0:01:40.338087
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:22:26.022460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.03
 ---- batch: 020 ----
mean loss: 54.35
 ---- batch: 030 ----
mean loss: 52.60
train mean loss: 53.25
epoch train time: 0:00:00.595789
elapsed time: 0:01:40.934329
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:22:26.618645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.20
 ---- batch: 020 ----
mean loss: 55.29
 ---- batch: 030 ----
mean loss: 51.29
train mean loss: 53.60
epoch train time: 0:00:00.599151
elapsed time: 0:01:41.533771
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:22:27.218157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.92
 ---- batch: 020 ----
mean loss: 51.75
 ---- batch: 030 ----
mean loss: 51.51
train mean loss: 51.82
epoch train time: 0:00:00.595193
elapsed time: 0:01:42.129394
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:22:27.813773
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.66
 ---- batch: 020 ----
mean loss: 50.65
 ---- batch: 030 ----
mean loss: 54.06
train mean loss: 51.61
epoch train time: 0:00:00.604760
elapsed time: 0:01:42.734586
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:22:28.418984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.07
 ---- batch: 020 ----
mean loss: 52.57
 ---- batch: 030 ----
mean loss: 50.36
train mean loss: 51.26
epoch train time: 0:00:00.598895
elapsed time: 0:01:43.333989
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:22:29.018411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.30
 ---- batch: 020 ----
mean loss: 50.26
 ---- batch: 030 ----
mean loss: 50.81
train mean loss: 49.89
epoch train time: 0:00:00.602613
elapsed time: 0:01:43.937039
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:22:29.621459
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.41
 ---- batch: 020 ----
mean loss: 51.42
 ---- batch: 030 ----
mean loss: 50.63
train mean loss: 50.25
epoch train time: 0:00:00.593317
elapsed time: 0:01:44.530750
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:22:30.215129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.85
 ---- batch: 020 ----
mean loss: 48.52
 ---- batch: 030 ----
mean loss: 50.97
train mean loss: 48.73
epoch train time: 0:00:00.604899
elapsed time: 0:01:45.136061
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:22:30.820435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.03
 ---- batch: 020 ----
mean loss: 48.44
 ---- batch: 030 ----
mean loss: 49.32
train mean loss: 49.23
epoch train time: 0:00:00.588473
elapsed time: 0:01:45.724937
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:22:31.409315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.04
 ---- batch: 020 ----
mean loss: 48.21
 ---- batch: 030 ----
mean loss: 50.01
train mean loss: 49.11
epoch train time: 0:00:00.598314
elapsed time: 0:01:46.323658
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:22:32.008055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.16
 ---- batch: 020 ----
mean loss: 50.02
 ---- batch: 030 ----
mean loss: 47.33
train mean loss: 48.10
epoch train time: 0:00:00.595367
elapsed time: 0:01:46.919456
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:22:32.603836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.48
 ---- batch: 020 ----
mean loss: 47.49
 ---- batch: 030 ----
mean loss: 46.02
train mean loss: 47.78
epoch train time: 0:00:00.595840
elapsed time: 0:01:47.515677
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:22:33.200050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.36
 ---- batch: 020 ----
mean loss: 45.17
 ---- batch: 030 ----
mean loss: 49.01
train mean loss: 47.09
epoch train time: 0:00:00.599213
elapsed time: 0:01:48.115279
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:22:33.799664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.75
 ---- batch: 020 ----
mean loss: 45.88
 ---- batch: 030 ----
mean loss: 45.71
train mean loss: 46.92
epoch train time: 0:00:00.600035
elapsed time: 0:01:48.715708
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:22:34.400104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.41
 ---- batch: 020 ----
mean loss: 46.32
 ---- batch: 030 ----
mean loss: 46.13
train mean loss: 45.95
epoch train time: 0:00:00.595799
elapsed time: 0:01:49.311953
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:22:34.996327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.08
 ---- batch: 020 ----
mean loss: 45.10
 ---- batch: 030 ----
mean loss: 45.30
train mean loss: 45.57
epoch train time: 0:00:00.582641
elapsed time: 0:01:49.894950
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:22:35.579322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.13
 ---- batch: 020 ----
mean loss: 43.34
 ---- batch: 030 ----
mean loss: 46.08
train mean loss: 45.19
epoch train time: 0:00:00.592531
elapsed time: 0:01:50.487933
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:22:36.172307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.43
 ---- batch: 020 ----
mean loss: 44.12
 ---- batch: 030 ----
mean loss: 47.11
train mean loss: 44.94
epoch train time: 0:00:00.598326
elapsed time: 0:01:51.086684
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:22:36.771064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.22
 ---- batch: 020 ----
mean loss: 43.22
 ---- batch: 030 ----
mean loss: 43.61
train mean loss: 44.16
epoch train time: 0:00:00.589188
elapsed time: 0:01:51.676234
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:22:37.360622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.34
 ---- batch: 020 ----
mean loss: 44.48
 ---- batch: 030 ----
mean loss: 46.66
train mean loss: 45.38
epoch train time: 0:00:00.587809
elapsed time: 0:01:52.264404
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:22:37.948780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.29
 ---- batch: 020 ----
mean loss: 42.53
 ---- batch: 030 ----
mean loss: 43.59
train mean loss: 43.51
epoch train time: 0:00:00.580155
elapsed time: 0:01:52.844889
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:22:38.529263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.31
 ---- batch: 020 ----
mean loss: 43.91
 ---- batch: 030 ----
mean loss: 42.65
train mean loss: 43.07
epoch train time: 0:00:00.625590
elapsed time: 0:01:53.470862
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:22:39.155254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.73
 ---- batch: 020 ----
mean loss: 43.12
 ---- batch: 030 ----
mean loss: 43.59
train mean loss: 43.03
epoch train time: 0:00:00.582042
elapsed time: 0:01:54.053293
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:22:39.737819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.24
 ---- batch: 020 ----
mean loss: 42.44
 ---- batch: 030 ----
mean loss: 42.40
train mean loss: 42.97
epoch train time: 0:00:00.598451
elapsed time: 0:01:54.652298
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:22:40.336683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.92
 ---- batch: 020 ----
mean loss: 40.54
 ---- batch: 030 ----
mean loss: 41.80
train mean loss: 41.94
epoch train time: 0:00:00.623526
elapsed time: 0:01:55.276167
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:22:40.960545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.82
 ---- batch: 020 ----
mean loss: 42.62
 ---- batch: 030 ----
mean loss: 41.03
train mean loss: 40.94
epoch train time: 0:00:00.599220
elapsed time: 0:01:55.875824
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:22:41.560146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.92
 ---- batch: 020 ----
mean loss: 42.19
 ---- batch: 030 ----
mean loss: 41.58
train mean loss: 40.82
epoch train time: 0:00:00.596795
elapsed time: 0:01:56.472934
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:22:42.157314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.54
 ---- batch: 020 ----
mean loss: 40.01
 ---- batch: 030 ----
mean loss: 42.53
train mean loss: 40.80
epoch train time: 0:00:00.592367
elapsed time: 0:01:57.065701
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:22:42.750078
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.25
 ---- batch: 020 ----
mean loss: 39.07
 ---- batch: 030 ----
mean loss: 40.29
train mean loss: 40.24
epoch train time: 0:00:00.591446
elapsed time: 0:01:57.657496
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:22:43.341876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.59
 ---- batch: 020 ----
mean loss: 39.28
 ---- batch: 030 ----
mean loss: 41.82
train mean loss: 40.18
epoch train time: 0:00:00.583379
elapsed time: 0:01:58.241214
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:22:43.925594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.57
 ---- batch: 020 ----
mean loss: 39.44
 ---- batch: 030 ----
mean loss: 38.76
train mean loss: 38.94
epoch train time: 0:00:00.587389
elapsed time: 0:01:58.828988
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:22:44.513359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.56
 ---- batch: 020 ----
mean loss: 38.40
 ---- batch: 030 ----
mean loss: 40.16
train mean loss: 38.99
epoch train time: 0:00:00.586062
elapsed time: 0:01:59.415383
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:22:45.099758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.11
 ---- batch: 020 ----
mean loss: 38.10
 ---- batch: 030 ----
mean loss: 38.53
train mean loss: 38.47
epoch train time: 0:00:00.586702
elapsed time: 0:02:00.002465
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:22:45.686849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.95
 ---- batch: 020 ----
mean loss: 40.36
 ---- batch: 030 ----
mean loss: 38.40
train mean loss: 38.83
epoch train time: 0:00:00.596036
elapsed time: 0:02:00.598946
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:22:46.283327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.26
 ---- batch: 020 ----
mean loss: 40.02
 ---- batch: 030 ----
mean loss: 37.25
train mean loss: 37.56
epoch train time: 0:00:00.590680
elapsed time: 0:02:01.189991
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:22:46.874369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.09
 ---- batch: 020 ----
mean loss: 37.12
 ---- batch: 030 ----
mean loss: 39.67
train mean loss: 37.91
epoch train time: 0:00:00.587436
elapsed time: 0:02:01.777837
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:22:47.462214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.62
 ---- batch: 020 ----
mean loss: 38.48
 ---- batch: 030 ----
mean loss: 36.55
train mean loss: 37.87
epoch train time: 0:00:00.586243
elapsed time: 0:02:02.364454
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:22:48.048857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.79
 ---- batch: 020 ----
mean loss: 35.75
 ---- batch: 030 ----
mean loss: 36.65
train mean loss: 36.98
epoch train time: 0:00:00.585705
elapsed time: 0:02:02.950559
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:22:48.634974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.17
 ---- batch: 020 ----
mean loss: 35.81
 ---- batch: 030 ----
mean loss: 35.24
train mean loss: 36.32
epoch train time: 0:00:00.591119
elapsed time: 0:02:03.542117
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:22:49.226504
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 34.34
 ---- batch: 020 ----
mean loss: 37.47
 ---- batch: 030 ----
mean loss: 41.47
train mean loss: 37.70
epoch train time: 0:00:00.601560
elapsed time: 0:02:04.144075
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:22:49.828475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.25
 ---- batch: 020 ----
mean loss: 35.87
 ---- batch: 030 ----
mean loss: 34.32
train mean loss: 35.46
epoch train time: 0:00:00.584371
elapsed time: 0:02:04.728954
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:22:50.413373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 35.86
 ---- batch: 020 ----
mean loss: 35.15
 ---- batch: 030 ----
mean loss: 35.67
train mean loss: 35.47
epoch train time: 0:00:00.590754
elapsed time: 0:02:05.320108
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:22:51.004490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.34
 ---- batch: 020 ----
mean loss: 34.07
 ---- batch: 030 ----
mean loss: 35.26
train mean loss: 35.20
epoch train time: 0:00:00.587221
elapsed time: 0:02:05.907703
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:22:51.592093
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.22
 ---- batch: 020 ----
mean loss: 33.63
 ---- batch: 030 ----
mean loss: 34.90
train mean loss: 35.15
epoch train time: 0:00:00.596040
elapsed time: 0:02:06.504176
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:22:52.188581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 33.05
 ---- batch: 020 ----
mean loss: 32.89
 ---- batch: 030 ----
mean loss: 36.61
train mean loss: 34.44
epoch train time: 0:00:00.607527
elapsed time: 0:02:07.112097
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:22:52.796483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 33.64
 ---- batch: 020 ----
mean loss: 36.26
 ---- batch: 030 ----
mean loss: 35.43
train mean loss: 35.27
epoch train time: 0:00:00.584401
elapsed time: 0:02:07.696856
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:22:53.381225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 34.06
 ---- batch: 020 ----
mean loss: 32.53
 ---- batch: 030 ----
mean loss: 34.30
train mean loss: 33.88
epoch train time: 0:00:00.586178
elapsed time: 0:02:08.283346
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:22:53.967718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 34.45
 ---- batch: 020 ----
mean loss: 33.66
 ---- batch: 030 ----
mean loss: 32.74
train mean loss: 33.50
epoch train time: 0:00:00.589968
elapsed time: 0:02:08.873704
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:22:54.558082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 33.25
 ---- batch: 020 ----
mean loss: 34.58
 ---- batch: 030 ----
mean loss: 31.96
train mean loss: 33.10
epoch train time: 0:00:00.612043
elapsed time: 0:02:09.486081
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:22:55.170453
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 33.29
 ---- batch: 020 ----
mean loss: 32.26
 ---- batch: 030 ----
mean loss: 31.83
train mean loss: 32.59
epoch train time: 0:00:00.578200
elapsed time: 0:02:10.064615
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:22:55.748992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 32.05
 ---- batch: 020 ----
mean loss: 33.02
 ---- batch: 030 ----
mean loss: 31.24
train mean loss: 32.11
epoch train time: 0:00:00.595470
elapsed time: 0:02:10.660441
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:22:56.344836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 32.72
 ---- batch: 020 ----
mean loss: 30.90
 ---- batch: 030 ----
mean loss: 34.66
train mean loss: 32.65
epoch train time: 0:00:00.589600
elapsed time: 0:02:11.250403
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:22:56.934776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 33.72
 ---- batch: 020 ----
mean loss: 31.57
 ---- batch: 030 ----
mean loss: 34.86
train mean loss: 33.29
epoch train time: 0:00:00.587310
elapsed time: 0:02:11.838052
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:22:57.522424
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.82
 ---- batch: 020 ----
mean loss: 31.73
 ---- batch: 030 ----
mean loss: 33.82
train mean loss: 31.71
epoch train time: 0:00:00.596923
elapsed time: 0:02:12.435382
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:22:58.119698
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.98
 ---- batch: 020 ----
mean loss: 31.50
 ---- batch: 030 ----
mean loss: 31.30
train mean loss: 30.93
epoch train time: 0:00:00.590011
elapsed time: 0:02:13.025759
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:22:58.710131
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.88
 ---- batch: 020 ----
mean loss: 30.31
 ---- batch: 030 ----
mean loss: 31.11
train mean loss: 31.21
epoch train time: 0:00:00.589480
elapsed time: 0:02:13.615610
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:22:59.299980
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.55
 ---- batch: 020 ----
mean loss: 30.64
 ---- batch: 030 ----
mean loss: 30.51
train mean loss: 30.63
epoch train time: 0:00:00.588805
elapsed time: 0:02:14.204751
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:22:59.889130
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.17
 ---- batch: 020 ----
mean loss: 31.10
 ---- batch: 030 ----
mean loss: 30.76
train mean loss: 31.24
epoch train time: 0:00:00.594313
elapsed time: 0:02:14.799491
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:23:00.483862
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.28
 ---- batch: 020 ----
mean loss: 31.08
 ---- batch: 030 ----
mean loss: 31.31
train mean loss: 30.82
epoch train time: 0:00:00.590285
elapsed time: 0:02:15.390106
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:23:01.074489
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.46
 ---- batch: 020 ----
mean loss: 30.37
 ---- batch: 030 ----
mean loss: 31.61
train mean loss: 30.89
epoch train time: 0:00:00.593680
elapsed time: 0:02:15.984164
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:23:01.668540
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.84
 ---- batch: 020 ----
mean loss: 32.10
 ---- batch: 030 ----
mean loss: 31.04
train mean loss: 30.97
epoch train time: 0:00:00.595707
elapsed time: 0:02:16.580232
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:23:02.264666
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.74
 ---- batch: 020 ----
mean loss: 30.19
 ---- batch: 030 ----
mean loss: 30.23
train mean loss: 30.74
epoch train time: 0:00:00.588817
elapsed time: 0:02:17.169478
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:23:02.853846
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.59
 ---- batch: 020 ----
mean loss: 30.61
 ---- batch: 030 ----
mean loss: 31.81
train mean loss: 30.96
epoch train time: 0:00:00.574039
elapsed time: 0:02:17.743854
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:23:03.428225
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.58
 ---- batch: 020 ----
mean loss: 30.08
 ---- batch: 030 ----
mean loss: 29.31
train mean loss: 30.52
epoch train time: 0:00:00.599963
elapsed time: 0:02:18.344167
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:23:04.028561
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.72
 ---- batch: 020 ----
mean loss: 30.02
 ---- batch: 030 ----
mean loss: 30.87
train mean loss: 30.54
epoch train time: 0:00:00.591337
elapsed time: 0:02:18.935922
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:23:04.620289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.50
 ---- batch: 020 ----
mean loss: 29.36
 ---- batch: 030 ----
mean loss: 30.76
train mean loss: 30.69
epoch train time: 0:00:00.604103
elapsed time: 0:02:19.540347
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:23:05.224725
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.61
 ---- batch: 020 ----
mean loss: 30.39
 ---- batch: 030 ----
mean loss: 30.66
train mean loss: 30.59
epoch train time: 0:00:00.588672
elapsed time: 0:02:20.129400
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:23:05.813778
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.10
 ---- batch: 020 ----
mean loss: 30.41
 ---- batch: 030 ----
mean loss: 30.96
train mean loss: 30.05
epoch train time: 0:00:00.581918
elapsed time: 0:02:20.711673
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:23:06.396069
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.23
 ---- batch: 020 ----
mean loss: 31.16
 ---- batch: 030 ----
mean loss: 29.18
train mean loss: 30.43
epoch train time: 0:00:00.601473
elapsed time: 0:02:21.313531
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:23:06.997910
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.81
 ---- batch: 020 ----
mean loss: 29.73
 ---- batch: 030 ----
mean loss: 32.25
train mean loss: 30.63
epoch train time: 0:00:00.594494
elapsed time: 0:02:21.908365
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:23:07.592737
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.01
 ---- batch: 020 ----
mean loss: 30.75
 ---- batch: 030 ----
mean loss: 29.60
train mean loss: 30.45
epoch train time: 0:00:00.587600
elapsed time: 0:02:22.496311
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:23:08.180690
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.22
 ---- batch: 020 ----
mean loss: 31.34
 ---- batch: 030 ----
mean loss: 30.12
train mean loss: 30.57
epoch train time: 0:00:00.586120
elapsed time: 0:02:23.082814
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:23:08.767186
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.09
 ---- batch: 020 ----
mean loss: 31.19
 ---- batch: 030 ----
mean loss: 32.37
train mean loss: 30.78
epoch train time: 0:00:00.582068
elapsed time: 0:02:23.665308
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:23:09.349709
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.19
 ---- batch: 020 ----
mean loss: 29.44
 ---- batch: 030 ----
mean loss: 31.11
train mean loss: 30.34
epoch train time: 0:00:00.593424
elapsed time: 0:02:24.259091
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:23:09.943470
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.93
 ---- batch: 020 ----
mean loss: 31.25
 ---- batch: 030 ----
mean loss: 29.94
train mean loss: 30.41
epoch train time: 0:00:00.589081
elapsed time: 0:02:24.848510
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:23:10.532904
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.99
 ---- batch: 020 ----
mean loss: 29.48
 ---- batch: 030 ----
mean loss: 31.43
train mean loss: 30.23
epoch train time: 0:00:00.587479
elapsed time: 0:02:25.436380
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:23:11.120757
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.44
 ---- batch: 020 ----
mean loss: 30.06
 ---- batch: 030 ----
mean loss: 31.69
train mean loss: 30.60
epoch train time: 0:00:00.581164
elapsed time: 0:02:26.017940
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:23:11.702334
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.67
 ---- batch: 020 ----
mean loss: 30.06
 ---- batch: 030 ----
mean loss: 30.06
train mean loss: 30.36
epoch train time: 0:00:00.594155
elapsed time: 0:02:26.612460
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:23:12.296858
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.12
 ---- batch: 020 ----
mean loss: 29.21
 ---- batch: 030 ----
mean loss: 27.82
train mean loss: 30.06
epoch train time: 0:00:00.589997
elapsed time: 0:02:27.202840
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:23:12.887232
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.73
 ---- batch: 020 ----
mean loss: 30.57
 ---- batch: 030 ----
mean loss: 30.77
train mean loss: 30.43
epoch train time: 0:00:00.593502
elapsed time: 0:02:27.796759
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:23:13.481142
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.72
 ---- batch: 020 ----
mean loss: 29.43
 ---- batch: 030 ----
mean loss: 30.35
train mean loss: 30.26
epoch train time: 0:00:00.590347
elapsed time: 0:02:28.387477
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:23:14.071856
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.59
 ---- batch: 020 ----
mean loss: 29.55
 ---- batch: 030 ----
mean loss: 30.13
train mean loss: 30.15
epoch train time: 0:00:00.588065
elapsed time: 0:02:28.975889
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:23:14.660268
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.06
 ---- batch: 020 ----
mean loss: 30.79
 ---- batch: 030 ----
mean loss: 29.56
train mean loss: 29.94
epoch train time: 0:00:00.586085
elapsed time: 0:02:29.562319
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:23:15.246695
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.77
 ---- batch: 020 ----
mean loss: 29.65
 ---- batch: 030 ----
mean loss: 29.97
train mean loss: 29.95
epoch train time: 0:00:00.598847
elapsed time: 0:02:30.161565
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:23:15.845958
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.15
 ---- batch: 020 ----
mean loss: 31.00
 ---- batch: 030 ----
mean loss: 29.97
train mean loss: 30.10
epoch train time: 0:00:00.597390
elapsed time: 0:02:30.759314
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:23:16.443738
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.89
 ---- batch: 020 ----
mean loss: 29.89
 ---- batch: 030 ----
mean loss: 29.41
train mean loss: 30.18
epoch train time: 0:00:00.599479
elapsed time: 0:02:31.359341
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:23:17.043664
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.03
 ---- batch: 020 ----
mean loss: 30.56
 ---- batch: 030 ----
mean loss: 29.29
train mean loss: 30.08
epoch train time: 0:00:00.598918
elapsed time: 0:02:31.958558
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:23:17.642938
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.76
 ---- batch: 020 ----
mean loss: 29.86
 ---- batch: 030 ----
mean loss: 29.94
train mean loss: 29.90
epoch train time: 0:00:00.604432
elapsed time: 0:02:32.563408
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:23:18.247814
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.23
 ---- batch: 020 ----
mean loss: 29.65
 ---- batch: 030 ----
mean loss: 30.14
train mean loss: 30.02
epoch train time: 0:00:00.598143
elapsed time: 0:02:33.161966
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:23:18.846428
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.60
 ---- batch: 020 ----
mean loss: 30.04
 ---- batch: 030 ----
mean loss: 29.76
train mean loss: 29.89
epoch train time: 0:00:00.609411
elapsed time: 0:02:33.771808
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:23:19.456193
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 29.09
 ---- batch: 020 ----
mean loss: 30.31
 ---- batch: 030 ----
mean loss: 29.34
train mean loss: 29.74
epoch train time: 0:00:00.594923
elapsed time: 0:02:34.367130
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:23:20.051511
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.79
 ---- batch: 020 ----
mean loss: 29.21
 ---- batch: 030 ----
mean loss: 29.28
train mean loss: 29.83
epoch train time: 0:00:00.595027
elapsed time: 0:02:34.962705
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:23:20.647129
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.45
 ---- batch: 020 ----
mean loss: 29.99
 ---- batch: 030 ----
mean loss: 28.34
train mean loss: 29.77
epoch train time: 0:00:00.593006
elapsed time: 0:02:35.556087
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:23:21.240462
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 28.38
 ---- batch: 020 ----
mean loss: 29.53
 ---- batch: 030 ----
mean loss: 30.18
train mean loss: 29.57
epoch train time: 0:00:00.599628
elapsed time: 0:02:36.156096
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:23:21.840469
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.42
 ---- batch: 020 ----
mean loss: 28.19
 ---- batch: 030 ----
mean loss: 29.21
train mean loss: 29.35
epoch train time: 0:00:00.600963
elapsed time: 0:02:36.757492
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:23:22.441902
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 28.90
 ---- batch: 020 ----
mean loss: 30.36
 ---- batch: 030 ----
mean loss: 29.27
train mean loss: 29.56
epoch train time: 0:00:00.601491
elapsed time: 0:02:37.359426
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:23:23.043859
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 28.49
 ---- batch: 020 ----
mean loss: 31.19
 ---- batch: 030 ----
mean loss: 30.28
train mean loss: 29.93
epoch train time: 0:00:00.595622
elapsed time: 0:02:37.955451
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:23:23.639846
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.70
 ---- batch: 020 ----
mean loss: 29.97
 ---- batch: 030 ----
mean loss: 29.11
train mean loss: 29.56
epoch train time: 0:00:00.597392
elapsed time: 0:02:38.553236
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:23:24.237643
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.27
 ---- batch: 020 ----
mean loss: 28.69
 ---- batch: 030 ----
mean loss: 30.25
train mean loss: 29.71
epoch train time: 0:00:00.597602
elapsed time: 0:02:39.151253
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:23:24.835644
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.09
 ---- batch: 020 ----
mean loss: 27.86
 ---- batch: 030 ----
mean loss: 29.30
train mean loss: 29.37
epoch train time: 0:00:00.587481
elapsed time: 0:02:39.739160
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:23:25.423539
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.40
 ---- batch: 020 ----
mean loss: 30.17
 ---- batch: 030 ----
mean loss: 27.07
train mean loss: 29.43
epoch train time: 0:00:00.599725
elapsed time: 0:02:40.339257
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:23:26.023634
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 28.38
 ---- batch: 020 ----
mean loss: 30.11
 ---- batch: 030 ----
mean loss: 29.88
train mean loss: 29.29
epoch train time: 0:00:00.590244
elapsed time: 0:02:40.937855
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_5/checkpoint.pth.tar
**** end time: 2019-09-27 15:23:26.622144 ****
