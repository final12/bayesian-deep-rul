Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_4', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 22469
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-27 07:38:56.219342 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 31, 14]             200
           Sigmoid-2           [-1, 10, 31, 14]               0
    BayesianConv2d-3           [-1, 10, 30, 14]           2,000
           Sigmoid-4           [-1, 10, 30, 14]               0
    BayesianConv2d-5           [-1, 10, 31, 14]           2,000
           Sigmoid-6           [-1, 10, 31, 14]               0
    BayesianConv2d-7           [-1, 10, 30, 14]           2,000
           Sigmoid-8           [-1, 10, 30, 14]               0
    BayesianConv2d-9            [-1, 1, 30, 14]              60
         Softplus-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
   BayesianLinear-12                  [-1, 100]          84,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 90,460
Trainable params: 90,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 07:38:56.237055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2574.57
 ---- batch: 020 ----
mean loss: 1485.17
 ---- batch: 030 ----
mean loss: 1325.56
train mean loss: 1721.38
epoch train time: 0:00:17.294798
elapsed time: 0:00:17.320613
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 07:39:13.539999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1217.00
 ---- batch: 020 ----
mean loss: 1150.15
 ---- batch: 030 ----
mean loss: 1159.46
train mean loss: 1165.48
epoch train time: 0:00:07.075941
elapsed time: 0:00:24.397204
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 07:39:20.616748
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1119.21
 ---- batch: 020 ----
mean loss: 1108.12
 ---- batch: 030 ----
mean loss: 1089.88
train mean loss: 1102.94
epoch train time: 0:00:07.122556
elapsed time: 0:00:31.520594
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 07:39:27.740088
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1057.32
 ---- batch: 020 ----
mean loss: 1055.50
 ---- batch: 030 ----
mean loss: 1029.23
train mean loss: 1043.63
epoch train time: 0:00:07.021090
elapsed time: 0:00:38.542478
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 07:39:34.761975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1058.21
 ---- batch: 020 ----
mean loss: 1057.88
 ---- batch: 030 ----
mean loss: 1012.64
train mean loss: 1040.01
epoch train time: 0:00:07.057431
elapsed time: 0:00:45.600856
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 07:39:41.820363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 994.65
 ---- batch: 020 ----
mean loss: 1012.62
 ---- batch: 030 ----
mean loss: 966.46
train mean loss: 990.53
epoch train time: 0:00:06.923374
elapsed time: 0:00:52.525202
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 07:39:48.744709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.50
 ---- batch: 020 ----
mean loss: 836.97
 ---- batch: 030 ----
mean loss: 779.48
train mean loss: 835.51
epoch train time: 0:00:06.891401
elapsed time: 0:00:59.417408
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 07:39:55.636905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 693.75
 ---- batch: 020 ----
mean loss: 644.18
 ---- batch: 030 ----
mean loss: 582.53
train mean loss: 629.75
epoch train time: 0:00:07.027802
elapsed time: 0:01:06.446086
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 07:40:02.665666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 516.17
 ---- batch: 020 ----
mean loss: 495.61
 ---- batch: 030 ----
mean loss: 500.42
train mean loss: 499.57
epoch train time: 0:00:06.945108
elapsed time: 0:01:13.392040
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 07:40:09.611550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 472.23
 ---- batch: 020 ----
mean loss: 456.31
 ---- batch: 030 ----
mean loss: 442.18
train mean loss: 457.58
epoch train time: 0:00:06.974029
elapsed time: 0:01:20.366853
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 07:40:16.586351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 442.86
 ---- batch: 020 ----
mean loss: 443.73
 ---- batch: 030 ----
mean loss: 434.56
train mean loss: 438.79
epoch train time: 0:00:07.009126
elapsed time: 0:01:27.376746
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 07:40:23.596242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 429.57
 ---- batch: 020 ----
mean loss: 429.16
 ---- batch: 030 ----
mean loss: 413.06
train mean loss: 421.99
epoch train time: 0:00:06.944177
elapsed time: 0:01:34.321684
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 07:40:30.541240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.89
 ---- batch: 020 ----
mean loss: 425.70
 ---- batch: 030 ----
mean loss: 408.65
train mean loss: 412.72
epoch train time: 0:00:06.967564
elapsed time: 0:01:41.290118
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 07:40:37.509646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 395.32
 ---- batch: 020 ----
mean loss: 402.01
 ---- batch: 030 ----
mean loss: 395.32
train mean loss: 398.41
epoch train time: 0:00:06.955751
elapsed time: 0:01:48.246691
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 07:40:44.466240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 393.17
 ---- batch: 020 ----
mean loss: 397.89
 ---- batch: 030 ----
mean loss: 392.29
train mean loss: 393.91
epoch train time: 0:00:06.930480
elapsed time: 0:01:55.177955
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 07:40:51.397445
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.34
 ---- batch: 020 ----
mean loss: 390.30
 ---- batch: 030 ----
mean loss: 388.85
train mean loss: 393.46
epoch train time: 0:00:06.757963
elapsed time: 0:02:01.936701
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 07:40:58.156302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 377.44
 ---- batch: 020 ----
mean loss: 380.10
 ---- batch: 030 ----
mean loss: 375.11
train mean loss: 377.13
epoch train time: 0:00:06.905299
elapsed time: 0:02:08.842911
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 07:41:05.062403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.04
 ---- batch: 020 ----
mean loss: 360.88
 ---- batch: 030 ----
mean loss: 368.12
train mean loss: 365.77
epoch train time: 0:00:06.806995
elapsed time: 0:02:15.650693
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 07:41:11.870193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 370.19
 ---- batch: 020 ----
mean loss: 356.77
 ---- batch: 030 ----
mean loss: 350.29
train mean loss: 357.76
epoch train time: 0:00:06.781979
elapsed time: 0:02:22.433463
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 07:41:18.652959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.72
 ---- batch: 020 ----
mean loss: 352.49
 ---- batch: 030 ----
mean loss: 364.70
train mean loss: 360.85
epoch train time: 0:00:06.778818
elapsed time: 0:02:29.213075
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 07:41:25.432574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 339.20
 ---- batch: 020 ----
mean loss: 347.37
 ---- batch: 030 ----
mean loss: 341.67
train mean loss: 343.97
epoch train time: 0:00:06.754392
elapsed time: 0:02:35.968237
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 07:41:32.187734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 339.88
 ---- batch: 020 ----
mean loss: 345.95
 ---- batch: 030 ----
mean loss: 350.77
train mean loss: 341.70
epoch train time: 0:00:06.668169
elapsed time: 0:02:42.637173
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 07:41:38.856672
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 338.95
 ---- batch: 020 ----
mean loss: 339.10
 ---- batch: 030 ----
mean loss: 330.65
train mean loss: 335.48
epoch train time: 0:00:06.666315
elapsed time: 0:02:49.304253
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 07:41:45.523753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.36
 ---- batch: 020 ----
mean loss: 334.85
 ---- batch: 030 ----
mean loss: 324.05
train mean loss: 331.10
epoch train time: 0:00:06.828178
elapsed time: 0:02:56.133205
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 07:41:52.352709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.38
 ---- batch: 020 ----
mean loss: 315.45
 ---- batch: 030 ----
mean loss: 321.70
train mean loss: 319.30
epoch train time: 0:00:06.689545
elapsed time: 0:03:02.823551
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 07:41:59.043063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.53
 ---- batch: 020 ----
mean loss: 313.78
 ---- batch: 030 ----
mean loss: 315.51
train mean loss: 317.48
epoch train time: 0:00:06.743493
elapsed time: 0:03:09.567829
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 07:42:05.787333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.18
 ---- batch: 020 ----
mean loss: 314.65
 ---- batch: 030 ----
mean loss: 303.08
train mean loss: 309.87
epoch train time: 0:00:06.903651
elapsed time: 0:03:16.472283
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 07:42:12.691811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.48
 ---- batch: 020 ----
mean loss: 301.30
 ---- batch: 030 ----
mean loss: 297.26
train mean loss: 301.36
epoch train time: 0:00:06.958086
elapsed time: 0:03:23.431221
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 07:42:19.650718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.50
 ---- batch: 020 ----
mean loss: 287.38
 ---- batch: 030 ----
mean loss: 287.90
train mean loss: 288.38
epoch train time: 0:00:06.891582
elapsed time: 0:03:30.323576
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 07:42:26.543125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.16
 ---- batch: 020 ----
mean loss: 278.34
 ---- batch: 030 ----
mean loss: 273.74
train mean loss: 281.04
epoch train time: 0:00:06.937947
elapsed time: 0:03:37.262570
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 07:42:33.482161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.14
 ---- batch: 020 ----
mean loss: 277.97
 ---- batch: 030 ----
mean loss: 279.84
train mean loss: 272.95
epoch train time: 0:00:06.912924
elapsed time: 0:03:44.176369
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 07:42:40.395866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.85
 ---- batch: 020 ----
mean loss: 267.05
 ---- batch: 030 ----
mean loss: 266.58
train mean loss: 266.92
epoch train time: 0:00:06.926135
elapsed time: 0:03:51.103301
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 07:42:47.322805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.55
 ---- batch: 020 ----
mean loss: 245.12
 ---- batch: 030 ----
mean loss: 261.72
train mean loss: 253.15
epoch train time: 0:00:06.791309
elapsed time: 0:03:57.895431
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 07:42:54.114922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.12
 ---- batch: 020 ----
mean loss: 245.09
 ---- batch: 030 ----
mean loss: 247.22
train mean loss: 246.60
epoch train time: 0:00:06.783636
elapsed time: 0:04:04.679973
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 07:43:00.899513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.49
 ---- batch: 020 ----
mean loss: 238.26
 ---- batch: 030 ----
mean loss: 244.29
train mean loss: 242.74
epoch train time: 0:00:06.992471
elapsed time: 0:04:11.673330
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 07:43:07.892854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.51
 ---- batch: 020 ----
mean loss: 234.99
 ---- batch: 030 ----
mean loss: 235.88
train mean loss: 235.54
epoch train time: 0:00:06.956184
elapsed time: 0:04:18.630332
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 07:43:14.849845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.33
 ---- batch: 020 ----
mean loss: 224.78
 ---- batch: 030 ----
mean loss: 223.33
train mean loss: 223.13
epoch train time: 0:00:06.805317
elapsed time: 0:04:25.436540
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 07:43:21.656050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.10
 ---- batch: 020 ----
mean loss: 220.86
 ---- batch: 030 ----
mean loss: 223.57
train mean loss: 217.83
epoch train time: 0:00:06.895463
elapsed time: 0:04:32.332824
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 07:43:28.552323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.22
 ---- batch: 020 ----
mean loss: 213.83
 ---- batch: 030 ----
mean loss: 216.48
train mean loss: 212.77
epoch train time: 0:00:07.011367
elapsed time: 0:04:39.345014
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 07:43:35.564527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.21
 ---- batch: 020 ----
mean loss: 204.87
 ---- batch: 030 ----
mean loss: 205.83
train mean loss: 206.83
epoch train time: 0:00:07.010874
elapsed time: 0:04:46.356690
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 07:43:42.576188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.45
 ---- batch: 020 ----
mean loss: 198.47
 ---- batch: 030 ----
mean loss: 202.75
train mean loss: 203.08
epoch train time: 0:00:06.914826
elapsed time: 0:04:53.272310
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 07:43:49.491815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 200.72
 ---- batch: 020 ----
mean loss: 197.66
 ---- batch: 030 ----
mean loss: 202.92
train mean loss: 199.53
epoch train time: 0:00:07.001728
elapsed time: 0:05:00.274863
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 07:43:56.494384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.24
 ---- batch: 020 ----
mean loss: 196.45
 ---- batch: 030 ----
mean loss: 193.62
train mean loss: 197.33
epoch train time: 0:00:07.033888
elapsed time: 0:05:07.309635
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 07:44:03.529164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.51
 ---- batch: 020 ----
mean loss: 191.89
 ---- batch: 030 ----
mean loss: 188.71
train mean loss: 190.90
epoch train time: 0:00:06.942860
elapsed time: 0:05:14.253300
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 07:44:10.472830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.27
 ---- batch: 020 ----
mean loss: 192.90
 ---- batch: 030 ----
mean loss: 190.12
train mean loss: 189.48
epoch train time: 0:00:06.975131
elapsed time: 0:05:21.229231
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 07:44:17.448728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.72
 ---- batch: 020 ----
mean loss: 183.49
 ---- batch: 030 ----
mean loss: 186.14
train mean loss: 182.73
epoch train time: 0:00:06.980989
elapsed time: 0:05:28.211097
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 07:44:24.430628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.94
 ---- batch: 020 ----
mean loss: 185.30
 ---- batch: 030 ----
mean loss: 182.25
train mean loss: 181.86
epoch train time: 0:00:06.924389
elapsed time: 0:05:35.136367
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 07:44:31.355867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.56
 ---- batch: 020 ----
mean loss: 178.33
 ---- batch: 030 ----
mean loss: 174.64
train mean loss: 177.40
epoch train time: 0:00:06.903233
elapsed time: 0:05:42.040379
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 07:44:38.259887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.19
 ---- batch: 020 ----
mean loss: 182.22
 ---- batch: 030 ----
mean loss: 180.62
train mean loss: 179.64
epoch train time: 0:00:06.916802
elapsed time: 0:05:48.957979
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 07:44:45.177507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.20
 ---- batch: 020 ----
mean loss: 171.90
 ---- batch: 030 ----
mean loss: 175.25
train mean loss: 172.38
epoch train time: 0:00:06.989174
elapsed time: 0:05:55.948040
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 07:44:52.167546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.91
 ---- batch: 020 ----
mean loss: 171.10
 ---- batch: 030 ----
mean loss: 175.40
train mean loss: 174.13
epoch train time: 0:00:06.889014
elapsed time: 0:06:02.837866
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 07:44:59.057417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.21
 ---- batch: 020 ----
mean loss: 173.49
 ---- batch: 030 ----
mean loss: 170.06
train mean loss: 170.00
epoch train time: 0:00:06.979246
elapsed time: 0:06:09.817947
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 07:45:06.037444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.25
 ---- batch: 020 ----
mean loss: 168.72
 ---- batch: 030 ----
mean loss: 165.98
train mean loss: 168.46
epoch train time: 0:00:06.985772
elapsed time: 0:06:16.804655
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 07:45:13.024154
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.77
 ---- batch: 020 ----
mean loss: 170.07
 ---- batch: 030 ----
mean loss: 162.47
train mean loss: 166.00
epoch train time: 0:00:06.897522
elapsed time: 0:06:23.702986
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 07:45:19.922488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.87
 ---- batch: 020 ----
mean loss: 165.08
 ---- batch: 030 ----
mean loss: 163.65
train mean loss: 165.02
epoch train time: 0:00:06.957364
elapsed time: 0:06:30.661122
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 07:45:26.880621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.66
 ---- batch: 020 ----
mean loss: 158.93
 ---- batch: 030 ----
mean loss: 164.92
train mean loss: 163.08
epoch train time: 0:00:06.921148
elapsed time: 0:06:37.583023
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 07:45:33.802538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.12
 ---- batch: 020 ----
mean loss: 160.37
 ---- batch: 030 ----
mean loss: 157.36
train mean loss: 159.82
epoch train time: 0:00:06.883431
elapsed time: 0:06:44.467317
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 07:45:40.686874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.63
 ---- batch: 020 ----
mean loss: 162.13
 ---- batch: 030 ----
mean loss: 163.99
train mean loss: 162.25
epoch train time: 0:00:06.954362
elapsed time: 0:06:51.422524
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 07:45:47.642018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.98
 ---- batch: 020 ----
mean loss: 155.55
 ---- batch: 030 ----
mean loss: 159.67
train mean loss: 156.28
epoch train time: 0:00:06.823727
elapsed time: 0:06:58.247226
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 07:45:54.466736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.52
 ---- batch: 020 ----
mean loss: 154.61
 ---- batch: 030 ----
mean loss: 157.01
train mean loss: 155.35
epoch train time: 0:00:06.961736
elapsed time: 0:07:05.209740
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 07:46:01.429243
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.92
 ---- batch: 020 ----
mean loss: 148.63
 ---- batch: 030 ----
mean loss: 159.03
train mean loss: 153.62
epoch train time: 0:00:06.838468
elapsed time: 0:07:12.048991
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 07:46:08.268499
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.45
 ---- batch: 020 ----
mean loss: 153.74
 ---- batch: 030 ----
mean loss: 153.66
train mean loss: 154.97
epoch train time: 0:00:06.922006
elapsed time: 0:07:18.971784
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 07:46:15.191276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.42
 ---- batch: 020 ----
mean loss: 152.80
 ---- batch: 030 ----
mean loss: 152.77
train mean loss: 154.35
epoch train time: 0:00:06.908248
elapsed time: 0:07:25.880821
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 07:46:22.100317
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.37
 ---- batch: 020 ----
mean loss: 157.79
 ---- batch: 030 ----
mean loss: 156.87
train mean loss: 154.35
epoch train time: 0:00:06.731930
elapsed time: 0:07:32.613506
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 07:46:28.833021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.48
 ---- batch: 020 ----
mean loss: 153.42
 ---- batch: 030 ----
mean loss: 147.63
train mean loss: 148.54
epoch train time: 0:00:06.747065
elapsed time: 0:07:39.361323
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 07:46:35.580832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.06
 ---- batch: 020 ----
mean loss: 148.72
 ---- batch: 030 ----
mean loss: 143.85
train mean loss: 148.38
epoch train time: 0:00:07.053342
elapsed time: 0:07:46.415586
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 07:46:42.635124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.16
 ---- batch: 020 ----
mean loss: 146.47
 ---- batch: 030 ----
mean loss: 145.74
train mean loss: 146.71
epoch train time: 0:00:06.812894
elapsed time: 0:07:53.229311
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 07:46:49.448810
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.94
 ---- batch: 020 ----
mean loss: 142.61
 ---- batch: 030 ----
mean loss: 150.05
train mean loss: 147.75
epoch train time: 0:00:06.918894
elapsed time: 0:08:00.149011
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 07:46:56.368516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.08
 ---- batch: 020 ----
mean loss: 141.31
 ---- batch: 030 ----
mean loss: 142.49
train mean loss: 143.67
epoch train time: 0:00:06.900347
elapsed time: 0:08:07.050126
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 07:47:03.269649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.75
 ---- batch: 020 ----
mean loss: 145.43
 ---- batch: 030 ----
mean loss: 141.51
train mean loss: 144.35
epoch train time: 0:00:06.835383
elapsed time: 0:08:13.886434
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 07:47:10.105967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.86
 ---- batch: 020 ----
mean loss: 142.39
 ---- batch: 030 ----
mean loss: 139.42
train mean loss: 141.45
epoch train time: 0:00:06.868467
elapsed time: 0:08:20.755652
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 07:47:16.975147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.57
 ---- batch: 020 ----
mean loss: 142.94
 ---- batch: 030 ----
mean loss: 141.81
train mean loss: 142.84
epoch train time: 0:00:06.829772
elapsed time: 0:08:27.586309
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 07:47:23.805817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.23
 ---- batch: 020 ----
mean loss: 140.14
 ---- batch: 030 ----
mean loss: 137.55
train mean loss: 140.13
epoch train time: 0:00:06.898565
elapsed time: 0:08:34.485689
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 07:47:30.705186
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.82
 ---- batch: 020 ----
mean loss: 139.02
 ---- batch: 030 ----
mean loss: 143.92
train mean loss: 139.22
epoch train time: 0:00:06.782209
elapsed time: 0:08:41.268803
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 07:47:37.488326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.88
 ---- batch: 020 ----
mean loss: 139.12
 ---- batch: 030 ----
mean loss: 140.01
train mean loss: 137.70
epoch train time: 0:00:06.891918
elapsed time: 0:08:48.161500
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 07:47:44.381006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.30
 ---- batch: 020 ----
mean loss: 145.38
 ---- batch: 030 ----
mean loss: 139.24
train mean loss: 139.00
epoch train time: 0:00:06.862140
elapsed time: 0:08:55.024547
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 07:47:51.244056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.89
 ---- batch: 020 ----
mean loss: 135.12
 ---- batch: 030 ----
mean loss: 134.97
train mean loss: 137.03
epoch train time: 0:00:06.802504
elapsed time: 0:09:01.827869
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 07:47:58.047390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.52
 ---- batch: 020 ----
mean loss: 131.87
 ---- batch: 030 ----
mean loss: 138.97
train mean loss: 135.48
epoch train time: 0:00:06.860352
elapsed time: 0:09:08.689054
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 07:48:04.908564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.44
 ---- batch: 020 ----
mean loss: 135.10
 ---- batch: 030 ----
mean loss: 140.45
train mean loss: 138.10
epoch train time: 0:00:06.904879
elapsed time: 0:09:15.594730
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 07:48:11.814222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.30
 ---- batch: 020 ----
mean loss: 141.04
 ---- batch: 030 ----
mean loss: 135.72
train mean loss: 137.27
epoch train time: 0:00:06.752538
elapsed time: 0:09:22.348025
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 07:48:18.567530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.25
 ---- batch: 020 ----
mean loss: 135.62
 ---- batch: 030 ----
mean loss: 134.72
train mean loss: 137.10
epoch train time: 0:00:06.878936
elapsed time: 0:09:29.227724
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 07:48:25.447231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.04
 ---- batch: 020 ----
mean loss: 134.89
 ---- batch: 030 ----
mean loss: 133.98
train mean loss: 133.24
epoch train time: 0:00:06.703407
elapsed time: 0:09:35.931924
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 07:48:32.151439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.83
 ---- batch: 020 ----
mean loss: 133.31
 ---- batch: 030 ----
mean loss: 137.26
train mean loss: 135.98
epoch train time: 0:00:07.004441
elapsed time: 0:09:42.937184
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 07:48:39.156684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.93
 ---- batch: 020 ----
mean loss: 131.81
 ---- batch: 030 ----
mean loss: 132.85
train mean loss: 132.03
epoch train time: 0:00:07.031403
elapsed time: 0:09:49.969432
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 07:48:46.189027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.16
 ---- batch: 020 ----
mean loss: 138.29
 ---- batch: 030 ----
mean loss: 138.42
train mean loss: 133.88
epoch train time: 0:00:06.932309
elapsed time: 0:09:56.902727
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 07:48:53.122260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.73
 ---- batch: 020 ----
mean loss: 130.62
 ---- batch: 030 ----
mean loss: 128.70
train mean loss: 130.20
epoch train time: 0:00:07.052867
elapsed time: 0:10:03.956422
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 07:49:00.175914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.69
 ---- batch: 020 ----
mean loss: 131.35
 ---- batch: 030 ----
mean loss: 131.41
train mean loss: 130.45
epoch train time: 0:00:06.883251
elapsed time: 0:10:10.840445
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 07:49:07.059941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.22
 ---- batch: 020 ----
mean loss: 131.08
 ---- batch: 030 ----
mean loss: 124.80
train mean loss: 129.75
epoch train time: 0:00:06.966097
elapsed time: 0:10:17.807381
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 07:49:14.026904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.62
 ---- batch: 020 ----
mean loss: 129.05
 ---- batch: 030 ----
mean loss: 123.24
train mean loss: 128.29
epoch train time: 0:00:06.928473
elapsed time: 0:10:24.736705
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 07:49:20.956254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.73
 ---- batch: 020 ----
mean loss: 125.43
 ---- batch: 030 ----
mean loss: 131.06
train mean loss: 128.69
epoch train time: 0:00:07.023890
elapsed time: 0:10:31.761515
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 07:49:27.981015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.00
 ---- batch: 020 ----
mean loss: 126.19
 ---- batch: 030 ----
mean loss: 125.50
train mean loss: 126.09
epoch train time: 0:00:07.023092
elapsed time: 0:10:38.785364
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 07:49:35.004864
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.99
 ---- batch: 020 ----
mean loss: 126.80
 ---- batch: 030 ----
mean loss: 125.79
train mean loss: 125.36
epoch train time: 0:00:06.965055
elapsed time: 0:10:45.751189
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 07:49:41.970690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.29
 ---- batch: 020 ----
mean loss: 130.27
 ---- batch: 030 ----
mean loss: 124.96
train mean loss: 128.45
epoch train time: 0:00:06.781102
elapsed time: 0:10:52.533032
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 07:49:48.752528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.05
 ---- batch: 020 ----
mean loss: 121.93
 ---- batch: 030 ----
mean loss: 129.05
train mean loss: 126.53
epoch train time: 0:00:06.870097
elapsed time: 0:10:59.404061
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 07:49:55.623579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.90
 ---- batch: 020 ----
mean loss: 120.34
 ---- batch: 030 ----
mean loss: 124.69
train mean loss: 123.69
epoch train time: 0:00:07.057685
elapsed time: 0:11:06.462567
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 07:50:02.682068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.52
 ---- batch: 020 ----
mean loss: 122.43
 ---- batch: 030 ----
mean loss: 128.95
train mean loss: 125.30
epoch train time: 0:00:06.848632
elapsed time: 0:11:13.312081
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 07:50:09.531680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.01
 ---- batch: 020 ----
mean loss: 125.90
 ---- batch: 030 ----
mean loss: 125.81
train mean loss: 123.53
epoch train time: 0:00:06.957675
elapsed time: 0:11:20.270702
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 07:50:16.490234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.97
 ---- batch: 020 ----
mean loss: 123.12
 ---- batch: 030 ----
mean loss: 126.22
train mean loss: 123.01
epoch train time: 0:00:06.977442
elapsed time: 0:11:27.248907
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 07:50:23.468401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.69
 ---- batch: 020 ----
mean loss: 121.83
 ---- batch: 030 ----
mean loss: 120.08
train mean loss: 121.67
epoch train time: 0:00:06.859507
elapsed time: 0:11:34.109180
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 07:50:30.328728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.91
 ---- batch: 020 ----
mean loss: 121.90
 ---- batch: 030 ----
mean loss: 121.08
train mean loss: 123.46
epoch train time: 0:00:06.983563
elapsed time: 0:11:41.093571
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 07:50:37.313080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.47
 ---- batch: 020 ----
mean loss: 120.19
 ---- batch: 030 ----
mean loss: 120.16
train mean loss: 122.07
epoch train time: 0:00:06.884167
elapsed time: 0:11:47.978589
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 07:50:44.198087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.31
 ---- batch: 020 ----
mean loss: 119.08
 ---- batch: 030 ----
mean loss: 124.02
train mean loss: 122.08
epoch train time: 0:00:06.997462
elapsed time: 0:11:54.976827
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 07:50:51.196339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.89
 ---- batch: 020 ----
mean loss: 122.76
 ---- batch: 030 ----
mean loss: 118.22
train mean loss: 121.11
epoch train time: 0:00:06.851641
elapsed time: 0:12:01.829309
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 07:50:58.048814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.43
 ---- batch: 020 ----
mean loss: 122.66
 ---- batch: 030 ----
mean loss: 118.19
train mean loss: 119.45
epoch train time: 0:00:07.002350
elapsed time: 0:12:08.832512
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 07:51:05.052028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.51
 ---- batch: 020 ----
mean loss: 115.71
 ---- batch: 030 ----
mean loss: 120.29
train mean loss: 119.21
epoch train time: 0:00:06.887143
elapsed time: 0:12:15.720458
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 07:51:11.939956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.74
 ---- batch: 020 ----
mean loss: 116.17
 ---- batch: 030 ----
mean loss: 121.20
train mean loss: 118.92
epoch train time: 0:00:06.950637
elapsed time: 0:12:22.671947
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 07:51:18.891447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.21
 ---- batch: 020 ----
mean loss: 119.94
 ---- batch: 030 ----
mean loss: 117.13
train mean loss: 119.13
epoch train time: 0:00:06.899715
elapsed time: 0:12:29.572533
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 07:51:25.791926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.98
 ---- batch: 020 ----
mean loss: 118.85
 ---- batch: 030 ----
mean loss: 118.36
train mean loss: 118.23
epoch train time: 0:00:06.964037
elapsed time: 0:12:36.537247
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 07:51:32.756740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.68
 ---- batch: 020 ----
mean loss: 119.72
 ---- batch: 030 ----
mean loss: 111.67
train mean loss: 118.19
epoch train time: 0:00:06.917985
elapsed time: 0:12:43.456044
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 07:51:39.675558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.49
 ---- batch: 020 ----
mean loss: 116.05
 ---- batch: 030 ----
mean loss: 118.65
train mean loss: 116.26
epoch train time: 0:00:06.880686
elapsed time: 0:12:50.337579
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 07:51:46.557082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.72
 ---- batch: 020 ----
mean loss: 117.10
 ---- batch: 030 ----
mean loss: 118.02
train mean loss: 116.03
epoch train time: 0:00:07.001863
elapsed time: 0:12:57.340239
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 07:51:53.559769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.72
 ---- batch: 020 ----
mean loss: 115.01
 ---- batch: 030 ----
mean loss: 116.82
train mean loss: 117.84
epoch train time: 0:00:06.836580
elapsed time: 0:13:04.177620
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 07:52:00.397112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.11
 ---- batch: 020 ----
mean loss: 117.93
 ---- batch: 030 ----
mean loss: 113.33
train mean loss: 116.47
epoch train time: 0:00:06.979535
elapsed time: 0:13:11.157988
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 07:52:07.377492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.13
 ---- batch: 020 ----
mean loss: 115.65
 ---- batch: 030 ----
mean loss: 113.61
train mean loss: 116.13
epoch train time: 0:00:06.962050
elapsed time: 0:13:18.120831
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 07:52:14.340332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.96
 ---- batch: 020 ----
mean loss: 115.00
 ---- batch: 030 ----
mean loss: 114.23
train mean loss: 115.14
epoch train time: 0:00:07.011176
elapsed time: 0:13:25.132807
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 07:52:21.352340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.14
 ---- batch: 020 ----
mean loss: 111.78
 ---- batch: 030 ----
mean loss: 115.69
train mean loss: 113.35
epoch train time: 0:00:06.854446
elapsed time: 0:13:31.988099
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 07:52:28.207600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.70
 ---- batch: 020 ----
mean loss: 113.86
 ---- batch: 030 ----
mean loss: 116.98
train mean loss: 115.66
epoch train time: 0:00:06.926627
elapsed time: 0:13:38.915584
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 07:52:35.135077
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.82
 ---- batch: 020 ----
mean loss: 114.95
 ---- batch: 030 ----
mean loss: 113.68
train mean loss: 114.87
epoch train time: 0:00:06.972375
elapsed time: 0:13:45.888757
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 07:52:42.108248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.02
 ---- batch: 020 ----
mean loss: 113.92
 ---- batch: 030 ----
mean loss: 113.83
train mean loss: 114.23
epoch train time: 0:00:06.761806
elapsed time: 0:13:52.651615
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 07:52:48.871131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.31
 ---- batch: 020 ----
mean loss: 112.17
 ---- batch: 030 ----
mean loss: 113.97
train mean loss: 113.86
epoch train time: 0:00:06.858052
elapsed time: 0:13:59.510576
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 07:52:55.730067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.10
 ---- batch: 020 ----
mean loss: 116.94
 ---- batch: 030 ----
mean loss: 110.89
train mean loss: 115.31
epoch train time: 0:00:06.689644
elapsed time: 0:14:06.201008
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 07:53:02.420506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.86
 ---- batch: 020 ----
mean loss: 110.89
 ---- batch: 030 ----
mean loss: 116.75
train mean loss: 113.31
epoch train time: 0:00:06.707376
elapsed time: 0:14:12.909165
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 07:53:09.128666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.91
 ---- batch: 020 ----
mean loss: 115.67
 ---- batch: 030 ----
mean loss: 112.46
train mean loss: 112.98
epoch train time: 0:00:06.996799
elapsed time: 0:14:19.906785
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 07:53:16.126290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.02
 ---- batch: 020 ----
mean loss: 110.47
 ---- batch: 030 ----
mean loss: 113.81
train mean loss: 112.49
epoch train time: 0:00:06.777880
elapsed time: 0:14:26.685465
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 07:53:22.904985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.87
 ---- batch: 020 ----
mean loss: 109.25
 ---- batch: 030 ----
mean loss: 114.16
train mean loss: 111.96
epoch train time: 0:00:06.881794
elapsed time: 0:14:33.568056
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 07:53:29.787566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.13
 ---- batch: 020 ----
mean loss: 110.80
 ---- batch: 030 ----
mean loss: 108.72
train mean loss: 111.81
epoch train time: 0:00:06.769846
elapsed time: 0:14:40.338847
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 07:53:36.558342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.43
 ---- batch: 020 ----
mean loss: 110.26
 ---- batch: 030 ----
mean loss: 109.18
train mean loss: 109.42
epoch train time: 0:00:06.891540
elapsed time: 0:14:47.231319
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 07:53:43.450712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.89
 ---- batch: 020 ----
mean loss: 112.39
 ---- batch: 030 ----
mean loss: 113.75
train mean loss: 112.69
epoch train time: 0:00:06.900208
elapsed time: 0:14:54.132187
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 07:53:50.351689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.86
 ---- batch: 020 ----
mean loss: 109.75
 ---- batch: 030 ----
mean loss: 108.12
train mean loss: 109.86
epoch train time: 0:00:06.967338
elapsed time: 0:15:01.100303
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 07:53:57.319797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.00
 ---- batch: 020 ----
mean loss: 107.92
 ---- batch: 030 ----
mean loss: 108.38
train mean loss: 109.17
epoch train time: 0:00:07.072886
elapsed time: 0:15:08.174123
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 07:54:04.393637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.99
 ---- batch: 020 ----
mean loss: 107.31
 ---- batch: 030 ----
mean loss: 110.73
train mean loss: 108.28
epoch train time: 0:00:06.935040
elapsed time: 0:15:15.109988
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 07:54:11.329486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.83
 ---- batch: 020 ----
mean loss: 107.68
 ---- batch: 030 ----
mean loss: 107.78
train mean loss: 109.00
epoch train time: 0:00:06.998816
elapsed time: 0:15:22.109616
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 07:54:18.329116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.63
 ---- batch: 020 ----
mean loss: 109.14
 ---- batch: 030 ----
mean loss: 104.62
train mean loss: 108.70
epoch train time: 0:00:06.966597
elapsed time: 0:15:29.076928
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 07:54:25.296422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.38
 ---- batch: 020 ----
mean loss: 108.09
 ---- batch: 030 ----
mean loss: 109.59
train mean loss: 109.39
epoch train time: 0:00:06.859548
elapsed time: 0:15:35.937348
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 07:54:32.156875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.77
 ---- batch: 020 ----
mean loss: 107.24
 ---- batch: 030 ----
mean loss: 106.25
train mean loss: 106.25
epoch train time: 0:00:06.947735
elapsed time: 0:15:42.885890
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 07:54:39.105405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.21
 ---- batch: 020 ----
mean loss: 102.88
 ---- batch: 030 ----
mean loss: 109.83
train mean loss: 107.90
epoch train time: 0:00:06.888854
elapsed time: 0:15:49.775540
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 07:54:45.995055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.65
 ---- batch: 020 ----
mean loss: 108.39
 ---- batch: 030 ----
mean loss: 106.21
train mean loss: 107.62
epoch train time: 0:00:06.956484
elapsed time: 0:15:56.732974
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 07:54:52.952535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.68
 ---- batch: 020 ----
mean loss: 108.76
 ---- batch: 030 ----
mean loss: 105.78
train mean loss: 107.51
epoch train time: 0:00:06.900356
elapsed time: 0:16:03.634168
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 07:54:59.853728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.17
 ---- batch: 020 ----
mean loss: 108.98
 ---- batch: 030 ----
mean loss: 106.75
train mean loss: 107.09
epoch train time: 0:00:06.977515
elapsed time: 0:16:10.612523
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 07:55:06.832080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.52
 ---- batch: 020 ----
mean loss: 107.14
 ---- batch: 030 ----
mean loss: 105.57
train mean loss: 105.91
epoch train time: 0:00:06.968621
elapsed time: 0:16:17.582025
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 07:55:13.801508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.00
 ---- batch: 020 ----
mean loss: 102.47
 ---- batch: 030 ----
mean loss: 106.21
train mean loss: 105.15
epoch train time: 0:00:06.883742
elapsed time: 0:16:24.466559
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 07:55:20.686056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.99
 ---- batch: 020 ----
mean loss: 106.07
 ---- batch: 030 ----
mean loss: 108.03
train mean loss: 108.46
epoch train time: 0:00:06.959171
elapsed time: 0:16:31.426541
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 07:55:27.646092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.69
 ---- batch: 020 ----
mean loss: 105.17
 ---- batch: 030 ----
mean loss: 110.88
train mean loss: 106.65
epoch train time: 0:00:06.894617
elapsed time: 0:16:38.321988
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 07:55:34.541489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.45
 ---- batch: 020 ----
mean loss: 105.59
 ---- batch: 030 ----
mean loss: 105.09
train mean loss: 104.86
epoch train time: 0:00:06.951287
elapsed time: 0:16:45.274068
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 07:55:41.493585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.90
 ---- batch: 020 ----
mean loss: 106.33
 ---- batch: 030 ----
mean loss: 106.09
train mean loss: 105.47
epoch train time: 0:00:06.946043
elapsed time: 0:16:52.220951
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 07:55:48.440469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.83
 ---- batch: 020 ----
mean loss: 108.29
 ---- batch: 030 ----
mean loss: 102.73
train mean loss: 105.69
epoch train time: 0:00:06.928322
elapsed time: 0:16:59.150133
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 07:55:55.369725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.01
 ---- batch: 020 ----
mean loss: 107.26
 ---- batch: 030 ----
mean loss: 102.33
train mean loss: 104.91
epoch train time: 0:00:06.812375
elapsed time: 0:17:05.963329
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 07:56:02.182819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.66
 ---- batch: 020 ----
mean loss: 103.18
 ---- batch: 030 ----
mean loss: 104.80
train mean loss: 104.10
epoch train time: 0:00:06.795207
elapsed time: 0:17:12.759305
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 07:56:08.978811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.72
 ---- batch: 020 ----
mean loss: 103.61
 ---- batch: 030 ----
mean loss: 104.01
train mean loss: 103.82
epoch train time: 0:00:06.992709
elapsed time: 0:17:19.753010
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 07:56:15.972420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.10
 ---- batch: 020 ----
mean loss: 102.99
 ---- batch: 030 ----
mean loss: 102.84
train mean loss: 103.63
epoch train time: 0:00:06.984429
elapsed time: 0:17:26.738106
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 07:56:22.957707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.00
 ---- batch: 020 ----
mean loss: 106.90
 ---- batch: 030 ----
mean loss: 104.74
train mean loss: 103.55
epoch train time: 0:00:06.869828
elapsed time: 0:17:33.608950
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 07:56:29.828538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.64
 ---- batch: 020 ----
mean loss: 102.94
 ---- batch: 030 ----
mean loss: 105.70
train mean loss: 103.38
epoch train time: 0:00:06.980255
elapsed time: 0:17:40.590184
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 07:56:36.809726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.34
 ---- batch: 020 ----
mean loss: 107.47
 ---- batch: 030 ----
mean loss: 99.12
train mean loss: 103.57
epoch train time: 0:00:06.924797
elapsed time: 0:17:47.515816
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 07:56:43.735324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.70
 ---- batch: 020 ----
mean loss: 101.58
 ---- batch: 030 ----
mean loss: 105.34
train mean loss: 102.70
epoch train time: 0:00:06.901876
elapsed time: 0:17:54.418677
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 07:56:50.638189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.40
 ---- batch: 020 ----
mean loss: 104.23
 ---- batch: 030 ----
mean loss: 100.39
train mean loss: 102.17
epoch train time: 0:00:06.902908
elapsed time: 0:18:01.322436
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 07:56:57.541938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.63
 ---- batch: 020 ----
mean loss: 100.08
 ---- batch: 030 ----
mean loss: 104.12
train mean loss: 101.67
epoch train time: 0:00:06.884538
elapsed time: 0:18:08.207790
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 07:57:04.427280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.06
 ---- batch: 020 ----
mean loss: 102.06
 ---- batch: 030 ----
mean loss: 102.79
train mean loss: 102.60
epoch train time: 0:00:06.983681
elapsed time: 0:18:15.192301
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 07:57:11.411826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.94
 ---- batch: 020 ----
mean loss: 103.59
 ---- batch: 030 ----
mean loss: 103.27
train mean loss: 103.18
epoch train time: 0:00:06.834761
elapsed time: 0:18:22.027937
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 07:57:18.247433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.96
 ---- batch: 020 ----
mean loss: 101.36
 ---- batch: 030 ----
mean loss: 99.58
train mean loss: 100.59
epoch train time: 0:00:06.950436
elapsed time: 0:18:28.979195
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 07:57:25.198689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.98
 ---- batch: 020 ----
mean loss: 98.79
 ---- batch: 030 ----
mean loss: 98.42
train mean loss: 100.22
epoch train time: 0:00:06.887574
elapsed time: 0:18:35.867503
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 07:57:32.087283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.23
 ---- batch: 020 ----
mean loss: 98.79
 ---- batch: 030 ----
mean loss: 102.86
train mean loss: 101.84
epoch train time: 0:00:06.895028
elapsed time: 0:18:42.763651
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 07:57:38.983140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.51
 ---- batch: 020 ----
mean loss: 99.88
 ---- batch: 030 ----
mean loss: 101.20
train mean loss: 101.46
epoch train time: 0:00:06.921570
elapsed time: 0:18:49.686008
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 07:57:45.905508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.67
 ---- batch: 020 ----
mean loss: 101.11
 ---- batch: 030 ----
mean loss: 100.62
train mean loss: 100.18
epoch train time: 0:00:06.850285
elapsed time: 0:18:56.537062
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 07:57:52.756581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.11
 ---- batch: 020 ----
mean loss: 101.82
 ---- batch: 030 ----
mean loss: 99.20
train mean loss: 100.27
epoch train time: 0:00:06.910513
elapsed time: 0:19:03.448374
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 07:57:59.667872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.17
 ---- batch: 020 ----
mean loss: 99.06
 ---- batch: 030 ----
mean loss: 99.16
train mean loss: 99.32
epoch train time: 0:00:06.846156
elapsed time: 0:19:10.295334
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 07:58:06.514857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.10
 ---- batch: 020 ----
mean loss: 97.92
 ---- batch: 030 ----
mean loss: 101.41
train mean loss: 98.91
epoch train time: 0:00:06.943680
elapsed time: 0:19:17.239824
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 07:58:13.459395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.44
 ---- batch: 020 ----
mean loss: 98.87
 ---- batch: 030 ----
mean loss: 100.72
train mean loss: 100.64
epoch train time: 0:00:06.930825
elapsed time: 0:19:24.171538
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 07:58:20.391051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.64
 ---- batch: 020 ----
mean loss: 97.33
 ---- batch: 030 ----
mean loss: 99.90
train mean loss: 100.34
epoch train time: 0:00:06.876652
elapsed time: 0:19:31.048984
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 07:58:27.268481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.51
 ---- batch: 020 ----
mean loss: 96.68
 ---- batch: 030 ----
mean loss: 96.94
train mean loss: 98.82
epoch train time: 0:00:06.905046
elapsed time: 0:19:37.954875
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 07:58:34.174378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.50
 ---- batch: 020 ----
mean loss: 100.02
 ---- batch: 030 ----
mean loss: 97.30
train mean loss: 99.68
epoch train time: 0:00:06.913457
elapsed time: 0:19:44.869095
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 07:58:41.088618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.85
 ---- batch: 020 ----
mean loss: 100.85
 ---- batch: 030 ----
mean loss: 96.29
train mean loss: 99.28
epoch train time: 0:00:06.867000
elapsed time: 0:19:51.736931
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 07:58:47.956436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.96
 ---- batch: 020 ----
mean loss: 96.84
 ---- batch: 030 ----
mean loss: 99.29
train mean loss: 98.80
epoch train time: 0:00:06.935463
elapsed time: 0:19:58.673183
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 07:58:54.892686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.09
 ---- batch: 020 ----
mean loss: 94.68
 ---- batch: 030 ----
mean loss: 98.25
train mean loss: 98.29
epoch train time: 0:00:06.859507
elapsed time: 0:20:05.533503
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 07:59:01.752998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.73
 ---- batch: 020 ----
mean loss: 100.20
 ---- batch: 030 ----
mean loss: 98.69
train mean loss: 98.84
epoch train time: 0:00:06.942537
elapsed time: 0:20:12.476923
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 07:59:08.696326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.61
 ---- batch: 020 ----
mean loss: 98.53
 ---- batch: 030 ----
mean loss: 97.39
train mean loss: 97.40
epoch train time: 0:00:06.832570
elapsed time: 0:20:19.310120
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 07:59:15.529649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.00
 ---- batch: 020 ----
mean loss: 98.95
 ---- batch: 030 ----
mean loss: 97.27
train mean loss: 97.95
epoch train time: 0:00:06.717281
elapsed time: 0:20:26.028164
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 07:59:22.247690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.13
 ---- batch: 020 ----
mean loss: 96.81
 ---- batch: 030 ----
mean loss: 99.52
train mean loss: 97.90
epoch train time: 0:00:06.848117
elapsed time: 0:20:32.877179
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 07:59:29.096689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.72
 ---- batch: 020 ----
mean loss: 98.04
 ---- batch: 030 ----
mean loss: 98.44
train mean loss: 98.10
epoch train time: 0:00:07.024455
elapsed time: 0:20:39.902484
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 07:59:36.122003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.48
 ---- batch: 020 ----
mean loss: 98.00
 ---- batch: 030 ----
mean loss: 93.51
train mean loss: 96.62
epoch train time: 0:00:06.882177
elapsed time: 0:20:46.785466
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 07:59:43.005001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.39
 ---- batch: 020 ----
mean loss: 95.63
 ---- batch: 030 ----
mean loss: 96.64
train mean loss: 97.06
epoch train time: 0:00:06.939372
elapsed time: 0:20:53.725624
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 07:59:49.945113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.99
 ---- batch: 020 ----
mean loss: 98.70
 ---- batch: 030 ----
mean loss: 96.17
train mean loss: 96.13
epoch train time: 0:00:06.802267
elapsed time: 0:21:00.528802
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 07:59:56.748289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.98
 ---- batch: 020 ----
mean loss: 97.99
 ---- batch: 030 ----
mean loss: 98.11
train mean loss: 96.69
epoch train time: 0:00:06.885515
elapsed time: 0:21:07.415093
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 08:00:03.634602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.80
 ---- batch: 020 ----
mean loss: 96.95
 ---- batch: 030 ----
mean loss: 95.75
train mean loss: 96.34
epoch train time: 0:00:06.858076
elapsed time: 0:21:14.273996
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 08:00:10.493507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.05
 ---- batch: 020 ----
mean loss: 97.68
 ---- batch: 030 ----
mean loss: 97.01
train mean loss: 96.62
epoch train time: 0:00:06.884661
elapsed time: 0:21:21.159430
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 08:00:17.378930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.67
 ---- batch: 020 ----
mean loss: 96.07
 ---- batch: 030 ----
mean loss: 96.64
train mean loss: 95.83
epoch train time: 0:00:06.866536
elapsed time: 0:21:28.026736
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 08:00:24.246239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.86
 ---- batch: 020 ----
mean loss: 100.95
 ---- batch: 030 ----
mean loss: 92.96
train mean loss: 98.42
epoch train time: 0:00:06.819727
elapsed time: 0:21:34.847406
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 08:00:31.066900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.81
 ---- batch: 020 ----
mean loss: 99.09
 ---- batch: 030 ----
mean loss: 93.99
train mean loss: 97.53
epoch train time: 0:00:06.993705
elapsed time: 0:21:41.841887
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 08:00:38.061393
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.29
 ---- batch: 020 ----
mean loss: 95.12
 ---- batch: 030 ----
mean loss: 97.21
train mean loss: 94.39
epoch train time: 0:00:06.923774
elapsed time: 0:21:48.766446
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 08:00:44.985957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.57
 ---- batch: 020 ----
mean loss: 93.77
 ---- batch: 030 ----
mean loss: 98.93
train mean loss: 95.87
epoch train time: 0:00:07.059345
elapsed time: 0:21:55.826621
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 08:00:52.046205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.20
 ---- batch: 020 ----
mean loss: 94.07
 ---- batch: 030 ----
mean loss: 98.57
train mean loss: 94.70
epoch train time: 0:00:06.912777
elapsed time: 0:22:02.740258
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 08:00:58.959752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.74
 ---- batch: 020 ----
mean loss: 93.38
 ---- batch: 030 ----
mean loss: 94.06
train mean loss: 94.81
epoch train time: 0:00:07.018946
elapsed time: 0:22:09.760114
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 08:01:05.979624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.22
 ---- batch: 020 ----
mean loss: 93.70
 ---- batch: 030 ----
mean loss: 92.72
train mean loss: 93.68
epoch train time: 0:00:07.037518
elapsed time: 0:22:16.798502
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 08:01:13.018090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.04
 ---- batch: 020 ----
mean loss: 93.05
 ---- batch: 030 ----
mean loss: 97.37
train mean loss: 94.84
epoch train time: 0:00:07.003134
elapsed time: 0:22:23.802527
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 08:01:20.022035
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.03
 ---- batch: 020 ----
mean loss: 95.80
 ---- batch: 030 ----
mean loss: 91.51
train mean loss: 93.94
epoch train time: 0:00:06.909750
elapsed time: 0:22:30.713128
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 08:01:26.932904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.76
 ---- batch: 020 ----
mean loss: 97.79
 ---- batch: 030 ----
mean loss: 94.31
train mean loss: 95.57
epoch train time: 0:00:06.984535
elapsed time: 0:22:37.698766
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 08:01:33.918269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.73
 ---- batch: 020 ----
mean loss: 98.09
 ---- batch: 030 ----
mean loss: 94.56
train mean loss: 95.87
epoch train time: 0:00:06.974642
elapsed time: 0:22:44.674232
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 08:01:40.893752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.72
 ---- batch: 020 ----
mean loss: 95.65
 ---- batch: 030 ----
mean loss: 90.73
train mean loss: 93.96
epoch train time: 0:00:06.960614
elapsed time: 0:22:51.635638
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 08:01:47.855135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.76
 ---- batch: 020 ----
mean loss: 94.26
 ---- batch: 030 ----
mean loss: 93.21
train mean loss: 93.89
epoch train time: 0:00:07.069490
elapsed time: 0:22:58.705878
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 08:01:54.925375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.97
 ---- batch: 020 ----
mean loss: 93.50
 ---- batch: 030 ----
mean loss: 95.46
train mean loss: 93.20
epoch train time: 0:00:06.859815
elapsed time: 0:23:05.566485
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 08:02:01.786024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.14
 ---- batch: 020 ----
mean loss: 94.13
 ---- batch: 030 ----
mean loss: 94.17
train mean loss: 93.43
epoch train time: 0:00:06.967011
elapsed time: 0:23:12.534281
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 08:02:08.753776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.52
 ---- batch: 020 ----
mean loss: 95.30
 ---- batch: 030 ----
mean loss: 94.94
train mean loss: 93.62
epoch train time: 0:00:06.893669
elapsed time: 0:23:19.428813
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 08:02:15.648324
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.50
 ---- batch: 020 ----
mean loss: 91.19
 ---- batch: 030 ----
mean loss: 93.99
train mean loss: 92.05
epoch train time: 0:00:06.978331
elapsed time: 0:23:26.408030
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 08:02:22.627429
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.25
 ---- batch: 020 ----
mean loss: 92.35
 ---- batch: 030 ----
mean loss: 92.39
train mean loss: 92.53
epoch train time: 0:00:06.796605
elapsed time: 0:23:33.205318
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 08:02:29.424806
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.80
 ---- batch: 020 ----
mean loss: 92.37
 ---- batch: 030 ----
mean loss: 92.07
train mean loss: 92.39
epoch train time: 0:00:06.780879
elapsed time: 0:23:39.986940
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 08:02:36.206460
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.10
 ---- batch: 020 ----
mean loss: 88.11
 ---- batch: 030 ----
mean loss: 93.53
train mean loss: 91.94
epoch train time: 0:00:07.064723
elapsed time: 0:23:47.052535
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 08:02:43.272421
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.19
 ---- batch: 020 ----
mean loss: 91.00
 ---- batch: 030 ----
mean loss: 91.27
train mean loss: 91.62
epoch train time: 0:00:06.915237
elapsed time: 0:23:53.968943
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 08:02:50.188478
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.49
 ---- batch: 020 ----
mean loss: 93.60
 ---- batch: 030 ----
mean loss: 89.93
train mean loss: 92.18
epoch train time: 0:00:06.877460
elapsed time: 0:24:00.847328
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 08:02:57.066866
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.82
 ---- batch: 020 ----
mean loss: 92.23
 ---- batch: 030 ----
mean loss: 91.56
train mean loss: 92.24
epoch train time: 0:00:06.990094
elapsed time: 0:24:07.838293
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 08:03:04.057808
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.98
 ---- batch: 020 ----
mean loss: 87.90
 ---- batch: 030 ----
mean loss: 93.11
train mean loss: 91.97
epoch train time: 0:00:06.962943
elapsed time: 0:24:14.802195
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 08:03:11.021753
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.73
 ---- batch: 020 ----
mean loss: 93.75
 ---- batch: 030 ----
mean loss: 89.93
train mean loss: 92.45
epoch train time: 0:00:07.070237
elapsed time: 0:24:21.873523
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 08:03:18.093021
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.93
 ---- batch: 020 ----
mean loss: 90.67
 ---- batch: 030 ----
mean loss: 93.34
train mean loss: 92.15
epoch train time: 0:00:06.890573
elapsed time: 0:24:28.765030
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 08:03:24.984520
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.51
 ---- batch: 020 ----
mean loss: 91.26
 ---- batch: 030 ----
mean loss: 89.75
train mean loss: 91.64
epoch train time: 0:00:07.032072
elapsed time: 0:24:35.797938
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 08:03:32.017448
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.37
 ---- batch: 020 ----
mean loss: 94.87
 ---- batch: 030 ----
mean loss: 93.44
train mean loss: 92.79
epoch train time: 0:00:06.924771
elapsed time: 0:24:42.723481
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 08:03:38.942985
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.84
 ---- batch: 020 ----
mean loss: 89.45
 ---- batch: 030 ----
mean loss: 92.56
train mean loss: 92.26
epoch train time: 0:00:07.040129
elapsed time: 0:24:49.764437
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 08:03:45.983939
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.96
 ---- batch: 020 ----
mean loss: 92.97
 ---- batch: 030 ----
mean loss: 89.17
train mean loss: 92.11
epoch train time: 0:00:06.932351
elapsed time: 0:24:56.697553
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 08:03:52.917049
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.41
 ---- batch: 020 ----
mean loss: 89.34
 ---- batch: 030 ----
mean loss: 95.71
train mean loss: 92.24
epoch train time: 0:00:06.970954
elapsed time: 0:25:03.669372
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 08:03:59.888898
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.77
 ---- batch: 020 ----
mean loss: 95.14
 ---- batch: 030 ----
mean loss: 90.70
train mean loss: 92.78
epoch train time: 0:00:06.959214
elapsed time: 0:25:10.629366
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 08:04:06.848869
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.33
 ---- batch: 020 ----
mean loss: 92.62
 ---- batch: 030 ----
mean loss: 95.78
train mean loss: 92.42
epoch train time: 0:00:06.953054
elapsed time: 0:25:17.583199
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 08:04:13.802704
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.40
 ---- batch: 020 ----
mean loss: 91.06
 ---- batch: 030 ----
mean loss: 91.68
train mean loss: 92.69
epoch train time: 0:00:07.031756
elapsed time: 0:25:24.615755
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 08:04:20.835308
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.62
 ---- batch: 020 ----
mean loss: 94.48
 ---- batch: 030 ----
mean loss: 93.84
train mean loss: 92.22
epoch train time: 0:00:06.910529
elapsed time: 0:25:31.527082
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 08:04:27.746600
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.72
 ---- batch: 020 ----
mean loss: 92.41
 ---- batch: 030 ----
mean loss: 93.03
train mean loss: 92.37
epoch train time: 0:00:06.987775
elapsed time: 0:25:38.515696
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 08:04:34.735229
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.18
 ---- batch: 020 ----
mean loss: 93.14
 ---- batch: 030 ----
mean loss: 92.55
train mean loss: 92.59
epoch train time: 0:00:06.963962
elapsed time: 0:25:45.480502
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 08:04:41.700012
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.94
 ---- batch: 020 ----
mean loss: 90.98
 ---- batch: 030 ----
mean loss: 88.70
train mean loss: 91.42
epoch train time: 0:00:06.896914
elapsed time: 0:25:52.378208
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 08:04:48.597752
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.21
 ---- batch: 020 ----
mean loss: 90.56
 ---- batch: 030 ----
mean loss: 93.58
train mean loss: 91.14
epoch train time: 0:00:07.000907
elapsed time: 0:25:59.379998
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 08:04:55.599532
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.68
 ---- batch: 020 ----
mean loss: 91.23
 ---- batch: 030 ----
mean loss: 92.00
train mean loss: 92.78
epoch train time: 0:00:06.928142
elapsed time: 0:26:06.308976
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 08:05:02.528478
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.00
 ---- batch: 020 ----
mean loss: 92.40
 ---- batch: 030 ----
mean loss: 93.78
train mean loss: 92.59
epoch train time: 0:00:06.899496
elapsed time: 0:26:13.209271
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 08:05:09.428766
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.93
 ---- batch: 020 ----
mean loss: 93.38
 ---- batch: 030 ----
mean loss: 91.86
train mean loss: 91.77
epoch train time: 0:00:06.941874
elapsed time: 0:26:20.151951
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 08:05:16.371452
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.97
 ---- batch: 020 ----
mean loss: 94.73
 ---- batch: 030 ----
mean loss: 89.61
train mean loss: 91.96
epoch train time: 0:00:06.966479
elapsed time: 0:26:27.119183
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 08:05:23.338692
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.69
 ---- batch: 020 ----
mean loss: 92.44
 ---- batch: 030 ----
mean loss: 92.57
train mean loss: 92.20
epoch train time: 0:00:06.851840
elapsed time: 0:26:33.971800
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 08:05:30.191293
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.99
 ---- batch: 020 ----
mean loss: 93.30
 ---- batch: 030 ----
mean loss: 89.11
train mean loss: 91.86
epoch train time: 0:00:06.951836
elapsed time: 0:26:40.924445
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 08:05:37.143946
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.94
 ---- batch: 020 ----
mean loss: 93.60
 ---- batch: 030 ----
mean loss: 90.02
train mean loss: 91.57
epoch train time: 0:00:06.850610
elapsed time: 0:26:47.775804
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 08:05:43.995313
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.03
 ---- batch: 020 ----
mean loss: 91.41
 ---- batch: 030 ----
mean loss: 90.21
train mean loss: 91.80
epoch train time: 0:00:06.657235
elapsed time: 0:26:54.433829
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 08:05:50.653317
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.70
 ---- batch: 020 ----
mean loss: 91.40
 ---- batch: 030 ----
mean loss: 91.20
train mean loss: 91.47
epoch train time: 0:00:06.691113
elapsed time: 0:27:01.125744
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 08:05:57.345264
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.72
 ---- batch: 020 ----
mean loss: 91.94
 ---- batch: 030 ----
mean loss: 91.00
train mean loss: 92.10
epoch train time: 0:00:06.935609
elapsed time: 0:27:08.062497
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 08:06:04.281913
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.76
 ---- batch: 020 ----
mean loss: 90.85
 ---- batch: 030 ----
mean loss: 89.56
train mean loss: 91.43
epoch train time: 0:00:06.876969
elapsed time: 0:27:14.940182
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 08:06:11.159680
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.69
 ---- batch: 020 ----
mean loss: 90.59
 ---- batch: 030 ----
mean loss: 89.03
train mean loss: 91.63
epoch train time: 0:00:06.999229
elapsed time: 0:27:21.940300
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 08:06:18.159810
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.73
 ---- batch: 020 ----
mean loss: 89.75
 ---- batch: 030 ----
mean loss: 90.99
train mean loss: 91.65
epoch train time: 0:00:06.991275
elapsed time: 0:27:28.932325
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 08:06:25.151815
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.42
 ---- batch: 020 ----
mean loss: 92.01
 ---- batch: 030 ----
mean loss: 90.50
train mean loss: 91.72
epoch train time: 0:00:06.856714
elapsed time: 0:27:35.789931
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 08:06:32.009423
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.81
 ---- batch: 020 ----
mean loss: 91.93
 ---- batch: 030 ----
mean loss: 90.94
train mean loss: 92.25
epoch train time: 0:00:06.955462
elapsed time: 0:27:42.746172
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 08:06:38.965690
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.07
 ---- batch: 020 ----
mean loss: 91.12
 ---- batch: 030 ----
mean loss: 90.32
train mean loss: 91.81
epoch train time: 0:00:06.918375
elapsed time: 0:27:49.665509
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 08:06:45.885051
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.99
 ---- batch: 020 ----
mean loss: 91.05
 ---- batch: 030 ----
mean loss: 93.93
train mean loss: 91.80
epoch train time: 0:00:06.930170
elapsed time: 0:27:56.596516
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 08:06:52.816028
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.49
 ---- batch: 020 ----
mean loss: 91.41
 ---- batch: 030 ----
mean loss: 93.89
train mean loss: 91.82
epoch train time: 0:00:06.961326
elapsed time: 0:28:03.558661
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 08:06:59.778159
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.17
 ---- batch: 020 ----
mean loss: 91.93
 ---- batch: 030 ----
mean loss: 90.19
train mean loss: 91.16
epoch train time: 0:00:06.885400
elapsed time: 0:28:10.444893
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 08:07:06.664401
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.23
 ---- batch: 020 ----
mean loss: 92.85
 ---- batch: 030 ----
mean loss: 90.16
train mean loss: 91.52
epoch train time: 0:00:06.979627
elapsed time: 0:28:17.425292
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 08:07:13.644784
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.39
 ---- batch: 020 ----
mean loss: 90.68
 ---- batch: 030 ----
mean loss: 88.63
train mean loss: 90.87
epoch train time: 0:00:06.943352
elapsed time: 0:28:24.369415
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 08:07:20.588906
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.33
 ---- batch: 020 ----
mean loss: 90.64
 ---- batch: 030 ----
mean loss: 91.09
train mean loss: 91.10
epoch train time: 0:00:06.910601
elapsed time: 0:28:31.280930
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 08:07:27.500449
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.74
 ---- batch: 020 ----
mean loss: 93.09
 ---- batch: 030 ----
mean loss: 90.53
train mean loss: 91.36
epoch train time: 0:00:06.938647
elapsed time: 0:28:38.220395
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 08:07:34.439929
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.50
 ---- batch: 020 ----
mean loss: 88.61
 ---- batch: 030 ----
mean loss: 91.83
train mean loss: 91.20
epoch train time: 0:00:06.968397
elapsed time: 0:28:45.189653
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 08:07:41.409151
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.06
 ---- batch: 020 ----
mean loss: 89.93
 ---- batch: 030 ----
mean loss: 89.00
train mean loss: 90.76
epoch train time: 0:00:06.862368
elapsed time: 0:28:52.052896
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 08:07:48.272411
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.33
 ---- batch: 020 ----
mean loss: 92.06
 ---- batch: 030 ----
mean loss: 93.59
train mean loss: 91.26
epoch train time: 0:00:06.958892
elapsed time: 0:28:59.022249
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_4/checkpoint.pth.tar
**** end time: 2019-09-27 08:07:55.241656 ****
