Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_5', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30860
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 16:07:34.444148 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:07:34.452638
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3551.75
 ---- batch: 020 ----
mean loss: 1296.23
 ---- batch: 030 ----
mean loss: 685.61
train mean loss: 1662.04
epoch train time: 0:00:13.003142
elapsed time: 0:00:13.014382
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:07:47.458585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 445.56
 ---- batch: 020 ----
mean loss: 409.34
 ---- batch: 030 ----
mean loss: 374.35
train mean loss: 404.65
epoch train time: 0:00:01.522242
elapsed time: 0:00:14.536803
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:07:48.981022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 354.67
 ---- batch: 020 ----
mean loss: 349.13
 ---- batch: 030 ----
mean loss: 338.52
train mean loss: 344.81
epoch train time: 0:00:01.436824
elapsed time: 0:00:15.973820
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:07:50.418024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 316.89
 ---- batch: 020 ----
mean loss: 312.63
 ---- batch: 030 ----
mean loss: 299.36
train mean loss: 308.68
epoch train time: 0:00:01.425866
elapsed time: 0:00:17.399865
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:07:51.844073
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.69
 ---- batch: 020 ----
mean loss: 288.41
 ---- batch: 030 ----
mean loss: 276.41
train mean loss: 282.93
epoch train time: 0:00:01.432270
elapsed time: 0:00:18.832312
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:07:53.276532
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.09
 ---- batch: 020 ----
mean loss: 262.96
 ---- batch: 030 ----
mean loss: 251.72
train mean loss: 255.54
epoch train time: 0:00:01.428567
elapsed time: 0:00:20.261078
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:07:54.705292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.97
 ---- batch: 020 ----
mean loss: 237.52
 ---- batch: 030 ----
mean loss: 238.21
train mean loss: 238.48
epoch train time: 0:00:01.433591
elapsed time: 0:00:21.694872
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:07:56.139089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.84
 ---- batch: 020 ----
mean loss: 234.98
 ---- batch: 030 ----
mean loss: 225.00
train mean loss: 230.13
epoch train time: 0:00:01.439719
elapsed time: 0:00:23.134779
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:07:57.579009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.69
 ---- batch: 020 ----
mean loss: 212.45
 ---- batch: 030 ----
mean loss: 219.82
train mean loss: 217.66
epoch train time: 0:00:01.439407
elapsed time: 0:00:24.574403
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:07:59.018645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.62
 ---- batch: 020 ----
mean loss: 220.01
 ---- batch: 030 ----
mean loss: 214.00
train mean loss: 217.84
epoch train time: 0:00:01.439870
elapsed time: 0:00:26.014485
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:08:00.458703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.25
 ---- batch: 020 ----
mean loss: 207.49
 ---- batch: 030 ----
mean loss: 203.72
train mean loss: 206.76
epoch train time: 0:00:01.431175
elapsed time: 0:00:27.445853
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:08:01.890059
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.73
 ---- batch: 020 ----
mean loss: 210.98
 ---- batch: 030 ----
mean loss: 203.44
train mean loss: 203.62
epoch train time: 0:00:01.438907
elapsed time: 0:00:28.884943
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:08:03.329147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.87
 ---- batch: 020 ----
mean loss: 203.54
 ---- batch: 030 ----
mean loss: 198.34
train mean loss: 200.42
epoch train time: 0:00:01.441547
elapsed time: 0:00:30.326682
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:08:04.770891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.04
 ---- batch: 020 ----
mean loss: 200.96
 ---- batch: 030 ----
mean loss: 198.99
train mean loss: 199.02
epoch train time: 0:00:01.437367
elapsed time: 0:00:31.764237
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:08:06.208442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.37
 ---- batch: 020 ----
mean loss: 191.49
 ---- batch: 030 ----
mean loss: 193.00
train mean loss: 192.35
epoch train time: 0:00:01.437878
elapsed time: 0:00:33.202304
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:08:07.646513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.36
 ---- batch: 020 ----
mean loss: 187.31
 ---- batch: 030 ----
mean loss: 186.20
train mean loss: 187.55
epoch train time: 0:00:01.437416
elapsed time: 0:00:34.639916
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:08:09.084122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.60
 ---- batch: 020 ----
mean loss: 193.74
 ---- batch: 030 ----
mean loss: 194.58
train mean loss: 194.61
epoch train time: 0:00:01.445843
elapsed time: 0:00:36.085994
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:08:10.530203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.07
 ---- batch: 020 ----
mean loss: 182.42
 ---- batch: 030 ----
mean loss: 181.05
train mean loss: 183.48
epoch train time: 0:00:01.440047
elapsed time: 0:00:37.526221
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:08:11.970429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.91
 ---- batch: 020 ----
mean loss: 187.00
 ---- batch: 030 ----
mean loss: 182.73
train mean loss: 186.52
epoch train time: 0:00:01.435517
elapsed time: 0:00:38.961930
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:08:13.406134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.52
 ---- batch: 020 ----
mean loss: 191.18
 ---- batch: 030 ----
mean loss: 189.98
train mean loss: 186.56
epoch train time: 0:00:01.432202
elapsed time: 0:00:40.394334
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:08:14.838541
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.73
 ---- batch: 020 ----
mean loss: 189.53
 ---- batch: 030 ----
mean loss: 182.48
train mean loss: 186.06
epoch train time: 0:00:01.438611
elapsed time: 0:00:41.833119
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:08:16.277324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.08
 ---- batch: 020 ----
mean loss: 182.99
 ---- batch: 030 ----
mean loss: 185.10
train mean loss: 182.63
epoch train time: 0:00:01.437247
elapsed time: 0:00:43.270557
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:08:17.714792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.36
 ---- batch: 020 ----
mean loss: 189.76
 ---- batch: 030 ----
mean loss: 183.47
train mean loss: 184.04
epoch train time: 0:00:01.433849
elapsed time: 0:00:44.704616
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:08:19.148837
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.78
 ---- batch: 020 ----
mean loss: 181.13
 ---- batch: 030 ----
mean loss: 179.48
train mean loss: 178.67
epoch train time: 0:00:01.436498
elapsed time: 0:00:46.141342
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:08:20.585561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.58
 ---- batch: 020 ----
mean loss: 171.71
 ---- batch: 030 ----
mean loss: 180.86
train mean loss: 176.12
epoch train time: 0:00:01.438486
elapsed time: 0:00:47.580030
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:08:22.024247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.39
 ---- batch: 020 ----
mean loss: 180.11
 ---- batch: 030 ----
mean loss: 175.85
train mean loss: 179.69
epoch train time: 0:00:01.440231
elapsed time: 0:00:49.020449
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:08:23.464654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.93
 ---- batch: 020 ----
mean loss: 169.58
 ---- batch: 030 ----
mean loss: 192.37
train mean loss: 180.70
epoch train time: 0:00:01.430939
elapsed time: 0:00:50.451574
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:08:24.895784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.91
 ---- batch: 020 ----
mean loss: 181.43
 ---- batch: 030 ----
mean loss: 176.43
train mean loss: 178.82
epoch train time: 0:00:01.424654
elapsed time: 0:00:51.876411
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:08:26.320613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.37
 ---- batch: 020 ----
mean loss: 172.78
 ---- batch: 030 ----
mean loss: 174.52
train mean loss: 173.76
epoch train time: 0:00:01.427586
elapsed time: 0:00:53.304189
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:08:27.748414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.11
 ---- batch: 020 ----
mean loss: 179.52
 ---- batch: 030 ----
mean loss: 177.86
train mean loss: 178.23
epoch train time: 0:00:01.431884
elapsed time: 0:00:54.736252
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:08:29.180464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.09
 ---- batch: 020 ----
mean loss: 171.99
 ---- batch: 030 ----
mean loss: 168.30
train mean loss: 170.21
epoch train time: 0:00:01.432082
elapsed time: 0:00:56.168517
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:08:30.612720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.57
 ---- batch: 020 ----
mean loss: 167.11
 ---- batch: 030 ----
mean loss: 169.30
train mean loss: 168.14
epoch train time: 0:00:01.426127
elapsed time: 0:00:57.594812
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:08:32.039013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.40
 ---- batch: 020 ----
mean loss: 168.98
 ---- batch: 030 ----
mean loss: 168.26
train mean loss: 168.45
epoch train time: 0:00:01.431494
elapsed time: 0:00:59.026473
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:08:33.470679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.63
 ---- batch: 020 ----
mean loss: 163.65
 ---- batch: 030 ----
mean loss: 177.70
train mean loss: 173.36
epoch train time: 0:00:01.431720
elapsed time: 0:01:00.458403
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:08:34.902632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.89
 ---- batch: 020 ----
mean loss: 192.80
 ---- batch: 030 ----
mean loss: 179.62
train mean loss: 187.10
epoch train time: 0:00:01.428631
elapsed time: 0:01:01.887241
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:08:36.331446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.71
 ---- batch: 020 ----
mean loss: 166.32
 ---- batch: 030 ----
mean loss: 163.80
train mean loss: 165.95
epoch train time: 0:00:01.435995
elapsed time: 0:01:03.323415
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:08:37.767637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.39
 ---- batch: 020 ----
mean loss: 173.43
 ---- batch: 030 ----
mean loss: 159.15
train mean loss: 165.53
epoch train time: 0:00:01.434257
elapsed time: 0:01:04.757884
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:08:39.202090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.93
 ---- batch: 020 ----
mean loss: 161.80
 ---- batch: 030 ----
mean loss: 162.65
train mean loss: 162.52
epoch train time: 0:00:01.430271
elapsed time: 0:01:06.188322
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:08:40.632529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.93
 ---- batch: 020 ----
mean loss: 176.62
 ---- batch: 030 ----
mean loss: 169.45
train mean loss: 168.04
epoch train time: 0:00:01.436362
elapsed time: 0:01:07.624885
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:08:42.069090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.90
 ---- batch: 020 ----
mean loss: 161.20
 ---- batch: 030 ----
mean loss: 167.46
train mean loss: 163.18
epoch train time: 0:00:01.440867
elapsed time: 0:01:09.065934
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:08:43.510140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.04
 ---- batch: 020 ----
mean loss: 158.87
 ---- batch: 030 ----
mean loss: 159.18
train mean loss: 161.92
epoch train time: 0:00:01.441751
elapsed time: 0:01:10.507882
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:08:44.952087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.80
 ---- batch: 020 ----
mean loss: 166.54
 ---- batch: 030 ----
mean loss: 167.07
train mean loss: 161.92
epoch train time: 0:00:01.433019
elapsed time: 0:01:11.941079
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:08:46.385282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.42
 ---- batch: 020 ----
mean loss: 170.93
 ---- batch: 030 ----
mean loss: 156.52
train mean loss: 166.60
epoch train time: 0:00:01.438886
elapsed time: 0:01:13.380176
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:08:47.824391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.32
 ---- batch: 020 ----
mean loss: 163.51
 ---- batch: 030 ----
mean loss: 159.26
train mean loss: 161.49
epoch train time: 0:00:01.434736
elapsed time: 0:01:14.815105
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:08:49.259312
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.88
 ---- batch: 020 ----
mean loss: 168.72
 ---- batch: 030 ----
mean loss: 171.51
train mean loss: 167.41
epoch train time: 0:00:01.431499
elapsed time: 0:01:16.246784
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:08:50.690988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.71
 ---- batch: 020 ----
mean loss: 154.45
 ---- batch: 030 ----
mean loss: 155.81
train mean loss: 156.16
epoch train time: 0:00:01.435454
elapsed time: 0:01:17.682416
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:08:52.126619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.45
 ---- batch: 020 ----
mean loss: 156.73
 ---- batch: 030 ----
mean loss: 155.71
train mean loss: 157.86
epoch train time: 0:00:01.434191
elapsed time: 0:01:19.116782
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:08:53.560986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.49
 ---- batch: 020 ----
mean loss: 163.61
 ---- batch: 030 ----
mean loss: 154.21
train mean loss: 158.89
epoch train time: 0:00:01.436210
elapsed time: 0:01:20.553171
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:08:54.997378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.13
 ---- batch: 020 ----
mean loss: 153.98
 ---- batch: 030 ----
mean loss: 157.06
train mean loss: 155.09
epoch train time: 0:00:01.428760
elapsed time: 0:01:21.982124
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:08:56.426347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.47
 ---- batch: 020 ----
mean loss: 162.77
 ---- batch: 030 ----
mean loss: 160.07
train mean loss: 157.25
epoch train time: 0:00:01.427855
elapsed time: 0:01:23.410191
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:08:57.854395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.43
 ---- batch: 020 ----
mean loss: 154.72
 ---- batch: 030 ----
mean loss: 152.34
train mean loss: 152.96
epoch train time: 0:00:01.438085
elapsed time: 0:01:24.848446
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:08:59.292650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.07
 ---- batch: 020 ----
mean loss: 157.21
 ---- batch: 030 ----
mean loss: 154.13
train mean loss: 153.19
epoch train time: 0:00:01.426352
elapsed time: 0:01:26.274975
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:09:00.719178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.10
 ---- batch: 020 ----
mean loss: 153.63
 ---- batch: 030 ----
mean loss: 153.62
train mean loss: 153.35
epoch train time: 0:00:01.430399
elapsed time: 0:01:27.705567
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:09:02.149772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.27
 ---- batch: 020 ----
mean loss: 150.36
 ---- batch: 030 ----
mean loss: 148.57
train mean loss: 149.40
epoch train time: 0:00:01.426103
elapsed time: 0:01:29.131842
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:09:03.576045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.32
 ---- batch: 020 ----
mean loss: 157.90
 ---- batch: 030 ----
mean loss: 153.45
train mean loss: 152.20
epoch train time: 0:00:01.436845
elapsed time: 0:01:30.568873
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:09:05.013079
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.91
 ---- batch: 020 ----
mean loss: 156.94
 ---- batch: 030 ----
mean loss: 152.93
train mean loss: 152.22
epoch train time: 0:00:01.431737
elapsed time: 0:01:32.000804
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:09:06.445024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.37
 ---- batch: 020 ----
mean loss: 158.13
 ---- batch: 030 ----
mean loss: 158.67
train mean loss: 158.45
epoch train time: 0:00:01.429035
elapsed time: 0:01:33.430034
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:09:07.874237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.68
 ---- batch: 020 ----
mean loss: 152.90
 ---- batch: 030 ----
mean loss: 150.92
train mean loss: 151.19
epoch train time: 0:00:01.429938
elapsed time: 0:01:34.860149
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:09:09.304352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.73
 ---- batch: 020 ----
mean loss: 149.30
 ---- batch: 030 ----
mean loss: 150.88
train mean loss: 147.18
epoch train time: 0:00:01.430711
elapsed time: 0:01:36.291067
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:09:10.735275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.06
 ---- batch: 020 ----
mean loss: 154.89
 ---- batch: 030 ----
mean loss: 161.65
train mean loss: 157.44
epoch train time: 0:00:01.433409
elapsed time: 0:01:37.724659
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:09:12.168863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.77
 ---- batch: 020 ----
mean loss: 145.35
 ---- batch: 030 ----
mean loss: 154.24
train mean loss: 150.21
epoch train time: 0:00:01.435663
elapsed time: 0:01:39.160508
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:09:13.604712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.42
 ---- batch: 020 ----
mean loss: 147.21
 ---- batch: 030 ----
mean loss: 157.03
train mean loss: 150.80
epoch train time: 0:00:01.431442
elapsed time: 0:01:40.592132
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:09:15.036335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.81
 ---- batch: 020 ----
mean loss: 152.58
 ---- batch: 030 ----
mean loss: 149.25
train mean loss: 154.80
epoch train time: 0:00:01.429618
elapsed time: 0:01:42.021920
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:09:16.466140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.96
 ---- batch: 020 ----
mean loss: 154.27
 ---- batch: 030 ----
mean loss: 152.96
train mean loss: 151.78
epoch train time: 0:00:01.431656
elapsed time: 0:01:43.453771
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:09:17.897983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.44
 ---- batch: 020 ----
mean loss: 146.69
 ---- batch: 030 ----
mean loss: 145.73
train mean loss: 146.75
epoch train time: 0:00:01.434349
elapsed time: 0:01:44.888317
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:09:19.332523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.12
 ---- batch: 020 ----
mean loss: 146.39
 ---- batch: 030 ----
mean loss: 145.73
train mean loss: 147.25
epoch train time: 0:00:01.441679
elapsed time: 0:01:46.330197
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:09:20.774404
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.32
 ---- batch: 020 ----
mean loss: 151.70
 ---- batch: 030 ----
mean loss: 151.34
train mean loss: 150.88
epoch train time: 0:00:01.436407
elapsed time: 0:01:47.766808
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:09:22.211013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.52
 ---- batch: 020 ----
mean loss: 150.82
 ---- batch: 030 ----
mean loss: 145.92
train mean loss: 150.04
epoch train time: 0:00:01.425369
elapsed time: 0:01:49.192355
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:09:23.636556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.48
 ---- batch: 020 ----
mean loss: 148.89
 ---- batch: 030 ----
mean loss: 150.67
train mean loss: 151.84
epoch train time: 0:00:01.431136
elapsed time: 0:01:50.623662
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:09:25.067867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.33
 ---- batch: 020 ----
mean loss: 147.92
 ---- batch: 030 ----
mean loss: 145.08
train mean loss: 145.68
epoch train time: 0:00:01.430133
elapsed time: 0:01:52.054000
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:09:26.498203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.73
 ---- batch: 020 ----
mean loss: 150.12
 ---- batch: 030 ----
mean loss: 149.18
train mean loss: 148.93
epoch train time: 0:00:01.429635
elapsed time: 0:01:53.483820
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:09:27.928020
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.41
 ---- batch: 020 ----
mean loss: 145.09
 ---- batch: 030 ----
mean loss: 147.69
train mean loss: 146.31
epoch train time: 0:00:01.427743
elapsed time: 0:01:54.911734
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:09:29.355938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.68
 ---- batch: 020 ----
mean loss: 150.83
 ---- batch: 030 ----
mean loss: 148.34
train mean loss: 148.71
epoch train time: 0:00:01.432410
elapsed time: 0:01:56.344353
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:09:30.788560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.84
 ---- batch: 020 ----
mean loss: 167.52
 ---- batch: 030 ----
mean loss: 161.81
train mean loss: 156.75
epoch train time: 0:00:01.429503
elapsed time: 0:01:57.774056
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:09:32.218260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.05
 ---- batch: 020 ----
mean loss: 144.39
 ---- batch: 030 ----
mean loss: 148.74
train mean loss: 147.60
epoch train time: 0:00:01.435560
elapsed time: 0:01:59.209811
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:09:33.654015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.68
 ---- batch: 020 ----
mean loss: 150.80
 ---- batch: 030 ----
mean loss: 148.70
train mean loss: 148.78
epoch train time: 0:00:01.433751
elapsed time: 0:02:00.643742
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:09:35.087947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.68
 ---- batch: 020 ----
mean loss: 145.62
 ---- batch: 030 ----
mean loss: 142.93
train mean loss: 148.71
epoch train time: 0:00:01.431679
elapsed time: 0:02:02.075597
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:09:36.519817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.47
 ---- batch: 020 ----
mean loss: 148.45
 ---- batch: 030 ----
mean loss: 147.07
train mean loss: 146.62
epoch train time: 0:00:01.431466
elapsed time: 0:02:03.507265
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:09:37.951471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.46
 ---- batch: 020 ----
mean loss: 144.63
 ---- batch: 030 ----
mean loss: 151.08
train mean loss: 147.47
epoch train time: 0:00:01.435277
elapsed time: 0:02:04.942724
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:09:39.386930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.41
 ---- batch: 020 ----
mean loss: 149.48
 ---- batch: 030 ----
mean loss: 146.82
train mean loss: 147.40
epoch train time: 0:00:01.433474
elapsed time: 0:02:06.376425
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:09:40.820645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.23
 ---- batch: 020 ----
mean loss: 150.93
 ---- batch: 030 ----
mean loss: 147.50
train mean loss: 149.02
epoch train time: 0:00:01.432775
elapsed time: 0:02:07.809390
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:09:42.253597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.27
 ---- batch: 020 ----
mean loss: 145.32
 ---- batch: 030 ----
mean loss: 149.40
train mean loss: 145.91
epoch train time: 0:00:01.427167
elapsed time: 0:02:09.236745
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:09:43.680962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.35
 ---- batch: 020 ----
mean loss: 143.46
 ---- batch: 030 ----
mean loss: 145.98
train mean loss: 145.38
epoch train time: 0:00:01.434084
elapsed time: 0:02:10.671058
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:09:45.115269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.39
 ---- batch: 020 ----
mean loss: 147.62
 ---- batch: 030 ----
mean loss: 148.95
train mean loss: 148.10
epoch train time: 0:00:01.431142
elapsed time: 0:02:12.102374
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:09:46.546581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.85
 ---- batch: 020 ----
mean loss: 154.51
 ---- batch: 030 ----
mean loss: 149.35
train mean loss: 149.27
epoch train time: 0:00:01.428397
elapsed time: 0:02:13.530965
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:09:47.975198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.99
 ---- batch: 020 ----
mean loss: 147.51
 ---- batch: 030 ----
mean loss: 145.13
train mean loss: 145.82
epoch train time: 0:00:01.435121
elapsed time: 0:02:14.966303
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:09:49.410508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.69
 ---- batch: 020 ----
mean loss: 142.27
 ---- batch: 030 ----
mean loss: 145.44
train mean loss: 143.35
epoch train time: 0:00:01.435388
elapsed time: 0:02:16.401879
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:09:50.846087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.26
 ---- batch: 020 ----
mean loss: 153.71
 ---- batch: 030 ----
mean loss: 149.86
train mean loss: 150.81
epoch train time: 0:00:01.426188
elapsed time: 0:02:17.828240
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:09:52.272452
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.66
 ---- batch: 020 ----
mean loss: 142.29
 ---- batch: 030 ----
mean loss: 146.14
train mean loss: 147.01
epoch train time: 0:00:01.435858
elapsed time: 0:02:19.264284
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:09:53.708490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.30
 ---- batch: 020 ----
mean loss: 148.85
 ---- batch: 030 ----
mean loss: 148.11
train mean loss: 148.97
epoch train time: 0:00:01.431738
elapsed time: 0:02:20.696200
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:09:55.140454
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.79
 ---- batch: 020 ----
mean loss: 145.44
 ---- batch: 030 ----
mean loss: 144.89
train mean loss: 145.55
epoch train time: 0:00:01.428365
elapsed time: 0:02:22.124785
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:09:56.568986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.29
 ---- batch: 020 ----
mean loss: 150.34
 ---- batch: 030 ----
mean loss: 149.96
train mean loss: 147.47
epoch train time: 0:00:01.431305
elapsed time: 0:02:23.556258
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:09:58.000474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.68
 ---- batch: 020 ----
mean loss: 146.29
 ---- batch: 030 ----
mean loss: 145.02
train mean loss: 145.11
epoch train time: 0:00:01.433152
elapsed time: 0:02:24.989585
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:09:59.433785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.98
 ---- batch: 020 ----
mean loss: 143.54
 ---- batch: 030 ----
mean loss: 148.25
train mean loss: 147.30
epoch train time: 0:00:01.430587
elapsed time: 0:02:26.420373
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:10:00.864575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.07
 ---- batch: 020 ----
mean loss: 144.14
 ---- batch: 030 ----
mean loss: 153.99
train mean loss: 146.63
epoch train time: 0:00:01.430242
elapsed time: 0:02:27.850797
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:10:02.295006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.78
 ---- batch: 020 ----
mean loss: 142.38
 ---- batch: 030 ----
mean loss: 147.55
train mean loss: 146.48
epoch train time: 0:00:01.425231
elapsed time: 0:02:29.276221
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:10:03.720433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.95
 ---- batch: 020 ----
mean loss: 146.27
 ---- batch: 030 ----
mean loss: 144.88
train mean loss: 145.46
epoch train time: 0:00:01.430956
elapsed time: 0:02:30.707363
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:10:05.151566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.05
 ---- batch: 020 ----
mean loss: 147.22
 ---- batch: 030 ----
mean loss: 145.12
train mean loss: 144.42
epoch train time: 0:00:01.428888
elapsed time: 0:02:32.136456
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:10:06.580690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.42
 ---- batch: 020 ----
mean loss: 150.25
 ---- batch: 030 ----
mean loss: 151.99
train mean loss: 148.58
epoch train time: 0:00:01.434617
elapsed time: 0:02:33.571316
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:10:08.015575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.37
 ---- batch: 020 ----
mean loss: 144.33
 ---- batch: 030 ----
mean loss: 142.95
train mean loss: 146.52
epoch train time: 0:00:01.431784
elapsed time: 0:02:35.003354
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:10:09.447593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.04
 ---- batch: 020 ----
mean loss: 142.43
 ---- batch: 030 ----
mean loss: 142.77
train mean loss: 146.16
epoch train time: 0:00:01.434564
elapsed time: 0:02:36.438128
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:10:10.882329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.99
 ---- batch: 020 ----
mean loss: 146.12
 ---- batch: 030 ----
mean loss: 143.99
train mean loss: 144.82
epoch train time: 0:00:01.429548
elapsed time: 0:02:37.867879
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:10:12.312084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.22
 ---- batch: 020 ----
mean loss: 147.63
 ---- batch: 030 ----
mean loss: 140.19
train mean loss: 143.89
epoch train time: 0:00:01.429580
elapsed time: 0:02:39.297640
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:10:13.741851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.75
 ---- batch: 020 ----
mean loss: 144.38
 ---- batch: 030 ----
mean loss: 137.69
train mean loss: 141.68
epoch train time: 0:00:01.427152
elapsed time: 0:02:40.724970
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:10:15.169190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.16
 ---- batch: 020 ----
mean loss: 145.97
 ---- batch: 030 ----
mean loss: 142.46
train mean loss: 147.38
epoch train time: 0:00:01.432584
elapsed time: 0:02:42.157783
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:10:16.601982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.09
 ---- batch: 020 ----
mean loss: 145.43
 ---- batch: 030 ----
mean loss: 158.20
train mean loss: 149.22
epoch train time: 0:00:01.433004
elapsed time: 0:02:43.590963
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:10:18.035198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.53
 ---- batch: 020 ----
mean loss: 147.18
 ---- batch: 030 ----
mean loss: 142.85
train mean loss: 146.74
epoch train time: 0:00:01.433042
elapsed time: 0:02:45.024223
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:10:19.468410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.88
 ---- batch: 020 ----
mean loss: 143.84
 ---- batch: 030 ----
mean loss: 147.40
train mean loss: 145.22
epoch train time: 0:00:01.431365
elapsed time: 0:02:46.455748
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:10:20.899963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.60
 ---- batch: 020 ----
mean loss: 144.24
 ---- batch: 030 ----
mean loss: 140.60
train mean loss: 144.92
epoch train time: 0:00:01.431283
elapsed time: 0:02:47.887221
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:10:22.331428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.63
 ---- batch: 020 ----
mean loss: 147.14
 ---- batch: 030 ----
mean loss: 147.25
train mean loss: 151.80
epoch train time: 0:00:01.437163
elapsed time: 0:02:49.324559
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:10:23.768764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.27
 ---- batch: 020 ----
mean loss: 143.29
 ---- batch: 030 ----
mean loss: 145.44
train mean loss: 144.16
epoch train time: 0:00:01.431887
elapsed time: 0:02:50.756623
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:10:25.200827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.12
 ---- batch: 020 ----
mean loss: 145.80
 ---- batch: 030 ----
mean loss: 143.06
train mean loss: 146.12
epoch train time: 0:00:01.440272
elapsed time: 0:02:52.197114
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:10:26.641320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.51
 ---- batch: 020 ----
mean loss: 149.77
 ---- batch: 030 ----
mean loss: 145.55
train mean loss: 148.15
epoch train time: 0:00:01.431453
elapsed time: 0:02:53.628759
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:10:28.072974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.27
 ---- batch: 020 ----
mean loss: 142.33
 ---- batch: 030 ----
mean loss: 145.72
train mean loss: 143.87
epoch train time: 0:00:01.437829
elapsed time: 0:02:55.066792
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:10:29.511001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.37
 ---- batch: 020 ----
mean loss: 144.61
 ---- batch: 030 ----
mean loss: 145.37
train mean loss: 144.66
epoch train time: 0:00:01.436269
elapsed time: 0:02:56.503232
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:10:30.947433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.69
 ---- batch: 020 ----
mean loss: 141.36
 ---- batch: 030 ----
mean loss: 144.27
train mean loss: 142.86
epoch train time: 0:00:01.427872
elapsed time: 0:02:57.931286
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:10:32.375495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.83
 ---- batch: 020 ----
mean loss: 143.51
 ---- batch: 030 ----
mean loss: 141.73
train mean loss: 142.74
epoch train time: 0:00:01.432822
elapsed time: 0:02:59.364289
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:10:33.808517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.59
 ---- batch: 020 ----
mean loss: 145.04
 ---- batch: 030 ----
mean loss: 144.52
train mean loss: 147.72
epoch train time: 0:00:01.427798
elapsed time: 0:03:00.792297
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:10:35.236503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.41
 ---- batch: 020 ----
mean loss: 154.75
 ---- batch: 030 ----
mean loss: 145.83
train mean loss: 150.03
epoch train time: 0:00:01.433072
elapsed time: 0:03:02.225565
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:10:36.669772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.86
 ---- batch: 020 ----
mean loss: 144.09
 ---- batch: 030 ----
mean loss: 147.98
train mean loss: 144.33
epoch train time: 0:00:01.436744
elapsed time: 0:03:03.662487
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:10:38.106691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.87
 ---- batch: 020 ----
mean loss: 143.46
 ---- batch: 030 ----
mean loss: 141.57
train mean loss: 143.78
epoch train time: 0:00:01.434343
elapsed time: 0:03:05.097001
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:10:39.541207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.76
 ---- batch: 020 ----
mean loss: 141.75
 ---- batch: 030 ----
mean loss: 152.08
train mean loss: 145.56
epoch train time: 0:00:01.432295
elapsed time: 0:03:06.529576
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:10:40.973817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.25
 ---- batch: 020 ----
mean loss: 145.90
 ---- batch: 030 ----
mean loss: 140.16
train mean loss: 142.40
epoch train time: 0:00:01.433097
elapsed time: 0:03:07.962911
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:10:42.407117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.08
 ---- batch: 020 ----
mean loss: 139.73
 ---- batch: 030 ----
mean loss: 145.89
train mean loss: 142.43
epoch train time: 0:00:01.431106
elapsed time: 0:03:09.394183
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:10:43.838385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.25
 ---- batch: 020 ----
mean loss: 142.89
 ---- batch: 030 ----
mean loss: 144.16
train mean loss: 142.89
epoch train time: 0:00:01.431148
elapsed time: 0:03:10.825509
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:10:45.269718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.26
 ---- batch: 020 ----
mean loss: 146.52
 ---- batch: 030 ----
mean loss: 147.26
train mean loss: 147.92
epoch train time: 0:00:01.424247
elapsed time: 0:03:12.249949
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:10:46.694155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.24
 ---- batch: 020 ----
mean loss: 144.34
 ---- batch: 030 ----
mean loss: 144.07
train mean loss: 145.60
epoch train time: 0:00:01.435871
elapsed time: 0:03:13.685994
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:10:48.130182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.25
 ---- batch: 020 ----
mean loss: 147.81
 ---- batch: 030 ----
mean loss: 155.26
train mean loss: 148.56
epoch train time: 0:00:01.431783
elapsed time: 0:03:15.117933
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:10:49.562140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.64
 ---- batch: 020 ----
mean loss: 143.96
 ---- batch: 030 ----
mean loss: 140.29
train mean loss: 142.97
epoch train time: 0:00:01.431431
elapsed time: 0:03:16.549583
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:10:50.993790
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.19
 ---- batch: 020 ----
mean loss: 140.68
 ---- batch: 030 ----
mean loss: 142.64
train mean loss: 142.17
epoch train time: 0:00:01.431653
elapsed time: 0:03:17.981405
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:10:52.425623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.13
 ---- batch: 020 ----
mean loss: 154.81
 ---- batch: 030 ----
mean loss: 151.54
train mean loss: 151.30
epoch train time: 0:00:01.435958
elapsed time: 0:03:19.417573
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:10:53.861797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.23
 ---- batch: 020 ----
mean loss: 138.29
 ---- batch: 030 ----
mean loss: 146.47
train mean loss: 143.01
epoch train time: 0:00:01.436122
elapsed time: 0:03:20.853910
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:10:55.298116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.30
 ---- batch: 020 ----
mean loss: 147.00
 ---- batch: 030 ----
mean loss: 138.86
train mean loss: 142.43
epoch train time: 0:00:01.426807
elapsed time: 0:03:22.280899
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:10:56.725108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.66
 ---- batch: 020 ----
mean loss: 145.15
 ---- batch: 030 ----
mean loss: 145.36
train mean loss: 143.68
epoch train time: 0:00:01.433831
elapsed time: 0:03:23.714924
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:10:58.159128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.95
 ---- batch: 020 ----
mean loss: 141.37
 ---- batch: 030 ----
mean loss: 144.86
train mean loss: 142.27
epoch train time: 0:00:01.432102
elapsed time: 0:03:25.147196
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:10:59.591410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.09
 ---- batch: 020 ----
mean loss: 135.61
 ---- batch: 030 ----
mean loss: 145.91
train mean loss: 143.84
epoch train time: 0:00:01.428324
elapsed time: 0:03:26.575699
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:11:01.019904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.69
 ---- batch: 020 ----
mean loss: 144.51
 ---- batch: 030 ----
mean loss: 141.56
train mean loss: 143.69
epoch train time: 0:00:01.428137
elapsed time: 0:03:28.004002
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:11:02.448234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.87
 ---- batch: 020 ----
mean loss: 146.07
 ---- batch: 030 ----
mean loss: 142.84
train mean loss: 144.41
epoch train time: 0:00:01.430740
elapsed time: 0:03:29.434945
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:11:03.879156
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.35
 ---- batch: 020 ----
mean loss: 142.32
 ---- batch: 030 ----
mean loss: 141.39
train mean loss: 142.40
epoch train time: 0:00:01.430302
elapsed time: 0:03:30.865422
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:11:05.309670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.27
 ---- batch: 020 ----
mean loss: 137.93
 ---- batch: 030 ----
mean loss: 142.93
train mean loss: 140.40
epoch train time: 0:00:01.437895
elapsed time: 0:03:32.303545
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:11:06.747755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.89
 ---- batch: 020 ----
mean loss: 138.10
 ---- batch: 030 ----
mean loss: 145.21
train mean loss: 143.92
epoch train time: 0:00:01.435557
elapsed time: 0:03:33.739278
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:11:08.183481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.88
 ---- batch: 020 ----
mean loss: 139.28
 ---- batch: 030 ----
mean loss: 141.48
train mean loss: 143.67
epoch train time: 0:00:01.423550
elapsed time: 0:03:35.162990
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:11:09.607194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.17
 ---- batch: 020 ----
mean loss: 158.97
 ---- batch: 030 ----
mean loss: 158.26
train mean loss: 151.83
epoch train time: 0:00:01.432324
elapsed time: 0:03:36.595493
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:11:11.039697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.08
 ---- batch: 020 ----
mean loss: 140.59
 ---- batch: 030 ----
mean loss: 142.38
train mean loss: 142.68
epoch train time: 0:00:01.430859
elapsed time: 0:03:38.026514
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:11:12.470732
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.29
 ---- batch: 020 ----
mean loss: 143.64
 ---- batch: 030 ----
mean loss: 142.86
train mean loss: 145.76
epoch train time: 0:00:01.431132
elapsed time: 0:03:39.457829
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:11:13.902028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.58
 ---- batch: 020 ----
mean loss: 144.38
 ---- batch: 030 ----
mean loss: 140.28
train mean loss: 144.18
epoch train time: 0:00:01.432132
elapsed time: 0:03:40.890175
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:11:15.334377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.97
 ---- batch: 020 ----
mean loss: 138.78
 ---- batch: 030 ----
mean loss: 140.33
train mean loss: 139.70
epoch train time: 0:00:01.437084
elapsed time: 0:03:42.327448
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:11:16.771653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.22
 ---- batch: 020 ----
mean loss: 137.55
 ---- batch: 030 ----
mean loss: 145.28
train mean loss: 141.97
epoch train time: 0:00:01.431899
elapsed time: 0:03:43.759510
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:11:18.203713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.86
 ---- batch: 020 ----
mean loss: 141.56
 ---- batch: 030 ----
mean loss: 142.96
train mean loss: 142.88
epoch train time: 0:00:01.425495
elapsed time: 0:03:45.185181
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:11:19.629369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.49
 ---- batch: 020 ----
mean loss: 141.30
 ---- batch: 030 ----
mean loss: 144.25
train mean loss: 142.56
epoch train time: 0:00:01.426071
elapsed time: 0:03:46.611414
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:11:21.055617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.75
 ---- batch: 020 ----
mean loss: 140.63
 ---- batch: 030 ----
mean loss: 140.27
train mean loss: 140.08
epoch train time: 0:00:01.436149
elapsed time: 0:03:48.047764
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:11:22.491969
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.56
 ---- batch: 020 ----
mean loss: 143.30
 ---- batch: 030 ----
mean loss: 147.71
train mean loss: 145.88
epoch train time: 0:00:01.431966
elapsed time: 0:03:49.479901
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:11:23.924102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.06
 ---- batch: 020 ----
mean loss: 144.06
 ---- batch: 030 ----
mean loss: 135.82
train mean loss: 142.20
epoch train time: 0:00:01.423401
elapsed time: 0:03:50.903466
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:11:25.347666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.36
 ---- batch: 020 ----
mean loss: 144.01
 ---- batch: 030 ----
mean loss: 146.81
train mean loss: 144.39
epoch train time: 0:00:01.430949
elapsed time: 0:03:52.334580
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:11:26.778785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.36
 ---- batch: 020 ----
mean loss: 142.38
 ---- batch: 030 ----
mean loss: 139.61
train mean loss: 143.34
epoch train time: 0:00:01.429947
elapsed time: 0:03:53.764690
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:11:28.208889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.69
 ---- batch: 020 ----
mean loss: 140.71
 ---- batch: 030 ----
mean loss: 144.95
train mean loss: 142.04
epoch train time: 0:00:01.430469
elapsed time: 0:03:55.195331
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:11:29.639556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.11
 ---- batch: 020 ----
mean loss: 142.78
 ---- batch: 030 ----
mean loss: 142.13
train mean loss: 142.45
epoch train time: 0:00:01.429312
elapsed time: 0:03:56.624846
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:11:31.069049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.05
 ---- batch: 020 ----
mean loss: 140.55
 ---- batch: 030 ----
mean loss: 143.75
train mean loss: 142.02
epoch train time: 0:00:01.437875
elapsed time: 0:03:58.062899
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:11:32.507124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.66
 ---- batch: 020 ----
mean loss: 147.67
 ---- batch: 030 ----
mean loss: 143.30
train mean loss: 143.23
epoch train time: 0:00:01.435537
elapsed time: 0:03:59.498627
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:11:33.942829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.52
 ---- batch: 020 ----
mean loss: 157.72
 ---- batch: 030 ----
mean loss: 147.34
train mean loss: 149.77
epoch train time: 0:00:01.430677
elapsed time: 0:04:00.929501
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:11:35.373709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.66
 ---- batch: 020 ----
mean loss: 143.35
 ---- batch: 030 ----
mean loss: 138.54
train mean loss: 141.53
epoch train time: 0:00:01.430551
elapsed time: 0:04:02.360230
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:11:36.804443
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.20
 ---- batch: 020 ----
mean loss: 134.68
 ---- batch: 030 ----
mean loss: 137.98
train mean loss: 139.78
epoch train time: 0:00:01.425949
elapsed time: 0:04:03.786364
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:11:38.230566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.43
 ---- batch: 020 ----
mean loss: 140.39
 ---- batch: 030 ----
mean loss: 139.06
train mean loss: 140.91
epoch train time: 0:00:01.435620
elapsed time: 0:04:05.222154
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:11:39.666358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.77
 ---- batch: 020 ----
mean loss: 149.59
 ---- batch: 030 ----
mean loss: 142.96
train mean loss: 146.06
epoch train time: 0:00:01.425624
elapsed time: 0:04:06.647949
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:11:41.092169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.58
 ---- batch: 020 ----
mean loss: 136.40
 ---- batch: 030 ----
mean loss: 137.29
train mean loss: 138.90
epoch train time: 0:00:01.428496
elapsed time: 0:04:08.076691
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:11:42.520907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.68
 ---- batch: 020 ----
mean loss: 141.76
 ---- batch: 030 ----
mean loss: 142.24
train mean loss: 141.19
epoch train time: 0:00:01.429093
elapsed time: 0:04:09.505977
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:11:43.950183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.41
 ---- batch: 020 ----
mean loss: 140.65
 ---- batch: 030 ----
mean loss: 144.51
train mean loss: 144.89
epoch train time: 0:00:01.430193
elapsed time: 0:04:10.936342
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:11:45.380556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.52
 ---- batch: 020 ----
mean loss: 139.81
 ---- batch: 030 ----
mean loss: 138.95
train mean loss: 142.87
epoch train time: 0:00:01.431178
elapsed time: 0:04:12.367713
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:11:46.811929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.71
 ---- batch: 020 ----
mean loss: 136.17
 ---- batch: 030 ----
mean loss: 137.16
train mean loss: 139.37
epoch train time: 0:00:01.437008
elapsed time: 0:04:13.804914
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:11:48.249121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.29
 ---- batch: 020 ----
mean loss: 141.19
 ---- batch: 030 ----
mean loss: 135.21
train mean loss: 141.09
epoch train time: 0:00:01.425147
elapsed time: 0:04:15.230239
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:11:49.674464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.93
 ---- batch: 020 ----
mean loss: 139.61
 ---- batch: 030 ----
mean loss: 141.64
train mean loss: 141.85
epoch train time: 0:00:01.424972
elapsed time: 0:04:16.655415
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:11:51.099653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.30
 ---- batch: 020 ----
mean loss: 143.74
 ---- batch: 030 ----
mean loss: 141.17
train mean loss: 141.80
epoch train time: 0:00:01.429977
elapsed time: 0:04:18.085587
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:11:52.529789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.72
 ---- batch: 020 ----
mean loss: 138.04
 ---- batch: 030 ----
mean loss: 144.95
train mean loss: 142.42
epoch train time: 0:00:01.431872
elapsed time: 0:04:19.517621
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:11:53.961822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.51
 ---- batch: 020 ----
mean loss: 152.59
 ---- batch: 030 ----
mean loss: 143.45
train mean loss: 149.02
epoch train time: 0:00:01.429425
elapsed time: 0:04:20.947262
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:11:55.391453
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.17
 ---- batch: 020 ----
mean loss: 140.35
 ---- batch: 030 ----
mean loss: 139.87
train mean loss: 138.90
epoch train time: 0:00:01.432074
elapsed time: 0:04:22.379497
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:11:56.823698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.54
 ---- batch: 020 ----
mean loss: 141.28
 ---- batch: 030 ----
mean loss: 139.12
train mean loss: 142.04
epoch train time: 0:00:01.428614
elapsed time: 0:04:23.808268
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:11:58.252473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.32
 ---- batch: 020 ----
mean loss: 138.90
 ---- batch: 030 ----
mean loss: 143.55
train mean loss: 140.11
epoch train time: 0:00:01.434851
elapsed time: 0:04:25.243320
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:11:59.687582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.97
 ---- batch: 020 ----
mean loss: 138.90
 ---- batch: 030 ----
mean loss: 142.29
train mean loss: 139.53
epoch train time: 0:00:01.431259
elapsed time: 0:04:26.674796
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:12:01.119000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.37
 ---- batch: 020 ----
mean loss: 146.15
 ---- batch: 030 ----
mean loss: 141.15
train mean loss: 142.75
epoch train time: 0:00:01.431427
elapsed time: 0:04:28.106386
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:12:02.550587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.54
 ---- batch: 020 ----
mean loss: 138.14
 ---- batch: 030 ----
mean loss: 138.29
train mean loss: 140.10
epoch train time: 0:00:01.434290
elapsed time: 0:04:29.540841
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:12:03.985045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.72
 ---- batch: 020 ----
mean loss: 144.37
 ---- batch: 030 ----
mean loss: 140.01
train mean loss: 141.60
epoch train time: 0:00:01.427799
elapsed time: 0:04:30.968854
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:12:05.413064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.57
 ---- batch: 020 ----
mean loss: 139.13
 ---- batch: 030 ----
mean loss: 142.10
train mean loss: 139.12
epoch train time: 0:00:01.430616
elapsed time: 0:04:32.399652
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:12:06.843871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.83
 ---- batch: 020 ----
mean loss: 139.31
 ---- batch: 030 ----
mean loss: 137.16
train mean loss: 139.23
epoch train time: 0:00:01.428771
elapsed time: 0:04:33.828678
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:12:08.272901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.03
 ---- batch: 020 ----
mean loss: 148.50
 ---- batch: 030 ----
mean loss: 139.52
train mean loss: 143.52
epoch train time: 0:00:01.433826
elapsed time: 0:04:35.262696
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:12:09.706900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.63
 ---- batch: 020 ----
mean loss: 134.14
 ---- batch: 030 ----
mean loss: 139.15
train mean loss: 137.51
epoch train time: 0:00:01.437439
elapsed time: 0:04:36.700348
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:12:11.144578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.37
 ---- batch: 020 ----
mean loss: 146.43
 ---- batch: 030 ----
mean loss: 136.03
train mean loss: 141.20
epoch train time: 0:00:01.428560
elapsed time: 0:04:38.129092
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:12:12.573291
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.62
 ---- batch: 020 ----
mean loss: 141.87
 ---- batch: 030 ----
mean loss: 135.60
train mean loss: 139.57
epoch train time: 0:00:01.431569
elapsed time: 0:04:39.560825
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:12:14.005032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.79
 ---- batch: 020 ----
mean loss: 145.93
 ---- batch: 030 ----
mean loss: 146.31
train mean loss: 143.40
epoch train time: 0:00:01.430376
elapsed time: 0:04:40.991385
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:12:15.435587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.45
 ---- batch: 020 ----
mean loss: 138.14
 ---- batch: 030 ----
mean loss: 147.03
train mean loss: 144.04
epoch train time: 0:00:01.429563
elapsed time: 0:04:42.421126
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:12:16.865359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.99
 ---- batch: 020 ----
mean loss: 144.01
 ---- batch: 030 ----
mean loss: 142.68
train mean loss: 141.10
epoch train time: 0:00:01.430212
elapsed time: 0:04:43.851544
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:12:18.295759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.25
 ---- batch: 020 ----
mean loss: 137.29
 ---- batch: 030 ----
mean loss: 139.13
train mean loss: 139.27
epoch train time: 0:00:01.430269
elapsed time: 0:04:45.281984
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:12:19.726186
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.51
 ---- batch: 020 ----
mean loss: 134.08
 ---- batch: 030 ----
mean loss: 138.51
train mean loss: 137.84
epoch train time: 0:00:01.431633
elapsed time: 0:04:46.713809
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:12:21.158055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.89
 ---- batch: 020 ----
mean loss: 142.00
 ---- batch: 030 ----
mean loss: 142.27
train mean loss: 144.97
epoch train time: 0:00:01.434318
elapsed time: 0:04:48.148366
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:12:22.592571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.00
 ---- batch: 020 ----
mean loss: 144.59
 ---- batch: 030 ----
mean loss: 135.34
train mean loss: 140.07
epoch train time: 0:00:01.430934
elapsed time: 0:04:49.579460
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:12:24.023663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.93
 ---- batch: 020 ----
mean loss: 141.82
 ---- batch: 030 ----
mean loss: 139.87
train mean loss: 139.18
epoch train time: 0:00:01.430932
elapsed time: 0:04:51.010549
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:12:25.454748
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.86
 ---- batch: 020 ----
mean loss: 142.61
 ---- batch: 030 ----
mean loss: 139.46
train mean loss: 139.99
epoch train time: 0:00:01.427128
elapsed time: 0:04:52.437839
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:12:26.882039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.03
 ---- batch: 020 ----
mean loss: 142.40
 ---- batch: 030 ----
mean loss: 136.45
train mean loss: 141.46
epoch train time: 0:00:01.435131
elapsed time: 0:04:53.873195
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:12:28.317397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.92
 ---- batch: 020 ----
mean loss: 140.27
 ---- batch: 030 ----
mean loss: 144.64
train mean loss: 141.47
epoch train time: 0:00:01.434437
elapsed time: 0:04:55.307823
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:12:29.752073
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.81
 ---- batch: 020 ----
mean loss: 140.09
 ---- batch: 030 ----
mean loss: 139.45
train mean loss: 139.04
epoch train time: 0:00:01.431235
elapsed time: 0:04:56.739303
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:12:31.183505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.47
 ---- batch: 020 ----
mean loss: 148.21
 ---- batch: 030 ----
mean loss: 143.22
train mean loss: 142.53
epoch train time: 0:00:01.427174
elapsed time: 0:04:58.166633
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:12:32.610848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.86
 ---- batch: 020 ----
mean loss: 137.54
 ---- batch: 030 ----
mean loss: 144.16
train mean loss: 141.03
epoch train time: 0:00:01.424153
elapsed time: 0:04:59.590966
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:12:34.035227
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.25
 ---- batch: 020 ----
mean loss: 136.45
 ---- batch: 030 ----
mean loss: 137.95
train mean loss: 137.70
epoch train time: 0:00:01.428853
elapsed time: 0:05:01.020074
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:12:35.464297
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.74
 ---- batch: 020 ----
mean loss: 136.95
 ---- batch: 030 ----
mean loss: 135.11
train mean loss: 136.36
epoch train time: 0:00:01.430690
elapsed time: 0:05:02.450956
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:12:36.895173
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.30
 ---- batch: 020 ----
mean loss: 135.67
 ---- batch: 030 ----
mean loss: 139.14
train mean loss: 138.62
epoch train time: 0:00:01.423590
elapsed time: 0:05:03.874731
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:12:38.318931
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.09
 ---- batch: 020 ----
mean loss: 135.99
 ---- batch: 030 ----
mean loss: 136.62
train mean loss: 137.00
epoch train time: 0:00:01.432108
elapsed time: 0:05:05.307011
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:12:39.751215
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.34
 ---- batch: 020 ----
mean loss: 135.01
 ---- batch: 030 ----
mean loss: 134.24
train mean loss: 137.13
epoch train time: 0:00:01.429603
elapsed time: 0:05:06.736775
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:12:41.180977
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.10
 ---- batch: 020 ----
mean loss: 137.51
 ---- batch: 030 ----
mean loss: 135.16
train mean loss: 136.69
epoch train time: 0:00:01.432134
elapsed time: 0:05:08.169068
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:12:42.613267
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.55
 ---- batch: 020 ----
mean loss: 134.98
 ---- batch: 030 ----
mean loss: 140.27
train mean loss: 137.78
epoch train time: 0:00:01.429728
elapsed time: 0:05:09.598951
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:12:44.043151
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.78
 ---- batch: 020 ----
mean loss: 134.46
 ---- batch: 030 ----
mean loss: 136.16
train mean loss: 136.73
epoch train time: 0:00:01.430276
elapsed time: 0:05:11.029391
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:12:45.473633
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.61
 ---- batch: 020 ----
mean loss: 139.68
 ---- batch: 030 ----
mean loss: 136.84
train mean loss: 137.46
epoch train time: 0:00:01.426815
elapsed time: 0:05:12.456459
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:12:46.900686
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.26
 ---- batch: 020 ----
mean loss: 132.53
 ---- batch: 030 ----
mean loss: 135.33
train mean loss: 135.90
epoch train time: 0:00:01.429151
elapsed time: 0:05:13.885845
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:12:48.330046
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.87
 ---- batch: 020 ----
mean loss: 131.96
 ---- batch: 030 ----
mean loss: 132.95
train mean loss: 134.10
epoch train time: 0:00:01.429917
elapsed time: 0:05:15.315975
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:12:49.760211
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.28
 ---- batch: 020 ----
mean loss: 141.21
 ---- batch: 030 ----
mean loss: 140.41
train mean loss: 138.13
epoch train time: 0:00:01.428057
elapsed time: 0:05:16.744236
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:12:51.188450
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.91
 ---- batch: 020 ----
mean loss: 136.82
 ---- batch: 030 ----
mean loss: 137.03
train mean loss: 136.86
epoch train time: 0:00:01.434123
elapsed time: 0:05:18.178532
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:12:52.622748
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.02
 ---- batch: 020 ----
mean loss: 137.86
 ---- batch: 030 ----
mean loss: 133.76
train mean loss: 136.84
epoch train time: 0:00:01.432516
elapsed time: 0:05:19.611235
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:12:54.055451
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.04
 ---- batch: 020 ----
mean loss: 131.30
 ---- batch: 030 ----
mean loss: 139.75
train mean loss: 136.28
epoch train time: 0:00:01.435260
elapsed time: 0:05:21.046689
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:12:55.490894
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.08
 ---- batch: 020 ----
mean loss: 134.90
 ---- batch: 030 ----
mean loss: 137.43
train mean loss: 135.97
epoch train time: 0:00:01.427962
elapsed time: 0:05:22.474815
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:12:56.919015
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.75
 ---- batch: 020 ----
mean loss: 138.27
 ---- batch: 030 ----
mean loss: 140.35
train mean loss: 137.66
epoch train time: 0:00:01.430770
elapsed time: 0:05:23.905759
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:12:58.349960
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.84
 ---- batch: 020 ----
mean loss: 133.74
 ---- batch: 030 ----
mean loss: 136.71
train mean loss: 136.83
epoch train time: 0:00:01.431457
elapsed time: 0:05:25.337398
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:12:59.781641
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.81
 ---- batch: 020 ----
mean loss: 135.38
 ---- batch: 030 ----
mean loss: 135.11
train mean loss: 134.72
epoch train time: 0:00:01.432700
elapsed time: 0:05:26.770345
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:13:01.214553
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.74
 ---- batch: 020 ----
mean loss: 136.08
 ---- batch: 030 ----
mean loss: 137.26
train mean loss: 135.94
epoch train time: 0:00:01.438138
elapsed time: 0:05:28.208668
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:13:02.652871
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.54
 ---- batch: 020 ----
mean loss: 138.02
 ---- batch: 030 ----
mean loss: 133.37
train mean loss: 135.17
epoch train time: 0:00:01.431747
elapsed time: 0:05:29.640586
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:13:04.084790
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.62
 ---- batch: 020 ----
mean loss: 133.99
 ---- batch: 030 ----
mean loss: 137.99
train mean loss: 137.08
epoch train time: 0:00:01.437170
elapsed time: 0:05:31.077940
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:13:05.522138
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.65
 ---- batch: 020 ----
mean loss: 133.81
 ---- batch: 030 ----
mean loss: 138.43
train mean loss: 135.65
epoch train time: 0:00:01.429252
elapsed time: 0:05:32.507373
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:13:06.951576
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.07
 ---- batch: 020 ----
mean loss: 131.81
 ---- batch: 030 ----
mean loss: 130.67
train mean loss: 135.42
epoch train time: 0:00:01.435668
elapsed time: 0:05:33.943205
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:13:08.387439
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.92
 ---- batch: 020 ----
mean loss: 132.70
 ---- batch: 030 ----
mean loss: 139.00
train mean loss: 135.05
epoch train time: 0:00:01.433508
elapsed time: 0:05:35.376919
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:13:09.821130
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.92
 ---- batch: 020 ----
mean loss: 135.63
 ---- batch: 030 ----
mean loss: 134.71
train mean loss: 136.52
epoch train time: 0:00:01.431112
elapsed time: 0:05:36.808243
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:13:11.252444
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.65
 ---- batch: 020 ----
mean loss: 142.56
 ---- batch: 030 ----
mean loss: 135.78
train mean loss: 137.26
epoch train time: 0:00:01.430339
elapsed time: 0:05:38.238741
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:13:12.682953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.82
 ---- batch: 020 ----
mean loss: 135.72
 ---- batch: 030 ----
mean loss: 133.73
train mean loss: 136.79
epoch train time: 0:00:01.429574
elapsed time: 0:05:39.668524
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:13:14.112742
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.58
 ---- batch: 020 ----
mean loss: 133.37
 ---- batch: 030 ----
mean loss: 134.47
train mean loss: 134.94
epoch train time: 0:00:01.432161
elapsed time: 0:05:41.100884
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:13:15.545087
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.56
 ---- batch: 020 ----
mean loss: 139.22
 ---- batch: 030 ----
mean loss: 136.40
train mean loss: 135.95
epoch train time: 0:00:01.435949
elapsed time: 0:05:42.537021
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:13:16.981247
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.54
 ---- batch: 020 ----
mean loss: 136.71
 ---- batch: 030 ----
mean loss: 133.86
train mean loss: 135.63
epoch train time: 0:00:01.434962
elapsed time: 0:05:43.972204
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:13:18.416408
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.72
 ---- batch: 020 ----
mean loss: 138.28
 ---- batch: 030 ----
mean loss: 133.81
train mean loss: 136.57
epoch train time: 0:00:01.433698
elapsed time: 0:05:45.406105
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:13:19.850321
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.61
 ---- batch: 020 ----
mean loss: 141.36
 ---- batch: 030 ----
mean loss: 133.13
train mean loss: 137.28
epoch train time: 0:00:01.433689
elapsed time: 0:05:46.840017
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:13:21.284210
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.00
 ---- batch: 020 ----
mean loss: 136.33
 ---- batch: 030 ----
mean loss: 129.99
train mean loss: 135.40
epoch train time: 0:00:01.433742
elapsed time: 0:05:48.273904
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:13:22.718105
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.72
 ---- batch: 020 ----
mean loss: 132.04
 ---- batch: 030 ----
mean loss: 135.89
train mean loss: 136.11
epoch train time: 0:00:01.432500
elapsed time: 0:05:49.706564
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:13:24.150767
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.64
 ---- batch: 020 ----
mean loss: 138.87
 ---- batch: 030 ----
mean loss: 136.02
train mean loss: 137.70
epoch train time: 0:00:01.428127
elapsed time: 0:05:51.134859
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:13:25.579087
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.00
 ---- batch: 020 ----
mean loss: 133.82
 ---- batch: 030 ----
mean loss: 137.16
train mean loss: 135.52
epoch train time: 0:00:01.433219
elapsed time: 0:05:52.568297
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:13:27.012505
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.26
 ---- batch: 020 ----
mean loss: 137.15
 ---- batch: 030 ----
mean loss: 133.94
train mean loss: 136.30
epoch train time: 0:00:01.435762
elapsed time: 0:05:54.004284
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:13:28.448537
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.49
 ---- batch: 020 ----
mean loss: 138.13
 ---- batch: 030 ----
mean loss: 136.16
train mean loss: 137.32
epoch train time: 0:00:01.429199
elapsed time: 0:05:55.433711
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:13:29.877923
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.57
 ---- batch: 020 ----
mean loss: 136.17
 ---- batch: 030 ----
mean loss: 138.40
train mean loss: 135.75
epoch train time: 0:00:01.437427
elapsed time: 0:05:56.871335
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:13:31.315555
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.84
 ---- batch: 020 ----
mean loss: 136.36
 ---- batch: 030 ----
mean loss: 136.12
train mean loss: 136.81
epoch train time: 0:00:01.431430
elapsed time: 0:05:58.302952
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:13:32.747154
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.01
 ---- batch: 020 ----
mean loss: 136.48
 ---- batch: 030 ----
mean loss: 131.02
train mean loss: 135.55
epoch train time: 0:00:01.430019
elapsed time: 0:05:59.733141
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:13:34.177345
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.90
 ---- batch: 020 ----
mean loss: 139.07
 ---- batch: 030 ----
mean loss: 137.20
train mean loss: 136.74
epoch train time: 0:00:01.429264
elapsed time: 0:06:01.162569
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:13:35.606772
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.29
 ---- batch: 020 ----
mean loss: 134.45
 ---- batch: 030 ----
mean loss: 131.81
train mean loss: 135.23
epoch train time: 0:00:01.434142
elapsed time: 0:06:02.596882
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:13:37.041086
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.63
 ---- batch: 020 ----
mean loss: 136.85
 ---- batch: 030 ----
mean loss: 135.52
train mean loss: 134.76
epoch train time: 0:00:01.430849
elapsed time: 0:06:04.027897
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:13:38.472103
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.27
 ---- batch: 020 ----
mean loss: 135.05
 ---- batch: 030 ----
mean loss: 134.27
train mean loss: 134.64
epoch train time: 0:00:01.426169
elapsed time: 0:06:05.454243
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:13:39.898447
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.35
 ---- batch: 020 ----
mean loss: 133.83
 ---- batch: 030 ----
mean loss: 132.71
train mean loss: 134.49
epoch train time: 0:00:01.431849
elapsed time: 0:06:06.886287
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:13:41.330505
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.94
 ---- batch: 020 ----
mean loss: 138.30
 ---- batch: 030 ----
mean loss: 134.23
train mean loss: 136.26
epoch train time: 0:00:01.434713
elapsed time: 0:06:08.321199
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:13:42.765411
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.72
 ---- batch: 020 ----
mean loss: 136.36
 ---- batch: 030 ----
mean loss: 139.07
train mean loss: 135.84
epoch train time: 0:00:01.427541
elapsed time: 0:06:09.752316
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_5/checkpoint.pth.tar
**** end time: 2019-09-27 16:13:44.196482 ****
