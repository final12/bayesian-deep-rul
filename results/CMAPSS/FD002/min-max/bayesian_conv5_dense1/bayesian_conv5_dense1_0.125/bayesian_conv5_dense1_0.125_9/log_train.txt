Namespace(batch_size=512, dataset='CMAPSS/FD002', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD002/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_9', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.125, resume=False, step_size=200, visualize_step=50)
pid: 18050
use_cuda: True
Dataset: CMAPSS/FD002
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-25 17:14:04.726243 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 21, 24]             200
           Sigmoid-2           [-1, 10, 21, 24]               0
    BayesianConv2d-3           [-1, 10, 20, 24]           2,000
           Sigmoid-4           [-1, 10, 20, 24]               0
    BayesianConv2d-5           [-1, 10, 21, 24]           2,000
           Sigmoid-6           [-1, 10, 21, 24]               0
    BayesianConv2d-7           [-1, 10, 20, 24]           2,000
           Sigmoid-8           [-1, 10, 20, 24]               0
    BayesianConv2d-9            [-1, 1, 20, 24]              60
         Softplus-10            [-1, 1, 20, 24]               0
          Flatten-11                  [-1, 480]               0
   BayesianLinear-12                  [-1, 100]          96,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 102,460
Trainable params: 102,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-25 17:14:04.743005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2634.87
train mean loss: 2523.26
epoch train time: 0:00:05.907133
elapsed time: 0:00:05.931907
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-25 17:14:10.658204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1618.69
train mean loss: 1592.51
epoch train time: 0:00:02.132527
elapsed time: 0:00:08.064720
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-25 17:14:12.791056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1301.20
train mean loss: 1300.31
epoch train time: 0:00:02.122642
elapsed time: 0:00:10.188382
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-25 17:14:14.914740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1286.54
train mean loss: 1272.97
epoch train time: 0:00:02.105994
elapsed time: 0:00:12.294724
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-25 17:14:17.021073
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1172.87
train mean loss: 1171.92
epoch train time: 0:00:02.139685
elapsed time: 0:00:14.434735
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-25 17:14:19.161050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1123.47
train mean loss: 1130.43
epoch train time: 0:00:02.139612
elapsed time: 0:00:16.574707
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-25 17:14:21.301030
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1110.89
train mean loss: 1105.27
epoch train time: 0:00:02.140918
elapsed time: 0:00:18.715940
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-25 17:14:23.442257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1096.98
train mean loss: 1089.94
epoch train time: 0:00:02.148539
elapsed time: 0:00:20.864800
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-25 17:14:25.591118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1065.32
train mean loss: 1072.93
epoch train time: 0:00:02.133299
elapsed time: 0:00:22.998387
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-25 17:14:27.724716
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1034.53
train mean loss: 1042.11
epoch train time: 0:00:02.129969
elapsed time: 0:00:25.128658
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-25 17:14:29.854989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1035.27
train mean loss: 1033.28
epoch train time: 0:00:02.121106
elapsed time: 0:00:27.250051
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-25 17:14:31.976386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1047.45
train mean loss: 1042.40
epoch train time: 0:00:02.136113
elapsed time: 0:00:29.386469
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-25 17:14:34.112797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1049.46
train mean loss: 1032.33
epoch train time: 0:00:02.131385
elapsed time: 0:00:31.518265
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-25 17:14:36.244602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1023.79
train mean loss: 1021.63
epoch train time: 0:00:02.119064
elapsed time: 0:00:33.638160
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-25 17:14:38.364485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1032.49
train mean loss: 1029.35
epoch train time: 0:00:02.136696
elapsed time: 0:00:35.775147
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-25 17:14:40.501478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1033.61
train mean loss: 1020.60
epoch train time: 0:00:02.129586
elapsed time: 0:00:37.905026
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-25 17:14:42.631342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1012.76
train mean loss: 1014.31
epoch train time: 0:00:02.134343
elapsed time: 0:00:40.039662
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-25 17:14:44.765992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 997.61
train mean loss: 992.54
epoch train time: 0:00:02.128714
elapsed time: 0:00:42.168652
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-25 17:14:46.894987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1004.58
train mean loss: 995.78
epoch train time: 0:00:02.121639
elapsed time: 0:00:44.290590
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-25 17:14:49.016910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 999.71
train mean loss: 1003.24
epoch train time: 0:00:02.127958
elapsed time: 0:00:46.418846
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-25 17:14:51.145183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1002.89
train mean loss: 1007.88
epoch train time: 0:00:02.129000
elapsed time: 0:00:48.548134
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-25 17:14:53.274446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1014.10
train mean loss: 1005.84
epoch train time: 0:00:02.135599
elapsed time: 0:00:50.684007
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-25 17:14:55.410324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 997.13
train mean loss: 994.63
epoch train time: 0:00:02.131121
elapsed time: 0:00:52.815445
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-25 17:14:57.541787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1000.77
train mean loss: 1004.54
epoch train time: 0:00:02.130090
elapsed time: 0:00:54.945848
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-25 17:14:59.672162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 988.44
train mean loss: 985.72
epoch train time: 0:00:02.125661
elapsed time: 0:00:57.071849
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-25 17:15:01.798150
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 993.29
train mean loss: 989.45
epoch train time: 0:00:02.134373
elapsed time: 0:00:59.206515
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-25 17:15:03.932835
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 996.35
train mean loss: 995.77
epoch train time: 0:00:02.127821
elapsed time: 0:01:01.334609
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-25 17:15:06.060932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 983.18
train mean loss: 981.46
epoch train time: 0:00:02.137672
elapsed time: 0:01:03.472563
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-25 17:15:08.198892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 980.22
train mean loss: 987.63
epoch train time: 0:00:02.122447
elapsed time: 0:01:05.595334
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-25 17:15:10.321717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 992.81
train mean loss: 995.25
epoch train time: 0:00:02.127859
elapsed time: 0:01:07.723578
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-25 17:15:12.449916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 961.67
train mean loss: 972.52
epoch train time: 0:00:02.123760
elapsed time: 0:01:09.847652
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-25 17:15:14.574021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 979.44
train mean loss: 979.59
epoch train time: 0:00:02.129464
elapsed time: 0:01:11.977526
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-25 17:15:16.703892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 981.77
train mean loss: 983.20
epoch train time: 0:00:02.140425
elapsed time: 0:01:14.118293
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-25 17:15:18.844609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 989.39
train mean loss: 993.35
epoch train time: 0:00:02.133893
elapsed time: 0:01:16.252455
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-25 17:15:20.978772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 972.92
train mean loss: 984.43
epoch train time: 0:00:02.116441
elapsed time: 0:01:18.369170
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-25 17:15:23.095499
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 967.50
train mean loss: 969.78
epoch train time: 0:00:02.124593
elapsed time: 0:01:20.494063
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-25 17:15:25.220382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 965.01
train mean loss: 970.11
epoch train time: 0:00:02.124169
elapsed time: 0:01:22.618581
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-25 17:15:27.344939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 969.87
train mean loss: 968.97
epoch train time: 0:00:02.125979
elapsed time: 0:01:24.744896
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-25 17:15:29.471232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 982.61
train mean loss: 979.01
epoch train time: 0:00:02.126391
elapsed time: 0:01:26.871590
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-25 17:15:31.597912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 977.88
train mean loss: 973.14
epoch train time: 0:00:02.127190
elapsed time: 0:01:28.999125
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-25 17:15:33.725484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 973.83
train mean loss: 977.15
epoch train time: 0:00:02.128806
elapsed time: 0:01:31.128250
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-25 17:15:35.854570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 965.16
train mean loss: 962.99
epoch train time: 0:00:02.122256
elapsed time: 0:01:33.250801
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-25 17:15:37.977128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.90
train mean loss: 964.07
epoch train time: 0:00:02.114398
elapsed time: 0:01:35.365483
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-25 17:15:40.091800
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 963.90
train mean loss: 969.76
epoch train time: 0:00:02.126507
elapsed time: 0:01:37.492262
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-25 17:15:42.218599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.23
train mean loss: 958.93
epoch train time: 0:00:02.126871
elapsed time: 0:01:39.619437
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-25 17:15:44.345755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 971.88
train mean loss: 972.19
epoch train time: 0:00:02.123046
elapsed time: 0:01:41.742805
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-25 17:15:46.469139
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 975.73
train mean loss: 970.43
epoch train time: 0:00:02.127489
elapsed time: 0:01:43.870603
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-25 17:15:48.596931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 953.71
train mean loss: 957.07
epoch train time: 0:00:02.130446
elapsed time: 0:01:46.001350
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-25 17:15:50.727682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 955.15
train mean loss: 955.66
epoch train time: 0:00:02.129528
elapsed time: 0:01:48.131183
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-25 17:15:52.857500
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 963.40
train mean loss: 954.03
epoch train time: 0:00:02.135090
elapsed time: 0:01:50.266551
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-25 17:15:54.992880
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 975.08
train mean loss: 967.91
epoch train time: 0:00:02.124656
elapsed time: 0:01:52.391512
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-25 17:15:57.117832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 955.95
train mean loss: 958.26
epoch train time: 0:00:02.117500
elapsed time: 0:01:54.509311
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-25 17:15:59.235626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.22
train mean loss: 953.85
epoch train time: 0:00:02.146927
elapsed time: 0:01:56.656515
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-25 17:16:01.382834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 940.88
train mean loss: 943.82
epoch train time: 0:00:02.138259
elapsed time: 0:01:58.795072
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-25 17:16:03.521388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 956.78
train mean loss: 954.53
epoch train time: 0:00:02.137743
elapsed time: 0:02:00.933093
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-25 17:16:05.659451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 951.29
train mean loss: 958.91
epoch train time: 0:00:02.131683
elapsed time: 0:02:03.065105
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-25 17:16:07.791423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 952.03
train mean loss: 950.21
epoch train time: 0:00:02.138295
elapsed time: 0:02:05.203676
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-25 17:16:09.929994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 947.18
train mean loss: 952.16
epoch train time: 0:00:02.133781
elapsed time: 0:02:07.337795
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-25 17:16:12.064116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 956.14
train mean loss: 956.48
epoch train time: 0:00:02.124461
elapsed time: 0:02:09.462547
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-25 17:16:14.188913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 958.89
train mean loss: 949.05
epoch train time: 0:00:02.119813
elapsed time: 0:02:11.582708
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-25 17:16:16.309025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.12
train mean loss: 952.59
epoch train time: 0:00:02.123091
elapsed time: 0:02:13.706127
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-25 17:16:18.432482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 950.73
train mean loss: 945.77
epoch train time: 0:00:02.124072
elapsed time: 0:02:15.830507
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-25 17:16:20.556830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 955.92
train mean loss: 952.62
epoch train time: 0:00:02.123433
elapsed time: 0:02:17.954261
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-25 17:16:22.680578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 955.45
train mean loss: 951.94
epoch train time: 0:00:02.128497
elapsed time: 0:02:20.083076
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-25 17:16:24.809394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 956.76
train mean loss: 957.42
epoch train time: 0:00:02.139239
elapsed time: 0:02:22.222606
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-25 17:16:26.948931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 946.62
train mean loss: 947.32
epoch train time: 0:00:02.136710
elapsed time: 0:02:24.359621
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-25 17:16:29.085964
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 931.66
train mean loss: 940.30
epoch train time: 0:00:02.134258
elapsed time: 0:02:26.494221
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-25 17:16:31.220538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 945.16
train mean loss: 941.13
epoch train time: 0:00:02.132352
elapsed time: 0:02:28.626856
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-25 17:16:33.353179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 951.02
train mean loss: 951.97
epoch train time: 0:00:02.139602
elapsed time: 0:02:30.766728
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-25 17:16:35.493045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 938.70
train mean loss: 947.93
epoch train time: 0:00:02.130407
elapsed time: 0:02:32.897438
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-25 17:16:37.623758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 956.14
train mean loss: 952.18
epoch train time: 0:00:02.131160
elapsed time: 0:02:35.028877
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-25 17:16:39.755212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 939.41
train mean loss: 943.17
epoch train time: 0:00:02.129289
elapsed time: 0:02:37.158474
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-25 17:16:41.884788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 934.03
train mean loss: 944.04
epoch train time: 0:00:02.128543
elapsed time: 0:02:39.287310
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-25 17:16:44.013650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.36
train mean loss: 944.36
epoch train time: 0:00:02.134694
elapsed time: 0:02:41.422319
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-25 17:16:46.148642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.38
train mean loss: 945.45
epoch train time: 0:00:02.129899
elapsed time: 0:02:43.552511
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-25 17:16:48.278834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 953.61
train mean loss: 945.83
epoch train time: 0:00:02.136569
elapsed time: 0:02:45.689361
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-25 17:16:50.415683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 944.65
train mean loss: 942.59
epoch train time: 0:00:02.140583
elapsed time: 0:02:47.830274
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-25 17:16:52.556594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 947.34
train mean loss: 951.48
epoch train time: 0:00:02.134094
elapsed time: 0:02:49.964697
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-25 17:16:54.691033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 933.00
train mean loss: 932.24
epoch train time: 0:00:02.132778
elapsed time: 0:02:52.097832
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-25 17:16:56.824158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 950.08
train mean loss: 938.18
epoch train time: 0:00:02.122848
elapsed time: 0:02:54.221001
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-25 17:16:58.947323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 933.25
train mean loss: 932.29
epoch train time: 0:00:02.126710
elapsed time: 0:02:56.348003
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-25 17:17:01.074320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 935.37
train mean loss: 934.86
epoch train time: 0:00:02.135771
elapsed time: 0:02:58.484059
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-25 17:17:03.210377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 927.97
train mean loss: 928.50
epoch train time: 0:00:02.131978
elapsed time: 0:03:00.616311
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-25 17:17:05.342647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 936.19
train mean loss: 932.78
epoch train time: 0:00:02.135521
elapsed time: 0:03:02.752138
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-25 17:17:07.478461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.41
train mean loss: 928.82
epoch train time: 0:00:02.134468
elapsed time: 0:03:04.886907
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-25 17:17:09.613241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 924.44
train mean loss: 925.84
epoch train time: 0:00:02.136042
elapsed time: 0:03:07.023273
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-25 17:17:11.749593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 928.41
train mean loss: 924.91
epoch train time: 0:00:02.141343
elapsed time: 0:03:09.164981
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-25 17:17:13.891301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 940.66
train mean loss: 929.20
epoch train time: 0:00:02.116602
elapsed time: 0:03:11.281888
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-25 17:17:16.008210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.75
train mean loss: 918.77
epoch train time: 0:00:02.130956
elapsed time: 0:03:13.413145
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-25 17:17:18.139478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 919.89
train mean loss: 923.68
epoch train time: 0:00:02.139555
elapsed time: 0:03:15.552982
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-25 17:17:20.279317
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.17
train mean loss: 912.41
epoch train time: 0:00:02.132133
elapsed time: 0:03:17.685420
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-25 17:17:22.411734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.22
train mean loss: 916.88
epoch train time: 0:00:02.123083
elapsed time: 0:03:19.808773
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-25 17:17:24.535095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 910.86
train mean loss: 913.37
epoch train time: 0:00:02.144640
elapsed time: 0:03:21.953729
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-25 17:17:26.680082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 902.54
train mean loss: 910.73
epoch train time: 0:00:02.130804
elapsed time: 0:03:24.084903
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-25 17:17:28.811225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 921.30
train mean loss: 917.88
epoch train time: 0:00:02.139136
elapsed time: 0:03:26.224349
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-25 17:17:30.950667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 903.89
train mean loss: 906.49
epoch train time: 0:00:02.136144
elapsed time: 0:03:28.360868
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-25 17:17:33.087297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 924.89
train mean loss: 914.89
epoch train time: 0:00:02.128403
elapsed time: 0:03:30.489729
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-25 17:17:35.216054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 912.04
train mean loss: 910.75
epoch train time: 0:00:02.133882
elapsed time: 0:03:32.623909
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-25 17:17:37.350238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.05
train mean loss: 910.26
epoch train time: 0:00:02.133464
elapsed time: 0:03:34.757659
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-25 17:17:39.483980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 902.36
train mean loss: 908.01
epoch train time: 0:00:02.133445
elapsed time: 0:03:36.891409
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-25 17:17:41.617737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 905.19
train mean loss: 904.17
epoch train time: 0:00:02.134459
elapsed time: 0:03:39.026215
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-25 17:17:43.752559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 910.88
train mean loss: 906.05
epoch train time: 0:00:02.129898
elapsed time: 0:03:41.156448
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-25 17:17:45.882787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 905.09
train mean loss: 907.08
epoch train time: 0:00:02.133767
elapsed time: 0:03:43.290526
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-25 17:17:48.016866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 895.67
train mean loss: 898.95
epoch train time: 0:00:02.139392
elapsed time: 0:03:45.430255
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-25 17:17:50.156577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.77
train mean loss: 894.01
epoch train time: 0:00:02.132695
elapsed time: 0:03:47.563250
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-25 17:17:52.289572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.88
train mean loss: 904.25
epoch train time: 0:00:02.130463
elapsed time: 0:03:49.694037
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-25 17:17:54.420370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 889.71
train mean loss: 897.84
epoch train time: 0:00:02.132048
elapsed time: 0:03:51.826406
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-25 17:17:56.552694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 885.91
train mean loss: 887.52
epoch train time: 0:00:02.130759
elapsed time: 0:03:53.957454
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-25 17:17:58.683782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 889.27
train mean loss: 891.98
epoch train time: 0:00:02.135598
elapsed time: 0:03:56.093378
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-25 17:18:00.819696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 883.22
train mean loss: 882.44
epoch train time: 0:00:02.130363
elapsed time: 0:03:58.224073
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-25 17:18:02.950413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 891.42
train mean loss: 894.29
epoch train time: 0:00:02.134724
elapsed time: 0:04:00.359091
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-25 17:18:05.085406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 885.59
train mean loss: 888.49
epoch train time: 0:00:02.128089
elapsed time: 0:04:02.487477
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-25 17:18:07.213812
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 883.35
train mean loss: 880.84
epoch train time: 0:00:02.135073
elapsed time: 0:04:04.622869
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-25 17:18:09.349200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 887.49
train mean loss: 881.67
epoch train time: 0:00:02.134898
elapsed time: 0:04:06.758096
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-25 17:18:11.484414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 880.20
train mean loss: 875.97
epoch train time: 0:00:02.137557
elapsed time: 0:04:08.895975
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-25 17:18:13.622293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 862.89
train mean loss: 863.35
epoch train time: 0:00:02.132041
elapsed time: 0:04:11.028326
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-25 17:18:15.754649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 878.87
train mean loss: 873.26
epoch train time: 0:00:02.134099
elapsed time: 0:04:13.162719
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-25 17:18:17.889038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.39
train mean loss: 875.75
epoch train time: 0:00:02.128743
elapsed time: 0:04:15.291799
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-25 17:18:20.018127
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 876.55
train mean loss: 864.92
epoch train time: 0:00:02.141504
elapsed time: 0:04:17.433654
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-25 17:18:22.159977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 864.74
train mean loss: 864.61
epoch train time: 0:00:02.145483
elapsed time: 0:04:19.579451
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-25 17:18:24.305776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 833.53
train mean loss: 836.00
epoch train time: 0:00:02.135117
elapsed time: 0:04:21.714857
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-25 17:18:26.441196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 838.93
train mean loss: 834.78
epoch train time: 0:00:02.133235
elapsed time: 0:04:23.848420
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-25 17:18:28.574743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 833.05
train mean loss: 830.34
epoch train time: 0:00:02.126501
elapsed time: 0:04:25.975207
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-25 17:18:30.701524
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 815.83
train mean loss: 816.79
epoch train time: 0:00:02.128018
elapsed time: 0:04:28.103552
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-25 17:18:32.829880
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 805.40
train mean loss: 808.03
epoch train time: 0:00:02.135765
elapsed time: 0:04:30.239604
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-25 17:18:34.965927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 806.17
train mean loss: 810.71
epoch train time: 0:00:02.129351
elapsed time: 0:04:32.369249
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-25 17:18:37.095569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 790.88
train mean loss: 795.25
epoch train time: 0:00:02.134164
elapsed time: 0:04:34.503764
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-25 17:18:39.230082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 780.34
train mean loss: 776.99
epoch train time: 0:00:02.137567
elapsed time: 0:04:36.641617
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-25 17:18:41.367950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 779.57
train mean loss: 781.75
epoch train time: 0:00:02.127800
elapsed time: 0:04:38.769731
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-25 17:18:43.496065
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 779.75
train mean loss: 779.72
epoch train time: 0:00:02.136905
elapsed time: 0:04:40.906940
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-25 17:18:45.633257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 777.47
train mean loss: 766.42
epoch train time: 0:00:02.146038
elapsed time: 0:04:43.053294
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-25 17:18:47.779614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 751.95
train mean loss: 753.33
epoch train time: 0:00:02.138760
elapsed time: 0:04:45.192357
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-25 17:18:49.918680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 748.45
train mean loss: 744.37
epoch train time: 0:00:02.130675
elapsed time: 0:04:47.323327
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-25 17:18:52.049667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 748.27
train mean loss: 743.98
epoch train time: 0:00:02.133255
elapsed time: 0:04:49.456885
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-25 17:18:54.183218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 732.09
train mean loss: 726.18
epoch train time: 0:00:02.136610
elapsed time: 0:04:51.593807
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-25 17:18:56.320142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 732.90
train mean loss: 732.02
epoch train time: 0:00:02.136083
elapsed time: 0:04:53.730186
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-25 17:18:58.456507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 733.17
train mean loss: 730.68
epoch train time: 0:00:02.117333
elapsed time: 0:04:55.847817
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-25 17:19:00.574136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 717.47
train mean loss: 713.02
epoch train time: 0:00:02.127326
elapsed time: 0:04:57.975460
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-25 17:19:02.701782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 717.74
train mean loss: 713.08
epoch train time: 0:00:02.127563
elapsed time: 0:05:00.103317
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-25 17:19:04.829654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 708.93
train mean loss: 706.76
epoch train time: 0:00:02.139747
elapsed time: 0:05:02.243391
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-25 17:19:06.969739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 710.32
train mean loss: 709.12
epoch train time: 0:00:02.132240
elapsed time: 0:05:04.376017
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-25 17:19:09.102358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 701.23
train mean loss: 697.52
epoch train time: 0:00:02.135800
elapsed time: 0:05:06.512124
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-25 17:19:11.238450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 689.26
train mean loss: 691.87
epoch train time: 0:00:02.138664
elapsed time: 0:05:08.651066
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-25 17:19:13.377384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 691.00
train mean loss: 687.73
epoch train time: 0:00:02.122629
elapsed time: 0:05:10.773986
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-25 17:19:15.500333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 682.23
train mean loss: 682.81
epoch train time: 0:00:02.135394
elapsed time: 0:05:12.909678
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-25 17:19:17.636002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 669.54
train mean loss: 669.34
epoch train time: 0:00:02.133792
elapsed time: 0:05:15.043770
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-25 17:19:19.770088
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 668.47
train mean loss: 671.40
epoch train time: 0:00:02.143583
elapsed time: 0:05:17.187664
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-25 17:19:21.913981
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 677.67
train mean loss: 674.23
epoch train time: 0:00:02.123308
elapsed time: 0:05:19.311285
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-25 17:19:24.037621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 671.82
train mean loss: 668.70
epoch train time: 0:00:02.136463
elapsed time: 0:05:21.448090
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-25 17:19:26.174377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 657.14
train mean loss: 653.68
epoch train time: 0:00:02.123404
elapsed time: 0:05:23.571759
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-25 17:19:28.298076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 662.83
train mean loss: 656.13
epoch train time: 0:00:02.131335
elapsed time: 0:05:25.703383
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-25 17:19:30.429699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 649.02
train mean loss: 643.59
epoch train time: 0:00:02.135768
elapsed time: 0:05:27.839463
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-25 17:19:32.565793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 649.82
train mean loss: 645.43
epoch train time: 0:00:02.151168
elapsed time: 0:05:29.990936
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-25 17:19:34.717256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 624.87
train mean loss: 619.87
epoch train time: 0:00:02.120780
elapsed time: 0:05:32.112065
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-25 17:19:36.838394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 625.42
train mean loss: 625.65
epoch train time: 0:00:02.132349
elapsed time: 0:05:34.244713
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-25 17:19:38.971028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 642.19
train mean loss: 633.99
epoch train time: 0:00:02.141294
elapsed time: 0:05:36.386290
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-25 17:19:41.112642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 611.79
train mean loss: 611.32
epoch train time: 0:00:02.128515
elapsed time: 0:05:38.515108
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-25 17:19:43.241433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 611.54
train mean loss: 610.49
epoch train time: 0:00:02.146199
elapsed time: 0:05:40.661588
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-25 17:19:45.387949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 596.20
train mean loss: 596.16
epoch train time: 0:00:02.137847
elapsed time: 0:05:42.799752
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-25 17:19:47.526094
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 601.02
train mean loss: 597.90
epoch train time: 0:00:02.133024
elapsed time: 0:05:44.933125
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-25 17:19:49.659438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 594.24
train mean loss: 587.05
epoch train time: 0:00:02.129771
elapsed time: 0:05:47.063191
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-25 17:19:51.789508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 589.76
train mean loss: 585.45
epoch train time: 0:00:02.133158
elapsed time: 0:05:49.196662
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-25 17:19:53.922999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 593.03
train mean loss: 592.27
epoch train time: 0:00:02.129826
elapsed time: 0:05:51.326780
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-25 17:19:56.053096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 575.96
train mean loss: 576.87
epoch train time: 0:00:02.132943
elapsed time: 0:05:53.460012
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-25 17:19:58.186352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 577.63
train mean loss: 573.77
epoch train time: 0:00:02.136924
elapsed time: 0:05:55.597244
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-25 17:20:00.323560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 579.99
train mean loss: 580.69
epoch train time: 0:00:02.134954
elapsed time: 0:05:57.732504
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-25 17:20:02.458820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 559.47
train mean loss: 557.51
epoch train time: 0:00:02.130173
elapsed time: 0:05:59.862954
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-25 17:20:04.589276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 535.75
train mean loss: 546.36
epoch train time: 0:00:02.125724
elapsed time: 0:06:01.988991
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-25 17:20:06.715310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.75
train mean loss: 553.31
epoch train time: 0:00:02.120680
elapsed time: 0:06:04.109955
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-25 17:20:08.836274
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 541.10
train mean loss: 541.31
epoch train time: 0:00:02.136816
elapsed time: 0:06:06.247087
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-25 17:20:10.973408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 546.21
train mean loss: 548.14
epoch train time: 0:00:02.135416
elapsed time: 0:06:08.382779
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-25 17:20:13.109125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.42
train mean loss: 549.77
epoch train time: 0:00:02.127261
elapsed time: 0:06:10.510362
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-25 17:20:15.236682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 539.47
train mean loss: 538.22
epoch train time: 0:00:02.128758
elapsed time: 0:06:12.639480
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-25 17:20:17.365799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 538.09
train mean loss: 535.21
epoch train time: 0:00:02.127913
elapsed time: 0:06:14.767721
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-25 17:20:19.494011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 527.26
train mean loss: 527.46
epoch train time: 0:00:02.125535
elapsed time: 0:06:16.893544
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-25 17:20:21.619859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 525.97
train mean loss: 523.27
epoch train time: 0:00:02.126458
elapsed time: 0:06:19.020381
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-25 17:20:23.746715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 526.45
train mean loss: 519.97
epoch train time: 0:00:02.125324
elapsed time: 0:06:21.146037
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-25 17:20:25.872380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 522.04
train mean loss: 519.56
epoch train time: 0:00:02.139135
elapsed time: 0:06:23.285494
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-25 17:20:28.011822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 505.05
train mean loss: 509.95
epoch train time: 0:00:02.123887
elapsed time: 0:06:25.409667
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-25 17:20:30.136002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 504.51
train mean loss: 502.34
epoch train time: 0:00:02.118230
elapsed time: 0:06:27.528192
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-25 17:20:32.254510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 514.34
train mean loss: 515.41
epoch train time: 0:00:02.131052
elapsed time: 0:06:29.659550
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-25 17:20:34.385873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 507.50
train mean loss: 508.51
epoch train time: 0:00:02.136122
elapsed time: 0:06:31.795988
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-25 17:20:36.522354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 501.42
train mean loss: 497.91
epoch train time: 0:00:02.117592
elapsed time: 0:06:33.913982
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-25 17:20:38.640341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 489.55
train mean loss: 490.38
epoch train time: 0:00:02.131373
elapsed time: 0:06:36.045714
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-25 17:20:40.772041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 490.21
train mean loss: 488.74
epoch train time: 0:00:02.123386
elapsed time: 0:06:38.169415
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-25 17:20:42.895739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 478.85
train mean loss: 477.15
epoch train time: 0:00:02.104534
elapsed time: 0:06:40.274229
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-25 17:20:45.000550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 481.75
train mean loss: 479.21
epoch train time: 0:00:02.117195
elapsed time: 0:06:42.391697
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-25 17:20:47.118013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 485.11
train mean loss: 486.71
epoch train time: 0:00:02.123126
elapsed time: 0:06:44.515082
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-25 17:20:49.241405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 499.42
train mean loss: 489.58
epoch train time: 0:00:02.111807
elapsed time: 0:06:46.627178
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-25 17:20:51.353494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 477.91
train mean loss: 477.30
epoch train time: 0:00:02.107668
elapsed time: 0:06:48.735107
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-25 17:20:53.461435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 474.07
train mean loss: 469.22
epoch train time: 0:00:02.107645
elapsed time: 0:06:50.843032
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-25 17:20:55.569351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 476.60
train mean loss: 472.16
epoch train time: 0:00:02.104987
elapsed time: 0:06:52.948311
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-25 17:20:57.674634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 474.86
train mean loss: 469.49
epoch train time: 0:00:02.110471
elapsed time: 0:06:55.059175
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-25 17:20:59.785505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 479.09
train mean loss: 474.44
epoch train time: 0:00:02.103459
elapsed time: 0:06:57.162936
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-25 17:21:01.889259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 467.96
train mean loss: 465.47
epoch train time: 0:00:02.098909
elapsed time: 0:06:59.262126
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-25 17:21:03.988475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 466.49
train mean loss: 465.42
epoch train time: 0:00:02.111747
elapsed time: 0:07:01.374182
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-25 17:21:06.100505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 455.54
train mean loss: 457.34
epoch train time: 0:00:02.112904
elapsed time: 0:07:03.487396
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-25 17:21:08.213716
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 446.54
train mean loss: 448.74
epoch train time: 0:00:02.112358
elapsed time: 0:07:05.600054
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-25 17:21:10.326413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 448.99
train mean loss: 446.42
epoch train time: 0:00:02.113773
elapsed time: 0:07:07.714143
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-25 17:21:12.440470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 455.41
train mean loss: 453.78
epoch train time: 0:00:02.103891
elapsed time: 0:07:09.818340
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-25 17:21:14.544659
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 434.40
train mean loss: 437.33
epoch train time: 0:00:02.104251
elapsed time: 0:07:11.922889
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-25 17:21:16.649240
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 440.67
train mean loss: 442.47
epoch train time: 0:00:02.106887
elapsed time: 0:07:14.030289
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-25 17:21:18.756606
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 457.72
train mean loss: 455.92
epoch train time: 0:00:02.120037
elapsed time: 0:07:16.150618
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-25 17:21:20.876940
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 448.35
train mean loss: 448.99
epoch train time: 0:00:02.122700
elapsed time: 0:07:18.273608
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-25 17:21:22.999928
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 448.11
train mean loss: 450.04
epoch train time: 0:00:02.127787
elapsed time: 0:07:20.401765
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-25 17:21:25.128081
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 444.90
train mean loss: 443.31
epoch train time: 0:00:02.135900
elapsed time: 0:07:22.537959
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-25 17:21:27.264305
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.79
train mean loss: 436.24
epoch train time: 0:00:02.139818
elapsed time: 0:07:24.678120
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-25 17:21:29.404455
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 445.29
train mean loss: 440.07
epoch train time: 0:00:02.144589
elapsed time: 0:07:26.823021
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-25 17:21:31.549348
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.07
train mean loss: 438.67
epoch train time: 0:00:02.134678
elapsed time: 0:07:28.958104
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-25 17:21:33.684517
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 441.47
train mean loss: 438.92
epoch train time: 0:00:02.133850
elapsed time: 0:07:31.092320
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-25 17:21:35.818643
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.58
train mean loss: 437.05
epoch train time: 0:00:02.131149
elapsed time: 0:07:33.223766
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-25 17:21:37.950083
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 451.61
train mean loss: 448.23
epoch train time: 0:00:02.124731
elapsed time: 0:07:35.348773
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-25 17:21:40.075092
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.65
train mean loss: 434.96
epoch train time: 0:00:02.126251
elapsed time: 0:07:37.475312
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-25 17:21:42.201676
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 445.77
train mean loss: 442.67
epoch train time: 0:00:02.127560
elapsed time: 0:07:39.603254
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-25 17:21:44.329586
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 442.45
train mean loss: 444.81
epoch train time: 0:00:02.131712
elapsed time: 0:07:41.735284
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-25 17:21:46.461619
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 442.20
train mean loss: 443.77
epoch train time: 0:00:02.112574
elapsed time: 0:07:43.848179
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-25 17:21:48.574513
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 445.82
train mean loss: 441.35
epoch train time: 0:00:02.135398
elapsed time: 0:07:45.983893
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-25 17:21:50.710246
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 443.04
train mean loss: 442.46
epoch train time: 0:00:02.120413
elapsed time: 0:07:48.104633
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-25 17:21:52.830953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 441.65
train mean loss: 438.79
epoch train time: 0:00:02.132776
elapsed time: 0:07:50.237766
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-25 17:21:54.964089
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 447.25
train mean loss: 445.55
epoch train time: 0:00:02.133625
elapsed time: 0:07:52.371681
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-25 17:21:57.098010
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 437.57
train mean loss: 445.24
epoch train time: 0:00:02.120129
elapsed time: 0:07:54.492085
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-25 17:21:59.218400
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 441.64
train mean loss: 441.24
epoch train time: 0:00:02.122386
elapsed time: 0:07:56.614791
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-25 17:22:01.341112
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.56
train mean loss: 435.44
epoch train time: 0:00:02.127823
elapsed time: 0:07:58.742959
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-25 17:22:03.469278
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 441.69
train mean loss: 440.62
epoch train time: 0:00:02.135577
elapsed time: 0:08:00.878847
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-25 17:22:05.605166
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 431.64
train mean loss: 430.86
epoch train time: 0:00:02.129444
elapsed time: 0:08:03.008570
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-25 17:22:07.734887
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 453.53
train mean loss: 449.87
epoch train time: 0:00:02.130702
elapsed time: 0:08:05.139587
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-25 17:22:09.865933
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.07
train mean loss: 432.37
epoch train time: 0:00:02.134667
elapsed time: 0:08:07.274559
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-25 17:22:12.000876
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 453.27
train mean loss: 449.51
epoch train time: 0:00:02.131654
elapsed time: 0:08:09.406496
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-25 17:22:14.132816
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 454.93
train mean loss: 448.18
epoch train time: 0:00:02.123391
elapsed time: 0:08:11.530195
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-25 17:22:16.256524
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.84
train mean loss: 434.90
epoch train time: 0:00:02.129247
elapsed time: 0:08:13.659743
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-25 17:22:18.386062
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 437.05
train mean loss: 437.23
epoch train time: 0:00:02.121969
elapsed time: 0:08:15.782043
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-25 17:22:20.508380
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 437.46
train mean loss: 436.53
epoch train time: 0:00:02.136654
elapsed time: 0:08:17.919014
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-25 17:22:22.645348
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.54
train mean loss: 442.32
epoch train time: 0:00:02.134691
elapsed time: 0:08:20.054012
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-25 17:22:24.780347
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 439.08
train mean loss: 439.48
epoch train time: 0:00:02.138754
elapsed time: 0:08:22.193102
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-25 17:22:26.919388
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 440.62
train mean loss: 437.84
epoch train time: 0:00:02.124805
elapsed time: 0:08:24.318179
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-25 17:22:29.044504
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 431.35
train mean loss: 433.19
epoch train time: 0:00:02.123501
elapsed time: 0:08:26.442043
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-25 17:22:31.168378
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 425.30
train mean loss: 426.56
epoch train time: 0:00:02.135093
elapsed time: 0:08:28.577490
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-25 17:22:33.303784
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 445.24
train mean loss: 442.73
epoch train time: 0:00:02.126385
elapsed time: 0:08:30.704140
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-25 17:22:35.430457
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 442.65
train mean loss: 442.10
epoch train time: 0:00:02.118786
elapsed time: 0:08:32.823287
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-25 17:22:37.549633
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 428.56
train mean loss: 432.61
epoch train time: 0:00:02.119811
elapsed time: 0:08:34.943498
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-25 17:22:39.669822
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 429.52
train mean loss: 426.23
epoch train time: 0:00:02.131914
elapsed time: 0:08:37.075717
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-25 17:22:41.802071
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 429.98
train mean loss: 431.22
epoch train time: 0:00:02.125506
elapsed time: 0:08:39.201537
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-25 17:22:43.927859
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 441.88
train mean loss: 440.18
epoch train time: 0:00:02.130093
elapsed time: 0:08:41.332001
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-25 17:22:46.058324
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 422.46
train mean loss: 427.74
epoch train time: 0:00:02.125118
elapsed time: 0:08:43.457401
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-25 17:22:48.183719
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.31
train mean loss: 438.22
epoch train time: 0:00:02.127005
elapsed time: 0:08:45.584678
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-25 17:22:50.311009
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 425.11
train mean loss: 426.01
epoch train time: 0:00:02.123981
elapsed time: 0:08:47.708974
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-25 17:22:52.435289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 430.30
train mean loss: 430.81
epoch train time: 0:00:02.122373
elapsed time: 0:08:49.831652
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-25 17:22:54.557968
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.36
train mean loss: 432.46
epoch train time: 0:00:02.121675
elapsed time: 0:08:51.953611
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-25 17:22:56.679938
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.27
train mean loss: 434.76
epoch train time: 0:00:02.132007
elapsed time: 0:08:54.085965
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-25 17:22:58.812284
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 427.63
train mean loss: 427.18
epoch train time: 0:00:02.132345
elapsed time: 0:08:56.227745
checkpoint saved in file: log/CMAPSS/FD002/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_9/checkpoint.pth.tar
**** end time: 2019-09-25 17:23:00.954006 ****
