Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_9', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32470
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 17:02:46.239079 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 17:02:46.242595
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4149.36
 ---- batch: 020 ----
mean loss: 3918.74
 ---- batch: 030 ----
mean loss: 3909.11
train mean loss: 3974.60
epoch train time: 0:00:12.401846
elapsed time: 0:00:12.408079
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 17:02:58.647207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3810.51
 ---- batch: 020 ----
mean loss: 3723.77
 ---- batch: 030 ----
mean loss: 3701.05
train mean loss: 3739.06
epoch train time: 0:00:00.182042
elapsed time: 0:00:12.590265
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 17:02:58.829423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3623.33
 ---- batch: 020 ----
mean loss: 3561.63
 ---- batch: 030 ----
mean loss: 3531.14
train mean loss: 3555.79
epoch train time: 0:00:00.178517
elapsed time: 0:00:12.768943
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 17:02:59.008066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3427.05
 ---- batch: 020 ----
mean loss: 3361.07
 ---- batch: 030 ----
mean loss: 3357.80
train mean loss: 3380.21
epoch train time: 0:00:00.177696
elapsed time: 0:00:12.946781
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 17:02:59.185917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3227.58
 ---- batch: 020 ----
mean loss: 3178.17
 ---- batch: 030 ----
mean loss: 3257.83
train mean loss: 3211.19
epoch train time: 0:00:00.178419
elapsed time: 0:00:13.125352
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 17:02:59.364486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3106.29
 ---- batch: 020 ----
mean loss: 3044.83
 ---- batch: 030 ----
mean loss: 3039.31
train mean loss: 3054.60
epoch train time: 0:00:00.175943
elapsed time: 0:00:13.301444
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 17:02:59.540572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2979.42
 ---- batch: 020 ----
mean loss: 2906.94
 ---- batch: 030 ----
mean loss: 2855.30
train mean loss: 2903.15
epoch train time: 0:00:00.176962
elapsed time: 0:00:13.478569
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 17:02:59.717697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2799.83
 ---- batch: 020 ----
mean loss: 2778.26
 ---- batch: 030 ----
mean loss: 2686.27
train mean loss: 2745.29
epoch train time: 0:00:00.176919
elapsed time: 0:00:13.655626
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 17:02:59.894752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2645.15
 ---- batch: 020 ----
mean loss: 2608.69
 ---- batch: 030 ----
mean loss: 2577.02
train mean loss: 2600.89
epoch train time: 0:00:00.173536
elapsed time: 0:00:13.829298
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 17:03:00.068426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2526.65
 ---- batch: 020 ----
mean loss: 2463.46
 ---- batch: 030 ----
mean loss: 2438.03
train mean loss: 2462.51
epoch train time: 0:00:00.173365
elapsed time: 0:00:14.002804
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 17:03:00.241929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2362.53
 ---- batch: 020 ----
mean loss: 2352.21
 ---- batch: 030 ----
mean loss: 2293.80
train mean loss: 2325.66
epoch train time: 0:00:00.178844
elapsed time: 0:00:14.181792
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 17:03:00.420977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2238.08
 ---- batch: 020 ----
mean loss: 2225.01
 ---- batch: 030 ----
mean loss: 2153.31
train mean loss: 2204.02
epoch train time: 0:00:00.180999
elapsed time: 0:00:14.363000
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 17:03:00.602124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2139.38
 ---- batch: 020 ----
mean loss: 2083.55
 ---- batch: 030 ----
mean loss: 2088.67
train mean loss: 2089.54
epoch train time: 0:00:00.175612
elapsed time: 0:00:14.538746
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 17:03:00.777874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2055.09
 ---- batch: 020 ----
mean loss: 2000.56
 ---- batch: 030 ----
mean loss: 1939.22
train mean loss: 1983.41
epoch train time: 0:00:00.173626
elapsed time: 0:00:14.712512
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 17:03:00.951638
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1912.34
 ---- batch: 020 ----
mean loss: 1890.73
 ---- batch: 030 ----
mean loss: 1860.14
train mean loss: 1880.89
epoch train time: 0:00:00.174426
elapsed time: 0:00:14.887093
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 17:03:01.126220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1808.13
 ---- batch: 020 ----
mean loss: 1781.01
 ---- batch: 030 ----
mean loss: 1768.45
train mean loss: 1780.16
epoch train time: 0:00:00.174681
elapsed time: 0:00:15.061964
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 17:03:01.301091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1718.47
 ---- batch: 020 ----
mean loss: 1681.26
 ---- batch: 030 ----
mean loss: 1663.45
train mean loss: 1682.20
epoch train time: 0:00:00.172508
elapsed time: 0:00:15.234691
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 17:03:01.473825
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1629.09
 ---- batch: 020 ----
mean loss: 1598.97
 ---- batch: 030 ----
mean loss: 1550.24
train mean loss: 1592.60
epoch train time: 0:00:00.180217
elapsed time: 0:00:15.415070
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 17:03:01.654227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1542.39
 ---- batch: 020 ----
mean loss: 1518.69
 ---- batch: 030 ----
mean loss: 1478.69
train mean loss: 1506.93
epoch train time: 0:00:00.171191
elapsed time: 0:00:15.586427
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 17:03:01.825553
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1460.31
 ---- batch: 020 ----
mean loss: 1426.96
 ---- batch: 030 ----
mean loss: 1406.64
train mean loss: 1426.01
epoch train time: 0:00:00.172029
elapsed time: 0:00:15.758612
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 17:03:01.997739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1361.60
 ---- batch: 020 ----
mean loss: 1354.04
 ---- batch: 030 ----
mean loss: 1334.82
train mean loss: 1351.19
epoch train time: 0:00:00.171101
elapsed time: 0:00:15.929847
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 17:03:02.168997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1293.96
 ---- batch: 020 ----
mean loss: 1311.09
 ---- batch: 030 ----
mean loss: 1264.95
train mean loss: 1279.06
epoch train time: 0:00:00.170151
elapsed time: 0:00:16.100210
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 17:03:02.339341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1245.17
 ---- batch: 020 ----
mean loss: 1216.74
 ---- batch: 030 ----
mean loss: 1201.39
train mean loss: 1211.35
epoch train time: 0:00:00.171228
elapsed time: 0:00:16.271579
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 17:03:02.510706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1154.57
 ---- batch: 020 ----
mean loss: 1168.02
 ---- batch: 030 ----
mean loss: 1150.62
train mean loss: 1146.61
epoch train time: 0:00:00.175493
elapsed time: 0:00:16.447213
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 17:03:02.686340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1118.54
 ---- batch: 020 ----
mean loss: 1105.58
 ---- batch: 030 ----
mean loss: 1062.60
train mean loss: 1085.43
epoch train time: 0:00:00.177643
elapsed time: 0:00:16.625009
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 17:03:02.864172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1032.85
 ---- batch: 020 ----
mean loss: 1049.06
 ---- batch: 030 ----
mean loss: 1018.91
train mean loss: 1027.04
epoch train time: 0:00:00.175715
elapsed time: 0:00:16.800901
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 17:03:03.040027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 992.65
 ---- batch: 020 ----
mean loss: 979.07
 ---- batch: 030 ----
mean loss: 935.75
train mean loss: 969.03
epoch train time: 0:00:00.174287
elapsed time: 0:00:16.975324
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 17:03:03.214461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 936.54
 ---- batch: 020 ----
mean loss: 917.26
 ---- batch: 030 ----
mean loss: 887.39
train mean loss: 909.79
epoch train time: 0:00:00.184487
elapsed time: 0:00:17.159962
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 17:03:03.399089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 863.16
 ---- batch: 020 ----
mean loss: 880.54
 ---- batch: 030 ----
mean loss: 838.54
train mean loss: 854.17
epoch train time: 0:00:00.177510
elapsed time: 0:00:17.337610
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 17:03:03.576737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 816.68
 ---- batch: 020 ----
mean loss: 803.52
 ---- batch: 030 ----
mean loss: 790.40
train mean loss: 801.87
epoch train time: 0:00:00.176557
elapsed time: 0:00:17.514305
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 17:03:03.753445
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 766.28
 ---- batch: 020 ----
mean loss: 740.59
 ---- batch: 030 ----
mean loss: 766.25
train mean loss: 753.55
epoch train time: 0:00:00.179391
elapsed time: 0:00:17.693861
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 17:03:03.932997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 723.01
 ---- batch: 020 ----
mean loss: 716.52
 ---- batch: 030 ----
mean loss: 695.17
train mean loss: 706.68
epoch train time: 0:00:00.180558
elapsed time: 0:00:17.874595
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 17:03:04.113725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 683.52
 ---- batch: 020 ----
mean loss: 662.87
 ---- batch: 030 ----
mean loss: 645.89
train mean loss: 665.46
epoch train time: 0:00:00.177004
elapsed time: 0:00:18.051768
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 17:03:04.290893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 641.51
 ---- batch: 020 ----
mean loss: 643.70
 ---- batch: 030 ----
mean loss: 611.01
train mean loss: 626.70
epoch train time: 0:00:00.175386
elapsed time: 0:00:18.227305
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 17:03:04.466432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 597.04
 ---- batch: 020 ----
mean loss: 596.25
 ---- batch: 030 ----
mean loss: 584.46
train mean loss: 590.32
epoch train time: 0:00:00.176092
elapsed time: 0:00:18.403536
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 17:03:04.642664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 562.86
 ---- batch: 020 ----
mean loss: 555.03
 ---- batch: 030 ----
mean loss: 562.66
train mean loss: 557.35
epoch train time: 0:00:00.176244
elapsed time: 0:00:18.579938
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 17:03:04.819065
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 537.12
 ---- batch: 020 ----
mean loss: 526.25
 ---- batch: 030 ----
mean loss: 517.25
train mean loss: 524.57
epoch train time: 0:00:00.178592
elapsed time: 0:00:18.758682
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 17:03:04.997811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 505.24
 ---- batch: 020 ----
mean loss: 492.97
 ---- batch: 030 ----
mean loss: 490.86
train mean loss: 494.97
epoch train time: 0:00:00.173068
elapsed time: 0:00:18.931899
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 17:03:05.171046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 485.31
 ---- batch: 020 ----
mean loss: 470.77
 ---- batch: 030 ----
mean loss: 458.66
train mean loss: 467.15
epoch train time: 0:00:00.173964
elapsed time: 0:00:19.106021
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 17:03:05.345146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 450.63
 ---- batch: 020 ----
mean loss: 435.26
 ---- batch: 030 ----
mean loss: 438.73
train mean loss: 440.77
epoch train time: 0:00:00.176235
elapsed time: 0:00:19.282391
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 17:03:05.521519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 429.37
 ---- batch: 020 ----
mean loss: 405.26
 ---- batch: 030 ----
mean loss: 414.40
train mean loss: 416.73
epoch train time: 0:00:00.174501
elapsed time: 0:00:19.457031
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 17:03:05.696160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 397.03
 ---- batch: 020 ----
mean loss: 389.66
 ---- batch: 030 ----
mean loss: 399.31
train mean loss: 393.42
epoch train time: 0:00:00.190221
elapsed time: 0:00:19.647391
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 17:03:05.886521
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 388.82
 ---- batch: 020 ----
mean loss: 373.41
 ---- batch: 030 ----
mean loss: 357.09
train mean loss: 372.16
epoch train time: 0:00:00.175262
elapsed time: 0:00:19.822811
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 17:03:06.061939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 353.96
 ---- batch: 020 ----
mean loss: 356.59
 ---- batch: 030 ----
mean loss: 348.24
train mean loss: 352.41
epoch train time: 0:00:00.172729
elapsed time: 0:00:19.995678
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 17:03:06.234807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 340.66
 ---- batch: 020 ----
mean loss: 329.76
 ---- batch: 030 ----
mean loss: 332.35
train mean loss: 333.47
epoch train time: 0:00:00.173729
elapsed time: 0:00:20.169546
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 17:03:06.408673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.58
 ---- batch: 020 ----
mean loss: 310.25
 ---- batch: 030 ----
mean loss: 311.75
train mean loss: 316.11
epoch train time: 0:00:00.174144
elapsed time: 0:00:20.343834
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 17:03:06.582964
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.70
 ---- batch: 020 ----
mean loss: 306.89
 ---- batch: 030 ----
mean loss: 297.01
train mean loss: 299.25
epoch train time: 0:00:00.175511
elapsed time: 0:00:20.519501
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 17:03:06.758631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.62
 ---- batch: 020 ----
mean loss: 285.58
 ---- batch: 030 ----
mean loss: 287.05
train mean loss: 284.21
epoch train time: 0:00:00.177648
elapsed time: 0:00:20.697291
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 17:03:06.936419
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.49
 ---- batch: 020 ----
mean loss: 269.77
 ---- batch: 030 ----
mean loss: 269.76
train mean loss: 270.41
epoch train time: 0:00:00.178036
elapsed time: 0:00:20.875518
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 17:03:07.114650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.80
 ---- batch: 020 ----
mean loss: 260.70
 ---- batch: 030 ----
mean loss: 251.70
train mean loss: 256.99
epoch train time: 0:00:00.178387
elapsed time: 0:00:21.054059
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 17:03:07.293185
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.88
 ---- batch: 020 ----
mean loss: 240.49
 ---- batch: 030 ----
mean loss: 245.52
train mean loss: 244.53
epoch train time: 0:00:00.177920
elapsed time: 0:00:21.232117
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 17:03:07.471244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.76
 ---- batch: 020 ----
mean loss: 234.55
 ---- batch: 030 ----
mean loss: 228.45
train mean loss: 233.14
epoch train time: 0:00:00.173125
elapsed time: 0:00:21.405380
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 17:03:07.644534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.09
 ---- batch: 020 ----
mean loss: 219.51
 ---- batch: 030 ----
mean loss: 220.30
train mean loss: 221.84
epoch train time: 0:00:00.173517
elapsed time: 0:00:21.579062
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 17:03:07.818188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.92
 ---- batch: 020 ----
mean loss: 217.12
 ---- batch: 030 ----
mean loss: 208.84
train mean loss: 212.11
epoch train time: 0:00:00.179806
elapsed time: 0:00:21.759015
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 17:03:07.998141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.28
 ---- batch: 020 ----
mean loss: 199.42
 ---- batch: 030 ----
mean loss: 202.92
train mean loss: 202.89
epoch train time: 0:00:00.168541
elapsed time: 0:00:21.927693
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 17:03:08.166819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.33
 ---- batch: 020 ----
mean loss: 195.87
 ---- batch: 030 ----
mean loss: 188.96
train mean loss: 194.46
epoch train time: 0:00:00.164442
elapsed time: 0:00:22.092272
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 17:03:08.331397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.93
 ---- batch: 020 ----
mean loss: 191.27
 ---- batch: 030 ----
mean loss: 182.94
train mean loss: 186.45
epoch train time: 0:00:00.169408
elapsed time: 0:00:22.261838
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 17:03:08.500965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.67
 ---- batch: 020 ----
mean loss: 176.60
 ---- batch: 030 ----
mean loss: 181.48
train mean loss: 178.89
epoch train time: 0:00:00.168851
elapsed time: 0:00:22.430828
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 17:03:08.669955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.59
 ---- batch: 020 ----
mean loss: 173.13
 ---- batch: 030 ----
mean loss: 172.33
train mean loss: 172.08
epoch train time: 0:00:00.174869
elapsed time: 0:00:22.605837
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 17:03:08.844967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.12
 ---- batch: 020 ----
mean loss: 164.64
 ---- batch: 030 ----
mean loss: 162.47
train mean loss: 165.29
epoch train time: 0:00:00.170266
elapsed time: 0:00:22.776243
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 17:03:09.015399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.20
 ---- batch: 020 ----
mean loss: 159.29
 ---- batch: 030 ----
mean loss: 159.03
train mean loss: 159.79
epoch train time: 0:00:00.168808
elapsed time: 0:00:22.945237
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 17:03:09.184362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.73
 ---- batch: 020 ----
mean loss: 153.12
 ---- batch: 030 ----
mean loss: 157.20
train mean loss: 154.19
epoch train time: 0:00:00.163434
elapsed time: 0:00:23.108804
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 17:03:09.347938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.47
 ---- batch: 020 ----
mean loss: 149.95
 ---- batch: 030 ----
mean loss: 145.25
train mean loss: 148.75
epoch train time: 0:00:00.165052
elapsed time: 0:00:23.273999
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 17:03:09.513124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.80
 ---- batch: 020 ----
mean loss: 145.48
 ---- batch: 030 ----
mean loss: 144.10
train mean loss: 143.67
epoch train time: 0:00:00.167204
elapsed time: 0:00:23.441344
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 17:03:09.680469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.30
 ---- batch: 020 ----
mean loss: 138.56
 ---- batch: 030 ----
mean loss: 138.93
train mean loss: 139.27
epoch train time: 0:00:00.169033
elapsed time: 0:00:23.610515
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 17:03:09.849685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.08
 ---- batch: 020 ----
mean loss: 135.12
 ---- batch: 030 ----
mean loss: 136.56
train mean loss: 135.10
epoch train time: 0:00:00.170554
elapsed time: 0:00:23.781252
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 17:03:10.020416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.01
 ---- batch: 020 ----
mean loss: 132.53
 ---- batch: 030 ----
mean loss: 129.10
train mean loss: 130.94
epoch train time: 0:00:00.170337
elapsed time: 0:00:23.951765
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 17:03:10.190899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.19
 ---- batch: 020 ----
mean loss: 127.09
 ---- batch: 030 ----
mean loss: 127.94
train mean loss: 127.75
epoch train time: 0:00:00.168598
elapsed time: 0:00:24.120512
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 17:03:10.359650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.17
 ---- batch: 020 ----
mean loss: 122.66
 ---- batch: 030 ----
mean loss: 119.74
train mean loss: 123.85
epoch train time: 0:00:00.170246
elapsed time: 0:00:24.290915
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 17:03:10.530042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.63
 ---- batch: 020 ----
mean loss: 118.78
 ---- batch: 030 ----
mean loss: 121.08
train mean loss: 120.69
epoch train time: 0:00:00.176768
elapsed time: 0:00:24.467848
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 17:03:10.706976
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.37
 ---- batch: 020 ----
mean loss: 119.12
 ---- batch: 030 ----
mean loss: 117.05
train mean loss: 117.69
epoch train time: 0:00:00.168867
elapsed time: 0:00:24.636852
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 17:03:10.875979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.17
 ---- batch: 020 ----
mean loss: 114.82
 ---- batch: 030 ----
mean loss: 112.71
train mean loss: 115.02
epoch train time: 0:00:00.168416
elapsed time: 0:00:24.805416
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 17:03:11.044540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.45
 ---- batch: 020 ----
mean loss: 112.43
 ---- batch: 030 ----
mean loss: 113.75
train mean loss: 112.17
epoch train time: 0:00:00.166747
elapsed time: 0:00:24.972298
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 17:03:11.211432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.39
 ---- batch: 020 ----
mean loss: 110.42
 ---- batch: 030 ----
mean loss: 108.88
train mean loss: 109.42
epoch train time: 0:00:00.166454
elapsed time: 0:00:25.138893
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 17:03:11.378033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.70
 ---- batch: 020 ----
mean loss: 108.86
 ---- batch: 030 ----
mean loss: 106.45
train mean loss: 107.15
epoch train time: 0:00:00.165979
elapsed time: 0:00:25.305019
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 17:03:11.544143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.14
 ---- batch: 020 ----
mean loss: 104.39
 ---- batch: 030 ----
mean loss: 106.57
train mean loss: 105.03
epoch train time: 0:00:00.168706
elapsed time: 0:00:25.473893
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 17:03:11.713019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.16
 ---- batch: 020 ----
mean loss: 102.17
 ---- batch: 030 ----
mean loss: 98.59
train mean loss: 102.86
epoch train time: 0:00:00.173454
elapsed time: 0:00:25.647487
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 17:03:11.886613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.51
 ---- batch: 020 ----
mean loss: 99.45
 ---- batch: 030 ----
mean loss: 101.59
train mean loss: 100.49
epoch train time: 0:00:00.167266
elapsed time: 0:00:25.814934
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 17:03:12.054056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.35
 ---- batch: 020 ----
mean loss: 97.38
 ---- batch: 030 ----
mean loss: 101.60
train mean loss: 99.10
epoch train time: 0:00:00.168629
elapsed time: 0:00:25.983692
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 17:03:12.222836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.01
 ---- batch: 020 ----
mean loss: 98.37
 ---- batch: 030 ----
mean loss: 98.08
train mean loss: 97.26
epoch train time: 0:00:00.165931
elapsed time: 0:00:26.149772
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 17:03:12.388893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.79
 ---- batch: 020 ----
mean loss: 93.39
 ---- batch: 030 ----
mean loss: 93.52
train mean loss: 95.14
epoch train time: 0:00:00.173692
elapsed time: 0:00:26.323611
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 17:03:12.562751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.40
 ---- batch: 020 ----
mean loss: 95.03
 ---- batch: 030 ----
mean loss: 94.86
train mean loss: 93.74
epoch train time: 0:00:00.169729
elapsed time: 0:00:26.493489
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 17:03:12.732614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.77
 ---- batch: 020 ----
mean loss: 94.23
 ---- batch: 030 ----
mean loss: 89.29
train mean loss: 92.01
epoch train time: 0:00:00.170618
elapsed time: 0:00:26.664242
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 17:03:12.903368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.39
 ---- batch: 020 ----
mean loss: 88.84
 ---- batch: 030 ----
mean loss: 91.38
train mean loss: 90.60
epoch train time: 0:00:00.173893
elapsed time: 0:00:26.838272
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 17:03:13.077410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.95
 ---- batch: 020 ----
mean loss: 92.65
 ---- batch: 030 ----
mean loss: 89.54
train mean loss: 89.29
epoch train time: 0:00:00.170281
elapsed time: 0:00:27.008714
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 17:03:13.247841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.46
 ---- batch: 020 ----
mean loss: 89.29
 ---- batch: 030 ----
mean loss: 86.68
train mean loss: 87.80
epoch train time: 0:00:00.169413
elapsed time: 0:00:27.178263
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 17:03:13.417390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.17
 ---- batch: 020 ----
mean loss: 85.90
 ---- batch: 030 ----
mean loss: 91.53
train mean loss: 87.57
epoch train time: 0:00:00.167394
elapsed time: 0:00:27.345792
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 17:03:13.584918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.13
 ---- batch: 020 ----
mean loss: 87.36
 ---- batch: 030 ----
mean loss: 82.75
train mean loss: 86.21
epoch train time: 0:00:00.170684
elapsed time: 0:00:27.516613
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 17:03:13.755742
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.86
 ---- batch: 020 ----
mean loss: 81.80
 ---- batch: 030 ----
mean loss: 85.14
train mean loss: 84.80
epoch train time: 0:00:00.171883
elapsed time: 0:00:27.688671
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 17:03:13.927799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.11
 ---- batch: 020 ----
mean loss: 81.35
 ---- batch: 030 ----
mean loss: 85.36
train mean loss: 83.84
epoch train time: 0:00:00.171017
elapsed time: 0:00:27.859827
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 17:03:14.098954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.46
 ---- batch: 020 ----
mean loss: 83.34
 ---- batch: 030 ----
mean loss: 82.75
train mean loss: 82.79
epoch train time: 0:00:00.169267
elapsed time: 0:00:28.029230
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 17:03:14.268358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.84
 ---- batch: 020 ----
mean loss: 83.26
 ---- batch: 030 ----
mean loss: 81.95
train mean loss: 81.85
epoch train time: 0:00:00.170167
elapsed time: 0:00:28.199535
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 17:03:14.438679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.71
 ---- batch: 020 ----
mean loss: 80.69
 ---- batch: 030 ----
mean loss: 82.98
train mean loss: 82.18
epoch train time: 0:00:00.174201
elapsed time: 0:00:28.373901
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 17:03:14.613029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.59
 ---- batch: 020 ----
mean loss: 79.77
 ---- batch: 030 ----
mean loss: 81.33
train mean loss: 80.20
epoch train time: 0:00:00.169347
elapsed time: 0:00:28.543393
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 17:03:14.782523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.70
 ---- batch: 020 ----
mean loss: 79.45
 ---- batch: 030 ----
mean loss: 80.55
train mean loss: 80.02
epoch train time: 0:00:00.170757
elapsed time: 0:00:28.714291
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 17:03:14.953431
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.58
 ---- batch: 020 ----
mean loss: 76.67
 ---- batch: 030 ----
mean loss: 81.37
train mean loss: 79.08
epoch train time: 0:00:00.173879
elapsed time: 0:00:28.888366
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 17:03:15.127508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.97
 ---- batch: 020 ----
mean loss: 78.47
 ---- batch: 030 ----
mean loss: 80.19
train mean loss: 78.12
epoch train time: 0:00:00.171501
elapsed time: 0:00:29.060020
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 17:03:15.299146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.38
 ---- batch: 020 ----
mean loss: 79.18
 ---- batch: 030 ----
mean loss: 78.62
train mean loss: 78.49
epoch train time: 0:00:00.170953
elapsed time: 0:00:29.231112
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 17:03:15.470239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.54
 ---- batch: 020 ----
mean loss: 77.25
 ---- batch: 030 ----
mean loss: 76.02
train mean loss: 77.24
epoch train time: 0:00:00.168880
elapsed time: 0:00:29.400129
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 17:03:15.639255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.47
 ---- batch: 020 ----
mean loss: 76.96
 ---- batch: 030 ----
mean loss: 73.95
train mean loss: 76.69
epoch train time: 0:00:00.170987
elapsed time: 0:00:29.571254
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 17:03:15.810388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.42
 ---- batch: 020 ----
mean loss: 75.95
 ---- batch: 030 ----
mean loss: 73.03
train mean loss: 76.09
epoch train time: 0:00:00.172755
elapsed time: 0:00:29.744167
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 17:03:15.983310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.07
 ---- batch: 020 ----
mean loss: 74.89
 ---- batch: 030 ----
mean loss: 74.16
train mean loss: 75.79
epoch train time: 0:00:00.171382
elapsed time: 0:00:29.915717
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 17:03:16.154843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.27
 ---- batch: 020 ----
mean loss: 77.61
 ---- batch: 030 ----
mean loss: 74.30
train mean loss: 75.28
epoch train time: 0:00:00.172407
elapsed time: 0:00:30.088282
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 17:03:16.327401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.31
 ---- batch: 020 ----
mean loss: 75.45
 ---- batch: 030 ----
mean loss: 73.96
train mean loss: 74.84
epoch train time: 0:00:00.169796
elapsed time: 0:00:30.258207
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 17:03:16.497334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.13
 ---- batch: 020 ----
mean loss: 72.37
 ---- batch: 030 ----
mean loss: 72.43
train mean loss: 74.47
epoch train time: 0:00:00.168151
elapsed time: 0:00:30.426509
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 17:03:16.665653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.88
 ---- batch: 020 ----
mean loss: 73.38
 ---- batch: 030 ----
mean loss: 75.70
train mean loss: 73.94
epoch train time: 0:00:00.173753
elapsed time: 0:00:30.600418
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 17:03:16.839565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.64
 ---- batch: 020 ----
mean loss: 74.11
 ---- batch: 030 ----
mean loss: 72.17
train mean loss: 73.42
epoch train time: 0:00:00.170993
elapsed time: 0:00:30.771582
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 17:03:17.010700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.53
 ---- batch: 020 ----
mean loss: 72.96
 ---- batch: 030 ----
mean loss: 74.95
train mean loss: 73.09
epoch train time: 0:00:00.173795
elapsed time: 0:00:30.945534
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 17:03:17.184660
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.72
 ---- batch: 020 ----
mean loss: 73.35
 ---- batch: 030 ----
mean loss: 69.09
train mean loss: 72.67
epoch train time: 0:00:00.173392
elapsed time: 0:00:31.119106
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 17:03:17.358233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.71
 ---- batch: 020 ----
mean loss: 73.00
 ---- batch: 030 ----
mean loss: 73.41
train mean loss: 72.41
epoch train time: 0:00:00.173491
elapsed time: 0:00:31.292732
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 17:03:17.531858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.48
 ---- batch: 020 ----
mean loss: 71.69
 ---- batch: 030 ----
mean loss: 73.38
train mean loss: 71.39
epoch train time: 0:00:00.168321
elapsed time: 0:00:31.461205
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 17:03:17.700330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.89
 ---- batch: 020 ----
mean loss: 71.07
 ---- batch: 030 ----
mean loss: 70.95
train mean loss: 71.75
epoch train time: 0:00:00.175944
elapsed time: 0:00:31.637280
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 17:03:17.876405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.45
 ---- batch: 020 ----
mean loss: 71.69
 ---- batch: 030 ----
mean loss: 71.26
train mean loss: 71.07
epoch train time: 0:00:00.167818
elapsed time: 0:00:31.805247
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 17:03:18.044388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.35
 ---- batch: 020 ----
mean loss: 68.09
 ---- batch: 030 ----
mean loss: 71.89
train mean loss: 70.62
epoch train time: 0:00:00.171186
elapsed time: 0:00:31.976582
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 17:03:18.215707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.25
 ---- batch: 020 ----
mean loss: 68.19
 ---- batch: 030 ----
mean loss: 71.79
train mean loss: 70.17
epoch train time: 0:00:00.167383
elapsed time: 0:00:32.144098
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 17:03:18.383223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.89
 ---- batch: 020 ----
mean loss: 68.49
 ---- batch: 030 ----
mean loss: 72.74
train mean loss: 70.31
epoch train time: 0:00:00.166283
elapsed time: 0:00:32.310514
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 17:03:18.549661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.45
 ---- batch: 020 ----
mean loss: 70.32
 ---- batch: 030 ----
mean loss: 71.73
train mean loss: 70.74
epoch train time: 0:00:00.167723
elapsed time: 0:00:32.478394
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 17:03:18.717539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.14
 ---- batch: 020 ----
mean loss: 70.43
 ---- batch: 030 ----
mean loss: 71.51
train mean loss: 70.42
epoch train time: 0:00:00.172363
elapsed time: 0:00:32.650915
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 17:03:18.890044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.81
 ---- batch: 020 ----
mean loss: 68.02
 ---- batch: 030 ----
mean loss: 70.57
train mean loss: 69.41
epoch train time: 0:00:00.165429
elapsed time: 0:00:32.816484
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 17:03:19.055624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.13
 ---- batch: 020 ----
mean loss: 69.79
 ---- batch: 030 ----
mean loss: 71.18
train mean loss: 69.94
epoch train time: 0:00:00.167889
elapsed time: 0:00:32.984531
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 17:03:19.223701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.64
 ---- batch: 020 ----
mean loss: 69.27
 ---- batch: 030 ----
mean loss: 68.00
train mean loss: 69.34
epoch train time: 0:00:00.166538
elapsed time: 0:00:33.151248
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 17:03:19.390374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.49
 ---- batch: 020 ----
mean loss: 67.59
 ---- batch: 030 ----
mean loss: 69.80
train mean loss: 67.96
epoch train time: 0:00:00.168252
elapsed time: 0:00:33.319672
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 17:03:19.558796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.76
 ---- batch: 020 ----
mean loss: 68.81
 ---- batch: 030 ----
mean loss: 68.04
train mean loss: 67.93
epoch train time: 0:00:00.172219
elapsed time: 0:00:33.492027
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 17:03:19.731155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.52
 ---- batch: 020 ----
mean loss: 67.63
 ---- batch: 030 ----
mean loss: 67.77
train mean loss: 67.45
epoch train time: 0:00:00.171029
elapsed time: 0:00:33.663196
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 17:03:19.902322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.32
 ---- batch: 020 ----
mean loss: 65.39
 ---- batch: 030 ----
mean loss: 68.56
train mean loss: 67.91
epoch train time: 0:00:00.167347
elapsed time: 0:00:33.830680
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 17:03:20.069808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.33
 ---- batch: 020 ----
mean loss: 65.20
 ---- batch: 030 ----
mean loss: 65.54
train mean loss: 67.32
epoch train time: 0:00:00.170409
elapsed time: 0:00:34.001235
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 17:03:20.240365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.74
 ---- batch: 020 ----
mean loss: 67.57
 ---- batch: 030 ----
mean loss: 68.06
train mean loss: 67.58
epoch train time: 0:00:00.177787
elapsed time: 0:00:34.179193
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 17:03:20.418310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.01
 ---- batch: 020 ----
mean loss: 67.34
 ---- batch: 030 ----
mean loss: 67.86
train mean loss: 67.32
epoch train time: 0:00:00.169179
elapsed time: 0:00:34.348509
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 17:03:20.587642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.97
 ---- batch: 020 ----
mean loss: 67.20
 ---- batch: 030 ----
mean loss: 65.75
train mean loss: 66.47
epoch train time: 0:00:00.169253
elapsed time: 0:00:34.517908
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 17:03:20.757037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.54
 ---- batch: 020 ----
mean loss: 67.93
 ---- batch: 030 ----
mean loss: 64.35
train mean loss: 66.35
epoch train time: 0:00:00.172420
elapsed time: 0:00:34.690498
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 17:03:20.929657
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.07
 ---- batch: 020 ----
mean loss: 66.78
 ---- batch: 030 ----
mean loss: 64.59
train mean loss: 66.47
epoch train time: 0:00:00.176899
elapsed time: 0:00:34.867572
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 17:03:21.106701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.31
 ---- batch: 020 ----
mean loss: 65.96
 ---- batch: 030 ----
mean loss: 65.95
train mean loss: 65.73
epoch train time: 0:00:00.176262
elapsed time: 0:00:35.043975
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 17:03:21.283103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.61
 ---- batch: 020 ----
mean loss: 67.89
 ---- batch: 030 ----
mean loss: 63.56
train mean loss: 65.69
epoch train time: 0:00:00.170892
elapsed time: 0:00:35.215006
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 17:03:21.454161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.23
 ---- batch: 020 ----
mean loss: 66.41
 ---- batch: 030 ----
mean loss: 66.61
train mean loss: 66.00
epoch train time: 0:00:00.170293
elapsed time: 0:00:35.385465
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 17:03:21.624593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.31
 ---- batch: 020 ----
mean loss: 65.89
 ---- batch: 030 ----
mean loss: 64.76
train mean loss: 65.36
epoch train time: 0:00:00.174840
elapsed time: 0:00:35.560444
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 17:03:21.799571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.53
 ---- batch: 020 ----
mean loss: 63.97
 ---- batch: 030 ----
mean loss: 65.95
train mean loss: 65.21
epoch train time: 0:00:00.169041
elapsed time: 0:00:35.729617
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 17:03:21.968742
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.61
 ---- batch: 020 ----
mean loss: 66.25
 ---- batch: 030 ----
mean loss: 63.33
train mean loss: 65.26
epoch train time: 0:00:00.166864
elapsed time: 0:00:35.896616
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 17:03:22.135743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.67
 ---- batch: 020 ----
mean loss: 66.69
 ---- batch: 030 ----
mean loss: 62.26
train mean loss: 64.91
epoch train time: 0:00:00.178938
elapsed time: 0:00:36.075691
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 17:03:22.314848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.60
 ---- batch: 020 ----
mean loss: 67.90
 ---- batch: 030 ----
mean loss: 65.29
train mean loss: 65.99
epoch train time: 0:00:00.169402
elapsed time: 0:00:36.245259
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 17:03:22.484384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.23
 ---- batch: 020 ----
mean loss: 66.15
 ---- batch: 030 ----
mean loss: 64.73
train mean loss: 64.69
epoch train time: 0:00:00.168600
elapsed time: 0:00:36.413992
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 17:03:22.653119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.92
 ---- batch: 020 ----
mean loss: 66.25
 ---- batch: 030 ----
mean loss: 67.12
train mean loss: 65.58
epoch train time: 0:00:00.169783
elapsed time: 0:00:36.583920
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 17:03:22.823050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.76
 ---- batch: 020 ----
mean loss: 65.56
 ---- batch: 030 ----
mean loss: 65.89
train mean loss: 65.12
epoch train time: 0:00:00.172634
elapsed time: 0:00:36.756693
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 17:03:22.995819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.50
 ---- batch: 020 ----
mean loss: 64.67
 ---- batch: 030 ----
mean loss: 65.45
train mean loss: 64.23
epoch train time: 0:00:00.169968
elapsed time: 0:00:36.926799
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 17:03:23.165936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.54
 ---- batch: 020 ----
mean loss: 63.51
 ---- batch: 030 ----
mean loss: 64.70
train mean loss: 63.79
epoch train time: 0:00:00.174187
elapsed time: 0:00:37.101134
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 17:03:23.340277
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.46
 ---- batch: 020 ----
mean loss: 62.65
 ---- batch: 030 ----
mean loss: 64.11
train mean loss: 63.47
epoch train time: 0:00:00.169841
elapsed time: 0:00:37.271132
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 17:03:23.510258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.11
 ---- batch: 020 ----
mean loss: 64.41
 ---- batch: 030 ----
mean loss: 61.26
train mean loss: 63.64
epoch train time: 0:00:00.168960
elapsed time: 0:00:37.440227
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 17:03:23.679353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.91
 ---- batch: 020 ----
mean loss: 65.93
 ---- batch: 030 ----
mean loss: 61.64
train mean loss: 63.64
epoch train time: 0:00:00.175705
elapsed time: 0:00:37.616102
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 17:03:23.855253
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.47
 ---- batch: 020 ----
mean loss: 62.87
 ---- batch: 030 ----
mean loss: 64.03
train mean loss: 63.06
epoch train time: 0:00:00.168553
elapsed time: 0:00:37.784815
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 17:03:24.023942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.60
 ---- batch: 020 ----
mean loss: 64.35
 ---- batch: 030 ----
mean loss: 62.84
train mean loss: 63.39
epoch train time: 0:00:00.166744
elapsed time: 0:00:37.951704
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 17:03:24.190819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.98
 ---- batch: 020 ----
mean loss: 64.16
 ---- batch: 030 ----
mean loss: 61.88
train mean loss: 63.79
epoch train time: 0:00:00.170240
elapsed time: 0:00:38.122082
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 17:03:24.361208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.55
 ---- batch: 020 ----
mean loss: 62.88
 ---- batch: 030 ----
mean loss: 63.05
train mean loss: 62.77
epoch train time: 0:00:00.168272
elapsed time: 0:00:38.290547
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 17:03:24.529669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.52
 ---- batch: 020 ----
mean loss: 63.13
 ---- batch: 030 ----
mean loss: 66.49
train mean loss: 63.39
epoch train time: 0:00:00.168910
elapsed time: 0:00:38.459599
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 17:03:24.698719
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.45
 ---- batch: 020 ----
mean loss: 63.88
 ---- batch: 030 ----
mean loss: 60.58
train mean loss: 62.48
epoch train time: 0:00:00.174140
elapsed time: 0:00:38.633885
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 17:03:24.873006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.16
 ---- batch: 020 ----
mean loss: 62.64
 ---- batch: 030 ----
mean loss: 64.31
train mean loss: 62.81
epoch train time: 0:00:00.167144
elapsed time: 0:00:38.801160
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 17:03:25.040286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.50
 ---- batch: 020 ----
mean loss: 65.12
 ---- batch: 030 ----
mean loss: 62.87
train mean loss: 63.23
epoch train time: 0:00:00.167953
elapsed time: 0:00:38.969247
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 17:03:25.208373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.01
 ---- batch: 020 ----
mean loss: 61.60
 ---- batch: 030 ----
mean loss: 64.42
train mean loss: 61.87
epoch train time: 0:00:00.171649
elapsed time: 0:00:39.141044
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 17:03:25.380168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.21
 ---- batch: 020 ----
mean loss: 59.62
 ---- batch: 030 ----
mean loss: 62.19
train mean loss: 61.65
epoch train time: 0:00:00.167804
elapsed time: 0:00:39.308980
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 17:03:25.548104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.23
 ---- batch: 020 ----
mean loss: 62.19
 ---- batch: 030 ----
mean loss: 63.38
train mean loss: 63.20
epoch train time: 0:00:00.163801
elapsed time: 0:00:39.472928
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 17:03:25.712070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.35
 ---- batch: 020 ----
mean loss: 63.45
 ---- batch: 030 ----
mean loss: 60.45
train mean loss: 61.38
epoch train time: 0:00:00.170255
elapsed time: 0:00:39.643341
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 17:03:25.882476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.68
 ---- batch: 020 ----
mean loss: 58.98
 ---- batch: 030 ----
mean loss: 60.18
train mean loss: 60.85
epoch train time: 0:00:00.171362
elapsed time: 0:00:39.814851
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 17:03:26.053978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.73
 ---- batch: 020 ----
mean loss: 59.34
 ---- batch: 030 ----
mean loss: 62.24
train mean loss: 60.97
epoch train time: 0:00:00.168465
elapsed time: 0:00:39.983483
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 17:03:26.222627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.69
 ---- batch: 020 ----
mean loss: 60.04
 ---- batch: 030 ----
mean loss: 59.99
train mean loss: 61.48
epoch train time: 0:00:00.170127
elapsed time: 0:00:40.153809
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 17:03:26.392950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.68
 ---- batch: 020 ----
mean loss: 61.44
 ---- batch: 030 ----
mean loss: 60.69
train mean loss: 60.45
epoch train time: 0:00:00.170679
elapsed time: 0:00:40.324634
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 17:03:26.563758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.36
 ---- batch: 020 ----
mean loss: 60.90
 ---- batch: 030 ----
mean loss: 60.08
train mean loss: 60.30
epoch train time: 0:00:00.167813
elapsed time: 0:00:40.492581
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 17:03:26.731708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.29
 ---- batch: 020 ----
mean loss: 59.06
 ---- batch: 030 ----
mean loss: 58.92
train mean loss: 59.90
epoch train time: 0:00:00.171830
elapsed time: 0:00:40.664548
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 17:03:26.903675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.15
 ---- batch: 020 ----
mean loss: 57.39
 ---- batch: 030 ----
mean loss: 61.59
train mean loss: 59.68
epoch train time: 0:00:00.168322
elapsed time: 0:00:40.833005
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 17:03:27.072131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.32
 ---- batch: 020 ----
mean loss: 58.13
 ---- batch: 030 ----
mean loss: 59.26
train mean loss: 59.29
epoch train time: 0:00:00.165884
elapsed time: 0:00:40.999024
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 17:03:27.238149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.79
 ---- batch: 020 ----
mean loss: 57.83
 ---- batch: 030 ----
mean loss: 61.56
train mean loss: 59.99
epoch train time: 0:00:00.168000
elapsed time: 0:00:41.167160
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 17:03:27.406285
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.28
 ---- batch: 020 ----
mean loss: 56.93
 ---- batch: 030 ----
mean loss: 58.52
train mean loss: 59.30
epoch train time: 0:00:00.167113
elapsed time: 0:00:41.334406
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 17:03:27.573529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.88
 ---- batch: 020 ----
mean loss: 61.34
 ---- batch: 030 ----
mean loss: 57.88
train mean loss: 58.86
epoch train time: 0:00:00.163172
elapsed time: 0:00:41.497713
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 17:03:27.736841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.28
 ---- batch: 020 ----
mean loss: 60.04
 ---- batch: 030 ----
mean loss: 58.00
train mean loss: 58.83
epoch train time: 0:00:00.171847
elapsed time: 0:00:41.669707
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 17:03:27.908834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.72
 ---- batch: 020 ----
mean loss: 59.35
 ---- batch: 030 ----
mean loss: 57.60
train mean loss: 59.50
epoch train time: 0:00:00.169202
elapsed time: 0:00:41.839047
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 17:03:28.078189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.74
 ---- batch: 020 ----
mean loss: 56.12
 ---- batch: 030 ----
mean loss: 58.91
train mean loss: 58.52
epoch train time: 0:00:00.163915
elapsed time: 0:00:42.003108
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 17:03:28.242233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.31
 ---- batch: 020 ----
mean loss: 59.08
 ---- batch: 030 ----
mean loss: 60.63
train mean loss: 59.10
epoch train time: 0:00:00.164008
elapsed time: 0:00:42.167302
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 17:03:28.406435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.92
 ---- batch: 020 ----
mean loss: 59.98
 ---- batch: 030 ----
mean loss: 59.34
train mean loss: 58.31
epoch train time: 0:00:00.166561
elapsed time: 0:00:42.334028
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 17:03:28.573173
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.50
 ---- batch: 020 ----
mean loss: 55.41
 ---- batch: 030 ----
mean loss: 59.99
train mean loss: 58.50
epoch train time: 0:00:00.163838
elapsed time: 0:00:42.498019
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 17:03:28.737145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.17
 ---- batch: 020 ----
mean loss: 56.60
 ---- batch: 030 ----
mean loss: 59.62
train mean loss: 58.05
epoch train time: 0:00:00.178225
elapsed time: 0:00:42.676400
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 17:03:28.915530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.97
 ---- batch: 020 ----
mean loss: 58.12
 ---- batch: 030 ----
mean loss: 59.41
train mean loss: 58.37
epoch train time: 0:00:00.170105
elapsed time: 0:00:42.846648
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 17:03:29.085789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.28
 ---- batch: 020 ----
mean loss: 57.31
 ---- batch: 030 ----
mean loss: 56.93
train mean loss: 57.12
epoch train time: 0:00:00.169198
elapsed time: 0:00:43.015999
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 17:03:29.255141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.38
 ---- batch: 020 ----
mean loss: 57.05
 ---- batch: 030 ----
mean loss: 57.29
train mean loss: 57.88
epoch train time: 0:00:00.172904
elapsed time: 0:00:43.189065
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 17:03:29.428199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.23
 ---- batch: 020 ----
mean loss: 57.57
 ---- batch: 030 ----
mean loss: 57.19
train mean loss: 56.52
epoch train time: 0:00:00.174567
elapsed time: 0:00:43.363773
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 17:03:29.602911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.47
 ---- batch: 020 ----
mean loss: 58.76
 ---- batch: 030 ----
mean loss: 58.07
train mean loss: 57.12
epoch train time: 0:00:00.169189
elapsed time: 0:00:43.533146
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 17:03:29.772272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.10
 ---- batch: 020 ----
mean loss: 59.34
 ---- batch: 030 ----
mean loss: 55.60
train mean loss: 56.12
epoch train time: 0:00:00.172270
elapsed time: 0:00:43.705551
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 17:03:29.944677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.60
 ---- batch: 020 ----
mean loss: 55.94
 ---- batch: 030 ----
mean loss: 57.93
train mean loss: 56.35
epoch train time: 0:00:00.171048
elapsed time: 0:00:43.876733
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 17:03:30.115859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.54
 ---- batch: 020 ----
mean loss: 57.14
 ---- batch: 030 ----
mean loss: 56.20
train mean loss: 56.35
epoch train time: 0:00:00.169904
elapsed time: 0:00:44.046771
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 17:03:30.285952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.87
 ---- batch: 020 ----
mean loss: 55.04
 ---- batch: 030 ----
mean loss: 55.85
train mean loss: 56.23
epoch train time: 0:00:00.169605
elapsed time: 0:00:44.216568
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 17:03:30.455696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.60
 ---- batch: 020 ----
mean loss: 57.00
 ---- batch: 030 ----
mean loss: 55.87
train mean loss: 56.71
epoch train time: 0:00:00.171410
elapsed time: 0:00:44.388113
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 17:03:30.627238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.98
 ---- batch: 020 ----
mean loss: 57.31
 ---- batch: 030 ----
mean loss: 59.37
train mean loss: 56.85
epoch train time: 0:00:00.170000
elapsed time: 0:00:44.558247
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 17:03:30.797392
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.01
 ---- batch: 020 ----
mean loss: 55.26
 ---- batch: 030 ----
mean loss: 55.08
train mean loss: 55.37
epoch train time: 0:00:00.171358
elapsed time: 0:00:44.729760
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 17:03:30.968888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.49
 ---- batch: 020 ----
mean loss: 53.93
 ---- batch: 030 ----
mean loss: 55.72
train mean loss: 54.95
epoch train time: 0:00:00.168348
elapsed time: 0:00:44.898248
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 17:03:31.137378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.27
 ---- batch: 020 ----
mean loss: 54.25
 ---- batch: 030 ----
mean loss: 54.66
train mean loss: 54.75
epoch train time: 0:00:00.166426
elapsed time: 0:00:45.064810
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 17:03:31.303948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.51
 ---- batch: 020 ----
mean loss: 53.77
 ---- batch: 030 ----
mean loss: 54.41
train mean loss: 54.66
epoch train time: 0:00:00.167131
elapsed time: 0:00:45.232101
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 17:03:31.471230
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.13
 ---- batch: 020 ----
mean loss: 53.07
 ---- batch: 030 ----
mean loss: 57.59
train mean loss: 54.87
epoch train time: 0:00:00.169870
elapsed time: 0:00:45.402130
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 17:03:31.641250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.95
 ---- batch: 020 ----
mean loss: 56.46
 ---- batch: 030 ----
mean loss: 53.93
train mean loss: 54.92
epoch train time: 0:00:00.167917
elapsed time: 0:00:45.570206
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 17:03:31.809334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.51
 ---- batch: 020 ----
mean loss: 54.10
 ---- batch: 030 ----
mean loss: 54.83
train mean loss: 54.52
epoch train time: 0:00:00.170863
elapsed time: 0:00:45.741216
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 17:03:31.980338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.30
 ---- batch: 020 ----
mean loss: 56.21
 ---- batch: 030 ----
mean loss: 54.14
train mean loss: 54.74
epoch train time: 0:00:00.168478
elapsed time: 0:00:45.909840
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 17:03:32.148966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.88
 ---- batch: 020 ----
mean loss: 56.85
 ---- batch: 030 ----
mean loss: 51.30
train mean loss: 53.98
epoch train time: 0:00:00.165890
elapsed time: 0:00:46.075875
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 17:03:32.315004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.32
 ---- batch: 020 ----
mean loss: 55.55
 ---- batch: 030 ----
mean loss: 53.14
train mean loss: 53.90
epoch train time: 0:00:00.165880
elapsed time: 0:00:46.241896
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 17:03:32.481025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.14
 ---- batch: 020 ----
mean loss: 54.13
 ---- batch: 030 ----
mean loss: 52.88
train mean loss: 53.88
epoch train time: 0:00:00.170377
elapsed time: 0:00:46.412412
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 17:03:32.651541
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.13
 ---- batch: 020 ----
mean loss: 50.87
 ---- batch: 030 ----
mean loss: 54.86
train mean loss: 53.93
epoch train time: 0:00:00.172697
elapsed time: 0:00:46.585249
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 17:03:32.824378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.55
 ---- batch: 020 ----
mean loss: 54.18
 ---- batch: 030 ----
mean loss: 57.24
train mean loss: 55.12
epoch train time: 0:00:00.172192
elapsed time: 0:00:46.757581
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 17:03:32.996714
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.14
 ---- batch: 020 ----
mean loss: 54.15
 ---- batch: 030 ----
mean loss: 54.68
train mean loss: 53.47
epoch train time: 0:00:00.167875
elapsed time: 0:00:46.925613
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 17:03:33.164751
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.05
 ---- batch: 020 ----
mean loss: 52.80
 ---- batch: 030 ----
mean loss: 52.16
train mean loss: 51.96
epoch train time: 0:00:00.167286
elapsed time: 0:00:47.093043
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 17:03:33.332170
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.59
 ---- batch: 020 ----
mean loss: 50.85
 ---- batch: 030 ----
mean loss: 52.50
train mean loss: 52.17
epoch train time: 0:00:00.168737
elapsed time: 0:00:47.261945
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 17:03:33.501076
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.15
 ---- batch: 020 ----
mean loss: 49.69
 ---- batch: 030 ----
mean loss: 52.31
train mean loss: 51.82
epoch train time: 0:00:00.170141
elapsed time: 0:00:47.432226
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 17:03:33.671352
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.36
 ---- batch: 020 ----
mean loss: 53.03
 ---- batch: 030 ----
mean loss: 51.43
train mean loss: 51.93
epoch train time: 0:00:00.189302
elapsed time: 0:00:47.621669
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 17:03:33.860795
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.57
 ---- batch: 020 ----
mean loss: 51.82
 ---- batch: 030 ----
mean loss: 51.93
train mean loss: 51.73
epoch train time: 0:00:00.172138
elapsed time: 0:00:47.793988
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 17:03:34.033116
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.69
 ---- batch: 020 ----
mean loss: 51.60
 ---- batch: 030 ----
mean loss: 51.22
train mean loss: 51.73
epoch train time: 0:00:00.171681
elapsed time: 0:00:47.965806
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 17:03:34.204943
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.91
 ---- batch: 020 ----
mean loss: 50.13
 ---- batch: 030 ----
mean loss: 50.89
train mean loss: 51.80
epoch train time: 0:00:00.172369
elapsed time: 0:00:48.138369
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 17:03:34.377497
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.38
 ---- batch: 020 ----
mean loss: 51.06
 ---- batch: 030 ----
mean loss: 51.11
train mean loss: 51.65
epoch train time: 0:00:00.172132
elapsed time: 0:00:48.310640
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 17:03:34.549768
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.44
 ---- batch: 020 ----
mean loss: 51.99
 ---- batch: 030 ----
mean loss: 52.68
train mean loss: 51.91
epoch train time: 0:00:00.172642
elapsed time: 0:00:48.483419
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 17:03:34.722543
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.43
 ---- batch: 020 ----
mean loss: 49.95
 ---- batch: 030 ----
mean loss: 50.20
train mean loss: 51.61
epoch train time: 0:00:00.183387
elapsed time: 0:00:48.666952
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 17:03:34.906088
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.39
 ---- batch: 020 ----
mean loss: 52.33
 ---- batch: 030 ----
mean loss: 51.94
train mean loss: 51.65
epoch train time: 0:00:00.182199
elapsed time: 0:00:48.849317
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 17:03:35.088445
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.44
 ---- batch: 020 ----
mean loss: 48.75
 ---- batch: 030 ----
mean loss: 52.61
train mean loss: 51.73
epoch train time: 0:00:00.171705
elapsed time: 0:00:49.021164
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 17:03:35.260290
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.12
 ---- batch: 020 ----
mean loss: 52.82
 ---- batch: 030 ----
mean loss: 50.47
train mean loss: 51.72
epoch train time: 0:00:00.171536
elapsed time: 0:00:49.192854
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 17:03:35.431981
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.51
 ---- batch: 020 ----
mean loss: 50.67
 ---- batch: 030 ----
mean loss: 54.55
train mean loss: 51.54
epoch train time: 0:00:00.174148
elapsed time: 0:00:49.367143
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 17:03:35.606289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.98
 ---- batch: 020 ----
mean loss: 52.29
 ---- batch: 030 ----
mean loss: 51.04
train mean loss: 51.63
epoch train time: 0:00:00.170095
elapsed time: 0:00:49.537401
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 17:03:35.776529
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.65
 ---- batch: 020 ----
mean loss: 52.24
 ---- batch: 030 ----
mean loss: 52.78
train mean loss: 51.49
epoch train time: 0:00:00.172316
elapsed time: 0:00:49.709858
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 17:03:35.949001
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.84
 ---- batch: 020 ----
mean loss: 51.87
 ---- batch: 030 ----
mean loss: 48.70
train mean loss: 51.62
epoch train time: 0:00:00.170758
elapsed time: 0:00:49.880769
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 17:03:36.119906
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.19
 ---- batch: 020 ----
mean loss: 52.74
 ---- batch: 030 ----
mean loss: 52.01
train mean loss: 51.53
epoch train time: 0:00:00.169217
elapsed time: 0:00:50.050135
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 17:03:36.289271
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.78
 ---- batch: 020 ----
mean loss: 51.24
 ---- batch: 030 ----
mean loss: 53.99
train mean loss: 51.61
epoch train time: 0:00:00.170987
elapsed time: 0:00:50.221266
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 17:03:36.460392
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.59
 ---- batch: 020 ----
mean loss: 50.83
 ---- batch: 030 ----
mean loss: 52.95
train mean loss: 51.42
epoch train time: 0:00:00.173740
elapsed time: 0:00:50.395146
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 17:03:36.634273
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.54
 ---- batch: 020 ----
mean loss: 51.50
 ---- batch: 030 ----
mean loss: 51.54
train mean loss: 51.51
epoch train time: 0:00:00.171963
elapsed time: 0:00:50.567250
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 17:03:36.806378
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.54
 ---- batch: 020 ----
mean loss: 50.81
 ---- batch: 030 ----
mean loss: 53.72
train mean loss: 51.42
epoch train time: 0:00:00.170975
elapsed time: 0:00:50.738364
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 17:03:36.977492
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.97
 ---- batch: 020 ----
mean loss: 49.68
 ---- batch: 030 ----
mean loss: 52.25
train mean loss: 51.38
epoch train time: 0:00:00.166753
elapsed time: 0:00:50.905253
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 17:03:37.144378
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.34
 ---- batch: 020 ----
mean loss: 50.12
 ---- batch: 030 ----
mean loss: 51.53
train mean loss: 51.41
epoch train time: 0:00:00.165107
elapsed time: 0:00:51.070492
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 17:03:37.309638
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.06
 ---- batch: 020 ----
mean loss: 50.33
 ---- batch: 030 ----
mean loss: 49.99
train mean loss: 51.30
epoch train time: 0:00:00.166920
elapsed time: 0:00:51.237567
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 17:03:37.476695
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.36
 ---- batch: 020 ----
mean loss: 54.26
 ---- batch: 030 ----
mean loss: 49.65
train mean loss: 51.28
epoch train time: 0:00:00.169022
elapsed time: 0:00:51.406734
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 17:03:37.645861
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.46
 ---- batch: 020 ----
mean loss: 51.51
 ---- batch: 030 ----
mean loss: 51.14
train mean loss: 51.23
epoch train time: 0:00:00.167963
elapsed time: 0:00:51.574858
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 17:03:37.814011
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.69
 ---- batch: 020 ----
mean loss: 49.69
 ---- batch: 030 ----
mean loss: 52.69
train mean loss: 51.09
epoch train time: 0:00:00.172337
elapsed time: 0:00:51.747355
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 17:03:37.986481
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.36
 ---- batch: 020 ----
mean loss: 53.43
 ---- batch: 030 ----
mean loss: 50.60
train mean loss: 51.31
epoch train time: 0:00:00.164311
elapsed time: 0:00:51.911802
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 17:03:38.150928
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.48
 ---- batch: 020 ----
mean loss: 50.68
 ---- batch: 030 ----
mean loss: 50.85
train mean loss: 51.17
epoch train time: 0:00:00.162353
elapsed time: 0:00:52.074286
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 17:03:38.313428
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.74
 ---- batch: 020 ----
mean loss: 51.85
 ---- batch: 030 ----
mean loss: 50.30
train mean loss: 51.06
epoch train time: 0:00:00.163511
elapsed time: 0:00:52.237964
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 17:03:38.477090
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.93
 ---- batch: 020 ----
mean loss: 51.32
 ---- batch: 030 ----
mean loss: 49.51
train mean loss: 51.22
epoch train time: 0:00:00.164399
elapsed time: 0:00:52.402513
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 17:03:38.641654
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.28
 ---- batch: 020 ----
mean loss: 52.58
 ---- batch: 030 ----
mean loss: 48.87
train mean loss: 51.29
epoch train time: 0:00:00.173222
elapsed time: 0:00:52.575902
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 17:03:38.815027
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.07
 ---- batch: 020 ----
mean loss: 51.21
 ---- batch: 030 ----
mean loss: 49.48
train mean loss: 51.14
epoch train time: 0:00:00.171904
elapsed time: 0:00:52.747972
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 17:03:38.987100
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.23
 ---- batch: 020 ----
mean loss: 49.76
 ---- batch: 030 ----
mean loss: 51.69
train mean loss: 50.99
epoch train time: 0:00:00.172174
elapsed time: 0:00:52.920285
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 17:03:39.159411
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.70
 ---- batch: 020 ----
mean loss: 50.80
 ---- batch: 030 ----
mean loss: 50.58
train mean loss: 51.08
epoch train time: 0:00:00.166513
elapsed time: 0:00:53.086934
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 17:03:39.326060
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.78
 ---- batch: 020 ----
mean loss: 50.31
 ---- batch: 030 ----
mean loss: 51.16
train mean loss: 51.03
epoch train time: 0:00:00.173012
elapsed time: 0:00:53.260096
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 17:03:39.499222
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.67
 ---- batch: 020 ----
mean loss: 51.02
 ---- batch: 030 ----
mean loss: 49.40
train mean loss: 51.06
epoch train time: 0:00:00.169571
elapsed time: 0:00:53.429808
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 17:03:39.668937
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.55
 ---- batch: 020 ----
mean loss: 51.33
 ---- batch: 030 ----
mean loss: 51.60
train mean loss: 51.15
epoch train time: 0:00:00.171231
elapsed time: 0:00:53.601181
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 17:03:39.840308
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.68
 ---- batch: 020 ----
mean loss: 50.32
 ---- batch: 030 ----
mean loss: 53.11
train mean loss: 50.95
epoch train time: 0:00:00.172833
elapsed time: 0:00:53.774151
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 17:03:40.013276
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.75
 ---- batch: 020 ----
mean loss: 50.99
 ---- batch: 030 ----
mean loss: 49.74
train mean loss: 50.95
epoch train time: 0:00:00.165727
elapsed time: 0:00:53.940011
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 17:03:40.179166
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.60
 ---- batch: 020 ----
mean loss: 50.86
 ---- batch: 030 ----
mean loss: 49.37
train mean loss: 50.95
epoch train time: 0:00:00.166350
elapsed time: 0:00:54.106553
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 17:03:40.345683
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.58
 ---- batch: 020 ----
mean loss: 51.88
 ---- batch: 030 ----
mean loss: 51.06
train mean loss: 50.83
epoch train time: 0:00:00.166085
elapsed time: 0:00:54.272776
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 17:03:40.511916
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.47
 ---- batch: 020 ----
mean loss: 50.48
 ---- batch: 030 ----
mean loss: 52.05
train mean loss: 50.82
epoch train time: 0:00:00.167154
elapsed time: 0:00:54.440084
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 17:03:40.679213
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.69
 ---- batch: 020 ----
mean loss: 50.12
 ---- batch: 030 ----
mean loss: 49.93
train mean loss: 50.76
epoch train time: 0:00:00.172898
elapsed time: 0:00:54.613123
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 17:03:40.852250
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.49
 ---- batch: 020 ----
mean loss: 49.13
 ---- batch: 030 ----
mean loss: 50.90
train mean loss: 50.70
epoch train time: 0:00:00.172040
elapsed time: 0:00:54.785301
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 17:03:41.024428
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.54
 ---- batch: 020 ----
mean loss: 50.91
 ---- batch: 030 ----
mean loss: 46.85
train mean loss: 50.86
epoch train time: 0:00:00.171249
elapsed time: 0:00:54.956686
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 17:03:41.195812
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.98
 ---- batch: 020 ----
mean loss: 52.45
 ---- batch: 030 ----
mean loss: 51.38
train mean loss: 50.81
epoch train time: 0:00:00.171377
elapsed time: 0:00:55.131323
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_9/checkpoint.pth.tar
**** end time: 2019-09-27 17:03:41.370419 ****
