Namespace(batch_size=512, dataset='CMAPSS/FD003', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_8', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.25, resume=False, step_size=200, visualize_step=50)
pid: 23865
use_cuda: True
Dataset: CMAPSS/FD003
Building BayesianDense3...
Done.
**** start time: 2019-10-01 14:49:41.312071 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-10-01 14:49:41.322091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4383.42
train mean loss: 4357.50
epoch train time: 0:00:03.939579
elapsed time: 0:00:03.955961
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-10-01 14:49:45.268076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4077.87
train mean loss: 4047.90
epoch train time: 0:00:00.177791
elapsed time: 0:00:04.133877
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-10-01 14:49:45.446002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3781.69
train mean loss: 3777.86
epoch train time: 0:00:00.173092
elapsed time: 0:00:04.307103
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-10-01 14:49:45.619217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3519.76
train mean loss: 3528.01
epoch train time: 0:00:00.173073
elapsed time: 0:00:04.480301
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-10-01 14:49:45.792435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3332.49
train mean loss: 3302.71
epoch train time: 0:00:00.168510
elapsed time: 0:00:04.648968
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-10-01 14:49:45.961087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3121.86
train mean loss: 3125.07
epoch train time: 0:00:00.170066
elapsed time: 0:00:04.819164
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-10-01 14:49:46.131280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2984.57
train mean loss: 2990.41
epoch train time: 0:00:00.170292
elapsed time: 0:00:04.989582
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-10-01 14:49:46.301698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2850.09
train mean loss: 2841.05
epoch train time: 0:00:00.169100
elapsed time: 0:00:05.158824
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-10-01 14:49:46.470939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2739.36
train mean loss: 2727.67
epoch train time: 0:00:00.171747
elapsed time: 0:00:05.330697
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-10-01 14:49:46.642810
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2629.41
train mean loss: 2638.80
epoch train time: 0:00:00.173990
elapsed time: 0:00:05.504819
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-10-01 14:49:46.816934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2550.85
train mean loss: 2556.43
epoch train time: 0:00:00.171517
elapsed time: 0:00:05.676460
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-10-01 14:49:46.988592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2480.66
train mean loss: 2469.37
epoch train time: 0:00:00.171640
elapsed time: 0:00:05.848243
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-10-01 14:49:47.160358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2415.21
train mean loss: 2408.09
epoch train time: 0:00:00.168091
elapsed time: 0:00:06.016458
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-10-01 14:49:47.328574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2367.81
train mean loss: 2355.58
epoch train time: 0:00:00.188658
elapsed time: 0:00:06.205256
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-10-01 14:49:47.517374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2298.77
train mean loss: 2303.41
epoch train time: 0:00:00.172903
elapsed time: 0:00:06.378379
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-10-01 14:49:47.690524
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2255.72
train mean loss: 2255.25
epoch train time: 0:00:00.175559
elapsed time: 0:00:06.554094
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-10-01 14:49:47.866210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2210.68
train mean loss: 2198.91
epoch train time: 0:00:00.167799
elapsed time: 0:00:06.722033
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-10-01 14:49:48.034149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2161.46
train mean loss: 2162.42
epoch train time: 0:00:00.170746
elapsed time: 0:00:06.892902
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-10-01 14:49:48.205017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2119.67
train mean loss: 2118.21
epoch train time: 0:00:00.171616
elapsed time: 0:00:07.064644
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-10-01 14:49:48.376758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2094.30
train mean loss: 2083.44
epoch train time: 0:00:00.168295
elapsed time: 0:00:07.233065
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-10-01 14:49:48.545182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2052.03
train mean loss: 2065.25
epoch train time: 0:00:00.189157
elapsed time: 0:00:07.422355
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-10-01 14:49:48.734470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2029.91
train mean loss: 2021.16
epoch train time: 0:00:00.173528
elapsed time: 0:00:07.596010
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-10-01 14:49:48.908128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1990.36
train mean loss: 1981.42
epoch train time: 0:00:00.182943
elapsed time: 0:00:07.779085
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-10-01 14:49:49.091215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1957.52
train mean loss: 1957.53
epoch train time: 0:00:00.180986
elapsed time: 0:00:07.960224
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-10-01 14:49:49.272349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1926.54
train mean loss: 1927.18
epoch train time: 0:00:00.185076
elapsed time: 0:00:08.145439
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-10-01 14:49:49.457556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1905.74
train mean loss: 1898.08
epoch train time: 0:00:00.171782
elapsed time: 0:00:08.317361
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-10-01 14:49:49.629479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1865.31
train mean loss: 1857.76
epoch train time: 0:00:00.175428
elapsed time: 0:00:08.492920
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-10-01 14:49:49.805038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1844.06
train mean loss: 1840.43
epoch train time: 0:00:00.175026
elapsed time: 0:00:08.668080
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-10-01 14:49:49.980199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1796.65
train mean loss: 1803.53
epoch train time: 0:00:00.175373
elapsed time: 0:00:08.843587
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-10-01 14:49:50.155703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1783.15
train mean loss: 1793.93
epoch train time: 0:00:00.179650
elapsed time: 0:00:09.023371
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-10-01 14:49:50.335486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1751.02
train mean loss: 1754.74
epoch train time: 0:00:00.173186
elapsed time: 0:00:09.196694
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-10-01 14:49:50.508813
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1727.01
train mean loss: 1728.44
epoch train time: 0:00:00.200980
elapsed time: 0:00:09.397812
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-10-01 14:49:50.709931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1695.12
train mean loss: 1696.96
epoch train time: 0:00:00.177952
elapsed time: 0:00:09.575897
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-10-01 14:49:50.888014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1676.31
train mean loss: 1676.80
epoch train time: 0:00:00.174021
elapsed time: 0:00:09.750051
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-10-01 14:49:51.062167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1653.23
train mean loss: 1651.15
epoch train time: 0:00:00.183441
elapsed time: 0:00:09.933632
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-10-01 14:49:51.245752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1628.42
train mean loss: 1632.98
epoch train time: 0:00:00.174732
elapsed time: 0:00:10.108503
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-10-01 14:49:51.420624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1607.71
train mean loss: 1607.79
epoch train time: 0:00:00.175499
elapsed time: 0:00:10.284134
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-10-01 14:49:51.596249
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1583.90
train mean loss: 1589.01
epoch train time: 0:00:00.178899
elapsed time: 0:00:10.463189
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-10-01 14:49:51.775304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1563.97
train mean loss: 1563.21
epoch train time: 0:00:00.186638
elapsed time: 0:00:10.649950
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-10-01 14:49:51.962063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1538.06
train mean loss: 1549.68
epoch train time: 0:00:00.173152
elapsed time: 0:00:10.823234
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-10-01 14:49:52.135349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1516.28
train mean loss: 1524.38
epoch train time: 0:00:00.176355
elapsed time: 0:00:10.999734
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-10-01 14:49:52.311861
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1497.46
train mean loss: 1502.57
epoch train time: 0:00:00.175489
elapsed time: 0:00:11.175357
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-10-01 14:49:52.487484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1477.46
train mean loss: 1482.39
epoch train time: 0:00:00.175793
elapsed time: 0:00:11.351286
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-10-01 14:49:52.663402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1468.90
train mean loss: 1465.99
epoch train time: 0:00:00.188976
elapsed time: 0:00:11.540386
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-10-01 14:49:52.852516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1436.13
train mean loss: 1442.16
epoch train time: 0:00:00.174524
elapsed time: 0:00:11.715048
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-10-01 14:49:53.027162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1416.03
train mean loss: 1420.68
epoch train time: 0:00:00.177933
elapsed time: 0:00:11.893129
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-10-01 14:49:53.205250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1399.18
train mean loss: 1400.74
epoch train time: 0:00:00.172891
elapsed time: 0:00:12.066145
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-10-01 14:49:53.378256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1380.67
train mean loss: 1377.98
epoch train time: 0:00:00.178061
elapsed time: 0:00:12.244343
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-10-01 14:49:53.556455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1352.53
train mean loss: 1356.99
epoch train time: 0:00:00.195313
elapsed time: 0:00:12.439786
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-10-01 14:49:53.751901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1345.69
train mean loss: 1339.08
epoch train time: 0:00:00.173811
elapsed time: 0:00:12.613752
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-10-01 14:49:53.925865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1314.12
train mean loss: 1324.22
epoch train time: 0:00:00.171301
elapsed time: 0:00:12.785170
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-10-01 14:49:54.097283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1305.94
train mean loss: 1309.27
epoch train time: 0:00:00.177667
elapsed time: 0:00:12.962963
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-10-01 14:49:54.275095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1294.55
train mean loss: 1292.39
epoch train time: 0:00:00.176595
elapsed time: 0:00:13.139698
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-10-01 14:49:54.451813
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1280.62
train mean loss: 1278.67
epoch train time: 0:00:00.175725
elapsed time: 0:00:13.315576
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-10-01 14:49:54.627697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1259.99
train mean loss: 1262.69
epoch train time: 0:00:00.175869
elapsed time: 0:00:13.491592
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-10-01 14:49:54.803721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1248.52
train mean loss: 1249.25
epoch train time: 0:00:00.176486
elapsed time: 0:00:13.668255
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-10-01 14:49:54.980394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1224.14
train mean loss: 1224.15
epoch train time: 0:00:00.176089
elapsed time: 0:00:13.844490
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-10-01 14:49:55.156603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1225.17
train mean loss: 1219.41
epoch train time: 0:00:00.179553
elapsed time: 0:00:14.024169
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-10-01 14:49:55.336283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1203.59
train mean loss: 1200.90
epoch train time: 0:00:00.170335
elapsed time: 0:00:14.194627
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-10-01 14:49:55.506757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1175.52
train mean loss: 1178.54
epoch train time: 0:00:00.177218
elapsed time: 0:00:14.371988
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-10-01 14:49:55.684104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1171.10
train mean loss: 1170.76
epoch train time: 0:00:00.186809
elapsed time: 0:00:14.558927
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-10-01 14:49:55.871049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1155.54
train mean loss: 1150.93
epoch train time: 0:00:00.173835
elapsed time: 0:00:14.732894
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-10-01 14:49:56.045010
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1123.03
train mean loss: 1123.86
epoch train time: 0:00:00.176609
elapsed time: 0:00:14.909625
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-10-01 14:49:56.221740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1079.61
train mean loss: 1076.52
epoch train time: 0:00:00.174476
elapsed time: 0:00:15.084224
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-10-01 14:49:56.396352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1047.25
train mean loss: 1047.34
epoch train time: 0:00:00.174323
elapsed time: 0:00:15.258688
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-10-01 14:49:56.570803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1020.64
train mean loss: 1023.55
epoch train time: 0:00:00.183202
elapsed time: 0:00:15.442039
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-10-01 14:49:56.754181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1005.05
train mean loss: 1000.45
epoch train time: 0:00:00.189570
elapsed time: 0:00:15.631760
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-10-01 14:49:56.943873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 980.36
train mean loss: 977.48
epoch train time: 0:00:00.174662
elapsed time: 0:00:15.806542
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-10-01 14:49:57.118657
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 955.32
train mean loss: 956.67
epoch train time: 0:00:00.174397
elapsed time: 0:00:15.981059
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-10-01 14:49:57.293190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 950.05
train mean loss: 947.96
epoch train time: 0:00:00.173079
elapsed time: 0:00:16.154278
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-10-01 14:49:57.466394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.36
train mean loss: 926.62
epoch train time: 0:00:00.175536
elapsed time: 0:00:16.329944
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-10-01 14:49:57.642060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 915.39
train mean loss: 918.56
epoch train time: 0:00:00.187972
elapsed time: 0:00:16.518048
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-10-01 14:49:57.830167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 901.03
train mean loss: 899.04
epoch train time: 0:00:00.177296
elapsed time: 0:00:16.695528
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-10-01 14:49:58.007642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 877.96
train mean loss: 878.96
epoch train time: 0:00:00.175302
elapsed time: 0:00:16.870949
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-10-01 14:49:58.183060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 870.80
train mean loss: 869.74
epoch train time: 0:00:00.169832
elapsed time: 0:00:17.040923
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-10-01 14:49:58.353035
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 853.99
train mean loss: 853.57
epoch train time: 0:00:00.173082
elapsed time: 0:00:17.214128
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-10-01 14:49:58.526259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 839.20
train mean loss: 835.56
epoch train time: 0:00:00.178799
elapsed time: 0:00:17.393088
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-10-01 14:49:58.705247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 819.33
train mean loss: 818.44
epoch train time: 0:00:00.170829
elapsed time: 0:00:17.564084
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-10-01 14:49:58.876215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 807.42
train mean loss: 807.88
epoch train time: 0:00:00.169495
elapsed time: 0:00:17.733740
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-10-01 14:49:59.045858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 802.75
train mean loss: 796.44
epoch train time: 0:00:00.170998
elapsed time: 0:00:17.904866
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-10-01 14:49:59.216980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 783.08
train mean loss: 784.26
epoch train time: 0:00:00.170104
elapsed time: 0:00:18.075085
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-10-01 14:49:59.387211
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 777.37
train mean loss: 774.87
epoch train time: 0:00:00.166251
elapsed time: 0:00:18.241463
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-10-01 14:49:59.553574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 757.94
train mean loss: 756.17
epoch train time: 0:00:00.177947
elapsed time: 0:00:18.419551
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-10-01 14:49:59.731687
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 745.86
train mean loss: 745.81
epoch train time: 0:00:00.197545
elapsed time: 0:00:18.617253
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-10-01 14:49:59.929369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 728.38
train mean loss: 734.18
epoch train time: 0:00:00.174524
elapsed time: 0:00:18.791902
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-10-01 14:50:00.104018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 710.63
train mean loss: 708.71
epoch train time: 0:00:00.173577
elapsed time: 0:00:18.965596
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-10-01 14:50:00.277709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 703.54
train mean loss: 708.25
epoch train time: 0:00:00.172991
elapsed time: 0:00:19.138703
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-10-01 14:50:00.450854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 696.89
train mean loss: 695.03
epoch train time: 0:00:00.172482
elapsed time: 0:00:19.311344
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-10-01 14:50:00.623471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 688.02
train mean loss: 685.83
epoch train time: 0:00:00.182779
elapsed time: 0:00:19.494276
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-10-01 14:50:00.806391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 672.20
train mean loss: 674.88
epoch train time: 0:00:00.175068
elapsed time: 0:00:19.669464
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-10-01 14:50:00.981587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 668.78
train mean loss: 660.92
epoch train time: 0:00:00.175484
elapsed time: 0:00:19.845076
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-10-01 14:50:01.157192
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 646.16
train mean loss: 646.27
epoch train time: 0:00:00.171820
elapsed time: 0:00:20.017014
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-10-01 14:50:01.329142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 641.07
train mean loss: 641.52
epoch train time: 0:00:00.171900
elapsed time: 0:00:20.189048
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-10-01 14:50:01.501177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 626.48
train mean loss: 626.15
epoch train time: 0:00:00.175612
elapsed time: 0:00:20.364800
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-10-01 14:50:01.676930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 617.62
train mean loss: 618.38
epoch train time: 0:00:00.178202
elapsed time: 0:00:20.543141
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-10-01 14:50:01.855282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 617.21
train mean loss: 610.76
epoch train time: 0:00:00.173896
elapsed time: 0:00:20.717206
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-10-01 14:50:02.029352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 594.64
train mean loss: 597.37
epoch train time: 0:00:00.173442
elapsed time: 0:00:20.890838
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-10-01 14:50:02.202970
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 584.65
train mean loss: 589.48
epoch train time: 0:00:00.173516
elapsed time: 0:00:21.064492
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-10-01 14:50:02.376604
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 575.79
train mean loss: 577.63
epoch train time: 0:00:00.170776
elapsed time: 0:00:21.235380
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-10-01 14:50:02.547490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 568.46
train mean loss: 566.82
epoch train time: 0:00:00.171234
elapsed time: 0:00:21.406733
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-10-01 14:50:02.718860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 561.46
train mean loss: 562.42
epoch train time: 0:00:00.188921
elapsed time: 0:00:21.595791
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-10-01 14:50:02.907905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 545.53
train mean loss: 547.02
epoch train time: 0:00:00.175614
elapsed time: 0:00:21.771530
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-10-01 14:50:03.083644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 545.93
train mean loss: 544.32
epoch train time: 0:00:00.173497
elapsed time: 0:00:21.945145
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-10-01 14:50:03.257256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 525.88
train mean loss: 529.25
epoch train time: 0:00:00.170617
elapsed time: 0:00:22.115893
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-10-01 14:50:03.428005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 522.10
train mean loss: 519.89
epoch train time: 0:00:00.170264
elapsed time: 0:00:22.286289
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-10-01 14:50:03.598401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 511.28
train mean loss: 508.79
epoch train time: 0:00:00.191027
elapsed time: 0:00:22.477444
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-10-01 14:50:03.789570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 505.71
train mean loss: 503.93
epoch train time: 0:00:00.193975
elapsed time: 0:00:22.671568
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-10-01 14:50:03.983691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 500.23
train mean loss: 502.14
epoch train time: 0:00:00.176809
elapsed time: 0:00:22.848506
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-10-01 14:50:04.160621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 486.94
train mean loss: 483.34
epoch train time: 0:00:00.178083
elapsed time: 0:00:23.026712
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-10-01 14:50:04.338827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 482.34
train mean loss: 480.18
epoch train time: 0:00:00.177918
elapsed time: 0:00:23.204770
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-10-01 14:50:04.516887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 473.86
train mean loss: 472.52
epoch train time: 0:00:00.180946
elapsed time: 0:00:23.385985
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-10-01 14:50:04.698110
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 457.54
train mean loss: 463.00
epoch train time: 0:00:00.177923
elapsed time: 0:00:23.564089
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-10-01 14:50:04.876202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 458.33
train mean loss: 457.61
epoch train time: 0:00:00.175148
elapsed time: 0:00:23.739362
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-10-01 14:50:05.051491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 446.04
train mean loss: 444.28
epoch train time: 0:00:00.175316
elapsed time: 0:00:23.914882
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-10-01 14:50:05.227033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 439.51
train mean loss: 438.07
epoch train time: 0:00:00.171614
elapsed time: 0:00:24.086648
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-10-01 14:50:05.398762
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 432.46
train mean loss: 432.17
epoch train time: 0:00:00.172188
elapsed time: 0:00:24.258957
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-10-01 14:50:05.571072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 423.92
train mean loss: 422.71
epoch train time: 0:00:00.173257
elapsed time: 0:00:24.432389
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-10-01 14:50:05.744513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 416.53
train mean loss: 415.10
epoch train time: 0:00:00.188741
elapsed time: 0:00:24.621260
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-10-01 14:50:05.933391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 411.93
train mean loss: 411.89
epoch train time: 0:00:00.169460
elapsed time: 0:00:24.790855
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-10-01 14:50:06.102977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 409.01
train mean loss: 403.62
epoch train time: 0:00:00.166950
elapsed time: 0:00:24.957934
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-10-01 14:50:06.270050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 395.66
train mean loss: 390.99
epoch train time: 0:00:00.168867
elapsed time: 0:00:25.126931
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-10-01 14:50:06.439081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 391.62
train mean loss: 391.67
epoch train time: 0:00:00.165324
elapsed time: 0:00:25.292417
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-10-01 14:50:06.604530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 391.06
train mean loss: 389.13
epoch train time: 0:00:00.170870
elapsed time: 0:00:25.463436
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-10-01 14:50:06.775559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 379.51
train mean loss: 379.04
epoch train time: 0:00:00.178729
elapsed time: 0:00:25.642330
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-10-01 14:50:06.954444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.41
train mean loss: 373.89
epoch train time: 0:00:00.176588
elapsed time: 0:00:25.819054
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-10-01 14:50:07.131185
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.92
train mean loss: 367.16
epoch train time: 0:00:00.173866
elapsed time: 0:00:25.993058
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-10-01 14:50:07.305173
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 359.99
train mean loss: 359.55
epoch train time: 0:00:00.171761
elapsed time: 0:00:26.164961
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-10-01 14:50:07.477067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.25
train mean loss: 350.16
epoch train time: 0:00:00.175308
elapsed time: 0:00:26.340395
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-10-01 14:50:07.652510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 344.59
train mean loss: 344.64
epoch train time: 0:00:00.194359
elapsed time: 0:00:26.534880
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-10-01 14:50:07.846995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.95
train mean loss: 338.21
epoch train time: 0:00:00.172531
elapsed time: 0:00:26.707550
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-10-01 14:50:08.019675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 338.55
train mean loss: 338.80
epoch train time: 0:00:00.170736
elapsed time: 0:00:26.878411
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-10-01 14:50:08.190526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 332.63
train mean loss: 333.27
epoch train time: 0:00:00.172604
elapsed time: 0:00:27.051162
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-10-01 14:50:08.363313
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.54
train mean loss: 324.69
epoch train time: 0:00:00.173539
elapsed time: 0:00:27.224858
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-10-01 14:50:08.537046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 316.36
train mean loss: 318.11
epoch train time: 0:00:00.174599
elapsed time: 0:00:27.399653
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-10-01 14:50:08.711777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.59
train mean loss: 317.71
epoch train time: 0:00:00.176137
elapsed time: 0:00:27.575941
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-10-01 14:50:08.888055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 310.56
train mean loss: 308.42
epoch train time: 0:00:00.173567
elapsed time: 0:00:27.749630
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-10-01 14:50:09.061743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.53
train mean loss: 306.62
epoch train time: 0:00:00.170363
elapsed time: 0:00:27.920113
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-10-01 14:50:09.232226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.39
train mean loss: 302.67
epoch train time: 0:00:00.172665
elapsed time: 0:00:28.092901
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-10-01 14:50:09.405061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.71
train mean loss: 299.90
epoch train time: 0:00:00.188877
elapsed time: 0:00:28.281990
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-10-01 14:50:09.594107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.90
train mean loss: 289.57
epoch train time: 0:00:00.190015
elapsed time: 0:00:28.472135
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-10-01 14:50:09.784268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.79
train mean loss: 284.22
epoch train time: 0:00:00.177139
elapsed time: 0:00:28.649419
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-10-01 14:50:09.961535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.98
train mean loss: 278.86
epoch train time: 0:00:00.179830
elapsed time: 0:00:28.829379
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-10-01 14:50:10.141506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.97
train mean loss: 277.40
epoch train time: 0:00:00.176967
elapsed time: 0:00:29.006479
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-10-01 14:50:10.318623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.37
train mean loss: 273.51
epoch train time: 0:00:00.177630
elapsed time: 0:00:29.184258
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-10-01 14:50:10.496370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.86
train mean loss: 268.65
epoch train time: 0:00:00.178900
elapsed time: 0:00:29.363283
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-10-01 14:50:10.675397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.67
train mean loss: 263.90
epoch train time: 0:00:00.190411
elapsed time: 0:00:29.553837
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-10-01 14:50:10.865950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.92
train mean loss: 261.58
epoch train time: 0:00:00.174711
elapsed time: 0:00:29.728713
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-10-01 14:50:11.040863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.49
train mean loss: 257.33
epoch train time: 0:00:00.176089
elapsed time: 0:00:29.904974
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-10-01 14:50:11.217108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.88
train mean loss: 251.13
epoch train time: 0:00:00.174687
elapsed time: 0:00:30.079831
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-10-01 14:50:11.391948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.94
train mean loss: 249.63
epoch train time: 0:00:00.179726
elapsed time: 0:00:30.259695
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-10-01 14:50:11.571815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.91
train mean loss: 246.17
epoch train time: 0:00:00.184387
elapsed time: 0:00:30.444247
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-10-01 14:50:11.756394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.15
train mean loss: 244.09
epoch train time: 0:00:00.191566
elapsed time: 0:00:30.636008
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-10-01 14:50:11.948120
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.88
train mean loss: 237.14
epoch train time: 0:00:00.178127
elapsed time: 0:00:30.814259
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-10-01 14:50:12.126374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.78
train mean loss: 236.54
epoch train time: 0:00:00.179271
elapsed time: 0:00:30.993668
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-10-01 14:50:12.305829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.77
train mean loss: 230.42
epoch train time: 0:00:00.175842
elapsed time: 0:00:31.169733
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-10-01 14:50:12.481869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.80
train mean loss: 229.53
epoch train time: 0:00:00.179511
elapsed time: 0:00:31.349402
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-10-01 14:50:12.661517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.88
train mean loss: 223.50
epoch train time: 0:00:00.180759
elapsed time: 0:00:31.530285
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-10-01 14:50:12.842400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.08
train mean loss: 223.52
epoch train time: 0:00:00.170494
elapsed time: 0:00:31.700900
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-10-01 14:50:13.013013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.12
train mean loss: 216.56
epoch train time: 0:00:00.173724
elapsed time: 0:00:31.874755
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-10-01 14:50:13.186870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.92
train mean loss: 214.46
epoch train time: 0:00:00.174048
elapsed time: 0:00:32.048940
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-10-01 14:50:13.361057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.44
train mean loss: 213.61
epoch train time: 0:00:00.174019
elapsed time: 0:00:32.223086
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-10-01 14:50:13.535200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.05
train mean loss: 210.21
epoch train time: 0:00:00.182117
elapsed time: 0:00:32.405333
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-10-01 14:50:13.717456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 206.81
train mean loss: 206.84
epoch train time: 0:00:00.188686
elapsed time: 0:00:32.594154
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-10-01 14:50:13.906270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.71
train mean loss: 205.79
epoch train time: 0:00:00.174203
elapsed time: 0:00:32.768480
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-10-01 14:50:14.080593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 203.55
train mean loss: 202.00
epoch train time: 0:00:00.175205
elapsed time: 0:00:32.943822
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-10-01 14:50:14.255952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.29
train mean loss: 203.40
epoch train time: 0:00:00.174791
elapsed time: 0:00:33.118771
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-10-01 14:50:14.430889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 194.23
train mean loss: 193.20
epoch train time: 0:00:00.177326
elapsed time: 0:00:33.296227
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-10-01 14:50:14.608345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 194.99
train mean loss: 195.67
epoch train time: 0:00:00.177341
elapsed time: 0:00:33.473722
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-10-01 14:50:14.785841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.41
train mean loss: 193.24
epoch train time: 0:00:00.183406
elapsed time: 0:00:33.657269
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-10-01 14:50:14.969422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.89
train mean loss: 191.42
epoch train time: 0:00:00.170352
elapsed time: 0:00:33.827781
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-10-01 14:50:15.139904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.60
train mean loss: 184.57
epoch train time: 0:00:00.169227
elapsed time: 0:00:33.997130
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-10-01 14:50:15.309244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.53
train mean loss: 185.59
epoch train time: 0:00:00.170935
elapsed time: 0:00:34.168792
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-10-01 14:50:15.480930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.94
train mean loss: 183.40
epoch train time: 0:00:00.174157
elapsed time: 0:00:34.343095
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-10-01 14:50:15.655210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.22
train mean loss: 178.74
epoch train time: 0:00:00.196402
elapsed time: 0:00:34.539703
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-10-01 14:50:15.851811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.11
train mean loss: 178.56
epoch train time: 0:00:00.175722
elapsed time: 0:00:34.715544
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-10-01 14:50:16.027661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.16
train mean loss: 174.00
epoch train time: 0:00:00.175368
elapsed time: 0:00:34.891036
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-10-01 14:50:16.203164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.12
train mean loss: 175.34
epoch train time: 0:00:00.175338
elapsed time: 0:00:35.066533
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-10-01 14:50:16.378644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.83
train mean loss: 168.46
epoch train time: 0:00:00.174521
elapsed time: 0:00:35.241170
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-10-01 14:50:16.553282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.00
train mean loss: 168.19
epoch train time: 0:00:00.174718
elapsed time: 0:00:35.416023
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-10-01 14:50:16.728154
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.52
train mean loss: 167.71
epoch train time: 0:00:00.179313
elapsed time: 0:00:35.595472
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-10-01 14:50:16.907583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.54
train mean loss: 164.23
epoch train time: 0:00:00.172384
elapsed time: 0:00:35.767988
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-10-01 14:50:17.080103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.19
train mean loss: 161.63
epoch train time: 0:00:00.176258
elapsed time: 0:00:35.944378
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-10-01 14:50:17.256490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.21
train mean loss: 159.97
epoch train time: 0:00:00.175744
elapsed time: 0:00:36.120246
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-10-01 14:50:17.432371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.82
train mean loss: 157.13
epoch train time: 0:00:00.175604
elapsed time: 0:00:36.295982
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-10-01 14:50:17.608098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.11
train mean loss: 157.53
epoch train time: 0:00:00.195980
elapsed time: 0:00:36.492133
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-10-01 14:50:17.804269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.59
train mean loss: 157.28
epoch train time: 0:00:00.179689
elapsed time: 0:00:36.671970
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-10-01 14:50:17.984099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.03
train mean loss: 154.23
epoch train time: 0:00:00.175479
elapsed time: 0:00:36.847588
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-10-01 14:50:18.159702
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.32
train mean loss: 154.44
epoch train time: 0:00:00.174929
elapsed time: 0:00:37.022637
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-10-01 14:50:18.334774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.50
train mean loss: 154.64
epoch train time: 0:00:00.175603
elapsed time: 0:00:37.198388
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-10-01 14:50:18.510505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.24
train mean loss: 150.05
epoch train time: 0:00:00.178201
elapsed time: 0:00:37.376727
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-10-01 14:50:18.688845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.04
train mean loss: 148.05
epoch train time: 0:00:00.182704
elapsed time: 0:00:37.559570
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-10-01 14:50:18.871686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.13
train mean loss: 148.60
epoch train time: 0:00:00.176743
elapsed time: 0:00:37.736440
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-10-01 14:50:19.048557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.75
train mean loss: 145.54
epoch train time: 0:00:00.179453
elapsed time: 0:00:37.916022
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-10-01 14:50:19.228138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.20
train mean loss: 145.44
epoch train time: 0:00:00.176196
elapsed time: 0:00:38.092346
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-10-01 14:50:19.404460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.95
train mean loss: 142.92
epoch train time: 0:00:00.177602
elapsed time: 0:00:38.270072
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-10-01 14:50:19.582200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.77
train mean loss: 140.85
epoch train time: 0:00:00.178313
elapsed time: 0:00:38.448527
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-10-01 14:50:19.760642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.00
train mean loss: 141.23
epoch train time: 0:00:00.180725
elapsed time: 0:00:38.629375
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-10-01 14:50:19.941488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.78
train mean loss: 135.47
epoch train time: 0:00:00.170820
elapsed time: 0:00:38.800355
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-10-01 14:50:20.112473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.33
train mean loss: 137.14
epoch train time: 0:00:00.171111
elapsed time: 0:00:38.971590
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-10-01 14:50:20.283704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.51
train mean loss: 134.17
epoch train time: 0:00:00.172074
elapsed time: 0:00:39.143784
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-10-01 14:50:20.455896
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.68
train mean loss: 133.93
epoch train time: 0:00:00.171305
elapsed time: 0:00:39.315220
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-10-01 14:50:20.627335
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.45
train mean loss: 136.02
epoch train time: 0:00:00.174625
elapsed time: 0:00:39.490013
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-10-01 14:50:20.802122
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.06
train mean loss: 134.40
epoch train time: 0:00:00.171275
elapsed time: 0:00:39.661399
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-10-01 14:50:20.973510
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.37
train mean loss: 131.27
epoch train time: 0:00:00.175096
elapsed time: 0:00:39.836627
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-10-01 14:50:21.148740
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.66
train mean loss: 133.69
epoch train time: 0:00:00.172738
elapsed time: 0:00:40.009482
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-10-01 14:50:21.321605
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.02
train mean loss: 133.07
epoch train time: 0:00:00.179728
elapsed time: 0:00:40.189341
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-10-01 14:50:21.501473
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.33
train mean loss: 132.02
epoch train time: 0:00:00.176175
elapsed time: 0:00:40.365658
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-10-01 14:50:21.677806
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.18
train mean loss: 133.38
epoch train time: 0:00:00.177875
elapsed time: 0:00:40.543711
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-10-01 14:50:21.855827
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.63
train mean loss: 130.11
epoch train time: 0:00:00.179307
elapsed time: 0:00:40.723141
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-10-01 14:50:22.035266
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.58
train mean loss: 133.58
epoch train time: 0:00:00.175039
elapsed time: 0:00:40.898314
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-10-01 14:50:22.210427
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.10
train mean loss: 133.59
epoch train time: 0:00:00.174755
elapsed time: 0:00:41.073221
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-10-01 14:50:22.385333
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.18
train mean loss: 133.75
epoch train time: 0:00:00.175367
elapsed time: 0:00:41.248733
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-10-01 14:50:22.560857
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.30
train mean loss: 132.57
epoch train time: 0:00:00.170316
elapsed time: 0:00:41.419225
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-10-01 14:50:22.731389
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.69
train mean loss: 130.43
epoch train time: 0:00:00.171577
elapsed time: 0:00:41.591031
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-10-01 14:50:22.903142
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.86
train mean loss: 133.87
epoch train time: 0:00:00.172045
elapsed time: 0:00:41.763223
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-10-01 14:50:23.075337
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.04
train mean loss: 130.55
epoch train time: 0:00:00.171342
elapsed time: 0:00:41.934683
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-10-01 14:50:23.246795
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.61
train mean loss: 134.31
epoch train time: 0:00:00.171973
elapsed time: 0:00:42.106783
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-10-01 14:50:23.418897
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.22
train mean loss: 132.18
epoch train time: 0:00:00.171683
elapsed time: 0:00:42.278590
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-10-01 14:50:23.590704
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.00
train mean loss: 132.09
epoch train time: 0:00:00.174056
elapsed time: 0:00:42.452769
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-10-01 14:50:23.764892
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.21
train mean loss: 130.83
epoch train time: 0:00:00.184450
elapsed time: 0:00:42.637351
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-10-01 14:50:23.949466
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.23
train mean loss: 131.21
epoch train time: 0:00:00.174225
elapsed time: 0:00:42.811717
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-10-01 14:50:24.123830
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.16
train mean loss: 130.51
epoch train time: 0:00:00.173840
elapsed time: 0:00:42.985678
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-10-01 14:50:24.297823
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.80
train mean loss: 128.05
epoch train time: 0:00:00.175831
elapsed time: 0:00:43.161681
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-10-01 14:50:24.473823
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.44
train mean loss: 130.72
epoch train time: 0:00:00.177274
elapsed time: 0:00:43.339106
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-10-01 14:50:24.651244
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.46
train mean loss: 130.93
epoch train time: 0:00:00.181747
elapsed time: 0:00:43.521005
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-10-01 14:50:24.833150
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.36
train mean loss: 130.73
epoch train time: 0:00:00.177230
elapsed time: 0:00:43.698438
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-10-01 14:50:25.010551
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.94
train mean loss: 130.26
epoch train time: 0:00:00.179663
elapsed time: 0:00:43.878278
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-10-01 14:50:25.190409
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.18
train mean loss: 129.12
epoch train time: 0:00:00.177439
elapsed time: 0:00:44.055858
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-10-01 14:50:25.367975
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.26
train mean loss: 130.46
epoch train time: 0:00:00.177354
elapsed time: 0:00:44.233340
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-10-01 14:50:25.545473
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.44
train mean loss: 129.33
epoch train time: 0:00:00.178426
elapsed time: 0:00:44.411913
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-10-01 14:50:25.724030
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.22
train mean loss: 130.48
epoch train time: 0:00:00.188598
elapsed time: 0:00:44.600690
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-10-01 14:50:25.912871
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.39
train mean loss: 129.37
epoch train time: 0:00:00.172964
elapsed time: 0:00:44.773849
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-10-01 14:50:26.085964
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.66
train mean loss: 126.75
epoch train time: 0:00:00.173477
elapsed time: 0:00:44.947454
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-10-01 14:50:26.259574
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.09
train mean loss: 130.30
epoch train time: 0:00:00.177491
elapsed time: 0:00:45.125088
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-10-01 14:50:26.437196
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.29
train mean loss: 127.23
epoch train time: 0:00:00.174395
elapsed time: 0:00:45.299623
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-10-01 14:50:26.611737
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.33
train mean loss: 127.76
epoch train time: 0:00:00.176314
elapsed time: 0:00:45.476062
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-10-01 14:50:26.788187
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.27
train mean loss: 126.87
epoch train time: 0:00:00.190263
elapsed time: 0:00:45.666466
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-10-01 14:50:26.978582
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.39
train mean loss: 128.59
epoch train time: 0:00:00.178142
elapsed time: 0:00:45.844736
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-10-01 14:50:27.156851
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.49
train mean loss: 130.07
epoch train time: 0:00:00.179838
elapsed time: 0:00:46.024715
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-10-01 14:50:27.336845
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.98
train mean loss: 126.25
epoch train time: 0:00:00.177950
elapsed time: 0:00:46.202808
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-10-01 14:50:27.514923
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.51
train mean loss: 127.96
epoch train time: 0:00:00.182519
elapsed time: 0:00:46.385467
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-10-01 14:50:27.697584
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.67
train mean loss: 129.49
epoch train time: 0:00:00.179384
elapsed time: 0:00:46.564994
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-10-01 14:50:27.877123
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 126.65
train mean loss: 126.62
epoch train time: 0:00:00.177484
elapsed time: 0:00:46.742616
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-10-01 14:50:28.054739
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.37
train mean loss: 127.94
epoch train time: 0:00:00.175571
elapsed time: 0:00:46.918316
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-10-01 14:50:28.230429
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.35
train mean loss: 128.05
epoch train time: 0:00:00.177180
elapsed time: 0:00:47.095621
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-10-01 14:50:28.407737
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.19
train mean loss: 126.85
epoch train time: 0:00:00.177935
elapsed time: 0:00:47.273680
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-10-01 14:50:28.585828
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.17
train mean loss: 128.59
epoch train time: 0:00:00.176015
elapsed time: 0:00:47.449878
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-10-01 14:50:28.761993
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.47
train mean loss: 127.95
epoch train time: 0:00:00.172295
elapsed time: 0:00:47.622297
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-10-01 14:50:28.934410
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 124.44
train mean loss: 126.69
epoch train time: 0:00:00.168926
elapsed time: 0:00:47.791338
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-10-01 14:50:29.103457
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.34
train mean loss: 127.58
epoch train time: 0:00:00.175442
elapsed time: 0:00:47.974512
checkpoint saved in file: log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_8/checkpoint.pth.tar
**** end time: 2019-10-01 14:50:29.286601 ****
