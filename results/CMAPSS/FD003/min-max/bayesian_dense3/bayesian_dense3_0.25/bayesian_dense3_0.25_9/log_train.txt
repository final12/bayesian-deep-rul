Namespace(batch_size=512, dataset='CMAPSS/FD003', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_9', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.25, resume=False, step_size=200, visualize_step=50)
pid: 23938
use_cuda: True
Dataset: CMAPSS/FD003
Building BayesianDense3...
Done.
**** start time: 2019-10-01 14:50:49.992643 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-10-01 14:50:50.002637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4736.72
train mean loss: 4717.93
epoch train time: 0:00:03.886577
elapsed time: 0:00:03.902778
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-10-01 14:50:53.895463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4544.12
train mean loss: 4513.84
epoch train time: 0:00:00.183532
elapsed time: 0:00:04.086429
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-10-01 14:50:54.079145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4273.39
train mean loss: 4265.20
epoch train time: 0:00:00.171810
elapsed time: 0:00:04.258394
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-10-01 14:50:54.251095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3993.09
train mean loss: 4002.43
epoch train time: 0:00:00.173828
elapsed time: 0:00:04.432358
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-10-01 14:50:54.425045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3778.07
train mean loss: 3750.74
epoch train time: 0:00:00.171297
elapsed time: 0:00:04.603780
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-10-01 14:50:54.596468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3562.67
train mean loss: 3564.90
epoch train time: 0:00:00.174962
elapsed time: 0:00:04.778898
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-10-01 14:50:54.771588
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3394.87
train mean loss: 3398.98
epoch train time: 0:00:00.178783
elapsed time: 0:00:04.957807
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-10-01 14:50:54.950493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3256.44
train mean loss: 3246.96
epoch train time: 0:00:00.175627
elapsed time: 0:00:05.133587
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-10-01 14:50:55.126276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3138.52
train mean loss: 3128.46
epoch train time: 0:00:00.175002
elapsed time: 0:00:05.308718
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-10-01 14:50:55.301404
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3003.66
train mean loss: 3013.51
epoch train time: 0:00:00.177177
elapsed time: 0:00:05.486058
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-10-01 14:50:55.478741
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2922.54
train mean loss: 2924.99
epoch train time: 0:00:00.176975
elapsed time: 0:00:05.663174
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-10-01 14:50:55.655892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2836.71
train mean loss: 2821.54
epoch train time: 0:00:00.192129
elapsed time: 0:00:05.855490
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-10-01 14:50:55.848178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2762.77
train mean loss: 2752.95
epoch train time: 0:00:00.174759
elapsed time: 0:00:06.030371
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-10-01 14:50:56.023078
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2684.70
train mean loss: 2670.21
epoch train time: 0:00:00.175325
elapsed time: 0:00:06.205836
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-10-01 14:50:56.198520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2604.75
train mean loss: 2610.32
epoch train time: 0:00:00.176596
elapsed time: 0:00:06.382554
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-10-01 14:50:56.375255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2564.84
train mean loss: 2564.45
epoch train time: 0:00:00.175769
elapsed time: 0:00:06.558470
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-10-01 14:50:56.551157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2515.23
train mean loss: 2501.72
epoch train time: 0:00:00.179519
elapsed time: 0:00:06.738142
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-10-01 14:50:56.730833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2453.42
train mean loss: 2452.56
epoch train time: 0:00:00.176279
elapsed time: 0:00:06.914589
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-10-01 14:50:56.907298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2406.51
train mean loss: 2400.77
epoch train time: 0:00:00.178967
elapsed time: 0:00:07.093704
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-10-01 14:50:57.086456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2366.74
train mean loss: 2351.70
epoch train time: 0:00:00.175472
elapsed time: 0:00:07.269384
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-10-01 14:50:57.262071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2310.22
train mean loss: 2324.07
epoch train time: 0:00:00.174768
elapsed time: 0:00:07.444287
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-10-01 14:50:57.436974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2290.48
train mean loss: 2281.07
epoch train time: 0:00:00.176839
elapsed time: 0:00:07.621257
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-10-01 14:50:57.613951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2243.05
train mean loss: 2236.43
epoch train time: 0:00:00.183691
elapsed time: 0:00:07.805078
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-10-01 14:50:57.797785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2204.26
train mean loss: 2205.42
epoch train time: 0:00:00.178396
elapsed time: 0:00:07.983622
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-10-01 14:50:57.976311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2179.80
train mean loss: 2176.83
epoch train time: 0:00:00.184112
elapsed time: 0:00:08.167899
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-10-01 14:50:58.160586
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2130.15
train mean loss: 2122.61
epoch train time: 0:00:00.181541
elapsed time: 0:00:08.349582
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-10-01 14:50:58.342279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2102.97
train mean loss: 2097.79
epoch train time: 0:00:00.178625
elapsed time: 0:00:08.528346
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-10-01 14:50:58.521063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2068.12
train mean loss: 2065.51
epoch train time: 0:00:00.189016
elapsed time: 0:00:08.717536
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-10-01 14:50:58.710225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2030.83
train mean loss: 2037.25
epoch train time: 0:00:00.187168
elapsed time: 0:00:08.904850
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-10-01 14:50:58.897546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2015.71
train mean loss: 2027.10
epoch train time: 0:00:00.179159
elapsed time: 0:00:09.084144
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-10-01 14:50:59.076829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1961.40
train mean loss: 1972.69
epoch train time: 0:00:00.172029
elapsed time: 0:00:09.256377
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-10-01 14:50:59.249115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1942.97
train mean loss: 1945.93
epoch train time: 0:00:00.173949
elapsed time: 0:00:09.430519
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-10-01 14:50:59.423221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1906.35
train mean loss: 1913.56
epoch train time: 0:00:00.174453
elapsed time: 0:00:09.605143
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-10-01 14:50:59.597833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1894.06
train mean loss: 1897.31
epoch train time: 0:00:00.192266
elapsed time: 0:00:09.797556
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-10-01 14:50:59.790246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1870.50
train mean loss: 1867.37
epoch train time: 0:00:00.185673
elapsed time: 0:00:09.983358
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-10-01 14:50:59.976046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1836.20
train mean loss: 1842.24
epoch train time: 0:00:00.178174
elapsed time: 0:00:10.161666
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-10-01 14:51:00.154356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1810.75
train mean loss: 1810.35
epoch train time: 0:00:00.175786
elapsed time: 0:00:10.337597
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-10-01 14:51:00.330320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1772.83
train mean loss: 1778.46
epoch train time: 0:00:00.176614
elapsed time: 0:00:10.514384
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-10-01 14:51:00.507087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1762.41
train mean loss: 1759.69
epoch train time: 0:00:00.181126
elapsed time: 0:00:10.695653
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-10-01 14:51:00.688342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1725.07
train mean loss: 1738.34
epoch train time: 0:00:00.177864
elapsed time: 0:00:10.873667
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-10-01 14:51:00.866374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1703.67
train mean loss: 1712.90
epoch train time: 0:00:00.186340
elapsed time: 0:00:11.060166
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-10-01 14:51:01.052854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1691.03
train mean loss: 1692.99
epoch train time: 0:00:00.176251
elapsed time: 0:00:11.236543
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-10-01 14:51:01.229231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1661.92
train mean loss: 1667.29
epoch train time: 0:00:00.175799
elapsed time: 0:00:11.412470
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-10-01 14:51:01.405180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1658.98
train mean loss: 1650.37
epoch train time: 0:00:00.174877
elapsed time: 0:00:11.587494
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-10-01 14:51:01.580179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1611.29
train mean loss: 1619.11
epoch train time: 0:00:00.185683
elapsed time: 0:00:11.773302
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-10-01 14:51:01.765989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1595.02
train mean loss: 1601.76
epoch train time: 0:00:00.179629
elapsed time: 0:00:11.953058
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-10-01 14:51:01.945744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1588.13
train mean loss: 1585.61
epoch train time: 0:00:00.177670
elapsed time: 0:00:12.130864
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-10-01 14:51:02.123552
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1551.74
train mean loss: 1551.25
epoch train time: 0:00:00.176398
elapsed time: 0:00:12.307390
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-10-01 14:51:02.300077
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1538.19
train mean loss: 1545.44
epoch train time: 0:00:00.178270
elapsed time: 0:00:12.485790
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-10-01 14:51:02.478481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1516.18
train mean loss: 1513.12
epoch train time: 0:00:00.175198
elapsed time: 0:00:12.661136
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-10-01 14:51:02.653826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1492.23
train mean loss: 1498.87
epoch train time: 0:00:00.175631
elapsed time: 0:00:12.836895
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-10-01 14:51:02.829583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1480.26
train mean loss: 1485.57
epoch train time: 0:00:00.168879
elapsed time: 0:00:13.005939
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-10-01 14:51:02.998639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1443.94
train mean loss: 1439.27
epoch train time: 0:00:00.174874
elapsed time: 0:00:13.180952
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-10-01 14:51:03.173636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1424.42
train mean loss: 1420.32
epoch train time: 0:00:00.170244
elapsed time: 0:00:13.351323
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-10-01 14:51:03.344010
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1383.21
train mean loss: 1382.38
epoch train time: 0:00:00.172188
elapsed time: 0:00:13.523649
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-10-01 14:51:03.516352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1347.12
train mean loss: 1353.75
epoch train time: 0:00:00.179062
elapsed time: 0:00:13.703976
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-10-01 14:51:03.696705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1338.16
train mean loss: 1339.04
epoch train time: 0:00:00.197218
elapsed time: 0:00:13.901367
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-10-01 14:51:03.894063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1315.03
train mean loss: 1311.14
epoch train time: 0:00:00.179737
elapsed time: 0:00:14.081253
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-10-01 14:51:04.073940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1290.71
train mean loss: 1288.39
epoch train time: 0:00:00.171875
elapsed time: 0:00:14.253252
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-10-01 14:51:04.245935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1278.07
train mean loss: 1280.02
epoch train time: 0:00:00.172772
elapsed time: 0:00:14.426147
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-10-01 14:51:04.418835
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1248.20
train mean loss: 1252.83
epoch train time: 0:00:00.173662
elapsed time: 0:00:14.599927
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-10-01 14:51:04.592610
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1246.66
train mean loss: 1240.73
epoch train time: 0:00:00.171633
elapsed time: 0:00:14.771685
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-10-01 14:51:04.764372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1217.16
train mean loss: 1222.21
epoch train time: 0:00:00.175828
elapsed time: 0:00:14.947636
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-10-01 14:51:04.940324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1200.50
train mean loss: 1197.66
epoch train time: 0:00:00.179383
elapsed time: 0:00:15.127149
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-10-01 14:51:05.119837
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1175.91
train mean loss: 1179.67
epoch train time: 0:00:00.174899
elapsed time: 0:00:15.302173
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-10-01 14:51:05.294858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1167.18
train mean loss: 1174.63
epoch train time: 0:00:00.177999
elapsed time: 0:00:15.480388
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-10-01 14:51:05.473089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1147.78
train mean loss: 1145.68
epoch train time: 0:00:00.180551
elapsed time: 0:00:15.661153
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-10-01 14:51:05.653843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1130.61
train mean loss: 1126.97
epoch train time: 0:00:00.195284
elapsed time: 0:00:15.856565
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-10-01 14:51:05.849250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1108.98
train mean loss: 1108.65
epoch train time: 0:00:00.175181
elapsed time: 0:00:16.031873
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-10-01 14:51:06.024561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1090.13
train mean loss: 1089.70
epoch train time: 0:00:00.174759
elapsed time: 0:00:16.206757
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-10-01 14:51:06.199442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1077.63
train mean loss: 1075.44
epoch train time: 0:00:00.174610
elapsed time: 0:00:16.381494
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-10-01 14:51:06.374197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1056.99
train mean loss: 1058.11
epoch train time: 0:00:00.176267
elapsed time: 0:00:16.557903
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-10-01 14:51:06.550592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1036.15
train mean loss: 1037.22
epoch train time: 0:00:00.178290
elapsed time: 0:00:16.736328
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-10-01 14:51:06.729016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1022.59
train mean loss: 1027.69
epoch train time: 0:00:00.179188
elapsed time: 0:00:16.915640
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-10-01 14:51:06.908341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1018.43
train mean loss: 1012.36
epoch train time: 0:00:00.174251
elapsed time: 0:00:17.090034
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-10-01 14:51:07.082720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 987.97
train mean loss: 987.14
epoch train time: 0:00:00.172260
elapsed time: 0:00:17.262420
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-10-01 14:51:07.255126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 980.22
train mean loss: 974.17
epoch train time: 0:00:00.172364
elapsed time: 0:00:17.434927
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-10-01 14:51:07.427616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 958.84
train mean loss: 961.03
epoch train time: 0:00:00.173060
elapsed time: 0:00:17.608153
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-10-01 14:51:07.600840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 947.26
train mean loss: 950.22
epoch train time: 0:00:00.175366
elapsed time: 0:00:17.783649
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-10-01 14:51:07.776337
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 940.81
train mean loss: 931.71
epoch train time: 0:00:00.188046
elapsed time: 0:00:17.971819
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-10-01 14:51:07.964518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 918.36
train mean loss: 918.96
epoch train time: 0:00:00.173599
elapsed time: 0:00:18.145561
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-10-01 14:51:08.138248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 898.57
train mean loss: 898.56
epoch train time: 0:00:00.176665
elapsed time: 0:00:18.322359
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-10-01 14:51:08.315071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 889.29
train mean loss: 887.39
epoch train time: 0:00:00.182576
elapsed time: 0:00:18.505085
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-10-01 14:51:08.497792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.89
train mean loss: 873.01
epoch train time: 0:00:00.170165
elapsed time: 0:00:18.675405
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-10-01 14:51:08.668126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 858.51
train mean loss: 862.32
epoch train time: 0:00:00.185575
elapsed time: 0:00:18.861177
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-10-01 14:51:08.853876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 848.37
train mean loss: 848.67
epoch train time: 0:00:00.177186
elapsed time: 0:00:19.038512
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-10-01 14:51:09.031213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 835.95
train mean loss: 840.83
epoch train time: 0:00:00.175920
elapsed time: 0:00:19.214611
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-10-01 14:51:09.207310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 825.49
train mean loss: 820.84
epoch train time: 0:00:00.172802
elapsed time: 0:00:19.387577
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-10-01 14:51:09.380277
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 810.57
train mean loss: 810.71
epoch train time: 0:00:00.170460
elapsed time: 0:00:19.558175
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-10-01 14:51:09.550859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 796.00
train mean loss: 797.94
epoch train time: 0:00:00.175034
elapsed time: 0:00:19.733350
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-10-01 14:51:09.726036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 788.07
train mean loss: 778.49
epoch train time: 0:00:00.179717
elapsed time: 0:00:19.913221
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-10-01 14:51:09.905909
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 773.30
train mean loss: 771.85
epoch train time: 0:00:00.175964
elapsed time: 0:00:20.089316
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-10-01 14:51:10.082018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 762.99
train mean loss: 764.57
epoch train time: 0:00:00.177141
elapsed time: 0:00:20.266637
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-10-01 14:51:10.259325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 748.41
train mean loss: 745.63
epoch train time: 0:00:00.174651
elapsed time: 0:00:20.441457
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-10-01 14:51:10.434158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 743.63
train mean loss: 742.10
epoch train time: 0:00:00.178370
elapsed time: 0:00:20.619967
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-10-01 14:51:10.612655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 721.77
train mean loss: 713.79
epoch train time: 0:00:00.176685
elapsed time: 0:00:20.796782
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-10-01 14:51:10.789470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 713.24
train mean loss: 712.15
epoch train time: 0:00:00.193916
elapsed time: 0:00:20.990829
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-10-01 14:51:10.983516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 702.48
train mean loss: 709.54
epoch train time: 0:00:00.179281
elapsed time: 0:00:21.170252
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-10-01 14:51:11.162940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 690.35
train mean loss: 690.90
epoch train time: 0:00:00.181050
elapsed time: 0:00:21.351431
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-10-01 14:51:11.344119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 688.77
train mean loss: 683.70
epoch train time: 0:00:00.181279
elapsed time: 0:00:21.532859
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-10-01 14:51:11.525545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 671.18
train mean loss: 668.33
epoch train time: 0:00:00.190727
elapsed time: 0:00:21.723714
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-10-01 14:51:11.716402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 663.16
train mean loss: 665.26
epoch train time: 0:00:00.182369
elapsed time: 0:00:21.906291
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-10-01 14:51:11.898980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 655.52
train mean loss: 656.12
epoch train time: 0:00:00.180999
elapsed time: 0:00:22.087442
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-10-01 14:51:12.080132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 637.84
train mean loss: 644.52
epoch train time: 0:00:00.181394
elapsed time: 0:00:22.268971
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-10-01 14:51:12.261663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 629.07
train mean loss: 626.16
epoch train time: 0:00:00.181082
elapsed time: 0:00:22.450198
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-10-01 14:51:12.442885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 623.55
train mean loss: 621.94
epoch train time: 0:00:00.181363
elapsed time: 0:00:22.631701
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-10-01 14:51:12.624393
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 611.61
train mean loss: 611.22
epoch train time: 0:00:00.187954
elapsed time: 0:00:22.819822
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-10-01 14:51:12.812510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 602.56
train mean loss: 604.53
epoch train time: 0:00:00.180074
elapsed time: 0:00:23.000032
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-10-01 14:51:12.992722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 594.65
train mean loss: 591.08
epoch train time: 0:00:00.177816
elapsed time: 0:00:23.177980
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-10-01 14:51:13.170667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 592.04
train mean loss: 586.78
epoch train time: 0:00:00.175054
elapsed time: 0:00:23.353264
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-10-01 14:51:13.345951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 572.96
train mean loss: 572.47
epoch train time: 0:00:00.172337
elapsed time: 0:00:23.525721
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-10-01 14:51:13.518421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 557.23
train mean loss: 568.14
epoch train time: 0:00:00.173170
elapsed time: 0:00:23.699048
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-10-01 14:51:13.691735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 558.12
train mean loss: 556.31
epoch train time: 0:00:00.195471
elapsed time: 0:00:23.894650
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-10-01 14:51:13.887338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 551.10
train mean loss: 550.35
epoch train time: 0:00:00.175582
elapsed time: 0:00:24.070355
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-10-01 14:51:14.063040
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 536.06
train mean loss: 535.34
epoch train time: 0:00:00.177379
elapsed time: 0:00:24.247862
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-10-01 14:51:14.240549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 531.62
train mean loss: 530.71
epoch train time: 0:00:00.179053
elapsed time: 0:00:24.427044
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-10-01 14:51:14.419733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 527.65
train mean loss: 521.66
epoch train time: 0:00:00.184790
elapsed time: 0:00:24.611966
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-10-01 14:51:14.604656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 514.03
train mean loss: 512.64
epoch train time: 0:00:00.183251
elapsed time: 0:00:24.795348
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-10-01 14:51:14.788036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 506.07
train mean loss: 507.90
epoch train time: 0:00:00.186183
elapsed time: 0:00:24.981665
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-10-01 14:51:14.974354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 506.36
train mean loss: 501.92
epoch train time: 0:00:00.187684
elapsed time: 0:00:25.169487
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-10-01 14:51:15.162178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 495.04
train mean loss: 492.42
epoch train time: 0:00:00.189769
elapsed time: 0:00:25.359408
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-10-01 14:51:15.352099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 493.16
train mean loss: 489.70
epoch train time: 0:00:00.181566
elapsed time: 0:00:25.541146
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-10-01 14:51:15.533839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 481.75
train mean loss: 479.07
epoch train time: 0:00:00.183308
elapsed time: 0:00:25.724591
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-10-01 14:51:15.717282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 466.21
train mean loss: 467.12
epoch train time: 0:00:00.177584
elapsed time: 0:00:25.902306
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-10-01 14:51:15.894991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 463.34
train mean loss: 464.60
epoch train time: 0:00:00.176302
elapsed time: 0:00:26.078745
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-10-01 14:51:16.071431
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 458.71
train mean loss: 460.99
epoch train time: 0:00:00.177484
elapsed time: 0:00:26.256360
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-10-01 14:51:16.249049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 451.11
train mean loss: 452.62
epoch train time: 0:00:00.176631
elapsed time: 0:00:26.433160
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-10-01 14:51:16.425843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 440.34
train mean loss: 439.22
epoch train time: 0:00:00.176241
elapsed time: 0:00:26.609543
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-10-01 14:51:16.602232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 439.10
train mean loss: 441.69
epoch train time: 0:00:00.178957
elapsed time: 0:00:26.788631
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-10-01 14:51:16.781335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 429.92
train mean loss: 427.79
epoch train time: 0:00:00.177633
elapsed time: 0:00:26.966410
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-10-01 14:51:16.959098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 421.61
train mean loss: 422.16
epoch train time: 0:00:00.177780
elapsed time: 0:00:27.144317
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-10-01 14:51:17.137003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.02
train mean loss: 414.20
epoch train time: 0:00:00.178775
elapsed time: 0:00:27.323218
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-10-01 14:51:17.315907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 411.75
train mean loss: 407.95
epoch train time: 0:00:00.176360
elapsed time: 0:00:27.499718
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-10-01 14:51:17.492405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 404.33
train mean loss: 405.77
epoch train time: 0:00:00.175654
elapsed time: 0:00:27.675501
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-10-01 14:51:17.668189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 406.52
train mean loss: 404.80
epoch train time: 0:00:00.180726
elapsed time: 0:00:27.856360
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-10-01 14:51:17.849057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 398.85
train mean loss: 396.07
epoch train time: 0:00:00.173672
elapsed time: 0:00:28.030170
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-10-01 14:51:18.022855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 387.33
train mean loss: 385.92
epoch train time: 0:00:00.169553
elapsed time: 0:00:28.199843
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-10-01 14:51:18.192529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 376.61
train mean loss: 381.06
epoch train time: 0:00:00.170598
elapsed time: 0:00:28.370563
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-10-01 14:51:18.363248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 378.02
train mean loss: 378.73
epoch train time: 0:00:00.170816
elapsed time: 0:00:28.541504
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-10-01 14:51:18.534193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.49
train mean loss: 368.54
epoch train time: 0:00:00.176952
elapsed time: 0:00:28.718603
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-10-01 14:51:18.711307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 359.66
train mean loss: 359.21
epoch train time: 0:00:00.194143
elapsed time: 0:00:28.912888
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-10-01 14:51:18.905577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 359.35
train mean loss: 358.47
epoch train time: 0:00:00.174193
elapsed time: 0:00:29.087208
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-10-01 14:51:19.079895
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 352.80
train mean loss: 355.17
epoch train time: 0:00:00.177299
elapsed time: 0:00:29.264646
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-10-01 14:51:19.257334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.34
train mean loss: 352.31
epoch train time: 0:00:00.175295
elapsed time: 0:00:29.440061
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-10-01 14:51:19.432744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 344.67
train mean loss: 344.82
epoch train time: 0:00:00.171580
elapsed time: 0:00:29.611758
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-10-01 14:51:19.604442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 335.29
train mean loss: 337.44
epoch train time: 0:00:00.194606
elapsed time: 0:00:29.806488
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-10-01 14:51:19.799188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 334.40
train mean loss: 336.30
epoch train time: 0:00:00.174991
elapsed time: 0:00:29.981613
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-10-01 14:51:19.974298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 332.63
train mean loss: 331.93
epoch train time: 0:00:00.170068
elapsed time: 0:00:30.151804
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-10-01 14:51:20.144519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.21
train mean loss: 324.10
epoch train time: 0:00:00.172544
elapsed time: 0:00:30.324511
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-10-01 14:51:20.317188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.31
train mean loss: 322.04
epoch train time: 0:00:00.169444
elapsed time: 0:00:30.494063
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-10-01 14:51:20.486746
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.57
train mean loss: 319.26
epoch train time: 0:00:00.169632
elapsed time: 0:00:30.663811
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-10-01 14:51:20.656495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 310.17
train mean loss: 310.43
epoch train time: 0:00:00.181054
elapsed time: 0:00:30.844988
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-10-01 14:51:20.837679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.98
train mean loss: 306.66
epoch train time: 0:00:00.168673
elapsed time: 0:00:31.013789
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-10-01 14:51:21.006476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 304.42
train mean loss: 303.29
epoch train time: 0:00:00.168251
elapsed time: 0:00:31.182161
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-10-01 14:51:21.174845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.74
train mean loss: 297.84
epoch train time: 0:00:00.169284
elapsed time: 0:00:31.351565
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-10-01 14:51:21.344252
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.79
train mean loss: 291.94
epoch train time: 0:00:00.172264
elapsed time: 0:00:31.523957
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-10-01 14:51:21.516645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.43
train mean loss: 291.53
epoch train time: 0:00:00.170680
elapsed time: 0:00:31.694762
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-10-01 14:51:21.687448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.34
train mean loss: 286.21
epoch train time: 0:00:00.195270
elapsed time: 0:00:31.890165
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-10-01 14:51:21.882853
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.87
train mean loss: 282.76
epoch train time: 0:00:00.175624
elapsed time: 0:00:32.065932
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-10-01 14:51:22.058655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.93
train mean loss: 284.60
epoch train time: 0:00:00.173806
elapsed time: 0:00:32.239900
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-10-01 14:51:22.232601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.80
train mean loss: 269.85
epoch train time: 0:00:00.174473
elapsed time: 0:00:32.414514
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-10-01 14:51:22.407202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.78
train mean loss: 273.75
epoch train time: 0:00:00.172787
elapsed time: 0:00:32.587425
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-10-01 14:51:22.580111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.92
train mean loss: 265.26
epoch train time: 0:00:00.173275
elapsed time: 0:00:32.760853
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-10-01 14:51:22.753538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.16
train mean loss: 262.43
epoch train time: 0:00:00.183717
elapsed time: 0:00:32.944693
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-10-01 14:51:22.937377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.82
train mean loss: 259.48
epoch train time: 0:00:00.177528
elapsed time: 0:00:33.122354
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-10-01 14:51:23.115043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.40
train mean loss: 252.84
epoch train time: 0:00:00.180323
elapsed time: 0:00:33.302803
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-10-01 14:51:23.295505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.57
train mean loss: 249.18
epoch train time: 0:00:00.177534
elapsed time: 0:00:33.480488
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-10-01 14:51:23.473176
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.25
train mean loss: 248.44
epoch train time: 0:00:00.178081
elapsed time: 0:00:33.658734
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-10-01 14:51:23.651458
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.65
train mean loss: 247.98
epoch train time: 0:00:00.197472
elapsed time: 0:00:33.856370
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-10-01 14:51:23.849060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.90
train mean loss: 242.29
epoch train time: 0:00:00.177911
elapsed time: 0:00:34.034423
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-10-01 14:51:24.027125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.00
train mean loss: 244.47
epoch train time: 0:00:00.174722
elapsed time: 0:00:34.209298
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-10-01 14:51:24.201985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.90
train mean loss: 233.65
epoch train time: 0:00:00.173529
elapsed time: 0:00:34.382949
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-10-01 14:51:24.375641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.49
train mean loss: 237.67
epoch train time: 0:00:00.173856
elapsed time: 0:00:34.556944
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-10-01 14:51:24.549639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.71
train mean loss: 231.54
epoch train time: 0:00:00.181114
elapsed time: 0:00:34.738214
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-10-01 14:51:24.730901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.57
train mean loss: 227.92
epoch train time: 0:00:00.189402
elapsed time: 0:00:34.927747
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-10-01 14:51:24.920436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.43
train mean loss: 221.88
epoch train time: 0:00:00.176875
elapsed time: 0:00:35.104751
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-10-01 14:51:25.097467
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.04
train mean loss: 223.00
epoch train time: 0:00:00.174943
elapsed time: 0:00:35.279846
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-10-01 14:51:25.272532
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.55
train mean loss: 220.64
epoch train time: 0:00:00.178029
elapsed time: 0:00:35.458001
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-10-01 14:51:25.450717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.95
train mean loss: 212.56
epoch train time: 0:00:00.176060
elapsed time: 0:00:35.634213
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-10-01 14:51:25.626901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.06
train mean loss: 211.67
epoch train time: 0:00:00.176907
elapsed time: 0:00:35.811262
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-10-01 14:51:25.803954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.00
train mean loss: 211.84
epoch train time: 0:00:00.171975
elapsed time: 0:00:35.983363
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-10-01 14:51:25.976046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.19
train mean loss: 210.05
epoch train time: 0:00:00.168508
elapsed time: 0:00:36.151989
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-10-01 14:51:26.144676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.43
train mean loss: 204.84
epoch train time: 0:00:00.168151
elapsed time: 0:00:36.320275
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-10-01 14:51:26.312977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.11
train mean loss: 204.11
epoch train time: 0:00:00.172127
elapsed time: 0:00:36.492539
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-10-01 14:51:26.485241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 206.42
train mean loss: 205.04
epoch train time: 0:00:00.169538
elapsed time: 0:00:36.662221
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-10-01 14:51:26.654916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.62
train mean loss: 196.33
epoch train time: 0:00:00.182013
elapsed time: 0:00:36.844374
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-10-01 14:51:26.837069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.42
train mean loss: 198.17
epoch train time: 0:00:00.174025
elapsed time: 0:00:37.018536
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-10-01 14:51:27.011223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.58
train mean loss: 190.59
epoch train time: 0:00:00.173856
elapsed time: 0:00:37.192562
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-10-01 14:51:27.185265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.92
train mean loss: 191.26
epoch train time: 0:00:00.172535
elapsed time: 0:00:37.365238
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-10-01 14:51:27.357924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.18
train mean loss: 189.33
epoch train time: 0:00:00.173215
elapsed time: 0:00:37.538584
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-10-01 14:51:27.531288
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.10
train mean loss: 186.60
epoch train time: 0:00:00.171895
elapsed time: 0:00:37.710642
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-10-01 14:51:27.703341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.02
train mean loss: 180.59
epoch train time: 0:00:00.191729
elapsed time: 0:00:37.902541
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-10-01 14:51:27.895229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.67
train mean loss: 184.68
epoch train time: 0:00:00.175949
elapsed time: 0:00:38.078614
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-10-01 14:51:28.071310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.72
train mean loss: 180.87
epoch train time: 0:00:00.171913
elapsed time: 0:00:38.250654
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-10-01 14:51:28.243351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.41
train mean loss: 178.76
epoch train time: 0:00:00.175917
elapsed time: 0:00:38.426708
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-10-01 14:51:28.419397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.86
train mean loss: 173.45
epoch train time: 0:00:00.170913
elapsed time: 0:00:38.597739
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-10-01 14:51:28.590431
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.83
train mean loss: 174.00
epoch train time: 0:00:00.166897
elapsed time: 0:00:38.764758
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-10-01 14:51:28.757440
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.06
train mean loss: 172.53
epoch train time: 0:00:00.175198
elapsed time: 0:00:38.940101
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-10-01 14:51:28.932785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.04
train mean loss: 169.53
epoch train time: 0:00:00.177297
elapsed time: 0:00:39.117538
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-10-01 14:51:29.110227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.56
train mean loss: 169.99
epoch train time: 0:00:00.176443
elapsed time: 0:00:39.294100
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-10-01 14:51:29.286801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.20
train mean loss: 166.38
epoch train time: 0:00:00.177018
elapsed time: 0:00:39.471291
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-10-01 14:51:29.464000
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 165.43
train mean loss: 165.40
epoch train time: 0:00:00.174048
elapsed time: 0:00:39.645493
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-10-01 14:51:29.638171
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 164.04
train mean loss: 165.26
epoch train time: 0:00:00.182001
elapsed time: 0:00:39.827612
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-10-01 14:51:29.820317
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 163.85
train mean loss: 163.26
epoch train time: 0:00:00.181952
elapsed time: 0:00:40.009723
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-10-01 14:51:30.002426
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 165.11
train mean loss: 166.32
epoch train time: 0:00:00.173687
elapsed time: 0:00:40.183550
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-10-01 14:51:30.176237
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 164.35
train mean loss: 165.11
epoch train time: 0:00:00.175710
elapsed time: 0:00:40.359391
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-10-01 14:51:30.352081
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 164.41
train mean loss: 163.97
epoch train time: 0:00:00.190320
elapsed time: 0:00:40.549860
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-10-01 14:51:30.542571
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 163.90
train mean loss: 163.20
epoch train time: 0:00:00.189148
elapsed time: 0:00:40.739168
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-10-01 14:51:30.731859
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 163.83
train mean loss: 164.61
epoch train time: 0:00:00.189699
elapsed time: 0:00:40.929001
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-10-01 14:51:30.921690
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 162.64
train mean loss: 161.66
epoch train time: 0:00:00.179086
elapsed time: 0:00:41.108218
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-10-01 14:51:31.100909
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 163.80
train mean loss: 163.32
epoch train time: 0:00:00.178952
elapsed time: 0:00:41.287301
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-10-01 14:51:31.279990
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 163.45
train mean loss: 164.50
epoch train time: 0:00:00.180224
elapsed time: 0:00:41.467686
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-10-01 14:51:31.460406
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 166.16
train mean loss: 166.18
epoch train time: 0:00:00.175021
elapsed time: 0:00:41.642860
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-10-01 14:51:31.635545
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 162.23
train mean loss: 162.20
epoch train time: 0:00:00.175759
elapsed time: 0:00:41.818742
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-10-01 14:51:31.811429
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.82
train mean loss: 161.56
epoch train time: 0:00:00.181913
elapsed time: 0:00:42.000778
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-10-01 14:51:31.993463
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 162.42
train mean loss: 162.74
epoch train time: 0:00:00.173524
elapsed time: 0:00:42.174426
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-10-01 14:51:32.167150
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 162.40
train mean loss: 161.91
epoch train time: 0:00:00.172477
elapsed time: 0:00:42.347057
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-10-01 14:51:32.339743
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.29
train mean loss: 160.76
epoch train time: 0:00:00.178107
elapsed time: 0:00:42.525292
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-10-01 14:51:32.517978
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 159.88
train mean loss: 161.84
epoch train time: 0:00:00.177346
elapsed time: 0:00:42.702763
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-10-01 14:51:32.695449
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.77
train mean loss: 160.23
epoch train time: 0:00:00.175882
elapsed time: 0:00:42.878769
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-10-01 14:51:32.871452
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.53
train mean loss: 159.61
epoch train time: 0:00:00.172870
elapsed time: 0:00:43.051757
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-10-01 14:51:33.044459
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.74
train mean loss: 159.10
epoch train time: 0:00:00.169974
elapsed time: 0:00:43.221865
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-10-01 14:51:33.214564
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 161.12
train mean loss: 160.11
epoch train time: 0:00:00.168990
elapsed time: 0:00:43.390987
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-10-01 14:51:33.383670
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.70
train mean loss: 159.36
epoch train time: 0:00:00.188133
elapsed time: 0:00:43.579245
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-10-01 14:51:33.571933
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.69
train mean loss: 158.05
epoch train time: 0:00:00.176594
elapsed time: 0:00:43.755967
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-10-01 14:51:33.748657
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.87
train mean loss: 160.72
epoch train time: 0:00:00.176373
elapsed time: 0:00:43.932469
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-10-01 14:51:33.925155
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 158.77
train mean loss: 160.04
epoch train time: 0:00:00.166667
elapsed time: 0:00:44.100014
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-10-01 14:51:34.092717
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 161.05
train mean loss: 159.98
epoch train time: 0:00:00.169716
elapsed time: 0:00:44.269890
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-10-01 14:51:34.262603
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.56
train mean loss: 160.20
epoch train time: 0:00:00.167710
elapsed time: 0:00:44.437758
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-10-01 14:51:34.430455
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.68
train mean loss: 159.20
epoch train time: 0:00:00.168206
elapsed time: 0:00:44.606109
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-10-01 14:51:34.598824
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 158.98
train mean loss: 160.04
epoch train time: 0:00:00.167251
elapsed time: 0:00:44.773506
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-10-01 14:51:34.766206
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.81
train mean loss: 156.88
epoch train time: 0:00:00.179945
elapsed time: 0:00:44.953603
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-10-01 14:51:34.946289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 158.36
train mean loss: 156.70
epoch train time: 0:00:00.174951
elapsed time: 0:00:45.128688
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-10-01 14:51:35.121374
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 159.62
train mean loss: 160.09
epoch train time: 0:00:00.175352
elapsed time: 0:00:45.304191
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-10-01 14:51:35.296871
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 159.05
train mean loss: 160.01
epoch train time: 0:00:00.175089
elapsed time: 0:00:45.479396
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-10-01 14:51:35.472080
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.18
train mean loss: 159.68
epoch train time: 0:00:00.173565
elapsed time: 0:00:45.653079
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-10-01 14:51:35.645793
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 160.64
train mean loss: 160.47
epoch train time: 0:00:00.192037
elapsed time: 0:00:45.845273
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-10-01 14:51:35.837959
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 159.31
train mean loss: 158.08
epoch train time: 0:00:00.172316
elapsed time: 0:00:46.017715
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-10-01 14:51:36.010400
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 161.04
train mean loss: 160.42
epoch train time: 0:00:00.170963
elapsed time: 0:00:46.188817
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-10-01 14:51:36.181533
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.71
train mean loss: 154.78
epoch train time: 0:00:00.169350
elapsed time: 0:00:46.358331
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-10-01 14:51:36.351029
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.23
train mean loss: 156.11
epoch train time: 0:00:00.171094
elapsed time: 0:00:46.529561
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-10-01 14:51:36.522244
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.75
train mean loss: 158.04
epoch train time: 0:00:00.172095
elapsed time: 0:00:46.701776
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-10-01 14:51:36.694460
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.09
train mean loss: 156.54
epoch train time: 0:00:00.179502
elapsed time: 0:00:46.881407
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-10-01 14:51:36.874105
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.17
train mean loss: 156.43
epoch train time: 0:00:00.170376
elapsed time: 0:00:47.051915
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-10-01 14:51:37.044599
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 156.11
train mean loss: 157.03
epoch train time: 0:00:00.170256
elapsed time: 0:00:47.222290
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-10-01 14:51:37.214974
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.75
train mean loss: 157.85
epoch train time: 0:00:00.170233
elapsed time: 0:00:47.392654
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-10-01 14:51:37.385336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 157.38
train mean loss: 155.85
epoch train time: 0:00:00.173590
elapsed time: 0:00:47.566367
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-10-01 14:51:37.559052
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 152.40
train mean loss: 151.54
epoch train time: 0:00:00.174982
elapsed time: 0:00:47.741473
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-10-01 14:51:37.734158
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 155.17
train mean loss: 156.88
epoch train time: 0:00:00.169256
elapsed time: 0:00:47.910847
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-10-01 14:51:37.903532
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.42
train mean loss: 151.97
epoch train time: 0:00:00.168211
elapsed time: 0:00:48.086456
checkpoint saved in file: log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_9/checkpoint.pth.tar
**** end time: 2019-10-01 14:51:38.079115 ****
