Namespace(batch_size=512, dataset='CMAPSS/FD003', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_0', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.25, resume=False, step_size=200, visualize_step=50)
pid: 23283
use_cuda: True
Dataset: CMAPSS/FD003
Building BayesianDense3...
Done.
**** start time: 2019-10-01 14:40:34.517333 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-10-01 14:40:34.527074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4610.05
train mean loss: 4586.78
epoch train time: 0:00:03.907086
elapsed time: 0:00:03.922830
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-10-01 14:40:38.440202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4371.56
train mean loss: 4340.75
epoch train time: 0:00:00.177789
elapsed time: 0:00:04.100802
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-10-01 14:40:38.618197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4075.19
train mean loss: 4074.34
epoch train time: 0:00:00.182466
elapsed time: 0:00:04.283423
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-10-01 14:40:38.800821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3809.11
train mean loss: 3820.15
epoch train time: 0:00:00.183782
elapsed time: 0:00:04.467346
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-10-01 14:40:38.984721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3611.50
train mean loss: 3583.22
epoch train time: 0:00:00.169364
elapsed time: 0:00:04.636873
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-10-01 14:40:39.154307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3399.53
train mean loss: 3403.23
epoch train time: 0:00:00.171548
elapsed time: 0:00:04.808597
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-10-01 14:40:39.325973
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3236.18
train mean loss: 3237.97
epoch train time: 0:00:00.173214
elapsed time: 0:00:04.981938
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-10-01 14:40:39.499314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3105.90
train mean loss: 3096.00
epoch train time: 0:00:00.179014
elapsed time: 0:00:05.161088
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-10-01 14:40:39.678465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2982.61
train mean loss: 2969.73
epoch train time: 0:00:00.176923
elapsed time: 0:00:05.338147
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-10-01 14:40:39.855538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2852.17
train mean loss: 2862.80
epoch train time: 0:00:00.171820
elapsed time: 0:00:05.510098
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-10-01 14:40:40.027474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2774.23
train mean loss: 2778.63
epoch train time: 0:00:00.171087
elapsed time: 0:00:05.681321
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-10-01 14:40:40.198717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2709.61
train mean loss: 2696.62
epoch train time: 0:00:00.172592
elapsed time: 0:00:05.854071
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-10-01 14:40:40.371463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2636.03
train mean loss: 2624.05
epoch train time: 0:00:00.171952
elapsed time: 0:00:06.026164
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-10-01 14:40:40.543541
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2579.85
train mean loss: 2567.88
epoch train time: 0:00:00.177539
elapsed time: 0:00:06.203847
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-10-01 14:40:40.721246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2503.42
train mean loss: 2508.74
epoch train time: 0:00:00.182997
elapsed time: 0:00:06.386990
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-10-01 14:40:40.904369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2459.16
train mean loss: 2460.39
epoch train time: 0:00:00.170575
elapsed time: 0:00:06.557697
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-10-01 14:40:41.075120
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2426.38
train mean loss: 2414.80
epoch train time: 0:00:00.171605
elapsed time: 0:00:06.729498
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-10-01 14:40:41.246881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2369.66
train mean loss: 2369.33
epoch train time: 0:00:00.171912
elapsed time: 0:00:06.901541
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-10-01 14:40:41.418920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2337.40
train mean loss: 2331.69
epoch train time: 0:00:00.172635
elapsed time: 0:00:07.074359
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-10-01 14:40:41.591749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2292.05
train mean loss: 2283.09
epoch train time: 0:00:00.175946
elapsed time: 0:00:07.250470
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-10-01 14:40:41.767852
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2242.94
train mean loss: 2253.42
epoch train time: 0:00:00.176057
elapsed time: 0:00:07.426654
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-10-01 14:40:41.944029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2223.77
train mean loss: 2215.72
epoch train time: 0:00:00.172550
elapsed time: 0:00:07.599321
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-10-01 14:40:42.116698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2182.94
train mean loss: 2170.04
epoch train time: 0:00:00.172553
elapsed time: 0:00:07.771991
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-10-01 14:40:42.289368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2163.14
train mean loss: 2158.40
epoch train time: 0:00:00.174657
elapsed time: 0:00:07.946775
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-10-01 14:40:42.464153
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2135.01
train mean loss: 2130.04
epoch train time: 0:00:00.173453
elapsed time: 0:00:08.120357
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-10-01 14:40:42.637748
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2103.99
train mean loss: 2096.32
epoch train time: 0:00:00.186402
elapsed time: 0:00:08.306925
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-10-01 14:40:42.824365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2061.47
train mean loss: 2058.17
epoch train time: 0:00:00.168770
elapsed time: 0:00:08.475874
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-10-01 14:40:42.993248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2037.53
train mean loss: 2033.33
epoch train time: 0:00:00.165660
elapsed time: 0:00:08.641645
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-10-01 14:40:43.159034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2000.33
train mean loss: 2006.27
epoch train time: 0:00:00.165115
elapsed time: 0:00:08.806899
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-10-01 14:40:43.324289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1969.70
train mean loss: 1982.01
epoch train time: 0:00:00.168705
elapsed time: 0:00:08.975738
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-10-01 14:40:43.493130
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1925.66
train mean loss: 1930.60
epoch train time: 0:00:00.167937
elapsed time: 0:00:09.143818
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-10-01 14:40:43.661197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1903.86
train mean loss: 1904.83
epoch train time: 0:00:00.181249
elapsed time: 0:00:09.325197
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-10-01 14:40:43.842575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1882.29
train mean loss: 1887.40
epoch train time: 0:00:00.171917
elapsed time: 0:00:09.497237
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-10-01 14:40:44.014613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1848.79
train mean loss: 1848.57
epoch train time: 0:00:00.171978
elapsed time: 0:00:09.669359
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-10-01 14:40:44.186756
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1828.47
train mean loss: 1825.95
epoch train time: 0:00:00.169811
elapsed time: 0:00:09.839307
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-10-01 14:40:44.356695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1795.78
train mean loss: 1799.29
epoch train time: 0:00:00.173024
elapsed time: 0:00:10.012522
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-10-01 14:40:44.529906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1757.43
train mean loss: 1753.78
epoch train time: 0:00:00.173789
elapsed time: 0:00:10.186465
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-10-01 14:40:44.703853
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1746.75
train mean loss: 1753.68
epoch train time: 0:00:00.191982
elapsed time: 0:00:10.378584
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-10-01 14:40:44.895960
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1730.47
train mean loss: 1732.85
epoch train time: 0:00:00.172700
elapsed time: 0:00:10.551404
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-10-01 14:40:45.068779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1705.36
train mean loss: 1718.37
epoch train time: 0:00:00.171554
elapsed time: 0:00:10.723070
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-10-01 14:40:45.240444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1673.83
train mean loss: 1683.54
epoch train time: 0:00:00.172257
elapsed time: 0:00:10.895449
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-10-01 14:40:45.412855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1644.62
train mean loss: 1645.78
epoch train time: 0:00:00.172161
elapsed time: 0:00:11.067766
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-10-01 14:40:45.585143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1624.89
train mean loss: 1628.70
epoch train time: 0:00:00.172217
elapsed time: 0:00:11.240109
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-10-01 14:40:45.757486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1615.29
train mean loss: 1608.89
epoch train time: 0:00:00.173411
elapsed time: 0:00:11.413640
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-10-01 14:40:45.931015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1564.61
train mean loss: 1572.29
epoch train time: 0:00:00.169521
elapsed time: 0:00:11.583278
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-10-01 14:40:46.100653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1534.07
train mean loss: 1542.86
epoch train time: 0:00:00.168761
elapsed time: 0:00:11.752153
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-10-01 14:40:46.269528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1526.35
train mean loss: 1521.60
epoch train time: 0:00:00.167760
elapsed time: 0:00:11.920036
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-10-01 14:40:46.437416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1489.10
train mean loss: 1485.41
epoch train time: 0:00:00.171527
elapsed time: 0:00:12.091699
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-10-01 14:40:46.609081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1457.55
train mean loss: 1459.54
epoch train time: 0:00:00.196921
elapsed time: 0:00:12.288758
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-10-01 14:40:46.806141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1432.66
train mean loss: 1428.38
epoch train time: 0:00:00.178267
elapsed time: 0:00:12.467154
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-10-01 14:40:46.984544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1404.72
train mean loss: 1412.82
epoch train time: 0:00:00.167502
elapsed time: 0:00:12.634790
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-10-01 14:40:47.152166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1368.51
train mean loss: 1373.41
epoch train time: 0:00:00.165273
elapsed time: 0:00:12.800172
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-10-01 14:40:47.317544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1359.34
train mean loss: 1350.05
epoch train time: 0:00:00.171597
elapsed time: 0:00:12.971891
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-10-01 14:40:47.489266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1331.41
train mean loss: 1330.40
epoch train time: 0:00:00.170874
elapsed time: 0:00:13.142886
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-10-01 14:40:47.660260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1312.10
train mean loss: 1308.14
epoch train time: 0:00:00.177221
elapsed time: 0:00:13.320229
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-10-01 14:40:47.837606
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1296.54
train mean loss: 1299.49
epoch train time: 0:00:00.174988
elapsed time: 0:00:13.495339
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-10-01 14:40:48.012715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1278.67
train mean loss: 1279.31
epoch train time: 0:00:00.165526
elapsed time: 0:00:13.660970
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-10-01 14:40:48.178342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1254.84
train mean loss: 1253.67
epoch train time: 0:00:00.164247
elapsed time: 0:00:13.825320
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-10-01 14:40:48.342708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1241.33
train mean loss: 1235.77
epoch train time: 0:00:00.184343
elapsed time: 0:00:14.009829
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-10-01 14:40:48.527213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1209.17
train mean loss: 1210.84
epoch train time: 0:00:00.175420
elapsed time: 0:00:14.185376
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-10-01 14:40:48.702749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1180.16
train mean loss: 1186.11
epoch train time: 0:00:00.177330
elapsed time: 0:00:14.362837
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-10-01 14:40:48.880225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1171.33
train mean loss: 1169.61
epoch train time: 0:00:00.175081
elapsed time: 0:00:14.538053
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-10-01 14:40:49.055431
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1151.25
train mean loss: 1152.60
epoch train time: 0:00:00.172071
elapsed time: 0:00:14.710239
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-10-01 14:40:49.227615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1137.97
train mean loss: 1139.41
epoch train time: 0:00:00.169576
elapsed time: 0:00:14.879926
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-10-01 14:40:49.397309
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1119.18
train mean loss: 1121.40
epoch train time: 0:00:00.166897
elapsed time: 0:00:15.046974
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-10-01 14:40:49.564347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1105.35
train mean loss: 1105.72
epoch train time: 0:00:00.167156
elapsed time: 0:00:15.214271
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-10-01 14:40:49.731679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1083.44
train mean loss: 1076.48
epoch train time: 0:00:00.174447
elapsed time: 0:00:15.388875
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-10-01 14:40:49.906251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1067.51
train mean loss: 1065.37
epoch train time: 0:00:00.174208
elapsed time: 0:00:15.563236
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-10-01 14:40:50.080623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1044.77
train mean loss: 1045.54
epoch train time: 0:00:00.169681
elapsed time: 0:00:15.733069
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-10-01 14:40:50.250443
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1030.08
train mean loss: 1026.75
epoch train time: 0:00:00.173439
elapsed time: 0:00:15.906636
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-10-01 14:40:50.424009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1019.45
train mean loss: 1017.51
epoch train time: 0:00:00.173644
elapsed time: 0:00:16.080396
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-10-01 14:40:50.597815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 991.99
train mean loss: 995.94
epoch train time: 0:00:00.185423
elapsed time: 0:00:16.266019
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-10-01 14:40:50.783424
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 979.61
train mean loss: 982.03
epoch train time: 0:00:00.176663
elapsed time: 0:00:16.442864
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-10-01 14:40:50.960257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 961.63
train mean loss: 963.39
epoch train time: 0:00:00.168868
elapsed time: 0:00:16.611858
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-10-01 14:40:51.129271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 941.45
train mean loss: 937.28
epoch train time: 0:00:00.169529
elapsed time: 0:00:16.781550
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-10-01 14:40:51.298926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 938.80
train mean loss: 934.78
epoch train time: 0:00:00.173290
elapsed time: 0:00:16.954959
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-10-01 14:40:51.472334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 925.95
train mean loss: 920.87
epoch train time: 0:00:00.175952
elapsed time: 0:00:17.131031
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-10-01 14:40:51.648406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 912.62
train mean loss: 913.23
epoch train time: 0:00:00.174319
elapsed time: 0:00:17.305479
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-10-01 14:40:51.822857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 881.94
train mean loss: 884.50
epoch train time: 0:00:00.181808
elapsed time: 0:00:17.487428
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-10-01 14:40:52.004805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.22
train mean loss: 864.59
epoch train time: 0:00:00.173904
elapsed time: 0:00:17.661446
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-10-01 14:40:52.178821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 863.33
train mean loss: 865.69
epoch train time: 0:00:00.172448
elapsed time: 0:00:17.834043
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-10-01 14:40:52.351418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 847.36
train mean loss: 845.89
epoch train time: 0:00:00.177323
elapsed time: 0:00:18.011497
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-10-01 14:40:52.528873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 832.46
train mean loss: 830.41
epoch train time: 0:00:00.175364
elapsed time: 0:00:18.186995
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-10-01 14:40:52.704372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 816.45
train mean loss: 815.51
epoch train time: 0:00:00.183559
elapsed time: 0:00:18.370674
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-10-01 14:40:52.888050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 808.69
train mean loss: 810.70
epoch train time: 0:00:00.177744
elapsed time: 0:00:18.548548
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-10-01 14:40:53.065957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 794.93
train mean loss: 796.65
epoch train time: 0:00:00.171894
elapsed time: 0:00:18.720589
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-10-01 14:40:53.237961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 779.31
train mean loss: 782.12
epoch train time: 0:00:00.170628
elapsed time: 0:00:18.891371
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-10-01 14:40:53.408756
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 769.06
train mean loss: 765.35
epoch train time: 0:00:00.170675
elapsed time: 0:00:19.062169
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-10-01 14:40:53.579557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 751.41
train mean loss: 752.99
epoch train time: 0:00:00.172968
elapsed time: 0:00:19.235280
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-10-01 14:40:53.752664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 738.29
train mean loss: 745.00
epoch train time: 0:00:00.171957
elapsed time: 0:00:19.407362
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-10-01 14:40:53.924753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 732.77
train mean loss: 724.08
epoch train time: 0:00:00.175558
elapsed time: 0:00:19.583058
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-10-01 14:40:54.100433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 718.37
train mean loss: 723.28
epoch train time: 0:00:00.171544
elapsed time: 0:00:19.754714
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-10-01 14:40:54.272141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 704.26
train mean loss: 705.46
epoch train time: 0:00:00.174115
elapsed time: 0:00:19.928999
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-10-01 14:40:54.446373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 698.41
train mean loss: 696.23
epoch train time: 0:00:00.170266
elapsed time: 0:00:20.099430
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-10-01 14:40:54.616806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 687.62
train mean loss: 686.24
epoch train time: 0:00:00.192875
elapsed time: 0:00:20.292466
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-10-01 14:40:54.809845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 682.07
train mean loss: 676.86
epoch train time: 0:00:00.174258
elapsed time: 0:00:20.466846
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-10-01 14:40:54.984220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 662.09
train mean loss: 662.15
epoch train time: 0:00:00.173611
elapsed time: 0:00:20.640597
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-10-01 14:40:55.157989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 643.69
train mean loss: 651.57
epoch train time: 0:00:00.171155
elapsed time: 0:00:20.811879
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-10-01 14:40:55.329251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 641.90
train mean loss: 644.36
epoch train time: 0:00:00.172434
elapsed time: 0:00:20.984449
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-10-01 14:40:55.501828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 630.40
train mean loss: 627.03
epoch train time: 0:00:00.173601
elapsed time: 0:00:21.158180
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-10-01 14:40:55.675557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 626.12
train mean loss: 625.61
epoch train time: 0:00:00.172845
elapsed time: 0:00:21.331145
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-10-01 14:40:55.848520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 613.87
train mean loss: 614.22
epoch train time: 0:00:00.172039
elapsed time: 0:00:21.503312
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-10-01 14:40:56.020685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 606.23
train mean loss: 606.29
epoch train time: 0:00:00.174523
elapsed time: 0:00:21.677965
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-10-01 14:40:56.195353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 595.45
train mean loss: 599.01
epoch train time: 0:00:00.170257
elapsed time: 0:00:21.848348
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-10-01 14:40:56.365721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 592.92
train mean loss: 590.31
epoch train time: 0:00:00.172884
elapsed time: 0:00:22.021345
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-10-01 14:40:56.538720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 574.36
train mean loss: 572.82
epoch train time: 0:00:00.176659
elapsed time: 0:00:22.198136
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-10-01 14:40:56.715522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 568.02
train mean loss: 567.29
epoch train time: 0:00:00.199398
elapsed time: 0:00:22.397680
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-10-01 14:40:56.915049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 559.33
train mean loss: 561.37
epoch train time: 0:00:00.176196
elapsed time: 0:00:22.574000
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-10-01 14:40:57.091380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 557.84
train mean loss: 554.32
epoch train time: 0:00:00.176130
elapsed time: 0:00:22.750264
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-10-01 14:40:57.267641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 548.18
train mean loss: 547.56
epoch train time: 0:00:00.172254
elapsed time: 0:00:22.922644
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-10-01 14:40:57.440023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 531.50
train mean loss: 533.07
epoch train time: 0:00:00.176789
elapsed time: 0:00:23.099555
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-10-01 14:40:57.616930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 523.49
train mean loss: 525.92
epoch train time: 0:00:00.173372
elapsed time: 0:00:23.273049
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-10-01 14:40:57.790426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 511.26
train mean loss: 511.03
epoch train time: 0:00:00.173520
elapsed time: 0:00:23.446689
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-10-01 14:40:57.964066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 514.41
train mean loss: 512.00
epoch train time: 0:00:00.173168
elapsed time: 0:00:23.619991
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-10-01 14:40:58.137378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 498.96
train mean loss: 498.58
epoch train time: 0:00:00.174397
elapsed time: 0:00:23.794525
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-10-01 14:40:58.311910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 491.48
train mean loss: 487.20
epoch train time: 0:00:00.174079
elapsed time: 0:00:23.968746
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-10-01 14:40:58.486130
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 493.70
train mean loss: 488.62
epoch train time: 0:00:00.171846
elapsed time: 0:00:24.140722
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-10-01 14:40:58.658096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.18
train mean loss: 471.00
epoch train time: 0:00:00.193845
elapsed time: 0:00:24.334695
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-10-01 14:40:58.852113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 469.85
train mean loss: 470.12
epoch train time: 0:00:00.179126
elapsed time: 0:00:24.513982
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-10-01 14:40:59.031357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 466.36
train mean loss: 462.96
epoch train time: 0:00:00.172511
elapsed time: 0:00:24.686617
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-10-01 14:40:59.203996
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 459.02
train mean loss: 455.50
epoch train time: 0:00:00.171890
elapsed time: 0:00:24.858651
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-10-01 14:40:59.376031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 442.35
train mean loss: 441.20
epoch train time: 0:00:00.172731
elapsed time: 0:00:25.031511
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-10-01 14:40:59.548886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 446.65
train mean loss: 443.67
epoch train time: 0:00:00.171669
elapsed time: 0:00:25.203326
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-10-01 14:40:59.720700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 439.31
train mean loss: 439.62
epoch train time: 0:00:00.172137
elapsed time: 0:00:25.375579
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-10-01 14:40:59.892952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 428.05
train mean loss: 426.17
epoch train time: 0:00:00.172146
elapsed time: 0:00:25.547845
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-10-01 14:41:00.065224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 421.70
train mean loss: 424.09
epoch train time: 0:00:00.173748
elapsed time: 0:00:25.721721
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-10-01 14:41:00.239102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 409.11
train mean loss: 407.80
epoch train time: 0:00:00.176281
elapsed time: 0:00:25.898141
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-10-01 14:41:00.415510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.34
train mean loss: 406.73
epoch train time: 0:00:00.175963
elapsed time: 0:00:26.074215
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-10-01 14:41:00.591587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 399.86
train mean loss: 401.66
epoch train time: 0:00:00.185322
elapsed time: 0:00:26.259661
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-10-01 14:41:00.777042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 401.33
train mean loss: 402.35
epoch train time: 0:00:00.177099
elapsed time: 0:00:26.436888
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-10-01 14:41:00.954267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 388.97
train mean loss: 391.56
epoch train time: 0:00:00.174319
elapsed time: 0:00:26.611327
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-10-01 14:41:01.128707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 384.53
train mean loss: 383.20
epoch train time: 0:00:00.176919
elapsed time: 0:00:26.788374
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-10-01 14:41:01.305750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 378.46
train mean loss: 375.50
epoch train time: 0:00:00.172839
elapsed time: 0:00:26.961332
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-10-01 14:41:01.478710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.69
train mean loss: 374.67
epoch train time: 0:00:00.171423
elapsed time: 0:00:27.132876
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-10-01 14:41:01.650250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 366.05
train mean loss: 364.56
epoch train time: 0:00:00.172622
elapsed time: 0:00:27.305624
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-10-01 14:41:01.823042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.28
train mean loss: 364.81
epoch train time: 0:00:00.169960
elapsed time: 0:00:27.475762
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-10-01 14:41:01.993137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 360.34
train mean loss: 359.41
epoch train time: 0:00:00.167582
elapsed time: 0:00:27.643461
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-10-01 14:41:02.160846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.74
train mean loss: 353.59
epoch train time: 0:00:00.170438
elapsed time: 0:00:27.814042
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-10-01 14:41:02.331452
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.31
train mean loss: 346.34
epoch train time: 0:00:00.168883
elapsed time: 0:00:27.983124
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-10-01 14:41:02.500513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 336.55
train mean loss: 335.92
epoch train time: 0:00:00.170270
elapsed time: 0:00:28.153539
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-10-01 14:41:02.670956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 335.72
train mean loss: 335.08
epoch train time: 0:00:00.191097
elapsed time: 0:00:28.344799
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-10-01 14:41:02.862172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.10
train mean loss: 330.82
epoch train time: 0:00:00.166150
elapsed time: 0:00:28.511065
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-10-01 14:41:03.028456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.27
train mean loss: 326.23
epoch train time: 0:00:00.166598
elapsed time: 0:00:28.677795
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-10-01 14:41:03.195335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.79
train mean loss: 316.20
epoch train time: 0:00:00.166074
elapsed time: 0:00:28.844168
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-10-01 14:41:03.361549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 313.13
train mean loss: 313.43
epoch train time: 0:00:00.169356
elapsed time: 0:00:29.013655
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-10-01 14:41:03.531038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.15
train mean loss: 306.44
epoch train time: 0:00:00.177287
elapsed time: 0:00:29.191072
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-10-01 14:41:03.708449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 307.58
train mean loss: 308.42
epoch train time: 0:00:00.169420
elapsed time: 0:00:29.360616
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-10-01 14:41:03.877992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.50
train mean loss: 305.45
epoch train time: 0:00:00.167412
elapsed time: 0:00:29.528140
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-10-01 14:41:04.045516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.96
train mean loss: 290.47
epoch train time: 0:00:00.167888
elapsed time: 0:00:29.696162
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-10-01 14:41:04.213529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.07
train mean loss: 291.05
epoch train time: 0:00:00.170236
elapsed time: 0:00:29.866524
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-10-01 14:41:04.383904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.84
train mean loss: 285.08
epoch train time: 0:00:00.170013
elapsed time: 0:00:30.036656
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-10-01 14:41:04.554029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.16
train mean loss: 284.26
epoch train time: 0:00:00.169453
elapsed time: 0:00:30.206228
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-10-01 14:41:04.723604
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.85
train mean loss: 274.55
epoch train time: 0:00:00.166909
elapsed time: 0:00:30.373251
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-10-01 14:41:04.890624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.28
train mean loss: 271.93
epoch train time: 0:00:00.165486
elapsed time: 0:00:30.538858
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-10-01 14:41:05.056233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.54
train mean loss: 271.82
epoch train time: 0:00:00.167417
elapsed time: 0:00:30.706418
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-10-01 14:41:05.223791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.06
train mean loss: 262.81
epoch train time: 0:00:00.163268
elapsed time: 0:00:30.869799
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-10-01 14:41:05.387173
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.31
train mean loss: 260.22
epoch train time: 0:00:00.174340
elapsed time: 0:00:31.044262
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-10-01 14:41:05.561642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.41
train mean loss: 257.27
epoch train time: 0:00:00.177775
elapsed time: 0:00:31.222170
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-10-01 14:41:05.739558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.21
train mean loss: 254.04
epoch train time: 0:00:00.176612
elapsed time: 0:00:31.398915
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-10-01 14:41:05.916289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.48
train mean loss: 248.93
epoch train time: 0:00:00.167847
elapsed time: 0:00:31.566878
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-10-01 14:41:06.084296
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.00
train mean loss: 245.15
epoch train time: 0:00:00.165813
elapsed time: 0:00:31.732847
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-10-01 14:41:06.250222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.92
train mean loss: 241.37
epoch train time: 0:00:00.167367
elapsed time: 0:00:31.900334
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-10-01 14:41:06.417711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.22
train mean loss: 240.29
epoch train time: 0:00:00.172154
elapsed time: 0:00:32.072611
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-10-01 14:41:06.589985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.53
train mean loss: 230.74
epoch train time: 0:00:00.169514
elapsed time: 0:00:32.242259
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-10-01 14:41:06.759635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.20
train mean loss: 227.71
epoch train time: 0:00:00.170325
elapsed time: 0:00:32.412722
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-10-01 14:41:06.930096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.14
train mean loss: 229.76
epoch train time: 0:00:00.170790
elapsed time: 0:00:32.583659
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-10-01 14:41:07.101036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.39
train mean loss: 227.52
epoch train time: 0:00:00.168469
elapsed time: 0:00:32.752242
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-10-01 14:41:07.269615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.07
train mean loss: 222.57
epoch train time: 0:00:00.166821
elapsed time: 0:00:32.919174
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-10-01 14:41:07.436547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.88
train mean loss: 217.56
epoch train time: 0:00:00.173310
elapsed time: 0:00:33.092606
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-10-01 14:41:07.609982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.21
train mean loss: 219.57
epoch train time: 0:00:00.185621
elapsed time: 0:00:33.278348
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-10-01 14:41:07.795726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.76
train mean loss: 215.86
epoch train time: 0:00:00.167799
elapsed time: 0:00:33.446283
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-10-01 14:41:07.963656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.61
train mean loss: 211.32
epoch train time: 0:00:00.165422
elapsed time: 0:00:33.611826
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-10-01 14:41:08.129200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 203.95
train mean loss: 204.72
epoch train time: 0:00:00.167388
elapsed time: 0:00:33.779328
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-10-01 14:41:08.296705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.90
train mean loss: 206.05
epoch train time: 0:00:00.167511
elapsed time: 0:00:33.946966
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-10-01 14:41:08.464349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.87
train mean loss: 199.75
epoch train time: 0:00:00.173899
elapsed time: 0:00:34.120994
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-10-01 14:41:08.638368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.90
train mean loss: 198.49
epoch train time: 0:00:00.172243
elapsed time: 0:00:34.293361
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-10-01 14:41:08.810791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 194.19
train mean loss: 193.87
epoch train time: 0:00:00.173711
elapsed time: 0:00:34.467242
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-10-01 14:41:08.984615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.62
train mean loss: 196.18
epoch train time: 0:00:00.169873
elapsed time: 0:00:34.637229
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-10-01 14:41:09.154606
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.25
train mean loss: 195.38
epoch train time: 0:00:00.168900
elapsed time: 0:00:34.806251
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-10-01 14:41:09.323628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.75
train mean loss: 191.67
epoch train time: 0:00:00.170038
elapsed time: 0:00:34.976402
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-10-01 14:41:09.493829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.86
train mean loss: 191.68
epoch train time: 0:00:00.173217
elapsed time: 0:00:35.149794
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-10-01 14:41:09.667170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.03
train mean loss: 183.98
epoch train time: 0:00:00.179733
elapsed time: 0:00:35.329660
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-10-01 14:41:09.847037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.45
train mean loss: 184.73
epoch train time: 0:00:00.172437
elapsed time: 0:00:35.502245
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-10-01 14:41:10.019620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.31
train mean loss: 177.33
epoch train time: 0:00:00.170348
elapsed time: 0:00:35.672705
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-10-01 14:41:10.190077
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.96
train mean loss: 175.30
epoch train time: 0:00:00.168835
elapsed time: 0:00:35.841653
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-10-01 14:41:10.359026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.87
train mean loss: 175.48
epoch train time: 0:00:00.169250
elapsed time: 0:00:36.011010
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-10-01 14:41:10.528383
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.01
train mean loss: 171.46
epoch train time: 0:00:00.174114
elapsed time: 0:00:36.185270
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-10-01 14:41:10.702647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.00
train mean loss: 171.34
epoch train time: 0:00:00.198643
elapsed time: 0:00:36.384041
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-10-01 14:41:10.901416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.22
train mean loss: 169.41
epoch train time: 0:00:00.167862
elapsed time: 0:00:36.552024
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-10-01 14:41:11.069397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.35
train mean loss: 165.20
epoch train time: 0:00:00.173451
elapsed time: 0:00:36.725594
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-10-01 14:41:11.242970
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.88
train mean loss: 167.82
epoch train time: 0:00:00.180295
elapsed time: 0:00:36.906037
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-10-01 14:41:11.423413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.96
train mean loss: 162.11
epoch train time: 0:00:00.175194
elapsed time: 0:00:37.081355
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-10-01 14:41:11.598779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.96
train mean loss: 163.28
epoch train time: 0:00:00.184437
elapsed time: 0:00:37.265974
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-10-01 14:41:11.783355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.26
train mean loss: 161.37
epoch train time: 0:00:00.181785
elapsed time: 0:00:37.447890
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-10-01 14:41:11.965269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.45
train mean loss: 161.28
epoch train time: 0:00:00.173902
elapsed time: 0:00:37.621922
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-10-01 14:41:12.139325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.94
train mean loss: 159.57
epoch train time: 0:00:00.174912
elapsed time: 0:00:37.796988
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-10-01 14:41:12.314366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.28
train mean loss: 153.80
epoch train time: 0:00:00.178241
elapsed time: 0:00:37.975371
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-10-01 14:41:12.492747
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.80
train mean loss: 153.06
epoch train time: 0:00:00.176502
elapsed time: 0:00:38.152008
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-10-01 14:41:12.669386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.07
train mean loss: 149.52
epoch train time: 0:00:00.184624
elapsed time: 0:00:38.336760
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-10-01 14:41:12.854169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.49
train mean loss: 150.96
epoch train time: 0:00:00.177082
elapsed time: 0:00:38.513998
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-10-01 14:41:13.031388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.59
train mean loss: 146.64
epoch train time: 0:00:00.187200
elapsed time: 0:00:38.701335
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-10-01 14:41:13.218716
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.95
train mean loss: 145.63
epoch train time: 0:00:00.171590
elapsed time: 0:00:38.873054
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-10-01 14:41:13.390420
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.16
train mean loss: 143.39
epoch train time: 0:00:00.179517
elapsed time: 0:00:39.052679
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-10-01 14:41:13.570055
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 151.69
train mean loss: 150.07
epoch train time: 0:00:00.179266
elapsed time: 0:00:39.232072
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-10-01 14:41:13.749448
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.24
train mean loss: 144.47
epoch train time: 0:00:00.173645
elapsed time: 0:00:39.405851
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-10-01 14:41:13.923225
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 149.08
train mean loss: 149.28
epoch train time: 0:00:00.168993
elapsed time: 0:00:39.574957
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-10-01 14:41:14.092335
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 148.36
train mean loss: 147.66
epoch train time: 0:00:00.168961
elapsed time: 0:00:39.744049
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-10-01 14:41:14.261470
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.11
train mean loss: 145.32
epoch train time: 0:00:00.170037
elapsed time: 0:00:39.914304
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-10-01 14:41:14.431679
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.54
train mean loss: 145.41
epoch train time: 0:00:00.170423
elapsed time: 0:00:40.084839
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-10-01 14:41:14.602211
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 148.31
train mean loss: 149.19
epoch train time: 0:00:00.173068
elapsed time: 0:00:40.258028
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-10-01 14:41:14.775406
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 146.04
train mean loss: 144.92
epoch train time: 0:00:00.174341
elapsed time: 0:00:40.432512
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-10-01 14:41:14.949894
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 146.32
train mean loss: 145.50
epoch train time: 0:00:00.167474
elapsed time: 0:00:40.600102
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-10-01 14:41:15.117474
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.89
train mean loss: 146.28
epoch train time: 0:00:00.165971
elapsed time: 0:00:40.766216
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-10-01 14:41:15.283619
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.06
train mean loss: 144.60
epoch train time: 0:00:00.166086
elapsed time: 0:00:40.932487
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-10-01 14:41:15.449863
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.58
train mean loss: 144.15
epoch train time: 0:00:00.165856
elapsed time: 0:00:41.098455
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-10-01 14:41:15.615843
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.07
train mean loss: 144.21
epoch train time: 0:00:00.182818
elapsed time: 0:00:41.281428
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-10-01 14:41:15.798806
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.03
train mean loss: 142.13
epoch train time: 0:00:00.174513
elapsed time: 0:00:41.456075
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-10-01 14:41:15.973465
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.60
train mean loss: 143.65
epoch train time: 0:00:00.170721
elapsed time: 0:00:41.626949
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-10-01 14:41:16.144328
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.15
train mean loss: 142.06
epoch train time: 0:00:00.171730
elapsed time: 0:00:41.798836
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-10-01 14:41:16.316243
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.89
train mean loss: 143.59
epoch train time: 0:00:00.171284
elapsed time: 0:00:41.970265
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-10-01 14:41:16.487637
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.66
train mean loss: 140.65
epoch train time: 0:00:00.170389
elapsed time: 0:00:42.140782
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-10-01 14:41:16.658164
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.63
train mean loss: 147.08
epoch train time: 0:00:00.190213
elapsed time: 0:00:42.331143
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-10-01 14:41:16.848524
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.18
train mean loss: 143.32
epoch train time: 0:00:00.170181
elapsed time: 0:00:42.501448
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-10-01 14:41:17.018822
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.46
train mean loss: 142.16
epoch train time: 0:00:00.168254
elapsed time: 0:00:42.669812
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-10-01 14:41:17.187185
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.68
train mean loss: 142.56
epoch train time: 0:00:00.171539
elapsed time: 0:00:42.841500
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-10-01 14:41:17.358935
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.12
train mean loss: 142.46
epoch train time: 0:00:00.174455
elapsed time: 0:00:43.016183
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-10-01 14:41:17.533572
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.87
train mean loss: 143.62
epoch train time: 0:00:00.175009
elapsed time: 0:00:43.191331
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-10-01 14:41:17.708722
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.04
train mean loss: 140.01
epoch train time: 0:00:00.185543
elapsed time: 0:00:43.377018
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-10-01 14:41:17.894395
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 145.03
train mean loss: 143.47
epoch train time: 0:00:00.173284
elapsed time: 0:00:43.550434
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-10-01 14:41:18.067840
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.37
train mean loss: 142.88
epoch train time: 0:00:00.169966
elapsed time: 0:00:43.720548
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-10-01 14:41:18.237923
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.51
train mean loss: 144.44
epoch train time: 0:00:00.173002
elapsed time: 0:00:43.893671
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-10-01 14:41:18.411080
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.59
train mean loss: 143.74
epoch train time: 0:00:00.172710
elapsed time: 0:00:44.066532
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-10-01 14:41:18.583907
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.09
train mean loss: 141.58
epoch train time: 0:00:00.175546
elapsed time: 0:00:44.242196
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-10-01 14:41:18.759572
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.63
train mean loss: 144.96
epoch train time: 0:00:00.176795
elapsed time: 0:00:44.419125
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-10-01 14:41:18.936494
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.57
train mean loss: 138.97
epoch train time: 0:00:00.174462
elapsed time: 0:00:44.593701
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-10-01 14:41:19.111091
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.62
train mean loss: 138.57
epoch train time: 0:00:00.173703
elapsed time: 0:00:44.767534
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-10-01 14:41:19.284908
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.51
train mean loss: 141.70
epoch train time: 0:00:00.174793
elapsed time: 0:00:44.942460
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-10-01 14:41:19.459835
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.92
train mean loss: 141.19
epoch train time: 0:00:00.172845
elapsed time: 0:00:45.115436
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-10-01 14:41:19.632810
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.02
train mean loss: 136.74
epoch train time: 0:00:00.171108
elapsed time: 0:00:45.286669
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-10-01 14:41:19.804047
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.64
train mean loss: 138.49
epoch train time: 0:00:00.183414
elapsed time: 0:00:45.470217
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-10-01 14:41:19.987597
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.37
train mean loss: 142.37
epoch train time: 0:00:00.174462
elapsed time: 0:00:45.644815
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-10-01 14:41:20.162190
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.05
train mean loss: 137.60
epoch train time: 0:00:00.172694
elapsed time: 0:00:45.817637
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-10-01 14:41:20.335016
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.81
train mean loss: 139.93
epoch train time: 0:00:00.174475
elapsed time: 0:00:45.992237
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-10-01 14:41:20.509615
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.82
train mean loss: 135.90
epoch train time: 0:00:00.172213
elapsed time: 0:00:46.164578
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-10-01 14:41:20.681983
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.14
train mean loss: 138.75
epoch train time: 0:00:00.169064
elapsed time: 0:00:46.333792
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-10-01 14:41:20.851165
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.46
train mean loss: 142.74
epoch train time: 0:00:00.174342
elapsed time: 0:00:46.508275
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-10-01 14:41:21.025654
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.25
train mean loss: 137.67
epoch train time: 0:00:00.171047
elapsed time: 0:00:46.679452
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-10-01 14:41:21.196830
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.69
train mean loss: 139.64
epoch train time: 0:00:00.170013
elapsed time: 0:00:46.849587
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-10-01 14:41:21.366964
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.30
train mean loss: 138.44
epoch train time: 0:00:00.171405
elapsed time: 0:00:47.021106
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-10-01 14:41:21.538489
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.55
train mean loss: 139.03
epoch train time: 0:00:00.171388
elapsed time: 0:00:47.200460
checkpoint saved in file: log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_0/checkpoint.pth.tar
**** end time: 2019-10-01 14:41:21.717811 ****
