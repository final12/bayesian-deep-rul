Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_9', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30193
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:32:31.697238 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:32:31.706867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3773.67
 ---- batch: 020 ----
mean loss: 3454.94
 ---- batch: 030 ----
mean loss: 3345.46
train mean loss: 3483.61
epoch train time: 0:00:12.722640
elapsed time: 0:00:12.738544
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:32:44.435821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3114.37
 ---- batch: 020 ----
mean loss: 2935.48
 ---- batch: 030 ----
mean loss: 2854.41
train mean loss: 2942.40
epoch train time: 0:00:00.575571
elapsed time: 0:00:13.314405
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:32:45.011771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2675.03
 ---- batch: 020 ----
mean loss: 2564.46
 ---- batch: 030 ----
mean loss: 2483.97
train mean loss: 2547.94
epoch train time: 0:00:00.560864
elapsed time: 0:00:13.875632
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:32:45.572963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2335.55
 ---- batch: 020 ----
mean loss: 2233.09
 ---- batch: 030 ----
mean loss: 2207.43
train mean loss: 2249.74
epoch train time: 0:00:00.585892
elapsed time: 0:00:14.461845
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:32:46.159190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2070.01
 ---- batch: 020 ----
mean loss: 2019.88
 ---- batch: 030 ----
mean loss: 2051.09
train mean loss: 2035.71
epoch train time: 0:00:00.597931
elapsed time: 0:00:15.060122
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:32:46.757483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1922.84
 ---- batch: 020 ----
mean loss: 1879.54
 ---- batch: 030 ----
mean loss: 1858.39
train mean loss: 1876.95
epoch train time: 0:00:00.600701
elapsed time: 0:00:15.661161
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:32:47.358507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1792.43
 ---- batch: 020 ----
mean loss: 1727.84
 ---- batch: 030 ----
mean loss: 1700.81
train mean loss: 1732.94
epoch train time: 0:00:00.580919
elapsed time: 0:00:16.242428
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:32:47.939779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1661.00
 ---- batch: 020 ----
mean loss: 1647.90
 ---- batch: 030 ----
mean loss: 1591.65
train mean loss: 1627.44
epoch train time: 0:00:00.573907
elapsed time: 0:00:16.816693
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:32:48.514025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1561.42
 ---- batch: 020 ----
mean loss: 1528.12
 ---- batch: 030 ----
mean loss: 1510.32
train mean loss: 1525.59
epoch train time: 0:00:00.575144
elapsed time: 0:00:17.392160
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:32:49.089537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1471.98
 ---- batch: 020 ----
mean loss: 1427.52
 ---- batch: 030 ----
mean loss: 1405.12
train mean loss: 1425.07
epoch train time: 0:00:00.572487
elapsed time: 0:00:17.965006
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:32:49.662373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1364.49
 ---- batch: 020 ----
mean loss: 1363.35
 ---- batch: 030 ----
mean loss: 1320.47
train mean loss: 1343.89
epoch train time: 0:00:00.585437
elapsed time: 0:00:18.550769
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:32:50.248100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1288.32
 ---- batch: 020 ----
mean loss: 1279.68
 ---- batch: 030 ----
mean loss: 1231.40
train mean loss: 1266.37
epoch train time: 0:00:00.581674
elapsed time: 0:00:19.132756
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:32:50.830090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1230.26
 ---- batch: 020 ----
mean loss: 1196.06
 ---- batch: 030 ----
mean loss: 1182.46
train mean loss: 1192.75
epoch train time: 0:00:00.571127
elapsed time: 0:00:19.704202
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:32:51.401542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1160.94
 ---- batch: 020 ----
mean loss: 1128.74
 ---- batch: 030 ----
mean loss: 1100.29
train mean loss: 1118.65
epoch train time: 0:00:00.574164
elapsed time: 0:00:20.278682
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:32:51.976020
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1073.83
 ---- batch: 020 ----
mean loss: 1065.00
 ---- batch: 030 ----
mean loss: 1047.07
train mean loss: 1058.08
epoch train time: 0:00:00.567162
elapsed time: 0:00:20.846155
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:32:52.543512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1020.98
 ---- batch: 020 ----
mean loss: 994.00
 ---- batch: 030 ----
mean loss: 986.91
train mean loss: 994.53
epoch train time: 0:00:00.573050
elapsed time: 0:00:21.419537
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:32:53.116887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 958.56
 ---- batch: 020 ----
mean loss: 940.95
 ---- batch: 030 ----
mean loss: 919.70
train mean loss: 935.72
epoch train time: 0:00:00.559351
elapsed time: 0:00:21.979351
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:32:53.676708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 897.10
 ---- batch: 020 ----
mean loss: 889.59
 ---- batch: 030 ----
mean loss: 855.02
train mean loss: 881.84
epoch train time: 0:00:00.585097
elapsed time: 0:00:22.564809
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:32:54.262144
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 849.30
 ---- batch: 020 ----
mean loss: 835.42
 ---- batch: 030 ----
mean loss: 816.12
train mean loss: 827.76
epoch train time: 0:00:00.583088
elapsed time: 0:00:23.148239
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:32:54.845577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 800.63
 ---- batch: 020 ----
mean loss: 786.07
 ---- batch: 030 ----
mean loss: 759.15
train mean loss: 776.56
epoch train time: 0:00:00.567118
elapsed time: 0:00:23.715674
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:32:55.413006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 732.32
 ---- batch: 020 ----
mean loss: 740.18
 ---- batch: 030 ----
mean loss: 718.02
train mean loss: 730.24
epoch train time: 0:00:00.576137
elapsed time: 0:00:24.292115
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:32:55.989448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 704.93
 ---- batch: 020 ----
mean loss: 698.93
 ---- batch: 030 ----
mean loss: 682.35
train mean loss: 690.01
epoch train time: 0:00:00.558355
elapsed time: 0:00:24.850784
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:32:56.548116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 667.27
 ---- batch: 020 ----
mean loss: 646.52
 ---- batch: 030 ----
mean loss: 636.06
train mean loss: 644.24
epoch train time: 0:00:00.585588
elapsed time: 0:00:25.436668
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:32:57.134056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 615.05
 ---- batch: 020 ----
mean loss: 621.06
 ---- batch: 030 ----
mean loss: 611.92
train mean loss: 608.32
epoch train time: 0:00:00.568072
elapsed time: 0:00:26.005140
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:32:57.702494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 586.25
 ---- batch: 020 ----
mean loss: 583.57
 ---- batch: 030 ----
mean loss: 560.66
train mean loss: 572.86
epoch train time: 0:00:00.566958
elapsed time: 0:00:26.572457
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:32:58.269798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 544.52
 ---- batch: 020 ----
mean loss: 551.19
 ---- batch: 030 ----
mean loss: 526.50
train mean loss: 536.47
epoch train time: 0:00:00.587640
elapsed time: 0:00:27.160481
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:32:58.857836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 510.86
 ---- batch: 020 ----
mean loss: 517.47
 ---- batch: 030 ----
mean loss: 493.67
train mean loss: 507.02
epoch train time: 0:00:00.559363
elapsed time: 0:00:27.720168
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:32:59.417502
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 487.02
 ---- batch: 020 ----
mean loss: 480.66
 ---- batch: 030 ----
mean loss: 461.24
train mean loss: 474.63
epoch train time: 0:00:00.591219
elapsed time: 0:00:28.311695
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:33:00.009054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 449.70
 ---- batch: 020 ----
mean loss: 454.84
 ---- batch: 030 ----
mean loss: 431.61
train mean loss: 442.57
epoch train time: 0:00:00.570078
elapsed time: 0:00:28.882101
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:33:00.579438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 430.73
 ---- batch: 020 ----
mean loss: 422.33
 ---- batch: 030 ----
mean loss: 415.26
train mean loss: 423.53
epoch train time: 0:00:00.566598
elapsed time: 0:00:29.449006
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:33:01.146338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.86
 ---- batch: 020 ----
mean loss: 390.69
 ---- batch: 030 ----
mean loss: 404.75
train mean loss: 398.06
epoch train time: 0:00:00.560637
elapsed time: 0:00:30.009953
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:33:01.707304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 393.23
 ---- batch: 020 ----
mean loss: 376.55
 ---- batch: 030 ----
mean loss: 370.22
train mean loss: 378.46
epoch train time: 0:00:00.558520
elapsed time: 0:00:30.568806
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:33:02.266174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.30
 ---- batch: 020 ----
mean loss: 358.24
 ---- batch: 030 ----
mean loss: 353.50
train mean loss: 359.27
epoch train time: 0:00:00.572236
elapsed time: 0:00:31.141460
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:33:02.838798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 344.76
 ---- batch: 020 ----
mean loss: 345.82
 ---- batch: 030 ----
mean loss: 335.89
train mean loss: 339.43
epoch train time: 0:00:00.573225
elapsed time: 0:00:31.714991
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:33:03.412350
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 326.74
 ---- batch: 020 ----
mean loss: 333.17
 ---- batch: 030 ----
mean loss: 319.18
train mean loss: 323.92
epoch train time: 0:00:00.594301
elapsed time: 0:00:32.309648
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:33:04.006990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.39
 ---- batch: 020 ----
mean loss: 306.26
 ---- batch: 030 ----
mean loss: 309.26
train mean loss: 306.49
epoch train time: 0:00:00.560440
elapsed time: 0:00:32.870446
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:33:04.567807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.15
 ---- batch: 020 ----
mean loss: 291.20
 ---- batch: 030 ----
mean loss: 290.91
train mean loss: 292.30
epoch train time: 0:00:00.577866
elapsed time: 0:00:33.448665
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:33:05.146013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.03
 ---- batch: 020 ----
mean loss: 276.12
 ---- batch: 030 ----
mean loss: 276.82
train mean loss: 278.45
epoch train time: 0:00:00.571294
elapsed time: 0:00:34.020290
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:33:05.717650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.79
 ---- batch: 020 ----
mean loss: 265.47
 ---- batch: 030 ----
mean loss: 265.85
train mean loss: 265.18
epoch train time: 0:00:00.582465
elapsed time: 0:00:34.603108
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:33:06.300480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.56
 ---- batch: 020 ----
mean loss: 249.48
 ---- batch: 030 ----
mean loss: 255.92
train mean loss: 253.67
epoch train time: 0:00:00.591778
elapsed time: 0:00:35.195262
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:33:06.892599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.17
 ---- batch: 020 ----
mean loss: 233.73
 ---- batch: 030 ----
mean loss: 244.96
train mean loss: 244.89
epoch train time: 0:00:00.570611
elapsed time: 0:00:35.766224
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:33:07.463574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.25
 ---- batch: 020 ----
mean loss: 232.76
 ---- batch: 030 ----
mean loss: 229.04
train mean loss: 230.00
epoch train time: 0:00:00.577387
elapsed time: 0:00:36.343971
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:33:08.041362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.30
 ---- batch: 020 ----
mean loss: 228.85
 ---- batch: 030 ----
mean loss: 217.54
train mean loss: 225.86
epoch train time: 0:00:00.581453
elapsed time: 0:00:36.925790
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:33:08.623127
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.88
 ---- batch: 020 ----
mean loss: 218.35
 ---- batch: 030 ----
mean loss: 223.71
train mean loss: 217.86
epoch train time: 0:00:00.575451
elapsed time: 0:00:37.501540
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:33:09.198871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.97
 ---- batch: 020 ----
mean loss: 201.77
 ---- batch: 030 ----
mean loss: 204.17
train mean loss: 205.48
epoch train time: 0:00:00.569411
elapsed time: 0:00:38.071343
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:33:09.768685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.23
 ---- batch: 020 ----
mean loss: 198.95
 ---- batch: 030 ----
mean loss: 200.18
train mean loss: 201.03
epoch train time: 0:00:00.567537
elapsed time: 0:00:38.639187
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:33:10.336522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 194.16
 ---- batch: 020 ----
mean loss: 197.26
 ---- batch: 030 ----
mean loss: 193.05
train mean loss: 194.79
epoch train time: 0:00:00.561549
elapsed time: 0:00:39.201067
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:33:10.898406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.04
 ---- batch: 020 ----
mean loss: 186.78
 ---- batch: 030 ----
mean loss: 187.67
train mean loss: 187.57
epoch train time: 0:00:00.572932
elapsed time: 0:00:39.774323
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:33:11.471671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.91
 ---- batch: 020 ----
mean loss: 178.54
 ---- batch: 030 ----
mean loss: 181.63
train mean loss: 179.43
epoch train time: 0:00:00.574394
elapsed time: 0:00:40.349066
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:33:12.046402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.39
 ---- batch: 020 ----
mean loss: 181.35
 ---- batch: 030 ----
mean loss: 175.24
train mean loss: 176.76
epoch train time: 0:00:00.561543
elapsed time: 0:00:40.910913
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:33:12.608244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.58
 ---- batch: 020 ----
mean loss: 166.37
 ---- batch: 030 ----
mean loss: 168.91
train mean loss: 170.38
epoch train time: 0:00:00.575560
elapsed time: 0:00:41.486785
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:33:13.184124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.30
 ---- batch: 020 ----
mean loss: 168.32
 ---- batch: 030 ----
mean loss: 166.60
train mean loss: 167.49
epoch train time: 0:00:00.577395
elapsed time: 0:00:42.064523
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:33:13.761866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.72
 ---- batch: 020 ----
mean loss: 158.30
 ---- batch: 030 ----
mean loss: 161.92
train mean loss: 160.45
epoch train time: 0:00:00.584896
elapsed time: 0:00:42.649777
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:33:14.347122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.30
 ---- batch: 020 ----
mean loss: 163.46
 ---- batch: 030 ----
mean loss: 156.99
train mean loss: 158.75
epoch train time: 0:00:00.576391
elapsed time: 0:00:43.226491
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:33:14.923830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.75
 ---- batch: 020 ----
mean loss: 151.13
 ---- batch: 030 ----
mean loss: 152.86
train mean loss: 154.03
epoch train time: 0:00:00.573127
elapsed time: 0:00:43.799943
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:33:15.497294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.85
 ---- batch: 020 ----
mean loss: 154.34
 ---- batch: 030 ----
mean loss: 147.23
train mean loss: 152.83
epoch train time: 0:00:00.582333
elapsed time: 0:00:44.382601
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:33:16.079952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.44
 ---- batch: 020 ----
mean loss: 150.39
 ---- batch: 030 ----
mean loss: 146.06
train mean loss: 147.58
epoch train time: 0:00:00.573915
elapsed time: 0:00:44.956914
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:33:16.654254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.30
 ---- batch: 020 ----
mean loss: 143.39
 ---- batch: 030 ----
mean loss: 144.07
train mean loss: 143.22
epoch train time: 0:00:00.597541
elapsed time: 0:00:45.554792
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:33:17.252129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.08
 ---- batch: 020 ----
mean loss: 141.25
 ---- batch: 030 ----
mean loss: 140.64
train mean loss: 140.68
epoch train time: 0:00:00.573589
elapsed time: 0:00:46.128723
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:33:17.826062
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.74
 ---- batch: 020 ----
mean loss: 131.77
 ---- batch: 030 ----
mean loss: 136.61
train mean loss: 136.78
epoch train time: 0:00:00.556996
elapsed time: 0:00:46.686031
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:33:18.383364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.43
 ---- batch: 020 ----
mean loss: 131.85
 ---- batch: 030 ----
mean loss: 136.01
train mean loss: 135.29
epoch train time: 0:00:00.566167
elapsed time: 0:00:47.252549
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:33:18.949971
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.85
 ---- batch: 020 ----
mean loss: 132.65
 ---- batch: 030 ----
mean loss: 133.54
train mean loss: 133.07
epoch train time: 0:00:00.557296
elapsed time: 0:00:47.810235
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:33:19.507584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.04
 ---- batch: 020 ----
mean loss: 128.91
 ---- batch: 030 ----
mean loss: 129.02
train mean loss: 129.33
epoch train time: 0:00:00.563258
elapsed time: 0:00:48.373834
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:33:20.071177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.87
 ---- batch: 020 ----
mean loss: 130.74
 ---- batch: 030 ----
mean loss: 128.16
train mean loss: 128.49
epoch train time: 0:00:00.557078
elapsed time: 0:00:48.931213
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:33:20.628587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.94
 ---- batch: 020 ----
mean loss: 125.72
 ---- batch: 030 ----
mean loss: 123.01
train mean loss: 125.37
epoch train time: 0:00:00.572201
elapsed time: 0:00:49.503816
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:33:21.201166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.73
 ---- batch: 020 ----
mean loss: 123.59
 ---- batch: 030 ----
mean loss: 123.12
train mean loss: 123.26
epoch train time: 0:00:00.570855
elapsed time: 0:00:50.074993
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:33:21.772362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.08
 ---- batch: 020 ----
mean loss: 123.07
 ---- batch: 030 ----
mean loss: 120.20
train mean loss: 123.42
epoch train time: 0:00:00.583814
elapsed time: 0:00:50.659171
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:33:22.356523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.09
 ---- batch: 020 ----
mean loss: 121.44
 ---- batch: 030 ----
mean loss: 121.08
train mean loss: 121.07
epoch train time: 0:00:00.574607
elapsed time: 0:00:51.234120
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:33:22.931471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.75
 ---- batch: 020 ----
mean loss: 116.94
 ---- batch: 030 ----
mean loss: 114.60
train mean loss: 118.52
epoch train time: 0:00:00.571789
elapsed time: 0:00:51.806297
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:33:23.503658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.44
 ---- batch: 020 ----
mean loss: 117.66
 ---- batch: 030 ----
mean loss: 117.70
train mean loss: 118.03
epoch train time: 0:00:00.575602
elapsed time: 0:00:52.382248
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:33:24.079589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.07
 ---- batch: 020 ----
mean loss: 117.06
 ---- batch: 030 ----
mean loss: 111.74
train mean loss: 115.08
epoch train time: 0:00:00.566133
elapsed time: 0:00:52.948712
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:33:24.646076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.70
 ---- batch: 020 ----
mean loss: 115.89
 ---- batch: 030 ----
mean loss: 111.38
train mean loss: 112.95
epoch train time: 0:00:00.571825
elapsed time: 0:00:53.520874
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:33:25.218206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.06
 ---- batch: 020 ----
mean loss: 113.56
 ---- batch: 030 ----
mean loss: 112.80
train mean loss: 112.58
epoch train time: 0:00:00.559687
elapsed time: 0:00:54.080922
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:33:25.778276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.63
 ---- batch: 020 ----
mean loss: 112.53
 ---- batch: 030 ----
mean loss: 110.07
train mean loss: 110.79
epoch train time: 0:00:00.563715
elapsed time: 0:00:54.645015
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:33:26.342400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.06
 ---- batch: 020 ----
mean loss: 109.92
 ---- batch: 030 ----
mean loss: 109.16
train mean loss: 108.65
epoch train time: 0:00:00.584195
elapsed time: 0:00:55.229595
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:33:26.926935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.65
 ---- batch: 020 ----
mean loss: 105.60
 ---- batch: 030 ----
mean loss: 110.82
train mean loss: 108.25
epoch train time: 0:00:00.574151
elapsed time: 0:00:55.804133
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:33:27.501473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.87
 ---- batch: 020 ----
mean loss: 106.13
 ---- batch: 030 ----
mean loss: 103.57
train mean loss: 107.12
epoch train time: 0:00:00.577197
elapsed time: 0:00:56.381627
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:33:28.078999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.91
 ---- batch: 020 ----
mean loss: 103.32
 ---- batch: 030 ----
mean loss: 110.10
train mean loss: 107.40
epoch train time: 0:00:00.568431
elapsed time: 0:00:56.950426
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:33:28.647769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.38
 ---- batch: 020 ----
mean loss: 103.30
 ---- batch: 030 ----
mean loss: 107.74
train mean loss: 104.59
epoch train time: 0:00:00.576133
elapsed time: 0:00:57.526887
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:33:29.224232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.02
 ---- batch: 020 ----
mean loss: 104.05
 ---- batch: 030 ----
mean loss: 103.83
train mean loss: 102.92
epoch train time: 0:00:00.586356
elapsed time: 0:00:58.113565
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:33:29.810902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.82
 ---- batch: 020 ----
mean loss: 97.64
 ---- batch: 030 ----
mean loss: 99.67
train mean loss: 101.14
epoch train time: 0:00:00.572959
elapsed time: 0:00:58.686847
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:33:30.384236
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.90
 ---- batch: 020 ----
mean loss: 106.11
 ---- batch: 030 ----
mean loss: 104.63
train mean loss: 103.83
epoch train time: 0:00:00.575312
elapsed time: 0:00:59.262564
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:33:30.959924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.07
 ---- batch: 020 ----
mean loss: 102.81
 ---- batch: 030 ----
mean loss: 96.28
train mean loss: 100.92
epoch train time: 0:00:00.585096
elapsed time: 0:00:59.847996
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:33:31.545354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.05
 ---- batch: 020 ----
mean loss: 96.92
 ---- batch: 030 ----
mean loss: 99.22
train mean loss: 100.14
epoch train time: 0:00:00.593242
elapsed time: 0:01:00.441584
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:33:32.138913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.54
 ---- batch: 020 ----
mean loss: 102.11
 ---- batch: 030 ----
mean loss: 99.99
train mean loss: 99.37
epoch train time: 0:00:00.564127
elapsed time: 0:01:01.006031
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:33:32.703365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.57
 ---- batch: 020 ----
mean loss: 97.96
 ---- batch: 030 ----
mean loss: 97.65
train mean loss: 96.95
epoch train time: 0:00:00.577406
elapsed time: 0:01:01.583760
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:33:33.281096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.36
 ---- batch: 020 ----
mean loss: 97.54
 ---- batch: 030 ----
mean loss: 101.87
train mean loss: 97.72
epoch train time: 0:00:00.584301
elapsed time: 0:01:02.168450
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:33:33.865788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.99
 ---- batch: 020 ----
mean loss: 96.27
 ---- batch: 030 ----
mean loss: 91.67
train mean loss: 95.17
epoch train time: 0:00:00.574469
elapsed time: 0:01:02.743338
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:33:34.440690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.81
 ---- batch: 020 ----
mean loss: 92.92
 ---- batch: 030 ----
mean loss: 96.22
train mean loss: 96.79
epoch train time: 0:00:00.580805
elapsed time: 0:01:03.324509
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:33:35.021848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.20
 ---- batch: 020 ----
mean loss: 94.93
 ---- batch: 030 ----
mean loss: 97.64
train mean loss: 96.22
epoch train time: 0:00:00.560447
elapsed time: 0:01:03.885280
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:33:35.582649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.65
 ---- batch: 020 ----
mean loss: 95.68
 ---- batch: 030 ----
mean loss: 93.18
train mean loss: 94.52
epoch train time: 0:00:00.586014
elapsed time: 0:01:04.471657
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:33:36.169021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.93
 ---- batch: 020 ----
mean loss: 96.54
 ---- batch: 030 ----
mean loss: 94.33
train mean loss: 94.74
epoch train time: 0:00:00.579931
elapsed time: 0:01:05.051990
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:33:36.749332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.80
 ---- batch: 020 ----
mean loss: 89.64
 ---- batch: 030 ----
mean loss: 94.59
train mean loss: 92.57
epoch train time: 0:00:00.573494
elapsed time: 0:01:05.625819
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:33:37.323154
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.66
 ---- batch: 020 ----
mean loss: 91.17
 ---- batch: 030 ----
mean loss: 92.79
train mean loss: 91.16
epoch train time: 0:00:00.595135
elapsed time: 0:01:06.221261
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:33:37.918608
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.43
 ---- batch: 020 ----
mean loss: 90.32
 ---- batch: 030 ----
mean loss: 93.03
train mean loss: 91.76
epoch train time: 0:00:00.573569
elapsed time: 0:01:06.795165
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:33:38.492498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.81
 ---- batch: 020 ----
mean loss: 89.57
 ---- batch: 030 ----
mean loss: 94.15
train mean loss: 91.95
epoch train time: 0:00:00.573529
elapsed time: 0:01:07.369028
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:33:39.066380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.37
 ---- batch: 020 ----
mean loss: 90.49
 ---- batch: 030 ----
mean loss: 93.03
train mean loss: 90.44
epoch train time: 0:00:00.563338
elapsed time: 0:01:07.932718
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:33:39.630060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.81
 ---- batch: 020 ----
mean loss: 92.37
 ---- batch: 030 ----
mean loss: 89.48
train mean loss: 90.13
epoch train time: 0:00:00.568676
elapsed time: 0:01:08.501797
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:33:40.199155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.22
 ---- batch: 020 ----
mean loss: 90.26
 ---- batch: 030 ----
mean loss: 87.90
train mean loss: 88.81
epoch train time: 0:00:00.571970
elapsed time: 0:01:09.074125
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:33:40.771462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.90
 ---- batch: 020 ----
mean loss: 88.47
 ---- batch: 030 ----
mean loss: 85.55
train mean loss: 87.89
epoch train time: 0:00:00.568125
elapsed time: 0:01:09.642558
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:33:41.339893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.00
 ---- batch: 020 ----
mean loss: 86.09
 ---- batch: 030 ----
mean loss: 85.33
train mean loss: 86.73
epoch train time: 0:00:00.576058
elapsed time: 0:01:10.218966
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:33:41.916301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.06
 ---- batch: 020 ----
mean loss: 85.26
 ---- batch: 030 ----
mean loss: 88.47
train mean loss: 87.41
epoch train time: 0:00:00.559247
elapsed time: 0:01:10.778529
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:33:42.475865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.30
 ---- batch: 020 ----
mean loss: 88.25
 ---- batch: 030 ----
mean loss: 85.31
train mean loss: 86.07
epoch train time: 0:00:00.572446
elapsed time: 0:01:11.351287
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:33:43.048658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.19
 ---- batch: 020 ----
mean loss: 85.36
 ---- batch: 030 ----
mean loss: 83.29
train mean loss: 84.99
epoch train time: 0:00:00.580338
elapsed time: 0:01:11.932046
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:33:43.629384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.01
 ---- batch: 020 ----
mean loss: 82.40
 ---- batch: 030 ----
mean loss: 81.88
train mean loss: 84.69
epoch train time: 0:00:00.592136
elapsed time: 0:01:12.524549
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:33:44.221886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.25
 ---- batch: 020 ----
mean loss: 83.26
 ---- batch: 030 ----
mean loss: 86.19
train mean loss: 84.16
epoch train time: 0:00:00.574685
elapsed time: 0:01:13.099546
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:33:44.796889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.79
 ---- batch: 020 ----
mean loss: 83.23
 ---- batch: 030 ----
mean loss: 83.46
train mean loss: 84.28
epoch train time: 0:00:00.572838
elapsed time: 0:01:13.672750
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:33:45.370043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.42
 ---- batch: 020 ----
mean loss: 83.29
 ---- batch: 030 ----
mean loss: 84.22
train mean loss: 83.01
epoch train time: 0:00:00.605910
elapsed time: 0:01:14.278923
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:33:45.976261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.61
 ---- batch: 020 ----
mean loss: 83.43
 ---- batch: 030 ----
mean loss: 79.71
train mean loss: 82.27
epoch train time: 0:00:00.574307
elapsed time: 0:01:14.853608
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:33:46.550962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.28
 ---- batch: 020 ----
mean loss: 82.13
 ---- batch: 030 ----
mean loss: 79.79
train mean loss: 81.85
epoch train time: 0:00:00.575301
elapsed time: 0:01:15.429250
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:33:47.126609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.27
 ---- batch: 020 ----
mean loss: 81.80
 ---- batch: 030 ----
mean loss: 83.81
train mean loss: 82.11
epoch train time: 0:00:00.578360
elapsed time: 0:01:16.007999
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:33:47.705332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.07
 ---- batch: 020 ----
mean loss: 80.54
 ---- batch: 030 ----
mean loss: 78.86
train mean loss: 81.24
epoch train time: 0:00:00.577936
elapsed time: 0:01:16.586244
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:33:48.283590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.59
 ---- batch: 020 ----
mean loss: 80.46
 ---- batch: 030 ----
mean loss: 78.87
train mean loss: 79.41
epoch train time: 0:00:00.565435
elapsed time: 0:01:17.152077
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:33:48.849414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.93
 ---- batch: 020 ----
mean loss: 77.90
 ---- batch: 030 ----
mean loss: 79.77
train mean loss: 79.10
epoch train time: 0:00:00.567818
elapsed time: 0:01:17.720207
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:33:49.417550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.80
 ---- batch: 020 ----
mean loss: 76.12
 ---- batch: 030 ----
mean loss: 81.04
train mean loss: 79.97
epoch train time: 0:00:00.583077
elapsed time: 0:01:18.303600
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:33:50.000970
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.57
 ---- batch: 020 ----
mean loss: 78.19
 ---- batch: 030 ----
mean loss: 80.98
train mean loss: 79.33
epoch train time: 0:00:00.576275
elapsed time: 0:01:18.880230
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:33:50.577574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.85
 ---- batch: 020 ----
mean loss: 76.62
 ---- batch: 030 ----
mean loss: 78.57
train mean loss: 77.30
epoch train time: 0:00:00.577353
elapsed time: 0:01:19.457951
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:33:51.155293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.32
 ---- batch: 020 ----
mean loss: 78.55
 ---- batch: 030 ----
mean loss: 79.45
train mean loss: 78.36
epoch train time: 0:00:00.573650
elapsed time: 0:01:20.031920
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:33:51.729253
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.72
 ---- batch: 020 ----
mean loss: 77.55
 ---- batch: 030 ----
mean loss: 78.37
train mean loss: 77.99
epoch train time: 0:00:00.576416
elapsed time: 0:01:20.608682
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:33:52.306027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.59
 ---- batch: 020 ----
mean loss: 75.20
 ---- batch: 030 ----
mean loss: 77.40
train mean loss: 76.30
epoch train time: 0:00:00.600253
elapsed time: 0:01:21.209365
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:33:52.906712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.54
 ---- batch: 020 ----
mean loss: 77.47
 ---- batch: 030 ----
mean loss: 74.35
train mean loss: 76.37
epoch train time: 0:00:00.577270
elapsed time: 0:01:21.786975
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:33:53.484321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.89
 ---- batch: 020 ----
mean loss: 74.49
 ---- batch: 030 ----
mean loss: 77.29
train mean loss: 74.84
epoch train time: 0:00:00.580719
elapsed time: 0:01:22.368036
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:33:54.065366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.55
 ---- batch: 020 ----
mean loss: 74.42
 ---- batch: 030 ----
mean loss: 74.29
train mean loss: 74.65
epoch train time: 0:00:00.561420
elapsed time: 0:01:22.929763
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:33:54.627115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.93
 ---- batch: 020 ----
mean loss: 73.27
 ---- batch: 030 ----
mean loss: 73.80
train mean loss: 73.77
epoch train time: 0:00:00.576334
elapsed time: 0:01:23.506426
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:33:55.203781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.74
 ---- batch: 020 ----
mean loss: 72.27
 ---- batch: 030 ----
mean loss: 74.73
train mean loss: 73.64
epoch train time: 0:00:00.577273
elapsed time: 0:01:24.084029
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:33:55.781363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.82
 ---- batch: 020 ----
mean loss: 73.55
 ---- batch: 030 ----
mean loss: 72.98
train mean loss: 74.03
epoch train time: 0:00:00.583150
elapsed time: 0:01:24.667496
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:33:56.364832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.47
 ---- batch: 020 ----
mean loss: 73.11
 ---- batch: 030 ----
mean loss: 72.57
train mean loss: 72.83
epoch train time: 0:00:00.604993
elapsed time: 0:01:25.272883
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:33:56.970187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.07
 ---- batch: 020 ----
mean loss: 69.77
 ---- batch: 030 ----
mean loss: 71.92
train mean loss: 71.16
epoch train time: 0:00:00.587495
elapsed time: 0:01:25.860672
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:33:57.558018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.36
 ---- batch: 020 ----
mean loss: 73.44
 ---- batch: 030 ----
mean loss: 71.00
train mean loss: 72.78
epoch train time: 0:00:00.607237
elapsed time: 0:01:26.468228
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:33:58.165569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.67
 ---- batch: 020 ----
mean loss: 73.34
 ---- batch: 030 ----
mean loss: 71.27
train mean loss: 70.96
epoch train time: 0:00:00.574437
elapsed time: 0:01:27.043034
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:33:58.740378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.21
 ---- batch: 020 ----
mean loss: 71.61
 ---- batch: 030 ----
mean loss: 67.98
train mean loss: 70.05
epoch train time: 0:00:00.568845
elapsed time: 0:01:27.612187
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:33:59.309526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.46
 ---- batch: 020 ----
mean loss: 70.03
 ---- batch: 030 ----
mean loss: 72.41
train mean loss: 70.46
epoch train time: 0:00:00.585644
elapsed time: 0:01:28.198260
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:33:59.895622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.95
 ---- batch: 020 ----
mean loss: 72.63
 ---- batch: 030 ----
mean loss: 65.98
train mean loss: 69.12
epoch train time: 0:00:00.573030
elapsed time: 0:01:28.771630
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:34:00.468984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.90
 ---- batch: 020 ----
mean loss: 68.64
 ---- batch: 030 ----
mean loss: 70.89
train mean loss: 69.36
epoch train time: 0:00:00.570261
elapsed time: 0:01:29.342249
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:34:01.039622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.41
 ---- batch: 020 ----
mean loss: 68.91
 ---- batch: 030 ----
mean loss: 67.53
train mean loss: 68.27
epoch train time: 0:00:00.563009
elapsed time: 0:01:29.905645
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:34:01.603014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.77
 ---- batch: 020 ----
mean loss: 66.96
 ---- batch: 030 ----
mean loss: 69.90
train mean loss: 68.41
epoch train time: 0:00:00.575296
elapsed time: 0:01:30.481295
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:34:02.178635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.30
 ---- batch: 020 ----
mean loss: 68.40
 ---- batch: 030 ----
mean loss: 65.39
train mean loss: 68.49
epoch train time: 0:00:00.581580
elapsed time: 0:01:31.063223
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:34:02.760575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.63
 ---- batch: 020 ----
mean loss: 70.38
 ---- batch: 030 ----
mean loss: 65.46
train mean loss: 67.79
epoch train time: 0:00:00.582268
elapsed time: 0:01:31.645835
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:34:03.343186
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.19
 ---- batch: 020 ----
mean loss: 70.03
 ---- batch: 030 ----
mean loss: 66.76
train mean loss: 67.76
epoch train time: 0:00:00.601475
elapsed time: 0:01:32.247638
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:34:03.944986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.31
 ---- batch: 020 ----
mean loss: 67.44
 ---- batch: 030 ----
mean loss: 64.41
train mean loss: 65.51
epoch train time: 0:00:00.570979
elapsed time: 0:01:32.818970
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:34:04.516310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.10
 ---- batch: 020 ----
mean loss: 63.03
 ---- batch: 030 ----
mean loss: 67.60
train mean loss: 65.43
epoch train time: 0:00:00.577517
elapsed time: 0:01:33.396811
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:34:05.094153
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.47
 ---- batch: 020 ----
mean loss: 64.99
 ---- batch: 030 ----
mean loss: 65.66
train mean loss: 65.24
epoch train time: 0:00:00.577297
elapsed time: 0:01:33.974490
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:34:05.671838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.65
 ---- batch: 020 ----
mean loss: 64.50
 ---- batch: 030 ----
mean loss: 66.31
train mean loss: 64.11
epoch train time: 0:00:00.566138
elapsed time: 0:01:34.540934
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:34:06.238265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.43
 ---- batch: 020 ----
mean loss: 65.10
 ---- batch: 030 ----
mean loss: 64.95
train mean loss: 64.42
epoch train time: 0:00:00.574763
elapsed time: 0:01:35.116079
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:34:06.813436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.34
 ---- batch: 020 ----
mean loss: 62.81
 ---- batch: 030 ----
mean loss: 63.63
train mean loss: 64.05
epoch train time: 0:00:00.578442
elapsed time: 0:01:35.694852
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:34:07.392188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.23
 ---- batch: 020 ----
mean loss: 63.74
 ---- batch: 030 ----
mean loss: 60.79
train mean loss: 62.98
epoch train time: 0:00:00.602143
elapsed time: 0:01:36.297313
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:34:07.994658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.68
 ---- batch: 020 ----
mean loss: 65.88
 ---- batch: 030 ----
mean loss: 60.21
train mean loss: 62.94
epoch train time: 0:00:00.563829
elapsed time: 0:01:36.861500
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:34:08.558835
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.22
 ---- batch: 020 ----
mean loss: 62.48
 ---- batch: 030 ----
mean loss: 62.78
train mean loss: 61.69
epoch train time: 0:00:00.564192
elapsed time: 0:01:37.425991
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:34:09.123330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.10
 ---- batch: 020 ----
mean loss: 63.95
 ---- batch: 030 ----
mean loss: 59.90
train mean loss: 61.71
epoch train time: 0:00:00.561716
elapsed time: 0:01:37.988094
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:34:09.685375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.01
 ---- batch: 020 ----
mean loss: 60.44
 ---- batch: 030 ----
mean loss: 61.50
train mean loss: 61.67
epoch train time: 0:00:00.580060
elapsed time: 0:01:38.568449
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:34:10.265799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.72
 ---- batch: 020 ----
mean loss: 61.37
 ---- batch: 030 ----
mean loss: 59.12
train mean loss: 60.92
epoch train time: 0:00:00.587157
elapsed time: 0:01:39.155953
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:34:10.853306
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.58
 ---- batch: 020 ----
mean loss: 60.35
 ---- batch: 030 ----
mean loss: 63.64
train mean loss: 60.48
epoch train time: 0:00:00.560456
elapsed time: 0:01:39.716760
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:34:11.414094
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.96
 ---- batch: 020 ----
mean loss: 62.41
 ---- batch: 030 ----
mean loss: 59.70
train mean loss: 60.56
epoch train time: 0:00:00.574749
elapsed time: 0:01:40.291824
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:34:11.989176
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.26
 ---- batch: 020 ----
mean loss: 58.34
 ---- batch: 030 ----
mean loss: 61.00
train mean loss: 59.24
epoch train time: 0:00:00.579596
elapsed time: 0:01:40.871767
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:34:12.569109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.46
 ---- batch: 020 ----
mean loss: 58.83
 ---- batch: 030 ----
mean loss: 57.75
train mean loss: 58.02
epoch train time: 0:00:00.588132
elapsed time: 0:01:41.460309
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:34:13.157672
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.04
 ---- batch: 020 ----
mean loss: 57.35
 ---- batch: 030 ----
mean loss: 60.04
train mean loss: 57.75
epoch train time: 0:00:00.572738
elapsed time: 0:01:42.033388
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:34:13.730743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.12
 ---- batch: 020 ----
mean loss: 56.62
 ---- batch: 030 ----
mean loss: 56.50
train mean loss: 57.33
epoch train time: 0:00:00.582274
elapsed time: 0:01:42.615989
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:34:14.313329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.71
 ---- batch: 020 ----
mean loss: 57.26
 ---- batch: 030 ----
mean loss: 57.63
train mean loss: 57.73
epoch train time: 0:00:00.581872
elapsed time: 0:01:43.198198
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:34:14.895581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.79
 ---- batch: 020 ----
mean loss: 58.32
 ---- batch: 030 ----
mean loss: 54.28
train mean loss: 55.85
epoch train time: 0:00:00.574441
elapsed time: 0:01:43.773028
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:34:15.470372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.00
 ---- batch: 020 ----
mean loss: 54.21
 ---- batch: 030 ----
mean loss: 54.79
train mean loss: 55.97
epoch train time: 0:00:00.584300
elapsed time: 0:01:44.357645
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:34:16.054998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.77
 ---- batch: 020 ----
mean loss: 54.97
 ---- batch: 030 ----
mean loss: 59.45
train mean loss: 56.20
epoch train time: 0:00:00.575279
elapsed time: 0:01:44.933250
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:34:16.630581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.54
 ---- batch: 020 ----
mean loss: 54.16
 ---- batch: 030 ----
mean loss: 54.01
train mean loss: 55.46
epoch train time: 0:00:00.576663
elapsed time: 0:01:45.510252
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:34:17.207589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.17
 ---- batch: 020 ----
mean loss: 55.90
 ---- batch: 030 ----
mean loss: 55.16
train mean loss: 54.90
epoch train time: 0:00:00.579399
elapsed time: 0:01:46.089977
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:34:17.787322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.45
 ---- batch: 020 ----
mean loss: 54.33
 ---- batch: 030 ----
mean loss: 52.81
train mean loss: 54.03
epoch train time: 0:00:00.572506
elapsed time: 0:01:46.662795
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:34:18.360128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.41
 ---- batch: 020 ----
mean loss: 53.25
 ---- batch: 030 ----
mean loss: 53.49
train mean loss: 53.74
epoch train time: 0:00:00.578719
elapsed time: 0:01:47.241838
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:34:18.939194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.67
 ---- batch: 020 ----
mean loss: 51.61
 ---- batch: 030 ----
mean loss: 55.10
train mean loss: 53.06
epoch train time: 0:00:00.578808
elapsed time: 0:01:47.820989
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:34:19.518328
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.34
 ---- batch: 020 ----
mean loss: 52.05
 ---- batch: 030 ----
mean loss: 51.77
train mean loss: 53.38
epoch train time: 0:00:00.574753
elapsed time: 0:01:48.396073
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:34:20.093419
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.22
 ---- batch: 020 ----
mean loss: 50.39
 ---- batch: 030 ----
mean loss: 54.20
train mean loss: 52.98
epoch train time: 0:00:00.570210
elapsed time: 0:01:48.966600
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:34:20.663937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.68
 ---- batch: 020 ----
mean loss: 51.74
 ---- batch: 030 ----
mean loss: 51.01
train mean loss: 52.49
epoch train time: 0:00:00.568998
elapsed time: 0:01:49.535900
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:34:21.233231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.51
 ---- batch: 020 ----
mean loss: 53.19
 ---- batch: 030 ----
mean loss: 51.79
train mean loss: 51.65
epoch train time: 0:00:00.577008
elapsed time: 0:01:50.113215
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:34:21.810555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.28
 ---- batch: 020 ----
mean loss: 50.62
 ---- batch: 030 ----
mean loss: 51.89
train mean loss: 51.13
epoch train time: 0:00:00.566930
elapsed time: 0:01:50.680485
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:34:22.377819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.50
 ---- batch: 020 ----
mean loss: 52.44
 ---- batch: 030 ----
mean loss: 49.61
train mean loss: 51.58
epoch train time: 0:00:00.583238
elapsed time: 0:01:51.264026
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:34:22.961371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.57
 ---- batch: 020 ----
mean loss: 49.45
 ---- batch: 030 ----
mean loss: 49.58
train mean loss: 50.26
epoch train time: 0:00:00.585126
elapsed time: 0:01:51.849487
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:34:23.546829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.53
 ---- batch: 020 ----
mean loss: 50.81
 ---- batch: 030 ----
mean loss: 49.40
train mean loss: 49.65
epoch train time: 0:00:00.606848
elapsed time: 0:01:52.456756
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:34:24.154039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.60
 ---- batch: 020 ----
mean loss: 49.39
 ---- batch: 030 ----
mean loss: 50.63
train mean loss: 49.11
epoch train time: 0:00:00.580004
elapsed time: 0:01:53.037028
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:34:24.734368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.27
 ---- batch: 020 ----
mean loss: 48.25
 ---- batch: 030 ----
mean loss: 50.12
train mean loss: 49.19
epoch train time: 0:00:00.572501
elapsed time: 0:01:53.609846
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:34:25.307182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.96
 ---- batch: 020 ----
mean loss: 48.98
 ---- batch: 030 ----
mean loss: 48.32
train mean loss: 48.40
epoch train time: 0:00:00.572326
elapsed time: 0:01:54.182528
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:34:25.879867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.16
 ---- batch: 020 ----
mean loss: 48.97
 ---- batch: 030 ----
mean loss: 49.47
train mean loss: 48.34
epoch train time: 0:00:00.557023
elapsed time: 0:01:54.739894
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:34:26.437253
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.33
 ---- batch: 020 ----
mean loss: 48.51
 ---- batch: 030 ----
mean loss: 44.97
train mean loss: 47.81
epoch train time: 0:00:00.572023
elapsed time: 0:01:55.312242
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:34:27.009628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.58
 ---- batch: 020 ----
mean loss: 46.23
 ---- batch: 030 ----
mean loss: 47.54
train mean loss: 46.81
epoch train time: 0:00:00.568813
elapsed time: 0:01:55.881430
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:34:27.578787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.94
 ---- batch: 020 ----
mean loss: 47.53
 ---- batch: 030 ----
mean loss: 47.36
train mean loss: 46.24
epoch train time: 0:00:00.562578
elapsed time: 0:01:56.444340
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:34:28.141696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.62
 ---- batch: 020 ----
mean loss: 49.32
 ---- batch: 030 ----
mean loss: 47.45
train mean loss: 46.97
epoch train time: 0:00:00.557406
elapsed time: 0:01:57.002087
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:34:28.699432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.26
 ---- batch: 020 ----
mean loss: 47.49
 ---- batch: 030 ----
mean loss: 44.47
train mean loss: 45.64
epoch train time: 0:00:00.580430
elapsed time: 0:01:57.582843
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:34:29.280216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.18
 ---- batch: 020 ----
mean loss: 47.22
 ---- batch: 030 ----
mean loss: 46.48
train mean loss: 45.69
epoch train time: 0:00:00.584500
elapsed time: 0:01:58.167702
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:34:29.865043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.13
 ---- batch: 020 ----
mean loss: 44.88
 ---- batch: 030 ----
mean loss: 43.32
train mean loss: 44.05
epoch train time: 0:00:00.575361
elapsed time: 0:01:58.743372
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:34:30.440723
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.95
 ---- batch: 020 ----
mean loss: 43.51
 ---- batch: 030 ----
mean loss: 45.26
train mean loss: 45.07
epoch train time: 0:00:00.576117
elapsed time: 0:01:59.319897
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:34:31.017233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.56
 ---- batch: 020 ----
mean loss: 45.26
 ---- batch: 030 ----
mean loss: 42.78
train mean loss: 44.83
epoch train time: 0:00:00.573419
elapsed time: 0:01:59.893622
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:34:31.590971
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.63
 ---- batch: 020 ----
mean loss: 42.81
 ---- batch: 030 ----
mean loss: 45.99
train mean loss: 43.92
epoch train time: 0:00:00.571667
elapsed time: 0:02:00.465621
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:34:32.162961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.01
 ---- batch: 020 ----
mean loss: 43.64
 ---- batch: 030 ----
mean loss: 42.23
train mean loss: 43.03
epoch train time: 0:00:00.587059
elapsed time: 0:02:01.052991
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:34:32.750329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.52
 ---- batch: 020 ----
mean loss: 41.73
 ---- batch: 030 ----
mean loss: 42.97
train mean loss: 42.73
epoch train time: 0:00:00.576432
elapsed time: 0:02:01.629803
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:34:33.327172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.66
 ---- batch: 020 ----
mean loss: 41.83
 ---- batch: 030 ----
mean loss: 42.17
train mean loss: 41.82
epoch train time: 0:00:00.580881
elapsed time: 0:02:02.211025
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:34:33.908362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.80
 ---- batch: 020 ----
mean loss: 41.78
 ---- batch: 030 ----
mean loss: 42.48
train mean loss: 42.41
epoch train time: 0:00:00.577282
elapsed time: 0:02:02.788779
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:34:34.486179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.33
 ---- batch: 020 ----
mean loss: 40.49
 ---- batch: 030 ----
mean loss: 44.27
train mean loss: 41.56
epoch train time: 0:00:00.575659
elapsed time: 0:02:03.364810
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:34:35.062142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.07
 ---- batch: 020 ----
mean loss: 43.09
 ---- batch: 030 ----
mean loss: 42.24
train mean loss: 42.02
epoch train time: 0:00:00.582338
elapsed time: 0:02:03.947529
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:34:35.644870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.02
 ---- batch: 020 ----
mean loss: 40.18
 ---- batch: 030 ----
mean loss: 41.68
train mean loss: 41.04
epoch train time: 0:00:00.571685
elapsed time: 0:02:04.519559
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:34:36.216907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.69
 ---- batch: 020 ----
mean loss: 42.27
 ---- batch: 030 ----
mean loss: 39.81
train mean loss: 41.46
epoch train time: 0:00:00.589774
elapsed time: 0:02:05.109689
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:34:36.807031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.57
 ---- batch: 020 ----
mean loss: 40.64
 ---- batch: 030 ----
mean loss: 38.23
train mean loss: 40.06
epoch train time: 0:00:00.566445
elapsed time: 0:02:05.676455
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:34:37.373807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.51
 ---- batch: 020 ----
mean loss: 40.36
 ---- batch: 030 ----
mean loss: 39.01
train mean loss: 39.79
epoch train time: 0:00:00.590537
elapsed time: 0:02:06.267328
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:34:37.964679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.50
 ---- batch: 020 ----
mean loss: 40.63
 ---- batch: 030 ----
mean loss: 38.85
train mean loss: 39.33
epoch train time: 0:00:00.578713
elapsed time: 0:02:06.846360
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:34:38.543717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.06
 ---- batch: 020 ----
mean loss: 36.54
 ---- batch: 030 ----
mean loss: 41.85
train mean loss: 39.27
epoch train time: 0:00:00.581722
elapsed time: 0:02:07.428448
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:34:39.125782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.44
 ---- batch: 020 ----
mean loss: 36.80
 ---- batch: 030 ----
mean loss: 38.71
train mean loss: 38.31
epoch train time: 0:00:00.575794
elapsed time: 0:02:08.004582
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:34:39.701940
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.60
 ---- batch: 020 ----
mean loss: 38.25
 ---- batch: 030 ----
mean loss: 40.36
train mean loss: 38.17
epoch train time: 0:00:00.583054
elapsed time: 0:02:08.588046
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:34:40.285327
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.98
 ---- batch: 020 ----
mean loss: 38.50
 ---- batch: 030 ----
mean loss: 36.13
train mean loss: 37.02
epoch train time: 0:00:00.590216
elapsed time: 0:02:09.178704
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:34:40.876054
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.97
 ---- batch: 020 ----
mean loss: 35.82
 ---- batch: 030 ----
mean loss: 37.80
train mean loss: 37.60
epoch train time: 0:00:00.591726
elapsed time: 0:02:09.770753
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:34:41.468089
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.86
 ---- batch: 020 ----
mean loss: 37.01
 ---- batch: 030 ----
mean loss: 37.90
train mean loss: 37.17
epoch train time: 0:00:00.591031
elapsed time: 0:02:10.362103
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:34:42.059444
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.44
 ---- batch: 020 ----
mean loss: 38.38
 ---- batch: 030 ----
mean loss: 36.45
train mean loss: 37.29
epoch train time: 0:00:00.594629
elapsed time: 0:02:10.957122
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:34:42.654519
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.51
 ---- batch: 020 ----
mean loss: 37.10
 ---- batch: 030 ----
mean loss: 39.25
train mean loss: 37.62
epoch train time: 0:00:00.578855
elapsed time: 0:02:11.536359
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:34:43.233715
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.63
 ---- batch: 020 ----
mean loss: 36.30
 ---- batch: 030 ----
mean loss: 38.49
train mean loss: 37.46
epoch train time: 0:00:00.584339
elapsed time: 0:02:12.121046
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:34:43.818384
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.76
 ---- batch: 020 ----
mean loss: 38.37
 ---- batch: 030 ----
mean loss: 36.34
train mean loss: 37.37
epoch train time: 0:00:00.590502
elapsed time: 0:02:12.711897
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:34:44.409233
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 38.31
 ---- batch: 020 ----
mean loss: 37.43
 ---- batch: 030 ----
mean loss: 36.36
train mean loss: 37.08
epoch train time: 0:00:00.587288
elapsed time: 0:02:13.299531
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:34:44.996871
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.95
 ---- batch: 020 ----
mean loss: 36.01
 ---- batch: 030 ----
mean loss: 38.99
train mean loss: 37.22
epoch train time: 0:00:00.581037
elapsed time: 0:02:13.880887
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:34:45.578224
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.65
 ---- batch: 020 ----
mean loss: 37.00
 ---- batch: 030 ----
mean loss: 35.45
train mean loss: 37.20
epoch train time: 0:00:00.587015
elapsed time: 0:02:14.468226
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:34:46.165565
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.06
 ---- batch: 020 ----
mean loss: 37.46
 ---- batch: 030 ----
mean loss: 37.66
train mean loss: 36.99
epoch train time: 0:00:00.587710
elapsed time: 0:02:15.056269
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:34:46.753629
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.92
 ---- batch: 020 ----
mean loss: 35.58
 ---- batch: 030 ----
mean loss: 37.85
train mean loss: 37.22
epoch train time: 0:00:00.578667
elapsed time: 0:02:15.635281
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:34:47.332617
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.74
 ---- batch: 020 ----
mean loss: 36.63
 ---- batch: 030 ----
mean loss: 37.16
train mean loss: 36.78
epoch train time: 0:00:00.587573
elapsed time: 0:02:16.223180
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:34:47.920515
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.23
 ---- batch: 020 ----
mean loss: 37.63
 ---- batch: 030 ----
mean loss: 39.13
train mean loss: 37.29
epoch train time: 0:00:00.573785
elapsed time: 0:02:16.797284
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:34:48.494640
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.49
 ---- batch: 020 ----
mean loss: 37.26
 ---- batch: 030 ----
mean loss: 36.11
train mean loss: 36.89
epoch train time: 0:00:00.583984
elapsed time: 0:02:17.381588
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:34:49.078916
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.63
 ---- batch: 020 ----
mean loss: 36.44
 ---- batch: 030 ----
mean loss: 38.32
train mean loss: 36.92
epoch train time: 0:00:00.579243
elapsed time: 0:02:17.961152
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:34:49.658567
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 38.16
 ---- batch: 020 ----
mean loss: 38.35
 ---- batch: 030 ----
mean loss: 34.99
train mean loss: 37.22
epoch train time: 0:00:00.583776
elapsed time: 0:02:18.545319
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:34:50.242675
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.48
 ---- batch: 020 ----
mean loss: 38.10
 ---- batch: 030 ----
mean loss: 37.20
train mean loss: 37.21
epoch train time: 0:00:00.576551
elapsed time: 0:02:19.122218
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:34:50.819556
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.39
 ---- batch: 020 ----
mean loss: 36.23
 ---- batch: 030 ----
mean loss: 38.73
train mean loss: 36.81
epoch train time: 0:00:00.553226
elapsed time: 0:02:19.675753
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:34:51.373095
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.45
 ---- batch: 020 ----
mean loss: 36.59
 ---- batch: 030 ----
mean loss: 36.97
train mean loss: 36.64
epoch train time: 0:00:00.554575
elapsed time: 0:02:20.230641
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:34:51.927970
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.86
 ---- batch: 020 ----
mean loss: 36.67
 ---- batch: 030 ----
mean loss: 36.74
train mean loss: 36.60
epoch train time: 0:00:00.556326
elapsed time: 0:02:20.787265
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:34:52.484604
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.27
 ---- batch: 020 ----
mean loss: 36.42
 ---- batch: 030 ----
mean loss: 38.76
train mean loss: 36.66
epoch train time: 0:00:00.575471
elapsed time: 0:02:21.363065
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:34:53.060407
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.43
 ---- batch: 020 ----
mean loss: 36.18
 ---- batch: 030 ----
mean loss: 37.45
train mean loss: 36.87
epoch train time: 0:00:00.575184
elapsed time: 0:02:21.938563
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:34:53.635940
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.31
 ---- batch: 020 ----
mean loss: 35.18
 ---- batch: 030 ----
mean loss: 38.60
train mean loss: 37.05
epoch train time: 0:00:00.565186
elapsed time: 0:02:22.504089
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:34:54.201421
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.60
 ---- batch: 020 ----
mean loss: 35.38
 ---- batch: 030 ----
mean loss: 34.32
train mean loss: 36.28
epoch train time: 0:00:00.569112
elapsed time: 0:02:23.073579
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:34:54.770944
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.36
 ---- batch: 020 ----
mean loss: 35.85
 ---- batch: 030 ----
mean loss: 37.55
train mean loss: 36.47
epoch train time: 0:00:00.593490
elapsed time: 0:02:23.667438
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:34:55.364771
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.82
 ---- batch: 020 ----
mean loss: 35.46
 ---- batch: 030 ----
mean loss: 36.61
train mean loss: 36.43
epoch train time: 0:00:00.587599
elapsed time: 0:02:24.255375
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:34:55.952716
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.16
 ---- batch: 020 ----
mean loss: 36.21
 ---- batch: 030 ----
mean loss: 36.08
train mean loss: 36.16
epoch train time: 0:00:00.578151
elapsed time: 0:02:24.833850
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:34:56.531196
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.46
 ---- batch: 020 ----
mean loss: 37.69
 ---- batch: 030 ----
mean loss: 35.27
train mean loss: 35.99
epoch train time: 0:00:00.588142
elapsed time: 0:02:25.422360
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:34:57.119744
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.49
 ---- batch: 020 ----
mean loss: 36.11
 ---- batch: 030 ----
mean loss: 36.37
train mean loss: 36.52
epoch train time: 0:00:00.571219
elapsed time: 0:02:25.993945
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:34:57.691278
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.11
 ---- batch: 020 ----
mean loss: 38.18
 ---- batch: 030 ----
mean loss: 34.76
train mean loss: 36.13
epoch train time: 0:00:00.588315
elapsed time: 0:02:26.582567
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:34:58.279929
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.70
 ---- batch: 020 ----
mean loss: 36.94
 ---- batch: 030 ----
mean loss: 34.32
train mean loss: 36.18
epoch train time: 0:00:00.589871
elapsed time: 0:02:27.172843
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:34:58.870124
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.34
 ---- batch: 020 ----
mean loss: 37.78
 ---- batch: 030 ----
mean loss: 34.07
train mean loss: 36.32
epoch train time: 0:00:00.577982
elapsed time: 0:02:27.751071
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:34:59.448404
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 38.68
 ---- batch: 020 ----
mean loss: 36.12
 ---- batch: 030 ----
mean loss: 35.90
train mean loss: 36.61
epoch train time: 0:00:00.592293
elapsed time: 0:02:28.343696
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:35:00.041033
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.19
 ---- batch: 020 ----
mean loss: 35.56
 ---- batch: 030 ----
mean loss: 37.47
train mean loss: 36.33
epoch train time: 0:00:00.589946
elapsed time: 0:02:28.934008
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:35:00.631504
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.18
 ---- batch: 020 ----
mean loss: 36.17
 ---- batch: 030 ----
mean loss: 35.40
train mean loss: 35.84
epoch train time: 0:00:00.582330
elapsed time: 0:02:29.516864
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:35:01.214210
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.96
 ---- batch: 020 ----
mean loss: 36.07
 ---- batch: 030 ----
mean loss: 35.74
train mean loss: 35.73
epoch train time: 0:00:00.573065
elapsed time: 0:02:30.090262
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:35:01.787599
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 38.19
 ---- batch: 020 ----
mean loss: 35.09
 ---- batch: 030 ----
mean loss: 34.52
train mean loss: 35.96
epoch train time: 0:00:00.577927
elapsed time: 0:02:30.668570
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:35:02.365945
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.35
 ---- batch: 020 ----
mean loss: 37.42
 ---- batch: 030 ----
mean loss: 34.53
train mean loss: 35.69
epoch train time: 0:00:00.588170
elapsed time: 0:02:31.257128
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:35:02.954462
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.61
 ---- batch: 020 ----
mean loss: 35.80
 ---- batch: 030 ----
mean loss: 35.83
train mean loss: 36.03
epoch train time: 0:00:00.586819
elapsed time: 0:02:31.844329
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:35:03.541733
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.55
 ---- batch: 020 ----
mean loss: 35.73
 ---- batch: 030 ----
mean loss: 35.10
train mean loss: 35.83
epoch train time: 0:00:00.591071
elapsed time: 0:02:32.435839
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:35:04.133174
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.82
 ---- batch: 020 ----
mean loss: 37.06
 ---- batch: 030 ----
mean loss: 35.05
train mean loss: 35.99
epoch train time: 0:00:00.584009
elapsed time: 0:02:33.020179
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:35:04.717511
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.41
 ---- batch: 020 ----
mean loss: 36.32
 ---- batch: 030 ----
mean loss: 37.51
train mean loss: 35.81
epoch train time: 0:00:00.580692
elapsed time: 0:02:33.601193
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:35:05.298529
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.50
 ---- batch: 020 ----
mean loss: 35.93
 ---- batch: 030 ----
mean loss: 36.38
train mean loss: 35.63
epoch train time: 0:00:00.572283
elapsed time: 0:02:34.173797
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:35:05.871157
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.06
 ---- batch: 020 ----
mean loss: 34.61
 ---- batch: 030 ----
mean loss: 35.99
train mean loss: 35.42
epoch train time: 0:00:00.567446
elapsed time: 0:02:34.741565
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:35:06.438918
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.12
 ---- batch: 020 ----
mean loss: 33.66
 ---- batch: 030 ----
mean loss: 36.21
train mean loss: 35.43
epoch train time: 0:00:00.586384
elapsed time: 0:02:35.328280
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:35:07.025635
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.79
 ---- batch: 020 ----
mean loss: 35.36
 ---- batch: 030 ----
mean loss: 34.21
train mean loss: 35.56
epoch train time: 0:00:00.571903
elapsed time: 0:02:35.900560
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:35:07.597910
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.03
 ---- batch: 020 ----
mean loss: 36.71
 ---- batch: 030 ----
mean loss: 36.43
train mean loss: 36.07
epoch train time: 0:00:00.565962
elapsed time: 0:02:36.474176
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_9/checkpoint.pth.tar
**** end time: 2019-09-27 15:35:08.171430 ****
