Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_1', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 28873
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 14:41:48.854223 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 14:41:48.864983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4111.77
 ---- batch: 020 ----
mean loss: 3964.92
 ---- batch: 030 ----
mean loss: 4013.65
train mean loss: 4027.49
epoch train time: 0:00:12.626758
elapsed time: 0:00:12.640610
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 14:42:01.494877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3955.72
 ---- batch: 020 ----
mean loss: 3861.47
 ---- batch: 030 ----
mean loss: 3825.23
train mean loss: 3871.30
epoch train time: 0:00:00.532700
elapsed time: 0:00:13.173565
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 14:42:02.027889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3729.94
 ---- batch: 020 ----
mean loss: 3659.96
 ---- batch: 030 ----
mean loss: 3614.97
train mean loss: 3648.55
epoch train time: 0:00:00.525788
elapsed time: 0:00:13.699650
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 14:42:02.553972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3486.97
 ---- batch: 020 ----
mean loss: 3406.56
 ---- batch: 030 ----
mean loss: 3398.37
train mean loss: 3423.95
epoch train time: 0:00:00.522258
elapsed time: 0:00:14.222216
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 14:42:03.076525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3256.66
 ---- batch: 020 ----
mean loss: 3213.78
 ---- batch: 030 ----
mean loss: 3281.64
train mean loss: 3241.02
epoch train time: 0:00:00.522833
elapsed time: 0:00:14.745331
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 14:42:03.599644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3121.24
 ---- batch: 020 ----
mean loss: 3071.36
 ---- batch: 030 ----
mean loss: 3060.95
train mean loss: 3077.06
epoch train time: 0:00:00.528503
elapsed time: 0:00:15.274096
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 14:42:04.128403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2997.16
 ---- batch: 020 ----
mean loss: 2923.32
 ---- batch: 030 ----
mean loss: 2879.28
train mean loss: 2925.80
epoch train time: 0:00:00.517854
elapsed time: 0:00:15.792223
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 14:42:04.646529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2840.02
 ---- batch: 020 ----
mean loss: 2838.23
 ---- batch: 030 ----
mean loss: 2731.71
train mean loss: 2793.74
epoch train time: 0:00:00.534182
elapsed time: 0:00:16.326668
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 14:42:05.180977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2684.39
 ---- batch: 020 ----
mean loss: 2651.32
 ---- batch: 030 ----
mean loss: 2626.52
train mean loss: 2644.01
epoch train time: 0:00:00.521072
elapsed time: 0:00:16.848065
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 14:42:05.702377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2540.92
 ---- batch: 020 ----
mean loss: 2492.03
 ---- batch: 030 ----
mean loss: 2462.07
train mean loss: 2484.22
epoch train time: 0:00:00.534718
elapsed time: 0:00:17.383058
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 14:42:06.237367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2370.41
 ---- batch: 020 ----
mean loss: 2357.78
 ---- batch: 030 ----
mean loss: 2302.10
train mean loss: 2330.58
epoch train time: 0:00:00.522026
elapsed time: 0:00:17.905355
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 14:42:06.759666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2227.36
 ---- batch: 020 ----
mean loss: 2215.99
 ---- batch: 030 ----
mean loss: 2147.55
train mean loss: 2192.70
epoch train time: 0:00:00.514342
elapsed time: 0:00:18.419981
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 14:42:07.274290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2126.00
 ---- batch: 020 ----
mean loss: 2070.54
 ---- batch: 030 ----
mean loss: 2074.40
train mean loss: 2073.67
epoch train time: 0:00:00.514105
elapsed time: 0:00:18.934421
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 14:42:07.788764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2035.85
 ---- batch: 020 ----
mean loss: 1969.45
 ---- batch: 030 ----
mean loss: 1918.02
train mean loss: 1961.28
epoch train time: 0:00:00.530643
elapsed time: 0:00:19.465429
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 14:42:08.319757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1887.79
 ---- batch: 020 ----
mean loss: 1869.26
 ---- batch: 030 ----
mean loss: 1842.29
train mean loss: 1860.18
epoch train time: 0:00:00.535051
elapsed time: 0:00:20.000790
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 14:42:08.855103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1786.11
 ---- batch: 020 ----
mean loss: 1762.67
 ---- batch: 030 ----
mean loss: 1778.98
train mean loss: 1771.95
epoch train time: 0:00:00.527386
elapsed time: 0:00:20.528486
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 14:42:09.382797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1716.35
 ---- batch: 020 ----
mean loss: 1677.88
 ---- batch: 030 ----
mean loss: 1661.37
train mean loss: 1679.37
epoch train time: 0:00:00.519774
elapsed time: 0:00:21.048525
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 14:42:09.902864
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1613.63
 ---- batch: 020 ----
mean loss: 1600.29
 ---- batch: 030 ----
mean loss: 1530.47
train mean loss: 1578.22
epoch train time: 0:00:00.519677
elapsed time: 0:00:21.568494
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 14:42:10.422806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1524.68
 ---- batch: 020 ----
mean loss: 1499.93
 ---- batch: 030 ----
mean loss: 1446.11
train mean loss: 1481.71
epoch train time: 0:00:00.524538
elapsed time: 0:00:22.093326
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 14:42:10.947656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1416.89
 ---- batch: 020 ----
mean loss: 1385.42
 ---- batch: 030 ----
mean loss: 1364.23
train mean loss: 1383.27
epoch train time: 0:00:00.519893
elapsed time: 0:00:22.613528
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 14:42:11.467848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1317.64
 ---- batch: 020 ----
mean loss: 1328.34
 ---- batch: 030 ----
mean loss: 1292.70
train mean loss: 1313.34
epoch train time: 0:00:00.539373
elapsed time: 0:00:23.153185
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 14:42:12.007498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1259.38
 ---- batch: 020 ----
mean loss: 1263.22
 ---- batch: 030 ----
mean loss: 1223.18
train mean loss: 1239.41
epoch train time: 0:00:00.522076
elapsed time: 0:00:23.675544
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 14:42:12.529855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1215.28
 ---- batch: 020 ----
mean loss: 1173.93
 ---- batch: 030 ----
mean loss: 1168.66
train mean loss: 1174.28
epoch train time: 0:00:00.521612
elapsed time: 0:00:24.197434
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 14:42:13.051743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1126.40
 ---- batch: 020 ----
mean loss: 1125.72
 ---- batch: 030 ----
mean loss: 1122.48
train mean loss: 1115.52
epoch train time: 0:00:00.518681
elapsed time: 0:00:24.716377
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 14:42:13.570684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1083.56
 ---- batch: 020 ----
mean loss: 1074.18
 ---- batch: 030 ----
mean loss: 1048.83
train mean loss: 1060.60
epoch train time: 0:00:00.541893
elapsed time: 0:00:25.258537
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 14:42:14.112851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1018.34
 ---- batch: 020 ----
mean loss: 1034.58
 ---- batch: 030 ----
mean loss: 1004.93
train mean loss: 1015.62
epoch train time: 0:00:00.522896
elapsed time: 0:00:25.781735
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 14:42:14.636046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 987.48
 ---- batch: 020 ----
mean loss: 980.67
 ---- batch: 030 ----
mean loss: 940.64
train mean loss: 969.72
epoch train time: 0:00:00.523042
elapsed time: 0:00:26.305067
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 14:42:15.159396
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 944.95
 ---- batch: 020 ----
mean loss: 932.19
 ---- batch: 030 ----
mean loss: 902.66
train mean loss: 922.12
epoch train time: 0:00:00.522066
elapsed time: 0:00:26.827450
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 14:42:15.681769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 887.90
 ---- batch: 020 ----
mean loss: 910.79
 ---- batch: 030 ----
mean loss: 871.12
train mean loss: 883.33
epoch train time: 0:00:00.528435
elapsed time: 0:00:27.356207
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 14:42:16.210524
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 854.24
 ---- batch: 020 ----
mean loss: 843.38
 ---- batch: 030 ----
mean loss: 838.20
train mean loss: 844.38
epoch train time: 0:00:00.529478
elapsed time: 0:00:27.885976
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 14:42:16.740282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 806.66
 ---- batch: 020 ----
mean loss: 785.83
 ---- batch: 030 ----
mean loss: 792.73
train mean loss: 792.74
epoch train time: 0:00:00.532147
elapsed time: 0:00:28.418425
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 14:42:17.272762
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 771.06
 ---- batch: 020 ----
mean loss: 750.83
 ---- batch: 030 ----
mean loss: 731.74
train mean loss: 746.48
epoch train time: 0:00:00.523933
elapsed time: 0:00:28.942663
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 14:42:17.796984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 734.31
 ---- batch: 020 ----
mean loss: 712.77
 ---- batch: 030 ----
mean loss: 694.13
train mean loss: 714.27
epoch train time: 0:00:00.526177
elapsed time: 0:00:29.469118
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 14:42:18.323457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 698.69
 ---- batch: 020 ----
mean loss: 699.53
 ---- batch: 030 ----
mean loss: 674.80
train mean loss: 687.80
epoch train time: 0:00:00.526929
elapsed time: 0:00:29.996456
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 14:42:18.850797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 665.75
 ---- batch: 020 ----
mean loss: 657.56
 ---- batch: 030 ----
mean loss: 653.37
train mean loss: 657.26
epoch train time: 0:00:00.520501
elapsed time: 0:00:30.517267
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 14:42:19.371576
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 639.93
 ---- batch: 020 ----
mean loss: 628.10
 ---- batch: 030 ----
mean loss: 646.54
train mean loss: 637.11
epoch train time: 0:00:00.524408
elapsed time: 0:00:31.041999
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 14:42:19.896311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 611.92
 ---- batch: 020 ----
mean loss: 611.53
 ---- batch: 030 ----
mean loss: 608.96
train mean loss: 606.79
epoch train time: 0:00:00.524384
elapsed time: 0:00:31.566658
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 14:42:20.420980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 591.77
 ---- batch: 020 ----
mean loss: 593.90
 ---- batch: 030 ----
mean loss: 589.95
train mean loss: 590.13
epoch train time: 0:00:00.526541
elapsed time: 0:00:32.093507
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 14:42:20.947836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 575.08
 ---- batch: 020 ----
mean loss: 561.64
 ---- batch: 030 ----
mean loss: 569.25
train mean loss: 567.35
epoch train time: 0:00:00.527889
elapsed time: 0:00:32.621679
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 14:42:21.475994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 559.83
 ---- batch: 020 ----
mean loss: 553.90
 ---- batch: 030 ----
mean loss: 549.08
train mean loss: 555.06
epoch train time: 0:00:00.528648
elapsed time: 0:00:33.150590
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 14:42:22.004894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 537.62
 ---- batch: 020 ----
mean loss: 535.50
 ---- batch: 030 ----
mean loss: 544.33
train mean loss: 540.25
epoch train time: 0:00:00.511105
elapsed time: 0:00:33.661981
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 14:42:22.516315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 523.62
 ---- batch: 020 ----
mean loss: 524.57
 ---- batch: 030 ----
mean loss: 538.88
train mean loss: 528.04
epoch train time: 0:00:00.526259
elapsed time: 0:00:34.188598
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 14:42:23.042918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 517.11
 ---- batch: 020 ----
mean loss: 509.84
 ---- batch: 030 ----
mean loss: 508.31
train mean loss: 510.94
epoch train time: 0:00:00.509673
elapsed time: 0:00:34.698597
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 14:42:23.552955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 499.71
 ---- batch: 020 ----
mean loss: 513.68
 ---- batch: 030 ----
mean loss: 500.10
train mean loss: 502.80
epoch train time: 0:00:00.527079
elapsed time: 0:00:35.226001
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 14:42:24.080308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 493.35
 ---- batch: 020 ----
mean loss: 488.97
 ---- batch: 030 ----
mean loss: 500.33
train mean loss: 494.18
epoch train time: 0:00:00.510158
elapsed time: 0:00:35.736416
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 14:42:24.590722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 484.07
 ---- batch: 020 ----
mean loss: 479.24
 ---- batch: 030 ----
mean loss: 477.68
train mean loss: 481.55
epoch train time: 0:00:00.525446
elapsed time: 0:00:36.262142
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 14:42:25.116468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 472.73
 ---- batch: 020 ----
mean loss: 485.65
 ---- batch: 030 ----
mean loss: 472.20
train mean loss: 475.71
epoch train time: 0:00:00.518633
elapsed time: 0:00:36.781086
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 14:42:25.635405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 465.22
 ---- batch: 020 ----
mean loss: 468.75
 ---- batch: 030 ----
mean loss: 465.83
train mean loss: 463.42
epoch train time: 0:00:00.535335
elapsed time: 0:00:37.316715
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 14:42:26.171045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 461.14
 ---- batch: 020 ----
mean loss: 462.36
 ---- batch: 030 ----
mean loss: 448.14
train mean loss: 456.42
epoch train time: 0:00:00.528633
elapsed time: 0:00:37.845665
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 14:42:26.700071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 461.46
 ---- batch: 020 ----
mean loss: 448.05
 ---- batch: 030 ----
mean loss: 445.41
train mean loss: 449.27
epoch train time: 0:00:00.522641
elapsed time: 0:00:38.368669
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 14:42:27.222988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 449.51
 ---- batch: 020 ----
mean loss: 431.92
 ---- batch: 030 ----
mean loss: 445.42
train mean loss: 439.45
epoch train time: 0:00:00.529628
elapsed time: 0:00:38.898601
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 14:42:27.752913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 433.21
 ---- batch: 020 ----
mean loss: 428.73
 ---- batch: 030 ----
mean loss: 436.60
train mean loss: 432.24
epoch train time: 0:00:00.522381
elapsed time: 0:00:39.421276
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 14:42:28.275601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 427.77
 ---- batch: 020 ----
mean loss: 427.79
 ---- batch: 030 ----
mean loss: 415.65
train mean loss: 423.74
epoch train time: 0:00:00.520684
elapsed time: 0:00:39.942247
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 14:42:28.796560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.65
 ---- batch: 020 ----
mean loss: 424.80
 ---- batch: 030 ----
mean loss: 419.36
train mean loss: 422.05
epoch train time: 0:00:00.524789
elapsed time: 0:00:40.467311
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 14:42:29.321659
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.28
 ---- batch: 020 ----
mean loss: 413.84
 ---- batch: 030 ----
mean loss: 416.40
train mean loss: 415.17
epoch train time: 0:00:00.531404
elapsed time: 0:00:40.999045
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 14:42:29.853355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 413.83
 ---- batch: 020 ----
mean loss: 403.70
 ---- batch: 030 ----
mean loss: 410.70
train mean loss: 407.89
epoch train time: 0:00:00.518653
elapsed time: 0:00:41.517986
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 14:42:30.372297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.69
 ---- batch: 020 ----
mean loss: 409.77
 ---- batch: 030 ----
mean loss: 397.00
train mean loss: 402.56
epoch train time: 0:00:00.536556
elapsed time: 0:00:42.054814
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 14:42:30.909121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.20
 ---- batch: 020 ----
mean loss: 395.50
 ---- batch: 030 ----
mean loss: 395.28
train mean loss: 396.25
epoch train time: 0:00:00.517771
elapsed time: 0:00:42.572875
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 14:42:31.427191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 386.88
 ---- batch: 020 ----
mean loss: 400.39
 ---- batch: 030 ----
mean loss: 390.52
train mean loss: 390.61
epoch train time: 0:00:00.538250
elapsed time: 0:00:43.111447
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 14:42:31.965814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 395.97
 ---- batch: 020 ----
mean loss: 391.72
 ---- batch: 030 ----
mean loss: 383.14
train mean loss: 388.05
epoch train time: 0:00:00.532553
elapsed time: 0:00:43.644338
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 14:42:32.498652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 384.24
 ---- batch: 020 ----
mean loss: 375.44
 ---- batch: 030 ----
mean loss: 384.30
train mean loss: 382.94
epoch train time: 0:00:00.538247
elapsed time: 0:00:44.182860
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 14:42:33.037197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.62
 ---- batch: 020 ----
mean loss: 373.07
 ---- batch: 030 ----
mean loss: 381.36
train mean loss: 376.70
epoch train time: 0:00:00.517216
elapsed time: 0:00:44.700369
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 14:42:33.554680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.27
 ---- batch: 020 ----
mean loss: 378.25
 ---- batch: 030 ----
mean loss: 365.21
train mean loss: 372.96
epoch train time: 0:00:00.518290
elapsed time: 0:00:45.218947
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 14:42:34.073259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.46
 ---- batch: 020 ----
mean loss: 373.02
 ---- batch: 030 ----
mean loss: 370.38
train mean loss: 369.39
epoch train time: 0:00:00.512535
elapsed time: 0:00:45.731751
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 14:42:34.586064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.28
 ---- batch: 020 ----
mean loss: 361.58
 ---- batch: 030 ----
mean loss: 373.07
train mean loss: 367.71
epoch train time: 0:00:00.525190
elapsed time: 0:00:46.257209
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 14:42:35.111528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 363.95
 ---- batch: 020 ----
mean loss: 362.77
 ---- batch: 030 ----
mean loss: 364.76
train mean loss: 364.69
epoch train time: 0:00:00.510280
elapsed time: 0:00:46.767775
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 14:42:35.622091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 363.63
 ---- batch: 020 ----
mean loss: 354.50
 ---- batch: 030 ----
mean loss: 359.24
train mean loss: 360.11
epoch train time: 0:00:00.526876
elapsed time: 0:00:47.294972
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 14:42:36.149296
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 363.95
 ---- batch: 020 ----
mean loss: 358.65
 ---- batch: 030 ----
mean loss: 364.69
train mean loss: 362.06
epoch train time: 0:00:00.520236
elapsed time: 0:00:47.815533
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 14:42:36.669885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 354.94
 ---- batch: 020 ----
mean loss: 359.01
 ---- batch: 030 ----
mean loss: 350.66
train mean loss: 354.06
epoch train time: 0:00:00.543668
elapsed time: 0:00:48.359567
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 14:42:37.213885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.93
 ---- batch: 020 ----
mean loss: 354.03
 ---- batch: 030 ----
mean loss: 351.03
train mean loss: 353.97
epoch train time: 0:00:00.531015
elapsed time: 0:00:48.890964
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 14:42:37.745279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.59
 ---- batch: 020 ----
mean loss: 344.95
 ---- batch: 030 ----
mean loss: 356.48
train mean loss: 351.05
epoch train time: 0:00:00.520816
elapsed time: 0:00:49.412055
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 14:42:38.266365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 353.12
 ---- batch: 020 ----
mean loss: 345.94
 ---- batch: 030 ----
mean loss: 346.29
train mean loss: 349.16
epoch train time: 0:00:00.519544
elapsed time: 0:00:49.931882
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 14:42:38.786293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 347.65
 ---- batch: 020 ----
mean loss: 348.77
 ---- batch: 030 ----
mean loss: 342.81
train mean loss: 346.03
epoch train time: 0:00:00.513950
elapsed time: 0:00:50.446202
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 14:42:39.300507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 340.00
 ---- batch: 020 ----
mean loss: 351.33
 ---- batch: 030 ----
mean loss: 340.14
train mean loss: 343.27
epoch train time: 0:00:00.518630
elapsed time: 0:00:50.965179
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 14:42:39.819510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 344.32
 ---- batch: 020 ----
mean loss: 336.17
 ---- batch: 030 ----
mean loss: 343.60
train mean loss: 340.67
epoch train time: 0:00:00.529861
elapsed time: 0:00:51.495359
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 14:42:40.349705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.98
 ---- batch: 020 ----
mean loss: 343.86
 ---- batch: 030 ----
mean loss: 339.83
train mean loss: 339.71
epoch train time: 0:00:00.524562
elapsed time: 0:00:52.020288
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 14:42:40.874650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 343.50
 ---- batch: 020 ----
mean loss: 335.77
 ---- batch: 030 ----
mean loss: 332.85
train mean loss: 338.07
epoch train time: 0:00:00.520651
elapsed time: 0:00:52.541261
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 14:42:41.395575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 330.51
 ---- batch: 020 ----
mean loss: 339.74
 ---- batch: 030 ----
mean loss: 337.11
train mean loss: 336.17
epoch train time: 0:00:00.519698
elapsed time: 0:00:53.061242
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 14:42:41.915558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 342.50
 ---- batch: 020 ----
mean loss: 329.21
 ---- batch: 030 ----
mean loss: 329.68
train mean loss: 335.35
epoch train time: 0:00:00.525620
elapsed time: 0:00:53.587140
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 14:42:42.441465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 328.96
 ---- batch: 020 ----
mean loss: 332.00
 ---- batch: 030 ----
mean loss: 338.54
train mean loss: 332.79
epoch train time: 0:00:00.524409
elapsed time: 0:00:54.111857
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 14:42:42.966174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.10
 ---- batch: 020 ----
mean loss: 332.42
 ---- batch: 030 ----
mean loss: 341.24
train mean loss: 331.42
epoch train time: 0:00:00.514514
elapsed time: 0:00:54.626644
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 14:42:43.480976
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.96
 ---- batch: 020 ----
mean loss: 329.29
 ---- batch: 030 ----
mean loss: 328.53
train mean loss: 328.42
epoch train time: 0:00:00.535307
elapsed time: 0:00:55.162253
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 14:42:44.016583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.80
 ---- batch: 020 ----
mean loss: 324.60
 ---- batch: 030 ----
mean loss: 328.27
train mean loss: 326.97
epoch train time: 0:00:00.531222
elapsed time: 0:00:55.693765
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 14:42:44.548083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.28
 ---- batch: 020 ----
mean loss: 327.52
 ---- batch: 030 ----
mean loss: 324.24
train mean loss: 323.34
epoch train time: 0:00:00.536848
elapsed time: 0:00:56.230889
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 14:42:45.085259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.98
 ---- batch: 020 ----
mean loss: 321.64
 ---- batch: 030 ----
mean loss: 324.95
train mean loss: 324.17
epoch train time: 0:00:00.511160
elapsed time: 0:00:56.742380
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 14:42:45.596687
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.78
 ---- batch: 020 ----
mean loss: 325.03
 ---- batch: 030 ----
mean loss: 322.42
train mean loss: 322.38
epoch train time: 0:00:00.529613
elapsed time: 0:00:57.272261
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 14:42:46.126568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.62
 ---- batch: 020 ----
mean loss: 320.62
 ---- batch: 030 ----
mean loss: 315.45
train mean loss: 319.63
epoch train time: 0:00:00.525197
elapsed time: 0:00:57.797731
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 14:42:46.652052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.88
 ---- batch: 020 ----
mean loss: 327.73
 ---- batch: 030 ----
mean loss: 308.10
train mean loss: 318.14
epoch train time: 0:00:00.535556
elapsed time: 0:00:58.333574
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 14:42:47.187905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.68
 ---- batch: 020 ----
mean loss: 311.75
 ---- batch: 030 ----
mean loss: 312.23
train mean loss: 316.63
epoch train time: 0:00:00.538041
elapsed time: 0:00:58.871972
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 14:42:47.726287
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.03
 ---- batch: 020 ----
mean loss: 313.73
 ---- batch: 030 ----
mean loss: 317.32
train mean loss: 316.72
epoch train time: 0:00:00.533184
elapsed time: 0:00:59.405463
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 14:42:48.259773
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.82
 ---- batch: 020 ----
mean loss: 316.84
 ---- batch: 030 ----
mean loss: 319.01
train mean loss: 314.77
epoch train time: 0:00:00.521853
elapsed time: 0:00:59.927643
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 14:42:48.781952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.86
 ---- batch: 020 ----
mean loss: 315.15
 ---- batch: 030 ----
mean loss: 315.25
train mean loss: 312.89
epoch train time: 0:00:00.527359
elapsed time: 0:01:00.455337
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 14:42:49.309699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 316.69
 ---- batch: 020 ----
mean loss: 313.85
 ---- batch: 030 ----
mean loss: 309.90
train mean loss: 312.47
epoch train time: 0:00:00.525349
elapsed time: 0:01:00.981052
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 14:42:49.835364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.74
 ---- batch: 020 ----
mean loss: 307.66
 ---- batch: 030 ----
mean loss: 310.63
train mean loss: 309.63
epoch train time: 0:00:00.532192
elapsed time: 0:01:01.513552
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 14:42:50.367867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.25
 ---- batch: 020 ----
mean loss: 303.20
 ---- batch: 030 ----
mean loss: 313.44
train mean loss: 309.05
epoch train time: 0:00:00.539953
elapsed time: 0:01:02.053774
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 14:42:50.908096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 304.90
 ---- batch: 020 ----
mean loss: 307.84
 ---- batch: 030 ----
mean loss: 314.46
train mean loss: 309.73
epoch train time: 0:00:00.513621
elapsed time: 0:01:02.567679
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 14:42:51.421993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.25
 ---- batch: 020 ----
mean loss: 304.78
 ---- batch: 030 ----
mean loss: 310.87
train mean loss: 305.61
epoch train time: 0:00:00.521190
elapsed time: 0:01:03.089153
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 14:42:51.943478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.81
 ---- batch: 020 ----
mean loss: 302.60
 ---- batch: 030 ----
mean loss: 304.00
train mean loss: 305.56
epoch train time: 0:00:00.525182
elapsed time: 0:01:03.614625
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 14:42:52.468945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 302.62
 ---- batch: 020 ----
mean loss: 301.79
 ---- batch: 030 ----
mean loss: 300.69
train mean loss: 302.86
epoch train time: 0:00:00.527515
elapsed time: 0:01:04.142419
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 14:42:52.996733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 307.53
 ---- batch: 020 ----
mean loss: 298.01
 ---- batch: 030 ----
mean loss: 305.87
train mean loss: 302.94
epoch train time: 0:00:00.521876
elapsed time: 0:01:04.664570
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 14:42:53.518884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.03
 ---- batch: 020 ----
mean loss: 303.41
 ---- batch: 030 ----
mean loss: 291.56
train mean loss: 300.62
epoch train time: 0:00:00.528064
elapsed time: 0:01:05.192959
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 14:42:54.047272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.16
 ---- batch: 020 ----
mean loss: 306.21
 ---- batch: 030 ----
mean loss: 304.24
train mean loss: 300.96
epoch train time: 0:00:00.517949
elapsed time: 0:01:05.711172
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 14:42:54.565482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.65
 ---- batch: 020 ----
mean loss: 299.51
 ---- batch: 030 ----
mean loss: 302.68
train mean loss: 299.31
epoch train time: 0:00:00.526080
elapsed time: 0:01:06.237544
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 14:42:55.091868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.15
 ---- batch: 020 ----
mean loss: 304.76
 ---- batch: 030 ----
mean loss: 301.04
train mean loss: 299.32
epoch train time: 0:00:00.523641
elapsed time: 0:01:06.761468
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 14:42:55.615776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.03
 ---- batch: 020 ----
mean loss: 300.03
 ---- batch: 030 ----
mean loss: 297.04
train mean loss: 296.70
epoch train time: 0:00:00.531890
elapsed time: 0:01:07.293619
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 14:42:56.147937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.21
 ---- batch: 020 ----
mean loss: 300.19
 ---- batch: 030 ----
mean loss: 302.61
train mean loss: 296.93
epoch train time: 0:00:00.529821
elapsed time: 0:01:07.823720
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 14:42:56.678037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.84
 ---- batch: 020 ----
mean loss: 298.82
 ---- batch: 030 ----
mean loss: 293.58
train mean loss: 294.83
epoch train time: 0:00:00.528333
elapsed time: 0:01:08.352388
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 14:42:57.206653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.07
 ---- batch: 020 ----
mean loss: 287.17
 ---- batch: 030 ----
mean loss: 298.58
train mean loss: 294.35
epoch train time: 0:00:00.523716
elapsed time: 0:01:08.876346
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 14:42:57.730683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.42
 ---- batch: 020 ----
mean loss: 298.15
 ---- batch: 030 ----
mean loss: 283.93
train mean loss: 291.58
epoch train time: 0:00:00.528894
elapsed time: 0:01:09.405549
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 14:42:58.259874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.95
 ---- batch: 020 ----
mean loss: 286.86
 ---- batch: 030 ----
mean loss: 292.73
train mean loss: 290.74
epoch train time: 0:00:00.528947
elapsed time: 0:01:09.934837
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 14:42:58.789116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.08
 ---- batch: 020 ----
mean loss: 291.42
 ---- batch: 030 ----
mean loss: 294.70
train mean loss: 290.67
epoch train time: 0:00:00.526776
elapsed time: 0:01:10.461859
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 14:42:59.316168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.00
 ---- batch: 020 ----
mean loss: 284.86
 ---- batch: 030 ----
mean loss: 290.69
train mean loss: 289.08
epoch train time: 0:00:00.527774
elapsed time: 0:01:10.989906
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 14:42:59.844220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.36
 ---- batch: 020 ----
mean loss: 286.70
 ---- batch: 030 ----
mean loss: 285.07
train mean loss: 288.94
epoch train time: 0:00:00.520151
elapsed time: 0:01:11.510330
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 14:43:00.364646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.61
 ---- batch: 020 ----
mean loss: 286.23
 ---- batch: 030 ----
mean loss: 292.40
train mean loss: 288.37
epoch train time: 0:00:00.525812
elapsed time: 0:01:12.036426
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 14:43:00.890735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 280.36
 ---- batch: 020 ----
mean loss: 289.88
 ---- batch: 030 ----
mean loss: 290.36
train mean loss: 286.02
epoch train time: 0:00:00.513539
elapsed time: 0:01:12.550238
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 14:43:01.404563
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.32
 ---- batch: 020 ----
mean loss: 291.03
 ---- batch: 030 ----
mean loss: 285.12
train mean loss: 286.90
epoch train time: 0:00:00.519076
elapsed time: 0:01:13.069611
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 14:43:01.923927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.87
 ---- batch: 020 ----
mean loss: 287.58
 ---- batch: 030 ----
mean loss: 284.85
train mean loss: 283.61
epoch train time: 0:00:00.513733
elapsed time: 0:01:13.583612
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 14:43:02.437917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.93
 ---- batch: 020 ----
mean loss: 286.33
 ---- batch: 030 ----
mean loss: 285.34
train mean loss: 282.86
epoch train time: 0:00:00.522833
elapsed time: 0:01:14.106724
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 14:43:02.961038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.85
 ---- batch: 020 ----
mean loss: 283.00
 ---- batch: 030 ----
mean loss: 281.37
train mean loss: 281.55
epoch train time: 0:00:00.520911
elapsed time: 0:01:14.627913
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 14:43:03.482227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.43
 ---- batch: 020 ----
mean loss: 276.39
 ---- batch: 030 ----
mean loss: 283.40
train mean loss: 281.25
epoch train time: 0:00:00.535298
elapsed time: 0:01:15.163503
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 14:43:04.017839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.59
 ---- batch: 020 ----
mean loss: 280.90
 ---- batch: 030 ----
mean loss: 275.70
train mean loss: 280.70
epoch train time: 0:00:00.527029
elapsed time: 0:01:15.690833
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 14:43:04.545149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.56
 ---- batch: 020 ----
mean loss: 279.81
 ---- batch: 030 ----
mean loss: 284.45
train mean loss: 279.58
epoch train time: 0:00:00.522154
elapsed time: 0:01:16.213262
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 14:43:05.067591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.07
 ---- batch: 020 ----
mean loss: 277.91
 ---- batch: 030 ----
mean loss: 279.09
train mean loss: 279.08
epoch train time: 0:00:00.522822
elapsed time: 0:01:16.736404
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 14:43:05.590718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.57
 ---- batch: 020 ----
mean loss: 276.74
 ---- batch: 030 ----
mean loss: 278.90
train mean loss: 276.64
epoch train time: 0:00:00.532073
elapsed time: 0:01:17.268792
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 14:43:06.123111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 279.39
 ---- batch: 020 ----
mean loss: 271.13
 ---- batch: 030 ----
mean loss: 276.58
train mean loss: 276.18
epoch train time: 0:00:00.534279
elapsed time: 0:01:17.803374
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 14:43:06.657728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 280.79
 ---- batch: 020 ----
mean loss: 269.18
 ---- batch: 030 ----
mean loss: 269.01
train mean loss: 275.47
epoch train time: 0:00:00.551595
elapsed time: 0:01:18.355308
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 14:43:07.209649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.38
 ---- batch: 020 ----
mean loss: 277.38
 ---- batch: 030 ----
mean loss: 274.42
train mean loss: 274.07
epoch train time: 0:00:00.543707
elapsed time: 0:01:18.899375
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 14:43:07.753681
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.26
 ---- batch: 020 ----
mean loss: 272.35
 ---- batch: 030 ----
mean loss: 276.90
train mean loss: 273.40
epoch train time: 0:00:00.537506
elapsed time: 0:01:19.437145
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 14:43:08.291519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.13
 ---- batch: 020 ----
mean loss: 274.65
 ---- batch: 030 ----
mean loss: 271.11
train mean loss: 273.07
epoch train time: 0:00:00.526440
elapsed time: 0:01:19.963944
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 14:43:08.818271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.93
 ---- batch: 020 ----
mean loss: 273.22
 ---- batch: 030 ----
mean loss: 270.74
train mean loss: 271.73
epoch train time: 0:00:00.542327
elapsed time: 0:01:20.506560
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 14:43:09.360877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.75
 ---- batch: 020 ----
mean loss: 268.26
 ---- batch: 030 ----
mean loss: 279.54
train mean loss: 271.05
epoch train time: 0:00:00.538681
elapsed time: 0:01:21.045520
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 14:43:09.899833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.97
 ---- batch: 020 ----
mean loss: 275.53
 ---- batch: 030 ----
mean loss: 268.46
train mean loss: 270.34
epoch train time: 0:00:00.522904
elapsed time: 0:01:21.568696
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 14:43:10.423019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.36
 ---- batch: 020 ----
mean loss: 271.59
 ---- batch: 030 ----
mean loss: 269.53
train mean loss: 268.60
epoch train time: 0:00:00.538028
elapsed time: 0:01:22.107461
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 14:43:10.961789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.50
 ---- batch: 020 ----
mean loss: 263.20
 ---- batch: 030 ----
mean loss: 263.39
train mean loss: 267.32
epoch train time: 0:00:00.528719
elapsed time: 0:01:22.636528
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 14:43:11.490851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.41
 ---- batch: 020 ----
mean loss: 262.94
 ---- batch: 030 ----
mean loss: 269.47
train mean loss: 267.47
epoch train time: 0:00:00.539482
elapsed time: 0:01:23.176334
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 14:43:12.030669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.44
 ---- batch: 020 ----
mean loss: 265.00
 ---- batch: 030 ----
mean loss: 270.00
train mean loss: 264.92
epoch train time: 0:00:00.543615
elapsed time: 0:01:23.720272
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 14:43:12.574588
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.14
 ---- batch: 020 ----
mean loss: 262.74
 ---- batch: 030 ----
mean loss: 260.48
train mean loss: 264.86
epoch train time: 0:00:00.540674
elapsed time: 0:01:24.261231
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 14:43:13.115560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.14
 ---- batch: 020 ----
mean loss: 260.18
 ---- batch: 030 ----
mean loss: 268.22
train mean loss: 262.94
epoch train time: 0:00:00.532755
elapsed time: 0:01:24.794291
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 14:43:13.648599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.15
 ---- batch: 020 ----
mean loss: 261.39
 ---- batch: 030 ----
mean loss: 265.96
train mean loss: 262.93
epoch train time: 0:00:00.530965
elapsed time: 0:01:25.325525
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 14:43:14.179832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.45
 ---- batch: 020 ----
mean loss: 262.59
 ---- batch: 030 ----
mean loss: 258.50
train mean loss: 262.99
epoch train time: 0:00:00.525229
elapsed time: 0:01:25.851089
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 14:43:14.705396
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.08
 ---- batch: 020 ----
mean loss: 267.64
 ---- batch: 030 ----
mean loss: 254.53
train mean loss: 262.30
epoch train time: 0:00:00.537422
elapsed time: 0:01:26.388825
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 14:43:15.243184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.44
 ---- batch: 020 ----
mean loss: 259.98
 ---- batch: 030 ----
mean loss: 258.70
train mean loss: 261.10
epoch train time: 0:00:00.538289
elapsed time: 0:01:26.927482
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 14:43:15.781802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.80
 ---- batch: 020 ----
mean loss: 262.33
 ---- batch: 030 ----
mean loss: 261.67
train mean loss: 259.48
epoch train time: 0:00:00.549672
elapsed time: 0:01:27.477445
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 14:43:16.331757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.19
 ---- batch: 020 ----
mean loss: 262.89
 ---- batch: 030 ----
mean loss: 258.14
train mean loss: 259.05
epoch train time: 0:00:00.535835
elapsed time: 0:01:28.013597
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 14:43:16.867908
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.72
 ---- batch: 020 ----
mean loss: 256.74
 ---- batch: 030 ----
mean loss: 262.06
train mean loss: 257.15
epoch train time: 0:00:00.529929
elapsed time: 0:01:28.543811
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 14:43:17.398126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.42
 ---- batch: 020 ----
mean loss: 262.32
 ---- batch: 030 ----
mean loss: 254.23
train mean loss: 257.71
epoch train time: 0:00:00.540804
elapsed time: 0:01:29.084911
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 14:43:17.939224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.60
 ---- batch: 020 ----
mean loss: 261.43
 ---- batch: 030 ----
mean loss: 254.91
train mean loss: 257.61
epoch train time: 0:00:00.526122
elapsed time: 0:01:29.611306
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 14:43:18.465635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.19
 ---- batch: 020 ----
mean loss: 255.92
 ---- batch: 030 ----
mean loss: 253.03
train mean loss: 255.72
epoch train time: 0:00:00.533343
elapsed time: 0:01:30.144942
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 14:43:18.999294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.28
 ---- batch: 020 ----
mean loss: 253.11
 ---- batch: 030 ----
mean loss: 260.45
train mean loss: 255.31
epoch train time: 0:00:00.519373
elapsed time: 0:01:30.664669
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 14:43:19.518961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.78
 ---- batch: 020 ----
mean loss: 250.83
 ---- batch: 030 ----
mean loss: 261.45
train mean loss: 254.75
epoch train time: 0:00:00.520400
elapsed time: 0:01:31.185310
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 14:43:20.039618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.57
 ---- batch: 020 ----
mean loss: 259.86
 ---- batch: 030 ----
mean loss: 253.67
train mean loss: 254.25
epoch train time: 0:00:00.519832
elapsed time: 0:01:31.705427
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 14:43:20.559798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.59
 ---- batch: 020 ----
mean loss: 254.49
 ---- batch: 030 ----
mean loss: 251.92
train mean loss: 252.75
epoch train time: 0:00:00.542710
elapsed time: 0:01:32.248583
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 14:43:21.102901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.41
 ---- batch: 020 ----
mean loss: 254.60
 ---- batch: 030 ----
mean loss: 246.03
train mean loss: 252.20
epoch train time: 0:00:00.521947
elapsed time: 0:01:32.770811
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 14:43:21.625122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.27
 ---- batch: 020 ----
mean loss: 249.78
 ---- batch: 030 ----
mean loss: 253.74
train mean loss: 250.88
epoch train time: 0:00:00.543487
elapsed time: 0:01:33.314563
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 14:43:22.168871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.85
 ---- batch: 020 ----
mean loss: 250.84
 ---- batch: 030 ----
mean loss: 252.74
train mean loss: 249.04
epoch train time: 0:00:00.524177
elapsed time: 0:01:33.839017
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 14:43:22.693333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.55
 ---- batch: 020 ----
mean loss: 246.71
 ---- batch: 030 ----
mean loss: 249.65
train mean loss: 250.06
epoch train time: 0:00:00.516882
elapsed time: 0:01:34.356216
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 14:43:23.210520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.35
 ---- batch: 020 ----
mean loss: 251.09
 ---- batch: 030 ----
mean loss: 244.04
train mean loss: 249.75
epoch train time: 0:00:00.532244
elapsed time: 0:01:34.888741
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 14:43:23.743057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.78
 ---- batch: 020 ----
mean loss: 253.45
 ---- batch: 030 ----
mean loss: 248.17
train mean loss: 248.53
epoch train time: 0:00:00.534617
elapsed time: 0:01:35.423625
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 14:43:24.277943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.85
 ---- batch: 020 ----
mean loss: 244.48
 ---- batch: 030 ----
mean loss: 248.51
train mean loss: 246.90
epoch train time: 0:00:00.525888
elapsed time: 0:01:35.949813
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 14:43:24.804137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.73
 ---- batch: 020 ----
mean loss: 247.35
 ---- batch: 030 ----
mean loss: 247.37
train mean loss: 247.32
epoch train time: 0:00:00.532452
elapsed time: 0:01:36.482556
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 14:43:25.336885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.94
 ---- batch: 020 ----
mean loss: 251.83
 ---- batch: 030 ----
mean loss: 245.71
train mean loss: 247.39
epoch train time: 0:00:00.538934
elapsed time: 0:01:37.021797
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 14:43:25.876106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.08
 ---- batch: 020 ----
mean loss: 243.71
 ---- batch: 030 ----
mean loss: 249.64
train mean loss: 245.21
epoch train time: 0:00:00.512760
elapsed time: 0:01:37.534827
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 14:43:26.389161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.44
 ---- batch: 020 ----
mean loss: 243.71
 ---- batch: 030 ----
mean loss: 250.31
train mean loss: 245.07
epoch train time: 0:00:00.512881
elapsed time: 0:01:38.048015
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 14:43:26.902332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.66
 ---- batch: 020 ----
mean loss: 248.75
 ---- batch: 030 ----
mean loss: 242.74
train mean loss: 243.53
epoch train time: 0:00:00.526124
elapsed time: 0:01:38.574428
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 14:43:27.428744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.80
 ---- batch: 020 ----
mean loss: 246.17
 ---- batch: 030 ----
mean loss: 242.12
train mean loss: 242.41
epoch train time: 0:00:00.531034
elapsed time: 0:01:39.105761
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 14:43:27.960100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.00
 ---- batch: 020 ----
mean loss: 244.24
 ---- batch: 030 ----
mean loss: 240.30
train mean loss: 242.93
epoch train time: 0:00:00.516833
elapsed time: 0:01:39.622901
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 14:43:28.477215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.34
 ---- batch: 020 ----
mean loss: 245.76
 ---- batch: 030 ----
mean loss: 241.48
train mean loss: 241.25
epoch train time: 0:00:00.522928
elapsed time: 0:01:40.146103
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 14:43:29.000420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.18
 ---- batch: 020 ----
mean loss: 237.30
 ---- batch: 030 ----
mean loss: 246.56
train mean loss: 241.18
epoch train time: 0:00:00.529591
elapsed time: 0:01:40.676007
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 14:43:29.530327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.06
 ---- batch: 020 ----
mean loss: 239.59
 ---- batch: 030 ----
mean loss: 240.27
train mean loss: 240.41
epoch train time: 0:00:00.543774
elapsed time: 0:01:41.220083
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 14:43:30.074400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.01
 ---- batch: 020 ----
mean loss: 240.81
 ---- batch: 030 ----
mean loss: 235.62
train mean loss: 239.83
epoch train time: 0:00:00.526683
elapsed time: 0:01:41.747039
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 14:43:30.601352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.44
 ---- batch: 020 ----
mean loss: 240.45
 ---- batch: 030 ----
mean loss: 238.42
train mean loss: 239.31
epoch train time: 0:00:00.526208
elapsed time: 0:01:42.273530
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 14:43:31.127845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.82
 ---- batch: 020 ----
mean loss: 240.60
 ---- batch: 030 ----
mean loss: 240.56
train mean loss: 238.34
epoch train time: 0:00:00.522656
elapsed time: 0:01:42.796473
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 14:43:31.650784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.68
 ---- batch: 020 ----
mean loss: 231.44
 ---- batch: 030 ----
mean loss: 242.88
train mean loss: 238.86
epoch train time: 0:00:00.513230
elapsed time: 0:01:43.309993
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 14:43:32.164309
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.25
 ---- batch: 020 ----
mean loss: 241.55
 ---- batch: 030 ----
mean loss: 230.46
train mean loss: 236.22
epoch train time: 0:00:00.515228
elapsed time: 0:01:43.825558
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 14:43:32.679829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.59
 ---- batch: 020 ----
mean loss: 240.80
 ---- batch: 030 ----
mean loss: 240.40
train mean loss: 237.67
epoch train time: 0:00:00.530399
elapsed time: 0:01:44.356195
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 14:43:33.210522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.61
 ---- batch: 020 ----
mean loss: 235.02
 ---- batch: 030 ----
mean loss: 235.79
train mean loss: 235.92
epoch train time: 0:00:00.513548
elapsed time: 0:01:44.870030
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 14:43:33.724363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.44
 ---- batch: 020 ----
mean loss: 227.60
 ---- batch: 030 ----
mean loss: 242.63
train mean loss: 235.38
epoch train time: 0:00:00.515267
elapsed time: 0:01:45.385591
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 14:43:34.239906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.29
 ---- batch: 020 ----
mean loss: 228.78
 ---- batch: 030 ----
mean loss: 235.66
train mean loss: 234.46
epoch train time: 0:00:00.526765
elapsed time: 0:01:45.912695
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 14:43:34.767017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.43
 ---- batch: 020 ----
mean loss: 240.53
 ---- batch: 030 ----
mean loss: 229.01
train mean loss: 233.60
epoch train time: 0:00:00.528861
elapsed time: 0:01:46.441845
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 14:43:35.296160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.72
 ---- batch: 020 ----
mean loss: 233.45
 ---- batch: 030 ----
mean loss: 238.02
train mean loss: 233.69
epoch train time: 0:00:00.523955
elapsed time: 0:01:46.966071
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 14:43:35.820384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.16
 ---- batch: 020 ----
mean loss: 236.20
 ---- batch: 030 ----
mean loss: 230.04
train mean loss: 233.22
epoch train time: 0:00:00.519712
elapsed time: 0:01:47.486304
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 14:43:36.340626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.05
 ---- batch: 020 ----
mean loss: 231.32
 ---- batch: 030 ----
mean loss: 231.73
train mean loss: 231.37
epoch train time: 0:00:00.533449
elapsed time: 0:01:48.020065
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 14:43:36.874381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.94
 ---- batch: 020 ----
mean loss: 232.15
 ---- batch: 030 ----
mean loss: 231.79
train mean loss: 231.54
epoch train time: 0:00:00.533868
elapsed time: 0:01:48.554209
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 14:43:37.408517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.23
 ---- batch: 020 ----
mean loss: 226.67
 ---- batch: 030 ----
mean loss: 232.51
train mean loss: 230.25
epoch train time: 0:00:00.521123
elapsed time: 0:01:49.075616
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 14:43:37.929934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.21
 ---- batch: 020 ----
mean loss: 224.47
 ---- batch: 030 ----
mean loss: 227.66
train mean loss: 229.15
epoch train time: 0:00:00.510888
elapsed time: 0:01:49.586770
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 14:43:38.441084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.74
 ---- batch: 020 ----
mean loss: 239.32
 ---- batch: 030 ----
mean loss: 221.09
train mean loss: 229.32
epoch train time: 0:00:00.525136
elapsed time: 0:01:50.112186
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 14:43:38.966505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.86
 ---- batch: 020 ----
mean loss: 234.35
 ---- batch: 030 ----
mean loss: 227.01
train mean loss: 228.74
epoch train time: 0:00:00.526730
elapsed time: 0:01:50.639208
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 14:43:39.493526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.44
 ---- batch: 020 ----
mean loss: 236.61
 ---- batch: 030 ----
mean loss: 228.98
train mean loss: 229.16
epoch train time: 0:00:00.537320
elapsed time: 0:01:51.176829
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 14:43:40.031168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.20
 ---- batch: 020 ----
mean loss: 220.89
 ---- batch: 030 ----
mean loss: 232.79
train mean loss: 227.50
epoch train time: 0:00:00.532770
elapsed time: 0:01:51.709955
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 14:43:40.564319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.63
 ---- batch: 020 ----
mean loss: 230.03
 ---- batch: 030 ----
mean loss: 232.36
train mean loss: 226.92
epoch train time: 0:00:00.525758
elapsed time: 0:01:52.236072
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 14:43:41.090373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.54
 ---- batch: 020 ----
mean loss: 231.64
 ---- batch: 030 ----
mean loss: 224.83
train mean loss: 225.90
epoch train time: 0:00:00.514988
elapsed time: 0:01:52.751324
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 14:43:41.605655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.73
 ---- batch: 020 ----
mean loss: 226.36
 ---- batch: 030 ----
mean loss: 227.26
train mean loss: 225.45
epoch train time: 0:00:00.534153
elapsed time: 0:01:53.285813
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 14:43:42.140120
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.83
 ---- batch: 020 ----
mean loss: 229.91
 ---- batch: 030 ----
mean loss: 219.74
train mean loss: 224.65
epoch train time: 0:00:00.516259
elapsed time: 0:01:53.802354
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 14:43:42.656665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.27
 ---- batch: 020 ----
mean loss: 228.27
 ---- batch: 030 ----
mean loss: 222.15
train mean loss: 224.13
epoch train time: 0:00:00.531053
elapsed time: 0:01:54.333679
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 14:43:43.187991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.70
 ---- batch: 020 ----
mean loss: 228.82
 ---- batch: 030 ----
mean loss: 219.89
train mean loss: 223.55
epoch train time: 0:00:00.535067
elapsed time: 0:01:54.869026
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 14:43:43.723336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.29
 ---- batch: 020 ----
mean loss: 220.11
 ---- batch: 030 ----
mean loss: 226.55
train mean loss: 222.88
epoch train time: 0:00:00.534162
elapsed time: 0:01:55.403501
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 14:43:44.257811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.72
 ---- batch: 020 ----
mean loss: 221.05
 ---- batch: 030 ----
mean loss: 219.08
train mean loss: 221.70
epoch train time: 0:00:00.536339
elapsed time: 0:01:55.940122
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 14:43:44.794457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.14
 ---- batch: 020 ----
mean loss: 230.27
 ---- batch: 030 ----
mean loss: 218.56
train mean loss: 221.61
epoch train time: 0:00:00.527626
elapsed time: 0:01:56.468055
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 14:43:45.322366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.46
 ---- batch: 020 ----
mean loss: 223.68
 ---- batch: 030 ----
mean loss: 222.26
train mean loss: 221.77
epoch train time: 0:00:00.529783
elapsed time: 0:01:56.998116
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 14:43:45.852436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.18
 ---- batch: 020 ----
mean loss: 221.19
 ---- batch: 030 ----
mean loss: 224.34
train mean loss: 221.29
epoch train time: 0:00:00.519688
elapsed time: 0:01:57.518098
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 14:43:46.372441
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.43
 ---- batch: 020 ----
mean loss: 219.12
 ---- batch: 030 ----
mean loss: 221.49
train mean loss: 220.00
epoch train time: 0:00:00.543242
elapsed time: 0:01:58.061652
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 14:43:46.915970
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.69
 ---- batch: 020 ----
mean loss: 216.90
 ---- batch: 030 ----
mean loss: 224.10
train mean loss: 220.16
epoch train time: 0:00:00.525840
elapsed time: 0:01:58.587849
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 14:43:47.442120
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.02
 ---- batch: 020 ----
mean loss: 223.55
 ---- batch: 030 ----
mean loss: 224.18
train mean loss: 220.53
epoch train time: 0:00:00.553426
elapsed time: 0:01:59.141504
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 14:43:47.995833
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 225.57
 ---- batch: 020 ----
mean loss: 223.74
 ---- batch: 030 ----
mean loss: 212.20
train mean loss: 220.58
epoch train time: 0:00:00.525257
elapsed time: 0:01:59.667054
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 14:43:48.521369
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.58
 ---- batch: 020 ----
mean loss: 215.03
 ---- batch: 030 ----
mean loss: 225.23
train mean loss: 219.82
epoch train time: 0:00:00.534508
elapsed time: 0:02:00.201870
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 14:43:49.056180
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 220.26
 ---- batch: 020 ----
mean loss: 220.61
 ---- batch: 030 ----
mean loss: 218.37
train mean loss: 219.31
epoch train time: 0:00:00.526442
elapsed time: 0:02:00.728579
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 14:43:49.582892
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.27
 ---- batch: 020 ----
mean loss: 220.79
 ---- batch: 030 ----
mean loss: 215.13
train mean loss: 219.65
epoch train time: 0:00:00.514461
elapsed time: 0:02:01.243318
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 14:43:50.097644
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 215.79
 ---- batch: 020 ----
mean loss: 218.10
 ---- batch: 030 ----
mean loss: 225.00
train mean loss: 219.66
epoch train time: 0:00:00.508923
elapsed time: 0:02:01.752547
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 14:43:50.606852
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 219.43
 ---- batch: 020 ----
mean loss: 217.89
 ---- batch: 030 ----
mean loss: 221.59
train mean loss: 220.10
epoch train time: 0:00:00.517791
elapsed time: 0:02:02.270593
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 14:43:51.124898
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.34
 ---- batch: 020 ----
mean loss: 225.91
 ---- batch: 030 ----
mean loss: 218.38
train mean loss: 219.14
epoch train time: 0:00:00.528891
elapsed time: 0:02:02.799757
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 14:43:51.654073
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.36
 ---- batch: 020 ----
mean loss: 216.69
 ---- batch: 030 ----
mean loss: 224.82
train mean loss: 219.31
epoch train time: 0:00:00.530198
elapsed time: 0:02:03.330229
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 14:43:52.184541
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.63
 ---- batch: 020 ----
mean loss: 220.36
 ---- batch: 030 ----
mean loss: 224.31
train mean loss: 219.56
epoch train time: 0:00:00.522768
elapsed time: 0:02:03.853281
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 14:43:52.707591
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.11
 ---- batch: 020 ----
mean loss: 223.90
 ---- batch: 030 ----
mean loss: 220.43
train mean loss: 218.75
epoch train time: 0:00:00.522952
elapsed time: 0:02:04.376499
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 14:43:53.230813
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.17
 ---- batch: 020 ----
mean loss: 214.55
 ---- batch: 030 ----
mean loss: 214.58
train mean loss: 218.97
epoch train time: 0:00:00.523608
elapsed time: 0:02:04.900390
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 14:43:53.754702
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 220.48
 ---- batch: 020 ----
mean loss: 220.58
 ---- batch: 030 ----
mean loss: 215.10
train mean loss: 220.14
epoch train time: 0:00:00.535244
elapsed time: 0:02:05.435909
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 14:43:54.290221
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.54
 ---- batch: 020 ----
mean loss: 218.25
 ---- batch: 030 ----
mean loss: 218.72
train mean loss: 218.77
epoch train time: 0:00:00.524102
elapsed time: 0:02:05.960306
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 14:43:54.814640
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.10
 ---- batch: 020 ----
mean loss: 220.94
 ---- batch: 030 ----
mean loss: 218.25
train mean loss: 219.77
epoch train time: 0:00:00.518546
elapsed time: 0:02:06.479137
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 14:43:55.333447
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.14
 ---- batch: 020 ----
mean loss: 215.24
 ---- batch: 030 ----
mean loss: 220.99
train mean loss: 218.96
epoch train time: 0:00:00.528808
elapsed time: 0:02:07.008297
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 14:43:55.862626
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.52
 ---- batch: 020 ----
mean loss: 214.42
 ---- batch: 030 ----
mean loss: 218.58
train mean loss: 219.67
epoch train time: 0:00:00.530901
elapsed time: 0:02:07.539538
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 14:43:56.393856
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.06
 ---- batch: 020 ----
mean loss: 218.65
 ---- batch: 030 ----
mean loss: 221.41
train mean loss: 218.62
epoch train time: 0:00:00.545570
elapsed time: 0:02:08.085413
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 14:43:56.939730
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.88
 ---- batch: 020 ----
mean loss: 220.84
 ---- batch: 030 ----
mean loss: 214.78
train mean loss: 218.70
epoch train time: 0:00:00.524610
elapsed time: 0:02:08.610369
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 14:43:57.464712
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.68
 ---- batch: 020 ----
mean loss: 222.46
 ---- batch: 030 ----
mean loss: 219.97
train mean loss: 219.65
epoch train time: 0:00:00.518270
elapsed time: 0:02:09.128954
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 14:43:57.983269
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 223.04
 ---- batch: 020 ----
mean loss: 211.75
 ---- batch: 030 ----
mean loss: 218.43
train mean loss: 218.20
epoch train time: 0:00:00.519934
elapsed time: 0:02:09.649163
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 14:43:58.503471
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.99
 ---- batch: 020 ----
mean loss: 219.85
 ---- batch: 030 ----
mean loss: 216.93
train mean loss: 218.85
epoch train time: 0:00:00.533351
elapsed time: 0:02:10.182801
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 14:43:59.037115
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.80
 ---- batch: 020 ----
mean loss: 218.92
 ---- batch: 030 ----
mean loss: 220.31
train mean loss: 218.49
epoch train time: 0:00:00.520042
elapsed time: 0:02:10.703129
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 14:43:59.557446
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.22
 ---- batch: 020 ----
mean loss: 223.00
 ---- batch: 030 ----
mean loss: 217.36
train mean loss: 219.38
epoch train time: 0:00:00.537748
elapsed time: 0:02:11.241154
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 14:44:00.095510
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.22
 ---- batch: 020 ----
mean loss: 217.97
 ---- batch: 030 ----
mean loss: 215.89
train mean loss: 218.29
epoch train time: 0:00:00.518006
elapsed time: 0:02:11.759536
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 14:44:00.613850
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.08
 ---- batch: 020 ----
mean loss: 221.19
 ---- batch: 030 ----
mean loss: 216.88
train mean loss: 218.31
epoch train time: 0:00:00.534002
elapsed time: 0:02:12.293827
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 14:44:01.148188
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 215.91
 ---- batch: 020 ----
mean loss: 221.21
 ---- batch: 030 ----
mean loss: 216.53
train mean loss: 218.98
epoch train time: 0:00:00.521541
elapsed time: 0:02:12.815711
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 14:44:01.670088
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 214.90
 ---- batch: 020 ----
mean loss: 217.32
 ---- batch: 030 ----
mean loss: 217.90
train mean loss: 218.58
epoch train time: 0:00:00.534349
elapsed time: 0:02:13.350455
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 14:44:02.204802
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.56
 ---- batch: 020 ----
mean loss: 223.72
 ---- batch: 030 ----
mean loss: 212.54
train mean loss: 217.65
epoch train time: 0:00:00.531322
elapsed time: 0:02:13.882101
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 14:44:02.736432
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 223.47
 ---- batch: 020 ----
mean loss: 213.48
 ---- batch: 030 ----
mean loss: 219.90
train mean loss: 218.47
epoch train time: 0:00:00.519426
elapsed time: 0:02:14.401851
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 14:44:03.256167
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.25
 ---- batch: 020 ----
mean loss: 217.76
 ---- batch: 030 ----
mean loss: 220.65
train mean loss: 217.44
epoch train time: 0:00:00.523040
elapsed time: 0:02:14.925239
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 14:44:03.779561
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 215.21
 ---- batch: 020 ----
mean loss: 223.35
 ---- batch: 030 ----
mean loss: 218.96
train mean loss: 217.93
epoch train time: 0:00:00.527323
elapsed time: 0:02:15.452914
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 14:44:04.307179
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.92
 ---- batch: 020 ----
mean loss: 216.86
 ---- batch: 030 ----
mean loss: 218.95
train mean loss: 218.92
epoch train time: 0:00:00.521040
elapsed time: 0:02:15.974187
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 14:44:04.828502
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 219.17
 ---- batch: 020 ----
mean loss: 215.12
 ---- batch: 030 ----
mean loss: 218.24
train mean loss: 217.97
epoch train time: 0:00:00.526643
elapsed time: 0:02:16.501123
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 14:44:05.355443
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.78
 ---- batch: 020 ----
mean loss: 219.60
 ---- batch: 030 ----
mean loss: 216.35
train mean loss: 218.02
epoch train time: 0:00:00.530361
elapsed time: 0:02:17.031801
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 14:44:05.886118
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.28
 ---- batch: 020 ----
mean loss: 222.85
 ---- batch: 030 ----
mean loss: 218.00
train mean loss: 217.97
epoch train time: 0:00:00.525834
elapsed time: 0:02:17.557913
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 14:44:06.412228
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.91
 ---- batch: 020 ----
mean loss: 217.91
 ---- batch: 030 ----
mean loss: 213.24
train mean loss: 217.86
epoch train time: 0:00:00.521787
elapsed time: 0:02:18.079988
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 14:44:06.934303
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.73
 ---- batch: 020 ----
mean loss: 222.83
 ---- batch: 030 ----
mean loss: 216.03
train mean loss: 218.08
epoch train time: 0:00:00.506915
elapsed time: 0:02:18.587218
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 14:44:07.441539
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.07
 ---- batch: 020 ----
mean loss: 216.94
 ---- batch: 030 ----
mean loss: 220.05
train mean loss: 217.55
epoch train time: 0:00:00.527487
elapsed time: 0:02:19.115008
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 14:44:07.969321
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.19
 ---- batch: 020 ----
mean loss: 216.82
 ---- batch: 030 ----
mean loss: 214.74
train mean loss: 217.19
epoch train time: 0:00:00.518045
elapsed time: 0:02:19.633331
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 14:44:08.487641
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.46
 ---- batch: 020 ----
mean loss: 213.87
 ---- batch: 030 ----
mean loss: 219.34
train mean loss: 217.39
epoch train time: 0:00:00.533463
elapsed time: 0:02:20.167095
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 14:44:09.021421
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.38
 ---- batch: 020 ----
mean loss: 221.98
 ---- batch: 030 ----
mean loss: 216.21
train mean loss: 217.76
epoch train time: 0:00:00.518942
elapsed time: 0:02:20.686329
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 14:44:09.540642
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.19
 ---- batch: 020 ----
mean loss: 217.60
 ---- batch: 030 ----
mean loss: 211.39
train mean loss: 217.52
epoch train time: 0:00:00.525411
elapsed time: 0:02:21.212015
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 14:44:10.066327
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 220.51
 ---- batch: 020 ----
mean loss: 212.24
 ---- batch: 030 ----
mean loss: 216.47
train mean loss: 216.47
epoch train time: 0:00:00.538580
elapsed time: 0:02:21.750893
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 14:44:10.605199
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.30
 ---- batch: 020 ----
mean loss: 222.20
 ---- batch: 030 ----
mean loss: 214.71
train mean loss: 217.31
epoch train time: 0:00:00.553629
elapsed time: 0:02:22.304802
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 14:44:11.159122
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.09
 ---- batch: 020 ----
mean loss: 219.96
 ---- batch: 030 ----
mean loss: 211.10
train mean loss: 217.42
epoch train time: 0:00:00.522646
elapsed time: 0:02:22.827726
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 14:44:11.682041
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.17
 ---- batch: 020 ----
mean loss: 215.20
 ---- batch: 030 ----
mean loss: 218.91
train mean loss: 217.30
epoch train time: 0:00:00.534310
elapsed time: 0:02:23.362313
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 14:44:12.216626
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.25
 ---- batch: 020 ----
mean loss: 215.61
 ---- batch: 030 ----
mean loss: 220.16
train mean loss: 217.94
epoch train time: 0:00:00.526146
elapsed time: 0:02:23.892311
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_1/checkpoint.pth.tar
**** end time: 2019-09-27 14:44:12.746551 ****
