Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_0', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 28806
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 14:39:09.333517 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 14:39:09.344137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3980.15
 ---- batch: 020 ----
mean loss: 3802.80
 ---- batch: 030 ----
mean loss: 3820.51
train mean loss: 3856.24
epoch train time: 0:00:13.006041
elapsed time: 0:00:13.019614
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 14:39:22.353175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3724.52
 ---- batch: 020 ----
mean loss: 3603.15
 ---- batch: 030 ----
mean loss: 3545.50
train mean loss: 3608.20
epoch train time: 0:00:00.522009
elapsed time: 0:00:13.541850
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 14:39:22.875473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3436.45
 ---- batch: 020 ----
mean loss: 3335.83
 ---- batch: 030 ----
mean loss: 3290.35
train mean loss: 3331.73
epoch train time: 0:00:00.523648
elapsed time: 0:00:14.065788
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 14:39:23.399394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3164.10
 ---- batch: 020 ----
mean loss: 3086.77
 ---- batch: 030 ----
mean loss: 3065.31
train mean loss: 3100.19
epoch train time: 0:00:00.527363
elapsed time: 0:00:14.593478
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 14:39:23.927089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2937.48
 ---- batch: 020 ----
mean loss: 2864.27
 ---- batch: 030 ----
mean loss: 2941.76
train mean loss: 2902.86
epoch train time: 0:00:00.525575
elapsed time: 0:00:15.119333
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 14:39:24.452988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2775.71
 ---- batch: 020 ----
mean loss: 2717.78
 ---- batch: 030 ----
mean loss: 2698.31
train mean loss: 2722.56
epoch train time: 0:00:00.524610
elapsed time: 0:00:15.644284
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 14:39:24.977888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2645.97
 ---- batch: 020 ----
mean loss: 2567.15
 ---- batch: 030 ----
mean loss: 2524.74
train mean loss: 2570.88
epoch train time: 0:00:00.521241
elapsed time: 0:00:16.165800
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 14:39:25.499411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2479.42
 ---- batch: 020 ----
mean loss: 2449.42
 ---- batch: 030 ----
mean loss: 2378.09
train mean loss: 2426.44
epoch train time: 0:00:00.522300
elapsed time: 0:00:16.688384
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 14:39:26.022005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2328.03
 ---- batch: 020 ----
mean loss: 2296.17
 ---- batch: 030 ----
mean loss: 2271.66
train mean loss: 2290.47
epoch train time: 0:00:00.522818
elapsed time: 0:00:17.211507
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 14:39:26.545154
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2230.03
 ---- batch: 020 ----
mean loss: 2165.74
 ---- batch: 030 ----
mean loss: 2134.83
train mean loss: 2165.17
epoch train time: 0:00:00.520142
elapsed time: 0:00:17.732051
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 14:39:27.065698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2061.80
 ---- batch: 020 ----
mean loss: 2056.43
 ---- batch: 030 ----
mean loss: 2006.80
train mean loss: 2030.35
epoch train time: 0:00:00.526865
elapsed time: 0:00:18.259226
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 14:39:27.592848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1939.42
 ---- batch: 020 ----
mean loss: 1930.23
 ---- batch: 030 ----
mean loss: 1862.71
train mean loss: 1906.74
epoch train time: 0:00:00.525403
elapsed time: 0:00:18.784922
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 14:39:28.118542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1835.62
 ---- batch: 020 ----
mean loss: 1805.07
 ---- batch: 030 ----
mean loss: 1784.70
train mean loss: 1793.39
epoch train time: 0:00:00.516891
elapsed time: 0:00:19.302113
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 14:39:28.635717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1746.25
 ---- batch: 020 ----
mean loss: 1696.39
 ---- batch: 030 ----
mean loss: 1644.87
train mean loss: 1683.30
epoch train time: 0:00:00.528512
elapsed time: 0:00:19.830892
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 14:39:29.164500
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1630.98
 ---- batch: 020 ----
mean loss: 1601.41
 ---- batch: 030 ----
mean loss: 1567.73
train mean loss: 1594.97
epoch train time: 0:00:00.521820
elapsed time: 0:00:20.353033
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 14:39:29.686611
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1536.31
 ---- batch: 020 ----
mean loss: 1508.25
 ---- batch: 030 ----
mean loss: 1488.91
train mean loss: 1505.38
epoch train time: 0:00:00.511027
elapsed time: 0:00:20.864304
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 14:39:30.197912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1453.30
 ---- batch: 020 ----
mean loss: 1423.97
 ---- batch: 030 ----
mean loss: 1417.25
train mean loss: 1425.32
epoch train time: 0:00:00.509373
elapsed time: 0:00:21.374216
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 14:39:30.707844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1384.13
 ---- batch: 020 ----
mean loss: 1363.35
 ---- batch: 030 ----
mean loss: 1313.76
train mean loss: 1351.23
epoch train time: 0:00:00.512003
elapsed time: 0:00:21.886518
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 14:39:31.220126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1313.29
 ---- batch: 020 ----
mean loss: 1302.19
 ---- batch: 030 ----
mean loss: 1267.68
train mean loss: 1287.65
epoch train time: 0:00:00.512032
elapsed time: 0:00:22.398865
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 14:39:31.732515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1245.63
 ---- batch: 020 ----
mean loss: 1223.98
 ---- batch: 030 ----
mean loss: 1186.93
train mean loss: 1215.46
epoch train time: 0:00:00.519699
elapsed time: 0:00:22.918920
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 14:39:32.252576
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1176.94
 ---- batch: 020 ----
mean loss: 1165.11
 ---- batch: 030 ----
mean loss: 1146.46
train mean loss: 1162.43
epoch train time: 0:00:00.517678
elapsed time: 0:00:23.436913
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 14:39:32.770519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1109.98
 ---- batch: 020 ----
mean loss: 1124.18
 ---- batch: 030 ----
mean loss: 1101.14
train mean loss: 1103.57
epoch train time: 0:00:00.518822
elapsed time: 0:00:23.956022
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 14:39:33.289673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1080.29
 ---- batch: 020 ----
mean loss: 1055.52
 ---- batch: 030 ----
mean loss: 1045.75
train mean loss: 1053.37
epoch train time: 0:00:00.523826
elapsed time: 0:00:24.480238
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 14:39:33.813876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1008.61
 ---- batch: 020 ----
mean loss: 1018.52
 ---- batch: 030 ----
mean loss: 1003.37
train mean loss: 1003.21
epoch train time: 0:00:00.508862
elapsed time: 0:00:24.989413
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 14:39:34.323018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 978.05
 ---- batch: 020 ----
mean loss: 975.59
 ---- batch: 030 ----
mean loss: 947.50
train mean loss: 959.63
epoch train time: 0:00:00.516656
elapsed time: 0:00:25.506338
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 14:39:34.839985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 920.17
 ---- batch: 020 ----
mean loss: 936.84
 ---- batch: 030 ----
mean loss: 914.71
train mean loss: 920.67
epoch train time: 0:00:00.521045
elapsed time: 0:00:26.027728
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 14:39:35.361338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 897.74
 ---- batch: 020 ----
mean loss: 894.80
 ---- batch: 030 ----
mean loss: 861.85
train mean loss: 884.76
epoch train time: 0:00:00.542932
elapsed time: 0:00:26.570996
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 14:39:35.904612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 866.36
 ---- batch: 020 ----
mean loss: 856.71
 ---- batch: 030 ----
mean loss: 832.94
train mean loss: 849.88
epoch train time: 0:00:00.521553
elapsed time: 0:00:27.092898
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 14:39:36.426508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 825.05
 ---- batch: 020 ----
mean loss: 833.89
 ---- batch: 030 ----
mean loss: 800.15
train mean loss: 813.42
epoch train time: 0:00:00.516226
elapsed time: 0:00:27.609409
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 14:39:36.943027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 797.00
 ---- batch: 020 ----
mean loss: 782.73
 ---- batch: 030 ----
mean loss: 781.29
train mean loss: 786.24
epoch train time: 0:00:00.513768
elapsed time: 0:00:28.123487
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 14:39:37.457126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 768.17
 ---- batch: 020 ----
mean loss: 746.24
 ---- batch: 030 ----
mean loss: 766.61
train mean loss: 756.58
epoch train time: 0:00:00.510519
elapsed time: 0:00:28.634306
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 14:39:37.967912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 743.34
 ---- batch: 020 ----
mean loss: 732.82
 ---- batch: 030 ----
mean loss: 710.11
train mean loss: 725.33
epoch train time: 0:00:00.514226
elapsed time: 0:00:29.148800
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 14:39:38.482406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 714.41
 ---- batch: 020 ----
mean loss: 703.31
 ---- batch: 030 ----
mean loss: 681.33
train mean loss: 699.41
epoch train time: 0:00:00.524352
elapsed time: 0:00:29.673414
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 14:39:39.007015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 694.43
 ---- batch: 020 ----
mean loss: 690.57
 ---- batch: 030 ----
mean loss: 673.83
train mean loss: 683.55
epoch train time: 0:00:00.509864
elapsed time: 0:00:30.183529
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 14:39:39.517128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 662.59
 ---- batch: 020 ----
mean loss: 665.91
 ---- batch: 030 ----
mean loss: 641.17
train mean loss: 656.28
epoch train time: 0:00:00.530835
elapsed time: 0:00:30.714645
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 14:39:40.048254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 641.55
 ---- batch: 020 ----
mean loss: 630.11
 ---- batch: 030 ----
mean loss: 640.68
train mean loss: 635.36
epoch train time: 0:00:00.518257
elapsed time: 0:00:31.233192
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 14:39:40.566799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 636.83
 ---- batch: 020 ----
mean loss: 622.85
 ---- batch: 030 ----
mean loss: 610.50
train mean loss: 620.35
epoch train time: 0:00:00.518739
elapsed time: 0:00:31.752230
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 14:39:41.085844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 608.98
 ---- batch: 020 ----
mean loss: 601.54
 ---- batch: 030 ----
mean loss: 598.45
train mean loss: 600.93
epoch train time: 0:00:00.520175
elapsed time: 0:00:32.272706
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 14:39:41.606332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 587.60
 ---- batch: 020 ----
mean loss: 583.09
 ---- batch: 030 ----
mean loss: 586.08
train mean loss: 584.83
epoch train time: 0:00:00.519862
elapsed time: 0:00:32.792943
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 14:39:42.126548
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 576.61
 ---- batch: 020 ----
mean loss: 568.28
 ---- batch: 030 ----
mean loss: 569.76
train mean loss: 569.82
epoch train time: 0:00:00.507820
elapsed time: 0:00:33.301023
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 14:39:42.634632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 555.17
 ---- batch: 020 ----
mean loss: 560.02
 ---- batch: 030 ----
mean loss: 549.70
train mean loss: 555.64
epoch train time: 0:00:00.523169
elapsed time: 0:00:33.824488
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 14:39:43.158097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 549.78
 ---- batch: 020 ----
mean loss: 537.84
 ---- batch: 030 ----
mean loss: 550.07
train mean loss: 545.49
epoch train time: 0:00:00.505315
elapsed time: 0:00:34.330089
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 14:39:43.663697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 542.60
 ---- batch: 020 ----
mean loss: 525.15
 ---- batch: 030 ----
mean loss: 523.45
train mean loss: 531.03
epoch train time: 0:00:00.533502
elapsed time: 0:00:34.863865
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 14:39:44.197483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 517.81
 ---- batch: 020 ----
mean loss: 528.19
 ---- batch: 030 ----
mean loss: 517.55
train mean loss: 518.92
epoch train time: 0:00:00.513741
elapsed time: 0:00:35.377898
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 14:39:44.711524
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 509.14
 ---- batch: 020 ----
mean loss: 501.61
 ---- batch: 030 ----
mean loss: 517.39
train mean loss: 510.22
epoch train time: 0:00:00.517184
elapsed time: 0:00:35.895373
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 14:39:45.228991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 503.31
 ---- batch: 020 ----
mean loss: 498.29
 ---- batch: 030 ----
mean loss: 494.83
train mean loss: 499.78
epoch train time: 0:00:00.532512
elapsed time: 0:00:36.428220
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 14:39:45.761829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 493.56
 ---- batch: 020 ----
mean loss: 488.00
 ---- batch: 030 ----
mean loss: 486.09
train mean loss: 489.88
epoch train time: 0:00:00.515707
elapsed time: 0:00:36.944245
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 14:39:46.277858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 490.02
 ---- batch: 020 ----
mean loss: 488.91
 ---- batch: 030 ----
mean loss: 479.35
train mean loss: 482.07
epoch train time: 0:00:00.519155
elapsed time: 0:00:37.463701
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 14:39:46.797311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 478.13
 ---- batch: 020 ----
mean loss: 480.12
 ---- batch: 030 ----
mean loss: 468.48
train mean loss: 473.75
epoch train time: 0:00:00.521241
elapsed time: 0:00:37.985221
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 14:39:47.318832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 477.74
 ---- batch: 020 ----
mean loss: 470.82
 ---- batch: 030 ----
mean loss: 460.84
train mean loss: 467.94
epoch train time: 0:00:00.535043
elapsed time: 0:00:38.520556
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 14:39:47.854182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 461.60
 ---- batch: 020 ----
mean loss: 457.20
 ---- batch: 030 ----
mean loss: 459.09
train mean loss: 456.32
epoch train time: 0:00:00.506328
elapsed time: 0:00:39.027189
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 14:39:48.360799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 455.60
 ---- batch: 020 ----
mean loss: 443.69
 ---- batch: 030 ----
mean loss: 450.20
train mean loss: 449.13
epoch train time: 0:00:00.521263
elapsed time: 0:00:39.548751
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 14:39:48.882383
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 444.05
 ---- batch: 020 ----
mean loss: 447.78
 ---- batch: 030 ----
mean loss: 433.71
train mean loss: 441.82
epoch train time: 0:00:00.520523
elapsed time: 0:00:40.069627
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 14:39:49.403239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 435.29
 ---- batch: 020 ----
mean loss: 438.93
 ---- batch: 030 ----
mean loss: 436.31
train mean loss: 437.04
epoch train time: 0:00:00.526755
elapsed time: 0:00:40.596668
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 14:39:49.930272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 437.42
 ---- batch: 020 ----
mean loss: 429.23
 ---- batch: 030 ----
mean loss: 425.61
train mean loss: 430.24
epoch train time: 0:00:00.522669
elapsed time: 0:00:41.119625
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 14:39:50.453231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 431.54
 ---- batch: 020 ----
mean loss: 423.73
 ---- batch: 030 ----
mean loss: 417.97
train mean loss: 423.45
epoch train time: 0:00:00.530956
elapsed time: 0:00:41.651057
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 14:39:50.984676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 421.77
 ---- batch: 020 ----
mean loss: 425.50
 ---- batch: 030 ----
mean loss: 416.84
train mean loss: 420.73
epoch train time: 0:00:00.519498
elapsed time: 0:00:42.170840
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 14:39:51.504447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 420.81
 ---- batch: 020 ----
mean loss: 412.24
 ---- batch: 030 ----
mean loss: 412.66
train mean loss: 413.87
epoch train time: 0:00:00.523430
elapsed time: 0:00:42.694629
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 14:39:52.028235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 402.49
 ---- batch: 020 ----
mean loss: 413.34
 ---- batch: 030 ----
mean loss: 409.37
train mean loss: 406.48
epoch train time: 0:00:00.510342
elapsed time: 0:00:43.205240
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 14:39:52.538847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.71
 ---- batch: 020 ----
mean loss: 410.60
 ---- batch: 030 ----
mean loss: 396.09
train mean loss: 401.77
epoch train time: 0:00:00.554716
elapsed time: 0:00:43.760355
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 14:39:53.093973
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 398.98
 ---- batch: 020 ----
mean loss: 393.74
 ---- batch: 030 ----
mean loss: 395.93
train mean loss: 397.35
epoch train time: 0:00:00.522524
elapsed time: 0:00:44.283186
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 14:39:53.616793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 390.71
 ---- batch: 020 ----
mean loss: 386.21
 ---- batch: 030 ----
mean loss: 398.05
train mean loss: 391.77
epoch train time: 0:00:00.527393
elapsed time: 0:00:44.810868
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 14:39:54.144477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 384.60
 ---- batch: 020 ----
mean loss: 388.12
 ---- batch: 030 ----
mean loss: 388.51
train mean loss: 387.89
epoch train time: 0:00:00.522130
elapsed time: 0:00:45.333296
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 14:39:54.666905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 374.02
 ---- batch: 020 ----
mean loss: 385.20
 ---- batch: 030 ----
mean loss: 384.03
train mean loss: 380.56
epoch train time: 0:00:00.523607
elapsed time: 0:00:45.857245
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 14:39:55.190854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 382.65
 ---- batch: 020 ----
mean loss: 376.15
 ---- batch: 030 ----
mean loss: 380.43
train mean loss: 379.19
epoch train time: 0:00:00.530027
elapsed time: 0:00:46.387568
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 14:39:55.721207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.84
 ---- batch: 020 ----
mean loss: 374.62
 ---- batch: 030 ----
mean loss: 373.90
train mean loss: 375.19
epoch train time: 0:00:00.546775
elapsed time: 0:00:46.934665
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 14:39:56.268273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 370.99
 ---- batch: 020 ----
mean loss: 372.54
 ---- batch: 030 ----
mean loss: 367.86
train mean loss: 369.91
epoch train time: 0:00:00.523776
elapsed time: 0:00:47.458718
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 14:39:56.792326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 366.43
 ---- batch: 020 ----
mean loss: 364.02
 ---- batch: 030 ----
mean loss: 372.38
train mean loss: 367.88
epoch train time: 0:00:00.520993
elapsed time: 0:00:47.979981
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 14:39:57.313587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.36
 ---- batch: 020 ----
mean loss: 369.60
 ---- batch: 030 ----
mean loss: 358.85
train mean loss: 363.87
epoch train time: 0:00:00.521855
elapsed time: 0:00:48.502125
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 14:39:57.835738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 361.60
 ---- batch: 020 ----
mean loss: 359.68
 ---- batch: 030 ----
mean loss: 358.48
train mean loss: 360.07
epoch train time: 0:00:00.513795
elapsed time: 0:00:49.016234
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 14:39:58.349846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.48
 ---- batch: 020 ----
mean loss: 353.75
 ---- batch: 030 ----
mean loss: 356.91
train mean loss: 357.10
epoch train time: 0:00:00.511793
elapsed time: 0:00:49.528316
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 14:39:58.861924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.87
 ---- batch: 020 ----
mean loss: 353.35
 ---- batch: 030 ----
mean loss: 349.36
train mean loss: 353.32
epoch train time: 0:00:00.513417
elapsed time: 0:00:50.042007
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 14:39:59.375616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.70
 ---- batch: 020 ----
mean loss: 352.01
 ---- batch: 030 ----
mean loss: 346.49
train mean loss: 351.07
epoch train time: 0:00:00.531972
elapsed time: 0:00:50.574375
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 14:39:59.907993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 349.79
 ---- batch: 020 ----
mean loss: 350.24
 ---- batch: 030 ----
mean loss: 344.34
train mean loss: 347.01
epoch train time: 0:00:00.528011
elapsed time: 0:00:51.102738
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 14:40:00.436374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 347.38
 ---- batch: 020 ----
mean loss: 345.03
 ---- batch: 030 ----
mean loss: 346.98
train mean loss: 345.72
epoch train time: 0:00:00.527717
elapsed time: 0:00:51.630807
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 14:40:00.964417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 342.72
 ---- batch: 020 ----
mean loss: 347.46
 ---- batch: 030 ----
mean loss: 343.81
train mean loss: 344.20
epoch train time: 0:00:00.522899
elapsed time: 0:00:52.153986
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 14:40:01.487597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 343.19
 ---- batch: 020 ----
mean loss: 337.49
 ---- batch: 030 ----
mean loss: 337.58
train mean loss: 340.44
epoch train time: 0:00:00.517822
elapsed time: 0:00:52.672121
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 14:40:02.005750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 333.06
 ---- batch: 020 ----
mean loss: 341.74
 ---- batch: 030 ----
mean loss: 341.93
train mean loss: 338.54
epoch train time: 0:00:00.521463
elapsed time: 0:00:53.193890
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 14:40:02.527512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 339.81
 ---- batch: 020 ----
mean loss: 328.41
 ---- batch: 030 ----
mean loss: 329.99
train mean loss: 335.03
epoch train time: 0:00:00.522122
elapsed time: 0:00:53.716324
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 14:40:03.049955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 333.14
 ---- batch: 020 ----
mean loss: 333.18
 ---- batch: 030 ----
mean loss: 338.72
train mean loss: 334.21
epoch train time: 0:00:00.541570
elapsed time: 0:00:54.258205
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 14:40:03.591808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 328.10
 ---- batch: 020 ----
mean loss: 325.42
 ---- batch: 030 ----
mean loss: 342.54
train mean loss: 330.09
epoch train time: 0:00:00.519467
elapsed time: 0:00:54.777933
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 14:40:04.111536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.87
 ---- batch: 020 ----
mean loss: 331.03
 ---- batch: 030 ----
mean loss: 326.53
train mean loss: 328.74
epoch train time: 0:00:00.507246
elapsed time: 0:00:55.285454
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 14:40:04.619061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.95
 ---- batch: 020 ----
mean loss: 324.21
 ---- batch: 030 ----
mean loss: 329.01
train mean loss: 327.95
epoch train time: 0:00:00.520901
elapsed time: 0:00:55.806672
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 14:40:05.140341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.83
 ---- batch: 020 ----
mean loss: 331.71
 ---- batch: 030 ----
mean loss: 326.36
train mean loss: 326.77
epoch train time: 0:00:00.527790
elapsed time: 0:00:56.334793
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 14:40:05.668395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.49
 ---- batch: 020 ----
mean loss: 320.18
 ---- batch: 030 ----
mean loss: 324.50
train mean loss: 324.77
epoch train time: 0:00:00.548516
elapsed time: 0:00:56.883580
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 14:40:06.217189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.05
 ---- batch: 020 ----
mean loss: 326.56
 ---- batch: 030 ----
mean loss: 319.59
train mean loss: 322.85
epoch train time: 0:00:00.519260
elapsed time: 0:00:57.403115
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 14:40:06.736719
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.84
 ---- batch: 020 ----
mean loss: 322.32
 ---- batch: 030 ----
mean loss: 317.59
train mean loss: 319.67
epoch train time: 0:00:00.514009
elapsed time: 0:00:57.917396
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 14:40:07.251017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.75
 ---- batch: 020 ----
mean loss: 327.04
 ---- batch: 030 ----
mean loss: 310.14
train mean loss: 318.35
epoch train time: 0:00:00.510359
elapsed time: 0:00:58.428049
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 14:40:07.761802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.44
 ---- batch: 020 ----
mean loss: 314.58
 ---- batch: 030 ----
mean loss: 313.01
train mean loss: 318.20
epoch train time: 0:00:00.533533
elapsed time: 0:00:58.962040
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 14:40:08.295653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.59
 ---- batch: 020 ----
mean loss: 311.85
 ---- batch: 030 ----
mean loss: 318.71
train mean loss: 315.34
epoch train time: 0:00:00.523731
elapsed time: 0:00:59.486067
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 14:40:08.819669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 313.81
 ---- batch: 020 ----
mean loss: 315.86
 ---- batch: 030 ----
mean loss: 312.20
train mean loss: 312.67
epoch train time: 0:00:00.522636
elapsed time: 0:01:00.009056
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 14:40:09.342667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.99
 ---- batch: 020 ----
mean loss: 312.55
 ---- batch: 030 ----
mean loss: 316.10
train mean loss: 312.12
epoch train time: 0:00:00.523242
elapsed time: 0:01:00.532571
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 14:40:09.866218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 313.25
 ---- batch: 020 ----
mean loss: 310.35
 ---- batch: 030 ----
mean loss: 306.44
train mean loss: 310.43
epoch train time: 0:00:00.506231
elapsed time: 0:01:01.039129
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 14:40:10.372737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.17
 ---- batch: 020 ----
mean loss: 304.36
 ---- batch: 030 ----
mean loss: 311.29
train mean loss: 309.93
epoch train time: 0:00:00.513527
elapsed time: 0:01:01.552933
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 14:40:10.886540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.06
 ---- batch: 020 ----
mean loss: 304.25
 ---- batch: 030 ----
mean loss: 312.40
train mean loss: 308.39
epoch train time: 0:00:00.518499
elapsed time: 0:01:02.071790
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 14:40:11.405414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 302.14
 ---- batch: 020 ----
mean loss: 303.22
 ---- batch: 030 ----
mean loss: 310.98
train mean loss: 306.13
epoch train time: 0:00:00.516995
elapsed time: 0:01:02.589078
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 14:40:11.922687
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.60
 ---- batch: 020 ----
mean loss: 304.19
 ---- batch: 030 ----
mean loss: 308.54
train mean loss: 303.44
epoch train time: 0:00:00.511007
elapsed time: 0:01:03.100372
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 14:40:12.433979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.46
 ---- batch: 020 ----
mean loss: 299.20
 ---- batch: 030 ----
mean loss: 301.64
train mean loss: 303.75
epoch train time: 0:00:00.525029
elapsed time: 0:01:03.625680
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 14:40:12.959300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.19
 ---- batch: 020 ----
mean loss: 297.62
 ---- batch: 030 ----
mean loss: 298.76
train mean loss: 300.53
epoch train time: 0:00:00.517023
elapsed time: 0:01:04.143012
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 14:40:13.476623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 301.17
 ---- batch: 020 ----
mean loss: 296.55
 ---- batch: 030 ----
mean loss: 306.55
train mean loss: 300.40
epoch train time: 0:00:00.533673
elapsed time: 0:01:04.676961
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 14:40:14.010566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.35
 ---- batch: 020 ----
mean loss: 300.66
 ---- batch: 030 ----
mean loss: 291.29
train mean loss: 299.70
epoch train time: 0:00:00.524020
elapsed time: 0:01:05.201256
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 14:40:14.534867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.55
 ---- batch: 020 ----
mean loss: 300.73
 ---- batch: 030 ----
mean loss: 297.21
train mean loss: 296.56
epoch train time: 0:00:00.520272
elapsed time: 0:01:05.721833
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 14:40:15.055443
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.85
 ---- batch: 020 ----
mean loss: 298.38
 ---- batch: 030 ----
mean loss: 298.04
train mean loss: 297.23
epoch train time: 0:00:00.519170
elapsed time: 0:01:06.241277
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 14:40:15.574911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.84
 ---- batch: 020 ----
mean loss: 300.71
 ---- batch: 030 ----
mean loss: 295.78
train mean loss: 295.41
epoch train time: 0:00:00.523166
elapsed time: 0:01:06.764737
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 14:40:16.098342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.93
 ---- batch: 020 ----
mean loss: 299.36
 ---- batch: 030 ----
mean loss: 295.05
train mean loss: 293.45
epoch train time: 0:00:00.508910
elapsed time: 0:01:07.273903
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 14:40:16.607506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.29
 ---- batch: 020 ----
mean loss: 296.44
 ---- batch: 030 ----
mean loss: 296.48
train mean loss: 292.90
epoch train time: 0:00:00.513935
elapsed time: 0:01:07.788117
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 14:40:17.121755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.03
 ---- batch: 020 ----
mean loss: 294.27
 ---- batch: 030 ----
mean loss: 292.01
train mean loss: 291.36
epoch train time: 0:00:00.509157
elapsed time: 0:01:08.297637
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 14:40:17.631208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.06
 ---- batch: 020 ----
mean loss: 282.26
 ---- batch: 030 ----
mean loss: 294.53
train mean loss: 289.50
epoch train time: 0:00:00.521010
elapsed time: 0:01:08.818922
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 14:40:18.152533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.69
 ---- batch: 020 ----
mean loss: 295.99
 ---- batch: 030 ----
mean loss: 282.88
train mean loss: 288.98
epoch train time: 0:00:00.505309
elapsed time: 0:01:09.324520
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 14:40:18.658127
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.07
 ---- batch: 020 ----
mean loss: 282.83
 ---- batch: 030 ----
mean loss: 290.18
train mean loss: 287.28
epoch train time: 0:00:00.519725
elapsed time: 0:01:09.844529
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 14:40:19.178140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.35
 ---- batch: 020 ----
mean loss: 289.05
 ---- batch: 030 ----
mean loss: 286.39
train mean loss: 286.18
epoch train time: 0:00:00.518304
elapsed time: 0:01:10.363116
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 14:40:19.696732
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.51
 ---- batch: 020 ----
mean loss: 277.15
 ---- batch: 030 ----
mean loss: 285.82
train mean loss: 283.02
epoch train time: 0:00:00.538500
elapsed time: 0:01:10.901942
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 14:40:20.235549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.31
 ---- batch: 020 ----
mean loss: 283.47
 ---- batch: 030 ----
mean loss: 279.34
train mean loss: 283.88
epoch train time: 0:00:00.518899
elapsed time: 0:01:11.421129
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 14:40:20.754738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 280.82
 ---- batch: 020 ----
mean loss: 280.57
 ---- batch: 030 ----
mean loss: 283.52
train mean loss: 281.67
epoch train time: 0:00:00.520450
elapsed time: 0:01:11.941995
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 14:40:21.275614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.21
 ---- batch: 020 ----
mean loss: 287.87
 ---- batch: 030 ----
mean loss: 285.76
train mean loss: 281.91
epoch train time: 0:00:00.526964
elapsed time: 0:01:12.469291
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 14:40:21.802896
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.12
 ---- batch: 020 ----
mean loss: 285.10
 ---- batch: 030 ----
mean loss: 277.68
train mean loss: 280.11
epoch train time: 0:00:00.526696
elapsed time: 0:01:12.996274
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 14:40:22.329880
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.83
 ---- batch: 020 ----
mean loss: 284.05
 ---- batch: 030 ----
mean loss: 280.04
train mean loss: 279.67
epoch train time: 0:00:00.530334
elapsed time: 0:01:13.526900
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 14:40:22.860518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 279.39
 ---- batch: 020 ----
mean loss: 281.81
 ---- batch: 030 ----
mean loss: 277.66
train mean loss: 277.39
epoch train time: 0:00:00.518591
elapsed time: 0:01:14.045794
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 14:40:23.379421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.19
 ---- batch: 020 ----
mean loss: 277.31
 ---- batch: 030 ----
mean loss: 277.77
train mean loss: 277.68
epoch train time: 0:00:00.532232
elapsed time: 0:01:14.578388
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 14:40:23.912041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.85
 ---- batch: 020 ----
mean loss: 271.48
 ---- batch: 030 ----
mean loss: 279.37
train mean loss: 275.70
epoch train time: 0:00:00.521461
elapsed time: 0:01:15.100186
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 14:40:24.433789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.66
 ---- batch: 020 ----
mean loss: 272.99
 ---- batch: 030 ----
mean loss: 271.63
train mean loss: 274.25
epoch train time: 0:00:00.527795
elapsed time: 0:01:15.628271
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 14:40:24.961898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.51
 ---- batch: 020 ----
mean loss: 271.38
 ---- batch: 030 ----
mean loss: 278.38
train mean loss: 272.58
epoch train time: 0:00:00.514882
elapsed time: 0:01:16.143475
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 14:40:25.477087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.87
 ---- batch: 020 ----
mean loss: 272.53
 ---- batch: 030 ----
mean loss: 271.98
train mean loss: 272.38
epoch train time: 0:00:00.510908
elapsed time: 0:01:16.654675
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 14:40:25.988289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.48
 ---- batch: 020 ----
mean loss: 269.16
 ---- batch: 030 ----
mean loss: 272.22
train mean loss: 271.13
epoch train time: 0:00:00.507389
elapsed time: 0:01:17.162339
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 14:40:26.495946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.06
 ---- batch: 020 ----
mean loss: 265.86
 ---- batch: 030 ----
mean loss: 270.25
train mean loss: 270.18
epoch train time: 0:00:00.522425
elapsed time: 0:01:17.685049
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 14:40:27.018660
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.89
 ---- batch: 020 ----
mean loss: 263.16
 ---- batch: 030 ----
mean loss: 263.93
train mean loss: 269.28
epoch train time: 0:00:00.517802
elapsed time: 0:01:18.203126
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 14:40:27.536737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.83
 ---- batch: 020 ----
mean loss: 271.93
 ---- batch: 030 ----
mean loss: 266.54
train mean loss: 267.34
epoch train time: 0:00:00.540624
elapsed time: 0:01:18.744073
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 14:40:28.077668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.85
 ---- batch: 020 ----
mean loss: 265.85
 ---- batch: 030 ----
mean loss: 268.52
train mean loss: 266.82
epoch train time: 0:00:00.519434
elapsed time: 0:01:19.263783
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 14:40:28.597422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.46
 ---- batch: 020 ----
mean loss: 268.62
 ---- batch: 030 ----
mean loss: 264.61
train mean loss: 266.52
epoch train time: 0:00:00.525219
elapsed time: 0:01:19.789333
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 14:40:29.122965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.08
 ---- batch: 020 ----
mean loss: 266.33
 ---- batch: 030 ----
mean loss: 265.43
train mean loss: 264.86
epoch train time: 0:00:00.526817
elapsed time: 0:01:20.316464
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 14:40:29.650072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.83
 ---- batch: 020 ----
mean loss: 263.84
 ---- batch: 030 ----
mean loss: 270.62
train mean loss: 264.81
epoch train time: 0:00:00.510640
elapsed time: 0:01:20.827420
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 14:40:30.161054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.15
 ---- batch: 020 ----
mean loss: 268.91
 ---- batch: 030 ----
mean loss: 262.13
train mean loss: 263.22
epoch train time: 0:00:00.511160
elapsed time: 0:01:21.338900
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 14:40:30.672525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.96
 ---- batch: 020 ----
mean loss: 263.96
 ---- batch: 030 ----
mean loss: 261.79
train mean loss: 261.14
epoch train time: 0:00:00.522339
elapsed time: 0:01:21.861540
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 14:40:31.195184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.04
 ---- batch: 020 ----
mean loss: 258.40
 ---- batch: 030 ----
mean loss: 259.60
train mean loss: 262.12
epoch train time: 0:00:00.521335
elapsed time: 0:01:22.383244
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 14:40:31.716854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.87
 ---- batch: 020 ----
mean loss: 256.00
 ---- batch: 030 ----
mean loss: 264.56
train mean loss: 260.87
epoch train time: 0:00:00.508830
elapsed time: 0:01:22.892343
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 14:40:32.225949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.21
 ---- batch: 020 ----
mean loss: 258.79
 ---- batch: 030 ----
mean loss: 262.85
train mean loss: 258.99
epoch train time: 0:00:00.519863
elapsed time: 0:01:23.412474
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 14:40:32.746104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.14
 ---- batch: 020 ----
mean loss: 256.14
 ---- batch: 030 ----
mean loss: 254.62
train mean loss: 259.06
epoch train time: 0:00:00.516689
elapsed time: 0:01:23.929462
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 14:40:33.263072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.77
 ---- batch: 020 ----
mean loss: 254.62
 ---- batch: 030 ----
mean loss: 259.75
train mean loss: 257.06
epoch train time: 0:00:00.510320
elapsed time: 0:01:24.440044
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 14:40:33.773666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.61
 ---- batch: 020 ----
mean loss: 256.80
 ---- batch: 030 ----
mean loss: 256.48
train mean loss: 256.54
epoch train time: 0:00:00.519560
elapsed time: 0:01:24.959935
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 14:40:34.293508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.26
 ---- batch: 020 ----
mean loss: 257.61
 ---- batch: 030 ----
mean loss: 251.73
train mean loss: 256.44
epoch train time: 0:00:00.519767
elapsed time: 0:01:25.479980
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 14:40:34.813589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.83
 ---- batch: 020 ----
mean loss: 259.12
 ---- batch: 030 ----
mean loss: 250.46
train mean loss: 255.20
epoch train time: 0:00:00.508459
elapsed time: 0:01:25.988712
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 14:40:35.322317
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.75
 ---- batch: 020 ----
mean loss: 251.96
 ---- batch: 030 ----
mean loss: 253.34
train mean loss: 254.45
epoch train time: 0:00:00.515205
elapsed time: 0:01:26.504213
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 14:40:35.837828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.32
 ---- batch: 020 ----
mean loss: 253.02
 ---- batch: 030 ----
mean loss: 254.12
train mean loss: 252.02
epoch train time: 0:00:00.509518
elapsed time: 0:01:27.014201
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 14:40:36.347817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.19
 ---- batch: 020 ----
mean loss: 253.91
 ---- batch: 030 ----
mean loss: 252.70
train mean loss: 252.11
epoch train time: 0:00:00.521207
elapsed time: 0:01:27.535697
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 14:40:36.869306
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.43
 ---- batch: 020 ----
mean loss: 250.12
 ---- batch: 030 ----
mean loss: 252.24
train mean loss: 250.12
epoch train time: 0:00:00.516581
elapsed time: 0:01:28.052563
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 14:40:37.386203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.40
 ---- batch: 020 ----
mean loss: 256.01
 ---- batch: 030 ----
mean loss: 248.70
train mean loss: 250.97
epoch train time: 0:00:00.528997
elapsed time: 0:01:28.581880
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 14:40:37.915516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.60
 ---- batch: 020 ----
mean loss: 249.87
 ---- batch: 030 ----
mean loss: 247.16
train mean loss: 248.67
epoch train time: 0:00:00.513018
elapsed time: 0:01:29.095200
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 14:40:38.428822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.70
 ---- batch: 020 ----
mean loss: 247.78
 ---- batch: 030 ----
mean loss: 247.14
train mean loss: 248.06
epoch train time: 0:00:00.519827
elapsed time: 0:01:29.615306
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 14:40:38.948911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.55
 ---- batch: 020 ----
mean loss: 246.62
 ---- batch: 030 ----
mean loss: 251.18
train mean loss: 247.93
epoch train time: 0:00:00.521558
elapsed time: 0:01:30.137198
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 14:40:39.470765
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.17
 ---- batch: 020 ----
mean loss: 244.07
 ---- batch: 030 ----
mean loss: 254.67
train mean loss: 247.29
epoch train time: 0:00:00.521214
elapsed time: 0:01:30.658656
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 14:40:39.992264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.57
 ---- batch: 020 ----
mean loss: 251.33
 ---- batch: 030 ----
mean loss: 244.66
train mean loss: 245.97
epoch train time: 0:00:00.524037
elapsed time: 0:01:31.183021
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 14:40:40.516646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.95
 ---- batch: 020 ----
mean loss: 248.74
 ---- batch: 030 ----
mean loss: 244.38
train mean loss: 245.88
epoch train time: 0:00:00.523828
elapsed time: 0:01:31.707197
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 14:40:41.040805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.30
 ---- batch: 020 ----
mean loss: 246.12
 ---- batch: 030 ----
mean loss: 239.42
train mean loss: 244.64
epoch train time: 0:00:00.521612
elapsed time: 0:01:32.229083
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 14:40:41.562692
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.62
 ---- batch: 020 ----
mean loss: 243.94
 ---- batch: 030 ----
mean loss: 245.53
train mean loss: 243.56
epoch train time: 0:00:00.536679
elapsed time: 0:01:32.766253
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 14:40:42.099867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.17
 ---- batch: 020 ----
mean loss: 242.96
 ---- batch: 030 ----
mean loss: 246.01
train mean loss: 242.17
epoch train time: 0:00:00.527464
elapsed time: 0:01:33.293998
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 14:40:42.627606
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.89
 ---- batch: 020 ----
mean loss: 238.65
 ---- batch: 030 ----
mean loss: 240.69
train mean loss: 242.45
epoch train time: 0:00:00.522914
elapsed time: 0:01:33.817217
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 14:40:43.150858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.83
 ---- batch: 020 ----
mean loss: 242.68
 ---- batch: 030 ----
mean loss: 236.38
train mean loss: 241.40
epoch train time: 0:00:00.532106
elapsed time: 0:01:34.349648
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 14:40:43.683273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.82
 ---- batch: 020 ----
mean loss: 244.99
 ---- batch: 030 ----
mean loss: 239.58
train mean loss: 239.98
epoch train time: 0:00:00.539188
elapsed time: 0:01:34.889146
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 14:40:44.222754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.36
 ---- batch: 020 ----
mean loss: 235.46
 ---- batch: 030 ----
mean loss: 242.26
train mean loss: 239.38
epoch train time: 0:00:00.516683
elapsed time: 0:01:35.406105
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 14:40:44.739713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.73
 ---- batch: 020 ----
mean loss: 237.49
 ---- batch: 030 ----
mean loss: 240.12
train mean loss: 238.36
epoch train time: 0:00:00.512677
elapsed time: 0:01:35.919043
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 14:40:45.252662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.75
 ---- batch: 020 ----
mean loss: 241.04
 ---- batch: 030 ----
mean loss: 235.10
train mean loss: 237.43
epoch train time: 0:00:00.510191
elapsed time: 0:01:36.429513
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 14:40:45.763115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.41
 ---- batch: 020 ----
mean loss: 234.89
 ---- batch: 030 ----
mean loss: 240.67
train mean loss: 236.94
epoch train time: 0:00:00.521227
elapsed time: 0:01:36.951006
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 14:40:46.284629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.02
 ---- batch: 020 ----
mean loss: 234.95
 ---- batch: 030 ----
mean loss: 240.81
train mean loss: 236.07
epoch train time: 0:00:00.522626
elapsed time: 0:01:37.473943
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 14:40:46.807547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.33
 ---- batch: 020 ----
mean loss: 241.40
 ---- batch: 030 ----
mean loss: 233.93
train mean loss: 235.51
epoch train time: 0:00:00.515621
elapsed time: 0:01:37.989831
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 14:40:47.323436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.25
 ---- batch: 020 ----
mean loss: 237.41
 ---- batch: 030 ----
mean loss: 233.95
train mean loss: 234.27
epoch train time: 0:00:00.534118
elapsed time: 0:01:38.524283
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 14:40:47.857903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.91
 ---- batch: 020 ----
mean loss: 233.93
 ---- batch: 030 ----
mean loss: 230.91
train mean loss: 232.87
epoch train time: 0:00:00.527071
elapsed time: 0:01:39.051638
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 14:40:48.385269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.09
 ---- batch: 020 ----
mean loss: 237.95
 ---- batch: 030 ----
mean loss: 233.05
train mean loss: 233.11
epoch train time: 0:00:00.529114
elapsed time: 0:01:39.581057
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 14:40:48.914664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.25
 ---- batch: 020 ----
mean loss: 227.97
 ---- batch: 030 ----
mean loss: 238.88
train mean loss: 232.23
epoch train time: 0:00:00.524834
elapsed time: 0:01:40.106178
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 14:40:49.439789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.88
 ---- batch: 020 ----
mean loss: 231.33
 ---- batch: 030 ----
mean loss: 231.36
train mean loss: 230.79
epoch train time: 0:00:00.533238
elapsed time: 0:01:40.639711
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 14:40:49.973317
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.23
 ---- batch: 020 ----
mean loss: 231.70
 ---- batch: 030 ----
mean loss: 225.41
train mean loss: 230.63
epoch train time: 0:00:00.514619
elapsed time: 0:01:41.154610
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 14:40:50.488218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.95
 ---- batch: 020 ----
mean loss: 230.06
 ---- batch: 030 ----
mean loss: 230.23
train mean loss: 230.20
epoch train time: 0:00:00.518252
elapsed time: 0:01:41.673146
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 14:40:51.006786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.19
 ---- batch: 020 ----
mean loss: 230.66
 ---- batch: 030 ----
mean loss: 231.38
train mean loss: 228.50
epoch train time: 0:00:00.534783
elapsed time: 0:01:42.208260
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 14:40:51.541870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.59
 ---- batch: 020 ----
mean loss: 221.02
 ---- batch: 030 ----
mean loss: 231.34
train mean loss: 228.49
epoch train time: 0:00:00.523440
elapsed time: 0:01:42.731983
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 14:40:52.065674
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.49
 ---- batch: 020 ----
mean loss: 233.15
 ---- batch: 030 ----
mean loss: 222.46
train mean loss: 228.16
epoch train time: 0:00:00.530836
elapsed time: 0:01:43.263248
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 14:40:52.596812
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.69
 ---- batch: 020 ----
mean loss: 230.95
 ---- batch: 030 ----
mean loss: 230.49
train mean loss: 227.40
epoch train time: 0:00:00.543540
elapsed time: 0:01:43.807032
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 14:40:53.140645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.51
 ---- batch: 020 ----
mean loss: 226.31
 ---- batch: 030 ----
mean loss: 227.24
train mean loss: 226.98
epoch train time: 0:00:00.520728
elapsed time: 0:01:44.328107
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 14:40:53.661715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.07
 ---- batch: 020 ----
mean loss: 218.87
 ---- batch: 030 ----
mean loss: 232.68
train mean loss: 225.89
epoch train time: 0:00:00.531038
elapsed time: 0:01:44.859413
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 14:40:54.193033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.88
 ---- batch: 020 ----
mean loss: 220.99
 ---- batch: 030 ----
mean loss: 226.25
train mean loss: 225.55
epoch train time: 0:00:00.505609
elapsed time: 0:01:45.365311
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 14:40:54.698917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.04
 ---- batch: 020 ----
mean loss: 233.32
 ---- batch: 030 ----
mean loss: 218.38
train mean loss: 224.40
epoch train time: 0:00:00.515322
elapsed time: 0:01:45.880909
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 14:40:55.214517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.05
 ---- batch: 020 ----
mean loss: 222.32
 ---- batch: 030 ----
mean loss: 227.59
train mean loss: 223.23
epoch train time: 0:00:00.512622
elapsed time: 0:01:46.393834
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 14:40:55.727478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.01
 ---- batch: 020 ----
mean loss: 227.05
 ---- batch: 030 ----
mean loss: 220.84
train mean loss: 223.69
epoch train time: 0:00:00.521030
elapsed time: 0:01:46.915172
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 14:40:56.248779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.77
 ---- batch: 020 ----
mean loss: 223.06
 ---- batch: 030 ----
mean loss: 222.33
train mean loss: 222.05
epoch train time: 0:00:00.517794
elapsed time: 0:01:47.433269
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 14:40:56.766879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.63
 ---- batch: 020 ----
mean loss: 223.53
 ---- batch: 030 ----
mean loss: 221.33
train mean loss: 221.68
epoch train time: 0:00:00.514778
elapsed time: 0:01:47.948365
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 14:40:57.282003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.75
 ---- batch: 020 ----
mean loss: 217.38
 ---- batch: 030 ----
mean loss: 223.81
train mean loss: 221.37
epoch train time: 0:00:00.512376
elapsed time: 0:01:48.461071
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 14:40:57.794679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.93
 ---- batch: 020 ----
mean loss: 214.46
 ---- batch: 030 ----
mean loss: 218.52
train mean loss: 219.52
epoch train time: 0:00:00.523937
elapsed time: 0:01:48.985306
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 14:40:58.318930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.98
 ---- batch: 020 ----
mean loss: 229.98
 ---- batch: 030 ----
mean loss: 211.45
train mean loss: 220.20
epoch train time: 0:00:00.525588
elapsed time: 0:01:49.511208
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 14:40:58.844849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.68
 ---- batch: 020 ----
mean loss: 222.87
 ---- batch: 030 ----
mean loss: 218.52
train mean loss: 218.96
epoch train time: 0:00:00.522195
elapsed time: 0:01:50.033739
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 14:40:59.367378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.40
 ---- batch: 020 ----
mean loss: 225.42
 ---- batch: 030 ----
mean loss: 219.27
train mean loss: 219.20
epoch train time: 0:00:00.542223
elapsed time: 0:01:50.576283
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 14:40:59.909891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.92
 ---- batch: 020 ----
mean loss: 212.04
 ---- batch: 030 ----
mean loss: 224.18
train mean loss: 218.06
epoch train time: 0:00:00.520807
elapsed time: 0:01:51.097367
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 14:41:00.431117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.17
 ---- batch: 020 ----
mean loss: 219.95
 ---- batch: 030 ----
mean loss: 220.26
train mean loss: 216.65
epoch train time: 0:00:00.522952
elapsed time: 0:01:51.620751
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 14:41:00.954355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.17
 ---- batch: 020 ----
mean loss: 220.67
 ---- batch: 030 ----
mean loss: 216.00
train mean loss: 216.47
epoch train time: 0:00:00.525467
elapsed time: 0:01:52.146542
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 14:41:01.480200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.39
 ---- batch: 020 ----
mean loss: 215.71
 ---- batch: 030 ----
mean loss: 217.75
train mean loss: 215.38
epoch train time: 0:00:00.533819
elapsed time: 0:01:52.680693
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 14:41:02.014303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.16
 ---- batch: 020 ----
mean loss: 219.72
 ---- batch: 030 ----
mean loss: 210.09
train mean loss: 214.77
epoch train time: 0:00:00.509536
elapsed time: 0:01:53.190503
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 14:41:02.524109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.76
 ---- batch: 020 ----
mean loss: 219.66
 ---- batch: 030 ----
mean loss: 211.64
train mean loss: 214.58
epoch train time: 0:00:00.521892
elapsed time: 0:01:53.712670
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 14:41:03.046278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.29
 ---- batch: 020 ----
mean loss: 218.80
 ---- batch: 030 ----
mean loss: 211.17
train mean loss: 214.08
epoch train time: 0:00:00.520624
elapsed time: 0:01:54.233556
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 14:41:03.567174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.16
 ---- batch: 020 ----
mean loss: 211.09
 ---- batch: 030 ----
mean loss: 218.34
train mean loss: 213.80
epoch train time: 0:00:00.541322
elapsed time: 0:01:54.775165
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 14:41:04.108774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.00
 ---- batch: 020 ----
mean loss: 212.29
 ---- batch: 030 ----
mean loss: 209.56
train mean loss: 212.32
epoch train time: 0:00:00.519400
elapsed time: 0:01:55.294854
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 14:41:04.628461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.31
 ---- batch: 020 ----
mean loss: 219.83
 ---- batch: 030 ----
mean loss: 208.96
train mean loss: 211.68
epoch train time: 0:00:00.510147
elapsed time: 0:01:55.805278
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 14:41:05.138920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.56
 ---- batch: 020 ----
mean loss: 214.04
 ---- batch: 030 ----
mean loss: 211.52
train mean loss: 211.76
epoch train time: 0:00:00.507902
elapsed time: 0:01:56.313503
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 14:41:05.647126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.55
 ---- batch: 020 ----
mean loss: 210.62
 ---- batch: 030 ----
mean loss: 214.15
train mean loss: 211.26
epoch train time: 0:00:00.519403
elapsed time: 0:01:56.833255
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 14:41:06.166902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.85
 ---- batch: 020 ----
mean loss: 210.24
 ---- batch: 030 ----
mean loss: 211.48
train mean loss: 210.38
epoch train time: 0:00:00.524540
elapsed time: 0:01:57.358109
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 14:41:06.691718
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.34
 ---- batch: 020 ----
mean loss: 207.41
 ---- batch: 030 ----
mean loss: 213.76
train mean loss: 210.28
epoch train time: 0:00:00.524593
elapsed time: 0:01:57.883034
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 14:41:07.216597
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.52
 ---- batch: 020 ----
mean loss: 213.83
 ---- batch: 030 ----
mean loss: 214.11
train mean loss: 210.62
epoch train time: 0:00:00.520683
elapsed time: 0:01:58.403955
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 14:41:07.737559
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 215.03
 ---- batch: 020 ----
mean loss: 213.09
 ---- batch: 030 ----
mean loss: 202.66
train mean loss: 210.14
epoch train time: 0:00:00.531652
elapsed time: 0:01:58.935881
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 14:41:08.269498
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 213.11
 ---- batch: 020 ----
mean loss: 205.47
 ---- batch: 030 ----
mean loss: 215.04
train mean loss: 210.14
epoch train time: 0:00:00.522834
elapsed time: 0:01:59.458998
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 14:41:08.792604
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.50
 ---- batch: 020 ----
mean loss: 209.34
 ---- batch: 030 ----
mean loss: 208.19
train mean loss: 209.28
epoch train time: 0:00:00.515628
elapsed time: 0:01:59.974893
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 14:41:09.308497
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.26
 ---- batch: 020 ----
mean loss: 210.02
 ---- batch: 030 ----
mean loss: 205.25
train mean loss: 209.59
epoch train time: 0:00:00.523369
elapsed time: 0:02:00.498546
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 14:41:09.832156
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.50
 ---- batch: 020 ----
mean loss: 205.31
 ---- batch: 030 ----
mean loss: 214.06
train mean loss: 209.59
epoch train time: 0:00:00.519743
elapsed time: 0:02:01.018591
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 14:41:10.352198
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.29
 ---- batch: 020 ----
mean loss: 209.49
 ---- batch: 030 ----
mean loss: 211.04
train mean loss: 210.02
epoch train time: 0:00:00.521573
elapsed time: 0:02:01.540478
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 14:41:10.874099
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.26
 ---- batch: 020 ----
mean loss: 215.24
 ---- batch: 030 ----
mean loss: 209.52
train mean loss: 209.75
epoch train time: 0:00:00.528733
elapsed time: 0:02:02.069504
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 14:41:11.403143
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.92
 ---- batch: 020 ----
mean loss: 206.76
 ---- batch: 030 ----
mean loss: 215.80
train mean loss: 209.95
epoch train time: 0:00:00.534279
elapsed time: 0:02:02.604139
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 14:41:11.937747
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.89
 ---- batch: 020 ----
mean loss: 210.52
 ---- batch: 030 ----
mean loss: 214.24
train mean loss: 209.52
epoch train time: 0:00:00.516151
elapsed time: 0:02:03.120566
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 14:41:12.454175
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.73
 ---- batch: 020 ----
mean loss: 214.33
 ---- batch: 030 ----
mean loss: 211.12
train mean loss: 209.51
epoch train time: 0:00:00.517593
elapsed time: 0:02:03.638435
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 14:41:12.972050
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.61
 ---- batch: 020 ----
mean loss: 205.18
 ---- batch: 030 ----
mean loss: 204.20
train mean loss: 209.55
epoch train time: 0:00:00.513853
elapsed time: 0:02:04.152564
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 14:41:13.486184
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 209.04
 ---- batch: 020 ----
mean loss: 210.49
 ---- batch: 030 ----
mean loss: 203.60
train mean loss: 209.68
epoch train time: 0:00:00.513900
elapsed time: 0:02:04.666758
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 14:41:14.000360
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.57
 ---- batch: 020 ----
mean loss: 208.07
 ---- batch: 030 ----
mean loss: 209.86
train mean loss: 209.66
epoch train time: 0:00:00.506868
elapsed time: 0:02:05.173895
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 14:41:14.507495
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.53
 ---- batch: 020 ----
mean loss: 210.21
 ---- batch: 030 ----
mean loss: 207.42
train mean loss: 209.21
epoch train time: 0:00:00.508777
elapsed time: 0:02:05.682948
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 14:41:15.016569
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.04
 ---- batch: 020 ----
mean loss: 205.45
 ---- batch: 030 ----
mean loss: 213.31
train mean loss: 209.43
epoch train time: 0:00:00.507571
elapsed time: 0:02:06.190799
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 14:41:15.524447
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.14
 ---- batch: 020 ----
mean loss: 204.74
 ---- batch: 030 ----
mean loss: 207.55
train mean loss: 209.67
epoch train time: 0:00:00.513144
elapsed time: 0:02:06.704307
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 14:41:16.037916
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 209.03
 ---- batch: 020 ----
mean loss: 208.96
 ---- batch: 030 ----
mean loss: 211.59
train mean loss: 209.10
epoch train time: 0:00:00.518389
elapsed time: 0:02:07.222967
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 14:41:16.556574
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 210.61
 ---- batch: 020 ----
mean loss: 211.51
 ---- batch: 030 ----
mean loss: 204.61
train mean loss: 208.92
epoch train time: 0:00:00.529641
elapsed time: 0:02:07.752900
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 14:41:17.086512
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.80
 ---- batch: 020 ----
mean loss: 212.01
 ---- batch: 030 ----
mean loss: 209.92
train mean loss: 209.15
epoch train time: 0:00:00.518154
elapsed time: 0:02:08.271352
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 14:41:17.604960
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.67
 ---- batch: 020 ----
mean loss: 203.92
 ---- batch: 030 ----
mean loss: 207.47
train mean loss: 208.36
epoch train time: 0:00:00.522971
elapsed time: 0:02:08.794601
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 14:41:18.128209
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.90
 ---- batch: 020 ----
mean loss: 208.83
 ---- batch: 030 ----
mean loss: 209.29
train mean loss: 208.84
epoch train time: 0:00:00.510680
elapsed time: 0:02:09.305577
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 14:41:18.639246
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.86
 ---- batch: 020 ----
mean loss: 210.04
 ---- batch: 030 ----
mean loss: 209.88
train mean loss: 208.76
epoch train time: 0:00:00.507327
elapsed time: 0:02:09.813241
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 14:41:19.146846
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.49
 ---- batch: 020 ----
mean loss: 213.17
 ---- batch: 030 ----
mean loss: 207.80
train mean loss: 209.22
epoch train time: 0:00:00.511285
elapsed time: 0:02:10.324820
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 14:41:19.658418
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.60
 ---- batch: 020 ----
mean loss: 209.35
 ---- batch: 030 ----
mean loss: 206.34
train mean loss: 208.50
epoch train time: 0:00:00.527795
elapsed time: 0:02:10.852892
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 14:41:20.186524
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.83
 ---- batch: 020 ----
mean loss: 211.00
 ---- batch: 030 ----
mean loss: 206.16
train mean loss: 208.15
epoch train time: 0:00:00.534713
elapsed time: 0:02:11.387947
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 14:41:20.721567
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.15
 ---- batch: 020 ----
mean loss: 211.85
 ---- batch: 030 ----
mean loss: 206.55
train mean loss: 208.74
epoch train time: 0:00:00.511535
elapsed time: 0:02:11.899806
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 14:41:21.233411
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 204.99
 ---- batch: 020 ----
mean loss: 208.05
 ---- batch: 030 ----
mean loss: 207.94
train mean loss: 208.63
epoch train time: 0:00:00.514175
elapsed time: 0:02:12.414302
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 14:41:21.747936
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.31
 ---- batch: 020 ----
mean loss: 213.51
 ---- batch: 030 ----
mean loss: 203.47
train mean loss: 207.88
epoch train time: 0:00:00.522533
elapsed time: 0:02:12.937142
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 14:41:22.270784
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.65
 ---- batch: 020 ----
mean loss: 202.75
 ---- batch: 030 ----
mean loss: 209.45
train mean loss: 208.08
epoch train time: 0:00:00.525280
elapsed time: 0:02:13.462743
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 14:41:22.796355
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.59
 ---- batch: 020 ----
mean loss: 208.62
 ---- batch: 030 ----
mean loss: 211.42
train mean loss: 208.28
epoch train time: 0:00:00.522798
elapsed time: 0:02:13.985814
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 14:41:23.319421
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.81
 ---- batch: 020 ----
mean loss: 213.65
 ---- batch: 030 ----
mean loss: 208.57
train mean loss: 208.59
epoch train time: 0:00:00.527945
elapsed time: 0:02:14.514179
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 14:41:23.847765
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.12
 ---- batch: 020 ----
mean loss: 204.84
 ---- batch: 030 ----
mean loss: 209.04
train mean loss: 208.31
epoch train time: 0:00:00.531173
elapsed time: 0:02:15.045662
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 14:41:24.379286
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 209.90
 ---- batch: 020 ----
mean loss: 206.19
 ---- batch: 030 ----
mean loss: 207.92
train mean loss: 208.19
epoch train time: 0:00:00.532263
elapsed time: 0:02:15.578228
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 14:41:24.911845
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.39
 ---- batch: 020 ----
mean loss: 209.16
 ---- batch: 030 ----
mean loss: 205.76
train mean loss: 207.71
epoch train time: 0:00:00.518816
elapsed time: 0:02:16.097324
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 14:41:25.430932
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.70
 ---- batch: 020 ----
mean loss: 212.94
 ---- batch: 030 ----
mean loss: 207.92
train mean loss: 208.36
epoch train time: 0:00:00.522581
elapsed time: 0:02:16.620202
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 14:41:25.953840
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.13
 ---- batch: 020 ----
mean loss: 208.19
 ---- batch: 030 ----
mean loss: 204.08
train mean loss: 208.25
epoch train time: 0:00:00.518281
elapsed time: 0:02:17.138780
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 14:41:26.472385
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.24
 ---- batch: 020 ----
mean loss: 213.11
 ---- batch: 030 ----
mean loss: 205.72
train mean loss: 208.19
epoch train time: 0:00:00.529945
elapsed time: 0:02:17.668988
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 14:41:27.002593
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 210.91
 ---- batch: 020 ----
mean loss: 207.93
 ---- batch: 030 ----
mean loss: 210.20
train mean loss: 207.64
epoch train time: 0:00:00.524278
elapsed time: 0:02:18.193556
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 14:41:27.527186
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 213.45
 ---- batch: 020 ----
mean loss: 206.49
 ---- batch: 030 ----
mean loss: 204.54
train mean loss: 207.62
epoch train time: 0:00:00.529454
elapsed time: 0:02:18.723312
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 14:41:28.056940
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 209.42
 ---- batch: 020 ----
mean loss: 204.27
 ---- batch: 030 ----
mean loss: 209.59
train mean loss: 207.61
epoch train time: 0:00:00.532656
elapsed time: 0:02:19.256297
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 14:41:28.589923
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.49
 ---- batch: 020 ----
mean loss: 213.02
 ---- batch: 030 ----
mean loss: 206.03
train mean loss: 207.65
epoch train time: 0:00:00.534527
elapsed time: 0:02:19.791111
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 14:41:29.124718
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.10
 ---- batch: 020 ----
mean loss: 209.31
 ---- batch: 030 ----
mean loss: 201.69
train mean loss: 208.04
epoch train time: 0:00:00.517214
elapsed time: 0:02:20.308654
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 14:41:29.642263
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 210.96
 ---- batch: 020 ----
mean loss: 202.70
 ---- batch: 030 ----
mean loss: 208.79
train mean loss: 207.39
epoch train time: 0:00:00.524820
elapsed time: 0:02:20.833766
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 14:41:30.167383
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.78
 ---- batch: 020 ----
mean loss: 211.74
 ---- batch: 030 ----
mean loss: 205.20
train mean loss: 207.52
epoch train time: 0:00:00.522628
elapsed time: 0:02:21.356688
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 14:41:30.690298
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.21
 ---- batch: 020 ----
mean loss: 210.15
 ---- batch: 030 ----
mean loss: 201.76
train mean loss: 207.76
epoch train time: 0:00:00.520855
elapsed time: 0:02:21.877820
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 14:41:31.211426
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 210.75
 ---- batch: 020 ----
mean loss: 205.71
 ---- batch: 030 ----
mean loss: 207.73
train mean loss: 207.15
epoch train time: 0:00:00.528276
elapsed time: 0:02:22.406365
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 14:41:31.739970
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.74
 ---- batch: 020 ----
mean loss: 205.79
 ---- batch: 030 ----
mean loss: 208.98
train mean loss: 207.36
epoch train time: 0:00:00.529155
elapsed time: 0:02:22.939558
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_0/checkpoint.pth.tar
**** end time: 2019-09-27 14:41:32.273094 ****
