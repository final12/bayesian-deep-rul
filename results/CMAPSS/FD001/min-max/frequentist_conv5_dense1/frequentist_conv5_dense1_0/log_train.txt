Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_0', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30265
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 15:35:25.043001 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:35:25.050904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3599.32
 ---- batch: 020 ----
mean loss: 1225.62
 ---- batch: 030 ----
mean loss: 680.05
train mean loss: 1647.60
epoch train time: 0:00:12.881961
elapsed time: 0:00:12.892392
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:35:37.935432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 425.78
 ---- batch: 020 ----
mean loss: 381.66
 ---- batch: 030 ----
mean loss: 359.68
train mean loss: 385.21
epoch train time: 0:00:01.512462
elapsed time: 0:00:14.405021
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:35:39.448085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 343.99
 ---- batch: 020 ----
mean loss: 335.32
 ---- batch: 030 ----
mean loss: 320.94
train mean loss: 331.58
epoch train time: 0:00:01.439385
elapsed time: 0:00:15.844579
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:35:40.887636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.77
 ---- batch: 020 ----
mean loss: 289.15
 ---- batch: 030 ----
mean loss: 278.57
train mean loss: 286.38
epoch train time: 0:00:01.436329
elapsed time: 0:00:17.281086
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:35:42.324160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.33
 ---- batch: 020 ----
mean loss: 253.58
 ---- batch: 030 ----
mean loss: 244.02
train mean loss: 247.19
epoch train time: 0:00:01.436730
elapsed time: 0:00:18.718017
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:35:43.761107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.54
 ---- batch: 020 ----
mean loss: 235.80
 ---- batch: 030 ----
mean loss: 233.98
train mean loss: 231.74
epoch train time: 0:00:01.433967
elapsed time: 0:00:20.152203
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:35:45.195294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.99
 ---- batch: 020 ----
mean loss: 212.10
 ---- batch: 030 ----
mean loss: 215.69
train mean loss: 217.96
epoch train time: 0:00:01.433998
elapsed time: 0:00:21.586408
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:35:46.629465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.16
 ---- batch: 020 ----
mean loss: 212.13
 ---- batch: 030 ----
mean loss: 209.04
train mean loss: 211.83
epoch train time: 0:00:01.432386
elapsed time: 0:00:23.018960
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:35:48.062016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.98
 ---- batch: 020 ----
mean loss: 203.90
 ---- batch: 030 ----
mean loss: 205.61
train mean loss: 205.96
epoch train time: 0:00:01.434630
elapsed time: 0:00:24.453747
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:35:49.496816
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.73
 ---- batch: 020 ----
mean loss: 201.46
 ---- batch: 030 ----
mean loss: 208.05
train mean loss: 204.93
epoch train time: 0:00:01.433897
elapsed time: 0:00:25.887814
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:35:50.930871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.47
 ---- batch: 020 ----
mean loss: 195.71
 ---- batch: 030 ----
mean loss: 194.03
train mean loss: 198.23
epoch train time: 0:00:01.432485
elapsed time: 0:00:27.320463
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:35:52.363521
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.02
 ---- batch: 020 ----
mean loss: 205.15
 ---- batch: 030 ----
mean loss: 196.95
train mean loss: 197.59
epoch train time: 0:00:01.435560
elapsed time: 0:00:28.756183
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:35:53.799242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.47
 ---- batch: 020 ----
mean loss: 192.09
 ---- batch: 030 ----
mean loss: 187.38
train mean loss: 191.46
epoch train time: 0:00:01.434164
elapsed time: 0:00:30.190542
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:35:55.233617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.02
 ---- batch: 020 ----
mean loss: 197.56
 ---- batch: 030 ----
mean loss: 191.28
train mean loss: 191.85
epoch train time: 0:00:01.439941
elapsed time: 0:00:31.630680
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:35:56.673737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.41
 ---- batch: 020 ----
mean loss: 186.44
 ---- batch: 030 ----
mean loss: 195.44
train mean loss: 191.57
epoch train time: 0:00:01.433463
elapsed time: 0:00:33.064315
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:35:58.107373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.56
 ---- batch: 020 ----
mean loss: 183.72
 ---- batch: 030 ----
mean loss: 187.04
train mean loss: 186.94
epoch train time: 0:00:01.437200
elapsed time: 0:00:34.501691
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:35:59.544753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.82
 ---- batch: 020 ----
mean loss: 186.50
 ---- batch: 030 ----
mean loss: 190.10
train mean loss: 188.45
epoch train time: 0:00:01.439516
elapsed time: 0:00:35.941401
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:36:00.984457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.25
 ---- batch: 020 ----
mean loss: 181.79
 ---- batch: 030 ----
mean loss: 181.63
train mean loss: 184.85
epoch train time: 0:00:01.434725
elapsed time: 0:00:37.376290
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:36:02.419347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.69
 ---- batch: 020 ----
mean loss: 191.55
 ---- batch: 030 ----
mean loss: 177.24
train mean loss: 185.49
epoch train time: 0:00:01.432655
elapsed time: 0:00:38.809130
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:36:03.852233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.78
 ---- batch: 020 ----
mean loss: 190.68
 ---- batch: 030 ----
mean loss: 191.26
train mean loss: 187.19
epoch train time: 0:00:01.429951
elapsed time: 0:00:40.239297
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:36:05.282358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.68
 ---- batch: 020 ----
mean loss: 180.51
 ---- batch: 030 ----
mean loss: 183.02
train mean loss: 183.47
epoch train time: 0:00:01.427289
elapsed time: 0:00:41.666760
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:36:06.709818
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.10
 ---- batch: 020 ----
mean loss: 183.40
 ---- batch: 030 ----
mean loss: 191.91
train mean loss: 186.39
epoch train time: 0:00:01.433199
elapsed time: 0:00:43.100142
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:36:08.143231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.19
 ---- batch: 020 ----
mean loss: 185.57
 ---- batch: 030 ----
mean loss: 175.82
train mean loss: 180.54
epoch train time: 0:00:01.430144
elapsed time: 0:00:44.530530
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:36:09.573589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.30
 ---- batch: 020 ----
mean loss: 182.70
 ---- batch: 030 ----
mean loss: 185.62
train mean loss: 182.14
epoch train time: 0:00:01.432340
elapsed time: 0:00:45.963034
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:36:11.006087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.49
 ---- batch: 020 ----
mean loss: 178.54
 ---- batch: 030 ----
mean loss: 185.99
train mean loss: 181.90
epoch train time: 0:00:01.436276
elapsed time: 0:00:47.399473
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:36:12.442534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.95
 ---- batch: 020 ----
mean loss: 180.04
 ---- batch: 030 ----
mean loss: 180.86
train mean loss: 181.70
epoch train time: 0:00:01.432653
elapsed time: 0:00:48.832295
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:36:13.875357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.18
 ---- batch: 020 ----
mean loss: 172.14
 ---- batch: 030 ----
mean loss: 171.22
train mean loss: 173.68
epoch train time: 0:00:01.433474
elapsed time: 0:00:50.265929
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:36:15.308995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.70
 ---- batch: 020 ----
mean loss: 176.57
 ---- batch: 030 ----
mean loss: 176.22
train mean loss: 177.08
epoch train time: 0:00:01.437079
elapsed time: 0:00:51.703196
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:36:16.746255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.64
 ---- batch: 020 ----
mean loss: 174.47
 ---- batch: 030 ----
mean loss: 180.05
train mean loss: 176.52
epoch train time: 0:00:01.431782
elapsed time: 0:00:53.135144
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:36:18.178200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.68
 ---- batch: 020 ----
mean loss: 173.49
 ---- batch: 030 ----
mean loss: 175.78
train mean loss: 176.17
epoch train time: 0:00:01.428942
elapsed time: 0:00:54.564243
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:36:19.607298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.36
 ---- batch: 020 ----
mean loss: 172.97
 ---- batch: 030 ----
mean loss: 178.29
train mean loss: 173.84
epoch train time: 0:00:01.429075
elapsed time: 0:00:55.993479
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:36:21.036540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.71
 ---- batch: 020 ----
mean loss: 178.64
 ---- batch: 030 ----
mean loss: 180.80
train mean loss: 175.07
epoch train time: 0:00:01.433501
elapsed time: 0:00:57.427166
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:36:22.470246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.76
 ---- batch: 020 ----
mean loss: 171.12
 ---- batch: 030 ----
mean loss: 176.44
train mean loss: 171.29
epoch train time: 0:00:01.434259
elapsed time: 0:00:58.861610
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:36:23.904665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.09
 ---- batch: 020 ----
mean loss: 171.77
 ---- batch: 030 ----
mean loss: 169.55
train mean loss: 171.54
epoch train time: 0:00:01.433928
elapsed time: 0:01:00.295705
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:36:25.338809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.46
 ---- batch: 020 ----
mean loss: 172.14
 ---- batch: 030 ----
mean loss: 167.01
train mean loss: 169.50
epoch train time: 0:00:01.436914
elapsed time: 0:01:01.732834
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:36:26.775890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.82
 ---- batch: 020 ----
mean loss: 175.84
 ---- batch: 030 ----
mean loss: 180.21
train mean loss: 174.13
epoch train time: 0:00:01.435123
elapsed time: 0:01:03.168139
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:36:28.211193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.91
 ---- batch: 020 ----
mean loss: 178.61
 ---- batch: 030 ----
mean loss: 168.32
train mean loss: 173.37
epoch train time: 0:00:01.433570
elapsed time: 0:01:04.601915
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:36:29.644982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.51
 ---- batch: 020 ----
mean loss: 176.10
 ---- batch: 030 ----
mean loss: 174.29
train mean loss: 174.61
epoch train time: 0:00:01.435049
elapsed time: 0:01:06.037136
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:36:31.080211
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.88
 ---- batch: 020 ----
mean loss: 167.93
 ---- batch: 030 ----
mean loss: 180.79
train mean loss: 170.97
epoch train time: 0:00:01.430873
elapsed time: 0:01:07.468205
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:36:32.511262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.98
 ---- batch: 020 ----
mean loss: 166.23
 ---- batch: 030 ----
mean loss: 166.90
train mean loss: 168.39
epoch train time: 0:00:01.423132
elapsed time: 0:01:08.891495
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:36:33.934554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.03
 ---- batch: 020 ----
mean loss: 161.04
 ---- batch: 030 ----
mean loss: 168.15
train mean loss: 168.65
epoch train time: 0:00:01.431482
elapsed time: 0:01:10.323144
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:36:35.366206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.61
 ---- batch: 020 ----
mean loss: 171.69
 ---- batch: 030 ----
mean loss: 163.98
train mean loss: 167.48
epoch train time: 0:00:01.433485
elapsed time: 0:01:11.756808
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:36:36.799866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.14
 ---- batch: 020 ----
mean loss: 169.33
 ---- batch: 030 ----
mean loss: 163.95
train mean loss: 166.07
epoch train time: 0:00:01.435859
elapsed time: 0:01:13.192826
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:36:38.235882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.55
 ---- batch: 020 ----
mean loss: 163.14
 ---- batch: 030 ----
mean loss: 162.52
train mean loss: 163.35
epoch train time: 0:00:01.427813
elapsed time: 0:01:14.620833
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:36:39.663887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.59
 ---- batch: 020 ----
mean loss: 156.03
 ---- batch: 030 ----
mean loss: 163.10
train mean loss: 160.23
epoch train time: 0:00:01.429793
elapsed time: 0:01:16.050794
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:36:41.093855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.62
 ---- batch: 020 ----
mean loss: 160.91
 ---- batch: 030 ----
mean loss: 157.11
train mean loss: 159.21
epoch train time: 0:00:01.431648
elapsed time: 0:01:17.482624
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:36:42.525704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.97
 ---- batch: 020 ----
mean loss: 158.07
 ---- batch: 030 ----
mean loss: 162.85
train mean loss: 161.69
epoch train time: 0:00:01.429163
elapsed time: 0:01:18.911970
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:36:43.955025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.61
 ---- batch: 020 ----
mean loss: 167.99
 ---- batch: 030 ----
mean loss: 159.60
train mean loss: 169.80
epoch train time: 0:00:01.432765
elapsed time: 0:01:20.344896
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:36:45.387964
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.72
 ---- batch: 020 ----
mean loss: 155.57
 ---- batch: 030 ----
mean loss: 161.60
train mean loss: 155.95
epoch train time: 0:00:01.431341
elapsed time: 0:01:21.776422
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:36:46.819488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.57
 ---- batch: 020 ----
mean loss: 160.75
 ---- batch: 030 ----
mean loss: 160.66
train mean loss: 157.65
epoch train time: 0:00:01.434185
elapsed time: 0:01:23.210785
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:36:48.253847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.24
 ---- batch: 020 ----
mean loss: 159.74
 ---- batch: 030 ----
mean loss: 160.29
train mean loss: 158.94
epoch train time: 0:00:01.436692
elapsed time: 0:01:24.647641
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:36:49.690695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.81
 ---- batch: 020 ----
mean loss: 157.97
 ---- batch: 030 ----
mean loss: 155.89
train mean loss: 157.19
epoch train time: 0:00:01.431365
elapsed time: 0:01:26.079167
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:36:51.122248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.37
 ---- batch: 020 ----
mean loss: 151.63
 ---- batch: 030 ----
mean loss: 150.96
train mean loss: 152.45
epoch train time: 0:00:01.429117
elapsed time: 0:01:27.508477
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:36:52.551550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.72
 ---- batch: 020 ----
mean loss: 148.09
 ---- batch: 030 ----
mean loss: 148.85
train mean loss: 151.75
epoch train time: 0:00:01.431134
elapsed time: 0:01:28.939788
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:36:53.982843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.09
 ---- batch: 020 ----
mean loss: 156.96
 ---- batch: 030 ----
mean loss: 150.22
train mean loss: 152.68
epoch train time: 0:00:01.428806
elapsed time: 0:01:30.368752
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:36:55.411805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.78
 ---- batch: 020 ----
mean loss: 164.28
 ---- batch: 030 ----
mean loss: 154.82
train mean loss: 157.17
epoch train time: 0:00:01.430371
elapsed time: 0:01:31.799301
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:36:56.842360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.84
 ---- batch: 020 ----
mean loss: 149.25
 ---- batch: 030 ----
mean loss: 157.82
train mean loss: 153.85
epoch train time: 0:00:01.431532
elapsed time: 0:01:33.231033
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:36:58.274104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.33
 ---- batch: 020 ----
mean loss: 157.49
 ---- batch: 030 ----
mean loss: 150.99
train mean loss: 153.77
epoch train time: 0:00:01.430142
elapsed time: 0:01:34.661351
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:36:59.704409
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.62
 ---- batch: 020 ----
mean loss: 153.00
 ---- batch: 030 ----
mean loss: 151.26
train mean loss: 149.53
epoch train time: 0:00:01.432138
elapsed time: 0:01:36.093654
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:37:01.136708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.46
 ---- batch: 020 ----
mean loss: 149.49
 ---- batch: 030 ----
mean loss: 153.41
train mean loss: 151.89
epoch train time: 0:00:01.432050
elapsed time: 0:01:37.525862
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:37:02.568938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.75
 ---- batch: 020 ----
mean loss: 149.02
 ---- batch: 030 ----
mean loss: 154.56
train mean loss: 150.63
epoch train time: 0:00:01.429597
elapsed time: 0:01:38.955639
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:37:03.998693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.56
 ---- batch: 020 ----
mean loss: 153.65
 ---- batch: 030 ----
mean loss: 157.16
train mean loss: 153.91
epoch train time: 0:00:01.431013
elapsed time: 0:01:40.386878
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:37:05.429961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.40
 ---- batch: 020 ----
mean loss: 154.87
 ---- batch: 030 ----
mean loss: 155.96
train mean loss: 156.74
epoch train time: 0:00:01.435370
elapsed time: 0:01:41.822442
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:37:06.865497
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.07
 ---- batch: 020 ----
mean loss: 161.08
 ---- batch: 030 ----
mean loss: 154.96
train mean loss: 156.89
epoch train time: 0:00:01.434263
elapsed time: 0:01:43.256865
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:37:08.299933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.00
 ---- batch: 020 ----
mean loss: 149.54
 ---- batch: 030 ----
mean loss: 148.50
train mean loss: 149.17
epoch train time: 0:00:01.435955
elapsed time: 0:01:44.692987
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:37:09.736040
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.47
 ---- batch: 020 ----
mean loss: 144.65
 ---- batch: 030 ----
mean loss: 149.22
train mean loss: 147.53
epoch train time: 0:00:01.432186
elapsed time: 0:01:46.125335
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:37:11.168390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.10
 ---- batch: 020 ----
mean loss: 146.66
 ---- batch: 030 ----
mean loss: 147.66
train mean loss: 148.59
epoch train time: 0:00:01.437128
elapsed time: 0:01:47.562668
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:37:12.605729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.47
 ---- batch: 020 ----
mean loss: 148.34
 ---- batch: 030 ----
mean loss: 150.15
train mean loss: 148.81
epoch train time: 0:00:01.430692
elapsed time: 0:01:48.993543
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:37:14.036617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.77
 ---- batch: 020 ----
mean loss: 149.02
 ---- batch: 030 ----
mean loss: 154.49
train mean loss: 152.59
epoch train time: 0:00:01.433113
elapsed time: 0:01:50.426846
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:37:15.469937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.46
 ---- batch: 020 ----
mean loss: 154.07
 ---- batch: 030 ----
mean loss: 156.06
train mean loss: 152.87
epoch train time: 0:00:01.436058
elapsed time: 0:01:51.863099
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:37:16.906170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.86
 ---- batch: 020 ----
mean loss: 152.24
 ---- batch: 030 ----
mean loss: 147.11
train mean loss: 149.27
epoch train time: 0:00:01.427632
elapsed time: 0:01:53.290916
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:37:18.333976
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.31
 ---- batch: 020 ----
mean loss: 149.87
 ---- batch: 030 ----
mean loss: 146.01
train mean loss: 148.81
epoch train time: 0:00:01.430571
elapsed time: 0:01:54.721686
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:37:19.764753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.01
 ---- batch: 020 ----
mean loss: 155.95
 ---- batch: 030 ----
mean loss: 153.84
train mean loss: 154.63
epoch train time: 0:00:01.433853
elapsed time: 0:01:56.155777
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:37:21.198987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.77
 ---- batch: 020 ----
mean loss: 151.83
 ---- batch: 030 ----
mean loss: 146.59
train mean loss: 145.92
epoch train time: 0:00:01.428255
elapsed time: 0:01:57.584350
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:37:22.627422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.39
 ---- batch: 020 ----
mean loss: 148.53
 ---- batch: 030 ----
mean loss: 151.81
train mean loss: 149.14
epoch train time: 0:00:01.434231
elapsed time: 0:01:59.018777
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:37:24.061838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.35
 ---- batch: 020 ----
mean loss: 146.88
 ---- batch: 030 ----
mean loss: 148.66
train mean loss: 146.24
epoch train time: 0:00:01.432476
elapsed time: 0:02:00.451413
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:37:25.494477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.76
 ---- batch: 020 ----
mean loss: 151.42
 ---- batch: 030 ----
mean loss: 141.06
train mean loss: 147.40
epoch train time: 0:00:01.434687
elapsed time: 0:02:01.886274
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:37:26.929331
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.20
 ---- batch: 020 ----
mean loss: 146.83
 ---- batch: 030 ----
mean loss: 147.40
train mean loss: 147.80
epoch train time: 0:00:01.433024
elapsed time: 0:02:03.319468
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:37:28.362556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.14
 ---- batch: 020 ----
mean loss: 144.88
 ---- batch: 030 ----
mean loss: 146.67
train mean loss: 146.06
epoch train time: 0:00:01.427452
elapsed time: 0:02:04.747115
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:37:29.790172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.17
 ---- batch: 020 ----
mean loss: 146.33
 ---- batch: 030 ----
mean loss: 146.15
train mean loss: 144.35
epoch train time: 0:00:01.430840
elapsed time: 0:02:06.178110
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:37:31.221163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.48
 ---- batch: 020 ----
mean loss: 149.08
 ---- batch: 030 ----
mean loss: 149.20
train mean loss: 148.24
epoch train time: 0:00:01.434867
elapsed time: 0:02:07.613135
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:37:32.656191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.14
 ---- batch: 020 ----
mean loss: 148.47
 ---- batch: 030 ----
mean loss: 147.76
train mean loss: 146.28
epoch train time: 0:00:01.427675
elapsed time: 0:02:09.040979
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:37:34.084106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.18
 ---- batch: 020 ----
mean loss: 144.27
 ---- batch: 030 ----
mean loss: 145.63
train mean loss: 145.70
epoch train time: 0:00:01.431364
elapsed time: 0:02:10.472568
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:37:35.515640
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.92
 ---- batch: 020 ----
mean loss: 148.22
 ---- batch: 030 ----
mean loss: 149.81
train mean loss: 148.99
epoch train time: 0:00:01.434901
elapsed time: 0:02:11.907655
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:37:36.950714
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.12
 ---- batch: 020 ----
mean loss: 152.25
 ---- batch: 030 ----
mean loss: 142.77
train mean loss: 146.55
epoch train time: 0:00:01.431198
elapsed time: 0:02:13.339017
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:37:38.382075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.90
 ---- batch: 020 ----
mean loss: 148.10
 ---- batch: 030 ----
mean loss: 144.37
train mean loss: 145.20
epoch train time: 0:00:01.433871
elapsed time: 0:02:14.773071
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:37:39.816146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.99
 ---- batch: 020 ----
mean loss: 143.76
 ---- batch: 030 ----
mean loss: 146.92
train mean loss: 146.46
epoch train time: 0:00:01.431520
elapsed time: 0:02:16.204778
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:37:41.247855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.23
 ---- batch: 020 ----
mean loss: 143.61
 ---- batch: 030 ----
mean loss: 138.77
train mean loss: 143.97
epoch train time: 0:00:01.435736
elapsed time: 0:02:17.640709
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:37:42.683769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.34
 ---- batch: 020 ----
mean loss: 141.38
 ---- batch: 030 ----
mean loss: 148.36
train mean loss: 146.43
epoch train time: 0:00:01.435551
elapsed time: 0:02:19.076457
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:37:44.119518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.70
 ---- batch: 020 ----
mean loss: 139.04
 ---- batch: 030 ----
mean loss: 144.51
train mean loss: 144.92
epoch train time: 0:00:01.431300
elapsed time: 0:02:20.507925
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:37:45.550979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.17
 ---- batch: 020 ----
mean loss: 161.03
 ---- batch: 030 ----
mean loss: 157.61
train mean loss: 155.23
epoch train time: 0:00:01.432307
elapsed time: 0:02:21.940384
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:37:46.983446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.54
 ---- batch: 020 ----
mean loss: 149.71
 ---- batch: 030 ----
mean loss: 147.40
train mean loss: 147.06
epoch train time: 0:00:01.433081
elapsed time: 0:02:23.373628
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:37:48.416693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.20
 ---- batch: 020 ----
mean loss: 142.66
 ---- batch: 030 ----
mean loss: 145.10
train mean loss: 143.92
epoch train time: 0:00:01.430716
elapsed time: 0:02:24.804525
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:37:49.847583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.79
 ---- batch: 020 ----
mean loss: 139.89
 ---- batch: 030 ----
mean loss: 145.45
train mean loss: 143.63
epoch train time: 0:00:01.432535
elapsed time: 0:02:26.237231
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:37:51.280284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.96
 ---- batch: 020 ----
mean loss: 141.90
 ---- batch: 030 ----
mean loss: 150.07
train mean loss: 144.53
epoch train time: 0:00:01.436244
elapsed time: 0:02:27.673642
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:37:52.716706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.42
 ---- batch: 020 ----
mean loss: 138.53
 ---- batch: 030 ----
mean loss: 149.20
train mean loss: 144.21
epoch train time: 0:00:01.429699
elapsed time: 0:02:29.103508
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:37:54.146560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.89
 ---- batch: 020 ----
mean loss: 147.84
 ---- batch: 030 ----
mean loss: 147.83
train mean loss: 148.35
epoch train time: 0:00:01.429515
elapsed time: 0:02:30.533179
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:37:55.576238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.31
 ---- batch: 020 ----
mean loss: 144.51
 ---- batch: 030 ----
mean loss: 145.12
train mean loss: 143.90
epoch train time: 0:00:01.435486
elapsed time: 0:02:31.968832
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:37:57.011888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.09
 ---- batch: 020 ----
mean loss: 143.54
 ---- batch: 030 ----
mean loss: 144.05
train mean loss: 143.45
epoch train time: 0:00:01.435320
elapsed time: 0:02:33.404335
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:37:58.447386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.22
 ---- batch: 020 ----
mean loss: 142.17
 ---- batch: 030 ----
mean loss: 138.76
train mean loss: 144.15
epoch train time: 0:00:01.435107
elapsed time: 0:02:34.839632
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:37:59.882755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.56
 ---- batch: 020 ----
mean loss: 142.05
 ---- batch: 030 ----
mean loss: 142.75
train mean loss: 143.54
epoch train time: 0:00:01.436646
elapsed time: 0:02:36.276506
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:38:01.319562
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.44
 ---- batch: 020 ----
mean loss: 142.60
 ---- batch: 030 ----
mean loss: 141.20
train mean loss: 143.13
epoch train time: 0:00:01.430287
elapsed time: 0:02:37.706970
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:38:02.750023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.35
 ---- batch: 020 ----
mean loss: 150.99
 ---- batch: 030 ----
mean loss: 146.18
train mean loss: 146.85
epoch train time: 0:00:01.429700
elapsed time: 0:02:39.136826
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:38:04.179878
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.29
 ---- batch: 020 ----
mean loss: 139.13
 ---- batch: 030 ----
mean loss: 140.22
train mean loss: 141.73
epoch train time: 0:00:01.423122
elapsed time: 0:02:40.560103
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:38:05.603160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.31
 ---- batch: 020 ----
mean loss: 140.48
 ---- batch: 030 ----
mean loss: 139.92
train mean loss: 143.01
epoch train time: 0:00:01.437304
elapsed time: 0:02:41.997572
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:38:07.040630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.47
 ---- batch: 020 ----
mean loss: 143.03
 ---- batch: 030 ----
mean loss: 149.00
train mean loss: 145.90
epoch train time: 0:00:01.435493
elapsed time: 0:02:43.433229
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:38:08.476286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.76
 ---- batch: 020 ----
mean loss: 141.77
 ---- batch: 030 ----
mean loss: 141.78
train mean loss: 144.10
epoch train time: 0:00:01.431197
elapsed time: 0:02:44.864604
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:38:09.907648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.92
 ---- batch: 020 ----
mean loss: 139.94
 ---- batch: 030 ----
mean loss: 143.32
train mean loss: 140.37
epoch train time: 0:00:01.433431
elapsed time: 0:02:46.298180
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:38:11.341239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.05
 ---- batch: 020 ----
mean loss: 144.41
 ---- batch: 030 ----
mean loss: 142.49
train mean loss: 144.94
epoch train time: 0:00:01.432351
elapsed time: 0:02:47.730727
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:38:12.773785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.12
 ---- batch: 020 ----
mean loss: 138.91
 ---- batch: 030 ----
mean loss: 141.42
train mean loss: 143.85
epoch train time: 0:00:01.435873
elapsed time: 0:02:49.166764
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:38:14.209820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.45
 ---- batch: 020 ----
mean loss: 143.67
 ---- batch: 030 ----
mean loss: 144.09
train mean loss: 143.69
epoch train time: 0:00:01.433119
elapsed time: 0:02:50.600048
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:38:15.643111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.95
 ---- batch: 020 ----
mean loss: 138.30
 ---- batch: 030 ----
mean loss: 138.20
train mean loss: 141.09
epoch train time: 0:00:01.436053
elapsed time: 0:02:52.036290
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:38:17.079346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.76
 ---- batch: 020 ----
mean loss: 153.08
 ---- batch: 030 ----
mean loss: 148.37
train mean loss: 151.61
epoch train time: 0:00:01.433743
elapsed time: 0:02:53.470202
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:38:18.513260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.21
 ---- batch: 020 ----
mean loss: 139.42
 ---- batch: 030 ----
mean loss: 145.98
train mean loss: 144.44
epoch train time: 0:00:01.429092
elapsed time: 0:02:54.899475
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:38:19.942572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.55
 ---- batch: 020 ----
mean loss: 141.04
 ---- batch: 030 ----
mean loss: 141.42
train mean loss: 143.18
epoch train time: 0:00:01.431209
elapsed time: 0:02:56.330886
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:38:21.373973
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.41
 ---- batch: 020 ----
mean loss: 138.64
 ---- batch: 030 ----
mean loss: 140.73
train mean loss: 140.05
epoch train time: 0:00:01.430532
elapsed time: 0:02:57.761617
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:38:22.804690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.12
 ---- batch: 020 ----
mean loss: 140.53
 ---- batch: 030 ----
mean loss: 138.90
train mean loss: 139.33
epoch train time: 0:00:01.432489
elapsed time: 0:02:59.194284
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:38:24.237340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.10
 ---- batch: 020 ----
mean loss: 138.16
 ---- batch: 030 ----
mean loss: 143.18
train mean loss: 141.02
epoch train time: 0:00:01.433142
elapsed time: 0:03:00.627641
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:38:25.670705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.66
 ---- batch: 020 ----
mean loss: 139.54
 ---- batch: 030 ----
mean loss: 143.78
train mean loss: 141.93
epoch train time: 0:00:01.437249
elapsed time: 0:03:02.065058
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:38:27.108116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.10
 ---- batch: 020 ----
mean loss: 139.78
 ---- batch: 030 ----
mean loss: 140.11
train mean loss: 139.46
epoch train time: 0:00:01.431155
elapsed time: 0:03:03.496406
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:38:28.539461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.19
 ---- batch: 020 ----
mean loss: 138.61
 ---- batch: 030 ----
mean loss: 135.15
train mean loss: 140.00
epoch train time: 0:00:01.429796
elapsed time: 0:03:04.926363
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:38:29.969433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.82
 ---- batch: 020 ----
mean loss: 137.73
 ---- batch: 030 ----
mean loss: 145.32
train mean loss: 141.40
epoch train time: 0:00:01.432952
elapsed time: 0:03:06.359489
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:38:31.402567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.08
 ---- batch: 020 ----
mean loss: 140.03
 ---- batch: 030 ----
mean loss: 142.91
train mean loss: 141.41
epoch train time: 0:00:01.434678
elapsed time: 0:03:07.794356
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:38:32.837414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.51
 ---- batch: 020 ----
mean loss: 140.68
 ---- batch: 030 ----
mean loss: 146.03
train mean loss: 143.19
epoch train time: 0:00:01.430749
elapsed time: 0:03:09.225266
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:38:34.268321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.42
 ---- batch: 020 ----
mean loss: 134.97
 ---- batch: 030 ----
mean loss: 147.08
train mean loss: 140.93
epoch train time: 0:00:01.427439
elapsed time: 0:03:10.652876
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:38:35.695939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.00
 ---- batch: 020 ----
mean loss: 138.63
 ---- batch: 030 ----
mean loss: 140.52
train mean loss: 141.79
epoch train time: 0:00:01.431741
elapsed time: 0:03:12.084782
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:38:37.127840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.32
 ---- batch: 020 ----
mean loss: 141.73
 ---- batch: 030 ----
mean loss: 142.87
train mean loss: 141.14
epoch train time: 0:00:01.433585
elapsed time: 0:03:13.518543
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:38:38.561624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.29
 ---- batch: 020 ----
mean loss: 138.30
 ---- batch: 030 ----
mean loss: 140.00
train mean loss: 138.55
epoch train time: 0:00:01.428645
elapsed time: 0:03:14.947377
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:38:39.990438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.40
 ---- batch: 020 ----
mean loss: 138.21
 ---- batch: 030 ----
mean loss: 138.78
train mean loss: 138.52
epoch train time: 0:00:01.431634
elapsed time: 0:03:16.379215
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:38:41.422273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.16
 ---- batch: 020 ----
mean loss: 140.34
 ---- batch: 030 ----
mean loss: 139.30
train mean loss: 141.37
epoch train time: 0:00:01.432246
elapsed time: 0:03:17.811641
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:38:42.854698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.85
 ---- batch: 020 ----
mean loss: 153.22
 ---- batch: 030 ----
mean loss: 141.53
train mean loss: 147.18
epoch train time: 0:00:01.429998
elapsed time: 0:03:19.241813
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:38:44.284885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.47
 ---- batch: 020 ----
mean loss: 136.72
 ---- batch: 030 ----
mean loss: 138.00
train mean loss: 139.73
epoch train time: 0:00:01.432962
elapsed time: 0:03:20.674975
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:38:45.718046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.10
 ---- batch: 020 ----
mean loss: 141.10
 ---- batch: 030 ----
mean loss: 137.71
train mean loss: 138.44
epoch train time: 0:00:01.432032
elapsed time: 0:03:22.107179
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:38:47.150236
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.46
 ---- batch: 020 ----
mean loss: 148.35
 ---- batch: 030 ----
mean loss: 147.69
train mean loss: 145.21
epoch train time: 0:00:01.428576
elapsed time: 0:03:23.535915
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:38:48.578981
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.65
 ---- batch: 020 ----
mean loss: 137.70
 ---- batch: 030 ----
mean loss: 142.15
train mean loss: 140.04
epoch train time: 0:00:01.435964
elapsed time: 0:03:24.972053
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:38:50.015107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.00
 ---- batch: 020 ----
mean loss: 130.26
 ---- batch: 030 ----
mean loss: 138.15
train mean loss: 135.49
epoch train time: 0:00:01.430154
elapsed time: 0:03:26.402364
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:38:51.445427
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.77
 ---- batch: 020 ----
mean loss: 138.39
 ---- batch: 030 ----
mean loss: 141.29
train mean loss: 140.36
epoch train time: 0:00:01.435253
elapsed time: 0:03:27.837785
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:38:52.880841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.01
 ---- batch: 020 ----
mean loss: 141.42
 ---- batch: 030 ----
mean loss: 138.62
train mean loss: 139.34
epoch train time: 0:00:01.430338
elapsed time: 0:03:29.268283
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:38:54.311339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.94
 ---- batch: 020 ----
mean loss: 140.33
 ---- batch: 030 ----
mean loss: 139.88
train mean loss: 142.09
epoch train time: 0:00:01.434726
elapsed time: 0:03:30.703170
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:38:55.746226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.99
 ---- batch: 020 ----
mean loss: 138.57
 ---- batch: 030 ----
mean loss: 141.27
train mean loss: 139.65
epoch train time: 0:00:01.435056
elapsed time: 0:03:32.138383
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:38:57.181437
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.23
 ---- batch: 020 ----
mean loss: 139.49
 ---- batch: 030 ----
mean loss: 142.81
train mean loss: 140.75
epoch train time: 0:00:01.432305
elapsed time: 0:03:33.570860
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:38:58.613938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.56
 ---- batch: 020 ----
mean loss: 136.01
 ---- batch: 030 ----
mean loss: 141.05
train mean loss: 139.13
epoch train time: 0:00:01.429635
elapsed time: 0:03:35.000695
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:39:00.043765
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.30
 ---- batch: 020 ----
mean loss: 149.07
 ---- batch: 030 ----
mean loss: 155.49
train mean loss: 147.78
epoch train time: 0:00:01.429485
elapsed time: 0:03:36.430363
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:39:01.473428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.38
 ---- batch: 020 ----
mean loss: 136.69
 ---- batch: 030 ----
mean loss: 139.79
train mean loss: 139.16
epoch train time: 0:00:01.430116
elapsed time: 0:03:37.860651
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:39:02.903709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.79
 ---- batch: 020 ----
mean loss: 139.18
 ---- batch: 030 ----
mean loss: 137.09
train mean loss: 139.78
epoch train time: 0:00:01.430221
elapsed time: 0:03:39.291039
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:39:04.334095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.27
 ---- batch: 020 ----
mean loss: 143.57
 ---- batch: 030 ----
mean loss: 135.48
train mean loss: 140.89
epoch train time: 0:00:01.430017
elapsed time: 0:03:40.721231
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:39:05.764289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.02
 ---- batch: 020 ----
mean loss: 140.37
 ---- batch: 030 ----
mean loss: 135.82
train mean loss: 139.84
epoch train time: 0:00:01.436181
elapsed time: 0:03:42.157573
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:39:07.200631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.46
 ---- batch: 020 ----
mean loss: 137.75
 ---- batch: 030 ----
mean loss: 142.18
train mean loss: 138.91
epoch train time: 0:00:01.432926
elapsed time: 0:03:43.590681
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:39:08.633745
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.30
 ---- batch: 020 ----
mean loss: 141.74
 ---- batch: 030 ----
mean loss: 136.32
train mean loss: 137.73
epoch train time: 0:00:01.431953
elapsed time: 0:03:45.022815
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:39:10.065856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.14
 ---- batch: 020 ----
mean loss: 136.73
 ---- batch: 030 ----
mean loss: 138.09
train mean loss: 139.08
epoch train time: 0:00:01.433157
elapsed time: 0:03:46.456133
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:39:11.499219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.64
 ---- batch: 020 ----
mean loss: 144.04
 ---- batch: 030 ----
mean loss: 141.08
train mean loss: 142.07
epoch train time: 0:00:01.429966
elapsed time: 0:03:47.886293
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:39:12.929350
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.82
 ---- batch: 020 ----
mean loss: 138.01
 ---- batch: 030 ----
mean loss: 140.55
train mean loss: 138.09
epoch train time: 0:00:01.433719
elapsed time: 0:03:49.320174
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:39:14.363229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.19
 ---- batch: 020 ----
mean loss: 139.61
 ---- batch: 030 ----
mean loss: 133.40
train mean loss: 136.80
epoch train time: 0:00:01.431104
elapsed time: 0:03:50.751450
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:39:15.794526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.32
 ---- batch: 020 ----
mean loss: 135.71
 ---- batch: 030 ----
mean loss: 139.89
train mean loss: 138.97
epoch train time: 0:00:01.433189
elapsed time: 0:03:52.184814
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:39:17.227893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.19
 ---- batch: 020 ----
mean loss: 144.25
 ---- batch: 030 ----
mean loss: 138.78
train mean loss: 141.31
epoch train time: 0:00:01.430828
elapsed time: 0:03:53.615822
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:39:18.658877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.99
 ---- batch: 020 ----
mean loss: 137.30
 ---- batch: 030 ----
mean loss: 139.99
train mean loss: 138.04
epoch train time: 0:00:01.432940
elapsed time: 0:03:55.048930
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:39:20.092008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.95
 ---- batch: 020 ----
mean loss: 142.67
 ---- batch: 030 ----
mean loss: 137.34
train mean loss: 139.52
epoch train time: 0:00:01.428549
elapsed time: 0:03:56.477659
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:39:21.520713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.92
 ---- batch: 020 ----
mean loss: 141.14
 ---- batch: 030 ----
mean loss: 135.96
train mean loss: 137.72
epoch train time: 0:00:01.431209
elapsed time: 0:03:57.909057
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:39:22.952127
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.13
 ---- batch: 020 ----
mean loss: 138.69
 ---- batch: 030 ----
mean loss: 140.15
train mean loss: 137.88
epoch train time: 0:00:01.436009
elapsed time: 0:03:59.345243
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:39:24.388302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.02
 ---- batch: 020 ----
mean loss: 141.73
 ---- batch: 030 ----
mean loss: 141.43
train mean loss: 143.00
epoch train time: 0:00:01.431946
elapsed time: 0:04:00.777412
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:39:25.820523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.14
 ---- batch: 020 ----
mean loss: 141.52
 ---- batch: 030 ----
mean loss: 135.71
train mean loss: 139.14
epoch train time: 0:00:01.438286
elapsed time: 0:04:02.215912
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:39:27.258965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.78
 ---- batch: 020 ----
mean loss: 136.71
 ---- batch: 030 ----
mean loss: 135.57
train mean loss: 136.31
epoch train time: 0:00:01.433747
elapsed time: 0:04:03.649848
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:39:28.692905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.34
 ---- batch: 020 ----
mean loss: 140.48
 ---- batch: 030 ----
mean loss: 137.99
train mean loss: 138.77
epoch train time: 0:00:01.433921
elapsed time: 0:04:05.083930
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:39:30.126986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.69
 ---- batch: 020 ----
mean loss: 139.14
 ---- batch: 030 ----
mean loss: 134.90
train mean loss: 138.43
epoch train time: 0:00:01.426829
elapsed time: 0:04:06.510929
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:39:31.553986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.92
 ---- batch: 020 ----
mean loss: 138.22
 ---- batch: 030 ----
mean loss: 133.59
train mean loss: 137.06
epoch train time: 0:00:01.433400
elapsed time: 0:04:07.944501
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:39:32.987557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.98
 ---- batch: 020 ----
mean loss: 132.06
 ---- batch: 030 ----
mean loss: 141.39
train mean loss: 136.95
epoch train time: 0:00:01.427163
elapsed time: 0:04:09.371826
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:39:34.414885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.69
 ---- batch: 020 ----
mean loss: 140.20
 ---- batch: 030 ----
mean loss: 140.75
train mean loss: 140.41
epoch train time: 0:00:01.431437
elapsed time: 0:04:10.803445
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:39:35.846502
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.81
 ---- batch: 020 ----
mean loss: 134.90
 ---- batch: 030 ----
mean loss: 141.21
train mean loss: 139.74
epoch train time: 0:00:01.431010
elapsed time: 0:04:12.234628
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:39:37.277721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.92
 ---- batch: 020 ----
mean loss: 131.89
 ---- batch: 030 ----
mean loss: 137.18
train mean loss: 137.16
epoch train time: 0:00:01.430117
elapsed time: 0:04:13.664964
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:39:38.708024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.37
 ---- batch: 020 ----
mean loss: 139.03
 ---- batch: 030 ----
mean loss: 134.79
train mean loss: 137.82
epoch train time: 0:00:01.433183
elapsed time: 0:04:15.098349
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:39:40.141494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.12
 ---- batch: 020 ----
mean loss: 140.54
 ---- batch: 030 ----
mean loss: 138.58
train mean loss: 139.18
epoch train time: 0:00:01.429492
elapsed time: 0:04:16.528093
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:39:41.571149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.71
 ---- batch: 020 ----
mean loss: 135.39
 ---- batch: 030 ----
mean loss: 140.45
train mean loss: 140.18
epoch train time: 0:00:01.428948
elapsed time: 0:04:17.957199
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:39:43.000255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.82
 ---- batch: 020 ----
mean loss: 136.39
 ---- batch: 030 ----
mean loss: 136.60
train mean loss: 136.44
epoch train time: 0:00:01.431756
elapsed time: 0:04:19.389136
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:39:44.432194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.55
 ---- batch: 020 ----
mean loss: 138.76
 ---- batch: 030 ----
mean loss: 134.96
train mean loss: 136.28
epoch train time: 0:00:01.433181
elapsed time: 0:04:20.822511
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:39:45.865557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.33
 ---- batch: 020 ----
mean loss: 139.12
 ---- batch: 030 ----
mean loss: 140.84
train mean loss: 138.29
epoch train time: 0:00:01.431670
elapsed time: 0:04:22.254352
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:39:47.297410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.44
 ---- batch: 020 ----
mean loss: 137.17
 ---- batch: 030 ----
mean loss: 135.25
train mean loss: 138.83
epoch train time: 0:00:01.433883
elapsed time: 0:04:23.688405
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:39:48.731461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.43
 ---- batch: 020 ----
mean loss: 146.53
 ---- batch: 030 ----
mean loss: 146.61
train mean loss: 144.23
epoch train time: 0:00:01.427184
elapsed time: 0:04:25.115745
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:39:50.158833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.29
 ---- batch: 020 ----
mean loss: 138.13
 ---- batch: 030 ----
mean loss: 135.83
train mean loss: 136.71
epoch train time: 0:00:01.431851
elapsed time: 0:04:26.547795
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:39:51.590877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.55
 ---- batch: 020 ----
mean loss: 134.34
 ---- batch: 030 ----
mean loss: 139.56
train mean loss: 138.03
epoch train time: 0:00:01.429128
elapsed time: 0:04:27.977126
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:39:53.020199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.93
 ---- batch: 020 ----
mean loss: 137.06
 ---- batch: 030 ----
mean loss: 137.56
train mean loss: 136.37
epoch train time: 0:00:01.433329
elapsed time: 0:04:29.410649
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:39:54.453707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.79
 ---- batch: 020 ----
mean loss: 142.22
 ---- batch: 030 ----
mean loss: 133.39
train mean loss: 135.52
epoch train time: 0:00:01.431209
elapsed time: 0:04:30.842034
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:39:55.885142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.35
 ---- batch: 020 ----
mean loss: 136.85
 ---- batch: 030 ----
mean loss: 138.64
train mean loss: 136.53
epoch train time: 0:00:01.438129
elapsed time: 0:04:32.280374
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:39:57.323430
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.70
 ---- batch: 020 ----
mean loss: 136.11
 ---- batch: 030 ----
mean loss: 137.41
train mean loss: 136.42
epoch train time: 0:00:01.426498
elapsed time: 0:04:33.707066
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:39:58.750176
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.53
 ---- batch: 020 ----
mean loss: 140.75
 ---- batch: 030 ----
mean loss: 144.67
train mean loss: 142.38
epoch train time: 0:00:01.429936
elapsed time: 0:04:35.137213
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:40:00.180268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.92
 ---- batch: 020 ----
mean loss: 141.84
 ---- batch: 030 ----
mean loss: 140.42
train mean loss: 142.44
epoch train time: 0:00:01.430072
elapsed time: 0:04:36.567497
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:40:01.610591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.43
 ---- batch: 020 ----
mean loss: 138.51
 ---- batch: 030 ----
mean loss: 132.31
train mean loss: 136.65
epoch train time: 0:00:01.433386
elapsed time: 0:04:38.001106
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:40:03.044182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.56
 ---- batch: 020 ----
mean loss: 134.59
 ---- batch: 030 ----
mean loss: 136.70
train mean loss: 136.19
epoch train time: 0:00:01.429135
elapsed time: 0:04:39.430435
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:40:04.473491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.60
 ---- batch: 020 ----
mean loss: 141.21
 ---- batch: 030 ----
mean loss: 136.13
train mean loss: 136.53
epoch train time: 0:00:01.431417
elapsed time: 0:04:40.862039
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:40:05.905097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.08
 ---- batch: 020 ----
mean loss: 134.40
 ---- batch: 030 ----
mean loss: 139.00
train mean loss: 137.72
epoch train time: 0:00:01.434120
elapsed time: 0:04:42.296321
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:40:07.339377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.20
 ---- batch: 020 ----
mean loss: 137.33
 ---- batch: 030 ----
mean loss: 139.44
train mean loss: 136.09
epoch train time: 0:00:01.430212
elapsed time: 0:04:43.726718
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:40:08.769779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.80
 ---- batch: 020 ----
mean loss: 135.47
 ---- batch: 030 ----
mean loss: 139.18
train mean loss: 137.60
epoch train time: 0:00:01.431801
elapsed time: 0:04:45.158721
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:40:10.201786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.66
 ---- batch: 020 ----
mean loss: 132.76
 ---- batch: 030 ----
mean loss: 131.00
train mean loss: 132.03
epoch train time: 0:00:01.427530
elapsed time: 0:04:46.586439
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:40:11.629501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.55
 ---- batch: 020 ----
mean loss: 140.30
 ---- batch: 030 ----
mean loss: 138.76
train mean loss: 138.16
epoch train time: 0:00:01.434022
elapsed time: 0:04:48.020642
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:40:13.063702
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.60
 ---- batch: 020 ----
mean loss: 138.88
 ---- batch: 030 ----
mean loss: 132.35
train mean loss: 134.72
epoch train time: 0:00:01.434486
elapsed time: 0:04:49.455312
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:40:14.498370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.46
 ---- batch: 020 ----
mean loss: 137.18
 ---- batch: 030 ----
mean loss: 135.39
train mean loss: 135.35
epoch train time: 0:00:01.434907
elapsed time: 0:04:50.890387
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:40:15.933514
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.40
 ---- batch: 020 ----
mean loss: 136.28
 ---- batch: 030 ----
mean loss: 136.72
train mean loss: 137.17
epoch train time: 0:00:01.426448
elapsed time: 0:04:52.317064
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:40:17.360122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.98
 ---- batch: 020 ----
mean loss: 138.83
 ---- batch: 030 ----
mean loss: 132.22
train mean loss: 137.40
epoch train time: 0:00:01.435525
elapsed time: 0:04:53.752760
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:40:18.795817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.22
 ---- batch: 020 ----
mean loss: 133.84
 ---- batch: 030 ----
mean loss: 137.39
train mean loss: 135.70
epoch train time: 0:00:01.432046
elapsed time: 0:04:55.184972
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:40:20.228027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.90
 ---- batch: 020 ----
mean loss: 135.95
 ---- batch: 030 ----
mean loss: 133.69
train mean loss: 135.25
epoch train time: 0:00:01.428264
elapsed time: 0:04:56.613414
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:40:21.656523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.63
 ---- batch: 020 ----
mean loss: 138.75
 ---- batch: 030 ----
mean loss: 136.09
train mean loss: 136.30
epoch train time: 0:00:01.430303
elapsed time: 0:04:58.043933
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:40:23.086990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.74
 ---- batch: 020 ----
mean loss: 133.57
 ---- batch: 030 ----
mean loss: 141.50
train mean loss: 136.05
epoch train time: 0:00:01.435134
elapsed time: 0:04:59.479229
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:40:24.522287
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.23
 ---- batch: 020 ----
mean loss: 134.12
 ---- batch: 030 ----
mean loss: 132.18
train mean loss: 133.32
epoch train time: 0:00:01.433719
elapsed time: 0:05:00.913135
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:40:25.956199
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.58
 ---- batch: 020 ----
mean loss: 134.30
 ---- batch: 030 ----
mean loss: 131.58
train mean loss: 132.20
epoch train time: 0:00:01.428566
elapsed time: 0:05:02.341931
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:40:27.384990
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.95
 ---- batch: 020 ----
mean loss: 129.33
 ---- batch: 030 ----
mean loss: 134.17
train mean loss: 132.12
epoch train time: 0:00:01.427917
elapsed time: 0:05:03.770033
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:40:28.813087
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.30
 ---- batch: 020 ----
mean loss: 128.59
 ---- batch: 030 ----
mean loss: 132.48
train mean loss: 133.03
epoch train time: 0:00:01.434907
elapsed time: 0:05:05.205119
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:40:30.248173
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.64
 ---- batch: 020 ----
mean loss: 133.86
 ---- batch: 030 ----
mean loss: 133.91
train mean loss: 133.79
epoch train time: 0:00:01.430705
elapsed time: 0:05:06.636798
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:40:31.679862
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.02
 ---- batch: 020 ----
mean loss: 133.07
 ---- batch: 030 ----
mean loss: 131.10
train mean loss: 132.61
epoch train time: 0:00:01.432872
elapsed time: 0:05:08.069845
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:40:33.112901
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.66
 ---- batch: 020 ----
mean loss: 130.42
 ---- batch: 030 ----
mean loss: 134.33
train mean loss: 133.92
epoch train time: 0:00:01.430196
elapsed time: 0:05:09.500237
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:40:34.543337
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.80
 ---- batch: 020 ----
mean loss: 128.92
 ---- batch: 030 ----
mean loss: 128.57
train mean loss: 132.51
epoch train time: 0:00:01.440100
elapsed time: 0:05:10.940582
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:40:35.983641
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.90
 ---- batch: 020 ----
mean loss: 134.43
 ---- batch: 030 ----
mean loss: 131.76
train mean loss: 132.97
epoch train time: 0:00:01.427894
elapsed time: 0:05:12.368690
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:40:37.411799
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.00
 ---- batch: 020 ----
mean loss: 132.07
 ---- batch: 030 ----
mean loss: 134.42
train mean loss: 133.60
epoch train time: 0:00:01.432902
elapsed time: 0:05:13.801806
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:40:38.844861
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.57
 ---- batch: 020 ----
mean loss: 134.53
 ---- batch: 030 ----
mean loss: 130.60
train mean loss: 134.43
epoch train time: 0:00:01.435074
elapsed time: 0:05:15.237096
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:40:40.280166
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.57
 ---- batch: 020 ----
mean loss: 135.22
 ---- batch: 030 ----
mean loss: 135.43
train mean loss: 133.22
epoch train time: 0:00:01.433797
elapsed time: 0:05:16.671072
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:40:41.714129
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.97
 ---- batch: 020 ----
mean loss: 133.48
 ---- batch: 030 ----
mean loss: 134.48
train mean loss: 133.49
epoch train time: 0:00:01.430236
elapsed time: 0:05:18.101480
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:40:43.144540
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.15
 ---- batch: 020 ----
mean loss: 137.17
 ---- batch: 030 ----
mean loss: 132.12
train mean loss: 135.26
epoch train time: 0:00:01.425907
elapsed time: 0:05:19.527548
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:40:44.570618
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.31
 ---- batch: 020 ----
mean loss: 129.51
 ---- batch: 030 ----
mean loss: 136.33
train mean loss: 132.87
epoch train time: 0:00:01.431427
elapsed time: 0:05:20.959167
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:40:46.002227
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.07
 ---- batch: 020 ----
mean loss: 131.30
 ---- batch: 030 ----
mean loss: 131.82
train mean loss: 131.32
epoch train time: 0:00:01.433302
elapsed time: 0:05:22.392666
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:40:47.435728
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.66
 ---- batch: 020 ----
mean loss: 133.68
 ---- batch: 030 ----
mean loss: 135.28
train mean loss: 134.69
epoch train time: 0:00:01.431494
elapsed time: 0:05:23.824338
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:40:48.867393
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.84
 ---- batch: 020 ----
mean loss: 136.49
 ---- batch: 030 ----
mean loss: 132.58
train mean loss: 134.31
epoch train time: 0:00:01.433803
elapsed time: 0:05:25.258302
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:40:50.301357
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.25
 ---- batch: 020 ----
mean loss: 131.43
 ---- batch: 030 ----
mean loss: 142.55
train mean loss: 135.32
epoch train time: 0:00:01.432790
elapsed time: 0:05:26.691260
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:40:51.734318
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.41
 ---- batch: 020 ----
mean loss: 136.17
 ---- batch: 030 ----
mean loss: 135.02
train mean loss: 133.64
epoch train time: 0:00:01.434208
elapsed time: 0:05:28.125626
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:40:53.168684
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.45
 ---- batch: 020 ----
mean loss: 134.95
 ---- batch: 030 ----
mean loss: 132.04
train mean loss: 134.06
epoch train time: 0:00:01.432871
elapsed time: 0:05:29.558681
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:40:54.601762
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.82
 ---- batch: 020 ----
mean loss: 135.51
 ---- batch: 030 ----
mean loss: 128.55
train mean loss: 132.77
epoch train time: 0:00:01.434676
elapsed time: 0:05:30.993547
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:40:56.036605
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.47
 ---- batch: 020 ----
mean loss: 130.34
 ---- batch: 030 ----
mean loss: 135.71
train mean loss: 133.31
epoch train time: 0:00:01.430191
elapsed time: 0:05:32.423901
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:40:57.466956
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.38
 ---- batch: 020 ----
mean loss: 130.63
 ---- batch: 030 ----
mean loss: 132.59
train mean loss: 133.26
epoch train time: 0:00:01.430146
elapsed time: 0:05:33.854208
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:40:58.897266
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.15
 ---- batch: 020 ----
mean loss: 139.07
 ---- batch: 030 ----
mean loss: 134.62
train mean loss: 135.24
epoch train time: 0:00:01.426488
elapsed time: 0:05:35.280852
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:41:00.323945
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.12
 ---- batch: 020 ----
mean loss: 134.88
 ---- batch: 030 ----
mean loss: 131.44
train mean loss: 132.53
epoch train time: 0:00:01.430513
elapsed time: 0:05:36.711566
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:41:01.754624
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.39
 ---- batch: 020 ----
mean loss: 136.02
 ---- batch: 030 ----
mean loss: 132.55
train mean loss: 134.15
epoch train time: 0:00:01.432163
elapsed time: 0:05:38.143923
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:41:03.186983
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.69
 ---- batch: 020 ----
mean loss: 135.01
 ---- batch: 030 ----
mean loss: 131.92
train mean loss: 132.65
epoch train time: 0:00:01.430234
elapsed time: 0:05:39.574326
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:41:04.617382
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.45
 ---- batch: 020 ----
mean loss: 130.20
 ---- batch: 030 ----
mean loss: 131.87
train mean loss: 133.54
epoch train time: 0:00:01.432911
elapsed time: 0:05:41.007412
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:41:06.050468
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.91
 ---- batch: 020 ----
mean loss: 136.12
 ---- batch: 030 ----
mean loss: 130.29
train mean loss: 131.78
epoch train time: 0:00:01.428429
elapsed time: 0:05:42.435996
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:41:07.479051
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.17
 ---- batch: 020 ----
mean loss: 131.39
 ---- batch: 030 ----
mean loss: 128.54
train mean loss: 131.66
epoch train time: 0:00:01.431673
elapsed time: 0:05:43.867826
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:41:08.910883
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.15
 ---- batch: 020 ----
mean loss: 133.55
 ---- batch: 030 ----
mean loss: 128.82
train mean loss: 132.59
epoch train time: 0:00:01.430751
elapsed time: 0:05:45.298729
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:41:10.341782
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.29
 ---- batch: 020 ----
mean loss: 132.66
 ---- batch: 030 ----
mean loss: 131.05
train mean loss: 133.43
epoch train time: 0:00:01.433095
elapsed time: 0:05:46.732009
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:41:11.775053
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.99
 ---- batch: 020 ----
mean loss: 130.40
 ---- batch: 030 ----
mean loss: 130.82
train mean loss: 132.67
epoch train time: 0:00:01.429950
elapsed time: 0:05:48.162107
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:41:13.205182
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.52
 ---- batch: 020 ----
mean loss: 131.92
 ---- batch: 030 ----
mean loss: 132.52
train mean loss: 132.38
epoch train time: 0:00:01.430566
elapsed time: 0:05:49.592851
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:41:14.635910
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.71
 ---- batch: 020 ----
mean loss: 131.46
 ---- batch: 030 ----
mean loss: 132.05
train mean loss: 132.64
epoch train time: 0:00:01.435336
elapsed time: 0:05:51.028351
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:41:16.071427
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.18
 ---- batch: 020 ----
mean loss: 137.22
 ---- batch: 030 ----
mean loss: 133.16
train mean loss: 134.16
epoch train time: 0:00:01.427456
elapsed time: 0:05:52.455987
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:41:17.499050
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.28
 ---- batch: 020 ----
mean loss: 131.17
 ---- batch: 030 ----
mean loss: 134.24
train mean loss: 133.09
epoch train time: 0:00:01.430700
elapsed time: 0:05:53.886862
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:41:18.929921
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.65
 ---- batch: 020 ----
mean loss: 131.14
 ---- batch: 030 ----
mean loss: 129.48
train mean loss: 131.26
epoch train time: 0:00:01.429516
elapsed time: 0:05:55.316539
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:41:20.359595
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.56
 ---- batch: 020 ----
mean loss: 133.65
 ---- batch: 030 ----
mean loss: 132.00
train mean loss: 132.48
epoch train time: 0:00:01.429535
elapsed time: 0:05:56.746232
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:41:21.789288
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.60
 ---- batch: 020 ----
mean loss: 129.85
 ---- batch: 030 ----
mean loss: 134.52
train mean loss: 133.13
epoch train time: 0:00:01.432762
elapsed time: 0:05:58.179173
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:41:23.222232
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.48
 ---- batch: 020 ----
mean loss: 136.31
 ---- batch: 030 ----
mean loss: 132.43
train mean loss: 133.39
epoch train time: 0:00:01.429091
elapsed time: 0:05:59.608427
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:41:24.651499
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.36
 ---- batch: 020 ----
mean loss: 132.57
 ---- batch: 030 ----
mean loss: 132.11
train mean loss: 131.44
epoch train time: 0:00:01.430988
elapsed time: 0:06:01.039603
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:41:26.082666
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.14
 ---- batch: 020 ----
mean loss: 130.38
 ---- batch: 030 ----
mean loss: 129.94
train mean loss: 132.22
epoch train time: 0:00:01.432765
elapsed time: 0:06:02.472534
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:41:27.515590
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.51
 ---- batch: 020 ----
mean loss: 133.95
 ---- batch: 030 ----
mean loss: 133.00
train mean loss: 132.26
epoch train time: 0:00:01.430700
elapsed time: 0:06:03.903410
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:41:28.946479
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.92
 ---- batch: 020 ----
mean loss: 131.84
 ---- batch: 030 ----
mean loss: 132.01
train mean loss: 132.68
epoch train time: 0:00:01.426370
elapsed time: 0:06:05.329958
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:41:30.373020
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.94
 ---- batch: 020 ----
mean loss: 132.54
 ---- batch: 030 ----
mean loss: 131.68
train mean loss: 133.00
epoch train time: 0:00:01.435267
elapsed time: 0:06:06.765391
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:41:31.808489
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.94
 ---- batch: 020 ----
mean loss: 134.63
 ---- batch: 030 ----
mean loss: 130.44
train mean loss: 132.03
epoch train time: 0:00:01.428471
elapsed time: 0:06:08.194068
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:41:33.237145
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.25
 ---- batch: 020 ----
mean loss: 135.24
 ---- batch: 030 ----
mean loss: 136.76
train mean loss: 133.99
epoch train time: 0:00:01.432605
elapsed time: 0:06:09.630169
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_0/checkpoint.pth.tar
**** end time: 2019-09-27 15:41:34.673189 ****
