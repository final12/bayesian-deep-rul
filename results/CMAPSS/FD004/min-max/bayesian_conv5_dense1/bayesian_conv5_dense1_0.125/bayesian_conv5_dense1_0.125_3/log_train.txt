Namespace(batch_size=512, dataset='CMAPSS/FD004', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD004/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_3', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.125, resume=False, step_size=200, visualize_step=50)
pid: 11241
use_cuda: True
Dataset: CMAPSS/FD004
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-26 19:23:56.869516 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 16, 24]             200
           Sigmoid-2           [-1, 10, 16, 24]               0
    BayesianConv2d-3           [-1, 10, 15, 24]           2,000
           Sigmoid-4           [-1, 10, 15, 24]               0
    BayesianConv2d-5           [-1, 10, 16, 24]           2,000
           Sigmoid-6           [-1, 10, 16, 24]               0
    BayesianConv2d-7           [-1, 10, 15, 24]           2,000
           Sigmoid-8           [-1, 10, 15, 24]               0
    BayesianConv2d-9            [-1, 1, 15, 24]              60
         Softplus-10            [-1, 1, 15, 24]               0
          Flatten-11                  [-1, 360]               0
   BayesianLinear-12                  [-1, 100]          72,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 78,460
Trainable params: 78,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-26 19:23:56.887377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2883.65
train mean loss: 2547.02
epoch train time: 0:00:05.826283
elapsed time: 0:00:05.851902
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-26 19:24:02.721460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1614.62
train mean loss: 1546.31
epoch train time: 0:00:01.990505
elapsed time: 0:00:07.842997
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-26 19:24:04.712688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1376.21
train mean loss: 1329.48
epoch train time: 0:00:02.002575
elapsed time: 0:00:09.846422
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-26 19:24:06.716111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1213.23
train mean loss: 1201.20
epoch train time: 0:00:02.001354
elapsed time: 0:00:11.848551
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-26 19:24:08.718235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1175.15
train mean loss: 1178.22
epoch train time: 0:00:02.006439
elapsed time: 0:00:13.855735
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-26 19:24:10.725408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1111.55
train mean loss: 1157.85
epoch train time: 0:00:02.006022
elapsed time: 0:00:15.862463
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-26 19:24:12.732120
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1104.07
train mean loss: 1098.70
epoch train time: 0:00:02.005604
elapsed time: 0:00:17.868766
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-26 19:24:14.738448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1076.62
train mean loss: 1060.00
epoch train time: 0:00:02.006189
elapsed time: 0:00:19.875643
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-26 19:24:16.745324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1039.63
train mean loss: 1035.58
epoch train time: 0:00:02.023003
elapsed time: 0:00:21.899372
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-26 19:24:18.769044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1015.07
train mean loss: 1017.09
epoch train time: 0:00:02.004249
elapsed time: 0:00:23.904314
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-26 19:24:20.773983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1040.25
train mean loss: 1037.65
epoch train time: 0:00:02.008064
elapsed time: 0:00:25.913194
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-26 19:24:22.782895
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1002.52
train mean loss: 1008.70
epoch train time: 0:00:02.007005
elapsed time: 0:00:27.920965
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-26 19:24:24.790612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1001.72
train mean loss: 1009.78
epoch train time: 0:00:01.998167
elapsed time: 0:00:29.920020
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-26 19:24:26.789765
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 998.98
train mean loss: 987.96
epoch train time: 0:00:02.002164
elapsed time: 0:00:31.922978
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-26 19:24:28.792662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 993.26
train mean loss: 1012.75
epoch train time: 0:00:02.007195
elapsed time: 0:00:33.930962
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-26 19:24:30.800701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 984.73
train mean loss: 1002.02
epoch train time: 0:00:02.004193
elapsed time: 0:00:35.935961
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-26 19:24:32.805653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1000.24
train mean loss: 1004.79
epoch train time: 0:00:01.996040
elapsed time: 0:00:37.932780
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-26 19:24:34.802448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 990.17
train mean loss: 986.15
epoch train time: 0:00:01.988438
elapsed time: 0:00:39.921878
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-26 19:24:36.791538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 991.86
train mean loss: 977.36
epoch train time: 0:00:01.992299
elapsed time: 0:00:41.914856
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-26 19:24:38.784536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 993.08
train mean loss: 985.23
epoch train time: 0:00:01.999990
elapsed time: 0:00:43.915561
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-26 19:24:40.785215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 967.50
train mean loss: 964.31
epoch train time: 0:00:02.004791
elapsed time: 0:00:45.921037
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-26 19:24:42.790702
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 965.44
train mean loss: 969.14
epoch train time: 0:00:02.006842
elapsed time: 0:00:47.928640
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-26 19:24:44.798301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 997.03
train mean loss: 975.27
epoch train time: 0:00:01.996265
elapsed time: 0:00:49.925645
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-26 19:24:46.795326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 968.93
train mean loss: 998.31
epoch train time: 0:00:01.993205
elapsed time: 0:00:51.919528
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-26 19:24:48.789188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 975.08
train mean loss: 954.43
epoch train time: 0:00:01.988307
elapsed time: 0:00:53.908534
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-26 19:24:50.778191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 960.70
train mean loss: 965.07
epoch train time: 0:00:02.005349
elapsed time: 0:00:55.914597
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-26 19:24:52.784275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 958.50
train mean loss: 968.49
epoch train time: 0:00:02.010732
elapsed time: 0:00:57.926017
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-26 19:24:54.795690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 953.75
train mean loss: 943.38
epoch train time: 0:00:02.002713
elapsed time: 0:00:59.929428
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-26 19:24:56.799083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 965.40
train mean loss: 961.96
epoch train time: 0:00:02.003455
elapsed time: 0:01:01.933692
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-26 19:24:58.803418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 965.39
train mean loss: 976.87
epoch train time: 0:00:02.009916
elapsed time: 0:01:03.944396
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-26 19:25:00.814051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 962.99
train mean loss: 960.48
epoch train time: 0:00:02.012551
elapsed time: 0:01:05.957629
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-26 19:25:02.827316
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 949.12
train mean loss: 954.51
epoch train time: 0:00:02.008492
elapsed time: 0:01:07.966816
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-26 19:25:04.836512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 947.73
train mean loss: 950.16
epoch train time: 0:00:02.006551
elapsed time: 0:01:09.974148
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-26 19:25:06.843822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 966.56
train mean loss: 954.18
epoch train time: 0:00:02.000515
elapsed time: 0:01:11.975433
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-26 19:25:08.845096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 965.56
train mean loss: 958.40
epoch train time: 0:00:01.999857
elapsed time: 0:01:13.975995
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-26 19:25:10.845668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 976.50
train mean loss: 960.21
epoch train time: 0:00:02.002710
elapsed time: 0:01:15.979451
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-26 19:25:12.849121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 938.33
train mean loss: 951.89
epoch train time: 0:00:02.007982
elapsed time: 0:01:17.988123
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-26 19:25:14.857781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 953.39
train mean loss: 954.88
epoch train time: 0:00:02.013153
elapsed time: 0:01:20.001935
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-26 19:25:16.871580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 939.36
train mean loss: 926.45
epoch train time: 0:00:02.013218
elapsed time: 0:01:22.015812
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-26 19:25:18.885480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 932.60
train mean loss: 934.55
epoch train time: 0:00:02.007885
elapsed time: 0:01:24.024392
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-26 19:25:20.894052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 956.35
train mean loss: 960.64
epoch train time: 0:00:01.999859
elapsed time: 0:01:26.024916
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-26 19:25:22.894581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.14
train mean loss: 941.37
epoch train time: 0:00:02.005129
elapsed time: 0:01:28.030782
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-26 19:25:24.900454
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 957.02
train mean loss: 940.81
epoch train time: 0:00:01.993256
elapsed time: 0:01:30.024762
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-26 19:25:26.894411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.22
train mean loss: 957.12
epoch train time: 0:00:02.003060
elapsed time: 0:01:32.028597
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-26 19:25:28.898254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 938.34
train mean loss: 942.48
epoch train time: 0:00:02.002749
elapsed time: 0:01:34.032012
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-26 19:25:30.901696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 932.82
train mean loss: 948.51
epoch train time: 0:00:02.002236
elapsed time: 0:01:36.034971
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-26 19:25:32.904664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 933.68
train mean loss: 925.07
epoch train time: 0:00:01.990764
elapsed time: 0:01:38.026454
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-26 19:25:34.896105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.41
train mean loss: 920.75
epoch train time: 0:00:02.008117
elapsed time: 0:01:40.035343
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-26 19:25:36.905041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.73
train mean loss: 952.91
epoch train time: 0:00:01.994646
elapsed time: 0:01:42.030815
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-26 19:25:38.900474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 933.98
train mean loss: 920.72
epoch train time: 0:00:02.003456
elapsed time: 0:01:44.035114
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-26 19:25:40.904764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 930.26
train mean loss: 940.36
epoch train time: 0:00:02.010703
elapsed time: 0:01:46.046581
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-26 19:25:42.916247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 951.28
train mean loss: 967.58
epoch train time: 0:00:02.005228
elapsed time: 0:01:48.052510
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-26 19:25:44.922159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 931.30
train mean loss: 935.81
epoch train time: 0:00:02.001347
elapsed time: 0:01:50.054603
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-26 19:25:46.924271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 927.72
train mean loss: 917.57
epoch train time: 0:00:02.002996
elapsed time: 0:01:52.058268
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-26 19:25:48.927916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 944.66
train mean loss: 932.29
epoch train time: 0:00:02.005002
elapsed time: 0:01:54.064019
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-26 19:25:50.933717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.85
train mean loss: 927.31
epoch train time: 0:00:02.013042
elapsed time: 0:01:56.077753
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-26 19:25:52.947431
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 912.52
train mean loss: 920.64
epoch train time: 0:00:02.000083
elapsed time: 0:01:58.078581
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-26 19:25:54.948275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 907.86
train mean loss: 924.33
epoch train time: 0:00:02.001130
elapsed time: 0:02:00.080506
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-26 19:25:56.950162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 918.93
train mean loss: 913.78
epoch train time: 0:00:02.001584
elapsed time: 0:02:02.082839
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-26 19:25:58.952489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 921.44
train mean loss: 936.02
epoch train time: 0:00:02.014700
elapsed time: 0:02:04.098195
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-26 19:26:00.967856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 917.40
train mean loss: 909.33
epoch train time: 0:00:02.006199
elapsed time: 0:02:06.105100
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-26 19:26:02.974763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 903.60
train mean loss: 922.35
epoch train time: 0:00:01.998704
elapsed time: 0:02:08.104560
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-26 19:26:04.974227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.06
train mean loss: 928.47
epoch train time: 0:00:02.009874
elapsed time: 0:02:10.115125
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-26 19:26:06.984779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 902.01
train mean loss: 908.84
epoch train time: 0:00:02.005392
elapsed time: 0:02:12.121231
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-26 19:26:08.990913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 918.15
train mean loss: 920.43
epoch train time: 0:00:01.997779
elapsed time: 0:02:14.119700
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-26 19:26:10.989372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 924.83
train mean loss: 929.55
epoch train time: 0:00:02.001690
elapsed time: 0:02:16.122190
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-26 19:26:12.991865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 914.63
train mean loss: 906.03
epoch train time: 0:00:02.009116
elapsed time: 0:02:18.132058
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-26 19:26:15.001733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 919.83
train mean loss: 914.40
epoch train time: 0:00:02.006235
elapsed time: 0:02:20.139006
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-26 19:26:17.008676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 900.68
train mean loss: 911.23
epoch train time: 0:00:02.001299
elapsed time: 0:02:22.140990
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-26 19:26:19.010649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 909.67
train mean loss: 942.09
epoch train time: 0:00:02.005636
elapsed time: 0:02:24.147309
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-26 19:26:21.016962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 895.63
train mean loss: 916.01
epoch train time: 0:00:02.001266
elapsed time: 0:02:26.149233
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-26 19:26:23.018887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 914.22
train mean loss: 906.18
epoch train time: 0:00:02.000807
elapsed time: 0:02:28.150677
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-26 19:26:25.020367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 902.87
train mean loss: 903.78
epoch train time: 0:00:02.003071
elapsed time: 0:02:30.154457
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-26 19:26:27.024121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 902.55
train mean loss: 904.39
epoch train time: 0:00:02.004777
elapsed time: 0:02:32.159903
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-26 19:26:29.029555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.49
train mean loss: 903.89
epoch train time: 0:00:02.012359
elapsed time: 0:02:34.172981
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-26 19:26:31.042664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 919.42
train mean loss: 914.10
epoch train time: 0:00:02.006299
elapsed time: 0:02:36.179975
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-26 19:26:33.049641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 900.67
train mean loss: 908.09
epoch train time: 0:00:02.000382
elapsed time: 0:02:38.181063
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-26 19:26:35.050730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 903.46
train mean loss: 915.42
epoch train time: 0:00:01.990495
elapsed time: 0:02:40.172242
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-26 19:26:37.041908
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 899.96
train mean loss: 904.56
epoch train time: 0:00:01.996508
elapsed time: 0:02:42.169411
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-26 19:26:39.039076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 886.72
train mean loss: 910.95
epoch train time: 0:00:02.013649
elapsed time: 0:02:44.183750
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-26 19:26:41.053391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 910.06
train mean loss: 897.66
epoch train time: 0:00:01.986485
elapsed time: 0:02:46.170932
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-26 19:26:43.040605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.33
train mean loss: 890.09
epoch train time: 0:00:01.998409
elapsed time: 0:02:48.170023
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-26 19:26:45.039679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 899.61
train mean loss: 901.34
epoch train time: 0:00:01.996982
elapsed time: 0:02:50.167661
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-26 19:26:47.037321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 899.96
train mean loss: 881.75
epoch train time: 0:00:01.986668
elapsed time: 0:02:52.155009
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-26 19:26:49.024703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 883.74
train mean loss: 895.55
epoch train time: 0:00:01.991620
elapsed time: 0:02:54.147374
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-26 19:26:51.017046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 878.23
train mean loss: 880.39
epoch train time: 0:00:01.994066
elapsed time: 0:02:56.142175
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-26 19:26:53.011839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.43
train mean loss: 902.42
epoch train time: 0:00:01.993545
elapsed time: 0:02:58.136383
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-26 19:26:55.006034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 899.05
train mean loss: 898.25
epoch train time: 0:00:01.998434
elapsed time: 0:03:00.135605
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-26 19:26:57.005271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 895.45
train mean loss: 875.75
epoch train time: 0:00:01.993034
elapsed time: 0:03:02.129378
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-26 19:26:58.999038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 889.83
train mean loss: 881.93
epoch train time: 0:00:01.998211
elapsed time: 0:03:04.128309
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-26 19:27:00.997980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 893.73
train mean loss: 881.84
epoch train time: 0:00:02.010716
elapsed time: 0:03:06.139778
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-26 19:27:03.009466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 905.81
train mean loss: 889.48
epoch train time: 0:00:02.013576
elapsed time: 0:03:08.154077
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-26 19:27:05.023724
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 897.03
train mean loss: 888.22
epoch train time: 0:00:02.010621
elapsed time: 0:03:10.165432
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-26 19:27:07.035085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 882.80
train mean loss: 883.57
epoch train time: 0:00:02.005895
elapsed time: 0:03:12.171997
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-26 19:27:09.041676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 885.72
train mean loss: 891.34
epoch train time: 0:00:02.029376
elapsed time: 0:03:14.202198
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-26 19:27:11.071849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.55
train mean loss: 892.97
epoch train time: 0:00:02.041940
elapsed time: 0:03:16.244791
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-26 19:27:13.114452
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 895.69
train mean loss: 893.07
epoch train time: 0:00:02.018758
elapsed time: 0:03:18.264245
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-26 19:27:15.133913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 889.61
train mean loss: 886.04
epoch train time: 0:00:02.017127
elapsed time: 0:03:20.282041
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-26 19:27:17.151713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 879.35
train mean loss: 884.01
epoch train time: 0:00:02.014749
elapsed time: 0:03:22.297480
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-26 19:27:19.167141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 888.63
train mean loss: 902.30
epoch train time: 0:00:02.012985
elapsed time: 0:03:24.311243
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-26 19:27:21.180923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 879.58
train mean loss: 873.86
epoch train time: 0:00:02.010455
elapsed time: 0:03:26.322379
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-26 19:27:23.192055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 865.71
train mean loss: 879.15
epoch train time: 0:00:02.010132
elapsed time: 0:03:28.333321
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-26 19:27:25.202978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 867.85
train mean loss: 880.10
epoch train time: 0:00:02.020960
elapsed time: 0:03:30.354980
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-26 19:27:27.224690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 869.57
train mean loss: 870.90
epoch train time: 0:00:02.014955
elapsed time: 0:03:32.370620
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-26 19:27:29.240270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 863.79
train mean loss: 869.64
epoch train time: 0:00:02.003328
elapsed time: 0:03:34.374594
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-26 19:27:31.244259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.96
train mean loss: 884.83
epoch train time: 0:00:02.001628
elapsed time: 0:03:36.376964
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-26 19:27:33.246619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 876.34
train mean loss: 859.58
epoch train time: 0:00:02.001289
elapsed time: 0:03:38.379078
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-26 19:27:35.248658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 869.46
train mean loss: 846.06
epoch train time: 0:00:01.995193
elapsed time: 0:03:40.374874
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-26 19:27:37.244542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 838.68
train mean loss: 843.12
epoch train time: 0:00:02.008830
elapsed time: 0:03:42.384396
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-26 19:27:39.254057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 839.86
train mean loss: 827.08
epoch train time: 0:00:02.013682
elapsed time: 0:03:44.398801
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-26 19:27:41.268478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 826.14
train mean loss: 825.43
epoch train time: 0:00:02.013937
elapsed time: 0:03:46.413484
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-26 19:27:43.283137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 823.94
train mean loss: 831.07
epoch train time: 0:00:02.002918
elapsed time: 0:03:48.417108
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-26 19:27:45.286792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 828.12
train mean loss: 804.17
epoch train time: 0:00:02.000143
elapsed time: 0:03:50.417973
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-26 19:27:47.287657
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 801.85
train mean loss: 794.37
epoch train time: 0:00:02.001273
elapsed time: 0:03:52.419994
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-26 19:27:49.289672
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 786.99
train mean loss: 799.75
epoch train time: 0:00:02.003771
elapsed time: 0:03:54.424506
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-26 19:27:51.294165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 779.52
train mean loss: 781.23
epoch train time: 0:00:02.008723
elapsed time: 0:03:56.433973
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-26 19:27:53.303624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 774.68
train mean loss: 789.02
epoch train time: 0:00:02.000930
elapsed time: 0:03:58.435546
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-26 19:27:55.305217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 783.52
train mean loss: 775.30
epoch train time: 0:00:02.017140
elapsed time: 0:04:00.453448
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-26 19:27:57.323113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 763.43
train mean loss: 757.41
epoch train time: 0:00:02.005381
elapsed time: 0:04:02.459505
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-26 19:27:59.329159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 773.12
train mean loss: 767.47
epoch train time: 0:00:02.013280
elapsed time: 0:04:04.473540
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-26 19:28:01.343245
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 755.25
train mean loss: 753.77
epoch train time: 0:00:02.004670
elapsed time: 0:04:06.478993
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-26 19:28:03.348685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 730.76
train mean loss: 731.42
epoch train time: 0:00:02.009540
elapsed time: 0:04:08.489210
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-26 19:28:05.358860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 740.34
train mean loss: 748.82
epoch train time: 0:00:02.005658
elapsed time: 0:04:10.495527
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-26 19:28:07.365183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 739.18
train mean loss: 745.30
epoch train time: 0:00:01.999189
elapsed time: 0:04:12.495433
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-26 19:28:09.365131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 724.46
train mean loss: 723.83
epoch train time: 0:00:01.996037
elapsed time: 0:04:14.492206
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-26 19:28:11.361863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 728.59
train mean loss: 731.82
epoch train time: 0:00:02.018779
elapsed time: 0:04:16.511673
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-26 19:28:13.381324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 722.92
train mean loss: 714.24
epoch train time: 0:00:02.030333
elapsed time: 0:04:18.542885
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-26 19:28:15.412481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 702.38
train mean loss: 715.62
epoch train time: 0:00:02.034642
elapsed time: 0:04:20.578132
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-26 19:28:17.447799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 708.08
train mean loss: 714.73
epoch train time: 0:00:02.030845
elapsed time: 0:04:22.609714
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-26 19:28:19.479399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 714.80
train mean loss: 710.41
epoch train time: 0:00:02.033966
elapsed time: 0:04:24.644411
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-26 19:28:21.514076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 712.50
train mean loss: 719.06
epoch train time: 0:00:02.006582
elapsed time: 0:04:26.651757
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-26 19:28:23.521438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 704.24
train mean loss: 699.79
epoch train time: 0:00:01.998420
elapsed time: 0:04:28.650935
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-26 19:28:25.520590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 678.99
train mean loss: 697.91
epoch train time: 0:00:02.001528
elapsed time: 0:04:30.653223
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-26 19:28:27.522892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 706.10
train mean loss: 697.34
epoch train time: 0:00:02.005229
elapsed time: 0:04:32.659166
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-26 19:28:29.528834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 687.85
train mean loss: 694.17
epoch train time: 0:00:02.005302
elapsed time: 0:04:34.665201
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-26 19:28:31.534883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 679.00
train mean loss: 686.26
epoch train time: 0:00:02.003368
elapsed time: 0:04:36.669296
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-26 19:28:33.538946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 681.75
train mean loss: 684.52
epoch train time: 0:00:02.001178
elapsed time: 0:04:38.671170
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-26 19:28:35.540855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 679.87
train mean loss: 676.41
epoch train time: 0:00:02.005359
elapsed time: 0:04:40.677273
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-26 19:28:37.546920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 670.79
train mean loss: 655.11
epoch train time: 0:00:01.999008
elapsed time: 0:04:42.677014
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-26 19:28:39.546665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 655.57
train mean loss: 652.70
epoch train time: 0:00:01.999148
elapsed time: 0:04:44.676799
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-26 19:28:41.546522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 652.78
train mean loss: 654.24
epoch train time: 0:00:01.994492
elapsed time: 0:04:46.672020
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-26 19:28:43.541704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 657.85
train mean loss: 645.04
epoch train time: 0:00:02.003566
elapsed time: 0:04:48.676355
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-26 19:28:45.545998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 637.72
train mean loss: 645.43
epoch train time: 0:00:02.010950
elapsed time: 0:04:50.687959
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-26 19:28:47.557628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 628.88
train mean loss: 625.80
epoch train time: 0:00:02.001220
elapsed time: 0:04:52.689873
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-26 19:28:49.559531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 648.90
train mean loss: 638.02
epoch train time: 0:00:02.008356
elapsed time: 0:04:54.698913
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-26 19:28:51.568570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 642.77
train mean loss: 632.67
epoch train time: 0:00:02.012418
elapsed time: 0:04:56.712107
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-26 19:28:53.581779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 615.54
train mean loss: 626.19
epoch train time: 0:00:02.006029
elapsed time: 0:04:58.718935
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-26 19:28:55.588642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 630.06
train mean loss: 621.35
epoch train time: 0:00:02.010164
elapsed time: 0:05:00.729831
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-26 19:28:57.599511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 626.33
train mean loss: 625.15
epoch train time: 0:00:02.009013
elapsed time: 0:05:02.739635
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-26 19:28:59.609200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 605.39
train mean loss: 601.81
epoch train time: 0:00:02.012526
elapsed time: 0:05:04.752740
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-26 19:29:01.622396
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 598.82
train mean loss: 595.13
epoch train time: 0:00:02.003094
elapsed time: 0:05:06.756575
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-26 19:29:03.626238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 605.78
train mean loss: 600.02
epoch train time: 0:00:02.005926
elapsed time: 0:05:08.763272
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-26 19:29:05.632963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 610.36
train mean loss: 597.48
epoch train time: 0:00:02.000221
elapsed time: 0:05:10.764218
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-26 19:29:07.633875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 588.24
train mean loss: 590.34
epoch train time: 0:00:02.007189
elapsed time: 0:05:12.772053
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-26 19:29:09.641741
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 585.76
train mean loss: 581.73
epoch train time: 0:00:02.001356
elapsed time: 0:05:14.774184
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-26 19:29:11.643854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 596.19
train mean loss: 598.33
epoch train time: 0:00:02.000458
elapsed time: 0:05:16.775327
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-26 19:29:13.644986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 589.90
train mean loss: 595.98
epoch train time: 0:00:02.024893
elapsed time: 0:05:18.800997
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-26 19:29:15.670706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 580.10
train mean loss: 574.04
epoch train time: 0:00:02.002513
elapsed time: 0:05:20.804275
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-26 19:29:17.673950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 559.11
train mean loss: 560.30
epoch train time: 0:00:02.004998
elapsed time: 0:05:22.809977
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-26 19:29:19.679626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 569.09
train mean loss: 573.30
epoch train time: 0:00:02.019000
elapsed time: 0:05:24.829632
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-26 19:29:21.699286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 570.43
train mean loss: 576.59
epoch train time: 0:00:01.968329
elapsed time: 0:05:26.798644
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-26 19:29:23.668306
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 573.69
train mean loss: 567.84
epoch train time: 0:00:02.029093
elapsed time: 0:05:28.828496
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-26 19:29:25.698156
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 547.89
train mean loss: 561.21
epoch train time: 0:00:01.982565
elapsed time: 0:05:30.811755
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-26 19:29:27.681423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.39
train mean loss: 548.62
epoch train time: 0:00:01.963808
elapsed time: 0:05:32.776275
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-26 19:29:29.645936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 548.95
train mean loss: 545.83
epoch train time: 0:00:01.979812
elapsed time: 0:05:34.756810
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-26 19:29:31.626480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 546.78
train mean loss: 552.63
epoch train time: 0:00:01.961571
elapsed time: 0:05:36.719058
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-26 19:29:33.588705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.68
train mean loss: 546.25
epoch train time: 0:00:01.964437
elapsed time: 0:05:38.684180
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-26 19:29:35.553839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 544.52
train mean loss: 527.45
epoch train time: 0:00:01.981527
elapsed time: 0:05:40.666411
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-26 19:29:37.536075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 545.07
train mean loss: 540.78
epoch train time: 0:00:01.973609
elapsed time: 0:05:42.640701
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-26 19:29:39.510354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 538.48
train mean loss: 535.63
epoch train time: 0:00:01.974187
elapsed time: 0:05:44.615545
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-26 19:29:41.485200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 528.83
train mean loss: 529.23
epoch train time: 0:00:02.012683
elapsed time: 0:05:46.628977
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-26 19:29:43.498735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 524.90
train mean loss: 525.09
epoch train time: 0:00:02.016626
elapsed time: 0:05:48.646493
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-26 19:29:45.516159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 519.21
train mean loss: 522.75
epoch train time: 0:00:02.033534
elapsed time: 0:05:50.680696
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-26 19:29:47.550366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 524.01
train mean loss: 529.60
epoch train time: 0:00:01.983325
elapsed time: 0:05:52.664829
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-26 19:29:49.534398
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 520.54
train mean loss: 521.69
epoch train time: 0:00:01.958802
elapsed time: 0:05:54.624285
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-26 19:29:51.493955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 524.08
train mean loss: 519.91
epoch train time: 0:00:01.964418
elapsed time: 0:05:56.589381
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-26 19:29:53.459050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 514.67
train mean loss: 508.79
epoch train time: 0:00:01.970313
elapsed time: 0:05:58.560407
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-26 19:29:55.430068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 515.27
train mean loss: 505.90
epoch train time: 0:00:01.979367
elapsed time: 0:06:00.540491
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-26 19:29:57.410148
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 500.51
train mean loss: 503.66
epoch train time: 0:00:01.983339
elapsed time: 0:06:02.524513
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-26 19:29:59.394168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 510.32
train mean loss: 501.92
epoch train time: 0:00:01.983633
elapsed time: 0:06:04.508821
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-26 19:30:01.378485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 525.64
train mean loss: 513.20
epoch train time: 0:00:01.965422
elapsed time: 0:06:06.474917
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-26 19:30:03.344571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 515.55
train mean loss: 507.04
epoch train time: 0:00:01.981614
elapsed time: 0:06:08.457216
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-26 19:30:05.326873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 496.84
train mean loss: 502.39
epoch train time: 0:00:01.988522
elapsed time: 0:06:10.446434
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-26 19:30:07.316135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 499.84
train mean loss: 502.04
epoch train time: 0:00:02.008069
elapsed time: 0:06:12.455294
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-26 19:30:09.324947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 484.86
train mean loss: 479.77
epoch train time: 0:00:02.023995
elapsed time: 0:06:14.479936
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-26 19:30:11.349581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 492.44
train mean loss: 491.57
epoch train time: 0:00:02.015427
elapsed time: 0:06:16.496033
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-26 19:30:13.365715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 491.06
train mean loss: 492.99
epoch train time: 0:00:02.005669
elapsed time: 0:06:18.502417
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-26 19:30:15.372086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 477.72
train mean loss: 501.68
epoch train time: 0:00:02.006785
elapsed time: 0:06:20.509895
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-26 19:30:17.379544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 488.29
train mean loss: 481.64
epoch train time: 0:00:01.999286
elapsed time: 0:06:22.509862
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-26 19:30:19.379530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 478.08
train mean loss: 471.50
epoch train time: 0:00:02.010468
elapsed time: 0:06:24.521041
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-26 19:30:21.390708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.67
train mean loss: 475.30
epoch train time: 0:00:02.042442
elapsed time: 0:06:26.564380
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-26 19:30:23.434040
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 482.40
train mean loss: 466.35
epoch train time: 0:00:02.027472
elapsed time: 0:06:28.592552
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-26 19:30:25.462205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 479.90
train mean loss: 466.14
epoch train time: 0:00:02.035980
elapsed time: 0:06:30.629222
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-26 19:30:27.498965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 463.12
train mean loss: 449.80
epoch train time: 0:00:02.041767
elapsed time: 0:06:32.671762
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-26 19:30:29.541494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 465.42
train mean loss: 466.49
epoch train time: 0:00:02.025794
elapsed time: 0:06:34.698330
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-26 19:30:31.567997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 457.05
train mean loss: 467.14
epoch train time: 0:00:02.008942
elapsed time: 0:06:36.707946
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-26 19:30:33.577620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 458.58
train mean loss: 456.15
epoch train time: 0:00:02.004414
elapsed time: 0:06:38.713142
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-26 19:30:35.582796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 462.25
train mean loss: 452.67
epoch train time: 0:00:02.006262
elapsed time: 0:06:40.720068
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-26 19:30:37.589772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 453.83
train mean loss: 453.45
epoch train time: 0:00:02.007336
elapsed time: 0:06:42.728137
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-26 19:30:39.597799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 452.47
train mean loss: 449.53
epoch train time: 0:00:02.047633
elapsed time: 0:06:44.776473
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-26 19:30:41.646133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 455.42
train mean loss: 451.77
epoch train time: 0:00:02.019056
elapsed time: 0:06:46.796208
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-26 19:30:43.665874
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 448.75
train mean loss: 447.31
epoch train time: 0:00:02.005983
elapsed time: 0:06:48.802994
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-26 19:30:45.672558
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 445.11
train mean loss: 442.78
epoch train time: 0:00:02.015507
elapsed time: 0:06:50.819116
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-26 19:30:47.688786
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 442.33
train mean loss: 444.63
epoch train time: 0:00:02.000611
elapsed time: 0:06:52.820486
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-26 19:30:49.690147
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.95
train mean loss: 445.81
epoch train time: 0:00:01.995044
elapsed time: 0:06:54.816237
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-26 19:30:51.685893
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 439.01
train mean loss: 431.02
epoch train time: 0:00:02.008718
elapsed time: 0:06:56.825717
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-26 19:30:53.695371
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 437.85
train mean loss: 435.12
epoch train time: 0:00:01.985053
elapsed time: 0:06:58.811470
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-26 19:30:55.681132
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.57
train mean loss: 438.33
epoch train time: 0:00:01.995220
elapsed time: 0:07:00.807379
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-26 19:30:57.677052
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 455.82
train mean loss: 437.36
epoch train time: 0:00:02.001404
elapsed time: 0:07:02.809488
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-26 19:30:59.679144
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 430.96
train mean loss: 446.86
epoch train time: 0:00:02.014897
elapsed time: 0:07:04.825061
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-26 19:31:01.694746
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 441.18
train mean loss: 451.41
epoch train time: 0:00:02.020087
elapsed time: 0:07:06.845899
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-26 19:31:03.715559
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 442.53
train mean loss: 440.53
epoch train time: 0:00:02.022431
elapsed time: 0:07:08.869014
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-26 19:31:05.738676
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 449.69
train mean loss: 439.42
epoch train time: 0:00:02.003853
elapsed time: 0:07:10.873572
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-26 19:31:07.743236
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.66
train mean loss: 439.67
epoch train time: 0:00:02.018115
elapsed time: 0:07:12.892367
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-26 19:31:09.762031
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 437.21
train mean loss: 438.55
epoch train time: 0:00:02.014322
elapsed time: 0:07:14.907383
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-26 19:31:11.777046
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.91
train mean loss: 434.62
epoch train time: 0:00:02.002573
elapsed time: 0:07:16.910634
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-26 19:31:13.780288
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 445.28
train mean loss: 440.04
epoch train time: 0:00:01.995133
elapsed time: 0:07:18.906572
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-26 19:31:15.776252
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.41
train mean loss: 442.44
epoch train time: 0:00:02.051823
elapsed time: 0:07:20.959138
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-26 19:31:17.828810
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 445.30
train mean loss: 441.32
epoch train time: 0:00:02.038410
elapsed time: 0:07:22.998233
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-26 19:31:19.867890
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 447.45
train mean loss: 439.09
epoch train time: 0:00:02.032188
elapsed time: 0:07:25.031128
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-26 19:31:21.900778
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.02
train mean loss: 441.16
epoch train time: 0:00:02.033027
elapsed time: 0:07:27.064844
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-26 19:31:23.934510
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.50
train mean loss: 433.50
epoch train time: 0:00:02.031027
elapsed time: 0:07:29.096572
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-26 19:31:25.966223
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.96
train mean loss: 445.56
epoch train time: 0:00:02.027354
elapsed time: 0:07:31.124725
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-26 19:31:27.994415
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 442.64
train mean loss: 442.91
epoch train time: 0:00:02.043777
elapsed time: 0:07:33.169211
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-26 19:31:30.038862
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 441.57
train mean loss: 445.00
epoch train time: 0:00:02.032815
elapsed time: 0:07:35.202821
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-26 19:31:32.072523
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 432.88
train mean loss: 437.08
epoch train time: 0:00:02.026565
elapsed time: 0:07:37.230093
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-26 19:31:34.099748
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 433.14
train mean loss: 423.55
epoch train time: 0:00:02.019570
elapsed time: 0:07:39.250337
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-26 19:31:36.120001
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.86
train mean loss: 438.15
epoch train time: 0:00:02.019837
elapsed time: 0:07:41.270972
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-26 19:31:38.140623
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 430.91
train mean loss: 431.30
epoch train time: 0:00:02.025412
elapsed time: 0:07:43.297055
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-26 19:31:40.166722
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 423.46
train mean loss: 429.18
epoch train time: 0:00:02.034417
elapsed time: 0:07:45.332164
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-26 19:31:42.201820
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.12
train mean loss: 441.63
epoch train time: 0:00:02.025641
elapsed time: 0:07:47.358486
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-26 19:31:44.228159
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 439.29
train mean loss: 436.84
epoch train time: 0:00:02.032040
elapsed time: 0:07:49.391263
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-26 19:31:46.260950
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 437.41
train mean loss: 436.39
epoch train time: 0:00:02.030380
elapsed time: 0:07:51.422390
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-26 19:31:48.292052
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 436.01
train mean loss: 430.07
epoch train time: 0:00:02.035909
elapsed time: 0:07:53.459196
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-26 19:31:50.328764
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 422.47
train mean loss: 437.75
epoch train time: 0:00:02.055018
elapsed time: 0:07:55.514859
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-26 19:31:52.384531
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.20
train mean loss: 429.16
epoch train time: 0:00:02.041245
elapsed time: 0:07:57.556796
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-26 19:31:54.426460
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 431.71
train mean loss: 423.81
epoch train time: 0:00:02.023181
elapsed time: 0:07:59.580738
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-26 19:31:56.450404
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 432.61
train mean loss: 431.66
epoch train time: 0:00:02.027797
elapsed time: 0:08:01.609266
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-26 19:31:58.478930
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 438.57
train mean loss: 438.42
epoch train time: 0:00:02.042125
elapsed time: 0:08:03.652123
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-26 19:32:00.521784
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 421.26
train mean loss: 420.19
epoch train time: 0:00:02.027810
elapsed time: 0:08:05.680718
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-26 19:32:02.550400
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.65
train mean loss: 439.30
epoch train time: 0:00:02.013839
elapsed time: 0:08:07.695231
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-26 19:32:04.564890
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 434.67
train mean loss: 452.58
epoch train time: 0:00:02.020502
elapsed time: 0:08:09.716455
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-26 19:32:06.586123
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 435.63
train mean loss: 429.18
epoch train time: 0:00:02.020411
elapsed time: 0:08:11.737574
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-26 19:32:08.607236
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 427.35
train mean loss: 425.99
epoch train time: 0:00:01.997599
elapsed time: 0:08:13.735924
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-26 19:32:10.605588
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 428.97
train mean loss: 431.06
epoch train time: 0:00:02.006912
elapsed time: 0:08:15.743627
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-26 19:32:12.613325
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 433.44
train mean loss: 444.01
epoch train time: 0:00:02.019871
elapsed time: 0:08:17.764246
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-26 19:32:14.633912
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 425.14
train mean loss: 429.32
epoch train time: 0:00:02.047458
elapsed time: 0:08:19.812441
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-26 19:32:16.682096
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 431.77
train mean loss: 431.17
epoch train time: 0:00:02.028899
elapsed time: 0:08:21.842164
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-26 19:32:18.711816
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 424.44
train mean loss: 427.36
epoch train time: 0:00:02.050106
elapsed time: 0:08:23.892957
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-26 19:32:20.762615
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 430.22
train mean loss: 425.92
epoch train time: 0:00:02.008261
elapsed time: 0:08:25.911325
checkpoint saved in file: log/CMAPSS/FD004/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_3/checkpoint.pth.tar
**** end time: 2019-09-26 19:32:22.780863 ****
