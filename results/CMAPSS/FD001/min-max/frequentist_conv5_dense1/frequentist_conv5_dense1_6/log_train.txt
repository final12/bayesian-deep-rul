Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_6', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30972
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 16:14:00.418192 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:14:00.426034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3688.22
 ---- batch: 020 ----
mean loss: 1439.40
 ---- batch: 030 ----
mean loss: 672.35
train mean loss: 1743.51
epoch train time: 0:00:12.865174
elapsed time: 0:00:12.875682
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:14:13.293914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 459.40
 ---- batch: 020 ----
mean loss: 403.92
 ---- batch: 030 ----
mean loss: 363.11
train mean loss: 403.37
epoch train time: 0:00:01.497784
elapsed time: 0:00:14.373613
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:14:14.791870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 346.53
 ---- batch: 020 ----
mean loss: 344.36
 ---- batch: 030 ----
mean loss: 334.63
train mean loss: 340.60
epoch train time: 0:00:01.434363
elapsed time: 0:00:15.808192
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:14:16.226449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 318.84
 ---- batch: 020 ----
mean loss: 310.77
 ---- batch: 030 ----
mean loss: 298.96
train mean loss: 309.53
epoch train time: 0:00:01.433874
elapsed time: 0:00:17.242266
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:14:17.660519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.72
 ---- batch: 020 ----
mean loss: 275.68
 ---- batch: 030 ----
mean loss: 263.95
train mean loss: 271.10
epoch train time: 0:00:01.428705
elapsed time: 0:00:18.671135
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:14:19.089382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.51
 ---- batch: 020 ----
mean loss: 247.66
 ---- batch: 030 ----
mean loss: 244.73
train mean loss: 243.44
epoch train time: 0:00:01.440274
elapsed time: 0:00:20.111610
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:14:20.529857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.63
 ---- batch: 020 ----
mean loss: 229.23
 ---- batch: 030 ----
mean loss: 223.54
train mean loss: 227.88
epoch train time: 0:00:01.429186
elapsed time: 0:00:21.540957
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:14:21.959217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.63
 ---- batch: 020 ----
mean loss: 218.04
 ---- batch: 030 ----
mean loss: 218.77
train mean loss: 220.73
epoch train time: 0:00:01.430356
elapsed time: 0:00:22.971527
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:14:23.389767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.14
 ---- batch: 020 ----
mean loss: 212.29
 ---- batch: 030 ----
mean loss: 221.44
train mean loss: 217.79
epoch train time: 0:00:01.434220
elapsed time: 0:00:24.405925
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:14:24.824214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.15
 ---- batch: 020 ----
mean loss: 214.67
 ---- batch: 030 ----
mean loss: 208.14
train mean loss: 210.67
epoch train time: 0:00:01.437750
elapsed time: 0:00:25.843901
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:14:26.262167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.95
 ---- batch: 020 ----
mean loss: 202.66
 ---- batch: 030 ----
mean loss: 209.15
train mean loss: 207.91
epoch train time: 0:00:01.436183
elapsed time: 0:00:27.280263
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:14:27.698526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.59
 ---- batch: 020 ----
mean loss: 206.28
 ---- batch: 030 ----
mean loss: 202.27
train mean loss: 201.47
epoch train time: 0:00:01.435648
elapsed time: 0:00:28.716104
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:14:29.134361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 200.50
 ---- batch: 020 ----
mean loss: 204.21
 ---- batch: 030 ----
mean loss: 194.27
train mean loss: 201.20
epoch train time: 0:00:01.438265
elapsed time: 0:00:30.154549
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:14:30.572796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.45
 ---- batch: 020 ----
mean loss: 209.93
 ---- batch: 030 ----
mean loss: 216.45
train mean loss: 207.15
epoch train time: 0:00:01.438369
elapsed time: 0:00:31.593076
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:14:32.011323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.11
 ---- batch: 020 ----
mean loss: 196.38
 ---- batch: 030 ----
mean loss: 199.59
train mean loss: 199.42
epoch train time: 0:00:01.434829
elapsed time: 0:00:33.028060
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:14:33.446307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.48
 ---- batch: 020 ----
mean loss: 188.85
 ---- batch: 030 ----
mean loss: 192.59
train mean loss: 190.24
epoch train time: 0:00:01.436920
elapsed time: 0:00:34.465156
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:14:34.883424
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.01
 ---- batch: 020 ----
mean loss: 192.20
 ---- batch: 030 ----
mean loss: 196.83
train mean loss: 193.77
epoch train time: 0:00:01.435605
elapsed time: 0:00:35.900980
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:14:36.319217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.32
 ---- batch: 020 ----
mean loss: 195.74
 ---- batch: 030 ----
mean loss: 197.20
train mean loss: 198.05
epoch train time: 0:00:01.433564
elapsed time: 0:00:37.334762
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:14:37.753024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.71
 ---- batch: 020 ----
mean loss: 199.54
 ---- batch: 030 ----
mean loss: 194.08
train mean loss: 194.45
epoch train time: 0:00:01.432250
elapsed time: 0:00:38.767256
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:14:39.185502
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.48
 ---- batch: 020 ----
mean loss: 196.55
 ---- batch: 030 ----
mean loss: 194.03
train mean loss: 192.53
epoch train time: 0:00:01.430395
elapsed time: 0:00:40.197817
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:14:40.616066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.53
 ---- batch: 020 ----
mean loss: 186.74
 ---- batch: 030 ----
mean loss: 183.91
train mean loss: 186.74
epoch train time: 0:00:01.432790
elapsed time: 0:00:41.630820
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:14:42.049067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.81
 ---- batch: 020 ----
mean loss: 187.59
 ---- batch: 030 ----
mean loss: 184.98
train mean loss: 186.92
epoch train time: 0:00:01.438943
elapsed time: 0:00:43.069938
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:14:43.488227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.64
 ---- batch: 020 ----
mean loss: 190.65
 ---- batch: 030 ----
mean loss: 180.86
train mean loss: 184.36
epoch train time: 0:00:01.438148
elapsed time: 0:00:44.508314
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:14:44.926577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.44
 ---- batch: 020 ----
mean loss: 191.26
 ---- batch: 030 ----
mean loss: 186.20
train mean loss: 186.69
epoch train time: 0:00:01.438610
elapsed time: 0:00:45.947117
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:14:46.365366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.13
 ---- batch: 020 ----
mean loss: 184.68
 ---- batch: 030 ----
mean loss: 184.92
train mean loss: 184.65
epoch train time: 0:00:01.436513
elapsed time: 0:00:47.383849
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:14:47.802098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.94
 ---- batch: 020 ----
mean loss: 176.14
 ---- batch: 030 ----
mean loss: 184.16
train mean loss: 180.35
epoch train time: 0:00:01.438871
elapsed time: 0:00:48.822887
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:14:49.241135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.91
 ---- batch: 020 ----
mean loss: 174.10
 ---- batch: 030 ----
mean loss: 183.32
train mean loss: 179.89
epoch train time: 0:00:01.430677
elapsed time: 0:00:50.253756
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:14:50.672002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.38
 ---- batch: 020 ----
mean loss: 177.43
 ---- batch: 030 ----
mean loss: 182.16
train mean loss: 179.26
epoch train time: 0:00:01.435442
elapsed time: 0:00:51.689356
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:14:52.107601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.91
 ---- batch: 020 ----
mean loss: 172.66
 ---- batch: 030 ----
mean loss: 180.36
train mean loss: 178.52
epoch train time: 0:00:01.433257
elapsed time: 0:00:53.122786
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:14:53.541034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.79
 ---- batch: 020 ----
mean loss: 176.51
 ---- batch: 030 ----
mean loss: 172.75
train mean loss: 176.42
epoch train time: 0:00:01.430204
elapsed time: 0:00:54.553156
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:14:54.971422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.66
 ---- batch: 020 ----
mean loss: 179.34
 ---- batch: 030 ----
mean loss: 176.53
train mean loss: 176.47
epoch train time: 0:00:01.429657
elapsed time: 0:00:55.983010
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:14:56.401258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.55
 ---- batch: 020 ----
mean loss: 173.95
 ---- batch: 030 ----
mean loss: 184.05
train mean loss: 178.41
epoch train time: 0:00:01.436724
elapsed time: 0:00:57.419938
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:14:57.838202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.74
 ---- batch: 020 ----
mean loss: 171.77
 ---- batch: 030 ----
mean loss: 174.51
train mean loss: 173.79
epoch train time: 0:00:01.441218
elapsed time: 0:00:58.861371
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:14:59.279619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.20
 ---- batch: 020 ----
mean loss: 165.62
 ---- batch: 030 ----
mean loss: 176.45
train mean loss: 169.36
epoch train time: 0:00:01.432518
elapsed time: 0:01:00.294051
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:15:00.712326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.24
 ---- batch: 020 ----
mean loss: 169.70
 ---- batch: 030 ----
mean loss: 170.06
train mean loss: 169.06
epoch train time: 0:00:01.434836
elapsed time: 0:01:01.729098
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:15:02.147347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.19
 ---- batch: 020 ----
mean loss: 171.84
 ---- batch: 030 ----
mean loss: 168.70
train mean loss: 171.27
epoch train time: 0:00:01.435223
elapsed time: 0:01:03.164486
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:15:03.582749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.14
 ---- batch: 020 ----
mean loss: 184.40
 ---- batch: 030 ----
mean loss: 170.82
train mean loss: 175.03
epoch train time: 0:00:01.432607
elapsed time: 0:01:04.597273
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:15:05.015554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.82
 ---- batch: 020 ----
mean loss: 169.97
 ---- batch: 030 ----
mean loss: 170.05
train mean loss: 169.74
epoch train time: 0:00:01.434730
elapsed time: 0:01:06.032212
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:15:06.450469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.46
 ---- batch: 020 ----
mean loss: 163.97
 ---- batch: 030 ----
mean loss: 183.52
train mean loss: 171.22
epoch train time: 0:00:01.430928
elapsed time: 0:01:07.463341
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:15:07.881623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.37
 ---- batch: 020 ----
mean loss: 164.81
 ---- batch: 030 ----
mean loss: 170.63
train mean loss: 168.28
epoch train time: 0:00:01.433144
elapsed time: 0:01:08.896677
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:15:09.314924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.61
 ---- batch: 020 ----
mean loss: 162.78
 ---- batch: 030 ----
mean loss: 164.84
train mean loss: 165.21
epoch train time: 0:00:01.427926
elapsed time: 0:01:10.324779
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:15:10.743029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.62
 ---- batch: 020 ----
mean loss: 166.03
 ---- batch: 030 ----
mean loss: 169.86
train mean loss: 166.23
epoch train time: 0:00:01.438721
elapsed time: 0:01:11.763748
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:15:12.181998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.71
 ---- batch: 020 ----
mean loss: 162.68
 ---- batch: 030 ----
mean loss: 163.92
train mean loss: 162.33
epoch train time: 0:00:01.435065
elapsed time: 0:01:13.198973
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:15:13.617217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.71
 ---- batch: 020 ----
mean loss: 166.70
 ---- batch: 030 ----
mean loss: 168.69
train mean loss: 165.68
epoch train time: 0:00:01.432471
elapsed time: 0:01:14.631632
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:15:15.049884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.41
 ---- batch: 020 ----
mean loss: 161.72
 ---- batch: 030 ----
mean loss: 158.78
train mean loss: 162.04
epoch train time: 0:00:01.434653
elapsed time: 0:01:16.066477
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:15:16.484724
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.05
 ---- batch: 020 ----
mean loss: 166.40
 ---- batch: 030 ----
mean loss: 163.42
train mean loss: 161.74
epoch train time: 0:00:01.434802
elapsed time: 0:01:17.501449
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:15:17.919696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.89
 ---- batch: 020 ----
mean loss: 161.75
 ---- batch: 030 ----
mean loss: 156.83
train mean loss: 158.95
epoch train time: 0:00:01.432275
elapsed time: 0:01:18.933885
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:15:19.352129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.87
 ---- batch: 020 ----
mean loss: 168.81
 ---- batch: 030 ----
mean loss: 168.64
train mean loss: 166.27
epoch train time: 0:00:01.430938
elapsed time: 0:01:20.364976
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:15:20.783224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.96
 ---- batch: 020 ----
mean loss: 159.65
 ---- batch: 030 ----
mean loss: 163.20
train mean loss: 161.17
epoch train time: 0:00:01.433035
elapsed time: 0:01:21.798194
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:15:22.216478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.11
 ---- batch: 020 ----
mean loss: 151.74
 ---- batch: 030 ----
mean loss: 155.85
train mean loss: 155.22
epoch train time: 0:00:01.436248
elapsed time: 0:01:23.234702
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:15:23.652968
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.95
 ---- batch: 020 ----
mean loss: 161.21
 ---- batch: 030 ----
mean loss: 171.16
train mean loss: 164.41
epoch train time: 0:00:01.437683
elapsed time: 0:01:24.672588
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:15:25.090877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.78
 ---- batch: 020 ----
mean loss: 153.54
 ---- batch: 030 ----
mean loss: 155.76
train mean loss: 154.59
epoch train time: 0:00:01.435046
elapsed time: 0:01:26.107864
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:15:26.526113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.02
 ---- batch: 020 ----
mean loss: 156.78
 ---- batch: 030 ----
mean loss: 160.45
train mean loss: 156.28
epoch train time: 0:00:01.436553
elapsed time: 0:01:27.544600
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:15:27.962846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.66
 ---- batch: 020 ----
mean loss: 154.61
 ---- batch: 030 ----
mean loss: 160.79
train mean loss: 157.89
epoch train time: 0:00:01.440106
elapsed time: 0:01:28.984876
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:15:29.403125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.15
 ---- batch: 020 ----
mean loss: 160.40
 ---- batch: 030 ----
mean loss: 160.47
train mean loss: 158.22
epoch train time: 0:00:01.441267
elapsed time: 0:01:30.426338
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:15:30.844593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.05
 ---- batch: 020 ----
mean loss: 155.81
 ---- batch: 030 ----
mean loss: 153.10
train mean loss: 154.12
epoch train time: 0:00:01.435924
elapsed time: 0:01:31.862459
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:15:32.280710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.27
 ---- batch: 020 ----
mean loss: 152.74
 ---- batch: 030 ----
mean loss: 153.78
train mean loss: 154.45
epoch train time: 0:00:01.430089
elapsed time: 0:01:33.292750
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:15:33.710999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.22
 ---- batch: 020 ----
mean loss: 154.45
 ---- batch: 030 ----
mean loss: 148.91
train mean loss: 153.79
epoch train time: 0:00:01.434736
elapsed time: 0:01:34.727667
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:15:35.145922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.54
 ---- batch: 020 ----
mean loss: 153.67
 ---- batch: 030 ----
mean loss: 155.22
train mean loss: 152.34
epoch train time: 0:00:01.433943
elapsed time: 0:01:36.161792
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:15:36.580066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.03
 ---- batch: 020 ----
mean loss: 157.23
 ---- batch: 030 ----
mean loss: 157.95
train mean loss: 159.88
epoch train time: 0:00:01.436615
elapsed time: 0:01:37.598602
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:15:38.016849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.25
 ---- batch: 020 ----
mean loss: 152.72
 ---- batch: 030 ----
mean loss: 154.52
train mean loss: 153.76
epoch train time: 0:00:01.435436
elapsed time: 0:01:39.034226
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:15:39.452472
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.43
 ---- batch: 020 ----
mean loss: 154.55
 ---- batch: 030 ----
mean loss: 157.29
train mean loss: 155.79
epoch train time: 0:00:01.438716
elapsed time: 0:01:40.473114
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:15:40.891366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.16
 ---- batch: 020 ----
mean loss: 153.13
 ---- batch: 030 ----
mean loss: 152.76
train mean loss: 153.93
epoch train time: 0:00:01.432914
elapsed time: 0:01:41.906226
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:15:42.324473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.81
 ---- batch: 020 ----
mean loss: 168.84
 ---- batch: 030 ----
mean loss: 164.39
train mean loss: 162.92
epoch train time: 0:00:01.432528
elapsed time: 0:01:43.338951
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:15:43.757220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.73
 ---- batch: 020 ----
mean loss: 154.57
 ---- batch: 030 ----
mean loss: 152.73
train mean loss: 154.50
epoch train time: 0:00:01.428790
elapsed time: 0:01:44.767947
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:15:45.186194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.29
 ---- batch: 020 ----
mean loss: 154.78
 ---- batch: 030 ----
mean loss: 151.95
train mean loss: 153.43
epoch train time: 0:00:01.435455
elapsed time: 0:01:46.203585
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:15:46.621835
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.37
 ---- batch: 020 ----
mean loss: 155.38
 ---- batch: 030 ----
mean loss: 154.86
train mean loss: 154.10
epoch train time: 0:00:01.435616
elapsed time: 0:01:47.639393
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:15:48.057664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.49
 ---- batch: 020 ----
mean loss: 151.23
 ---- batch: 030 ----
mean loss: 145.49
train mean loss: 147.82
epoch train time: 0:00:01.435458
elapsed time: 0:01:49.075049
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:15:49.493295
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.01
 ---- batch: 020 ----
mean loss: 148.82
 ---- batch: 030 ----
mean loss: 148.86
train mean loss: 150.02
epoch train time: 0:00:01.432508
elapsed time: 0:01:50.507743
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:15:50.925992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.78
 ---- batch: 020 ----
mean loss: 145.46
 ---- batch: 030 ----
mean loss: 152.83
train mean loss: 150.32
epoch train time: 0:00:01.436227
elapsed time: 0:01:51.944145
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:15:52.362394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.90
 ---- batch: 020 ----
mean loss: 150.56
 ---- batch: 030 ----
mean loss: 148.68
train mean loss: 150.07
epoch train time: 0:00:01.429486
elapsed time: 0:01:53.373821
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:15:53.792098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.73
 ---- batch: 020 ----
mean loss: 152.19
 ---- batch: 030 ----
mean loss: 155.56
train mean loss: 152.84
epoch train time: 0:00:01.428334
elapsed time: 0:01:54.802367
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:15:55.220614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.36
 ---- batch: 020 ----
mean loss: 147.59
 ---- batch: 030 ----
mean loss: 153.57
train mean loss: 150.12
epoch train time: 0:00:01.440214
elapsed time: 0:01:56.242768
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:15:56.661032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.32
 ---- batch: 020 ----
mean loss: 154.24
 ---- batch: 030 ----
mean loss: 148.40
train mean loss: 149.93
epoch train time: 0:00:01.433128
elapsed time: 0:01:57.676075
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:15:58.094320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.61
 ---- batch: 020 ----
mean loss: 153.73
 ---- batch: 030 ----
mean loss: 152.70
train mean loss: 153.13
epoch train time: 0:00:01.428524
elapsed time: 0:01:59.104789
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:15:59.523038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.89
 ---- batch: 020 ----
mean loss: 147.55
 ---- batch: 030 ----
mean loss: 144.27
train mean loss: 148.66
epoch train time: 0:00:01.427456
elapsed time: 0:02:00.532433
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:16:00.950680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.06
 ---- batch: 020 ----
mean loss: 153.55
 ---- batch: 030 ----
mean loss: 150.35
train mean loss: 153.09
epoch train time: 0:00:01.435052
elapsed time: 0:02:01.967672
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:16:02.385980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.16
 ---- batch: 020 ----
mean loss: 149.73
 ---- batch: 030 ----
mean loss: 154.17
train mean loss: 150.54
epoch train time: 0:00:01.430172
elapsed time: 0:02:03.398110
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:16:03.816361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.78
 ---- batch: 020 ----
mean loss: 144.49
 ---- batch: 030 ----
mean loss: 143.73
train mean loss: 146.89
epoch train time: 0:00:01.433312
elapsed time: 0:02:04.831598
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:16:05.249860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.18
 ---- batch: 020 ----
mean loss: 149.26
 ---- batch: 030 ----
mean loss: 151.39
train mean loss: 148.81
epoch train time: 0:00:01.434322
elapsed time: 0:02:06.266114
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:16:06.684365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.24
 ---- batch: 020 ----
mean loss: 149.38
 ---- batch: 030 ----
mean loss: 146.58
train mean loss: 147.71
epoch train time: 0:00:01.442480
elapsed time: 0:02:07.708772
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:16:08.127023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.46
 ---- batch: 020 ----
mean loss: 146.13
 ---- batch: 030 ----
mean loss: 145.75
train mean loss: 146.47
epoch train time: 0:00:01.431872
elapsed time: 0:02:09.140806
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:16:09.559095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.09
 ---- batch: 020 ----
mean loss: 145.14
 ---- batch: 030 ----
mean loss: 151.33
train mean loss: 148.29
epoch train time: 0:00:01.429223
elapsed time: 0:02:10.570230
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:16:10.988476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.53
 ---- batch: 020 ----
mean loss: 150.73
 ---- batch: 030 ----
mean loss: 154.20
train mean loss: 150.83
epoch train time: 0:00:01.434483
elapsed time: 0:02:12.004896
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:16:12.423150
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.34
 ---- batch: 020 ----
mean loss: 151.46
 ---- batch: 030 ----
mean loss: 146.22
train mean loss: 148.80
epoch train time: 0:00:01.436068
elapsed time: 0:02:13.441128
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:16:13.859374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.38
 ---- batch: 020 ----
mean loss: 148.57
 ---- batch: 030 ----
mean loss: 145.77
train mean loss: 147.24
epoch train time: 0:00:01.429868
elapsed time: 0:02:14.871189
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:16:15.289482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.22
 ---- batch: 020 ----
mean loss: 145.72
 ---- batch: 030 ----
mean loss: 146.74
train mean loss: 145.78
epoch train time: 0:00:01.452848
elapsed time: 0:02:16.324286
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:16:16.742536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.81
 ---- batch: 020 ----
mean loss: 148.35
 ---- batch: 030 ----
mean loss: 141.49
train mean loss: 147.33
epoch train time: 0:00:01.429505
elapsed time: 0:02:17.753966
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:16:18.172217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.67
 ---- batch: 020 ----
mean loss: 143.16
 ---- batch: 030 ----
mean loss: 147.47
train mean loss: 148.18
epoch train time: 0:00:01.428905
elapsed time: 0:02:19.183053
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:16:19.601303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.12
 ---- batch: 020 ----
mean loss: 145.73
 ---- batch: 030 ----
mean loss: 146.96
train mean loss: 148.30
epoch train time: 0:00:01.432151
elapsed time: 0:02:20.615374
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:16:21.033641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.77
 ---- batch: 020 ----
mean loss: 147.19
 ---- batch: 030 ----
mean loss: 145.81
train mean loss: 146.00
epoch train time: 0:00:01.435338
elapsed time: 0:02:22.050901
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:16:22.469163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.55
 ---- batch: 020 ----
mean loss: 152.69
 ---- batch: 030 ----
mean loss: 156.12
train mean loss: 149.23
epoch train time: 0:00:01.439725
elapsed time: 0:02:23.490819
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:16:23.909069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.00
 ---- batch: 020 ----
mean loss: 148.17
 ---- batch: 030 ----
mean loss: 146.31
train mean loss: 147.52
epoch train time: 0:00:01.438009
elapsed time: 0:02:24.929016
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:16:25.347266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.43
 ---- batch: 020 ----
mean loss: 143.71
 ---- batch: 030 ----
mean loss: 149.26
train mean loss: 146.54
epoch train time: 0:00:01.437677
elapsed time: 0:02:26.366865
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:16:26.785118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.67
 ---- batch: 020 ----
mean loss: 154.16
 ---- batch: 030 ----
mean loss: 158.95
train mean loss: 153.55
epoch train time: 0:00:01.436533
elapsed time: 0:02:27.803564
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:16:28.221812
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.42
 ---- batch: 020 ----
mean loss: 142.89
 ---- batch: 030 ----
mean loss: 151.43
train mean loss: 146.59
epoch train time: 0:00:01.432886
elapsed time: 0:02:29.236636
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:16:29.654899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.89
 ---- batch: 020 ----
mean loss: 145.71
 ---- batch: 030 ----
mean loss: 144.07
train mean loss: 144.84
epoch train time: 0:00:01.429307
elapsed time: 0:02:30.666123
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:16:31.084378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.84
 ---- batch: 020 ----
mean loss: 144.05
 ---- batch: 030 ----
mean loss: 144.98
train mean loss: 145.99
epoch train time: 0:00:01.436391
elapsed time: 0:02:32.102693
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:16:32.520941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.57
 ---- batch: 020 ----
mean loss: 150.77
 ---- batch: 030 ----
mean loss: 153.66
train mean loss: 151.40
epoch train time: 0:00:01.434179
elapsed time: 0:02:33.537089
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:16:33.955339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.43
 ---- batch: 020 ----
mean loss: 152.14
 ---- batch: 030 ----
mean loss: 150.07
train mean loss: 155.02
epoch train time: 0:00:01.436712
elapsed time: 0:02:34.973978
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:16:35.392226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.09
 ---- batch: 020 ----
mean loss: 146.86
 ---- batch: 030 ----
mean loss: 144.29
train mean loss: 146.52
epoch train time: 0:00:01.438862
elapsed time: 0:02:36.413051
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:16:36.831302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.69
 ---- batch: 020 ----
mean loss: 144.07
 ---- batch: 030 ----
mean loss: 151.27
train mean loss: 148.25
epoch train time: 0:00:01.443337
elapsed time: 0:02:37.856633
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:16:38.274880
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.71
 ---- batch: 020 ----
mean loss: 146.39
 ---- batch: 030 ----
mean loss: 141.84
train mean loss: 149.04
epoch train time: 0:00:01.444212
elapsed time: 0:02:39.301045
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:16:39.719336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.51
 ---- batch: 020 ----
mean loss: 143.17
 ---- batch: 030 ----
mean loss: 140.82
train mean loss: 145.33
epoch train time: 0:00:01.442372
elapsed time: 0:02:40.743637
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:16:41.161899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.42
 ---- batch: 020 ----
mean loss: 146.58
 ---- batch: 030 ----
mean loss: 143.47
train mean loss: 146.08
epoch train time: 0:00:01.439350
elapsed time: 0:02:42.183178
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:16:42.601450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.03
 ---- batch: 020 ----
mean loss: 150.07
 ---- batch: 030 ----
mean loss: 159.94
train mean loss: 152.09
epoch train time: 0:00:01.435497
elapsed time: 0:02:43.618874
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:16:44.037124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.86
 ---- batch: 020 ----
mean loss: 143.73
 ---- batch: 030 ----
mean loss: 144.47
train mean loss: 146.27
epoch train time: 0:00:01.445526
elapsed time: 0:02:45.064597
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:16:45.482832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.52
 ---- batch: 020 ----
mean loss: 143.03
 ---- batch: 030 ----
mean loss: 143.77
train mean loss: 144.19
epoch train time: 0:00:01.441101
elapsed time: 0:02:46.505873
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:16:46.924123
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.92
 ---- batch: 020 ----
mean loss: 144.22
 ---- batch: 030 ----
mean loss: 147.89
train mean loss: 146.10
epoch train time: 0:00:01.444175
elapsed time: 0:02:47.950243
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:16:48.368492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.57
 ---- batch: 020 ----
mean loss: 144.09
 ---- batch: 030 ----
mean loss: 142.98
train mean loss: 144.46
epoch train time: 0:00:01.439311
elapsed time: 0:02:49.389728
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:16:49.807987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.11
 ---- batch: 020 ----
mean loss: 145.25
 ---- batch: 030 ----
mean loss: 144.70
train mean loss: 144.48
epoch train time: 0:00:01.439195
elapsed time: 0:02:50.829104
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:16:51.247351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.50
 ---- batch: 020 ----
mean loss: 140.84
 ---- batch: 030 ----
mean loss: 146.63
train mean loss: 146.76
epoch train time: 0:00:01.432766
elapsed time: 0:02:52.262023
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:16:52.680266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.32
 ---- batch: 020 ----
mean loss: 146.88
 ---- batch: 030 ----
mean loss: 146.66
train mean loss: 147.15
epoch train time: 0:00:01.431884
elapsed time: 0:02:53.694059
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:16:54.112303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.12
 ---- batch: 020 ----
mean loss: 142.12
 ---- batch: 030 ----
mean loss: 143.34
train mean loss: 142.30
epoch train time: 0:00:01.430204
elapsed time: 0:02:55.124435
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:16:55.542683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.42
 ---- batch: 020 ----
mean loss: 150.39
 ---- batch: 030 ----
mean loss: 146.48
train mean loss: 147.35
epoch train time: 0:00:01.436574
elapsed time: 0:02:56.561175
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:16:56.979433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.69
 ---- batch: 020 ----
mean loss: 146.02
 ---- batch: 030 ----
mean loss: 148.83
train mean loss: 145.85
epoch train time: 0:00:01.435358
elapsed time: 0:02:57.996703
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:16:58.414950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.34
 ---- batch: 020 ----
mean loss: 148.05
 ---- batch: 030 ----
mean loss: 148.21
train mean loss: 147.89
epoch train time: 0:00:01.430093
elapsed time: 0:02:59.426960
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:16:59.845209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.38
 ---- batch: 020 ----
mean loss: 142.94
 ---- batch: 030 ----
mean loss: 143.04
train mean loss: 143.51
epoch train time: 0:00:01.437201
elapsed time: 0:03:00.864330
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:17:01.282594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.67
 ---- batch: 020 ----
mean loss: 145.61
 ---- batch: 030 ----
mean loss: 147.14
train mean loss: 145.48
epoch train time: 0:00:01.437738
elapsed time: 0:03:02.302276
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:17:02.720539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.49
 ---- batch: 020 ----
mean loss: 144.65
 ---- batch: 030 ----
mean loss: 142.98
train mean loss: 143.33
epoch train time: 0:00:01.431174
elapsed time: 0:03:03.733644
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:17:04.151893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.17
 ---- batch: 020 ----
mean loss: 147.13
 ---- batch: 030 ----
mean loss: 136.24
train mean loss: 144.16
epoch train time: 0:00:01.436301
elapsed time: 0:03:05.170103
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:17:05.588351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.43
 ---- batch: 020 ----
mean loss: 151.52
 ---- batch: 030 ----
mean loss: 152.88
train mean loss: 149.58
epoch train time: 0:00:01.435015
elapsed time: 0:03:06.605308
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:17:07.023572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.78
 ---- batch: 020 ----
mean loss: 145.14
 ---- batch: 030 ----
mean loss: 144.03
train mean loss: 145.76
epoch train time: 0:00:01.435759
elapsed time: 0:03:08.041262
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:17:08.459509
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.44
 ---- batch: 020 ----
mean loss: 148.71
 ---- batch: 030 ----
mean loss: 146.31
train mean loss: 147.84
epoch train time: 0:00:01.434223
elapsed time: 0:03:09.475648
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:17:09.893897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.00
 ---- batch: 020 ----
mean loss: 140.98
 ---- batch: 030 ----
mean loss: 148.19
train mean loss: 144.15
epoch train time: 0:00:01.436724
elapsed time: 0:03:10.912532
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:17:11.330780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.81
 ---- batch: 020 ----
mean loss: 153.59
 ---- batch: 030 ----
mean loss: 145.53
train mean loss: 150.50
epoch train time: 0:00:01.433202
elapsed time: 0:03:12.345896
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:17:12.764159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.05
 ---- batch: 020 ----
mean loss: 153.02
 ---- batch: 030 ----
mean loss: 151.54
train mean loss: 151.50
epoch train time: 0:00:01.434952
elapsed time: 0:03:13.781035
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:17:14.199267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.30
 ---- batch: 020 ----
mean loss: 143.73
 ---- batch: 030 ----
mean loss: 146.83
train mean loss: 144.34
epoch train time: 0:00:01.431638
elapsed time: 0:03:15.212825
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:17:15.631102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.49
 ---- batch: 020 ----
mean loss: 142.82
 ---- batch: 030 ----
mean loss: 144.46
train mean loss: 144.21
epoch train time: 0:00:01.434123
elapsed time: 0:03:16.647156
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:17:17.065403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.15
 ---- batch: 020 ----
mean loss: 144.59
 ---- batch: 030 ----
mean loss: 144.25
train mean loss: 144.06
epoch train time: 0:00:01.437545
elapsed time: 0:03:18.084925
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:17:18.503189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.22
 ---- batch: 020 ----
mean loss: 146.47
 ---- batch: 030 ----
mean loss: 144.20
train mean loss: 144.20
epoch train time: 0:00:01.436440
elapsed time: 0:03:19.521542
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:17:19.939805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.66
 ---- batch: 020 ----
mean loss: 144.07
 ---- batch: 030 ----
mean loss: 141.29
train mean loss: 143.22
epoch train time: 0:00:01.437222
elapsed time: 0:03:20.958941
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:17:21.377190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.96
 ---- batch: 020 ----
mean loss: 145.46
 ---- batch: 030 ----
mean loss: 138.49
train mean loss: 142.67
epoch train time: 0:00:01.435837
elapsed time: 0:03:22.394940
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:17:22.813187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.49
 ---- batch: 020 ----
mean loss: 144.76
 ---- batch: 030 ----
mean loss: 149.54
train mean loss: 146.01
epoch train time: 0:00:01.437850
elapsed time: 0:03:23.832953
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:17:24.251201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.85
 ---- batch: 020 ----
mean loss: 143.70
 ---- batch: 030 ----
mean loss: 146.00
train mean loss: 143.84
epoch train time: 0:00:01.436505
elapsed time: 0:03:25.269620
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:17:25.687866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.39
 ---- batch: 020 ----
mean loss: 137.54
 ---- batch: 030 ----
mean loss: 143.42
train mean loss: 141.28
epoch train time: 0:00:01.437516
elapsed time: 0:03:26.707304
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:17:27.125554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.88
 ---- batch: 020 ----
mean loss: 140.30
 ---- batch: 030 ----
mean loss: 141.84
train mean loss: 142.36
epoch train time: 0:00:01.435692
elapsed time: 0:03:28.143175
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:17:28.561423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.86
 ---- batch: 020 ----
mean loss: 148.70
 ---- batch: 030 ----
mean loss: 141.17
train mean loss: 144.74
epoch train time: 0:00:01.434606
elapsed time: 0:03:29.577939
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:17:29.996185
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.94
 ---- batch: 020 ----
mean loss: 141.72
 ---- batch: 030 ----
mean loss: 146.08
train mean loss: 143.27
epoch train time: 0:00:01.440400
elapsed time: 0:03:31.018521
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:17:31.436771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.89
 ---- batch: 020 ----
mean loss: 144.50
 ---- batch: 030 ----
mean loss: 142.17
train mean loss: 142.79
epoch train time: 0:00:01.457416
elapsed time: 0:03:32.476112
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:17:32.894358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.93
 ---- batch: 020 ----
mean loss: 145.33
 ---- batch: 030 ----
mean loss: 151.71
train mean loss: 147.84
epoch train time: 0:00:01.437086
elapsed time: 0:03:33.913359
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:17:34.331607
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.07
 ---- batch: 020 ----
mean loss: 143.47
 ---- batch: 030 ----
mean loss: 145.46
train mean loss: 145.56
epoch train time: 0:00:01.438099
elapsed time: 0:03:35.351630
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:17:35.769878
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.26
 ---- batch: 020 ----
mean loss: 148.47
 ---- batch: 030 ----
mean loss: 156.38
train mean loss: 147.79
epoch train time: 0:00:01.431309
elapsed time: 0:03:36.783104
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:17:37.201352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.50
 ---- batch: 020 ----
mean loss: 146.43
 ---- batch: 030 ----
mean loss: 145.93
train mean loss: 147.75
epoch train time: 0:00:01.436387
elapsed time: 0:03:38.219693
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:17:38.637936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.79
 ---- batch: 020 ----
mean loss: 142.25
 ---- batch: 030 ----
mean loss: 137.19
train mean loss: 143.11
epoch train time: 0:00:01.437369
elapsed time: 0:03:39.657231
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:17:40.075493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.63
 ---- batch: 020 ----
mean loss: 148.50
 ---- batch: 030 ----
mean loss: 137.95
train mean loss: 143.69
epoch train time: 0:00:01.436585
elapsed time: 0:03:41.093984
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:17:41.512227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.36
 ---- batch: 020 ----
mean loss: 143.61
 ---- batch: 030 ----
mean loss: 140.55
train mean loss: 142.35
epoch train time: 0:00:01.435863
elapsed time: 0:03:42.530040
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:17:42.948306
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.75
 ---- batch: 020 ----
mean loss: 142.53
 ---- batch: 030 ----
mean loss: 144.28
train mean loss: 143.71
epoch train time: 0:00:01.439685
elapsed time: 0:03:43.969899
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:17:44.388145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.53
 ---- batch: 020 ----
mean loss: 143.49
 ---- batch: 030 ----
mean loss: 139.13
train mean loss: 143.10
epoch train time: 0:00:01.433957
elapsed time: 0:03:45.404037
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:17:45.822270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.22
 ---- batch: 020 ----
mean loss: 141.76
 ---- batch: 030 ----
mean loss: 140.91
train mean loss: 142.22
epoch train time: 0:00:01.437436
elapsed time: 0:03:46.841619
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:17:47.259865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.82
 ---- batch: 020 ----
mean loss: 141.97
 ---- batch: 030 ----
mean loss: 138.62
train mean loss: 142.16
epoch train time: 0:00:01.434603
elapsed time: 0:03:48.276381
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:17:48.694628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.93
 ---- batch: 020 ----
mean loss: 142.56
 ---- batch: 030 ----
mean loss: 146.46
train mean loss: 142.75
epoch train time: 0:00:01.434459
elapsed time: 0:03:49.711026
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:17:50.129274
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.86
 ---- batch: 020 ----
mean loss: 142.20
 ---- batch: 030 ----
mean loss: 140.65
train mean loss: 141.40
epoch train time: 0:00:01.437910
elapsed time: 0:03:51.149096
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:17:51.567358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.71
 ---- batch: 020 ----
mean loss: 141.53
 ---- batch: 030 ----
mean loss: 145.95
train mean loss: 144.20
epoch train time: 0:00:01.439414
elapsed time: 0:03:52.588686
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:17:53.006935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.18
 ---- batch: 020 ----
mean loss: 147.47
 ---- batch: 030 ----
mean loss: 139.01
train mean loss: 146.08
epoch train time: 0:00:01.434378
elapsed time: 0:03:54.023238
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:17:54.441483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.92
 ---- batch: 020 ----
mean loss: 144.04
 ---- batch: 030 ----
mean loss: 145.25
train mean loss: 143.91
epoch train time: 0:00:01.433826
elapsed time: 0:03:55.457242
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:17:55.875508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.83
 ---- batch: 020 ----
mean loss: 138.58
 ---- batch: 030 ----
mean loss: 140.14
train mean loss: 139.86
epoch train time: 0:00:01.436164
elapsed time: 0:03:56.893604
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:17:57.311850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.83
 ---- batch: 020 ----
mean loss: 140.93
 ---- batch: 030 ----
mean loss: 140.60
train mean loss: 142.65
epoch train time: 0:00:01.437132
elapsed time: 0:03:58.330900
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:17:58.749168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.17
 ---- batch: 020 ----
mean loss: 136.02
 ---- batch: 030 ----
mean loss: 141.91
train mean loss: 140.76
epoch train time: 0:00:01.441735
elapsed time: 0:03:59.772829
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:18:00.191093
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.62
 ---- batch: 020 ----
mean loss: 151.30
 ---- batch: 030 ----
mean loss: 140.94
train mean loss: 146.19
epoch train time: 0:00:01.436461
elapsed time: 0:04:01.209478
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:18:01.627723
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.67
 ---- batch: 020 ----
mean loss: 143.02
 ---- batch: 030 ----
mean loss: 145.69
train mean loss: 143.57
epoch train time: 0:00:01.435916
elapsed time: 0:04:02.645581
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:18:03.063829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.45
 ---- batch: 020 ----
mean loss: 140.95
 ---- batch: 030 ----
mean loss: 142.02
train mean loss: 142.47
epoch train time: 0:00:01.435604
elapsed time: 0:04:04.081355
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:18:04.499600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.31
 ---- batch: 020 ----
mean loss: 147.50
 ---- batch: 030 ----
mean loss: 146.15
train mean loss: 146.90
epoch train time: 0:00:01.438850
elapsed time: 0:04:05.520383
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:18:05.938669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.28
 ---- batch: 020 ----
mean loss: 145.31
 ---- batch: 030 ----
mean loss: 142.17
train mean loss: 144.47
epoch train time: 0:00:01.437747
elapsed time: 0:04:06.958366
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:18:07.376611
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.43
 ---- batch: 020 ----
mean loss: 138.19
 ---- batch: 030 ----
mean loss: 139.54
train mean loss: 141.68
epoch train time: 0:00:01.439685
elapsed time: 0:04:08.398217
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:18:08.816465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.42
 ---- batch: 020 ----
mean loss: 140.08
 ---- batch: 030 ----
mean loss: 141.46
train mean loss: 141.32
epoch train time: 0:00:01.439016
elapsed time: 0:04:09.837439
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:18:10.255700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.95
 ---- batch: 020 ----
mean loss: 140.78
 ---- batch: 030 ----
mean loss: 140.96
train mean loss: 143.09
epoch train time: 0:00:01.437065
elapsed time: 0:04:11.274691
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:18:11.692967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.06
 ---- batch: 020 ----
mean loss: 138.25
 ---- batch: 030 ----
mean loss: 143.73
train mean loss: 140.24
epoch train time: 0:00:01.442465
elapsed time: 0:04:12.717347
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:18:13.135594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.58
 ---- batch: 020 ----
mean loss: 137.02
 ---- batch: 030 ----
mean loss: 138.43
train mean loss: 141.55
epoch train time: 0:00:01.438531
elapsed time: 0:04:14.156041
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:18:14.574307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.84
 ---- batch: 020 ----
mean loss: 135.29
 ---- batch: 030 ----
mean loss: 138.98
train mean loss: 138.97
epoch train time: 0:00:01.437319
elapsed time: 0:04:15.593544
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:18:16.011790
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.28
 ---- batch: 020 ----
mean loss: 143.24
 ---- batch: 030 ----
mean loss: 143.81
train mean loss: 143.96
epoch train time: 0:00:01.434774
elapsed time: 0:04:17.028525
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:18:17.446771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.12
 ---- batch: 020 ----
mean loss: 145.31
 ---- batch: 030 ----
mean loss: 144.71
train mean loss: 145.73
epoch train time: 0:00:01.434188
elapsed time: 0:04:18.462882
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:18:18.881153
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.80
 ---- batch: 020 ----
mean loss: 138.63
 ---- batch: 030 ----
mean loss: 143.75
train mean loss: 141.31
epoch train time: 0:00:01.433349
elapsed time: 0:04:19.896413
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:18:20.314660
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.57
 ---- batch: 020 ----
mean loss: 142.96
 ---- batch: 030 ----
mean loss: 138.14
train mean loss: 141.86
epoch train time: 0:00:01.435839
elapsed time: 0:04:21.332522
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:18:21.750779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.11
 ---- batch: 020 ----
mean loss: 143.75
 ---- batch: 030 ----
mean loss: 143.33
train mean loss: 141.67
epoch train time: 0:00:01.434064
elapsed time: 0:04:22.766787
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:18:23.185032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.21
 ---- batch: 020 ----
mean loss: 140.85
 ---- batch: 030 ----
mean loss: 136.70
train mean loss: 142.21
epoch train time: 0:00:01.437353
elapsed time: 0:04:24.204300
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:18:24.622568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.58
 ---- batch: 020 ----
mean loss: 143.95
 ---- batch: 030 ----
mean loss: 148.72
train mean loss: 146.13
epoch train time: 0:00:01.438541
elapsed time: 0:04:25.643023
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:18:26.061271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.88
 ---- batch: 020 ----
mean loss: 140.89
 ---- batch: 030 ----
mean loss: 139.61
train mean loss: 140.51
epoch train time: 0:00:01.439150
elapsed time: 0:04:27.082330
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:18:27.500575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.93
 ---- batch: 020 ----
mean loss: 140.47
 ---- batch: 030 ----
mean loss: 138.59
train mean loss: 140.58
epoch train time: 0:00:01.436207
elapsed time: 0:04:28.518705
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:18:28.936965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.96
 ---- batch: 020 ----
mean loss: 137.89
 ---- batch: 030 ----
mean loss: 141.86
train mean loss: 140.27
epoch train time: 0:00:01.434563
elapsed time: 0:04:29.953447
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:18:30.371699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.16
 ---- batch: 020 ----
mean loss: 148.97
 ---- batch: 030 ----
mean loss: 140.56
train mean loss: 143.91
epoch train time: 0:00:01.442642
elapsed time: 0:04:31.396266
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:18:31.814530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.42
 ---- batch: 020 ----
mean loss: 137.04
 ---- batch: 030 ----
mean loss: 139.20
train mean loss: 138.83
epoch train time: 0:00:01.443815
elapsed time: 0:04:32.840281
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:18:33.258531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.57
 ---- batch: 020 ----
mean loss: 144.05
 ---- batch: 030 ----
mean loss: 136.38
train mean loss: 140.41
epoch train time: 0:00:01.443502
elapsed time: 0:04:34.283978
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:18:34.702251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.53
 ---- batch: 020 ----
mean loss: 141.04
 ---- batch: 030 ----
mean loss: 144.27
train mean loss: 142.77
epoch train time: 0:00:01.442597
elapsed time: 0:04:35.726772
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:18:36.145019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.29
 ---- batch: 020 ----
mean loss: 143.38
 ---- batch: 030 ----
mean loss: 146.28
train mean loss: 144.42
epoch train time: 0:00:01.442792
elapsed time: 0:04:37.169744
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:18:37.588012
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.53
 ---- batch: 020 ----
mean loss: 140.97
 ---- batch: 030 ----
mean loss: 136.26
train mean loss: 139.24
epoch train time: 0:00:01.437011
elapsed time: 0:04:38.606932
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:18:39.025179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.76
 ---- batch: 020 ----
mean loss: 140.66
 ---- batch: 030 ----
mean loss: 141.00
train mean loss: 139.81
epoch train time: 0:00:01.435080
elapsed time: 0:04:40.042167
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:18:40.460414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.33
 ---- batch: 020 ----
mean loss: 140.34
 ---- batch: 030 ----
mean loss: 138.16
train mean loss: 137.60
epoch train time: 0:00:01.433879
elapsed time: 0:04:41.476210
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:18:41.894471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.07
 ---- batch: 020 ----
mean loss: 136.40
 ---- batch: 030 ----
mean loss: 137.75
train mean loss: 137.29
epoch train time: 0:00:01.435388
elapsed time: 0:04:42.911772
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:18:43.330019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.43
 ---- batch: 020 ----
mean loss: 140.58
 ---- batch: 030 ----
mean loss: 145.78
train mean loss: 141.89
epoch train time: 0:00:01.436994
elapsed time: 0:04:44.348930
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:18:44.767180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.44
 ---- batch: 020 ----
mean loss: 144.82
 ---- batch: 030 ----
mean loss: 142.21
train mean loss: 146.18
epoch train time: 0:00:01.436571
elapsed time: 0:04:45.785664
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:18:46.203925
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.26
 ---- batch: 020 ----
mean loss: 143.62
 ---- batch: 030 ----
mean loss: 149.79
train mean loss: 145.88
epoch train time: 0:00:01.434217
elapsed time: 0:04:47.220062
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:18:47.638311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.94
 ---- batch: 020 ----
mean loss: 142.05
 ---- batch: 030 ----
mean loss: 145.62
train mean loss: 142.93
epoch train time: 0:00:01.463889
elapsed time: 0:04:48.684129
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:18:49.102378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.46
 ---- batch: 020 ----
mean loss: 142.08
 ---- batch: 030 ----
mean loss: 139.98
train mean loss: 140.59
epoch train time: 0:00:01.438034
elapsed time: 0:04:50.122336
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:18:50.540584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.24
 ---- batch: 020 ----
mean loss: 146.13
 ---- batch: 030 ----
mean loss: 139.11
train mean loss: 142.12
epoch train time: 0:00:01.436124
elapsed time: 0:04:51.558622
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:18:51.976870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.12
 ---- batch: 020 ----
mean loss: 140.31
 ---- batch: 030 ----
mean loss: 145.55
train mean loss: 143.58
epoch train time: 0:00:01.441515
elapsed time: 0:04:53.000297
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:18:53.418544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.61
 ---- batch: 020 ----
mean loss: 142.48
 ---- batch: 030 ----
mean loss: 137.00
train mean loss: 142.80
epoch train time: 0:00:01.436172
elapsed time: 0:04:54.436633
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:18:54.854880
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.48
 ---- batch: 020 ----
mean loss: 140.77
 ---- batch: 030 ----
mean loss: 144.67
train mean loss: 141.72
epoch train time: 0:00:01.437277
elapsed time: 0:04:55.874072
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:18:56.292321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.81
 ---- batch: 020 ----
mean loss: 141.10
 ---- batch: 030 ----
mean loss: 141.61
train mean loss: 141.81
epoch train time: 0:00:01.436813
elapsed time: 0:04:57.311046
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:18:57.729302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.94
 ---- batch: 020 ----
mean loss: 147.24
 ---- batch: 030 ----
mean loss: 145.81
train mean loss: 144.08
epoch train time: 0:00:01.432263
elapsed time: 0:04:58.743519
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:18:59.161772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.59
 ---- batch: 020 ----
mean loss: 139.63
 ---- batch: 030 ----
mean loss: 146.22
train mean loss: 141.22
epoch train time: 0:00:01.440395
elapsed time: 0:05:00.184096
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:19:00.602344
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.19
 ---- batch: 020 ----
mean loss: 139.12
 ---- batch: 030 ----
mean loss: 140.02
train mean loss: 139.23
epoch train time: 0:00:01.439696
elapsed time: 0:05:01.623976
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:19:02.042232
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.26
 ---- batch: 020 ----
mean loss: 136.80
 ---- batch: 030 ----
mean loss: 137.09
train mean loss: 137.85
epoch train time: 0:00:01.437038
elapsed time: 0:05:03.061180
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:19:03.479425
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.55
 ---- batch: 020 ----
mean loss: 138.43
 ---- batch: 030 ----
mean loss: 139.34
train mean loss: 138.37
epoch train time: 0:00:01.439126
elapsed time: 0:05:04.500473
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:19:04.918723
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 144.23
 ---- batch: 020 ----
mean loss: 135.09
 ---- batch: 030 ----
mean loss: 137.88
train mean loss: 139.67
epoch train time: 0:00:01.436738
elapsed time: 0:05:05.937412
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:19:06.355661
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.84
 ---- batch: 020 ----
mean loss: 135.29
 ---- batch: 030 ----
mean loss: 134.95
train mean loss: 137.40
epoch train time: 0:00:01.438855
elapsed time: 0:05:07.376440
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:19:07.794687
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.18
 ---- batch: 020 ----
mean loss: 136.53
 ---- batch: 030 ----
mean loss: 138.83
train mean loss: 138.11
epoch train time: 0:00:01.442977
elapsed time: 0:05:08.820272
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:19:09.238531
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.12
 ---- batch: 020 ----
mean loss: 136.53
 ---- batch: 030 ----
mean loss: 136.41
train mean loss: 136.99
epoch train time: 0:00:01.438611
elapsed time: 0:05:10.259061
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:19:10.677312
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.36
 ---- batch: 020 ----
mean loss: 132.40
 ---- batch: 030 ----
mean loss: 139.33
train mean loss: 138.22
epoch train time: 0:00:01.437417
elapsed time: 0:05:11.696638
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:19:12.114883
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.63
 ---- batch: 020 ----
mean loss: 137.81
 ---- batch: 030 ----
mean loss: 138.28
train mean loss: 137.92
epoch train time: 0:00:01.436813
elapsed time: 0:05:13.133609
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:19:13.551879
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.37
 ---- batch: 020 ----
mean loss: 136.36
 ---- batch: 030 ----
mean loss: 138.95
train mean loss: 138.34
epoch train time: 0:00:01.437505
elapsed time: 0:05:14.571349
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:19:14.989598
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.24
 ---- batch: 020 ----
mean loss: 139.49
 ---- batch: 030 ----
mean loss: 138.69
train mean loss: 139.93
epoch train time: 0:00:01.435328
elapsed time: 0:05:16.006836
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:19:16.425113
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.07
 ---- batch: 020 ----
mean loss: 138.96
 ---- batch: 030 ----
mean loss: 134.06
train mean loss: 135.48
epoch train time: 0:00:01.434749
elapsed time: 0:05:17.441792
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:19:17.860040
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.39
 ---- batch: 020 ----
mean loss: 133.64
 ---- batch: 030 ----
mean loss: 134.84
train mean loss: 137.80
epoch train time: 0:00:01.439542
elapsed time: 0:05:18.881499
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:19:19.299752
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.45
 ---- batch: 020 ----
mean loss: 143.03
 ---- batch: 030 ----
mean loss: 137.11
train mean loss: 139.28
epoch train time: 0:00:01.435223
elapsed time: 0:05:20.316893
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:19:20.735155
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.46
 ---- batch: 020 ----
mean loss: 134.27
 ---- batch: 030 ----
mean loss: 145.53
train mean loss: 139.67
epoch train time: 0:00:01.433366
elapsed time: 0:05:21.750495
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:19:22.168740
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.17
 ---- batch: 020 ----
mean loss: 140.06
 ---- batch: 030 ----
mean loss: 139.49
train mean loss: 139.47
epoch train time: 0:00:01.435624
elapsed time: 0:05:23.186290
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:19:23.604549
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.63
 ---- batch: 020 ----
mean loss: 140.06
 ---- batch: 030 ----
mean loss: 138.11
train mean loss: 137.69
epoch train time: 0:00:01.436878
elapsed time: 0:05:24.623351
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:19:25.041601
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.14
 ---- batch: 020 ----
mean loss: 134.54
 ---- batch: 030 ----
mean loss: 137.50
train mean loss: 138.67
epoch train time: 0:00:01.435557
elapsed time: 0:05:26.059069
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:19:26.477315
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.71
 ---- batch: 020 ----
mean loss: 136.33
 ---- batch: 030 ----
mean loss: 138.85
train mean loss: 137.67
epoch train time: 0:00:01.438403
elapsed time: 0:05:27.497675
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:19:27.915953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.54
 ---- batch: 020 ----
mean loss: 137.42
 ---- batch: 030 ----
mean loss: 138.29
train mean loss: 137.26
epoch train time: 0:00:01.437555
elapsed time: 0:05:28.935457
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:19:29.353723
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.08
 ---- batch: 020 ----
mean loss: 138.10
 ---- batch: 030 ----
mean loss: 139.41
train mean loss: 137.84
epoch train time: 0:00:01.438801
elapsed time: 0:05:30.374440
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:19:30.792687
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.95
 ---- batch: 020 ----
mean loss: 137.09
 ---- batch: 030 ----
mean loss: 132.26
train mean loss: 137.92
epoch train time: 0:00:01.436468
elapsed time: 0:05:31.811074
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:19:32.229322
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.84
 ---- batch: 020 ----
mean loss: 139.35
 ---- batch: 030 ----
mean loss: 139.25
train mean loss: 137.28
epoch train time: 0:00:01.438278
elapsed time: 0:05:33.249518
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:19:33.667764
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.65
 ---- batch: 020 ----
mean loss: 140.13
 ---- batch: 030 ----
mean loss: 133.37
train mean loss: 137.70
epoch train time: 0:00:01.436533
elapsed time: 0:05:34.686210
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:19:35.104468
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.05
 ---- batch: 020 ----
mean loss: 139.92
 ---- batch: 030 ----
mean loss: 137.33
train mean loss: 137.31
epoch train time: 0:00:01.437089
elapsed time: 0:05:36.123490
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:19:36.541775
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.30
 ---- batch: 020 ----
mean loss: 134.27
 ---- batch: 030 ----
mean loss: 138.61
train mean loss: 136.71
epoch train time: 0:00:01.436956
elapsed time: 0:05:37.560654
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:19:37.978917
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.34
 ---- batch: 020 ----
mean loss: 139.94
 ---- batch: 030 ----
mean loss: 136.40
train mean loss: 137.23
epoch train time: 0:00:01.443187
elapsed time: 0:05:39.004022
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:19:39.422271
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.59
 ---- batch: 020 ----
mean loss: 138.49
 ---- batch: 030 ----
mean loss: 136.24
train mean loss: 136.89
epoch train time: 0:00:01.438090
elapsed time: 0:05:40.442275
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:19:40.860526
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.59
 ---- batch: 020 ----
mean loss: 139.19
 ---- batch: 030 ----
mean loss: 137.97
train mean loss: 137.74
epoch train time: 0:00:01.443911
elapsed time: 0:05:41.886371
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:19:42.304622
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.36
 ---- batch: 020 ----
mean loss: 140.50
 ---- batch: 030 ----
mean loss: 135.04
train mean loss: 137.78
epoch train time: 0:00:01.436704
elapsed time: 0:05:43.323273
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:19:43.741538
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.31
 ---- batch: 020 ----
mean loss: 139.38
 ---- batch: 030 ----
mean loss: 137.92
train mean loss: 139.26
epoch train time: 0:00:01.434486
elapsed time: 0:05:44.757933
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:19:45.176189
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.24
 ---- batch: 020 ----
mean loss: 138.39
 ---- batch: 030 ----
mean loss: 139.05
train mean loss: 138.55
epoch train time: 0:00:01.443101
elapsed time: 0:05:46.201271
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:19:46.619527
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.23
 ---- batch: 020 ----
mean loss: 142.12
 ---- batch: 030 ----
mean loss: 137.52
train mean loss: 139.67
epoch train time: 0:00:01.443105
elapsed time: 0:05:47.644584
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:19:48.062820
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.02
 ---- batch: 020 ----
mean loss: 137.65
 ---- batch: 030 ----
mean loss: 139.22
train mean loss: 139.81
epoch train time: 0:00:01.438442
elapsed time: 0:05:49.083184
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:19:49.501434
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.85
 ---- batch: 020 ----
mean loss: 132.78
 ---- batch: 030 ----
mean loss: 135.51
train mean loss: 136.86
epoch train time: 0:00:01.439022
elapsed time: 0:05:50.522378
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:19:50.940625
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.05
 ---- batch: 020 ----
mean loss: 137.21
 ---- batch: 030 ----
mean loss: 139.52
train mean loss: 138.66
epoch train time: 0:00:01.435573
elapsed time: 0:05:51.958126
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:19:52.376395
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.38
 ---- batch: 020 ----
mean loss: 135.24
 ---- batch: 030 ----
mean loss: 137.86
train mean loss: 138.36
epoch train time: 0:00:01.433830
elapsed time: 0:05:53.392161
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:19:53.810408
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.55
 ---- batch: 020 ----
mean loss: 139.06
 ---- batch: 030 ----
mean loss: 137.93
train mean loss: 137.66
epoch train time: 0:00:01.444699
elapsed time: 0:05:54.837045
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:19:55.255326
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.24
 ---- batch: 020 ----
mean loss: 137.26
 ---- batch: 030 ----
mean loss: 138.35
train mean loss: 138.68
epoch train time: 0:00:01.431940
elapsed time: 0:05:56.269203
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:19:56.687461
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.62
 ---- batch: 020 ----
mean loss: 136.48
 ---- batch: 030 ----
mean loss: 137.41
train mean loss: 136.84
epoch train time: 0:00:01.441822
elapsed time: 0:05:57.711253
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:19:58.129502
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.20
 ---- batch: 020 ----
mean loss: 136.72
 ---- batch: 030 ----
mean loss: 140.47
train mean loss: 138.63
epoch train time: 0:00:01.438421
elapsed time: 0:05:59.149848
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:19:59.568094
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.55
 ---- batch: 020 ----
mean loss: 136.84
 ---- batch: 030 ----
mean loss: 135.65
train mean loss: 138.10
epoch train time: 0:00:01.433789
elapsed time: 0:06:00.583807
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:20:01.002054
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.84
 ---- batch: 020 ----
mean loss: 139.50
 ---- batch: 030 ----
mean loss: 141.56
train mean loss: 138.50
epoch train time: 0:00:01.438110
elapsed time: 0:06:02.022123
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:20:02.440372
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.70
 ---- batch: 020 ----
mean loss: 138.49
 ---- batch: 030 ----
mean loss: 133.19
train mean loss: 137.19
epoch train time: 0:00:01.437153
elapsed time: 0:06:03.459457
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:20:03.877705
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.13
 ---- batch: 020 ----
mean loss: 134.80
 ---- batch: 030 ----
mean loss: 138.31
train mean loss: 138.11
epoch train time: 0:00:01.437025
elapsed time: 0:06:04.896662
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:20:05.314908
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.75
 ---- batch: 020 ----
mean loss: 139.14
 ---- batch: 030 ----
mean loss: 134.49
train mean loss: 137.30
epoch train time: 0:00:01.436492
elapsed time: 0:06:06.333329
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:20:06.751584
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.50
 ---- batch: 020 ----
mean loss: 136.73
 ---- batch: 030 ----
mean loss: 137.80
train mean loss: 138.26
epoch train time: 0:00:01.436543
elapsed time: 0:06:07.770046
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:20:08.188295
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.73
 ---- batch: 020 ----
mean loss: 138.03
 ---- batch: 030 ----
mean loss: 136.46
train mean loss: 137.32
epoch train time: 0:00:01.436846
elapsed time: 0:06:09.207053
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:20:09.625300
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.87
 ---- batch: 020 ----
mean loss: 142.21
 ---- batch: 030 ----
mean loss: 138.43
train mean loss: 137.63
epoch train time: 0:00:01.433053
elapsed time: 0:06:10.643847
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_6/checkpoint.pth.tar
**** end time: 2019-09-27 16:20:11.062057 ****
