Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_2', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32102
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 16:54:21.417562 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:54:21.420765
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4109.73
 ---- batch: 020 ----
mean loss: 3880.23
 ---- batch: 030 ----
mean loss: 3860.42
train mean loss: 3929.79
epoch train time: 0:00:12.571564
elapsed time: 0:00:12.577053
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:54:33.994659
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3738.79
 ---- batch: 020 ----
mean loss: 3638.29
 ---- batch: 030 ----
mean loss: 3604.12
train mean loss: 3651.65
epoch train time: 0:00:00.171339
elapsed time: 0:00:12.748521
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:54:34.166142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3516.54
 ---- batch: 020 ----
mean loss: 3451.86
 ---- batch: 030 ----
mean loss: 3418.71
train mean loss: 3445.56
epoch train time: 0:00:00.166329
elapsed time: 0:00:12.914995
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:54:34.332619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3312.23
 ---- batch: 020 ----
mean loss: 3245.25
 ---- batch: 030 ----
mean loss: 3239.59
train mean loss: 3263.38
epoch train time: 0:00:00.169033
elapsed time: 0:00:13.084180
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:54:34.501789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3110.74
 ---- batch: 020 ----
mean loss: 3060.75
 ---- batch: 030 ----
mean loss: 3136.04
train mean loss: 3092.28
epoch train time: 0:00:00.168424
elapsed time: 0:00:13.252743
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:54:34.670354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2985.47
 ---- batch: 020 ----
mean loss: 2924.20
 ---- batch: 030 ----
mean loss: 2913.79
train mean loss: 2931.37
epoch train time: 0:00:00.186544
elapsed time: 0:00:13.439422
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:54:34.857030
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2845.22
 ---- batch: 020 ----
mean loss: 2768.93
 ---- batch: 030 ----
mean loss: 2717.13
train mean loss: 2766.21
epoch train time: 0:00:00.168974
elapsed time: 0:00:13.608535
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:54:35.026144
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2662.70
 ---- batch: 020 ----
mean loss: 2642.24
 ---- batch: 030 ----
mean loss: 2551.58
train mean loss: 2609.15
epoch train time: 0:00:00.171548
elapsed time: 0:00:13.780218
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:54:35.197843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2507.19
 ---- batch: 020 ----
mean loss: 2468.36
 ---- batch: 030 ----
mean loss: 2435.03
train mean loss: 2460.16
epoch train time: 0:00:00.169757
elapsed time: 0:00:13.950139
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:54:35.367744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2382.21
 ---- batch: 020 ----
mean loss: 2319.88
 ---- batch: 030 ----
mean loss: 2293.21
train mean loss: 2318.58
epoch train time: 0:00:00.167577
elapsed time: 0:00:14.117856
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:54:35.535470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2221.88
 ---- batch: 020 ----
mean loss: 2212.46
 ---- batch: 030 ----
mean loss: 2154.44
train mean loss: 2185.81
epoch train time: 0:00:00.170315
elapsed time: 0:00:14.288318
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:54:35.705941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2098.52
 ---- batch: 020 ----
mean loss: 2083.69
 ---- batch: 030 ----
mean loss: 2012.97
train mean loss: 2062.90
epoch train time: 0:00:00.174096
elapsed time: 0:00:14.462582
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:54:35.880196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1991.64
 ---- batch: 020 ----
mean loss: 1933.39
 ---- batch: 030 ----
mean loss: 1932.87
train mean loss: 1937.85
epoch train time: 0:00:00.175314
elapsed time: 0:00:14.638037
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:54:36.055649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1893.06
 ---- batch: 020 ----
mean loss: 1837.32
 ---- batch: 030 ----
mean loss: 1775.90
train mean loss: 1820.66
epoch train time: 0:00:00.169714
elapsed time: 0:00:14.807887
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:54:36.225525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1746.27
 ---- batch: 020 ----
mean loss: 1723.47
 ---- batch: 030 ----
mean loss: 1691.84
train mean loss: 1713.42
epoch train time: 0:00:00.165904
elapsed time: 0:00:14.973953
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:54:36.391564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1639.78
 ---- batch: 020 ----
mean loss: 1611.86
 ---- batch: 030 ----
mean loss: 1598.67
train mean loss: 1610.89
epoch train time: 0:00:00.167680
elapsed time: 0:00:15.141786
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:54:36.559386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1548.53
 ---- batch: 020 ----
mean loss: 1510.99
 ---- batch: 030 ----
mean loss: 1491.40
train mean loss: 1510.95
epoch train time: 0:00:00.166046
elapsed time: 0:00:15.307971
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:54:36.725573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1454.14
 ---- batch: 020 ----
mean loss: 1423.37
 ---- batch: 030 ----
mean loss: 1374.47
train mean loss: 1416.03
epoch train time: 0:00:00.166837
elapsed time: 0:00:15.474932
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:54:36.892541
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1360.36
 ---- batch: 020 ----
mean loss: 1335.13
 ---- batch: 030 ----
mean loss: 1295.35
train mean loss: 1323.56
epoch train time: 0:00:00.184243
elapsed time: 0:00:15.659327
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:54:37.076934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1272.14
 ---- batch: 020 ----
mean loss: 1239.25
 ---- batch: 030 ----
mean loss: 1217.63
train mean loss: 1237.31
epoch train time: 0:00:00.168787
elapsed time: 0:00:15.828248
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:54:37.245857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1171.49
 ---- batch: 020 ----
mean loss: 1162.89
 ---- batch: 030 ----
mean loss: 1141.41
train mean loss: 1158.72
epoch train time: 0:00:00.172440
elapsed time: 0:00:16.000822
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:54:37.418445
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1100.71
 ---- batch: 020 ----
mean loss: 1113.56
 ---- batch: 030 ----
mean loss: 1068.80
train mean loss: 1084.15
epoch train time: 0:00:00.170089
elapsed time: 0:00:16.171076
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:54:37.588687
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1047.56
 ---- batch: 020 ----
mean loss: 1020.59
 ---- batch: 030 ----
mean loss: 1004.07
train mean loss: 1014.91
epoch train time: 0:00:00.170513
elapsed time: 0:00:16.341740
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:54:37.759349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.30
 ---- batch: 020 ----
mean loss: 969.52
 ---- batch: 030 ----
mean loss: 951.35
train mean loss: 950.02
epoch train time: 0:00:00.166829
elapsed time: 0:00:16.508714
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:54:37.926332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 921.13
 ---- batch: 020 ----
mean loss: 907.38
 ---- batch: 030 ----
mean loss: 868.84
train mean loss: 890.00
epoch train time: 0:00:00.169558
elapsed time: 0:00:16.678523
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:54:38.096181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 841.72
 ---- batch: 020 ----
mean loss: 853.36
 ---- batch: 030 ----
mean loss: 825.65
train mean loss: 834.31
epoch train time: 0:00:00.165147
elapsed time: 0:00:16.843861
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:54:38.261469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 802.54
 ---- batch: 020 ----
mean loss: 790.85
 ---- batch: 030 ----
mean loss: 753.31
train mean loss: 781.89
epoch train time: 0:00:00.168510
elapsed time: 0:00:17.012504
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:54:38.430139
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 753.89
 ---- batch: 020 ----
mean loss: 736.75
 ---- batch: 030 ----
mean loss: 712.25
train mean loss: 730.91
epoch train time: 0:00:00.164910
elapsed time: 0:00:17.177601
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:54:38.595212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 691.48
 ---- batch: 020 ----
mean loss: 706.32
 ---- batch: 030 ----
mean loss: 670.82
train mean loss: 684.11
epoch train time: 0:00:00.175999
elapsed time: 0:00:17.353745
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:54:38.771355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 652.82
 ---- batch: 020 ----
mean loss: 642.64
 ---- batch: 030 ----
mean loss: 631.71
train mean loss: 641.02
epoch train time: 0:00:00.172805
elapsed time: 0:00:17.526684
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:54:38.944294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 611.47
 ---- batch: 020 ----
mean loss: 590.94
 ---- batch: 030 ----
mean loss: 610.98
train mean loss: 600.87
epoch train time: 0:00:00.170117
elapsed time: 0:00:17.696938
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:54:39.114549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 575.64
 ---- batch: 020 ----
mean loss: 569.53
 ---- batch: 030 ----
mean loss: 551.42
train mean loss: 561.41
epoch train time: 0:00:00.171091
elapsed time: 0:00:17.868173
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:54:39.285784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 541.63
 ---- batch: 020 ----
mean loss: 524.23
 ---- batch: 030 ----
mean loss: 509.73
train mean loss: 526.20
epoch train time: 0:00:00.173421
elapsed time: 0:00:18.041729
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:54:39.459339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 505.28
 ---- batch: 020 ----
mean loss: 506.02
 ---- batch: 030 ----
mean loss: 481.64
train mean loss: 493.12
epoch train time: 0:00:00.167821
elapsed time: 0:00:18.209692
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:54:39.627296
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 467.18
 ---- batch: 020 ----
mean loss: 467.61
 ---- batch: 030 ----
mean loss: 457.03
train mean loss: 462.00
epoch train time: 0:00:00.176188
elapsed time: 0:00:18.386015
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:54:39.803634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 439.27
 ---- batch: 020 ----
mean loss: 432.25
 ---- batch: 030 ----
mean loss: 437.32
train mean loss: 433.96
epoch train time: 0:00:00.175108
elapsed time: 0:00:18.561325
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:54:39.978947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 416.78
 ---- batch: 020 ----
mean loss: 407.85
 ---- batch: 030 ----
mean loss: 400.88
train mean loss: 406.54
epoch train time: 0:00:00.174420
elapsed time: 0:00:18.735941
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:54:40.153568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 390.02
 ---- batch: 020 ----
mean loss: 380.40
 ---- batch: 030 ----
mean loss: 378.80
train mean loss: 381.97
epoch train time: 0:00:00.171507
elapsed time: 0:00:18.907604
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:54:40.325215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.95
 ---- batch: 020 ----
mean loss: 362.02
 ---- batch: 030 ----
mean loss: 352.98
train mean loss: 359.23
epoch train time: 0:00:00.173720
elapsed time: 0:00:19.081462
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:54:40.499083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 346.22
 ---- batch: 020 ----
mean loss: 333.89
 ---- batch: 030 ----
mean loss: 335.30
train mean loss: 337.72
epoch train time: 0:00:00.172967
elapsed time: 0:00:19.254607
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:54:40.672217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.18
 ---- batch: 020 ----
mean loss: 309.65
 ---- batch: 030 ----
mean loss: 316.65
train mean loss: 318.59
epoch train time: 0:00:00.179734
elapsed time: 0:00:19.434515
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:54:40.852136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.05
 ---- batch: 020 ----
mean loss: 297.01
 ---- batch: 030 ----
mean loss: 304.19
train mean loss: 299.95
epoch train time: 0:00:00.169525
elapsed time: 0:00:19.604234
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:54:41.021909
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 295.93
 ---- batch: 020 ----
mean loss: 284.01
 ---- batch: 030 ----
mean loss: 271.92
train mean loss: 283.18
epoch train time: 0:00:00.170721
elapsed time: 0:00:19.775156
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:54:41.192764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.82
 ---- batch: 020 ----
mean loss: 270.72
 ---- batch: 030 ----
mean loss: 265.04
train mean loss: 267.82
epoch train time: 0:00:00.167404
elapsed time: 0:00:19.942697
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:54:41.360308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.87
 ---- batch: 020 ----
mean loss: 250.55
 ---- batch: 030 ----
mean loss: 252.55
train mean loss: 253.22
epoch train time: 0:00:00.171988
elapsed time: 0:00:20.114828
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:54:41.532437
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.37
 ---- batch: 020 ----
mean loss: 236.12
 ---- batch: 030 ----
mean loss: 237.26
train mean loss: 240.12
epoch train time: 0:00:00.168715
elapsed time: 0:00:20.283702
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:54:41.701322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.62
 ---- batch: 020 ----
mean loss: 233.31
 ---- batch: 030 ----
mean loss: 225.00
train mean loss: 227.35
epoch train time: 0:00:00.174517
elapsed time: 0:00:20.458405
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:54:41.876017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.03
 ---- batch: 020 ----
mean loss: 216.93
 ---- batch: 030 ----
mean loss: 217.86
train mean loss: 216.28
epoch train time: 0:00:00.169284
elapsed time: 0:00:20.627827
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:54:42.045449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.66
 ---- batch: 020 ----
mean loss: 204.82
 ---- batch: 030 ----
mean loss: 207.54
train mean loss: 206.00
epoch train time: 0:00:00.172045
elapsed time: 0:00:20.800040
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:54:42.217675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.72
 ---- batch: 020 ----
mean loss: 198.93
 ---- batch: 030 ----
mean loss: 193.62
train mean loss: 196.35
epoch train time: 0:00:00.172257
elapsed time: 0:00:20.972471
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:54:42.390083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 194.28
 ---- batch: 020 ----
mean loss: 184.25
 ---- batch: 030 ----
mean loss: 187.42
train mean loss: 187.34
epoch train time: 0:00:00.170849
elapsed time: 0:00:21.143458
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:54:42.561065
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.02
 ---- batch: 020 ----
mean loss: 180.59
 ---- batch: 030 ----
mean loss: 175.59
train mean loss: 179.25
epoch train time: 0:00:00.169386
elapsed time: 0:00:21.312980
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:54:42.730590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.05
 ---- batch: 020 ----
mean loss: 169.95
 ---- batch: 030 ----
mean loss: 170.16
train mean loss: 171.19
epoch train time: 0:00:00.175182
elapsed time: 0:00:21.488300
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:54:42.905920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.33
 ---- batch: 020 ----
mean loss: 169.16
 ---- batch: 030 ----
mean loss: 162.66
train mean loss: 164.48
epoch train time: 0:00:00.170681
elapsed time: 0:00:21.659125
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:54:43.076754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.07
 ---- batch: 020 ----
mean loss: 155.29
 ---- batch: 030 ----
mean loss: 157.67
train mean loss: 157.88
epoch train time: 0:00:00.169675
elapsed time: 0:00:21.828956
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:54:43.246566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.53
 ---- batch: 020 ----
mean loss: 153.69
 ---- batch: 030 ----
mean loss: 148.02
train mean loss: 152.15
epoch train time: 0:00:00.169432
elapsed time: 0:00:21.998525
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:54:43.416134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.48
 ---- batch: 020 ----
mean loss: 149.87
 ---- batch: 030 ----
mean loss: 144.81
train mean loss: 146.63
epoch train time: 0:00:00.171321
elapsed time: 0:00:22.169992
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:54:43.587617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.62
 ---- batch: 020 ----
mean loss: 140.22
 ---- batch: 030 ----
mean loss: 143.69
train mean loss: 141.41
epoch train time: 0:00:00.170423
elapsed time: 0:00:22.340608
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:54:43.758216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.71
 ---- batch: 020 ----
mean loss: 137.76
 ---- batch: 030 ----
mean loss: 138.08
train mean loss: 136.86
epoch train time: 0:00:00.171968
elapsed time: 0:00:22.512712
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:54:43.930323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.98
 ---- batch: 020 ----
mean loss: 130.78
 ---- batch: 030 ----
mean loss: 131.24
train mean loss: 132.23
epoch train time: 0:00:00.170172
elapsed time: 0:00:22.683020
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:54:44.100630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.33
 ---- batch: 020 ----
mean loss: 127.99
 ---- batch: 030 ----
mean loss: 128.26
train mean loss: 128.82
epoch train time: 0:00:00.169749
elapsed time: 0:00:22.852959
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:54:44.270571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.16
 ---- batch: 020 ----
mean loss: 124.13
 ---- batch: 030 ----
mean loss: 127.06
train mean loss: 125.05
epoch train time: 0:00:00.171834
elapsed time: 0:00:23.024979
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:54:44.442589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.54
 ---- batch: 020 ----
mean loss: 122.75
 ---- batch: 030 ----
mean loss: 118.53
train mean loss: 121.40
epoch train time: 0:00:00.172364
elapsed time: 0:00:23.197491
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:54:44.615101
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.99
 ---- batch: 020 ----
mean loss: 119.01
 ---- batch: 030 ----
mean loss: 118.78
train mean loss: 117.95
epoch train time: 0:00:00.171349
elapsed time: 0:00:23.368977
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:54:44.786587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.49
 ---- batch: 020 ----
mean loss: 114.15
 ---- batch: 030 ----
mean loss: 114.57
train mean loss: 115.07
epoch train time: 0:00:00.170905
elapsed time: 0:00:23.540017
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:54:44.957647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.80
 ---- batch: 020 ----
mean loss: 112.84
 ---- batch: 030 ----
mean loss: 113.35
train mean loss: 112.43
epoch train time: 0:00:00.166845
elapsed time: 0:00:23.707015
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:54:45.124622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.58
 ---- batch: 020 ----
mean loss: 110.46
 ---- batch: 030 ----
mean loss: 108.45
train mean loss: 109.81
epoch train time: 0:00:00.165010
elapsed time: 0:00:23.872158
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:54:45.289767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.49
 ---- batch: 020 ----
mean loss: 106.78
 ---- batch: 030 ----
mean loss: 109.46
train mean loss: 108.22
epoch train time: 0:00:00.166285
elapsed time: 0:00:24.038576
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:54:45.456203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.48
 ---- batch: 020 ----
mean loss: 103.90
 ---- batch: 030 ----
mean loss: 101.58
train mean loss: 105.45
epoch train time: 0:00:00.169494
elapsed time: 0:00:24.208268
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:54:45.625876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.80
 ---- batch: 020 ----
mean loss: 101.65
 ---- batch: 030 ----
mean loss: 103.72
train mean loss: 103.37
epoch train time: 0:00:00.170291
elapsed time: 0:00:24.378708
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:54:45.796318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.87
 ---- batch: 020 ----
mean loss: 102.96
 ---- batch: 030 ----
mean loss: 101.28
train mean loss: 101.65
epoch train time: 0:00:00.169080
elapsed time: 0:00:24.547925
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:54:45.965545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.49
 ---- batch: 020 ----
mean loss: 100.32
 ---- batch: 030 ----
mean loss: 97.91
train mean loss: 100.12
epoch train time: 0:00:00.164475
elapsed time: 0:00:24.712547
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:54:46.130157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.54
 ---- batch: 020 ----
mean loss: 98.68
 ---- batch: 030 ----
mean loss: 100.01
train mean loss: 98.22
epoch train time: 0:00:00.162160
elapsed time: 0:00:24.874846
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:54:46.292455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.33
 ---- batch: 020 ----
mean loss: 98.63
 ---- batch: 030 ----
mean loss: 95.27
train mean loss: 96.15
epoch train time: 0:00:00.166956
elapsed time: 0:00:25.041933
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:54:46.459582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.86
 ---- batch: 020 ----
mean loss: 96.33
 ---- batch: 030 ----
mean loss: 94.43
train mean loss: 94.70
epoch train time: 0:00:00.169059
elapsed time: 0:00:25.211207
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:54:46.628830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.96
 ---- batch: 020 ----
mean loss: 92.48
 ---- batch: 030 ----
mean loss: 95.29
train mean loss: 93.35
epoch train time: 0:00:00.171892
elapsed time: 0:00:25.383248
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:54:46.800876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.88
 ---- batch: 020 ----
mean loss: 91.08
 ---- batch: 030 ----
mean loss: 88.21
train mean loss: 91.87
epoch train time: 0:00:00.173547
elapsed time: 0:00:25.556949
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:54:46.974557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.62
 ---- batch: 020 ----
mean loss: 89.05
 ---- batch: 030 ----
mean loss: 91.64
train mean loss: 90.28
epoch train time: 0:00:00.172588
elapsed time: 0:00:25.729668
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:54:47.147282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.01
 ---- batch: 020 ----
mean loss: 88.16
 ---- batch: 030 ----
mean loss: 91.91
train mean loss: 89.77
epoch train time: 0:00:00.170232
elapsed time: 0:00:25.900061
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:54:47.317678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.03
 ---- batch: 020 ----
mean loss: 89.25
 ---- batch: 030 ----
mean loss: 89.08
train mean loss: 88.38
epoch train time: 0:00:00.174500
elapsed time: 0:00:26.074706
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:54:47.492320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.81
 ---- batch: 020 ----
mean loss: 85.03
 ---- batch: 030 ----
mean loss: 85.52
train mean loss: 86.96
epoch train time: 0:00:00.174350
elapsed time: 0:00:26.249230
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:54:47.666863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.29
 ---- batch: 020 ----
mean loss: 87.63
 ---- batch: 030 ----
mean loss: 87.49
train mean loss: 86.17
epoch train time: 0:00:00.184416
elapsed time: 0:00:26.433805
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:54:47.851426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.07
 ---- batch: 020 ----
mean loss: 87.07
 ---- batch: 030 ----
mean loss: 82.44
train mean loss: 85.18
epoch train time: 0:00:00.177990
elapsed time: 0:00:26.611962
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:54:48.029565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.09
 ---- batch: 020 ----
mean loss: 81.92
 ---- batch: 030 ----
mean loss: 85.00
train mean loss: 84.16
epoch train time: 0:00:00.174828
elapsed time: 0:00:26.786930
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:54:48.204533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.88
 ---- batch: 020 ----
mean loss: 86.39
 ---- batch: 030 ----
mean loss: 83.24
train mean loss: 83.18
epoch train time: 0:00:00.171253
elapsed time: 0:00:26.958332
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:54:48.375945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.31
 ---- batch: 020 ----
mean loss: 83.43
 ---- batch: 030 ----
mean loss: 81.22
train mean loss: 82.13
epoch train time: 0:00:00.171562
elapsed time: 0:00:27.130058
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:54:48.547668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.40
 ---- batch: 020 ----
mean loss: 80.56
 ---- batch: 030 ----
mean loss: 86.09
train mean loss: 82.24
epoch train time: 0:00:00.171068
elapsed time: 0:00:27.301294
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:54:48.718914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.99
 ---- batch: 020 ----
mean loss: 82.27
 ---- batch: 030 ----
mean loss: 78.17
train mean loss: 81.29
epoch train time: 0:00:00.172031
elapsed time: 0:00:27.473476
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:54:48.891089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.74
 ---- batch: 020 ----
mean loss: 77.33
 ---- batch: 030 ----
mean loss: 79.08
train mean loss: 79.97
epoch train time: 0:00:00.178192
elapsed time: 0:00:27.651854
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:54:49.069467
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.71
 ---- batch: 020 ----
mean loss: 76.83
 ---- batch: 030 ----
mean loss: 80.67
train mean loss: 79.28
epoch train time: 0:00:00.167112
elapsed time: 0:00:27.819104
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:54:49.236714
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.68
 ---- batch: 020 ----
mean loss: 78.73
 ---- batch: 030 ----
mean loss: 78.51
train mean loss: 78.58
epoch train time: 0:00:00.167350
elapsed time: 0:00:27.986598
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:54:49.404208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.70
 ---- batch: 020 ----
mean loss: 79.29
 ---- batch: 030 ----
mean loss: 77.92
train mean loss: 77.58
epoch train time: 0:00:00.173884
elapsed time: 0:00:28.160617
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:54:49.578226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.30
 ---- batch: 020 ----
mean loss: 77.46
 ---- batch: 030 ----
mean loss: 78.54
train mean loss: 78.19
epoch train time: 0:00:00.173386
elapsed time: 0:00:28.334141
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:54:49.751752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.38
 ---- batch: 020 ----
mean loss: 76.13
 ---- batch: 030 ----
mean loss: 77.56
train mean loss: 76.67
epoch train time: 0:00:00.172386
elapsed time: 0:00:28.506733
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:54:49.924357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.20
 ---- batch: 020 ----
mean loss: 75.33
 ---- batch: 030 ----
mean loss: 77.10
train mean loss: 76.33
epoch train time: 0:00:00.173092
elapsed time: 0:00:28.680076
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:54:50.097714
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.18
 ---- batch: 020 ----
mean loss: 75.46
 ---- batch: 030 ----
mean loss: 78.51
train mean loss: 76.51
epoch train time: 0:00:00.172344
elapsed time: 0:00:28.852586
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:54:50.270198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.94
 ---- batch: 020 ----
mean loss: 75.26
 ---- batch: 030 ----
mean loss: 76.87
train mean loss: 74.74
epoch train time: 0:00:00.174548
elapsed time: 0:00:29.027273
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:54:50.444884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.13
 ---- batch: 020 ----
mean loss: 75.02
 ---- batch: 030 ----
mean loss: 75.80
train mean loss: 75.48
epoch train time: 0:00:00.171816
elapsed time: 0:00:29.199228
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:54:50.616839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.52
 ---- batch: 020 ----
mean loss: 74.28
 ---- batch: 030 ----
mean loss: 73.28
train mean loss: 74.38
epoch train time: 0:00:00.171420
elapsed time: 0:00:29.370801
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:54:50.788410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.87
 ---- batch: 020 ----
mean loss: 74.30
 ---- batch: 030 ----
mean loss: 71.77
train mean loss: 74.30
epoch train time: 0:00:00.173796
elapsed time: 0:00:29.544744
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:54:50.962355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.74
 ---- batch: 020 ----
mean loss: 72.12
 ---- batch: 030 ----
mean loss: 70.52
train mean loss: 72.94
epoch train time: 0:00:00.175683
elapsed time: 0:00:29.720597
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:54:51.138223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.97
 ---- batch: 020 ----
mean loss: 71.81
 ---- batch: 030 ----
mean loss: 72.17
train mean loss: 72.77
epoch train time: 0:00:00.169135
elapsed time: 0:00:29.889880
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:54:51.307489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.39
 ---- batch: 020 ----
mean loss: 74.97
 ---- batch: 030 ----
mean loss: 71.28
train mean loss: 72.33
epoch train time: 0:00:00.175243
elapsed time: 0:00:30.065260
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:54:51.482868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.19
 ---- batch: 020 ----
mean loss: 72.20
 ---- batch: 030 ----
mean loss: 70.70
train mean loss: 71.81
epoch train time: 0:00:00.171911
elapsed time: 0:00:30.237305
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:54:51.654913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.86
 ---- batch: 020 ----
mean loss: 69.58
 ---- batch: 030 ----
mean loss: 69.92
train mean loss: 71.72
epoch train time: 0:00:00.173908
elapsed time: 0:00:30.411349
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:54:51.828969
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.45
 ---- batch: 020 ----
mean loss: 70.80
 ---- batch: 030 ----
mean loss: 72.39
train mean loss: 71.47
epoch train time: 0:00:00.172480
elapsed time: 0:00:30.583978
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:54:52.001593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.21
 ---- batch: 020 ----
mean loss: 71.01
 ---- batch: 030 ----
mean loss: 69.40
train mean loss: 70.86
epoch train time: 0:00:00.175521
elapsed time: 0:00:30.759655
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:54:52.177258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.38
 ---- batch: 020 ----
mean loss: 70.81
 ---- batch: 030 ----
mean loss: 72.37
train mean loss: 71.06
epoch train time: 0:00:00.174781
elapsed time: 0:00:30.934567
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:54:52.352176
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.85
 ---- batch: 020 ----
mean loss: 72.81
 ---- batch: 030 ----
mean loss: 66.90
train mean loss: 70.56
epoch train time: 0:00:00.174603
elapsed time: 0:00:31.109321
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:54:52.526949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.48
 ---- batch: 020 ----
mean loss: 69.96
 ---- batch: 030 ----
mean loss: 71.01
train mean loss: 70.21
epoch train time: 0:00:00.172903
elapsed time: 0:00:31.282396
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:54:52.700010
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.78
 ---- batch: 020 ----
mean loss: 69.12
 ---- batch: 030 ----
mean loss: 72.02
train mean loss: 69.30
epoch train time: 0:00:00.175646
elapsed time: 0:00:31.458179
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:54:52.875787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.16
 ---- batch: 020 ----
mean loss: 69.01
 ---- batch: 030 ----
mean loss: 68.29
train mean loss: 69.63
epoch train time: 0:00:00.168891
elapsed time: 0:00:31.627203
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:54:53.044810
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.85
 ---- batch: 020 ----
mean loss: 70.24
 ---- batch: 030 ----
mean loss: 68.11
train mean loss: 69.71
epoch train time: 0:00:00.171242
elapsed time: 0:00:31.798601
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:54:53.216211
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.41
 ---- batch: 020 ----
mean loss: 66.02
 ---- batch: 030 ----
mean loss: 70.21
train mean loss: 68.76
epoch train time: 0:00:00.169659
elapsed time: 0:00:31.968397
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:54:53.386016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.54
 ---- batch: 020 ----
mean loss: 66.45
 ---- batch: 030 ----
mean loss: 69.28
train mean loss: 68.19
epoch train time: 0:00:00.174393
elapsed time: 0:00:32.143000
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:54:53.560609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.42
 ---- batch: 020 ----
mean loss: 67.02
 ---- batch: 030 ----
mean loss: 70.38
train mean loss: 68.47
epoch train time: 0:00:00.171841
elapsed time: 0:00:32.314978
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:54:53.732597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.66
 ---- batch: 020 ----
mean loss: 68.43
 ---- batch: 030 ----
mean loss: 71.81
train mean loss: 69.97
epoch train time: 0:00:00.171367
elapsed time: 0:00:32.486530
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:54:53.904139
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.42
 ---- batch: 020 ----
mean loss: 67.75
 ---- batch: 030 ----
mean loss: 69.96
train mean loss: 68.36
epoch train time: 0:00:00.173362
elapsed time: 0:00:32.660041
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:54:54.077708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.06
 ---- batch: 020 ----
mean loss: 67.35
 ---- batch: 030 ----
mean loss: 68.79
train mean loss: 67.82
epoch train time: 0:00:00.166438
elapsed time: 0:00:32.826668
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:54:54.244276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.61
 ---- batch: 020 ----
mean loss: 68.52
 ---- batch: 030 ----
mean loss: 68.58
train mean loss: 68.46
epoch train time: 0:00:00.170761
elapsed time: 0:00:32.997575
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:54:54.415188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.89
 ---- batch: 020 ----
mean loss: 68.43
 ---- batch: 030 ----
mean loss: 66.28
train mean loss: 68.11
epoch train time: 0:00:00.171672
elapsed time: 0:00:33.169383
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:54:54.587000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.54
 ---- batch: 020 ----
mean loss: 66.10
 ---- batch: 030 ----
mean loss: 68.76
train mean loss: 66.67
epoch train time: 0:00:00.175216
elapsed time: 0:00:33.344759
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:54:54.762410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.39
 ---- batch: 020 ----
mean loss: 67.07
 ---- batch: 030 ----
mean loss: 65.58
train mean loss: 66.11
epoch train time: 0:00:00.172010
elapsed time: 0:00:33.516975
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:54:54.934603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.23
 ---- batch: 020 ----
mean loss: 65.18
 ---- batch: 030 ----
mean loss: 65.72
train mean loss: 65.60
epoch train time: 0:00:00.169778
elapsed time: 0:00:33.686993
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:54:55.104609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.32
 ---- batch: 020 ----
mean loss: 63.93
 ---- batch: 030 ----
mean loss: 67.21
train mean loss: 66.13
epoch train time: 0:00:00.168719
elapsed time: 0:00:33.855868
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:54:55.273475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.96
 ---- batch: 020 ----
mean loss: 63.13
 ---- batch: 030 ----
mean loss: 64.50
train mean loss: 65.83
epoch train time: 0:00:00.167698
elapsed time: 0:00:34.023709
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:54:55.441322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.06
 ---- batch: 020 ----
mean loss: 64.91
 ---- batch: 030 ----
mean loss: 67.04
train mean loss: 65.70
epoch train time: 0:00:00.170315
elapsed time: 0:00:34.194175
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:54:55.611774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.90
 ---- batch: 020 ----
mean loss: 65.23
 ---- batch: 030 ----
mean loss: 67.60
train mean loss: 65.96
epoch train time: 0:00:00.176171
elapsed time: 0:00:34.370471
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:54:55.788095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.08
 ---- batch: 020 ----
mean loss: 65.58
 ---- batch: 030 ----
mean loss: 63.72
train mean loss: 65.07
epoch train time: 0:00:00.173595
elapsed time: 0:00:34.544217
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:54:55.961826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.96
 ---- batch: 020 ----
mean loss: 65.98
 ---- batch: 030 ----
mean loss: 62.73
train mean loss: 64.56
epoch train time: 0:00:00.168602
elapsed time: 0:00:34.712954
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:54:56.130571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.20
 ---- batch: 020 ----
mean loss: 64.23
 ---- batch: 030 ----
mean loss: 63.62
train mean loss: 64.77
epoch train time: 0:00:00.168547
elapsed time: 0:00:34.881643
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:54:56.299252
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.25
 ---- batch: 020 ----
mean loss: 63.28
 ---- batch: 030 ----
mean loss: 64.08
train mean loss: 63.80
epoch train time: 0:00:00.168006
elapsed time: 0:00:35.049783
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:54:56.467391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.79
 ---- batch: 020 ----
mean loss: 66.97
 ---- batch: 030 ----
mean loss: 61.76
train mean loss: 64.14
epoch train time: 0:00:00.170689
elapsed time: 0:00:35.220625
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:54:56.638264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.61
 ---- batch: 020 ----
mean loss: 65.47
 ---- batch: 030 ----
mean loss: 64.99
train mean loss: 64.47
epoch train time: 0:00:00.179708
elapsed time: 0:00:35.400497
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:54:56.818106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.12
 ---- batch: 020 ----
mean loss: 63.42
 ---- batch: 030 ----
mean loss: 64.04
train mean loss: 63.41
epoch train time: 0:00:00.169679
elapsed time: 0:00:35.570309
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:54:56.987918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.30
 ---- batch: 020 ----
mean loss: 61.36
 ---- batch: 030 ----
mean loss: 64.78
train mean loss: 63.44
epoch train time: 0:00:00.168573
elapsed time: 0:00:35.739015
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:54:57.156640
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.17
 ---- batch: 020 ----
mean loss: 64.06
 ---- batch: 030 ----
mean loss: 60.87
train mean loss: 63.39
epoch train time: 0:00:00.168349
elapsed time: 0:00:35.907514
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:54:57.325123
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.16
 ---- batch: 020 ----
mean loss: 65.33
 ---- batch: 030 ----
mean loss: 59.80
train mean loss: 63.19
epoch train time: 0:00:00.178743
elapsed time: 0:00:36.086402
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:54:57.504031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.91
 ---- batch: 020 ----
mean loss: 65.46
 ---- batch: 030 ----
mean loss: 64.11
train mean loss: 64.04
epoch train time: 0:00:00.169473
elapsed time: 0:00:36.256030
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:54:57.673664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.97
 ---- batch: 020 ----
mean loss: 64.18
 ---- batch: 030 ----
mean loss: 63.33
train mean loss: 62.70
epoch train time: 0:00:00.173529
elapsed time: 0:00:36.429718
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:54:57.847327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.68
 ---- batch: 020 ----
mean loss: 63.85
 ---- batch: 030 ----
mean loss: 66.00
train mean loss: 63.83
epoch train time: 0:00:00.166916
elapsed time: 0:00:36.596795
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:54:58.014401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.73
 ---- batch: 020 ----
mean loss: 63.46
 ---- batch: 030 ----
mean loss: 65.03
train mean loss: 63.63
epoch train time: 0:00:00.167250
elapsed time: 0:00:36.764178
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:54:58.181786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.96
 ---- batch: 020 ----
mean loss: 62.45
 ---- batch: 030 ----
mean loss: 63.25
train mean loss: 62.30
epoch train time: 0:00:00.165250
elapsed time: 0:00:36.929561
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:54:58.347170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.50
 ---- batch: 020 ----
mean loss: 61.35
 ---- batch: 030 ----
mean loss: 63.50
train mean loss: 61.68
epoch train time: 0:00:00.183316
elapsed time: 0:00:37.113012
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:54:58.530621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.63
 ---- batch: 020 ----
mean loss: 60.93
 ---- batch: 030 ----
mean loss: 61.84
train mean loss: 61.40
epoch train time: 0:00:00.171062
elapsed time: 0:00:37.284213
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:54:58.701821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.85
 ---- batch: 020 ----
mean loss: 61.94
 ---- batch: 030 ----
mean loss: 59.15
train mean loss: 61.36
epoch train time: 0:00:00.170986
elapsed time: 0:00:37.455332
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:54:58.872942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.15
 ---- batch: 020 ----
mean loss: 63.98
 ---- batch: 030 ----
mean loss: 59.38
train mean loss: 61.46
epoch train time: 0:00:00.168266
elapsed time: 0:00:37.623732
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:54:59.041341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.57
 ---- batch: 020 ----
mean loss: 61.15
 ---- batch: 030 ----
mean loss: 61.69
train mean loss: 60.97
epoch train time: 0:00:00.169057
elapsed time: 0:00:37.792920
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:54:59.210545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.00
 ---- batch: 020 ----
mean loss: 62.78
 ---- batch: 030 ----
mean loss: 60.20
train mean loss: 61.20
epoch train time: 0:00:00.166310
elapsed time: 0:00:37.959396
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:54:59.376996
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.23
 ---- batch: 020 ----
mean loss: 61.30
 ---- batch: 030 ----
mean loss: 59.51
train mean loss: 61.06
epoch train time: 0:00:00.170945
elapsed time: 0:00:38.130474
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:54:59.548114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.91
 ---- batch: 020 ----
mean loss: 61.61
 ---- batch: 030 ----
mean loss: 60.25
train mean loss: 61.06
epoch train time: 0:00:00.170996
elapsed time: 0:00:38.301633
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:54:59.719242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.62
 ---- batch: 020 ----
mean loss: 61.04
 ---- batch: 030 ----
mean loss: 67.51
train mean loss: 62.18
epoch train time: 0:00:00.176412
elapsed time: 0:00:38.478179
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:54:59.895787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.25
 ---- batch: 020 ----
mean loss: 62.30
 ---- batch: 030 ----
mean loss: 57.97
train mean loss: 60.52
epoch train time: 0:00:00.185242
elapsed time: 0:00:38.663557
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:55:00.081168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.01
 ---- batch: 020 ----
mean loss: 60.88
 ---- batch: 030 ----
mean loss: 62.78
train mean loss: 60.64
epoch train time: 0:00:00.173327
elapsed time: 0:00:38.837021
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:55:00.254629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.40
 ---- batch: 020 ----
mean loss: 62.55
 ---- batch: 030 ----
mean loss: 60.21
train mean loss: 60.78
epoch train time: 0:00:00.173150
elapsed time: 0:00:39.010304
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:55:00.427925
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.20
 ---- batch: 020 ----
mean loss: 61.26
 ---- batch: 030 ----
mean loss: 63.03
train mean loss: 60.31
epoch train time: 0:00:00.171568
elapsed time: 0:00:39.182022
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:55:00.599636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.47
 ---- batch: 020 ----
mean loss: 58.50
 ---- batch: 030 ----
mean loss: 59.39
train mean loss: 59.67
epoch train time: 0:00:00.176064
elapsed time: 0:00:39.358247
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:55:00.775872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.26
 ---- batch: 020 ----
mean loss: 61.96
 ---- batch: 030 ----
mean loss: 62.34
train mean loss: 62.22
epoch train time: 0:00:00.171603
elapsed time: 0:00:39.530010
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:55:00.947619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.27
 ---- batch: 020 ----
mean loss: 60.78
 ---- batch: 030 ----
mean loss: 57.48
train mean loss: 59.30
epoch train time: 0:00:00.170911
elapsed time: 0:00:39.701059
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:55:01.118668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.68
 ---- batch: 020 ----
mean loss: 57.51
 ---- batch: 030 ----
mean loss: 58.08
train mean loss: 59.03
epoch train time: 0:00:00.170035
elapsed time: 0:00:39.871229
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:55:01.288836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.48
 ---- batch: 020 ----
mean loss: 57.60
 ---- batch: 030 ----
mean loss: 60.83
train mean loss: 59.53
epoch train time: 0:00:00.169123
elapsed time: 0:00:40.040491
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:55:01.458100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.32
 ---- batch: 020 ----
mean loss: 58.71
 ---- batch: 030 ----
mean loss: 58.59
train mean loss: 60.25
epoch train time: 0:00:00.169542
elapsed time: 0:00:40.210170
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:55:01.627778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.41
 ---- batch: 020 ----
mean loss: 59.19
 ---- batch: 030 ----
mean loss: 60.70
train mean loss: 59.02
epoch train time: 0:00:00.175675
elapsed time: 0:00:40.385992
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:55:01.803630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.24
 ---- batch: 020 ----
mean loss: 59.62
 ---- batch: 030 ----
mean loss: 57.38
train mean loss: 58.51
epoch train time: 0:00:00.174096
elapsed time: 0:00:40.560256
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:55:01.977868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.89
 ---- batch: 020 ----
mean loss: 57.24
 ---- batch: 030 ----
mean loss: 57.00
train mean loss: 58.58
epoch train time: 0:00:00.173359
elapsed time: 0:00:40.733754
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:55:02.151365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.35
 ---- batch: 020 ----
mean loss: 55.67
 ---- batch: 030 ----
mean loss: 60.03
train mean loss: 58.28
epoch train time: 0:00:00.172720
elapsed time: 0:00:40.906612
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:55:02.324223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.17
 ---- batch: 020 ----
mean loss: 57.18
 ---- batch: 030 ----
mean loss: 56.55
train mean loss: 57.78
epoch train time: 0:00:00.176737
elapsed time: 0:00:41.083491
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:55:02.501104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.62
 ---- batch: 020 ----
mean loss: 56.98
 ---- batch: 030 ----
mean loss: 60.31
train mean loss: 59.09
epoch train time: 0:00:00.175960
elapsed time: 0:00:41.259635
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:55:02.677277
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.19
 ---- batch: 020 ----
mean loss: 56.15
 ---- batch: 030 ----
mean loss: 56.73
train mean loss: 57.60
epoch train time: 0:00:00.173734
elapsed time: 0:00:41.433540
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:55:02.851167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.64
 ---- batch: 020 ----
mean loss: 60.50
 ---- batch: 030 ----
mean loss: 57.32
train mean loss: 57.74
epoch train time: 0:00:00.176008
elapsed time: 0:00:41.609704
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:55:03.027315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.87
 ---- batch: 020 ----
mean loss: 58.56
 ---- batch: 030 ----
mean loss: 56.89
train mean loss: 57.30
epoch train time: 0:00:00.174808
elapsed time: 0:00:41.784668
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:55:03.202279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.58
 ---- batch: 020 ----
mean loss: 57.41
 ---- batch: 030 ----
mean loss: 56.18
train mean loss: 57.78
epoch train time: 0:00:00.173182
elapsed time: 0:00:41.958016
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:55:03.375645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.58
 ---- batch: 020 ----
mean loss: 54.94
 ---- batch: 030 ----
mean loss: 57.56
train mean loss: 57.14
epoch train time: 0:00:00.176637
elapsed time: 0:00:42.134811
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:55:03.552425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.03
 ---- batch: 020 ----
mean loss: 58.34
 ---- batch: 030 ----
mean loss: 58.48
train mean loss: 57.75
epoch train time: 0:00:00.174207
elapsed time: 0:00:42.309179
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:55:03.726778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.88
 ---- batch: 020 ----
mean loss: 59.25
 ---- batch: 030 ----
mean loss: 58.45
train mean loss: 57.28
epoch train time: 0:00:00.174190
elapsed time: 0:00:42.483528
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:55:03.901139
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.31
 ---- batch: 020 ----
mean loss: 55.11
 ---- batch: 030 ----
mean loss: 58.49
train mean loss: 57.54
epoch train time: 0:00:00.173343
elapsed time: 0:00:42.657009
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:55:04.074619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.31
 ---- batch: 020 ----
mean loss: 55.62
 ---- batch: 030 ----
mean loss: 57.78
train mean loss: 57.07
epoch train time: 0:00:00.169216
elapsed time: 0:00:42.826368
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:55:04.243998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.15
 ---- batch: 020 ----
mean loss: 56.46
 ---- batch: 030 ----
mean loss: 58.71
train mean loss: 57.22
epoch train time: 0:00:00.171866
elapsed time: 0:00:42.998390
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:55:04.415999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.66
 ---- batch: 020 ----
mean loss: 56.29
 ---- batch: 030 ----
mean loss: 55.00
train mean loss: 55.84
epoch train time: 0:00:00.170771
elapsed time: 0:00:43.169294
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:55:04.586920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.55
 ---- batch: 020 ----
mean loss: 55.76
 ---- batch: 030 ----
mean loss: 56.96
train mean loss: 56.56
epoch train time: 0:00:00.174386
elapsed time: 0:00:43.343843
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:55:04.761455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.69
 ---- batch: 020 ----
mean loss: 56.89
 ---- batch: 030 ----
mean loss: 54.95
train mean loss: 55.39
epoch train time: 0:00:00.171883
elapsed time: 0:00:43.515868
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:55:04.933479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.61
 ---- batch: 020 ----
mean loss: 58.07
 ---- batch: 030 ----
mean loss: 56.52
train mean loss: 55.93
epoch train time: 0:00:00.171952
elapsed time: 0:00:43.687992
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:55:05.105601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.98
 ---- batch: 020 ----
mean loss: 59.33
 ---- batch: 030 ----
mean loss: 53.79
train mean loss: 55.25
epoch train time: 0:00:00.173693
elapsed time: 0:00:43.861820
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:55:05.279430
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.52
 ---- batch: 020 ----
mean loss: 54.72
 ---- batch: 030 ----
mean loss: 57.33
train mean loss: 55.34
epoch train time: 0:00:00.173427
elapsed time: 0:00:44.035412
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:55:05.453072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.33
 ---- batch: 020 ----
mean loss: 56.34
 ---- batch: 030 ----
mean loss: 55.13
train mean loss: 55.30
epoch train time: 0:00:00.170799
elapsed time: 0:00:44.206399
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:55:05.624008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.60
 ---- batch: 020 ----
mean loss: 54.64
 ---- batch: 030 ----
mean loss: 54.36
train mean loss: 55.31
epoch train time: 0:00:00.172117
elapsed time: 0:00:44.378654
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:55:05.796264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.36
 ---- batch: 020 ----
mean loss: 55.65
 ---- batch: 030 ----
mean loss: 54.45
train mean loss: 55.67
epoch train time: 0:00:00.172622
elapsed time: 0:00:44.551417
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:55:05.969029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.49
 ---- batch: 020 ----
mean loss: 56.37
 ---- batch: 030 ----
mean loss: 58.72
train mean loss: 56.22
epoch train time: 0:00:00.172712
elapsed time: 0:00:44.724271
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:55:06.141920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.18
 ---- batch: 020 ----
mean loss: 53.31
 ---- batch: 030 ----
mean loss: 54.21
train mean loss: 54.39
epoch train time: 0:00:00.169876
elapsed time: 0:00:44.894321
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:55:06.311931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.48
 ---- batch: 020 ----
mean loss: 53.05
 ---- batch: 030 ----
mean loss: 55.71
train mean loss: 53.77
epoch train time: 0:00:00.172394
elapsed time: 0:00:45.066851
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:55:06.484460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.18
 ---- batch: 020 ----
mean loss: 52.52
 ---- batch: 030 ----
mean loss: 53.78
train mean loss: 53.74
epoch train time: 0:00:00.174403
elapsed time: 0:00:45.241399
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:55:06.659027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.88
 ---- batch: 020 ----
mean loss: 52.70
 ---- batch: 030 ----
mean loss: 54.46
train mean loss: 53.61
epoch train time: 0:00:00.176611
elapsed time: 0:00:45.418173
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:55:06.835785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.23
 ---- batch: 020 ----
mean loss: 52.57
 ---- batch: 030 ----
mean loss: 56.47
train mean loss: 53.98
epoch train time: 0:00:00.175745
elapsed time: 0:00:45.594068
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:55:07.011679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.43
 ---- batch: 020 ----
mean loss: 55.91
 ---- batch: 030 ----
mean loss: 53.34
train mean loss: 54.11
epoch train time: 0:00:00.174020
elapsed time: 0:00:45.768229
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:55:07.185841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.44
 ---- batch: 020 ----
mean loss: 53.34
 ---- batch: 030 ----
mean loss: 54.24
train mean loss: 53.63
epoch train time: 0:00:00.174568
elapsed time: 0:00:45.942936
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:55:07.360547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.51
 ---- batch: 020 ----
mean loss: 54.82
 ---- batch: 030 ----
mean loss: 53.02
train mean loss: 53.67
epoch train time: 0:00:00.174146
elapsed time: 0:00:46.117234
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:55:07.534846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.30
 ---- batch: 020 ----
mean loss: 54.92
 ---- batch: 030 ----
mean loss: 50.17
train mean loss: 52.84
epoch train time: 0:00:00.174093
elapsed time: 0:00:46.291472
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:55:07.709084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.03
 ---- batch: 020 ----
mean loss: 54.12
 ---- batch: 030 ----
mean loss: 52.14
train mean loss: 53.18
epoch train time: 0:00:00.174575
elapsed time: 0:00:46.466179
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:55:07.883786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.80
 ---- batch: 020 ----
mean loss: 52.67
 ---- batch: 030 ----
mean loss: 52.83
train mean loss: 52.93
epoch train time: 0:00:00.171103
elapsed time: 0:00:46.637414
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:55:08.055023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.61
 ---- batch: 020 ----
mean loss: 50.34
 ---- batch: 030 ----
mean loss: 54.46
train mean loss: 53.32
epoch train time: 0:00:00.169109
elapsed time: 0:00:46.806660
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:55:08.224279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.43
 ---- batch: 020 ----
mean loss: 52.68
 ---- batch: 030 ----
mean loss: 55.07
train mean loss: 53.86
epoch train time: 0:00:00.165592
elapsed time: 0:00:46.972411
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:55:08.390020
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.10
 ---- batch: 020 ----
mean loss: 53.46
 ---- batch: 030 ----
mean loss: 53.04
train mean loss: 52.47
epoch train time: 0:00:00.166656
elapsed time: 0:00:47.139217
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:55:08.556830
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.78
 ---- batch: 020 ----
mean loss: 51.52
 ---- batch: 030 ----
mean loss: 50.80
train mean loss: 51.18
epoch train time: 0:00:00.167836
elapsed time: 0:00:47.307237
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:55:08.724869
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.67
 ---- batch: 020 ----
mean loss: 49.66
 ---- batch: 030 ----
mean loss: 51.35
train mean loss: 51.31
epoch train time: 0:00:00.172284
elapsed time: 0:00:47.479681
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:55:08.897292
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.78
 ---- batch: 020 ----
mean loss: 49.96
 ---- batch: 030 ----
mean loss: 51.13
train mean loss: 51.06
epoch train time: 0:00:00.174075
elapsed time: 0:00:47.653912
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:55:09.071540
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.19
 ---- batch: 020 ----
mean loss: 51.81
 ---- batch: 030 ----
mean loss: 50.46
train mean loss: 51.18
epoch train time: 0:00:00.169666
elapsed time: 0:00:47.823774
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:55:09.241381
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.05
 ---- batch: 020 ----
mean loss: 51.36
 ---- batch: 030 ----
mean loss: 50.33
train mean loss: 51.04
epoch train time: 0:00:00.171848
elapsed time: 0:00:47.995754
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:55:09.413363
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.12
 ---- batch: 020 ----
mean loss: 52.16
 ---- batch: 030 ----
mean loss: 50.89
train mean loss: 51.01
epoch train time: 0:00:00.168238
elapsed time: 0:00:48.164150
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:55:09.581759
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.66
 ---- batch: 020 ----
mean loss: 49.98
 ---- batch: 030 ----
mean loss: 49.98
train mean loss: 51.03
epoch train time: 0:00:00.170493
elapsed time: 0:00:48.334776
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:55:09.752385
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.06
 ---- batch: 020 ----
mean loss: 50.66
 ---- batch: 030 ----
mean loss: 50.09
train mean loss: 50.91
epoch train time: 0:00:00.172249
elapsed time: 0:00:48.507160
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:55:09.924769
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.65
 ---- batch: 020 ----
mean loss: 51.47
 ---- batch: 030 ----
mean loss: 51.94
train mean loss: 51.10
epoch train time: 0:00:00.173023
elapsed time: 0:00:48.680322
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:55:10.097933
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.00
 ---- batch: 020 ----
mean loss: 49.65
 ---- batch: 030 ----
mean loss: 49.32
train mean loss: 50.81
epoch train time: 0:00:00.171775
elapsed time: 0:00:48.852236
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:55:10.269845
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.72
 ---- batch: 020 ----
mean loss: 52.12
 ---- batch: 030 ----
mean loss: 51.33
train mean loss: 50.89
epoch train time: 0:00:00.168336
elapsed time: 0:00:49.020704
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:55:10.438331
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.77
 ---- batch: 020 ----
mean loss: 48.49
 ---- batch: 030 ----
mean loss: 51.85
train mean loss: 50.99
epoch train time: 0:00:00.169277
elapsed time: 0:00:49.190133
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:55:10.607760
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.82
 ---- batch: 020 ----
mean loss: 51.48
 ---- batch: 030 ----
mean loss: 49.88
train mean loss: 50.99
epoch train time: 0:00:00.172638
elapsed time: 0:00:49.362934
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:55:10.780545
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.10
 ---- batch: 020 ----
mean loss: 50.07
 ---- batch: 030 ----
mean loss: 53.29
train mean loss: 50.74
epoch train time: 0:00:00.169310
elapsed time: 0:00:49.532383
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:55:10.949993
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.67
 ---- batch: 020 ----
mean loss: 51.57
 ---- batch: 030 ----
mean loss: 49.68
train mean loss: 50.94
epoch train time: 0:00:00.169288
elapsed time: 0:00:49.701806
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:55:11.119413
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.72
 ---- batch: 020 ----
mean loss: 52.13
 ---- batch: 030 ----
mean loss: 52.67
train mean loss: 50.81
epoch train time: 0:00:00.169374
elapsed time: 0:00:49.871328
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:55:11.288955
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.39
 ---- batch: 020 ----
mean loss: 51.02
 ---- batch: 030 ----
mean loss: 48.07
train mean loss: 50.88
epoch train time: 0:00:00.166070
elapsed time: 0:00:50.037552
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:55:11.455179
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.95
 ---- batch: 020 ----
mean loss: 51.09
 ---- batch: 030 ----
mean loss: 51.53
train mean loss: 50.75
epoch train time: 0:00:00.173462
elapsed time: 0:00:50.211195
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:55:11.628866
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.74
 ---- batch: 020 ----
mean loss: 50.91
 ---- batch: 030 ----
mean loss: 53.00
train mean loss: 50.86
epoch train time: 0:00:00.177362
elapsed time: 0:00:50.388757
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:55:11.806365
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.17
 ---- batch: 020 ----
mean loss: 50.61
 ---- batch: 030 ----
mean loss: 51.92
train mean loss: 50.74
epoch train time: 0:00:00.172255
elapsed time: 0:00:50.561147
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:55:11.978757
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.74
 ---- batch: 020 ----
mean loss: 50.60
 ---- batch: 030 ----
mean loss: 49.86
train mean loss: 50.82
epoch train time: 0:00:00.172623
elapsed time: 0:00:50.733912
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:55:12.151522
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.16
 ---- batch: 020 ----
mean loss: 49.71
 ---- batch: 030 ----
mean loss: 52.89
train mean loss: 50.66
epoch train time: 0:00:00.171404
elapsed time: 0:00:50.905452
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:55:12.323061
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.98
 ---- batch: 020 ----
mean loss: 49.41
 ---- batch: 030 ----
mean loss: 50.92
train mean loss: 50.71
epoch train time: 0:00:00.173779
elapsed time: 0:00:51.079378
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:55:12.497001
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.51
 ---- batch: 020 ----
mean loss: 49.74
 ---- batch: 030 ----
mean loss: 50.61
train mean loss: 50.69
epoch train time: 0:00:00.169934
elapsed time: 0:00:51.249464
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:55:12.667082
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.63
 ---- batch: 020 ----
mean loss: 49.82
 ---- batch: 030 ----
mean loss: 49.05
train mean loss: 50.56
epoch train time: 0:00:00.173235
elapsed time: 0:00:51.422869
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:55:12.840507
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.10
 ---- batch: 020 ----
mean loss: 52.53
 ---- batch: 030 ----
mean loss: 49.09
train mean loss: 50.62
epoch train time: 0:00:00.180191
elapsed time: 0:00:51.603227
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:55:13.020858
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.60
 ---- batch: 020 ----
mean loss: 50.68
 ---- batch: 030 ----
mean loss: 50.36
train mean loss: 50.58
epoch train time: 0:00:00.172684
elapsed time: 0:00:51.776098
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:55:13.193712
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.20
 ---- batch: 020 ----
mean loss: 49.70
 ---- batch: 030 ----
mean loss: 50.60
train mean loss: 50.38
epoch train time: 0:00:00.170595
elapsed time: 0:00:51.946843
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:55:13.364455
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.75
 ---- batch: 020 ----
mean loss: 52.84
 ---- batch: 030 ----
mean loss: 49.67
train mean loss: 50.62
epoch train time: 0:00:00.171426
elapsed time: 0:00:52.118417
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:55:13.536028
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.11
 ---- batch: 020 ----
mean loss: 50.34
 ---- batch: 030 ----
mean loss: 50.41
train mean loss: 50.48
epoch train time: 0:00:00.174981
elapsed time: 0:00:52.293539
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:55:13.711169
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.52
 ---- batch: 020 ----
mean loss: 52.48
 ---- batch: 030 ----
mean loss: 48.93
train mean loss: 50.31
epoch train time: 0:00:00.173767
elapsed time: 0:00:52.467475
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:55:13.885100
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.27
 ---- batch: 020 ----
mean loss: 49.49
 ---- batch: 030 ----
mean loss: 49.91
train mean loss: 50.51
epoch train time: 0:00:00.172264
elapsed time: 0:00:52.639904
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:55:14.057504
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.73
 ---- batch: 020 ----
mean loss: 51.77
 ---- batch: 030 ----
mean loss: 48.31
train mean loss: 50.51
epoch train time: 0:00:00.170585
elapsed time: 0:00:52.810611
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:55:14.228219
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.05
 ---- batch: 020 ----
mean loss: 50.64
 ---- batch: 030 ----
mean loss: 48.60
train mean loss: 50.46
epoch train time: 0:00:00.169764
elapsed time: 0:00:52.980509
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:55:14.398143
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.88
 ---- batch: 020 ----
mean loss: 49.43
 ---- batch: 030 ----
mean loss: 50.69
train mean loss: 50.42
epoch train time: 0:00:00.168282
elapsed time: 0:00:53.148949
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:55:14.566556
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.13
 ---- batch: 020 ----
mean loss: 49.94
 ---- batch: 030 ----
mean loss: 49.95
train mean loss: 50.44
epoch train time: 0:00:00.180115
elapsed time: 0:00:53.329198
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:55:14.746808
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.39
 ---- batch: 020 ----
mean loss: 50.10
 ---- batch: 030 ----
mean loss: 49.91
train mean loss: 50.46
epoch train time: 0:00:00.172248
elapsed time: 0:00:53.501620
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:55:14.919232
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.24
 ---- batch: 020 ----
mean loss: 49.95
 ---- batch: 030 ----
mean loss: 48.67
train mean loss: 50.37
epoch train time: 0:00:00.173948
elapsed time: 0:00:53.675704
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:55:15.093328
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.45
 ---- batch: 020 ----
mean loss: 50.57
 ---- batch: 030 ----
mean loss: 50.13
train mean loss: 50.51
epoch train time: 0:00:00.169823
elapsed time: 0:00:53.845675
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:55:15.263283
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.93
 ---- batch: 020 ----
mean loss: 49.39
 ---- batch: 030 ----
mean loss: 52.36
train mean loss: 50.26
epoch train time: 0:00:00.167056
elapsed time: 0:00:54.012863
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:55:15.430470
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.16
 ---- batch: 020 ----
mean loss: 50.48
 ---- batch: 030 ----
mean loss: 48.70
train mean loss: 50.28
epoch train time: 0:00:00.170667
elapsed time: 0:00:54.183677
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:55:15.601301
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.04
 ---- batch: 020 ----
mean loss: 50.98
 ---- batch: 030 ----
mean loss: 49.77
train mean loss: 50.29
epoch train time: 0:00:00.176506
elapsed time: 0:00:54.360344
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:55:15.777957
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.85
 ---- batch: 020 ----
mean loss: 50.79
 ---- batch: 030 ----
mean loss: 50.11
train mean loss: 50.20
epoch train time: 0:00:00.173095
elapsed time: 0:00:54.533580
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:55:15.951208
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.82
 ---- batch: 020 ----
mean loss: 50.09
 ---- batch: 030 ----
mean loss: 51.19
train mean loss: 50.21
epoch train time: 0:00:00.178990
elapsed time: 0:00:54.712726
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:55:16.130336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.23
 ---- batch: 020 ----
mean loss: 49.28
 ---- batch: 030 ----
mean loss: 49.51
train mean loss: 50.02
epoch train time: 0:00:00.175081
elapsed time: 0:00:54.887943
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:55:16.305552
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.06
 ---- batch: 020 ----
mean loss: 48.80
 ---- batch: 030 ----
mean loss: 49.64
train mean loss: 50.01
epoch train time: 0:00:00.171243
elapsed time: 0:00:55.059323
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:55:16.476933
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.78
 ---- batch: 020 ----
mean loss: 49.67
 ---- batch: 030 ----
mean loss: 46.30
train mean loss: 50.18
epoch train time: 0:00:00.168930
elapsed time: 0:00:55.228392
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:55:16.646019
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.89
 ---- batch: 020 ----
mean loss: 50.87
 ---- batch: 030 ----
mean loss: 51.35
train mean loss: 50.13
epoch train time: 0:00:00.175517
elapsed time: 0:00:55.407371
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_2/checkpoint.pth.tar
**** end time: 2019-09-27 16:55:16.824950 ****
