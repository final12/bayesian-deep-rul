Namespace(batch_size=512, dataset='CMAPSS/FD002', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD002/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_0', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.125, resume=False, step_size=200, visualize_step=50)
pid: 16762
use_cuda: True
Dataset: CMAPSS/FD002
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-25 15:49:46.122250 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 21, 24]             200
           Sigmoid-2           [-1, 10, 21, 24]               0
    BayesianConv2d-3           [-1, 10, 20, 24]           2,000
           Sigmoid-4           [-1, 10, 20, 24]               0
    BayesianConv2d-5           [-1, 10, 21, 24]           2,000
           Sigmoid-6           [-1, 10, 21, 24]               0
    BayesianConv2d-7           [-1, 10, 20, 24]           2,000
           Sigmoid-8           [-1, 10, 20, 24]               0
    BayesianConv2d-9            [-1, 1, 20, 24]              60
         Softplus-10            [-1, 1, 20, 24]               0
          Flatten-11                  [-1, 480]               0
   BayesianLinear-12                  [-1, 100]          96,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 102,460
Trainable params: 102,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-25 15:49:46.140144
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2134.27
train mean loss: 2035.28
epoch train time: 0:00:05.842570
elapsed time: 0:00:05.868763
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-25 15:49:51.991055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1309.25
train mean loss: 1279.77
epoch train time: 0:00:02.108201
elapsed time: 0:00:07.977205
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-25 15:49:54.099546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1179.46
train mean loss: 1171.26
epoch train time: 0:00:02.115566
elapsed time: 0:00:10.093104
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-25 15:49:56.215431
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1110.93
train mean loss: 1106.32
epoch train time: 0:00:02.108333
elapsed time: 0:00:12.201749
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-25 15:49:58.324088
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1066.48
train mean loss: 1071.04
epoch train time: 0:00:02.110246
elapsed time: 0:00:14.312309
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-25 15:50:00.434650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1040.53
train mean loss: 1045.73
epoch train time: 0:00:02.140148
elapsed time: 0:00:16.452808
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-25 15:50:02.575150
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1030.94
train mean loss: 1024.57
epoch train time: 0:00:02.115349
elapsed time: 0:00:18.568449
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-25 15:50:04.690774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1032.22
train mean loss: 1031.28
epoch train time: 0:00:02.105438
elapsed time: 0:00:20.674183
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-25 15:50:06.796515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1031.31
train mean loss: 1028.45
epoch train time: 0:00:02.081934
elapsed time: 0:00:22.756426
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-25 15:50:08.878762
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1009.39
train mean loss: 1022.14
epoch train time: 0:00:02.099292
elapsed time: 0:00:24.856013
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-25 15:50:10.978338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 997.09
train mean loss: 991.14
epoch train time: 0:00:02.116298
elapsed time: 0:00:26.972590
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-25 15:50:13.094917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 995.42
train mean loss: 996.31
epoch train time: 0:00:02.105895
elapsed time: 0:00:29.078829
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-25 15:50:15.201162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1008.40
train mean loss: 996.46
epoch train time: 0:00:02.107771
elapsed time: 0:00:31.186881
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-25 15:50:17.309214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1007.83
train mean loss: 1002.64
epoch train time: 0:00:02.099081
elapsed time: 0:00:33.286270
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-25 15:50:19.408597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 975.72
train mean loss: 977.10
epoch train time: 0:00:02.080991
elapsed time: 0:00:35.367569
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-25 15:50:21.489897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 981.04
train mean loss: 970.16
epoch train time: 0:00:02.107405
elapsed time: 0:00:37.475265
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-25 15:50:23.597593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 963.27
train mean loss: 970.96
epoch train time: 0:00:02.134736
elapsed time: 0:00:39.610304
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-25 15:50:25.732629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 970.38
train mean loss: 961.30
epoch train time: 0:00:02.130540
elapsed time: 0:00:41.741164
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-25 15:50:27.863508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 964.99
train mean loss: 965.83
epoch train time: 0:00:02.109536
elapsed time: 0:00:43.850996
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-25 15:50:29.973318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.70
train mean loss: 958.90
epoch train time: 0:00:02.113521
elapsed time: 0:00:45.964795
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-25 15:50:32.087119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 954.60
train mean loss: 959.98
epoch train time: 0:00:02.126983
elapsed time: 0:00:48.092053
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-25 15:50:34.214378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 968.02
train mean loss: 966.78
epoch train time: 0:00:02.107031
elapsed time: 0:00:50.199347
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-25 15:50:36.321750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 946.00
train mean loss: 951.37
epoch train time: 0:00:02.117526
elapsed time: 0:00:52.317228
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-25 15:50:38.439632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 942.48
train mean loss: 949.50
epoch train time: 0:00:02.105939
elapsed time: 0:00:54.423535
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-25 15:50:40.545866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 962.62
train mean loss: 961.22
epoch train time: 0:00:02.110675
elapsed time: 0:00:56.534475
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-25 15:50:42.656797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.32
train mean loss: 956.06
epoch train time: 0:00:02.103449
elapsed time: 0:00:58.638189
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-25 15:50:44.760514
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 947.09
train mean loss: 947.00
epoch train time: 0:00:02.108656
elapsed time: 0:01:00.747102
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-25 15:50:46.869428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.35
train mean loss: 944.79
epoch train time: 0:00:02.102361
elapsed time: 0:01:02.849722
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-25 15:50:48.972041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 937.92
train mean loss: 943.00
epoch train time: 0:00:02.098015
elapsed time: 0:01:04.948069
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-25 15:50:51.070401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 949.42
train mean loss: 954.19
epoch train time: 0:00:02.113695
elapsed time: 0:01:07.062018
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-25 15:50:53.184342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.53
train mean loss: 934.42
epoch train time: 0:00:02.108185
elapsed time: 0:01:09.170452
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-25 15:50:55.292777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 939.68
train mean loss: 945.19
epoch train time: 0:00:02.103424
elapsed time: 0:01:11.274229
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-25 15:50:57.396626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 944.29
train mean loss: 945.20
epoch train time: 0:00:02.101652
elapsed time: 0:01:13.376217
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-25 15:50:59.498563
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 939.59
train mean loss: 938.07
epoch train time: 0:00:02.107206
elapsed time: 0:01:15.483786
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-25 15:51:01.606116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 929.68
train mean loss: 939.63
epoch train time: 0:00:02.111066
elapsed time: 0:01:17.595150
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-25 15:51:03.717486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 928.95
train mean loss: 934.43
epoch train time: 0:00:02.116611
elapsed time: 0:01:19.712052
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-25 15:51:05.834375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 938.28
train mean loss: 941.66
epoch train time: 0:00:02.107875
elapsed time: 0:01:21.820210
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-25 15:51:07.942537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 937.65
train mean loss: 939.82
epoch train time: 0:00:02.108737
elapsed time: 0:01:23.929874
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-25 15:51:10.052226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.12
train mean loss: 937.66
epoch train time: 0:00:02.110042
elapsed time: 0:01:26.040222
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-25 15:51:12.162569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 943.90
train mean loss: 941.91
epoch train time: 0:00:02.109553
elapsed time: 0:01:28.150045
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-25 15:51:14.272368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 928.01
train mean loss: 929.56
epoch train time: 0:00:02.111178
elapsed time: 0:01:30.261500
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-25 15:51:16.383848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 935.31
train mean loss: 939.71
epoch train time: 0:00:02.111708
elapsed time: 0:01:32.373526
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-25 15:51:18.495873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 932.79
train mean loss: 935.36
epoch train time: 0:00:02.108793
elapsed time: 0:01:34.482602
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-25 15:51:20.604932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 942.92
train mean loss: 947.49
epoch train time: 0:00:02.109335
elapsed time: 0:01:36.592247
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-25 15:51:22.714595
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 925.05
train mean loss: 929.64
epoch train time: 0:00:02.113594
elapsed time: 0:01:38.706165
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-25 15:51:24.828490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 944.01
train mean loss: 940.47
epoch train time: 0:00:02.128435
elapsed time: 0:01:40.834893
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-25 15:51:26.957285
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 932.15
train mean loss: 928.18
epoch train time: 0:00:02.128464
elapsed time: 0:01:42.963760
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-25 15:51:29.086103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 933.31
train mean loss: 934.58
epoch train time: 0:00:02.126428
elapsed time: 0:01:45.090461
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-25 15:51:31.212797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 925.20
train mean loss: 921.99
epoch train time: 0:00:02.130023
elapsed time: 0:01:47.220757
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-25 15:51:33.343092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 927.67
train mean loss: 926.32
epoch train time: 0:00:02.113706
elapsed time: 0:01:49.334756
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-25 15:51:35.457081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 933.58
train mean loss: 932.74
epoch train time: 0:00:02.106815
elapsed time: 0:01:51.441850
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-25 15:51:37.564177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 922.36
train mean loss: 926.98
epoch train time: 0:00:02.112691
elapsed time: 0:01:53.554820
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-25 15:51:39.677142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 937.82
train mean loss: 934.76
epoch train time: 0:00:02.110631
elapsed time: 0:01:55.665733
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-25 15:51:41.788059
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 928.54
train mean loss: 930.46
epoch train time: 0:00:02.116607
elapsed time: 0:01:57.782694
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-25 15:51:43.905019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 924.21
train mean loss: 925.14
epoch train time: 0:00:02.109182
elapsed time: 0:01:59.892148
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-25 15:51:46.014472
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 929.36
train mean loss: 933.19
epoch train time: 0:00:02.112803
elapsed time: 0:02:02.005237
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-25 15:51:48.127579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 914.69
train mean loss: 916.13
epoch train time: 0:00:02.105484
elapsed time: 0:02:04.111070
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-25 15:51:50.233391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 909.04
train mean loss: 915.13
epoch train time: 0:00:02.120209
elapsed time: 0:02:06.231534
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-25 15:51:52.353855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 927.67
train mean loss: 928.24
epoch train time: 0:00:02.098963
elapsed time: 0:02:08.330772
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-25 15:51:54.453093
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.35
train mean loss: 918.12
epoch train time: 0:00:02.110312
elapsed time: 0:02:10.441344
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-25 15:51:56.563685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 917.03
train mean loss: 925.08
epoch train time: 0:00:02.114439
elapsed time: 0:02:12.556144
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-25 15:51:58.678470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 922.48
train mean loss: 918.86
epoch train time: 0:00:02.108511
elapsed time: 0:02:14.664922
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-25 15:52:00.787251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 927.09
train mean loss: 926.44
epoch train time: 0:00:02.110103
elapsed time: 0:02:16.775325
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-25 15:52:02.897684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 918.90
train mean loss: 917.72
epoch train time: 0:00:02.104507
elapsed time: 0:02:18.880126
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-25 15:52:05.002449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 929.63
train mean loss: 926.57
epoch train time: 0:00:02.103386
elapsed time: 0:02:20.983765
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-25 15:52:07.106097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 928.63
train mean loss: 923.83
epoch train time: 0:00:02.117922
elapsed time: 0:02:23.101990
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-25 15:52:09.224314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 906.12
train mean loss: 912.97
epoch train time: 0:00:02.098286
elapsed time: 0:02:25.200528
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-25 15:52:11.322850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 925.55
train mean loss: 924.46
epoch train time: 0:00:02.107802
elapsed time: 0:02:27.308607
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-25 15:52:13.430940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 914.10
train mean loss: 916.33
epoch train time: 0:00:02.110157
elapsed time: 0:02:29.419046
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-25 15:52:15.541368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 909.54
train mean loss: 918.69
epoch train time: 0:00:02.102497
elapsed time: 0:02:31.521812
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-25 15:52:17.644151
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.64
train mean loss: 919.23
epoch train time: 0:00:02.126340
elapsed time: 0:02:33.648439
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-25 15:52:19.770770
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 917.43
train mean loss: 920.83
epoch train time: 0:00:02.121195
elapsed time: 0:02:35.769931
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-25 15:52:21.892256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 900.06
train mean loss: 908.71
epoch train time: 0:00:02.103840
elapsed time: 0:02:37.874036
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-25 15:52:23.996360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 916.03
train mean loss: 916.39
epoch train time: 0:00:02.104780
elapsed time: 0:02:39.979108
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-25 15:52:26.101432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 909.10
train mean loss: 909.25
epoch train time: 0:00:02.104439
elapsed time: 0:02:42.083820
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-25 15:52:28.206163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 921.22
train mean loss: 911.29
epoch train time: 0:00:02.107681
elapsed time: 0:02:44.191791
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-25 15:52:30.314155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 909.94
train mean loss: 908.60
epoch train time: 0:00:02.103774
elapsed time: 0:02:46.295890
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-25 15:52:32.418215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.28
train mean loss: 912.18
epoch train time: 0:00:02.097934
elapsed time: 0:02:48.394080
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-25 15:52:34.516423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.89
train mean loss: 909.99
epoch train time: 0:00:02.101155
elapsed time: 0:02:50.495525
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-25 15:52:36.617845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 913.14
train mean loss: 905.93
epoch train time: 0:00:02.108141
elapsed time: 0:02:52.603952
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-25 15:52:38.726342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 907.83
train mean loss: 903.83
epoch train time: 0:00:02.100980
elapsed time: 0:02:54.705323
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-25 15:52:40.827686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.32
train mean loss: 908.05
epoch train time: 0:00:02.114061
elapsed time: 0:02:56.819712
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-25 15:52:42.942044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 894.27
train mean loss: 897.49
epoch train time: 0:00:02.111417
elapsed time: 0:02:58.931410
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-25 15:52:45.053739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.80
train mean loss: 901.40
epoch train time: 0:00:02.105341
elapsed time: 0:03:01.037017
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-25 15:52:47.159346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 890.19
train mean loss: 898.00
epoch train time: 0:00:02.107664
elapsed time: 0:03:03.144964
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-25 15:52:49.267284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 897.90
train mean loss: 898.38
epoch train time: 0:00:02.107415
elapsed time: 0:03:05.252667
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-25 15:52:51.374994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 906.26
train mean loss: 899.81
epoch train time: 0:00:02.103154
elapsed time: 0:03:07.356076
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-25 15:52:53.478417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 898.75
train mean loss: 890.88
epoch train time: 0:00:02.095933
elapsed time: 0:03:09.452296
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-25 15:52:55.574621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 901.70
train mean loss: 895.34
epoch train time: 0:00:02.096753
elapsed time: 0:03:11.549339
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-25 15:52:57.671680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 889.50
train mean loss: 891.66
epoch train time: 0:00:02.097982
elapsed time: 0:03:13.647612
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-25 15:52:59.769939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 890.83
train mean loss: 891.13
epoch train time: 0:00:02.108785
elapsed time: 0:03:15.756697
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-25 15:53:01.879032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 887.01
train mean loss: 882.20
epoch train time: 0:00:02.109742
elapsed time: 0:03:17.866776
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-25 15:53:03.989102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 870.54
train mean loss: 870.03
epoch train time: 0:00:02.101978
elapsed time: 0:03:19.969079
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-25 15:53:06.091399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 864.73
train mean loss: 867.63
epoch train time: 0:00:02.097029
elapsed time: 0:03:22.066367
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-25 15:53:08.188692
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 863.92
train mean loss: 861.25
epoch train time: 0:00:02.104989
elapsed time: 0:03:24.171660
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-25 15:53:10.294005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 857.36
train mean loss: 858.88
epoch train time: 0:00:02.106428
elapsed time: 0:03:26.278394
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-25 15:53:12.400752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 845.90
train mean loss: 836.67
epoch train time: 0:00:02.097024
elapsed time: 0:03:28.375714
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-25 15:53:14.498038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 819.48
train mean loss: 820.46
epoch train time: 0:00:02.104042
elapsed time: 0:03:30.480047
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-25 15:53:16.602375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 799.64
train mean loss: 802.49
epoch train time: 0:00:02.106327
elapsed time: 0:03:32.586696
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-25 15:53:18.709056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 776.06
train mean loss: 777.60
epoch train time: 0:00:02.097133
elapsed time: 0:03:34.684133
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-25 15:53:20.806457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 756.43
train mean loss: 757.30
epoch train time: 0:00:02.098009
elapsed time: 0:03:36.782415
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-25 15:53:22.904762
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 745.36
train mean loss: 737.84
epoch train time: 0:00:02.105518
elapsed time: 0:03:38.888220
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-25 15:53:25.010540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 719.82
train mean loss: 727.12
epoch train time: 0:00:02.103261
elapsed time: 0:03:40.991782
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-25 15:53:27.114114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 704.84
train mean loss: 703.39
epoch train time: 0:00:02.098252
elapsed time: 0:03:43.090319
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-25 15:53:29.212643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 700.27
train mean loss: 696.57
epoch train time: 0:00:02.109057
elapsed time: 0:03:45.199659
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-25 15:53:31.321983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 680.03
train mean loss: 681.22
epoch train time: 0:00:02.108920
elapsed time: 0:03:47.308819
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-25 15:53:33.431145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 676.05
train mean loss: 677.24
epoch train time: 0:00:02.101892
elapsed time: 0:03:49.411094
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-25 15:53:35.533395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 677.79
train mean loss: 679.21
epoch train time: 0:00:02.108089
elapsed time: 0:03:51.519446
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-25 15:53:37.641772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 665.06
train mean loss: 663.14
epoch train time: 0:00:02.106880
elapsed time: 0:03:53.626603
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-25 15:53:39.748942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 659.27
train mean loss: 661.37
epoch train time: 0:00:02.120282
elapsed time: 0:03:55.747195
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-25 15:53:41.869520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 647.85
train mean loss: 645.97
epoch train time: 0:00:02.096758
elapsed time: 0:03:57.844235
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-25 15:53:43.966557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 635.66
train mean loss: 635.95
epoch train time: 0:00:02.103688
elapsed time: 0:03:59.948186
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-25 15:53:46.070528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 627.55
train mean loss: 629.40
epoch train time: 0:00:02.094533
elapsed time: 0:04:02.043019
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-25 15:53:48.165345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 623.60
train mean loss: 619.16
epoch train time: 0:00:02.106032
elapsed time: 0:04:04.149296
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-25 15:53:50.271621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 616.34
train mean loss: 613.90
epoch train time: 0:00:02.103466
elapsed time: 0:04:06.253052
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-25 15:53:52.375403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 614.71
train mean loss: 615.19
epoch train time: 0:00:02.103101
elapsed time: 0:04:08.356451
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-25 15:53:54.478779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 602.20
train mean loss: 601.52
epoch train time: 0:00:02.100787
elapsed time: 0:04:10.457500
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-25 15:53:56.579886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 577.75
train mean loss: 589.69
epoch train time: 0:00:02.111874
elapsed time: 0:04:12.569716
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-25 15:53:58.692053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 591.01
train mean loss: 583.69
epoch train time: 0:00:02.116469
elapsed time: 0:04:14.686473
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-25 15:54:00.808798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 586.55
train mean loss: 579.03
epoch train time: 0:00:02.104769
elapsed time: 0:04:16.791539
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-25 15:54:02.913865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 554.18
train mean loss: 559.12
epoch train time: 0:00:02.093363
elapsed time: 0:04:18.885192
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-25 15:54:05.007520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 569.24
train mean loss: 566.88
epoch train time: 0:00:02.108067
elapsed time: 0:04:20.993546
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-25 15:54:07.115874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 551.22
train mean loss: 551.82
epoch train time: 0:00:02.105095
elapsed time: 0:04:23.098919
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-25 15:54:09.221245
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 543.08
train mean loss: 548.16
epoch train time: 0:00:02.104427
elapsed time: 0:04:25.203635
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-25 15:54:11.325971
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 544.19
train mean loss: 546.86
epoch train time: 0:00:02.097448
elapsed time: 0:04:27.301364
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-25 15:54:13.423689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 539.04
train mean loss: 539.74
epoch train time: 0:00:02.110886
elapsed time: 0:04:29.412522
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-25 15:54:15.534851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 529.99
train mean loss: 530.67
epoch train time: 0:00:02.099793
elapsed time: 0:04:31.512684
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-25 15:54:17.634988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 520.13
train mean loss: 520.01
epoch train time: 0:00:02.100188
elapsed time: 0:04:33.613132
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-25 15:54:19.735454
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 521.19
train mean loss: 521.82
epoch train time: 0:00:02.105256
elapsed time: 0:04:35.718700
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-25 15:54:21.841020
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 517.79
train mean loss: 517.76
epoch train time: 0:00:02.107426
elapsed time: 0:04:37.826393
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-25 15:54:23.948720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 501.49
train mean loss: 501.32
epoch train time: 0:00:02.105771
elapsed time: 0:04:39.932462
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-25 15:54:26.054787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 501.96
train mean loss: 500.37
epoch train time: 0:00:02.121147
elapsed time: 0:04:42.053900
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-25 15:54:28.176242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 502.16
train mean loss: 499.40
epoch train time: 0:00:02.121582
elapsed time: 0:04:44.175782
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-25 15:54:30.298146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 489.34
train mean loss: 485.29
epoch train time: 0:00:02.110203
elapsed time: 0:04:46.286422
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-25 15:54:32.408767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 485.19
train mean loss: 485.46
epoch train time: 0:00:02.109303
elapsed time: 0:04:48.396033
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-25 15:54:34.518359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 482.83
train mean loss: 482.68
epoch train time: 0:00:02.104169
elapsed time: 0:04:50.500479
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-25 15:54:36.622804
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 475.49
train mean loss: 473.54
epoch train time: 0:00:02.097820
elapsed time: 0:04:52.598573
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-25 15:54:38.720900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 474.72
train mean loss: 472.08
epoch train time: 0:00:02.100972
elapsed time: 0:04:54.699861
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-25 15:54:40.822187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 473.71
train mean loss: 474.61
epoch train time: 0:00:02.100995
elapsed time: 0:04:56.801123
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-25 15:54:42.923505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 474.19
train mean loss: 480.84
epoch train time: 0:00:02.099096
elapsed time: 0:04:58.900545
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-25 15:54:45.022869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 468.80
train mean loss: 467.50
epoch train time: 0:00:02.101423
elapsed time: 0:05:01.002245
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-25 15:54:47.124615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 465.25
train mean loss: 464.25
epoch train time: 0:00:02.099806
elapsed time: 0:05:03.102345
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-25 15:54:49.224688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 466.08
train mean loss: 463.36
epoch train time: 0:00:02.106766
elapsed time: 0:05:05.209408
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-25 15:54:51.331738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 451.83
train mean loss: 450.73
epoch train time: 0:00:02.107760
elapsed time: 0:05:07.317496
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-25 15:54:53.439850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 452.91
train mean loss: 453.52
epoch train time: 0:00:02.104129
elapsed time: 0:05:09.421937
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-25 15:54:55.544262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 451.51
train mean loss: 449.90
epoch train time: 0:00:02.105548
elapsed time: 0:05:11.527792
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-25 15:54:57.650114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 446.05
train mean loss: 447.46
epoch train time: 0:00:02.096680
elapsed time: 0:05:13.624730
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-25 15:54:59.747050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 439.20
train mean loss: 440.41
epoch train time: 0:00:02.105186
elapsed time: 0:05:15.730200
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-25 15:55:01.852546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 441.96
train mean loss: 439.78
epoch train time: 0:00:02.104045
elapsed time: 0:05:17.834584
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-25 15:55:03.956889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 423.53
train mean loss: 426.77
epoch train time: 0:00:02.103801
elapsed time: 0:05:19.938682
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-25 15:55:06.061017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 437.20
train mean loss: 435.18
epoch train time: 0:00:02.100535
elapsed time: 0:05:22.039526
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-25 15:55:08.161874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 431.27
train mean loss: 433.73
epoch train time: 0:00:02.102257
elapsed time: 0:05:24.142068
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-25 15:55:10.264421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 430.34
train mean loss: 427.72
epoch train time: 0:00:02.101696
elapsed time: 0:05:26.244062
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-25 15:55:12.366385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 423.36
train mean loss: 423.21
epoch train time: 0:00:02.106555
elapsed time: 0:05:28.350891
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-25 15:55:14.473219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.28
train mean loss: 415.79
epoch train time: 0:00:02.108340
elapsed time: 0:05:30.459533
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-25 15:55:16.581860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 437.82
train mean loss: 436.51
epoch train time: 0:00:02.101113
elapsed time: 0:05:32.560924
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-25 15:55:18.683278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 428.06
train mean loss: 429.66
epoch train time: 0:00:02.108534
elapsed time: 0:05:34.669757
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-25 15:55:20.792080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 434.10
train mean loss: 430.37
epoch train time: 0:00:02.097329
elapsed time: 0:05:36.767371
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-25 15:55:22.889700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 433.88
train mean loss: 431.13
epoch train time: 0:00:02.105731
elapsed time: 0:05:38.873377
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-25 15:55:24.995698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 424.78
train mean loss: 418.50
epoch train time: 0:00:02.101629
elapsed time: 0:05:40.975309
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-25 15:55:27.097654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.64
train mean loss: 411.42
epoch train time: 0:00:02.107715
elapsed time: 0:05:43.083315
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-25 15:55:29.205656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 416.82
train mean loss: 409.63
epoch train time: 0:00:02.106495
elapsed time: 0:05:45.190076
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-25 15:55:31.312417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 423.67
train mean loss: 422.69
epoch train time: 0:00:02.101313
elapsed time: 0:05:47.291694
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-25 15:55:33.414024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 407.04
train mean loss: 411.12
epoch train time: 0:00:02.101280
elapsed time: 0:05:49.393274
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-25 15:55:35.515600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 396.41
train mean loss: 396.66
epoch train time: 0:00:02.098428
elapsed time: 0:05:51.491960
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-25 15:55:37.614281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.61
train mean loss: 403.85
epoch train time: 0:00:02.100955
elapsed time: 0:05:53.593166
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-25 15:55:39.715491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 409.41
train mean loss: 410.07
epoch train time: 0:00:02.105746
elapsed time: 0:05:55.699262
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-25 15:55:41.821596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.66
train mean loss: 407.86
epoch train time: 0:00:02.100134
elapsed time: 0:05:57.799752
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-25 15:55:43.922082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 394.16
train mean loss: 393.47
epoch train time: 0:00:02.109753
elapsed time: 0:05:59.909815
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-25 15:55:46.032145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 401.32
train mean loss: 399.20
epoch train time: 0:00:02.106590
elapsed time: 0:06:02.016690
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-25 15:55:48.139048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 398.18
train mean loss: 397.80
epoch train time: 0:00:02.104202
elapsed time: 0:06:04.121204
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-25 15:55:50.243536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 393.41
train mean loss: 393.26
epoch train time: 0:00:02.105788
elapsed time: 0:06:06.227269
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-25 15:55:52.349630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 401.50
train mean loss: 403.55
epoch train time: 0:00:02.100891
elapsed time: 0:06:08.328475
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-25 15:55:54.450833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 392.93
train mean loss: 394.00
epoch train time: 0:00:02.099310
elapsed time: 0:06:10.428132
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-25 15:55:56.550428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 383.49
train mean loss: 384.77
epoch train time: 0:00:02.098170
elapsed time: 0:06:12.526579
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-25 15:55:58.648936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 399.62
train mean loss: 394.39
epoch train time: 0:00:02.108640
elapsed time: 0:06:14.635550
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-25 15:56:00.757873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 394.73
train mean loss: 392.59
epoch train time: 0:00:02.102958
elapsed time: 0:06:16.738791
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-25 15:56:02.861112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 381.76
train mean loss: 382.55
epoch train time: 0:00:02.102366
elapsed time: 0:06:18.841416
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-25 15:56:04.963749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 388.37
train mean loss: 387.75
epoch train time: 0:00:02.100350
elapsed time: 0:06:20.942033
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-25 15:56:07.064358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 394.61
train mean loss: 387.07
epoch train time: 0:00:02.104390
elapsed time: 0:06:23.046682
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-25 15:56:09.169000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 378.65
train mean loss: 378.69
epoch train time: 0:00:02.094801
elapsed time: 0:06:25.141744
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-25 15:56:11.264074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 378.11
train mean loss: 376.79
epoch train time: 0:00:02.112641
elapsed time: 0:06:27.254698
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-25 15:56:13.377034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 376.54
train mean loss: 373.81
epoch train time: 0:00:02.098829
elapsed time: 0:06:29.353793
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-25 15:56:15.476118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 386.72
train mean loss: 382.67
epoch train time: 0:00:02.106326
elapsed time: 0:06:31.460390
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-25 15:56:17.582711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.74
train mean loss: 373.31
epoch train time: 0:00:02.105871
elapsed time: 0:06:33.566512
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-25 15:56:19.688859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 380.40
train mean loss: 377.11
epoch train time: 0:00:02.113386
elapsed time: 0:06:35.680217
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-25 15:56:21.802543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 377.69
train mean loss: 373.67
epoch train time: 0:00:02.106493
elapsed time: 0:06:37.787002
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-25 15:56:23.909328
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 376.91
train mean loss: 380.05
epoch train time: 0:00:02.105739
elapsed time: 0:06:39.893018
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-25 15:56:26.015364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.13
train mean loss: 369.44
epoch train time: 0:00:02.098440
elapsed time: 0:06:41.991922
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-25 15:56:28.114255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 370.10
train mean loss: 368.90
epoch train time: 0:00:02.099088
elapsed time: 0:06:44.091289
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-25 15:56:30.213636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.79
train mean loss: 371.81
epoch train time: 0:00:02.103165
elapsed time: 0:06:46.194777
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-25 15:56:32.317122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.35
train mean loss: 363.93
epoch train time: 0:00:02.097353
elapsed time: 0:06:48.292415
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-25 15:56:34.414737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.78
train mean loss: 367.29
epoch train time: 0:00:02.106476
elapsed time: 0:06:50.399147
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-25 15:56:36.521489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 359.79
train mean loss: 356.86
epoch train time: 0:00:02.111408
elapsed time: 0:06:52.510861
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-25 15:56:38.633183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.09
train mean loss: 367.26
epoch train time: 0:00:02.119037
elapsed time: 0:06:54.630155
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-25 15:56:40.752475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.01
train mean loss: 363.26
epoch train time: 0:00:02.120013
elapsed time: 0:06:56.750428
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-25 15:56:42.872754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 360.78
train mean loss: 359.43
epoch train time: 0:00:02.119062
elapsed time: 0:06:58.869757
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-25 15:56:44.992076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 358.90
train mean loss: 357.19
epoch train time: 0:00:02.100188
elapsed time: 0:07:00.970212
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-25 15:56:47.092539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 357.79
train mean loss: 354.27
epoch train time: 0:00:02.099327
elapsed time: 0:07:03.069828
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-25 15:56:49.192151
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.39
train mean loss: 364.99
epoch train time: 0:00:02.093288
elapsed time: 0:07:05.163401
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-25 15:56:51.285727
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 367.95
train mean loss: 369.79
epoch train time: 0:00:02.101033
elapsed time: 0:07:07.264724
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-25 15:56:53.387068
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 360.70
train mean loss: 361.99
epoch train time: 0:00:02.095885
elapsed time: 0:07:09.360949
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-25 15:56:55.483246
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 355.65
train mean loss: 355.27
epoch train time: 0:00:02.091274
elapsed time: 0:07:11.452450
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-25 15:56:57.574773
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 356.21
train mean loss: 358.65
epoch train time: 0:00:02.091963
elapsed time: 0:07:13.544701
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-25 15:56:59.667030
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 351.20
train mean loss: 352.74
epoch train time: 0:00:02.092632
elapsed time: 0:07:15.637638
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-25 15:57:01.759967
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 357.08
train mean loss: 352.54
epoch train time: 0:00:02.094635
elapsed time: 0:07:17.732564
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-25 15:57:03.854896
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 358.37
train mean loss: 360.32
epoch train time: 0:00:02.086704
elapsed time: 0:07:19.819569
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-25 15:57:05.941923
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 356.31
train mean loss: 355.41
epoch train time: 0:00:02.086821
elapsed time: 0:07:21.906686
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-25 15:57:08.029021
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 353.13
train mean loss: 357.12
epoch train time: 0:00:02.096665
elapsed time: 0:07:24.003633
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-25 15:57:10.125953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 352.23
train mean loss: 356.22
epoch train time: 0:00:02.090344
elapsed time: 0:07:26.094249
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-25 15:57:12.216571
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 351.28
train mean loss: 351.88
epoch train time: 0:00:02.099493
elapsed time: 0:07:28.194003
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-25 15:57:14.316323
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 360.07
train mean loss: 358.08
epoch train time: 0:00:02.101543
elapsed time: 0:07:30.295821
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-25 15:57:16.418143
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 352.95
train mean loss: 354.71
epoch train time: 0:00:02.096505
elapsed time: 0:07:32.392607
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-25 15:57:18.514931
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 352.18
train mean loss: 349.71
epoch train time: 0:00:02.095891
elapsed time: 0:07:34.488775
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-25 15:57:20.611103
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 356.60
train mean loss: 353.57
epoch train time: 0:00:02.094466
elapsed time: 0:07:36.583597
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-25 15:57:22.705966
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 356.89
train mean loss: 354.05
epoch train time: 0:00:02.096956
elapsed time: 0:07:38.680872
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-25 15:57:24.803192
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 348.24
train mean loss: 348.64
epoch train time: 0:00:02.099829
elapsed time: 0:07:40.781013
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-25 15:57:26.903342
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 354.31
train mean loss: 354.40
epoch train time: 0:00:02.108614
elapsed time: 0:07:42.889923
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-25 15:57:29.012248
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 365.48
train mean loss: 361.01
epoch train time: 0:00:02.111851
elapsed time: 0:07:45.002068
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-25 15:57:31.124408
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 353.38
train mean loss: 352.68
epoch train time: 0:00:02.094995
elapsed time: 0:07:47.097355
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-25 15:57:33.219682
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 354.32
train mean loss: 359.36
epoch train time: 0:00:02.096041
elapsed time: 0:07:49.193736
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-25 15:57:35.316061
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 354.80
train mean loss: 353.28
epoch train time: 0:00:02.102676
elapsed time: 0:07:51.296697
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-25 15:57:37.419017
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 357.53
train mean loss: 355.82
epoch train time: 0:00:02.105830
elapsed time: 0:07:53.402830
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-25 15:57:39.525162
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 356.47
train mean loss: 353.10
epoch train time: 0:00:02.097920
elapsed time: 0:07:55.501075
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-25 15:57:41.623408
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 348.36
train mean loss: 348.89
epoch train time: 0:00:02.103762
elapsed time: 0:07:57.605114
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-25 15:57:43.727500
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 360.81
train mean loss: 358.11
epoch train time: 0:00:02.096445
elapsed time: 0:07:59.701926
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-25 15:57:45.824251
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 361.14
train mean loss: 354.90
epoch train time: 0:00:02.099962
elapsed time: 0:08:01.802190
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-25 15:57:47.924516
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 358.05
train mean loss: 354.73
epoch train time: 0:00:02.103328
elapsed time: 0:08:03.905807
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-25 15:57:50.028147
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 353.77
train mean loss: 351.52
epoch train time: 0:00:02.103252
elapsed time: 0:08:06.009345
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-25 15:57:52.131676
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 348.21
train mean loss: 350.49
epoch train time: 0:00:02.103186
elapsed time: 0:08:08.112813
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-25 15:57:54.235150
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 357.15
train mean loss: 357.47
epoch train time: 0:00:02.092259
elapsed time: 0:08:10.205330
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-25 15:57:56.327673
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 354.59
train mean loss: 349.67
epoch train time: 0:00:02.101379
elapsed time: 0:08:12.307001
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-25 15:57:58.429326
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 355.79
train mean loss: 352.70
epoch train time: 0:00:02.099506
elapsed time: 0:08:14.406755
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-25 15:58:00.529085
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 352.68
train mean loss: 351.27
epoch train time: 0:00:02.105110
elapsed time: 0:08:16.512202
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-25 15:58:02.634507
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 359.84
train mean loss: 353.74
epoch train time: 0:00:02.097350
elapsed time: 0:08:18.609875
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-25 15:58:04.732200
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 346.23
train mean loss: 349.07
epoch train time: 0:00:02.101315
elapsed time: 0:08:20.711528
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-25 15:58:06.833876
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 352.11
train mean loss: 352.01
epoch train time: 0:00:02.110216
elapsed time: 0:08:22.822621
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-25 15:58:08.944953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 359.26
train mean loss: 356.14
epoch train time: 0:00:02.098584
elapsed time: 0:08:24.921474
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-25 15:58:11.043799
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 348.70
train mean loss: 349.80
epoch train time: 0:00:02.103173
elapsed time: 0:08:27.024939
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-25 15:58:13.147263
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 344.61
train mean loss: 346.09
epoch train time: 0:00:02.106087
elapsed time: 0:08:29.131276
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-25 15:58:15.253626
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 351.27
train mean loss: 348.29
epoch train time: 0:00:02.105614
elapsed time: 0:08:31.237187
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-25 15:58:17.359511
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 351.63
train mean loss: 354.19
epoch train time: 0:00:02.100683
elapsed time: 0:08:33.338169
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-25 15:58:19.460521
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 353.88
train mean loss: 351.64
epoch train time: 0:00:02.107657
elapsed time: 0:08:35.446131
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-25 15:58:21.568473
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 349.14
train mean loss: 351.96
epoch train time: 0:00:02.105473
elapsed time: 0:08:37.551905
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-25 15:58:23.674255
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 348.48
train mean loss: 351.98
epoch train time: 0:00:02.095829
elapsed time: 0:08:39.648030
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-25 15:58:25.770359
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 354.08
train mean loss: 354.03
epoch train time: 0:00:02.098126
elapsed time: 0:08:41.746433
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-25 15:58:27.868757
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 347.30
train mean loss: 348.62
epoch train time: 0:00:02.098513
elapsed time: 0:08:43.845206
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-25 15:58:29.967528
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 351.90
train mean loss: 348.54
epoch train time: 0:00:02.107507
elapsed time: 0:08:45.953001
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-25 15:58:32.075326
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 349.03
train mean loss: 346.58
epoch train time: 0:00:02.101907
elapsed time: 0:08:48.055161
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-25 15:58:34.177494
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 354.12
train mean loss: 350.57
epoch train time: 0:00:02.106820
elapsed time: 0:08:50.171172
checkpoint saved in file: log/CMAPSS/FD002/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_0/checkpoint.pth.tar
**** end time: 2019-09-25 15:58:36.293439 ****
