Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_7', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 31112
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 16:20:27.348825 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:20:27.356803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3469.74
 ---- batch: 020 ----
mean loss: 1292.64
 ---- batch: 030 ----
mean loss: 688.67
train mean loss: 1645.08
epoch train time: 0:00:13.005604
elapsed time: 0:00:13.016844
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:20:40.365705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 480.34
 ---- batch: 020 ----
mean loss: 414.46
 ---- batch: 030 ----
mean loss: 381.01
train mean loss: 417.68
epoch train time: 0:00:01.512608
elapsed time: 0:00:14.529614
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:20:41.878518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.78
 ---- batch: 020 ----
mean loss: 347.31
 ---- batch: 030 ----
mean loss: 334.55
train mean loss: 344.06
epoch train time: 0:00:01.439466
elapsed time: 0:00:15.969285
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:20:43.318165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.84
 ---- batch: 020 ----
mean loss: 314.56
 ---- batch: 030 ----
mean loss: 303.16
train mean loss: 310.54
epoch train time: 0:00:01.439657
elapsed time: 0:00:17.409126
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:20:44.758005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.32
 ---- batch: 020 ----
mean loss: 277.29
 ---- batch: 030 ----
mean loss: 266.64
train mean loss: 271.82
epoch train time: 0:00:01.437808
elapsed time: 0:00:18.847089
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:20:46.195968
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.29
 ---- batch: 020 ----
mean loss: 248.82
 ---- batch: 030 ----
mean loss: 238.29
train mean loss: 241.46
epoch train time: 0:00:01.436631
elapsed time: 0:00:20.283905
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:20:47.632772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.37
 ---- batch: 020 ----
mean loss: 220.00
 ---- batch: 030 ----
mean loss: 221.21
train mean loss: 222.45
epoch train time: 0:00:01.442379
elapsed time: 0:00:21.726448
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:20:49.075326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.38
 ---- batch: 020 ----
mean loss: 215.56
 ---- batch: 030 ----
mean loss: 210.54
train mean loss: 215.04
epoch train time: 0:00:01.439185
elapsed time: 0:00:23.165797
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:20:50.514689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.26
 ---- batch: 020 ----
mean loss: 206.38
 ---- batch: 030 ----
mean loss: 203.89
train mean loss: 207.18
epoch train time: 0:00:01.440726
elapsed time: 0:00:24.606696
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:20:51.955590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.96
 ---- batch: 020 ----
mean loss: 200.96
 ---- batch: 030 ----
mean loss: 217.79
train mean loss: 207.86
epoch train time: 0:00:01.442979
elapsed time: 0:00:26.049886
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:20:53.398787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.49
 ---- batch: 020 ----
mean loss: 199.50
 ---- batch: 030 ----
mean loss: 194.00
train mean loss: 200.31
epoch train time: 0:00:01.437048
elapsed time: 0:00:27.487120
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:20:54.836001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.16
 ---- batch: 020 ----
mean loss: 201.71
 ---- batch: 030 ----
mean loss: 197.30
train mean loss: 196.06
epoch train time: 0:00:01.440168
elapsed time: 0:00:28.927445
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:20:56.276323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.98
 ---- batch: 020 ----
mean loss: 192.02
 ---- batch: 030 ----
mean loss: 189.06
train mean loss: 192.01
epoch train time: 0:00:01.439219
elapsed time: 0:00:30.366826
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:20:57.715705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.22
 ---- batch: 020 ----
mean loss: 195.25
 ---- batch: 030 ----
mean loss: 191.89
train mean loss: 191.68
epoch train time: 0:00:01.439727
elapsed time: 0:00:31.806733
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:20:59.155613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.71
 ---- batch: 020 ----
mean loss: 184.29
 ---- batch: 030 ----
mean loss: 194.47
train mean loss: 189.30
epoch train time: 0:00:01.443319
elapsed time: 0:00:33.250213
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:21:00.599089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.94
 ---- batch: 020 ----
mean loss: 185.79
 ---- batch: 030 ----
mean loss: 188.30
train mean loss: 184.76
epoch train time: 0:00:01.438406
elapsed time: 0:00:34.688810
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:21:02.037693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.67
 ---- batch: 020 ----
mean loss: 185.29
 ---- batch: 030 ----
mean loss: 194.59
train mean loss: 186.51
epoch train time: 0:00:01.435750
elapsed time: 0:00:36.124827
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:21:03.473713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.53
 ---- batch: 020 ----
mean loss: 181.08
 ---- batch: 030 ----
mean loss: 180.85
train mean loss: 182.46
epoch train time: 0:00:01.439686
elapsed time: 0:00:37.564695
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:21:04.913576
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.51
 ---- batch: 020 ----
mean loss: 193.13
 ---- batch: 030 ----
mean loss: 187.27
train mean loss: 189.21
epoch train time: 0:00:01.442302
elapsed time: 0:00:39.007160
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:21:06.356040
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.32
 ---- batch: 020 ----
mean loss: 188.09
 ---- batch: 030 ----
mean loss: 187.68
train mean loss: 184.68
epoch train time: 0:00:01.437375
elapsed time: 0:00:40.444696
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:21:07.793578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.49
 ---- batch: 020 ----
mean loss: 179.08
 ---- batch: 030 ----
mean loss: 177.18
train mean loss: 178.65
epoch train time: 0:00:01.437949
elapsed time: 0:00:41.882806
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:21:09.231683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.80
 ---- batch: 020 ----
mean loss: 187.93
 ---- batch: 030 ----
mean loss: 178.64
train mean loss: 182.43
epoch train time: 0:00:01.443735
elapsed time: 0:00:43.326706
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:21:10.675587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.13
 ---- batch: 020 ----
mean loss: 180.16
 ---- batch: 030 ----
mean loss: 174.97
train mean loss: 175.82
epoch train time: 0:00:01.438862
elapsed time: 0:00:44.765736
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:21:12.114618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.27
 ---- batch: 020 ----
mean loss: 189.34
 ---- batch: 030 ----
mean loss: 178.00
train mean loss: 182.63
epoch train time: 0:00:01.439217
elapsed time: 0:00:46.205124
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:21:13.554036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.58
 ---- batch: 020 ----
mean loss: 176.76
 ---- batch: 030 ----
mean loss: 175.65
train mean loss: 175.65
epoch train time: 0:00:01.438729
elapsed time: 0:00:47.644076
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:21:14.992955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.24
 ---- batch: 020 ----
mean loss: 172.97
 ---- batch: 030 ----
mean loss: 182.54
train mean loss: 177.88
epoch train time: 0:00:01.433316
elapsed time: 0:00:49.077547
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:21:16.426422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.20
 ---- batch: 020 ----
mean loss: 178.05
 ---- batch: 030 ----
mean loss: 181.40
train mean loss: 180.01
epoch train time: 0:00:01.439634
elapsed time: 0:00:50.517346
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:21:17.866226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.13
 ---- batch: 020 ----
mean loss: 174.72
 ---- batch: 030 ----
mean loss: 173.61
train mean loss: 172.50
epoch train time: 0:00:01.438811
elapsed time: 0:00:51.956317
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:21:19.305195
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.03
 ---- batch: 020 ----
mean loss: 172.53
 ---- batch: 030 ----
mean loss: 171.32
train mean loss: 173.92
epoch train time: 0:00:01.441220
elapsed time: 0:00:53.397727
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:21:20.746646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.73
 ---- batch: 020 ----
mean loss: 171.77
 ---- batch: 030 ----
mean loss: 171.38
train mean loss: 172.30
epoch train time: 0:00:01.437169
elapsed time: 0:00:54.835123
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:21:22.184001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.30
 ---- batch: 020 ----
mean loss: 173.00
 ---- batch: 030 ----
mean loss: 172.00
train mean loss: 172.77
epoch train time: 0:00:01.438285
elapsed time: 0:00:56.273582
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:21:23.622472
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.34
 ---- batch: 020 ----
mean loss: 166.19
 ---- batch: 030 ----
mean loss: 175.52
train mean loss: 170.48
epoch train time: 0:00:01.441315
elapsed time: 0:00:57.715067
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:21:25.063956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.85
 ---- batch: 020 ----
mean loss: 166.10
 ---- batch: 030 ----
mean loss: 178.55
train mean loss: 170.72
epoch train time: 0:00:01.440434
elapsed time: 0:00:59.155703
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:21:26.504591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.11
 ---- batch: 020 ----
mean loss: 167.24
 ---- batch: 030 ----
mean loss: 166.75
train mean loss: 165.67
epoch train time: 0:00:01.438147
elapsed time: 0:01:00.594028
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:21:27.942932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.86
 ---- batch: 020 ----
mean loss: 170.11
 ---- batch: 030 ----
mean loss: 166.08
train mean loss: 168.38
epoch train time: 0:00:01.438308
elapsed time: 0:01:02.032522
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:21:29.381400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.20
 ---- batch: 020 ----
mean loss: 169.54
 ---- batch: 030 ----
mean loss: 163.85
train mean loss: 167.26
epoch train time: 0:00:01.439550
elapsed time: 0:01:03.472239
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:21:30.821117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.35
 ---- batch: 020 ----
mean loss: 173.36
 ---- batch: 030 ----
mean loss: 168.18
train mean loss: 169.84
epoch train time: 0:00:01.438562
elapsed time: 0:01:04.910959
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:21:32.259866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.20
 ---- batch: 020 ----
mean loss: 165.09
 ---- batch: 030 ----
mean loss: 173.51
train mean loss: 168.32
epoch train time: 0:00:01.437336
elapsed time: 0:01:06.348494
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:21:33.697374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.79
 ---- batch: 020 ----
mean loss: 167.82
 ---- batch: 030 ----
mean loss: 164.01
train mean loss: 164.66
epoch train time: 0:00:01.440380
elapsed time: 0:01:07.789080
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:21:35.137999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.73
 ---- batch: 020 ----
mean loss: 168.23
 ---- batch: 030 ----
mean loss: 175.09
train mean loss: 171.41
epoch train time: 0:00:01.440648
elapsed time: 0:01:09.229928
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:21:36.578807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.64
 ---- batch: 020 ----
mean loss: 165.01
 ---- batch: 030 ----
mean loss: 167.19
train mean loss: 169.44
epoch train time: 0:00:01.438188
elapsed time: 0:01:10.668299
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:21:38.017177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.65
 ---- batch: 020 ----
mean loss: 167.68
 ---- batch: 030 ----
mean loss: 169.66
train mean loss: 167.19
epoch train time: 0:00:01.439186
elapsed time: 0:01:12.107648
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:21:39.456533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.36
 ---- batch: 020 ----
mean loss: 170.26
 ---- batch: 030 ----
mean loss: 163.68
train mean loss: 163.30
epoch train time: 0:00:01.441328
elapsed time: 0:01:13.549152
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:21:40.898031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.98
 ---- batch: 020 ----
mean loss: 164.04
 ---- batch: 030 ----
mean loss: 156.37
train mean loss: 160.18
epoch train time: 0:00:01.438194
elapsed time: 0:01:14.987510
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:21:42.336390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.63
 ---- batch: 020 ----
mean loss: 160.80
 ---- batch: 030 ----
mean loss: 158.17
train mean loss: 159.62
epoch train time: 0:00:01.436546
elapsed time: 0:01:16.424234
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:21:43.773114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.21
 ---- batch: 020 ----
mean loss: 157.99
 ---- batch: 030 ----
mean loss: 157.06
train mean loss: 157.61
epoch train time: 0:00:01.434398
elapsed time: 0:01:17.858834
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:21:45.207730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.96
 ---- batch: 020 ----
mean loss: 159.02
 ---- batch: 030 ----
mean loss: 157.41
train mean loss: 157.46
epoch train time: 0:00:01.443091
elapsed time: 0:01:19.302132
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:21:46.651013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.17
 ---- batch: 020 ----
mean loss: 156.89
 ---- batch: 030 ----
mean loss: 155.97
train mean loss: 158.92
epoch train time: 0:00:01.438333
elapsed time: 0:01:20.740623
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:21:48.089501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.28
 ---- batch: 020 ----
mean loss: 154.93
 ---- batch: 030 ----
mean loss: 165.08
train mean loss: 160.55
epoch train time: 0:00:01.437842
elapsed time: 0:01:22.178622
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:21:49.527519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.43
 ---- batch: 020 ----
mean loss: 159.74
 ---- batch: 030 ----
mean loss: 156.48
train mean loss: 158.67
epoch train time: 0:00:01.438816
elapsed time: 0:01:23.617783
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:21:50.966671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.54
 ---- batch: 020 ----
mean loss: 159.10
 ---- batch: 030 ----
mean loss: 160.22
train mean loss: 163.62
epoch train time: 0:00:01.439050
elapsed time: 0:01:25.057017
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:21:52.405927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.75
 ---- batch: 020 ----
mean loss: 157.17
 ---- batch: 030 ----
mean loss: 156.85
train mean loss: 155.69
epoch train time: 0:00:01.440051
elapsed time: 0:01:26.497308
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:21:53.846200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.95
 ---- batch: 020 ----
mean loss: 158.35
 ---- batch: 030 ----
mean loss: 154.28
train mean loss: 158.36
epoch train time: 0:00:01.436730
elapsed time: 0:01:27.934211
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:21:55.283091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.59
 ---- batch: 020 ----
mean loss: 154.49
 ---- batch: 030 ----
mean loss: 151.86
train mean loss: 154.93
epoch train time: 0:00:01.437652
elapsed time: 0:01:29.372039
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:21:56.720942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.86
 ---- batch: 020 ----
mean loss: 153.60
 ---- batch: 030 ----
mean loss: 156.54
train mean loss: 155.66
epoch train time: 0:00:01.437418
elapsed time: 0:01:30.809648
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:21:58.158526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.16
 ---- batch: 020 ----
mean loss: 158.21
 ---- batch: 030 ----
mean loss: 153.34
train mean loss: 153.94
epoch train time: 0:00:01.438782
elapsed time: 0:01:32.248626
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:21:59.597507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.62
 ---- batch: 020 ----
mean loss: 162.92
 ---- batch: 030 ----
mean loss: 159.35
train mean loss: 160.97
epoch train time: 0:00:01.443830
elapsed time: 0:01:33.692626
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:22:01.041505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.60
 ---- batch: 020 ----
mean loss: 156.71
 ---- batch: 030 ----
mean loss: 154.80
train mean loss: 154.39
epoch train time: 0:00:01.434686
elapsed time: 0:01:35.127466
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:22:02.476344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.12
 ---- batch: 020 ----
mean loss: 158.57
 ---- batch: 030 ----
mean loss: 153.87
train mean loss: 155.26
epoch train time: 0:00:01.441841
elapsed time: 0:01:36.569495
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:22:03.918360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.39
 ---- batch: 020 ----
mean loss: 156.77
 ---- batch: 030 ----
mean loss: 156.94
train mean loss: 160.42
epoch train time: 0:00:01.443733
elapsed time: 0:01:38.013427
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:22:05.362308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.09
 ---- batch: 020 ----
mean loss: 152.49
 ---- batch: 030 ----
mean loss: 151.85
train mean loss: 153.15
epoch train time: 0:00:01.445556
elapsed time: 0:01:39.459172
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:22:06.808051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.14
 ---- batch: 020 ----
mean loss: 157.25
 ---- batch: 030 ----
mean loss: 160.96
train mean loss: 157.20
epoch train time: 0:00:01.441051
elapsed time: 0:01:40.900382
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:22:08.249273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.18
 ---- batch: 020 ----
mean loss: 154.68
 ---- batch: 030 ----
mean loss: 157.99
train mean loss: 156.46
epoch train time: 0:00:01.434592
elapsed time: 0:01:42.335169
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:22:09.684047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.03
 ---- batch: 020 ----
mean loss: 162.77
 ---- batch: 030 ----
mean loss: 153.68
train mean loss: 158.37
epoch train time: 0:00:01.436885
elapsed time: 0:01:43.772210
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:22:11.121109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.29
 ---- batch: 020 ----
mean loss: 148.61
 ---- batch: 030 ----
mean loss: 149.15
train mean loss: 149.90
epoch train time: 0:00:01.436236
elapsed time: 0:01:45.208639
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:22:12.557546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.56
 ---- batch: 020 ----
mean loss: 147.94
 ---- batch: 030 ----
mean loss: 152.44
train mean loss: 150.70
epoch train time: 0:00:01.439780
elapsed time: 0:01:46.648605
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:22:13.997482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.89
 ---- batch: 020 ----
mean loss: 150.50
 ---- batch: 030 ----
mean loss: 153.17
train mean loss: 152.29
epoch train time: 0:00:01.436219
elapsed time: 0:01:48.085004
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:22:15.433914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.30
 ---- batch: 020 ----
mean loss: 154.70
 ---- batch: 030 ----
mean loss: 154.73
train mean loss: 153.90
epoch train time: 0:00:01.438470
elapsed time: 0:01:49.523666
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:22:16.872545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.29
 ---- batch: 020 ----
mean loss: 148.09
 ---- batch: 030 ----
mean loss: 152.63
train mean loss: 153.09
epoch train time: 0:00:01.440309
elapsed time: 0:01:50.964152
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:22:18.313033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.25
 ---- batch: 020 ----
mean loss: 152.17
 ---- batch: 030 ----
mean loss: 154.37
train mean loss: 150.64
epoch train time: 0:00:01.441275
elapsed time: 0:01:52.405607
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:22:19.754486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.57
 ---- batch: 020 ----
mean loss: 145.76
 ---- batch: 030 ----
mean loss: 151.19
train mean loss: 148.50
epoch train time: 0:00:01.443162
elapsed time: 0:01:53.848927
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:22:21.197825
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.56
 ---- batch: 020 ----
mean loss: 150.93
 ---- batch: 030 ----
mean loss: 151.25
train mean loss: 151.04
epoch train time: 0:00:01.437222
elapsed time: 0:01:55.286357
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:22:22.635242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.52
 ---- batch: 020 ----
mean loss: 152.64
 ---- batch: 030 ----
mean loss: 152.77
train mean loss: 150.55
epoch train time: 0:00:01.437910
elapsed time: 0:01:56.724459
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:22:24.073339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.74
 ---- batch: 020 ----
mean loss: 159.61
 ---- batch: 030 ----
mean loss: 149.54
train mean loss: 150.82
epoch train time: 0:00:01.438246
elapsed time: 0:01:58.162865
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:22:25.511744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.03
 ---- batch: 020 ----
mean loss: 144.92
 ---- batch: 030 ----
mean loss: 150.05
train mean loss: 149.50
epoch train time: 0:00:01.439645
elapsed time: 0:01:59.602700
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:22:26.951580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.16
 ---- batch: 020 ----
mean loss: 150.10
 ---- batch: 030 ----
mean loss: 147.29
train mean loss: 147.41
epoch train time: 0:00:01.438088
elapsed time: 0:02:01.040961
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:22:28.389854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.46
 ---- batch: 020 ----
mean loss: 146.38
 ---- batch: 030 ----
mean loss: 148.16
train mean loss: 150.41
epoch train time: 0:00:01.438297
elapsed time: 0:02:02.479442
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:22:29.828334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.67
 ---- batch: 020 ----
mean loss: 145.20
 ---- batch: 030 ----
mean loss: 153.20
train mean loss: 148.91
epoch train time: 0:00:01.437237
elapsed time: 0:02:03.916878
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:22:31.265785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.02
 ---- batch: 020 ----
mean loss: 145.75
 ---- batch: 030 ----
mean loss: 149.12
train mean loss: 148.78
epoch train time: 0:00:01.433535
elapsed time: 0:02:05.350602
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:22:32.699483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.17
 ---- batch: 020 ----
mean loss: 146.75
 ---- batch: 030 ----
mean loss: 149.34
train mean loss: 146.09
epoch train time: 0:00:01.438352
elapsed time: 0:02:06.789123
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:22:34.138005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.14
 ---- batch: 020 ----
mean loss: 146.71
 ---- batch: 030 ----
mean loss: 145.85
train mean loss: 147.10
epoch train time: 0:00:01.437304
elapsed time: 0:02:08.226595
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:22:35.575475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.11
 ---- batch: 020 ----
mean loss: 146.38
 ---- batch: 030 ----
mean loss: 151.50
train mean loss: 147.26
epoch train time: 0:00:01.434813
elapsed time: 0:02:09.661567
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:22:37.010448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.65
 ---- batch: 020 ----
mean loss: 147.97
 ---- batch: 030 ----
mean loss: 143.82
train mean loss: 146.14
epoch train time: 0:00:01.437193
elapsed time: 0:02:11.098917
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:22:38.447793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.01
 ---- batch: 020 ----
mean loss: 148.68
 ---- batch: 030 ----
mean loss: 150.41
train mean loss: 149.48
epoch train time: 0:00:01.438635
elapsed time: 0:02:12.537719
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:22:39.886599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.81
 ---- batch: 020 ----
mean loss: 147.41
 ---- batch: 030 ----
mean loss: 145.69
train mean loss: 146.54
epoch train time: 0:00:01.437867
elapsed time: 0:02:13.975745
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:22:41.324624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.90
 ---- batch: 020 ----
mean loss: 144.81
 ---- batch: 030 ----
mean loss: 140.56
train mean loss: 143.07
epoch train time: 0:00:01.441554
elapsed time: 0:02:15.417489
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:22:42.766369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.16
 ---- batch: 020 ----
mean loss: 142.18
 ---- batch: 030 ----
mean loss: 149.34
train mean loss: 146.95
epoch train time: 0:00:01.436890
elapsed time: 0:02:16.854560
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:22:44.203450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.08
 ---- batch: 020 ----
mean loss: 145.47
 ---- batch: 030 ----
mean loss: 144.11
train mean loss: 146.55
epoch train time: 0:00:01.439433
elapsed time: 0:02:18.294185
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:22:45.643066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.30
 ---- batch: 020 ----
mean loss: 138.77
 ---- batch: 030 ----
mean loss: 146.75
train mean loss: 144.22
epoch train time: 0:00:01.441459
elapsed time: 0:02:19.735805
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:22:47.084683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.11
 ---- batch: 020 ----
mean loss: 141.04
 ---- batch: 030 ----
mean loss: 145.18
train mean loss: 144.30
epoch train time: 0:00:01.437024
elapsed time: 0:02:21.172988
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:22:48.521888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.69
 ---- batch: 020 ----
mean loss: 143.30
 ---- batch: 030 ----
mean loss: 148.69
train mean loss: 145.50
epoch train time: 0:00:01.442306
elapsed time: 0:02:22.615476
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:22:49.964385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.07
 ---- batch: 020 ----
mean loss: 149.68
 ---- batch: 030 ----
mean loss: 137.58
train mean loss: 144.41
epoch train time: 0:00:01.441324
elapsed time: 0:02:24.056991
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:22:51.405869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.04
 ---- batch: 020 ----
mean loss: 146.84
 ---- batch: 030 ----
mean loss: 148.99
train mean loss: 146.89
epoch train time: 0:00:01.438095
elapsed time: 0:02:25.495259
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:22:52.844162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.27
 ---- batch: 020 ----
mean loss: 143.61
 ---- batch: 030 ----
mean loss: 144.88
train mean loss: 143.57
epoch train time: 0:00:01.436361
elapsed time: 0:02:26.931850
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:22:54.280746
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.35
 ---- batch: 020 ----
mean loss: 143.38
 ---- batch: 030 ----
mean loss: 147.13
train mean loss: 145.31
epoch train time: 0:00:01.438954
elapsed time: 0:02:28.370986
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:22:55.719863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.42
 ---- batch: 020 ----
mean loss: 142.39
 ---- batch: 030 ----
mean loss: 144.60
train mean loss: 144.02
epoch train time: 0:00:01.439476
elapsed time: 0:02:29.810620
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:22:57.159497
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.92
 ---- batch: 020 ----
mean loss: 139.70
 ---- batch: 030 ----
mean loss: 141.93
train mean loss: 141.92
epoch train time: 0:00:01.438418
elapsed time: 0:02:31.249193
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:22:58.598072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.38
 ---- batch: 020 ----
mean loss: 144.27
 ---- batch: 030 ----
mean loss: 146.57
train mean loss: 146.23
epoch train time: 0:00:01.440624
elapsed time: 0:02:32.689974
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:23:00.038850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.48
 ---- batch: 020 ----
mean loss: 145.42
 ---- batch: 030 ----
mean loss: 137.49
train mean loss: 143.28
epoch train time: 0:00:01.440198
elapsed time: 0:02:34.130322
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:23:01.479203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.96
 ---- batch: 020 ----
mean loss: 138.34
 ---- batch: 030 ----
mean loss: 139.30
train mean loss: 142.86
epoch train time: 0:00:01.439458
elapsed time: 0:02:35.569955
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:23:02.918839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.99
 ---- batch: 020 ----
mean loss: 140.59
 ---- batch: 030 ----
mean loss: 135.72
train mean loss: 141.21
epoch train time: 0:00:01.440779
elapsed time: 0:02:37.010907
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:23:04.359782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.05
 ---- batch: 020 ----
mean loss: 136.81
 ---- batch: 030 ----
mean loss: 140.77
train mean loss: 138.76
epoch train time: 0:00:01.433232
elapsed time: 0:02:38.444314
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:23:05.793207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.45
 ---- batch: 020 ----
mean loss: 142.89
 ---- batch: 030 ----
mean loss: 139.70
train mean loss: 139.96
epoch train time: 0:00:01.438653
elapsed time: 0:02:39.883145
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:23:07.232023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.18
 ---- batch: 020 ----
mean loss: 136.89
 ---- batch: 030 ----
mean loss: 142.38
train mean loss: 140.87
epoch train time: 0:00:01.435055
elapsed time: 0:02:41.318354
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:23:08.667232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.26
 ---- batch: 020 ----
mean loss: 143.61
 ---- batch: 030 ----
mean loss: 145.21
train mean loss: 145.82
epoch train time: 0:00:01.436401
elapsed time: 0:02:42.754907
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:23:10.103802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.76
 ---- batch: 020 ----
mean loss: 145.15
 ---- batch: 030 ----
mean loss: 142.04
train mean loss: 143.26
epoch train time: 0:00:01.436659
elapsed time: 0:02:44.191737
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:23:11.540616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.10
 ---- batch: 020 ----
mean loss: 139.66
 ---- batch: 030 ----
mean loss: 138.80
train mean loss: 141.53
epoch train time: 0:00:01.435187
elapsed time: 0:02:45.627091
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:23:12.975952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.63
 ---- batch: 020 ----
mean loss: 142.56
 ---- batch: 030 ----
mean loss: 142.15
train mean loss: 141.51
epoch train time: 0:00:01.434861
elapsed time: 0:02:47.062129
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:23:14.411009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.45
 ---- batch: 020 ----
mean loss: 140.96
 ---- batch: 030 ----
mean loss: 138.88
train mean loss: 139.25
epoch train time: 0:00:01.437309
elapsed time: 0:02:48.499622
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:23:15.848528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.66
 ---- batch: 020 ----
mean loss: 139.29
 ---- batch: 030 ----
mean loss: 141.06
train mean loss: 140.18
epoch train time: 0:00:01.435515
elapsed time: 0:02:49.935316
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:23:17.284192
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.42
 ---- batch: 020 ----
mean loss: 137.55
 ---- batch: 030 ----
mean loss: 140.36
train mean loss: 138.64
epoch train time: 0:00:01.439578
elapsed time: 0:02:51.375052
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:23:18.723933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.89
 ---- batch: 020 ----
mean loss: 137.88
 ---- batch: 030 ----
mean loss: 138.01
train mean loss: 141.05
epoch train time: 0:00:01.442071
elapsed time: 0:02:52.817294
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:23:20.166178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.79
 ---- batch: 020 ----
mean loss: 149.29
 ---- batch: 030 ----
mean loss: 143.62
train mean loss: 145.09
epoch train time: 0:00:01.437593
elapsed time: 0:02:54.255051
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:23:21.603927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.14
 ---- batch: 020 ----
mean loss: 136.44
 ---- batch: 030 ----
mean loss: 139.44
train mean loss: 140.89
epoch train time: 0:00:01.436758
elapsed time: 0:02:55.691968
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:23:23.040847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.35
 ---- batch: 020 ----
mean loss: 138.22
 ---- batch: 030 ----
mean loss: 142.84
train mean loss: 141.03
epoch train time: 0:00:01.437245
elapsed time: 0:02:57.129382
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:23:24.478258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.88
 ---- batch: 020 ----
mean loss: 136.51
 ---- batch: 030 ----
mean loss: 142.07
train mean loss: 139.91
epoch train time: 0:00:01.439155
elapsed time: 0:02:58.568700
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:23:25.917577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.67
 ---- batch: 020 ----
mean loss: 143.95
 ---- batch: 030 ----
mean loss: 141.93
train mean loss: 141.24
epoch train time: 0:00:01.438257
elapsed time: 0:03:00.007118
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:23:27.355997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.74
 ---- batch: 020 ----
mean loss: 133.50
 ---- batch: 030 ----
mean loss: 139.50
train mean loss: 136.92
epoch train time: 0:00:01.435395
elapsed time: 0:03:01.442701
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:23:28.791599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.51
 ---- batch: 020 ----
mean loss: 139.24
 ---- batch: 030 ----
mean loss: 139.23
train mean loss: 139.40
epoch train time: 0:00:01.436861
elapsed time: 0:03:02.879753
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:23:30.228632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.05
 ---- batch: 020 ----
mean loss: 139.54
 ---- batch: 030 ----
mean loss: 143.48
train mean loss: 140.48
epoch train time: 0:00:01.438023
elapsed time: 0:03:04.317931
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:23:31.666808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.40
 ---- batch: 020 ----
mean loss: 139.09
 ---- batch: 030 ----
mean loss: 134.73
train mean loss: 137.99
epoch train time: 0:00:01.434627
elapsed time: 0:03:05.752717
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:23:33.101596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.24
 ---- batch: 020 ----
mean loss: 138.41
 ---- batch: 030 ----
mean loss: 140.43
train mean loss: 137.41
epoch train time: 0:00:01.434901
elapsed time: 0:03:07.187772
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:23:34.536651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.75
 ---- batch: 020 ----
mean loss: 141.93
 ---- batch: 030 ----
mean loss: 143.02
train mean loss: 139.81
epoch train time: 0:00:01.438559
elapsed time: 0:03:08.626489
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:23:35.975366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.43
 ---- batch: 020 ----
mean loss: 139.95
 ---- batch: 030 ----
mean loss: 137.73
train mean loss: 139.44
epoch train time: 0:00:01.438353
elapsed time: 0:03:10.065019
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:23:37.413903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.97
 ---- batch: 020 ----
mean loss: 140.06
 ---- batch: 030 ----
mean loss: 137.09
train mean loss: 138.27
epoch train time: 0:00:01.439266
elapsed time: 0:03:11.504459
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:23:38.853359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.15
 ---- batch: 020 ----
mean loss: 139.19
 ---- batch: 030 ----
mean loss: 141.27
train mean loss: 141.51
epoch train time: 0:00:01.435665
elapsed time: 0:03:12.940317
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:23:40.289200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.77
 ---- batch: 020 ----
mean loss: 137.17
 ---- batch: 030 ----
mean loss: 136.59
train mean loss: 137.28
epoch train time: 0:00:01.439776
elapsed time: 0:03:14.380372
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:23:41.729249
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.29
 ---- batch: 020 ----
mean loss: 139.36
 ---- batch: 030 ----
mean loss: 146.00
train mean loss: 141.35
epoch train time: 0:00:01.440268
elapsed time: 0:03:15.820808
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:23:43.169692
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.88
 ---- batch: 020 ----
mean loss: 140.45
 ---- batch: 030 ----
mean loss: 137.58
train mean loss: 138.19
epoch train time: 0:00:01.437267
elapsed time: 0:03:17.258261
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:23:44.607138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.83
 ---- batch: 020 ----
mean loss: 136.03
 ---- batch: 030 ----
mean loss: 135.54
train mean loss: 137.37
epoch train time: 0:00:01.437622
elapsed time: 0:03:18.696041
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:23:46.044933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.15
 ---- batch: 020 ----
mean loss: 137.27
 ---- batch: 030 ----
mean loss: 142.69
train mean loss: 140.86
epoch train time: 0:00:01.436450
elapsed time: 0:03:20.132681
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:23:47.481562
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.58
 ---- batch: 020 ----
mean loss: 132.54
 ---- batch: 030 ----
mean loss: 138.27
train mean loss: 135.84
epoch train time: 0:00:01.439029
elapsed time: 0:03:21.571879
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:23:48.920780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.54
 ---- batch: 020 ----
mean loss: 138.05
 ---- batch: 030 ----
mean loss: 137.02
train mean loss: 138.28
epoch train time: 0:00:01.435656
elapsed time: 0:03:23.007738
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:23:50.356620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.50
 ---- batch: 020 ----
mean loss: 147.98
 ---- batch: 030 ----
mean loss: 138.77
train mean loss: 140.25
epoch train time: 0:00:01.433127
elapsed time: 0:03:24.441032
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:23:51.789910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.90
 ---- batch: 020 ----
mean loss: 134.93
 ---- batch: 030 ----
mean loss: 133.66
train mean loss: 134.98
epoch train time: 0:00:01.443642
elapsed time: 0:03:25.884861
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:23:53.233741
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.74
 ---- batch: 020 ----
mean loss: 133.11
 ---- batch: 030 ----
mean loss: 137.99
train mean loss: 136.14
epoch train time: 0:00:01.437233
elapsed time: 0:03:27.322259
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:23:54.671135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.07
 ---- batch: 020 ----
mean loss: 133.63
 ---- batch: 030 ----
mean loss: 136.38
train mean loss: 136.27
epoch train time: 0:00:01.436750
elapsed time: 0:03:28.759198
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:23:56.108085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.98
 ---- batch: 020 ----
mean loss: 139.17
 ---- batch: 030 ----
mean loss: 135.24
train mean loss: 135.35
epoch train time: 0:00:01.435675
elapsed time: 0:03:30.195063
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:23:57.543938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.96
 ---- batch: 020 ----
mean loss: 139.76
 ---- batch: 030 ----
mean loss: 140.28
train mean loss: 140.09
epoch train time: 0:00:01.438949
elapsed time: 0:03:31.634179
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:23:58.983059
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.51
 ---- batch: 020 ----
mean loss: 135.77
 ---- batch: 030 ----
mean loss: 139.06
train mean loss: 136.33
epoch train time: 0:00:01.440666
elapsed time: 0:03:33.075026
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:24:00.423915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.19
 ---- batch: 020 ----
mean loss: 135.92
 ---- batch: 030 ----
mean loss: 142.04
train mean loss: 138.32
epoch train time: 0:00:01.440727
elapsed time: 0:03:34.515928
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:24:01.864809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.34
 ---- batch: 020 ----
mean loss: 133.80
 ---- batch: 030 ----
mean loss: 138.84
train mean loss: 138.97
epoch train time: 0:00:01.434400
elapsed time: 0:03:35.950503
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:24:03.299380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.12
 ---- batch: 020 ----
mean loss: 140.93
 ---- batch: 030 ----
mean loss: 144.66
train mean loss: 139.27
epoch train time: 0:00:01.434589
elapsed time: 0:03:37.385247
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:24:04.734123
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.52
 ---- batch: 020 ----
mean loss: 138.08
 ---- batch: 030 ----
mean loss: 137.66
train mean loss: 137.28
epoch train time: 0:00:01.439477
elapsed time: 0:03:38.824911
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:24:06.173791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.52
 ---- batch: 020 ----
mean loss: 129.81
 ---- batch: 030 ----
mean loss: 132.70
train mean loss: 133.40
epoch train time: 0:00:01.439579
elapsed time: 0:03:40.264645
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:24:07.613536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.39
 ---- batch: 020 ----
mean loss: 141.73
 ---- batch: 030 ----
mean loss: 135.96
train mean loss: 137.37
epoch train time: 0:00:01.435947
elapsed time: 0:03:41.700756
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:24:09.049648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.31
 ---- batch: 020 ----
mean loss: 136.14
 ---- batch: 030 ----
mean loss: 132.66
train mean loss: 134.36
epoch train time: 0:00:01.437312
elapsed time: 0:03:43.138238
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:24:10.487113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.43
 ---- batch: 020 ----
mean loss: 134.93
 ---- batch: 030 ----
mean loss: 135.49
train mean loss: 133.84
epoch train time: 0:00:01.437867
elapsed time: 0:03:44.576258
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:24:11.925154
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.78
 ---- batch: 020 ----
mean loss: 135.79
 ---- batch: 030 ----
mean loss: 139.12
train mean loss: 137.51
epoch train time: 0:00:01.438987
elapsed time: 0:03:46.015437
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:24:13.364304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.45
 ---- batch: 020 ----
mean loss: 133.67
 ---- batch: 030 ----
mean loss: 134.42
train mean loss: 134.93
epoch train time: 0:00:01.437168
elapsed time: 0:03:47.452760
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:24:14.801672
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.89
 ---- batch: 020 ----
mean loss: 139.54
 ---- batch: 030 ----
mean loss: 140.39
train mean loss: 136.58
epoch train time: 0:00:01.439575
elapsed time: 0:03:48.892527
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:24:16.241406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.76
 ---- batch: 020 ----
mean loss: 134.62
 ---- batch: 030 ----
mean loss: 135.22
train mean loss: 135.53
epoch train time: 0:00:01.439335
elapsed time: 0:03:50.332040
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:24:17.680920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.28
 ---- batch: 020 ----
mean loss: 139.64
 ---- batch: 030 ----
mean loss: 131.59
train mean loss: 135.53
epoch train time: 0:00:01.440288
elapsed time: 0:03:51.772483
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:24:19.121359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.86
 ---- batch: 020 ----
mean loss: 132.61
 ---- batch: 030 ----
mean loss: 137.40
train mean loss: 135.89
epoch train time: 0:00:01.438415
elapsed time: 0:03:53.211055
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:24:20.559936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.93
 ---- batch: 020 ----
mean loss: 137.05
 ---- batch: 030 ----
mean loss: 135.43
train mean loss: 139.64
epoch train time: 0:00:01.436376
elapsed time: 0:03:54.647590
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:24:21.996471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.02
 ---- batch: 020 ----
mean loss: 134.84
 ---- batch: 030 ----
mean loss: 135.97
train mean loss: 133.89
epoch train time: 0:00:01.437709
elapsed time: 0:03:56.085465
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:24:23.434367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.59
 ---- batch: 020 ----
mean loss: 135.33
 ---- batch: 030 ----
mean loss: 132.94
train mean loss: 134.71
epoch train time: 0:00:01.441257
elapsed time: 0:03:57.526919
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:24:24.875796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.71
 ---- batch: 020 ----
mean loss: 136.80
 ---- batch: 030 ----
mean loss: 134.61
train mean loss: 136.69
epoch train time: 0:00:01.438926
elapsed time: 0:03:58.966033
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:24:26.314916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.19
 ---- batch: 020 ----
mean loss: 136.57
 ---- batch: 030 ----
mean loss: 133.53
train mean loss: 134.56
epoch train time: 0:00:01.437289
elapsed time: 0:04:00.403511
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:24:27.752408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.23
 ---- batch: 020 ----
mean loss: 141.98
 ---- batch: 030 ----
mean loss: 135.19
train mean loss: 139.08
epoch train time: 0:00:01.438370
elapsed time: 0:04:01.842071
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:24:29.190948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.39
 ---- batch: 020 ----
mean loss: 135.44
 ---- batch: 030 ----
mean loss: 138.21
train mean loss: 136.61
epoch train time: 0:00:01.437406
elapsed time: 0:04:03.279639
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:24:30.628515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.83
 ---- batch: 020 ----
mean loss: 135.48
 ---- batch: 030 ----
mean loss: 135.01
train mean loss: 138.01
epoch train time: 0:00:01.437277
elapsed time: 0:04:04.717079
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:24:32.065957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.75
 ---- batch: 020 ----
mean loss: 136.14
 ---- batch: 030 ----
mean loss: 134.90
train mean loss: 134.53
epoch train time: 0:00:01.444242
elapsed time: 0:04:06.161484
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:24:33.510364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.19
 ---- batch: 020 ----
mean loss: 135.09
 ---- batch: 030 ----
mean loss: 137.17
train mean loss: 134.71
epoch train time: 0:00:01.439096
elapsed time: 0:04:07.600745
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:24:34.949643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.05
 ---- batch: 020 ----
mean loss: 131.24
 ---- batch: 030 ----
mean loss: 128.76
train mean loss: 132.51
epoch train time: 0:00:01.441500
elapsed time: 0:04:09.042436
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:24:36.391330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.99
 ---- batch: 020 ----
mean loss: 130.93
 ---- batch: 030 ----
mean loss: 133.75
train mean loss: 133.15
epoch train time: 0:00:01.438236
elapsed time: 0:04:10.480867
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:24:37.829752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.85
 ---- batch: 020 ----
mean loss: 135.25
 ---- batch: 030 ----
mean loss: 130.86
train mean loss: 132.72
epoch train time: 0:00:01.441157
elapsed time: 0:04:11.922197
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:24:39.271087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.66
 ---- batch: 020 ----
mean loss: 130.73
 ---- batch: 030 ----
mean loss: 128.90
train mean loss: 132.31
epoch train time: 0:00:01.440034
elapsed time: 0:04:13.362425
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:24:40.711304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.76
 ---- batch: 020 ----
mean loss: 130.96
 ---- batch: 030 ----
mean loss: 134.58
train mean loss: 132.93
epoch train time: 0:00:01.436096
elapsed time: 0:04:14.798683
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:24:42.147560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.90
 ---- batch: 020 ----
mean loss: 133.63
 ---- batch: 030 ----
mean loss: 134.44
train mean loss: 135.25
epoch train time: 0:00:01.439318
elapsed time: 0:04:16.238170
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:24:43.587047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.89
 ---- batch: 020 ----
mean loss: 132.25
 ---- batch: 030 ----
mean loss: 130.99
train mean loss: 133.08
epoch train time: 0:00:01.440327
elapsed time: 0:04:17.678682
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:24:45.027557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.68
 ---- batch: 020 ----
mean loss: 134.31
 ---- batch: 030 ----
mean loss: 133.78
train mean loss: 134.93
epoch train time: 0:00:01.440283
elapsed time: 0:04:19.119134
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:24:46.468013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.24
 ---- batch: 020 ----
mean loss: 128.72
 ---- batch: 030 ----
mean loss: 132.97
train mean loss: 133.16
epoch train time: 0:00:01.436207
elapsed time: 0:04:20.555519
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:24:47.904426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.50
 ---- batch: 020 ----
mean loss: 136.12
 ---- batch: 030 ----
mean loss: 134.21
train mean loss: 135.34
epoch train time: 0:00:01.437491
elapsed time: 0:04:21.993218
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:24:49.342084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.35
 ---- batch: 020 ----
mean loss: 131.43
 ---- batch: 030 ----
mean loss: 133.44
train mean loss: 131.90
epoch train time: 0:00:01.439659
elapsed time: 0:04:23.433045
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:24:50.781930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.84
 ---- batch: 020 ----
mean loss: 131.87
 ---- batch: 030 ----
mean loss: 128.51
train mean loss: 129.87
epoch train time: 0:00:01.440775
elapsed time: 0:04:24.873983
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:24:52.222860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.30
 ---- batch: 020 ----
mean loss: 134.67
 ---- batch: 030 ----
mean loss: 133.93
train mean loss: 133.21
epoch train time: 0:00:01.440365
elapsed time: 0:04:26.314518
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:24:53.663414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.28
 ---- batch: 020 ----
mean loss: 135.17
 ---- batch: 030 ----
mean loss: 135.64
train mean loss: 132.78
epoch train time: 0:00:01.437039
elapsed time: 0:04:27.751727
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:24:55.100604
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.88
 ---- batch: 020 ----
mean loss: 133.18
 ---- batch: 030 ----
mean loss: 133.25
train mean loss: 133.57
epoch train time: 0:00:01.437477
elapsed time: 0:04:29.189361
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:24:56.538244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.58
 ---- batch: 020 ----
mean loss: 131.40
 ---- batch: 030 ----
mean loss: 133.67
train mean loss: 134.24
epoch train time: 0:00:01.440277
elapsed time: 0:04:30.629827
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:24:57.978703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.01
 ---- batch: 020 ----
mean loss: 131.23
 ---- batch: 030 ----
mean loss: 130.53
train mean loss: 129.98
epoch train time: 0:00:01.437437
elapsed time: 0:04:32.067414
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:24:59.416290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.20
 ---- batch: 020 ----
mean loss: 131.90
 ---- batch: 030 ----
mean loss: 132.14
train mean loss: 130.92
epoch train time: 0:00:01.439642
elapsed time: 0:04:33.507219
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:25:00.856097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.38
 ---- batch: 020 ----
mean loss: 130.62
 ---- batch: 030 ----
mean loss: 127.40
train mean loss: 129.26
epoch train time: 0:00:01.439405
elapsed time: 0:04:34.946781
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:25:02.295675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.48
 ---- batch: 020 ----
mean loss: 132.34
 ---- batch: 030 ----
mean loss: 136.15
train mean loss: 133.75
epoch train time: 0:00:01.440850
elapsed time: 0:04:36.387803
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:25:03.736680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.62
 ---- batch: 020 ----
mean loss: 133.74
 ---- batch: 030 ----
mean loss: 136.08
train mean loss: 134.91
epoch train time: 0:00:01.437151
elapsed time: 0:04:37.825113
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:25:05.173994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.20
 ---- batch: 020 ----
mean loss: 133.66
 ---- batch: 030 ----
mean loss: 124.83
train mean loss: 130.51
epoch train time: 0:00:01.439904
elapsed time: 0:04:39.265183
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:25:06.614078
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.64
 ---- batch: 020 ----
mean loss: 132.94
 ---- batch: 030 ----
mean loss: 127.95
train mean loss: 131.22
epoch train time: 0:00:01.437533
elapsed time: 0:04:40.702907
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:25:08.051789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.14
 ---- batch: 020 ----
mean loss: 134.08
 ---- batch: 030 ----
mean loss: 134.03
train mean loss: 132.31
epoch train time: 0:00:01.440070
elapsed time: 0:04:42.143139
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:25:09.492019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.19
 ---- batch: 020 ----
mean loss: 129.88
 ---- batch: 030 ----
mean loss: 132.28
train mean loss: 132.37
epoch train time: 0:00:01.438289
elapsed time: 0:04:43.581595
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:25:10.930474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.32
 ---- batch: 020 ----
mean loss: 135.15
 ---- batch: 030 ----
mean loss: 136.65
train mean loss: 133.77
epoch train time: 0:00:01.436879
elapsed time: 0:04:45.018632
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:25:12.367511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.29
 ---- batch: 020 ----
mean loss: 126.20
 ---- batch: 030 ----
mean loss: 130.35
train mean loss: 129.26
epoch train time: 0:00:01.438168
elapsed time: 0:04:46.457011
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:25:13.805886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.60
 ---- batch: 020 ----
mean loss: 129.58
 ---- batch: 030 ----
mean loss: 131.79
train mean loss: 131.51
epoch train time: 0:00:01.444901
elapsed time: 0:04:47.902099
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:25:15.250983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.12
 ---- batch: 020 ----
mean loss: 129.94
 ---- batch: 030 ----
mean loss: 131.06
train mean loss: 130.61
epoch train time: 0:00:01.450428
elapsed time: 0:04:49.352720
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:25:16.701627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.40
 ---- batch: 020 ----
mean loss: 131.29
 ---- batch: 030 ----
mean loss: 129.18
train mean loss: 129.77
epoch train time: 0:00:01.439501
elapsed time: 0:04:50.792408
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:25:18.141286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.69
 ---- batch: 020 ----
mean loss: 133.05
 ---- batch: 030 ----
mean loss: 136.86
train mean loss: 134.26
epoch train time: 0:00:01.438720
elapsed time: 0:04:52.231283
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:25:19.580165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.05
 ---- batch: 020 ----
mean loss: 129.94
 ---- batch: 030 ----
mean loss: 127.23
train mean loss: 130.73
epoch train time: 0:00:01.438343
elapsed time: 0:04:53.669807
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:25:21.018690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.25
 ---- batch: 020 ----
mean loss: 135.54
 ---- batch: 030 ----
mean loss: 128.64
train mean loss: 133.73
epoch train time: 0:00:01.441502
elapsed time: 0:04:55.111473
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:25:22.460352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.91
 ---- batch: 020 ----
mean loss: 133.38
 ---- batch: 030 ----
mean loss: 133.25
train mean loss: 132.17
epoch train time: 0:00:01.436315
elapsed time: 0:04:56.547949
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:25:23.896823
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.18
 ---- batch: 020 ----
mean loss: 126.78
 ---- batch: 030 ----
mean loss: 134.57
train mean loss: 130.54
epoch train time: 0:00:01.439681
elapsed time: 0:04:57.987783
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:25:25.336661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.97
 ---- batch: 020 ----
mean loss: 134.84
 ---- batch: 030 ----
mean loss: 136.41
train mean loss: 133.84
epoch train time: 0:00:01.439862
elapsed time: 0:04:59.427844
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:25:26.776768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.89
 ---- batch: 020 ----
mean loss: 131.81
 ---- batch: 030 ----
mean loss: 130.69
train mean loss: 131.41
epoch train time: 0:00:01.439115
elapsed time: 0:05:00.867159
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:25:28.216039
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.08
 ---- batch: 020 ----
mean loss: 130.93
 ---- batch: 030 ----
mean loss: 132.70
train mean loss: 129.82
epoch train time: 0:00:01.438967
elapsed time: 0:05:02.306342
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:25:29.655227
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.28
 ---- batch: 020 ----
mean loss: 128.66
 ---- batch: 030 ----
mean loss: 128.53
train mean loss: 129.51
epoch train time: 0:00:01.436609
elapsed time: 0:05:03.743119
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:25:31.091999
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.39
 ---- batch: 020 ----
mean loss: 128.76
 ---- batch: 030 ----
mean loss: 126.56
train mean loss: 128.97
epoch train time: 0:00:01.438662
elapsed time: 0:05:05.181964
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:25:32.530855
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.50
 ---- batch: 020 ----
mean loss: 128.21
 ---- batch: 030 ----
mean loss: 127.64
train mean loss: 128.20
epoch train time: 0:00:01.441284
elapsed time: 0:05:06.623484
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:25:33.972406
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.77
 ---- batch: 020 ----
mean loss: 129.80
 ---- batch: 030 ----
mean loss: 126.18
train mean loss: 129.51
epoch train time: 0:00:01.439096
elapsed time: 0:05:08.062791
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:25:35.411668
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 126.52
 ---- batch: 020 ----
mean loss: 129.36
 ---- batch: 030 ----
mean loss: 128.00
train mean loss: 128.77
epoch train time: 0:00:01.438791
elapsed time: 0:05:09.501771
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:25:36.850678
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.97
 ---- batch: 020 ----
mean loss: 127.97
 ---- batch: 030 ----
mean loss: 129.52
train mean loss: 130.62
epoch train time: 0:00:01.440362
elapsed time: 0:05:10.942341
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:25:38.291234
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.57
 ---- batch: 020 ----
mean loss: 124.13
 ---- batch: 030 ----
mean loss: 127.78
train mean loss: 128.52
epoch train time: 0:00:01.445127
elapsed time: 0:05:12.387640
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:25:39.736536
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.62
 ---- batch: 020 ----
mean loss: 128.61
 ---- batch: 030 ----
mean loss: 128.16
train mean loss: 128.22
epoch train time: 0:00:01.442077
elapsed time: 0:05:13.829892
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:25:41.178813
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.58
 ---- batch: 020 ----
mean loss: 128.72
 ---- batch: 030 ----
mean loss: 126.69
train mean loss: 128.30
epoch train time: 0:00:01.439984
elapsed time: 0:05:15.270075
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:25:42.618952
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.88
 ---- batch: 020 ----
mean loss: 129.24
 ---- batch: 030 ----
mean loss: 129.08
train mean loss: 128.96
epoch train time: 0:00:01.441561
elapsed time: 0:05:16.711799
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:25:44.060679
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.07
 ---- batch: 020 ----
mean loss: 129.72
 ---- batch: 030 ----
mean loss: 127.72
train mean loss: 128.00
epoch train time: 0:00:01.441562
elapsed time: 0:05:18.153523
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:25:45.502437
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.58
 ---- batch: 020 ----
mean loss: 130.04
 ---- batch: 030 ----
mean loss: 124.38
train mean loss: 130.01
epoch train time: 0:00:01.441242
elapsed time: 0:05:19.594960
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:25:46.943838
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.50
 ---- batch: 020 ----
mean loss: 132.05
 ---- batch: 030 ----
mean loss: 126.26
train mean loss: 128.84
epoch train time: 0:00:01.441357
elapsed time: 0:05:21.036476
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:25:48.385355
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.96
 ---- batch: 020 ----
mean loss: 125.79
 ---- batch: 030 ----
mean loss: 133.23
train mean loss: 129.94
epoch train time: 0:00:01.437462
elapsed time: 0:05:22.474100
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:25:49.822976
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 126.65
 ---- batch: 020 ----
mean loss: 126.99
 ---- batch: 030 ----
mean loss: 129.44
train mean loss: 128.62
epoch train time: 0:00:01.441705
elapsed time: 0:05:23.915959
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:25:51.264837
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.49
 ---- batch: 020 ----
mean loss: 128.40
 ---- batch: 030 ----
mean loss: 129.65
train mean loss: 129.11
epoch train time: 0:00:01.439424
elapsed time: 0:05:25.355546
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:25:52.704429
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.62
 ---- batch: 020 ----
mean loss: 125.75
 ---- batch: 030 ----
mean loss: 129.45
train mean loss: 128.30
epoch train time: 0:00:01.438446
elapsed time: 0:05:26.794159
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:25:54.143036
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 124.08
 ---- batch: 020 ----
mean loss: 133.23
 ---- batch: 030 ----
mean loss: 129.70
train mean loss: 129.21
epoch train time: 0:00:01.438478
elapsed time: 0:05:28.232816
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:25:55.581698
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.28
 ---- batch: 020 ----
mean loss: 129.37
 ---- batch: 030 ----
mean loss: 130.41
train mean loss: 128.83
epoch train time: 0:00:01.440130
elapsed time: 0:05:29.673106
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:25:57.022003
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.54
 ---- batch: 020 ----
mean loss: 128.34
 ---- batch: 030 ----
mean loss: 127.80
train mean loss: 128.20
epoch train time: 0:00:01.438457
elapsed time: 0:05:31.111742
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:25:58.460620
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.69
 ---- batch: 020 ----
mean loss: 127.01
 ---- batch: 030 ----
mean loss: 128.69
train mean loss: 129.28
epoch train time: 0:00:01.439225
elapsed time: 0:05:32.551155
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:25:59.900037
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.82
 ---- batch: 020 ----
mean loss: 131.23
 ---- batch: 030 ----
mean loss: 129.45
train mean loss: 128.72
epoch train time: 0:00:01.443170
elapsed time: 0:05:33.994483
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:26:01.343360
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.54
 ---- batch: 020 ----
mean loss: 130.02
 ---- batch: 030 ----
mean loss: 123.83
train mean loss: 127.96
epoch train time: 0:00:01.441170
elapsed time: 0:05:35.435823
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:26:02.784703
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.64
 ---- batch: 020 ----
mean loss: 124.47
 ---- batch: 030 ----
mean loss: 130.13
train mean loss: 127.76
epoch train time: 0:00:01.440693
elapsed time: 0:05:36.876685
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:26:04.225563
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.99
 ---- batch: 020 ----
mean loss: 128.04
 ---- batch: 030 ----
mean loss: 131.48
train mean loss: 129.18
epoch train time: 0:00:01.438266
elapsed time: 0:05:38.315110
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:26:05.664038
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 125.51
 ---- batch: 020 ----
mean loss: 132.92
 ---- batch: 030 ----
mean loss: 125.38
train mean loss: 127.32
epoch train time: 0:00:01.443099
elapsed time: 0:05:39.758425
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:26:07.107319
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.18
 ---- batch: 020 ----
mean loss: 127.72
 ---- batch: 030 ----
mean loss: 129.80
train mean loss: 128.78
epoch train time: 0:00:01.441178
elapsed time: 0:05:41.199772
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:26:08.548650
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.18
 ---- batch: 020 ----
mean loss: 129.54
 ---- batch: 030 ----
mean loss: 125.60
train mean loss: 128.74
epoch train time: 0:00:01.443833
elapsed time: 0:05:42.643768
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:26:09.992647
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.25
 ---- batch: 020 ----
mean loss: 131.37
 ---- batch: 030 ----
mean loss: 125.36
train mean loss: 129.09
epoch train time: 0:00:01.440490
elapsed time: 0:05:44.084468
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:26:11.433350
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.32
 ---- batch: 020 ----
mean loss: 131.59
 ---- batch: 030 ----
mean loss: 128.46
train mean loss: 129.19
epoch train time: 0:00:01.439609
elapsed time: 0:05:45.524272
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:26:12.873164
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.24
 ---- batch: 020 ----
mean loss: 130.20
 ---- batch: 030 ----
mean loss: 129.34
train mean loss: 128.88
epoch train time: 0:00:01.438044
elapsed time: 0:05:46.962496
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:26:14.311408
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.59
 ---- batch: 020 ----
mean loss: 129.77
 ---- batch: 030 ----
mean loss: 127.15
train mean loss: 128.80
epoch train time: 0:00:01.440897
elapsed time: 0:05:48.403606
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:26:15.752476
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.77
 ---- batch: 020 ----
mean loss: 124.62
 ---- batch: 030 ----
mean loss: 123.97
train mean loss: 127.32
epoch train time: 0:00:01.435381
elapsed time: 0:05:49.839143
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:26:17.188023
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.38
 ---- batch: 020 ----
mean loss: 129.83
 ---- batch: 030 ----
mean loss: 128.82
train mean loss: 129.92
epoch train time: 0:00:01.445362
elapsed time: 0:05:51.284707
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:26:18.633588
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.61
 ---- batch: 020 ----
mean loss: 128.45
 ---- batch: 030 ----
mean loss: 126.91
train mean loss: 128.27
epoch train time: 0:00:01.442877
elapsed time: 0:05:52.727787
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:26:20.076705
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 126.21
 ---- batch: 020 ----
mean loss: 128.79
 ---- batch: 030 ----
mean loss: 127.61
train mean loss: 127.14
epoch train time: 0:00:01.439477
elapsed time: 0:05:54.167461
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:26:21.516338
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 127.69
 ---- batch: 020 ----
mean loss: 124.73
 ---- batch: 030 ----
mean loss: 129.82
train mean loss: 127.91
epoch train time: 0:00:01.439226
elapsed time: 0:05:55.606849
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:26:22.955766
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.25
 ---- batch: 020 ----
mean loss: 127.32
 ---- batch: 030 ----
mean loss: 125.00
train mean loss: 128.95
epoch train time: 0:00:01.440971
elapsed time: 0:05:57.048018
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:26:24.396917
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 128.57
 ---- batch: 020 ----
mean loss: 131.05
 ---- batch: 030 ----
mean loss: 128.55
train mean loss: 128.33
epoch train time: 0:00:01.439997
elapsed time: 0:05:58.488214
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:26:25.837090
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.13
 ---- batch: 020 ----
mean loss: 127.74
 ---- batch: 030 ----
mean loss: 125.69
train mean loss: 128.61
epoch train time: 0:00:01.438572
elapsed time: 0:05:59.926943
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:26:27.275834
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.75
 ---- batch: 020 ----
mean loss: 128.69
 ---- batch: 030 ----
mean loss: 125.10
train mean loss: 127.79
epoch train time: 0:00:01.438832
elapsed time: 0:06:01.365950
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:26:28.714829
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 126.78
 ---- batch: 020 ----
mean loss: 128.50
 ---- batch: 030 ----
mean loss: 131.26
train mean loss: 128.29
epoch train time: 0:00:01.444608
elapsed time: 0:06:02.810718
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:26:30.159595
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 126.29
 ---- batch: 020 ----
mean loss: 129.21
 ---- batch: 030 ----
mean loss: 124.72
train mean loss: 127.44
epoch train time: 0:00:01.440659
elapsed time: 0:06:04.251568
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:26:31.600456
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.27
 ---- batch: 020 ----
mean loss: 128.77
 ---- batch: 030 ----
mean loss: 131.79
train mean loss: 129.39
epoch train time: 0:00:01.440610
elapsed time: 0:06:05.692345
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:26:33.041224
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 124.45
 ---- batch: 020 ----
mean loss: 129.87
 ---- batch: 030 ----
mean loss: 129.29
train mean loss: 127.82
epoch train time: 0:00:01.435795
elapsed time: 0:06:07.128557
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:26:34.477449
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.00
 ---- batch: 020 ----
mean loss: 125.43
 ---- batch: 030 ----
mean loss: 128.44
train mean loss: 128.86
epoch train time: 0:00:01.438902
elapsed time: 0:06:08.567657
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:26:35.916545
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.79
 ---- batch: 020 ----
mean loss: 127.62
 ---- batch: 030 ----
mean loss: 126.11
train mean loss: 128.79
epoch train time: 0:00:01.438666
elapsed time: 0:06:10.006496
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:26:37.355374
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 122.20
 ---- batch: 020 ----
mean loss: 131.95
 ---- batch: 030 ----
mean loss: 130.80
train mean loss: 128.41
epoch train time: 0:00:01.437905
elapsed time: 0:06:11.448181
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_7/checkpoint.pth.tar
**** end time: 2019-09-27 16:26:38.797026 ****
