Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_3', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30635
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 15:54:41.677912 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:54:41.686549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3544.92
 ---- batch: 020 ----
mean loss: 1342.44
 ---- batch: 030 ----
mean loss: 652.83
train mean loss: 1670.06
epoch train time: 0:00:12.920942
elapsed time: 0:00:12.932151
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:54:54.610102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 476.12
 ---- batch: 020 ----
mean loss: 428.12
 ---- batch: 030 ----
mean loss: 382.22
train mean loss: 422.29
epoch train time: 0:00:01.502850
elapsed time: 0:00:14.435164
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:54:56.113141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.37
 ---- batch: 020 ----
mean loss: 340.50
 ---- batch: 030 ----
mean loss: 320.47
train mean loss: 332.90
epoch train time: 0:00:01.425294
elapsed time: 0:00:15.860634
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:54:57.538600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.41
 ---- batch: 020 ----
mean loss: 292.65
 ---- batch: 030 ----
mean loss: 283.23
train mean loss: 288.28
epoch train time: 0:00:01.426650
elapsed time: 0:00:17.287443
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:54:58.965410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.96
 ---- batch: 020 ----
mean loss: 268.31
 ---- batch: 030 ----
mean loss: 258.54
train mean loss: 263.19
epoch train time: 0:00:01.430266
elapsed time: 0:00:18.717869
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:55:00.395834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.02
 ---- batch: 020 ----
mean loss: 250.38
 ---- batch: 030 ----
mean loss: 239.21
train mean loss: 241.99
epoch train time: 0:00:01.428259
elapsed time: 0:00:20.146386
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:55:01.824447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.31
 ---- batch: 020 ----
mean loss: 233.50
 ---- batch: 030 ----
mean loss: 226.34
train mean loss: 231.26
epoch train time: 0:00:01.435002
elapsed time: 0:00:21.581669
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:55:03.259636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.18
 ---- batch: 020 ----
mean loss: 222.60
 ---- batch: 030 ----
mean loss: 218.29
train mean loss: 222.09
epoch train time: 0:00:01.429213
elapsed time: 0:00:23.011049
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:55:04.689033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.26
 ---- batch: 020 ----
mean loss: 212.80
 ---- batch: 030 ----
mean loss: 213.32
train mean loss: 214.23
epoch train time: 0:00:01.434087
elapsed time: 0:00:24.445311
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:55:06.123294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.78
 ---- batch: 020 ----
mean loss: 200.76
 ---- batch: 030 ----
mean loss: 213.47
train mean loss: 207.17
epoch train time: 0:00:01.433108
elapsed time: 0:00:25.878599
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:55:07.556570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.39
 ---- batch: 020 ----
mean loss: 199.64
 ---- batch: 030 ----
mean loss: 199.28
train mean loss: 202.68
epoch train time: 0:00:01.435488
elapsed time: 0:00:27.314255
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:55:08.992233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.47
 ---- batch: 020 ----
mean loss: 194.67
 ---- batch: 030 ----
mean loss: 190.27
train mean loss: 192.50
epoch train time: 0:00:01.434291
elapsed time: 0:00:28.748717
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:55:10.426685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.19
 ---- batch: 020 ----
mean loss: 191.53
 ---- batch: 030 ----
mean loss: 187.68
train mean loss: 191.07
epoch train time: 0:00:01.428790
elapsed time: 0:00:30.177663
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:55:11.855628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.16
 ---- batch: 020 ----
mean loss: 186.11
 ---- batch: 030 ----
mean loss: 187.79
train mean loss: 186.39
epoch train time: 0:00:01.433115
elapsed time: 0:00:31.610932
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:55:13.288898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.34
 ---- batch: 020 ----
mean loss: 184.45
 ---- batch: 030 ----
mean loss: 190.05
train mean loss: 186.78
epoch train time: 0:00:01.436240
elapsed time: 0:00:33.047339
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:55:14.725311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.35
 ---- batch: 020 ----
mean loss: 178.87
 ---- batch: 030 ----
mean loss: 177.33
train mean loss: 179.62
epoch train time: 0:00:01.433676
elapsed time: 0:00:34.481181
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:55:16.159160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.65
 ---- batch: 020 ----
mean loss: 182.42
 ---- batch: 030 ----
mean loss: 186.78
train mean loss: 182.82
epoch train time: 0:00:01.433665
elapsed time: 0:00:35.915055
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:55:17.593024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.87
 ---- batch: 020 ----
mean loss: 173.80
 ---- batch: 030 ----
mean loss: 175.26
train mean loss: 176.52
epoch train time: 0:00:01.433207
elapsed time: 0:00:37.348431
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:55:19.026435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.29
 ---- batch: 020 ----
mean loss: 176.84
 ---- batch: 030 ----
mean loss: 175.71
train mean loss: 176.58
epoch train time: 0:00:01.431018
elapsed time: 0:00:38.779648
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:55:20.457641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.54
 ---- batch: 020 ----
mean loss: 177.61
 ---- batch: 030 ----
mean loss: 180.92
train mean loss: 175.92
epoch train time: 0:00:01.426706
elapsed time: 0:00:40.206558
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:55:21.884529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.73
 ---- batch: 020 ----
mean loss: 172.69
 ---- batch: 030 ----
mean loss: 171.11
train mean loss: 172.25
epoch train time: 0:00:01.425172
elapsed time: 0:00:41.631915
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:55:23.309892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.16
 ---- batch: 020 ----
mean loss: 167.72
 ---- batch: 030 ----
mean loss: 170.77
train mean loss: 170.87
epoch train time: 0:00:01.429139
elapsed time: 0:00:43.061288
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:55:24.739287
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.46
 ---- batch: 020 ----
mean loss: 175.65
 ---- batch: 030 ----
mean loss: 170.58
train mean loss: 170.24
epoch train time: 0:00:01.431911
elapsed time: 0:00:44.493395
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:55:26.171361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.88
 ---- batch: 020 ----
mean loss: 171.61
 ---- batch: 030 ----
mean loss: 169.97
train mean loss: 166.52
epoch train time: 0:00:01.423176
elapsed time: 0:00:45.916731
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:55:27.594698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.43
 ---- batch: 020 ----
mean loss: 166.53
 ---- batch: 030 ----
mean loss: 171.93
train mean loss: 166.14
epoch train time: 0:00:01.429400
elapsed time: 0:00:47.346322
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:55:29.024290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.65
 ---- batch: 020 ----
mean loss: 161.33
 ---- batch: 030 ----
mean loss: 162.02
train mean loss: 164.48
epoch train time: 0:00:01.429283
elapsed time: 0:00:48.775789
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:55:30.453761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.18
 ---- batch: 020 ----
mean loss: 155.53
 ---- batch: 030 ----
mean loss: 178.94
train mean loss: 166.51
epoch train time: 0:00:01.429919
elapsed time: 0:00:50.205879
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:55:31.883848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.36
 ---- batch: 020 ----
mean loss: 162.67
 ---- batch: 030 ----
mean loss: 157.77
train mean loss: 160.22
epoch train time: 0:00:01.429221
elapsed time: 0:00:51.635264
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:55:33.313230
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.04
 ---- batch: 020 ----
mean loss: 154.73
 ---- batch: 030 ----
mean loss: 158.86
train mean loss: 158.82
epoch train time: 0:00:01.431016
elapsed time: 0:00:53.066442
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:55:34.744411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.16
 ---- batch: 020 ----
mean loss: 168.19
 ---- batch: 030 ----
mean loss: 155.71
train mean loss: 162.09
epoch train time: 0:00:01.430688
elapsed time: 0:00:54.497311
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:55:36.175280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.04
 ---- batch: 020 ----
mean loss: 163.26
 ---- batch: 030 ----
mean loss: 162.70
train mean loss: 160.92
epoch train time: 0:00:01.430092
elapsed time: 0:00:55.927589
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:55:37.605578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.94
 ---- batch: 020 ----
mean loss: 159.20
 ---- batch: 030 ----
mean loss: 158.64
train mean loss: 158.56
epoch train time: 0:00:01.433113
elapsed time: 0:00:57.360894
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:55:39.038862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.79
 ---- batch: 020 ----
mean loss: 153.07
 ---- batch: 030 ----
mean loss: 156.61
train mean loss: 154.70
epoch train time: 0:00:01.430903
elapsed time: 0:00:58.791983
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:55:40.469954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.36
 ---- batch: 020 ----
mean loss: 160.45
 ---- batch: 030 ----
mean loss: 161.62
train mean loss: 156.84
epoch train time: 0:00:01.450270
elapsed time: 0:01:00.242447
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:55:41.920447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.01
 ---- batch: 020 ----
mean loss: 158.11
 ---- batch: 030 ----
mean loss: 153.04
train mean loss: 154.62
epoch train time: 0:00:01.429634
elapsed time: 0:01:01.672281
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:55:43.350276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.81
 ---- batch: 020 ----
mean loss: 162.37
 ---- batch: 030 ----
mean loss: 152.74
train mean loss: 155.52
epoch train time: 0:00:01.425175
elapsed time: 0:01:03.097666
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:55:44.775634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.86
 ---- batch: 020 ----
mean loss: 151.09
 ---- batch: 030 ----
mean loss: 151.88
train mean loss: 153.31
epoch train time: 0:00:01.442622
elapsed time: 0:01:04.540483
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:55:46.218455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.65
 ---- batch: 020 ----
mean loss: 147.05
 ---- batch: 030 ----
mean loss: 154.38
train mean loss: 152.63
epoch train time: 0:00:01.431895
elapsed time: 0:01:05.972566
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:55:47.650546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.03
 ---- batch: 020 ----
mean loss: 151.75
 ---- batch: 030 ----
mean loss: 178.12
train mean loss: 162.28
epoch train time: 0:00:01.426205
elapsed time: 0:01:07.398971
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:55:49.076941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.22
 ---- batch: 020 ----
mean loss: 158.27
 ---- batch: 030 ----
mean loss: 153.32
train mean loss: 158.29
epoch train time: 0:00:01.427414
elapsed time: 0:01:08.826545
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:55:50.504512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.55
 ---- batch: 020 ----
mean loss: 146.34
 ---- batch: 030 ----
mean loss: 147.17
train mean loss: 150.07
epoch train time: 0:00:01.429604
elapsed time: 0:01:10.256331
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:55:51.934299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.34
 ---- batch: 020 ----
mean loss: 156.22
 ---- batch: 030 ----
mean loss: 151.89
train mean loss: 153.65
epoch train time: 0:00:01.430370
elapsed time: 0:01:11.686867
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:55:53.364836
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.26
 ---- batch: 020 ----
mean loss: 152.25
 ---- batch: 030 ----
mean loss: 147.42
train mean loss: 150.76
epoch train time: 0:00:01.431003
elapsed time: 0:01:13.118100
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:55:54.796064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.00
 ---- batch: 020 ----
mean loss: 150.32
 ---- batch: 030 ----
mean loss: 150.60
train mean loss: 150.21
epoch train time: 0:00:01.429690
elapsed time: 0:01:14.547951
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:55:56.225919
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.06
 ---- batch: 020 ----
mean loss: 149.25
 ---- batch: 030 ----
mean loss: 149.86
train mean loss: 149.19
epoch train time: 0:00:01.432427
elapsed time: 0:01:15.980560
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:55:57.658531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.53
 ---- batch: 020 ----
mean loss: 155.55
 ---- batch: 030 ----
mean loss: 147.78
train mean loss: 152.07
epoch train time: 0:00:01.428832
elapsed time: 0:01:17.409609
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:55:59.087581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.45
 ---- batch: 020 ----
mean loss: 144.51
 ---- batch: 030 ----
mean loss: 146.34
train mean loss: 147.24
epoch train time: 0:00:01.428174
elapsed time: 0:01:18.837954
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:56:00.515920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.61
 ---- batch: 020 ----
mean loss: 151.53
 ---- batch: 030 ----
mean loss: 154.27
train mean loss: 152.24
epoch train time: 0:00:01.428255
elapsed time: 0:01:20.266374
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:56:01.944351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.33
 ---- batch: 020 ----
mean loss: 148.62
 ---- batch: 030 ----
mean loss: 146.81
train mean loss: 148.06
epoch train time: 0:00:01.430836
elapsed time: 0:01:21.697386
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:56:03.375353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.20
 ---- batch: 020 ----
mean loss: 148.00
 ---- batch: 030 ----
mean loss: 147.97
train mean loss: 146.21
epoch train time: 0:00:01.426734
elapsed time: 0:01:23.124295
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:56:04.802274
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.73
 ---- batch: 020 ----
mean loss: 158.77
 ---- batch: 030 ----
mean loss: 158.52
train mean loss: 155.63
epoch train time: 0:00:01.430189
elapsed time: 0:01:24.554683
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:56:06.232683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.00
 ---- batch: 020 ----
mean loss: 152.56
 ---- batch: 030 ----
mean loss: 155.25
train mean loss: 154.54
epoch train time: 0:00:01.431125
elapsed time: 0:01:25.986030
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:56:07.663989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.30
 ---- batch: 020 ----
mean loss: 148.26
 ---- batch: 030 ----
mean loss: 145.38
train mean loss: 147.48
epoch train time: 0:00:01.428693
elapsed time: 0:01:27.414883
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:56:09.092850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.29
 ---- batch: 020 ----
mean loss: 151.01
 ---- batch: 030 ----
mean loss: 151.18
train mean loss: 153.10
epoch train time: 0:00:01.432140
elapsed time: 0:01:28.847205
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:56:10.525174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.02
 ---- batch: 020 ----
mean loss: 148.13
 ---- batch: 030 ----
mean loss: 151.21
train mean loss: 149.09
epoch train time: 0:00:01.424419
elapsed time: 0:01:30.271822
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:56:11.949793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.17
 ---- batch: 020 ----
mean loss: 151.49
 ---- batch: 030 ----
mean loss: 144.65
train mean loss: 146.81
epoch train time: 0:00:01.424715
elapsed time: 0:01:31.696724
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:56:13.374697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.36
 ---- batch: 020 ----
mean loss: 144.92
 ---- batch: 030 ----
mean loss: 149.75
train mean loss: 146.29
epoch train time: 0:00:01.426903
elapsed time: 0:01:33.123836
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:56:14.801807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.75
 ---- batch: 020 ----
mean loss: 155.72
 ---- batch: 030 ----
mean loss: 144.35
train mean loss: 147.30
epoch train time: 0:00:01.434847
elapsed time: 0:01:34.558867
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:56:16.236838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.24
 ---- batch: 020 ----
mean loss: 144.06
 ---- batch: 030 ----
mean loss: 146.23
train mean loss: 144.61
epoch train time: 0:00:01.429595
elapsed time: 0:01:35.988664
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:56:17.666636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.79
 ---- batch: 020 ----
mean loss: 144.95
 ---- batch: 030 ----
mean loss: 154.87
train mean loss: 152.36
epoch train time: 0:00:01.431470
elapsed time: 0:01:37.420313
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:56:19.098283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.73
 ---- batch: 020 ----
mean loss: 147.24
 ---- batch: 030 ----
mean loss: 148.91
train mean loss: 149.23
epoch train time: 0:00:01.425963
elapsed time: 0:01:38.846451
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:56:20.524420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.01
 ---- batch: 020 ----
mean loss: 144.38
 ---- batch: 030 ----
mean loss: 145.92
train mean loss: 147.72
epoch train time: 0:00:01.435161
elapsed time: 0:01:40.281797
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:56:21.959786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.20
 ---- batch: 020 ----
mean loss: 153.13
 ---- batch: 030 ----
mean loss: 156.35
train mean loss: 154.74
epoch train time: 0:00:01.430169
elapsed time: 0:01:41.712163
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:56:23.390130
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.48
 ---- batch: 020 ----
mean loss: 149.45
 ---- batch: 030 ----
mean loss: 151.51
train mean loss: 149.28
epoch train time: 0:00:01.431706
elapsed time: 0:01:43.144069
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:56:24.822036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.32
 ---- batch: 020 ----
mean loss: 144.84
 ---- batch: 030 ----
mean loss: 142.14
train mean loss: 145.15
epoch train time: 0:00:01.431484
elapsed time: 0:01:44.575758
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:56:26.253730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.28
 ---- batch: 020 ----
mean loss: 147.89
 ---- batch: 030 ----
mean loss: 145.46
train mean loss: 147.83
epoch train time: 0:00:01.432625
elapsed time: 0:01:46.008562
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:56:27.686531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.49
 ---- batch: 020 ----
mean loss: 147.46
 ---- batch: 030 ----
mean loss: 148.41
train mean loss: 147.26
epoch train time: 0:00:01.428004
elapsed time: 0:01:47.436749
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:56:29.114717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.54
 ---- batch: 020 ----
mean loss: 145.76
 ---- batch: 030 ----
mean loss: 147.73
train mean loss: 144.58
epoch train time: 0:00:01.435625
elapsed time: 0:01:48.872555
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:56:30.550527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.15
 ---- batch: 020 ----
mean loss: 144.75
 ---- batch: 030 ----
mean loss: 147.87
train mean loss: 148.84
epoch train time: 0:00:01.432061
elapsed time: 0:01:50.304787
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:56:31.982756
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.27
 ---- batch: 020 ----
mean loss: 146.14
 ---- batch: 030 ----
mean loss: 148.97
train mean loss: 147.91
epoch train time: 0:00:01.426678
elapsed time: 0:01:51.731619
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:56:33.409584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.24
 ---- batch: 020 ----
mean loss: 144.77
 ---- batch: 030 ----
mean loss: 143.47
train mean loss: 144.13
epoch train time: 0:00:01.431347
elapsed time: 0:01:53.163132
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:56:34.841097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.88
 ---- batch: 020 ----
mean loss: 147.08
 ---- batch: 030 ----
mean loss: 144.67
train mean loss: 147.15
epoch train time: 0:00:01.431332
elapsed time: 0:01:54.594640
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:56:36.272607
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.28
 ---- batch: 020 ----
mean loss: 151.97
 ---- batch: 030 ----
mean loss: 148.86
train mean loss: 149.45
epoch train time: 0:00:01.432960
elapsed time: 0:01:56.027783
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:56:37.705772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.12
 ---- batch: 020 ----
mean loss: 151.25
 ---- batch: 030 ----
mean loss: 144.68
train mean loss: 144.84
epoch train time: 0:00:01.430569
elapsed time: 0:01:57.458531
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:56:39.136496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.79
 ---- batch: 020 ----
mean loss: 142.38
 ---- batch: 030 ----
mean loss: 146.56
train mean loss: 144.08
epoch train time: 0:00:01.429788
elapsed time: 0:01:58.888498
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:56:40.566472
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.88
 ---- batch: 020 ----
mean loss: 141.19
 ---- batch: 030 ----
mean loss: 152.77
train mean loss: 146.93
epoch train time: 0:00:01.433028
elapsed time: 0:02:00.321713
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:56:41.999680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.48
 ---- batch: 020 ----
mean loss: 145.37
 ---- batch: 030 ----
mean loss: 144.07
train mean loss: 147.46
epoch train time: 0:00:01.430537
elapsed time: 0:02:01.752413
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:56:43.430382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.97
 ---- batch: 020 ----
mean loss: 140.27
 ---- batch: 030 ----
mean loss: 150.27
train mean loss: 144.78
epoch train time: 0:00:01.428879
elapsed time: 0:02:03.181470
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:56:44.859446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.15
 ---- batch: 020 ----
mean loss: 144.00
 ---- batch: 030 ----
mean loss: 153.43
train mean loss: 148.18
epoch train time: 0:00:01.428913
elapsed time: 0:02:04.610585
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:56:46.288559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.07
 ---- batch: 020 ----
mean loss: 144.20
 ---- batch: 030 ----
mean loss: 145.98
train mean loss: 143.66
epoch train time: 0:00:01.431299
elapsed time: 0:02:06.042070
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:56:47.720035
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.51
 ---- batch: 020 ----
mean loss: 149.50
 ---- batch: 030 ----
mean loss: 142.34
train mean loss: 145.93
epoch train time: 0:00:01.431662
elapsed time: 0:02:07.473894
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:56:49.151866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.79
 ---- batch: 020 ----
mean loss: 148.38
 ---- batch: 030 ----
mean loss: 150.00
train mean loss: 145.67
epoch train time: 0:00:01.425098
elapsed time: 0:02:08.899160
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:56:50.577129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.39
 ---- batch: 020 ----
mean loss: 145.32
 ---- batch: 030 ----
mean loss: 145.49
train mean loss: 144.85
epoch train time: 0:00:01.433112
elapsed time: 0:02:10.332469
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:56:52.010460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.80
 ---- batch: 020 ----
mean loss: 144.69
 ---- batch: 030 ----
mean loss: 148.86
train mean loss: 145.55
epoch train time: 0:00:01.430278
elapsed time: 0:02:11.762947
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:56:53.440916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.80
 ---- batch: 020 ----
mean loss: 143.00
 ---- batch: 030 ----
mean loss: 146.66
train mean loss: 144.19
epoch train time: 0:00:01.429650
elapsed time: 0:02:13.192774
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:56:54.870743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.10
 ---- batch: 020 ----
mean loss: 141.85
 ---- batch: 030 ----
mean loss: 142.52
train mean loss: 143.31
epoch train time: 0:00:01.429903
elapsed time: 0:02:14.622841
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:56:56.300805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.14
 ---- batch: 020 ----
mean loss: 141.40
 ---- batch: 030 ----
mean loss: 148.31
train mean loss: 143.92
epoch train time: 0:00:01.429884
elapsed time: 0:02:16.052902
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:56:57.730870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.50
 ---- batch: 020 ----
mean loss: 142.18
 ---- batch: 030 ----
mean loss: 144.17
train mean loss: 146.45
epoch train time: 0:00:01.432007
elapsed time: 0:02:17.485073
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:56:59.163044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.33
 ---- batch: 020 ----
mean loss: 146.03
 ---- batch: 030 ----
mean loss: 142.65
train mean loss: 144.70
epoch train time: 0:00:01.430158
elapsed time: 0:02:18.915404
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:57:00.593389
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.23
 ---- batch: 020 ----
mean loss: 142.99
 ---- batch: 030 ----
mean loss: 149.91
train mean loss: 145.46
epoch train time: 0:00:01.431515
elapsed time: 0:02:20.347112
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:57:02.025080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.58
 ---- batch: 020 ----
mean loss: 139.84
 ---- batch: 030 ----
mean loss: 151.40
train mean loss: 146.34
epoch train time: 0:00:01.426011
elapsed time: 0:02:21.773290
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:57:03.451259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.54
 ---- batch: 020 ----
mean loss: 145.29
 ---- batch: 030 ----
mean loss: 149.53
train mean loss: 144.70
epoch train time: 0:00:01.429199
elapsed time: 0:02:23.202663
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:57:04.880648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.24
 ---- batch: 020 ----
mean loss: 147.42
 ---- batch: 030 ----
mean loss: 147.40
train mean loss: 147.70
epoch train time: 0:00:01.432696
elapsed time: 0:02:24.635555
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:57:06.313523
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.97
 ---- batch: 020 ----
mean loss: 140.50
 ---- batch: 030 ----
mean loss: 146.22
train mean loss: 142.68
epoch train time: 0:00:01.431544
elapsed time: 0:02:26.067276
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:57:07.745245
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.69
 ---- batch: 020 ----
mean loss: 147.32
 ---- batch: 030 ----
mean loss: 149.78
train mean loss: 146.80
epoch train time: 0:00:01.427982
elapsed time: 0:02:27.495428
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:57:09.173398
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.73
 ---- batch: 020 ----
mean loss: 142.92
 ---- batch: 030 ----
mean loss: 146.88
train mean loss: 145.38
epoch train time: 0:00:01.424641
elapsed time: 0:02:28.920253
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:57:10.598220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.26
 ---- batch: 020 ----
mean loss: 145.64
 ---- batch: 030 ----
mean loss: 146.95
train mean loss: 146.95
epoch train time: 0:00:01.432279
elapsed time: 0:02:30.352706
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:57:12.030676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.69
 ---- batch: 020 ----
mean loss: 140.87
 ---- batch: 030 ----
mean loss: 140.88
train mean loss: 143.42
epoch train time: 0:00:01.433616
elapsed time: 0:02:31.786503
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:57:13.464471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.34
 ---- batch: 020 ----
mean loss: 145.92
 ---- batch: 030 ----
mean loss: 149.83
train mean loss: 146.83
epoch train time: 0:00:01.432306
elapsed time: 0:02:33.218982
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:57:14.896963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.01
 ---- batch: 020 ----
mean loss: 145.80
 ---- batch: 030 ----
mean loss: 145.99
train mean loss: 146.79
epoch train time: 0:00:01.427534
elapsed time: 0:02:34.646699
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:57:16.324680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.96
 ---- batch: 020 ----
mean loss: 144.11
 ---- batch: 030 ----
mean loss: 140.88
train mean loss: 146.52
epoch train time: 0:00:01.438187
elapsed time: 0:02:36.085081
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:57:17.763052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.68
 ---- batch: 020 ----
mean loss: 145.04
 ---- batch: 030 ----
mean loss: 139.27
train mean loss: 143.98
epoch train time: 0:00:01.434046
elapsed time: 0:02:37.519323
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:57:19.197295
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.98
 ---- batch: 020 ----
mean loss: 146.03
 ---- batch: 030 ----
mean loss: 141.14
train mean loss: 143.72
epoch train time: 0:00:01.432761
elapsed time: 0:02:38.952281
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:57:20.630251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.16
 ---- batch: 020 ----
mean loss: 143.80
 ---- batch: 030 ----
mean loss: 142.09
train mean loss: 143.65
epoch train time: 0:00:01.434391
elapsed time: 0:02:40.386848
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:57:22.064815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.13
 ---- batch: 020 ----
mean loss: 140.62
 ---- batch: 030 ----
mean loss: 142.12
train mean loss: 141.81
epoch train time: 0:00:01.433080
elapsed time: 0:02:41.820105
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:57:23.498074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.55
 ---- batch: 020 ----
mean loss: 141.62
 ---- batch: 030 ----
mean loss: 154.25
train mean loss: 147.30
epoch train time: 0:00:01.426158
elapsed time: 0:02:43.246444
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:57:24.924451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.59
 ---- batch: 020 ----
mean loss: 154.66
 ---- batch: 030 ----
mean loss: 142.10
train mean loss: 150.02
epoch train time: 0:00:01.430349
elapsed time: 0:02:44.677036
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:57:26.354989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.38
 ---- batch: 020 ----
mean loss: 138.74
 ---- batch: 030 ----
mean loss: 147.21
train mean loss: 141.99
epoch train time: 0:00:01.428942
elapsed time: 0:02:46.106205
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:57:27.784197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.72
 ---- batch: 020 ----
mean loss: 149.44
 ---- batch: 030 ----
mean loss: 141.43
train mean loss: 145.01
epoch train time: 0:00:01.432503
elapsed time: 0:02:47.538909
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:57:29.216892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.24
 ---- batch: 020 ----
mean loss: 143.44
 ---- batch: 030 ----
mean loss: 141.10
train mean loss: 142.38
epoch train time: 0:00:01.434122
elapsed time: 0:02:48.973222
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:57:30.651192
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.18
 ---- batch: 020 ----
mean loss: 138.26
 ---- batch: 030 ----
mean loss: 145.06
train mean loss: 142.61
epoch train time: 0:00:01.433290
elapsed time: 0:02:50.406686
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:57:32.084653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.65
 ---- batch: 020 ----
mean loss: 141.04
 ---- batch: 030 ----
mean loss: 134.73
train mean loss: 142.59
epoch train time: 0:00:01.433204
elapsed time: 0:02:51.840060
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:57:33.518043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.25
 ---- batch: 020 ----
mean loss: 153.83
 ---- batch: 030 ----
mean loss: 138.18
train mean loss: 146.63
epoch train time: 0:00:01.428176
elapsed time: 0:02:53.268459
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:57:34.946424
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.43
 ---- batch: 020 ----
mean loss: 140.47
 ---- batch: 030 ----
mean loss: 147.86
train mean loss: 142.68
epoch train time: 0:00:01.429987
elapsed time: 0:02:54.698614
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:57:36.376593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.66
 ---- batch: 020 ----
mean loss: 139.73
 ---- batch: 030 ----
mean loss: 138.98
train mean loss: 141.16
epoch train time: 0:00:01.437069
elapsed time: 0:02:56.135863
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:57:37.813831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.26
 ---- batch: 020 ----
mean loss: 142.20
 ---- batch: 030 ----
mean loss: 143.90
train mean loss: 142.77
epoch train time: 0:00:01.431586
elapsed time: 0:02:57.567652
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:57:39.245661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.97
 ---- batch: 020 ----
mean loss: 140.90
 ---- batch: 030 ----
mean loss: 140.56
train mean loss: 139.14
epoch train time: 0:00:01.427906
elapsed time: 0:02:58.995787
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:57:40.673761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.86
 ---- batch: 020 ----
mean loss: 137.67
 ---- batch: 030 ----
mean loss: 141.71
train mean loss: 141.56
epoch train time: 0:00:01.429023
elapsed time: 0:03:00.425015
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:57:42.102998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.11
 ---- batch: 020 ----
mean loss: 142.63
 ---- batch: 030 ----
mean loss: 143.00
train mean loss: 142.92
epoch train time: 0:00:01.433291
elapsed time: 0:03:01.858487
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:57:43.536454
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.83
 ---- batch: 020 ----
mean loss: 141.50
 ---- batch: 030 ----
mean loss: 142.56
train mean loss: 140.45
epoch train time: 0:00:01.431599
elapsed time: 0:03:03.290252
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:57:44.968218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.48
 ---- batch: 020 ----
mean loss: 144.14
 ---- batch: 030 ----
mean loss: 138.90
train mean loss: 143.36
epoch train time: 0:00:01.429708
elapsed time: 0:03:04.720132
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:57:46.398103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.38
 ---- batch: 020 ----
mean loss: 140.35
 ---- batch: 030 ----
mean loss: 149.23
train mean loss: 142.31
epoch train time: 0:00:01.433161
elapsed time: 0:03:06.153473
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:57:47.831507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.42
 ---- batch: 020 ----
mean loss: 146.61
 ---- batch: 030 ----
mean loss: 141.89
train mean loss: 142.59
epoch train time: 0:00:01.436900
elapsed time: 0:03:07.590616
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:57:49.268584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.48
 ---- batch: 020 ----
mean loss: 140.43
 ---- batch: 030 ----
mean loss: 141.83
train mean loss: 142.47
epoch train time: 0:00:01.433076
elapsed time: 0:03:09.023869
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:57:50.701839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.08
 ---- batch: 020 ----
mean loss: 139.76
 ---- batch: 030 ----
mean loss: 143.63
train mean loss: 142.73
epoch train time: 0:00:01.434080
elapsed time: 0:03:10.458135
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:57:52.136110
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.53
 ---- batch: 020 ----
mean loss: 140.15
 ---- batch: 030 ----
mean loss: 142.22
train mean loss: 142.73
epoch train time: 0:00:01.431112
elapsed time: 0:03:11.889442
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:57:53.567414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.32
 ---- batch: 020 ----
mean loss: 141.65
 ---- batch: 030 ----
mean loss: 140.75
train mean loss: 141.66
epoch train time: 0:00:01.439845
elapsed time: 0:03:13.329482
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:57:55.007437
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.73
 ---- batch: 020 ----
mean loss: 146.04
 ---- batch: 030 ----
mean loss: 152.02
train mean loss: 146.93
epoch train time: 0:00:01.430126
elapsed time: 0:03:14.759787
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:57:56.437760
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.93
 ---- batch: 020 ----
mean loss: 141.10
 ---- batch: 030 ----
mean loss: 137.35
train mean loss: 141.44
epoch train time: 0:00:01.426732
elapsed time: 0:03:16.186758
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:57:57.864733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.96
 ---- batch: 020 ----
mean loss: 139.72
 ---- batch: 030 ----
mean loss: 137.32
train mean loss: 140.61
epoch train time: 0:00:01.429875
elapsed time: 0:03:17.616818
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:57:59.294784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.61
 ---- batch: 020 ----
mean loss: 148.14
 ---- batch: 030 ----
mean loss: 143.74
train mean loss: 146.13
epoch train time: 0:00:01.429948
elapsed time: 0:03:19.046937
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:58:00.724911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.04
 ---- batch: 020 ----
mean loss: 136.65
 ---- batch: 030 ----
mean loss: 136.68
train mean loss: 138.15
epoch train time: 0:00:01.430310
elapsed time: 0:03:20.477435
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:58:02.155406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.13
 ---- batch: 020 ----
mean loss: 143.78
 ---- batch: 030 ----
mean loss: 135.44
train mean loss: 138.76
epoch train time: 0:00:01.429529
elapsed time: 0:03:21.907144
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:58:03.585113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.65
 ---- batch: 020 ----
mean loss: 138.16
 ---- batch: 030 ----
mean loss: 142.06
train mean loss: 139.60
epoch train time: 0:00:01.432675
elapsed time: 0:03:23.340028
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:58:05.017997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.05
 ---- batch: 020 ----
mean loss: 141.94
 ---- batch: 030 ----
mean loss: 141.78
train mean loss: 141.24
epoch train time: 0:00:01.424458
elapsed time: 0:03:24.764682
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:58:06.442651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.88
 ---- batch: 020 ----
mean loss: 135.36
 ---- batch: 030 ----
mean loss: 140.90
train mean loss: 140.79
epoch train time: 0:00:01.435073
elapsed time: 0:03:26.199944
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:58:07.877914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.65
 ---- batch: 020 ----
mean loss: 141.61
 ---- batch: 030 ----
mean loss: 139.26
train mean loss: 140.45
epoch train time: 0:00:01.433795
elapsed time: 0:03:27.633923
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:58:09.311891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.83
 ---- batch: 020 ----
mean loss: 145.61
 ---- batch: 030 ----
mean loss: 138.42
train mean loss: 141.12
epoch train time: 0:00:01.431470
elapsed time: 0:03:29.065561
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:58:10.743560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.04
 ---- batch: 020 ----
mean loss: 139.17
 ---- batch: 030 ----
mean loss: 136.05
train mean loss: 138.44
epoch train time: 0:00:01.431609
elapsed time: 0:03:30.497366
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:58:12.175336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.77
 ---- batch: 020 ----
mean loss: 139.30
 ---- batch: 030 ----
mean loss: 138.24
train mean loss: 138.63
epoch train time: 0:00:01.431259
elapsed time: 0:03:31.928800
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:58:13.606768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.44
 ---- batch: 020 ----
mean loss: 142.80
 ---- batch: 030 ----
mean loss: 144.80
train mean loss: 144.02
epoch train time: 0:00:01.427222
elapsed time: 0:03:33.356209
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:58:15.034178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.30
 ---- batch: 020 ----
mean loss: 137.66
 ---- batch: 030 ----
mean loss: 142.04
train mean loss: 141.71
epoch train time: 0:00:01.433196
elapsed time: 0:03:34.789572
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:58:16.467542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.24
 ---- batch: 020 ----
mean loss: 149.99
 ---- batch: 030 ----
mean loss: 162.32
train mean loss: 150.44
epoch train time: 0:00:01.432970
elapsed time: 0:03:36.222723
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:58:17.900712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.60
 ---- batch: 020 ----
mean loss: 143.20
 ---- batch: 030 ----
mean loss: 144.97
train mean loss: 144.72
epoch train time: 0:00:01.435196
elapsed time: 0:03:37.658139
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:58:19.336105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.71
 ---- batch: 020 ----
mean loss: 142.41
 ---- batch: 030 ----
mean loss: 144.02
train mean loss: 142.36
epoch train time: 0:00:01.426391
elapsed time: 0:03:39.084719
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:58:20.762685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.76
 ---- batch: 020 ----
mean loss: 143.85
 ---- batch: 030 ----
mean loss: 136.92
train mean loss: 142.01
epoch train time: 0:00:01.435931
elapsed time: 0:03:40.520826
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:58:22.198794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.79
 ---- batch: 020 ----
mean loss: 144.44
 ---- batch: 030 ----
mean loss: 139.33
train mean loss: 142.19
epoch train time: 0:00:01.431100
elapsed time: 0:03:41.952090
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:58:23.630058
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.93
 ---- batch: 020 ----
mean loss: 139.78
 ---- batch: 030 ----
mean loss: 141.15
train mean loss: 140.26
epoch train time: 0:00:01.440356
elapsed time: 0:03:43.392674
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:58:25.070667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.77
 ---- batch: 020 ----
mean loss: 145.22
 ---- batch: 030 ----
mean loss: 138.84
train mean loss: 140.95
epoch train time: 0:00:01.436581
elapsed time: 0:03:44.829457
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:58:26.507410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.91
 ---- batch: 020 ----
mean loss: 133.11
 ---- batch: 030 ----
mean loss: 139.84
train mean loss: 138.95
epoch train time: 0:00:01.428460
elapsed time: 0:03:46.258079
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:58:27.936052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.39
 ---- batch: 020 ----
mean loss: 144.02
 ---- batch: 030 ----
mean loss: 140.67
train mean loss: 140.94
epoch train time: 0:00:01.429671
elapsed time: 0:03:47.687928
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:58:29.365913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.08
 ---- batch: 020 ----
mean loss: 136.79
 ---- batch: 030 ----
mean loss: 142.82
train mean loss: 140.12
epoch train time: 0:00:01.429861
elapsed time: 0:03:49.117988
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:58:30.795954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.61
 ---- batch: 020 ----
mean loss: 141.95
 ---- batch: 030 ----
mean loss: 134.18
train mean loss: 139.34
epoch train time: 0:00:01.433625
elapsed time: 0:03:50.551802
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:58:32.229771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.61
 ---- batch: 020 ----
mean loss: 143.24
 ---- batch: 030 ----
mean loss: 144.14
train mean loss: 143.29
epoch train time: 0:00:01.432309
elapsed time: 0:03:51.984294
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:58:33.662263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.22
 ---- batch: 020 ----
mean loss: 138.07
 ---- batch: 030 ----
mean loss: 138.45
train mean loss: 139.20
epoch train time: 0:00:01.435851
elapsed time: 0:03:53.420331
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:58:35.098309
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.39
 ---- batch: 020 ----
mean loss: 140.58
 ---- batch: 030 ----
mean loss: 143.86
train mean loss: 140.59
epoch train time: 0:00:01.429257
elapsed time: 0:03:54.849774
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:58:36.527767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.96
 ---- batch: 020 ----
mean loss: 143.44
 ---- batch: 030 ----
mean loss: 144.37
train mean loss: 143.05
epoch train time: 0:00:01.432510
elapsed time: 0:03:56.282505
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:58:37.960482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.27
 ---- batch: 020 ----
mean loss: 138.31
 ---- batch: 030 ----
mean loss: 138.94
train mean loss: 140.87
epoch train time: 0:00:01.428726
elapsed time: 0:03:57.711416
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:58:39.389386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.15
 ---- batch: 020 ----
mean loss: 139.33
 ---- batch: 030 ----
mean loss: 138.66
train mean loss: 139.62
epoch train time: 0:00:01.435282
elapsed time: 0:03:59.146907
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:58:40.824887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.92
 ---- batch: 020 ----
mean loss: 151.26
 ---- batch: 030 ----
mean loss: 144.93
train mean loss: 146.38
epoch train time: 0:00:01.431143
elapsed time: 0:04:00.578238
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:58:42.256202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.92
 ---- batch: 020 ----
mean loss: 137.86
 ---- batch: 030 ----
mean loss: 134.61
train mean loss: 137.09
epoch train time: 0:00:01.428762
elapsed time: 0:04:02.007186
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:58:43.685163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.88
 ---- batch: 020 ----
mean loss: 140.09
 ---- batch: 030 ----
mean loss: 139.74
train mean loss: 140.63
epoch train time: 0:00:01.426156
elapsed time: 0:04:03.433527
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:58:45.111494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.02
 ---- batch: 020 ----
mean loss: 136.55
 ---- batch: 030 ----
mean loss: 139.79
train mean loss: 137.21
epoch train time: 0:00:01.429561
elapsed time: 0:04:04.863267
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:58:46.541235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.97
 ---- batch: 020 ----
mean loss: 140.18
 ---- batch: 030 ----
mean loss: 139.40
train mean loss: 139.47
epoch train time: 0:00:01.435835
elapsed time: 0:04:06.299291
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:58:47.977261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.29
 ---- batch: 020 ----
mean loss: 139.05
 ---- batch: 030 ----
mean loss: 139.92
train mean loss: 141.00
epoch train time: 0:00:01.434468
elapsed time: 0:04:07.733928
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:58:49.411896
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.62
 ---- batch: 020 ----
mean loss: 136.29
 ---- batch: 030 ----
mean loss: 135.77
train mean loss: 137.48
epoch train time: 0:00:01.426704
elapsed time: 0:04:09.160811
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:58:50.838780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.51
 ---- batch: 020 ----
mean loss: 143.60
 ---- batch: 030 ----
mean loss: 135.53
train mean loss: 140.47
epoch train time: 0:00:01.427135
elapsed time: 0:04:10.588126
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:58:52.266108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.50
 ---- batch: 020 ----
mean loss: 133.93
 ---- batch: 030 ----
mean loss: 138.86
train mean loss: 138.57
epoch train time: 0:00:01.432249
elapsed time: 0:04:12.020621
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:58:53.698596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.14
 ---- batch: 020 ----
mean loss: 135.39
 ---- batch: 030 ----
mean loss: 139.08
train mean loss: 140.22
epoch train time: 0:00:01.430232
elapsed time: 0:04:13.451025
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:58:55.128993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.55
 ---- batch: 020 ----
mean loss: 138.30
 ---- batch: 030 ----
mean loss: 136.50
train mean loss: 139.60
epoch train time: 0:00:01.431762
elapsed time: 0:04:14.882950
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:58:56.560934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.64
 ---- batch: 020 ----
mean loss: 144.31
 ---- batch: 030 ----
mean loss: 139.65
train mean loss: 139.91
epoch train time: 0:00:01.431734
elapsed time: 0:04:16.314899
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:58:57.992866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.71
 ---- batch: 020 ----
mean loss: 138.93
 ---- batch: 030 ----
mean loss: 143.34
train mean loss: 141.06
epoch train time: 0:00:01.430394
elapsed time: 0:04:17.745480
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:58:59.423459
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.27
 ---- batch: 020 ----
mean loss: 135.60
 ---- batch: 030 ----
mean loss: 140.37
train mean loss: 140.13
epoch train time: 0:00:01.434366
elapsed time: 0:04:19.180056
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:59:00.858037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.99
 ---- batch: 020 ----
mean loss: 140.12
 ---- batch: 030 ----
mean loss: 134.95
train mean loss: 140.02
epoch train time: 0:00:01.424905
elapsed time: 0:04:20.605165
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:59:02.283119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.39
 ---- batch: 020 ----
mean loss: 136.73
 ---- batch: 030 ----
mean loss: 139.50
train mean loss: 137.41
epoch train time: 0:00:01.429204
elapsed time: 0:04:22.034531
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:59:03.712499
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.22
 ---- batch: 020 ----
mean loss: 134.99
 ---- batch: 030 ----
mean loss: 138.15
train mean loss: 138.92
epoch train time: 0:00:01.434217
elapsed time: 0:04:23.468983
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:59:05.146953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.98
 ---- batch: 020 ----
mean loss: 138.78
 ---- batch: 030 ----
mean loss: 139.09
train mean loss: 139.33
epoch train time: 0:00:01.433597
elapsed time: 0:04:24.902752
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:59:06.580718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.31
 ---- batch: 020 ----
mean loss: 137.95
 ---- batch: 030 ----
mean loss: 144.38
train mean loss: 140.69
epoch train time: 0:00:01.429181
elapsed time: 0:04:26.332101
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:59:08.010067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.85
 ---- batch: 020 ----
mean loss: 139.25
 ---- batch: 030 ----
mean loss: 133.59
train mean loss: 138.36
epoch train time: 0:00:01.435585
elapsed time: 0:04:27.767857
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:59:09.445827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.14
 ---- batch: 020 ----
mean loss: 136.22
 ---- batch: 030 ----
mean loss: 142.86
train mean loss: 138.37
epoch train time: 0:00:01.424561
elapsed time: 0:04:29.192595
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:59:10.870564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.72
 ---- batch: 020 ----
mean loss: 139.52
 ---- batch: 030 ----
mean loss: 139.07
train mean loss: 137.84
epoch train time: 0:00:01.425707
elapsed time: 0:04:30.618474
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:59:12.296446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.77
 ---- batch: 020 ----
mean loss: 142.21
 ---- batch: 030 ----
mean loss: 136.11
train mean loss: 137.74
epoch train time: 0:00:01.434744
elapsed time: 0:04:32.053396
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:59:13.731365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.17
 ---- batch: 020 ----
mean loss: 135.55
 ---- batch: 030 ----
mean loss: 139.40
train mean loss: 137.46
epoch train time: 0:00:01.431363
elapsed time: 0:04:33.484931
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:59:15.162947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.42
 ---- batch: 020 ----
mean loss: 145.51
 ---- batch: 030 ----
mean loss: 142.21
train mean loss: 144.89
epoch train time: 0:00:01.432074
elapsed time: 0:04:34.917225
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:59:16.595210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.57
 ---- batch: 020 ----
mean loss: 147.28
 ---- batch: 030 ----
mean loss: 138.19
train mean loss: 142.33
epoch train time: 0:00:01.430086
elapsed time: 0:04:36.347503
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:59:18.025498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.74
 ---- batch: 020 ----
mean loss: 142.57
 ---- batch: 030 ----
mean loss: 136.35
train mean loss: 138.51
epoch train time: 0:00:01.430188
elapsed time: 0:04:37.777882
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:59:19.455847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.98
 ---- batch: 020 ----
mean loss: 138.75
 ---- batch: 030 ----
mean loss: 134.94
train mean loss: 136.35
epoch train time: 0:00:01.435472
elapsed time: 0:04:39.213519
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:59:20.891489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.78
 ---- batch: 020 ----
mean loss: 139.56
 ---- batch: 030 ----
mean loss: 139.34
train mean loss: 137.42
epoch train time: 0:00:01.430694
elapsed time: 0:04:40.644382
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:59:22.322349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.04
 ---- batch: 020 ----
mean loss: 133.92
 ---- batch: 030 ----
mean loss: 136.12
train mean loss: 137.20
epoch train time: 0:00:01.428776
elapsed time: 0:04:42.073347
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:59:23.751329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.46
 ---- batch: 020 ----
mean loss: 138.22
 ---- batch: 030 ----
mean loss: 139.04
train mean loss: 138.87
epoch train time: 0:00:01.435191
elapsed time: 0:04:43.508779
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:59:25.186750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.68
 ---- batch: 020 ----
mean loss: 132.19
 ---- batch: 030 ----
mean loss: 137.79
train mean loss: 138.19
epoch train time: 0:00:01.434117
elapsed time: 0:04:44.943058
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:59:26.621033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.51
 ---- batch: 020 ----
mean loss: 137.83
 ---- batch: 030 ----
mean loss: 134.01
train mean loss: 135.86
epoch train time: 0:00:01.433634
elapsed time: 0:04:46.376872
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:59:28.054855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.19
 ---- batch: 020 ----
mean loss: 141.05
 ---- batch: 030 ----
mean loss: 139.06
train mean loss: 139.74
epoch train time: 0:00:01.429110
elapsed time: 0:04:47.806187
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:59:29.484156
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.06
 ---- batch: 020 ----
mean loss: 139.36
 ---- batch: 030 ----
mean loss: 135.18
train mean loss: 138.36
epoch train time: 0:00:01.429418
elapsed time: 0:04:49.235816
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:59:30.913789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.75
 ---- batch: 020 ----
mean loss: 143.26
 ---- batch: 030 ----
mean loss: 141.17
train mean loss: 142.03
epoch train time: 0:00:01.438923
elapsed time: 0:04:50.674911
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:59:32.352877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.90
 ---- batch: 020 ----
mean loss: 138.23
 ---- batch: 030 ----
mean loss: 138.18
train mean loss: 139.24
epoch train time: 0:00:01.428570
elapsed time: 0:04:52.103689
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:59:33.781680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.66
 ---- batch: 020 ----
mean loss: 144.35
 ---- batch: 030 ----
mean loss: 132.33
train mean loss: 138.51
epoch train time: 0:00:01.428038
elapsed time: 0:04:53.531950
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:59:35.209933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.75
 ---- batch: 020 ----
mean loss: 138.79
 ---- batch: 030 ----
mean loss: 142.27
train mean loss: 140.14
epoch train time: 0:00:01.431867
elapsed time: 0:04:54.964015
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:59:36.641985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.49
 ---- batch: 020 ----
mean loss: 135.88
 ---- batch: 030 ----
mean loss: 140.20
train mean loss: 137.23
epoch train time: 0:00:01.433049
elapsed time: 0:04:56.397277
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:59:38.075246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.67
 ---- batch: 020 ----
mean loss: 142.28
 ---- batch: 030 ----
mean loss: 141.54
train mean loss: 140.65
epoch train time: 0:00:01.429056
elapsed time: 0:04:57.826495
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:59:39.504459
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.35
 ---- batch: 020 ----
mean loss: 140.21
 ---- batch: 030 ----
mean loss: 145.99
train mean loss: 142.85
epoch train time: 0:00:01.426932
elapsed time: 0:04:59.253823
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:59:40.931800
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.00
 ---- batch: 020 ----
mean loss: 136.63
 ---- batch: 030 ----
mean loss: 133.98
train mean loss: 134.83
epoch train time: 0:00:01.440475
elapsed time: 0:05:00.694518
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:59:42.372494
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.97
 ---- batch: 020 ----
mean loss: 137.75
 ---- batch: 030 ----
mean loss: 136.89
train mean loss: 137.38
epoch train time: 0:00:01.432350
elapsed time: 0:05:02.127061
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:59:43.805031
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.19
 ---- batch: 020 ----
mean loss: 134.08
 ---- batch: 030 ----
mean loss: 136.42
train mean loss: 135.35
epoch train time: 0:00:01.431840
elapsed time: 0:05:03.559067
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:59:45.237035
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.44
 ---- batch: 020 ----
mean loss: 136.85
 ---- batch: 030 ----
mean loss: 135.64
train mean loss: 136.40
epoch train time: 0:00:01.428915
elapsed time: 0:05:04.988161
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:59:46.666132
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.05
 ---- batch: 020 ----
mean loss: 136.46
 ---- batch: 030 ----
mean loss: 137.76
train mean loss: 136.46
epoch train time: 0:00:01.441902
elapsed time: 0:05:06.430240
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:59:48.108213
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.93
 ---- batch: 020 ----
mean loss: 135.54
 ---- batch: 030 ----
mean loss: 130.67
train mean loss: 133.83
epoch train time: 0:00:01.436211
elapsed time: 0:05:07.866650
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:59:49.544619
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.87
 ---- batch: 020 ----
mean loss: 137.07
 ---- batch: 030 ----
mean loss: 135.41
train mean loss: 136.98
epoch train time: 0:00:01.441427
elapsed time: 0:05:09.308271
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:59:50.986242
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.70
 ---- batch: 020 ----
mean loss: 127.02
 ---- batch: 030 ----
mean loss: 133.07
train mean loss: 133.34
epoch train time: 0:00:01.434655
elapsed time: 0:05:10.743102
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:59:52.421073
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.91
 ---- batch: 020 ----
mean loss: 132.91
 ---- batch: 030 ----
mean loss: 137.71
train mean loss: 135.45
epoch train time: 0:00:01.435473
elapsed time: 0:05:12.178759
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:59:53.856762
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.07
 ---- batch: 020 ----
mean loss: 131.33
 ---- batch: 030 ----
mean loss: 132.20
train mean loss: 133.67
epoch train time: 0:00:01.433793
elapsed time: 0:05:13.612772
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:59:55.290742
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.27
 ---- batch: 020 ----
mean loss: 137.13
 ---- batch: 030 ----
mean loss: 135.32
train mean loss: 135.71
epoch train time: 0:00:01.433861
elapsed time: 0:05:15.046814
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:59:56.724785
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.78
 ---- batch: 020 ----
mean loss: 138.19
 ---- batch: 030 ----
mean loss: 134.65
train mean loss: 134.35
epoch train time: 0:00:01.429826
elapsed time: 0:05:16.476810
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:59:58.154793
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.94
 ---- batch: 020 ----
mean loss: 135.15
 ---- batch: 030 ----
mean loss: 132.78
train mean loss: 135.20
epoch train time: 0:00:01.431998
elapsed time: 0:05:17.909001
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:59:59.586969
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.92
 ---- batch: 020 ----
mean loss: 137.31
 ---- batch: 030 ----
mean loss: 131.52
train mean loss: 134.60
epoch train time: 0:00:01.427529
elapsed time: 0:05:19.336700
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:00:01.014668
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.82
 ---- batch: 020 ----
mean loss: 130.76
 ---- batch: 030 ----
mean loss: 137.89
train mean loss: 135.40
epoch train time: 0:00:01.432964
elapsed time: 0:05:20.769851
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:00:02.447835
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.93
 ---- batch: 020 ----
mean loss: 134.11
 ---- batch: 030 ----
mean loss: 134.58
train mean loss: 133.30
epoch train time: 0:00:01.437822
elapsed time: 0:05:22.207875
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:00:03.885843
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.63
 ---- batch: 020 ----
mean loss: 135.45
 ---- batch: 030 ----
mean loss: 135.34
train mean loss: 134.70
epoch train time: 0:00:01.430920
elapsed time: 0:05:23.639047
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:00:05.317029
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.67
 ---- batch: 020 ----
mean loss: 132.86
 ---- batch: 030 ----
mean loss: 132.82
train mean loss: 134.33
epoch train time: 0:00:01.435479
elapsed time: 0:05:25.074723
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:00:06.752693
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.66
 ---- batch: 020 ----
mean loss: 137.33
 ---- batch: 030 ----
mean loss: 136.69
train mean loss: 135.58
epoch train time: 0:00:01.432924
elapsed time: 0:05:26.507836
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:00:08.185850
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.53
 ---- batch: 020 ----
mean loss: 138.02
 ---- batch: 030 ----
mean loss: 136.72
train mean loss: 134.74
epoch train time: 0:00:01.428730
elapsed time: 0:05:27.936821
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:00:09.614785
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.05
 ---- batch: 020 ----
mean loss: 135.40
 ---- batch: 030 ----
mean loss: 133.64
train mean loss: 134.97
epoch train time: 0:00:01.432191
elapsed time: 0:05:29.369419
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:00:11.047391
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.46
 ---- batch: 020 ----
mean loss: 136.80
 ---- batch: 030 ----
mean loss: 132.72
train mean loss: 135.99
epoch train time: 0:00:01.430158
elapsed time: 0:05:30.799780
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:00:12.477750
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.68
 ---- batch: 020 ----
mean loss: 132.39
 ---- batch: 030 ----
mean loss: 133.43
train mean loss: 135.01
epoch train time: 0:00:01.433261
elapsed time: 0:05:32.233243
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:00:13.911231
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.75
 ---- batch: 020 ----
mean loss: 133.42
 ---- batch: 030 ----
mean loss: 129.57
train mean loss: 134.24
epoch train time: 0:00:01.433712
elapsed time: 0:05:33.667145
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:00:15.345114
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.25
 ---- batch: 020 ----
mean loss: 135.41
 ---- batch: 030 ----
mean loss: 136.49
train mean loss: 135.66
epoch train time: 0:00:01.432680
elapsed time: 0:05:35.100029
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:00:16.778031
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.92
 ---- batch: 020 ----
mean loss: 136.45
 ---- batch: 030 ----
mean loss: 129.70
train mean loss: 133.69
epoch train time: 0:00:01.431825
elapsed time: 0:05:36.532079
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:00:18.210052
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.75
 ---- batch: 020 ----
mean loss: 139.19
 ---- batch: 030 ----
mean loss: 134.61
train mean loss: 135.53
epoch train time: 0:00:01.434457
elapsed time: 0:05:37.966721
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:00:19.644691
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.97
 ---- batch: 020 ----
mean loss: 134.54
 ---- batch: 030 ----
mean loss: 135.96
train mean loss: 134.95
epoch train time: 0:00:01.432403
elapsed time: 0:05:39.399299
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:00:21.077270
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.53
 ---- batch: 020 ----
mean loss: 137.78
 ---- batch: 030 ----
mean loss: 133.66
train mean loss: 135.81
epoch train time: 0:00:01.433212
elapsed time: 0:05:40.832700
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:00:22.510671
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.89
 ---- batch: 020 ----
mean loss: 138.80
 ---- batch: 030 ----
mean loss: 132.31
train mean loss: 134.00
epoch train time: 0:00:01.430946
elapsed time: 0:05:42.263828
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:00:23.941803
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.18
 ---- batch: 020 ----
mean loss: 134.19
 ---- batch: 030 ----
mean loss: 131.01
train mean loss: 133.75
epoch train time: 0:00:01.432755
elapsed time: 0:05:43.696780
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:00:25.374752
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.26
 ---- batch: 020 ----
mean loss: 132.06
 ---- batch: 030 ----
mean loss: 133.58
train mean loss: 132.92
epoch train time: 0:00:01.432393
elapsed time: 0:05:45.129399
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:00:26.807383
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.87
 ---- batch: 020 ----
mean loss: 140.07
 ---- batch: 030 ----
mean loss: 134.93
train mean loss: 136.98
epoch train time: 0:00:01.433705
elapsed time: 0:05:46.563313
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:00:28.241268
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.95
 ---- batch: 020 ----
mean loss: 133.43
 ---- batch: 030 ----
mean loss: 136.56
train mean loss: 136.02
epoch train time: 0:00:01.429077
elapsed time: 0:05:47.992554
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:00:29.670525
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.78
 ---- batch: 020 ----
mean loss: 129.52
 ---- batch: 030 ----
mean loss: 135.63
train mean loss: 132.84
epoch train time: 0:00:01.429036
elapsed time: 0:05:49.421757
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:00:31.099725
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.45
 ---- batch: 020 ----
mean loss: 132.62
 ---- batch: 030 ----
mean loss: 132.06
train mean loss: 133.53
epoch train time: 0:00:01.427990
elapsed time: 0:05:50.849915
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:00:32.527905
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.21
 ---- batch: 020 ----
mean loss: 134.59
 ---- batch: 030 ----
mean loss: 132.85
train mean loss: 133.86
epoch train time: 0:00:01.432286
elapsed time: 0:05:52.282398
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:00:33.960369
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.09
 ---- batch: 020 ----
mean loss: 134.85
 ---- batch: 030 ----
mean loss: 135.60
train mean loss: 134.92
epoch train time: 0:00:01.430091
elapsed time: 0:05:53.712663
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:00:35.390629
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.84
 ---- batch: 020 ----
mean loss: 140.04
 ---- batch: 030 ----
mean loss: 133.59
train mean loss: 136.41
epoch train time: 0:00:01.428251
elapsed time: 0:05:55.141109
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:00:36.819086
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.25
 ---- batch: 020 ----
mean loss: 131.15
 ---- batch: 030 ----
mean loss: 134.86
train mean loss: 134.08
epoch train time: 0:00:01.431891
elapsed time: 0:05:56.573179
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:00:38.251146
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.77
 ---- batch: 020 ----
mean loss: 136.48
 ---- batch: 030 ----
mean loss: 133.39
train mean loss: 135.09
epoch train time: 0:00:01.434061
elapsed time: 0:05:58.007432
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:00:39.685404
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.41
 ---- batch: 020 ----
mean loss: 134.97
 ---- batch: 030 ----
mean loss: 131.08
train mean loss: 134.06
epoch train time: 0:00:01.438905
elapsed time: 0:05:59.446522
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:00:41.124489
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.53
 ---- batch: 020 ----
mean loss: 135.99
 ---- batch: 030 ----
mean loss: 136.78
train mean loss: 135.72
epoch train time: 0:00:01.434165
elapsed time: 0:06:00.880871
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:00:42.558840
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.53
 ---- batch: 020 ----
mean loss: 133.74
 ---- batch: 030 ----
mean loss: 131.55
train mean loss: 132.72
epoch train time: 0:00:01.442872
elapsed time: 0:06:02.323935
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:00:44.001903
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.35
 ---- batch: 020 ----
mean loss: 128.99
 ---- batch: 030 ----
mean loss: 133.40
train mean loss: 133.33
epoch train time: 0:00:01.440135
elapsed time: 0:06:03.764260
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:00:45.442231
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.46
 ---- batch: 020 ----
mean loss: 136.86
 ---- batch: 030 ----
mean loss: 132.82
train mean loss: 134.65
epoch train time: 0:00:01.440824
elapsed time: 0:06:05.205292
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:00:46.883262
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.96
 ---- batch: 020 ----
mean loss: 131.59
 ---- batch: 030 ----
mean loss: 135.95
train mean loss: 135.38
epoch train time: 0:00:01.436171
elapsed time: 0:06:06.641660
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:00:48.319630
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.86
 ---- batch: 020 ----
mean loss: 132.59
 ---- batch: 030 ----
mean loss: 132.90
train mean loss: 134.10
epoch train time: 0:00:01.437186
elapsed time: 0:06:08.079049
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:00:49.757021
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.12
 ---- batch: 020 ----
mean loss: 134.76
 ---- batch: 030 ----
mean loss: 139.19
train mean loss: 134.24
epoch train time: 0:00:01.438808
elapsed time: 0:06:09.521548
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_3/checkpoint.pth.tar
**** end time: 2019-09-27 16:00:51.199478 ****
