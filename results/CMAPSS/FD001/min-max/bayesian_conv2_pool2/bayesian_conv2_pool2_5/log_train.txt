Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_5', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29143
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 14:52:22.043049 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 14:52:22.053403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4057.90
 ---- batch: 020 ----
mean loss: 3893.11
 ---- batch: 030 ----
mean loss: 3933.84
train mean loss: 3953.28
epoch train time: 0:00:12.683625
elapsed time: 0:00:12.697227
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 14:52:34.740319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3847.96
 ---- batch: 020 ----
mean loss: 3739.50
 ---- batch: 030 ----
mean loss: 3703.12
train mean loss: 3752.48
epoch train time: 0:00:00.541550
elapsed time: 0:00:13.239025
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 14:52:35.282177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3587.75
 ---- batch: 020 ----
mean loss: 3508.43
 ---- batch: 030 ----
mean loss: 3473.63
train mean loss: 3504.49
epoch train time: 0:00:00.538610
elapsed time: 0:00:13.777996
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 14:52:35.821164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3351.09
 ---- batch: 020 ----
mean loss: 3277.00
 ---- batch: 030 ----
mean loss: 3257.01
train mean loss: 3290.82
epoch train time: 0:00:00.530132
elapsed time: 0:00:14.308449
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 14:52:36.351603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3117.29
 ---- batch: 020 ----
mean loss: 3074.40
 ---- batch: 030 ----
mean loss: 3137.48
train mean loss: 3098.02
epoch train time: 0:00:00.523352
elapsed time: 0:00:14.832095
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 14:52:36.875248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2974.28
 ---- batch: 020 ----
mean loss: 2923.02
 ---- batch: 030 ----
mean loss: 2904.88
train mean loss: 2924.65
epoch train time: 0:00:00.508051
elapsed time: 0:00:15.340439
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 14:52:37.383588
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2842.88
 ---- batch: 020 ----
mean loss: 2776.14
 ---- batch: 030 ----
mean loss: 2722.32
train mean loss: 2769.34
epoch train time: 0:00:00.517405
elapsed time: 0:00:15.858128
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 14:52:37.901268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2671.30
 ---- batch: 020 ----
mean loss: 2647.30
 ---- batch: 030 ----
mean loss: 2541.96
train mean loss: 2610.06
epoch train time: 0:00:00.513153
elapsed time: 0:00:16.371557
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 14:52:38.414699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2504.42
 ---- batch: 020 ----
mean loss: 2453.83
 ---- batch: 030 ----
mean loss: 2438.31
train mean loss: 2457.43
epoch train time: 0:00:00.528657
elapsed time: 0:00:16.900526
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 14:52:38.943666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2372.47
 ---- batch: 020 ----
mean loss: 2309.06
 ---- batch: 030 ----
mean loss: 2286.43
train mean loss: 2309.00
epoch train time: 0:00:00.514570
elapsed time: 0:00:17.415365
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 14:52:39.458501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2214.18
 ---- batch: 020 ----
mean loss: 2188.07
 ---- batch: 030 ----
mean loss: 2129.22
train mean loss: 2166.49
epoch train time: 0:00:00.531788
elapsed time: 0:00:17.947439
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 14:52:39.990599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2065.70
 ---- batch: 020 ----
mean loss: 2044.48
 ---- batch: 030 ----
mean loss: 1966.37
train mean loss: 2023.88
epoch train time: 0:00:00.523472
elapsed time: 0:00:18.471223
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 14:52:40.514366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1959.39
 ---- batch: 020 ----
mean loss: 1896.41
 ---- batch: 030 ----
mean loss: 1896.83
train mean loss: 1902.70
epoch train time: 0:00:00.545897
elapsed time: 0:00:19.017411
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 14:52:41.060547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1862.51
 ---- batch: 020 ----
mean loss: 1820.74
 ---- batch: 030 ----
mean loss: 1752.12
train mean loss: 1796.80
epoch train time: 0:00:00.521329
elapsed time: 0:00:19.539026
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 14:52:41.582164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1725.22
 ---- batch: 020 ----
mean loss: 1701.08
 ---- batch: 030 ----
mean loss: 1668.94
train mean loss: 1692.85
epoch train time: 0:00:00.519340
elapsed time: 0:00:20.058647
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 14:52:42.101785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1636.75
 ---- batch: 020 ----
mean loss: 1600.59
 ---- batch: 030 ----
mean loss: 1601.83
train mean loss: 1607.40
epoch train time: 0:00:00.518600
elapsed time: 0:00:20.577523
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 14:52:42.620663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1551.72
 ---- batch: 020 ----
mean loss: 1517.03
 ---- batch: 030 ----
mean loss: 1493.58
train mean loss: 1510.71
epoch train time: 0:00:00.518431
elapsed time: 0:00:21.096228
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 14:52:43.139365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1452.74
 ---- batch: 020 ----
mean loss: 1423.40
 ---- batch: 030 ----
mean loss: 1371.28
train mean loss: 1416.51
epoch train time: 0:00:00.508434
elapsed time: 0:00:21.604976
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 14:52:43.648141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1356.81
 ---- batch: 020 ----
mean loss: 1329.55
 ---- batch: 030 ----
mean loss: 1299.41
train mean loss: 1321.02
epoch train time: 0:00:00.530138
elapsed time: 0:00:22.135417
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 14:52:44.178577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1272.72
 ---- batch: 020 ----
mean loss: 1231.09
 ---- batch: 030 ----
mean loss: 1221.24
train mean loss: 1236.15
epoch train time: 0:00:00.520218
elapsed time: 0:00:22.655923
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 14:52:44.699061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1173.75
 ---- batch: 020 ----
mean loss: 1173.32
 ---- batch: 030 ----
mean loss: 1151.82
train mean loss: 1166.77
epoch train time: 0:00:00.519285
elapsed time: 0:00:23.175523
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 14:52:45.218661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1117.36
 ---- batch: 020 ----
mean loss: 1123.16
 ---- batch: 030 ----
mean loss: 1090.14
train mean loss: 1099.97
epoch train time: 0:00:00.521861
elapsed time: 0:00:23.697677
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 14:52:45.740819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1070.38
 ---- batch: 020 ----
mean loss: 1036.31
 ---- batch: 030 ----
mean loss: 1031.96
train mean loss: 1040.21
epoch train time: 0:00:00.515573
elapsed time: 0:00:24.213604
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 14:52:46.256727
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 994.61
 ---- batch: 020 ----
mean loss: 1004.72
 ---- batch: 030 ----
mean loss: 990.60
train mean loss: 987.97
epoch train time: 0:00:00.519887
elapsed time: 0:00:24.733774
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 14:52:46.776948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 963.67
 ---- batch: 020 ----
mean loss: 961.17
 ---- batch: 030 ----
mean loss: 921.20
train mean loss: 940.20
epoch train time: 0:00:00.526889
elapsed time: 0:00:25.260978
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 14:52:47.304118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 900.46
 ---- batch: 020 ----
mean loss: 903.60
 ---- batch: 030 ----
mean loss: 890.60
train mean loss: 893.41
epoch train time: 0:00:00.534165
elapsed time: 0:00:25.795437
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 14:52:47.838763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 869.43
 ---- batch: 020 ----
mean loss: 865.50
 ---- batch: 030 ----
mean loss: 837.26
train mean loss: 859.36
epoch train time: 0:00:00.525346
elapsed time: 0:00:26.321241
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 14:52:48.364379
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 838.58
 ---- batch: 020 ----
mean loss: 830.66
 ---- batch: 030 ----
mean loss: 801.25
train mean loss: 821.00
epoch train time: 0:00:00.523395
elapsed time: 0:00:26.844898
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 14:52:48.888034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 787.76
 ---- batch: 020 ----
mean loss: 799.18
 ---- batch: 030 ----
mean loss: 768.69
train mean loss: 780.25
epoch train time: 0:00:00.513962
elapsed time: 0:00:27.359187
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 14:52:49.402359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 755.76
 ---- batch: 020 ----
mean loss: 744.42
 ---- batch: 030 ----
mean loss: 741.12
train mean loss: 747.83
epoch train time: 0:00:00.520316
elapsed time: 0:00:27.879834
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 14:52:49.922979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 731.72
 ---- batch: 020 ----
mean loss: 712.88
 ---- batch: 030 ----
mean loss: 727.44
train mean loss: 721.78
epoch train time: 0:00:00.532754
elapsed time: 0:00:28.412876
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 14:52:50.456068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 708.15
 ---- batch: 020 ----
mean loss: 694.54
 ---- batch: 030 ----
mean loss: 689.08
train mean loss: 693.53
epoch train time: 0:00:00.536977
elapsed time: 0:00:28.950211
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 14:52:50.993350
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 681.91
 ---- batch: 020 ----
mean loss: 661.85
 ---- batch: 030 ----
mean loss: 649.87
train mean loss: 666.96
epoch train time: 0:00:00.534302
elapsed time: 0:00:29.484783
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 14:52:51.527969
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 651.18
 ---- batch: 020 ----
mean loss: 655.87
 ---- batch: 030 ----
mean loss: 638.28
train mean loss: 645.52
epoch train time: 0:00:00.538219
elapsed time: 0:00:30.023329
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 14:52:52.066470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 625.08
 ---- batch: 020 ----
mean loss: 634.21
 ---- batch: 030 ----
mean loss: 620.80
train mean loss: 625.45
epoch train time: 0:00:00.532361
elapsed time: 0:00:30.555964
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 14:52:52.599104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 610.00
 ---- batch: 020 ----
mean loss: 602.20
 ---- batch: 030 ----
mean loss: 610.95
train mean loss: 607.66
epoch train time: 0:00:00.520783
elapsed time: 0:00:31.077021
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 14:52:53.120163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 594.42
 ---- batch: 020 ----
mean loss: 589.22
 ---- batch: 030 ----
mean loss: 580.32
train mean loss: 584.57
epoch train time: 0:00:00.512928
elapsed time: 0:00:31.590214
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 14:52:53.633351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 575.16
 ---- batch: 020 ----
mean loss: 564.84
 ---- batch: 030 ----
mean loss: 576.03
train mean loss: 571.55
epoch train time: 0:00:00.534043
elapsed time: 0:00:32.124521
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 14:52:54.167698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 570.27
 ---- batch: 020 ----
mean loss: 552.10
 ---- batch: 030 ----
mean loss: 549.77
train mean loss: 556.52
epoch train time: 0:00:00.521635
elapsed time: 0:00:32.646507
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 14:52:54.689682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 543.10
 ---- batch: 020 ----
mean loss: 537.46
 ---- batch: 030 ----
mean loss: 540.20
train mean loss: 540.16
epoch train time: 0:00:00.524552
elapsed time: 0:00:33.171372
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 14:52:55.214525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 530.13
 ---- batch: 020 ----
mean loss: 522.37
 ---- batch: 030 ----
mean loss: 525.99
train mean loss: 526.20
epoch train time: 0:00:00.525749
elapsed time: 0:00:33.697418
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 14:52:55.740557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 520.05
 ---- batch: 020 ----
mean loss: 506.39
 ---- batch: 030 ----
mean loss: 514.26
train mean loss: 513.49
epoch train time: 0:00:00.531576
elapsed time: 0:00:34.229303
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 14:52:56.272442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 513.86
 ---- batch: 020 ----
mean loss: 501.31
 ---- batch: 030 ----
mean loss: 498.41
train mean loss: 504.04
epoch train time: 0:00:00.523315
elapsed time: 0:00:34.752911
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 14:52:56.796052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 489.05
 ---- batch: 020 ----
mean loss: 506.65
 ---- batch: 030 ----
mean loss: 486.06
train mean loss: 492.76
epoch train time: 0:00:00.511005
elapsed time: 0:00:35.264185
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 14:52:57.307322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 484.32
 ---- batch: 020 ----
mean loss: 478.31
 ---- batch: 030 ----
mean loss: 483.30
train mean loss: 481.98
epoch train time: 0:00:00.515273
elapsed time: 0:00:35.779813
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 14:52:57.822961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 474.90
 ---- batch: 020 ----
mean loss: 473.02
 ---- batch: 030 ----
mean loss: 475.19
train mean loss: 475.70
epoch train time: 0:00:00.518947
elapsed time: 0:00:36.299032
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 14:52:58.342179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 465.06
 ---- batch: 020 ----
mean loss: 465.25
 ---- batch: 030 ----
mean loss: 468.06
train mean loss: 464.71
epoch train time: 0:00:00.538510
elapsed time: 0:00:36.837873
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 14:52:58.881014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 457.57
 ---- batch: 020 ----
mean loss: 457.55
 ---- batch: 030 ----
mean loss: 451.88
train mean loss: 453.50
epoch train time: 0:00:00.514486
elapsed time: 0:00:37.352653
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 14:52:59.395811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 457.87
 ---- batch: 020 ----
mean loss: 448.97
 ---- batch: 030 ----
mean loss: 439.07
train mean loss: 446.96
epoch train time: 0:00:00.520797
elapsed time: 0:00:37.873800
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 14:52:59.916969
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 449.91
 ---- batch: 020 ----
mean loss: 442.41
 ---- batch: 030 ----
mean loss: 439.41
train mean loss: 441.88
epoch train time: 0:00:00.516303
elapsed time: 0:00:38.390413
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 14:53:00.433559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 437.77
 ---- batch: 020 ----
mean loss: 431.39
 ---- batch: 030 ----
mean loss: 433.54
train mean loss: 432.42
epoch train time: 0:00:00.521881
elapsed time: 0:00:38.912580
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 14:53:00.955741
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 432.68
 ---- batch: 020 ----
mean loss: 417.65
 ---- batch: 030 ----
mean loss: 428.29
train mean loss: 426.93
epoch train time: 0:00:00.522006
elapsed time: 0:00:39.434882
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 14:53:01.478019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 425.80
 ---- batch: 020 ----
mean loss: 424.31
 ---- batch: 030 ----
mean loss: 409.05
train mean loss: 419.89
epoch train time: 0:00:00.519287
elapsed time: 0:00:39.954448
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 14:53:01.997587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 410.67
 ---- batch: 020 ----
mean loss: 416.04
 ---- batch: 030 ----
mean loss: 415.13
train mean loss: 413.37
epoch train time: 0:00:00.526697
elapsed time: 0:00:40.481459
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 14:53:02.524607
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 414.79
 ---- batch: 020 ----
mean loss: 409.49
 ---- batch: 030 ----
mean loss: 405.60
train mean loss: 408.67
epoch train time: 0:00:00.521694
elapsed time: 0:00:41.003439
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 14:53:03.046591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.03
 ---- batch: 020 ----
mean loss: 399.78
 ---- batch: 030 ----
mean loss: 401.88
train mean loss: 401.22
epoch train time: 0:00:00.513123
elapsed time: 0:00:41.517192
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 14:53:03.560336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 398.46
 ---- batch: 020 ----
mean loss: 404.86
 ---- batch: 030 ----
mean loss: 391.73
train mean loss: 397.67
epoch train time: 0:00:00.524712
elapsed time: 0:00:42.042218
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 14:53:04.085364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 398.31
 ---- batch: 020 ----
mean loss: 392.49
 ---- batch: 030 ----
mean loss: 391.04
train mean loss: 392.72
epoch train time: 0:00:00.526742
elapsed time: 0:00:42.569262
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 14:53:04.612418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 385.63
 ---- batch: 020 ----
mean loss: 393.33
 ---- batch: 030 ----
mean loss: 390.05
train mean loss: 387.13
epoch train time: 0:00:00.540557
elapsed time: 0:00:43.110124
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 14:53:05.153282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 387.75
 ---- batch: 020 ----
mean loss: 385.60
 ---- batch: 030 ----
mean loss: 377.25
train mean loss: 382.61
epoch train time: 0:00:00.510621
elapsed time: 0:00:43.621071
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 14:53:05.664215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 383.95
 ---- batch: 020 ----
mean loss: 373.44
 ---- batch: 030 ----
mean loss: 379.18
train mean loss: 379.28
epoch train time: 0:00:00.524258
elapsed time: 0:00:44.145622
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 14:53:06.188760
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.12
 ---- batch: 020 ----
mean loss: 369.95
 ---- batch: 030 ----
mean loss: 384.98
train mean loss: 375.32
epoch train time: 0:00:00.510991
elapsed time: 0:00:44.656902
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 14:53:06.700042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.57
 ---- batch: 020 ----
mean loss: 375.35
 ---- batch: 030 ----
mean loss: 365.38
train mean loss: 369.96
epoch train time: 0:00:00.510121
elapsed time: 0:00:45.167371
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 14:53:07.210503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.41
 ---- batch: 020 ----
mean loss: 371.48
 ---- batch: 030 ----
mean loss: 364.47
train mean loss: 366.46
epoch train time: 0:00:00.510023
elapsed time: 0:00:45.677665
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 14:53:07.720818
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.52
 ---- batch: 020 ----
mean loss: 361.58
 ---- batch: 030 ----
mean loss: 367.57
train mean loss: 365.67
epoch train time: 0:00:00.525966
elapsed time: 0:00:46.203949
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 14:53:08.247112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 360.61
 ---- batch: 020 ----
mean loss: 360.15
 ---- batch: 030 ----
mean loss: 362.95
train mean loss: 361.75
epoch train time: 0:00:00.526174
elapsed time: 0:00:46.730456
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 14:53:08.773600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 357.53
 ---- batch: 020 ----
mean loss: 354.70
 ---- batch: 030 ----
mean loss: 357.22
train mean loss: 357.62
epoch train time: 0:00:00.511477
elapsed time: 0:00:47.242209
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 14:53:09.285348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 355.65
 ---- batch: 020 ----
mean loss: 350.89
 ---- batch: 030 ----
mean loss: 357.63
train mean loss: 355.49
epoch train time: 0:00:00.517227
elapsed time: 0:00:47.759724
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 14:53:09.802863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.60
 ---- batch: 020 ----
mean loss: 356.28
 ---- batch: 030 ----
mean loss: 347.40
train mean loss: 352.37
epoch train time: 0:00:00.517583
elapsed time: 0:00:48.277570
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 14:53:10.320708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.84
 ---- batch: 020 ----
mean loss: 349.24
 ---- batch: 030 ----
mean loss: 351.59
train mean loss: 349.82
epoch train time: 0:00:00.531981
elapsed time: 0:00:48.809815
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 14:53:10.852949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 347.36
 ---- batch: 020 ----
mean loss: 341.92
 ---- batch: 030 ----
mean loss: 352.05
train mean loss: 346.68
epoch train time: 0:00:00.511223
elapsed time: 0:00:49.321320
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 14:53:11.364459
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.65
 ---- batch: 020 ----
mean loss: 344.53
 ---- batch: 030 ----
mean loss: 339.22
train mean loss: 345.77
epoch train time: 0:00:00.521846
elapsed time: 0:00:49.843460
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 14:53:11.886602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 344.63
 ---- batch: 020 ----
mean loss: 346.54
 ---- batch: 030 ----
mean loss: 340.43
train mean loss: 343.15
epoch train time: 0:00:00.516508
elapsed time: 0:00:50.360266
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 14:53:12.403405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 342.58
 ---- batch: 020 ----
mean loss: 347.51
 ---- batch: 030 ----
mean loss: 339.24
train mean loss: 341.74
epoch train time: 0:00:00.521221
elapsed time: 0:00:50.881777
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 14:53:12.924954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 342.93
 ---- batch: 020 ----
mean loss: 336.08
 ---- batch: 030 ----
mean loss: 338.83
train mean loss: 338.24
epoch train time: 0:00:00.512971
elapsed time: 0:00:51.395050
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 14:53:13.438187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 332.12
 ---- batch: 020 ----
mean loss: 341.47
 ---- batch: 030 ----
mean loss: 337.70
train mean loss: 336.43
epoch train time: 0:00:00.522425
elapsed time: 0:00:51.917781
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 14:53:13.960947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 338.63
 ---- batch: 020 ----
mean loss: 330.53
 ---- batch: 030 ----
mean loss: 329.42
train mean loss: 333.92
epoch train time: 0:00:00.527469
elapsed time: 0:00:52.445566
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 14:53:14.488708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.80
 ---- batch: 020 ----
mean loss: 334.81
 ---- batch: 030 ----
mean loss: 335.87
train mean loss: 331.50
epoch train time: 0:00:00.529832
elapsed time: 0:00:52.975720
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 14:53:15.018884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.95
 ---- batch: 020 ----
mean loss: 326.25
 ---- batch: 030 ----
mean loss: 324.52
train mean loss: 331.13
epoch train time: 0:00:00.529444
elapsed time: 0:00:53.505463
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 14:53:15.548606
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.46
 ---- batch: 020 ----
mean loss: 329.62
 ---- batch: 030 ----
mean loss: 334.44
train mean loss: 330.16
epoch train time: 0:00:00.521882
elapsed time: 0:00:54.027616
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 14:53:16.070753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.98
 ---- batch: 020 ----
mean loss: 323.95
 ---- batch: 030 ----
mean loss: 341.75
train mean loss: 328.64
epoch train time: 0:00:00.511159
elapsed time: 0:00:54.539095
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 14:53:16.582258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 318.59
 ---- batch: 020 ----
mean loss: 326.73
 ---- batch: 030 ----
mean loss: 323.80
train mean loss: 324.33
epoch train time: 0:00:00.524511
elapsed time: 0:00:55.063908
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 14:53:17.107049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.50
 ---- batch: 020 ----
mean loss: 318.14
 ---- batch: 030 ----
mean loss: 323.20
train mean loss: 323.60
epoch train time: 0:00:00.539803
elapsed time: 0:00:55.604020
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 14:53:17.647164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.36
 ---- batch: 020 ----
mean loss: 326.92
 ---- batch: 030 ----
mean loss: 322.76
train mean loss: 323.68
epoch train time: 0:00:00.539882
elapsed time: 0:00:56.144180
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 14:53:18.187320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.47
 ---- batch: 020 ----
mean loss: 318.64
 ---- batch: 030 ----
mean loss: 322.57
train mean loss: 321.81
epoch train time: 0:00:00.521133
elapsed time: 0:00:56.665596
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 14:53:18.708751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.67
 ---- batch: 020 ----
mean loss: 322.73
 ---- batch: 030 ----
mean loss: 317.10
train mean loss: 319.21
epoch train time: 0:00:00.519764
elapsed time: 0:00:57.185669
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 14:53:19.228837
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 316.95
 ---- batch: 020 ----
mean loss: 317.93
 ---- batch: 030 ----
mean loss: 314.88
train mean loss: 316.89
epoch train time: 0:00:00.513999
elapsed time: 0:00:57.699970
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 14:53:19.743105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.42
 ---- batch: 020 ----
mean loss: 325.27
 ---- batch: 030 ----
mean loss: 308.65
train mean loss: 316.83
epoch train time: 0:00:00.517631
elapsed time: 0:00:58.217891
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 14:53:20.261035
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.26
 ---- batch: 020 ----
mean loss: 313.30
 ---- batch: 030 ----
mean loss: 311.41
train mean loss: 317.11
epoch train time: 0:00:00.513657
elapsed time: 0:00:58.731870
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 14:53:20.775019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.09
 ---- batch: 020 ----
mean loss: 310.18
 ---- batch: 030 ----
mean loss: 315.71
train mean loss: 313.48
epoch train time: 0:00:00.510647
elapsed time: 0:00:59.242824
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 14:53:21.285972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 310.14
 ---- batch: 020 ----
mean loss: 316.20
 ---- batch: 030 ----
mean loss: 312.11
train mean loss: 312.69
epoch train time: 0:00:00.514733
elapsed time: 0:00:59.757869
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 14:53:21.801017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.10
 ---- batch: 020 ----
mean loss: 310.67
 ---- batch: 030 ----
mean loss: 314.49
train mean loss: 310.58
epoch train time: 0:00:00.525704
elapsed time: 0:01:00.283868
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 14:53:22.327033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 313.87
 ---- batch: 020 ----
mean loss: 312.05
 ---- batch: 030 ----
mean loss: 305.70
train mean loss: 310.24
epoch train time: 0:00:00.518589
elapsed time: 0:01:00.802805
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 14:53:22.845968
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.65
 ---- batch: 020 ----
mean loss: 305.22
 ---- batch: 030 ----
mean loss: 314.73
train mean loss: 310.06
epoch train time: 0:00:00.519469
elapsed time: 0:01:01.322600
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 14:53:23.365738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.59
 ---- batch: 020 ----
mean loss: 301.51
 ---- batch: 030 ----
mean loss: 310.67
train mean loss: 307.06
epoch train time: 0:00:00.529189
elapsed time: 0:01:01.852137
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 14:53:23.895289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 304.52
 ---- batch: 020 ----
mean loss: 303.69
 ---- batch: 030 ----
mean loss: 311.96
train mean loss: 307.24
epoch train time: 0:00:00.525573
elapsed time: 0:01:02.377999
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 14:53:24.421137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 301.25
 ---- batch: 020 ----
mean loss: 303.95
 ---- batch: 030 ----
mean loss: 310.07
train mean loss: 304.94
epoch train time: 0:00:00.532083
elapsed time: 0:01:02.910352
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 14:53:24.953519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.12
 ---- batch: 020 ----
mean loss: 300.46
 ---- batch: 030 ----
mean loss: 303.70
train mean loss: 304.51
epoch train time: 0:00:00.517133
elapsed time: 0:01:03.427777
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 14:53:25.470911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 301.24
 ---- batch: 020 ----
mean loss: 302.25
 ---- batch: 030 ----
mean loss: 300.65
train mean loss: 303.09
epoch train time: 0:00:00.518407
elapsed time: 0:01:03.946450
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 14:53:25.989589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.92
 ---- batch: 020 ----
mean loss: 295.50
 ---- batch: 030 ----
mean loss: 304.59
train mean loss: 301.80
epoch train time: 0:00:00.515472
elapsed time: 0:01:04.462235
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 14:53:26.505370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.32
 ---- batch: 020 ----
mean loss: 302.37
 ---- batch: 030 ----
mean loss: 293.25
train mean loss: 301.03
epoch train time: 0:00:00.535627
elapsed time: 0:01:04.998152
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 14:53:27.041293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 295.89
 ---- batch: 020 ----
mean loss: 305.62
 ---- batch: 030 ----
mean loss: 299.86
train mean loss: 299.58
epoch train time: 0:00:00.527590
elapsed time: 0:01:05.526030
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 14:53:27.569183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.84
 ---- batch: 020 ----
mean loss: 300.87
 ---- batch: 030 ----
mean loss: 297.36
train mean loss: 298.39
epoch train time: 0:00:00.519320
elapsed time: 0:01:06.045662
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 14:53:28.088830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.07
 ---- batch: 020 ----
mean loss: 299.49
 ---- batch: 030 ----
mean loss: 300.80
train mean loss: 297.41
epoch train time: 0:00:00.510164
elapsed time: 0:01:06.556133
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 14:53:28.599271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.29
 ---- batch: 020 ----
mean loss: 301.62
 ---- batch: 030 ----
mean loss: 295.18
train mean loss: 295.74
epoch train time: 0:00:00.541044
elapsed time: 0:01:07.097458
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 14:53:29.140615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.79
 ---- batch: 020 ----
mean loss: 297.15
 ---- batch: 030 ----
mean loss: 300.93
train mean loss: 295.25
epoch train time: 0:00:00.528827
elapsed time: 0:01:07.626648
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 14:53:29.669791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.33
 ---- batch: 020 ----
mean loss: 295.28
 ---- batch: 030 ----
mean loss: 291.79
train mean loss: 293.10
epoch train time: 0:00:00.533586
elapsed time: 0:01:08.160581
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 14:53:30.203681
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 295.12
 ---- batch: 020 ----
mean loss: 284.92
 ---- batch: 030 ----
mean loss: 295.60
train mean loss: 291.31
epoch train time: 0:00:00.530613
elapsed time: 0:01:08.691449
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 14:53:30.734594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.36
 ---- batch: 020 ----
mean loss: 298.20
 ---- batch: 030 ----
mean loss: 285.22
train mean loss: 291.91
epoch train time: 0:00:00.527394
elapsed time: 0:01:09.219128
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 14:53:31.262266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.01
 ---- batch: 020 ----
mean loss: 286.47
 ---- batch: 030 ----
mean loss: 294.16
train mean loss: 291.37
epoch train time: 0:00:00.528829
elapsed time: 0:01:09.748241
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 14:53:31.791382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.08
 ---- batch: 020 ----
mean loss: 291.55
 ---- batch: 030 ----
mean loss: 289.86
train mean loss: 289.05
epoch train time: 0:00:00.528657
elapsed time: 0:01:10.277180
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 14:53:32.320321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.36
 ---- batch: 020 ----
mean loss: 285.42
 ---- batch: 030 ----
mean loss: 289.19
train mean loss: 288.56
epoch train time: 0:00:00.530062
elapsed time: 0:01:10.807546
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 14:53:32.850690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.87
 ---- batch: 020 ----
mean loss: 287.30
 ---- batch: 030 ----
mean loss: 284.11
train mean loss: 287.78
epoch train time: 0:00:00.526034
elapsed time: 0:01:11.333865
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 14:53:33.377007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.06
 ---- batch: 020 ----
mean loss: 285.69
 ---- batch: 030 ----
mean loss: 289.31
train mean loss: 286.51
epoch train time: 0:00:00.529268
elapsed time: 0:01:11.863432
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 14:53:33.906579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.06
 ---- batch: 020 ----
mean loss: 288.17
 ---- batch: 030 ----
mean loss: 292.16
train mean loss: 285.80
epoch train time: 0:00:00.531160
elapsed time: 0:01:12.394873
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 14:53:34.438014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.79
 ---- batch: 020 ----
mean loss: 286.85
 ---- batch: 030 ----
mean loss: 283.12
train mean loss: 284.45
epoch train time: 0:00:00.547732
elapsed time: 0:01:12.942906
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 14:53:34.986051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.48
 ---- batch: 020 ----
mean loss: 286.36
 ---- batch: 030 ----
mean loss: 283.71
train mean loss: 283.17
epoch train time: 0:00:00.525486
elapsed time: 0:01:13.468717
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 14:53:35.511916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.22
 ---- batch: 020 ----
mean loss: 286.56
 ---- batch: 030 ----
mean loss: 281.64
train mean loss: 281.29
epoch train time: 0:00:00.528928
elapsed time: 0:01:13.998050
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 14:53:36.041206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.98
 ---- batch: 020 ----
mean loss: 284.43
 ---- batch: 030 ----
mean loss: 281.38
train mean loss: 282.09
epoch train time: 0:00:00.533189
elapsed time: 0:01:14.531545
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 14:53:36.574719
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.06
 ---- batch: 020 ----
mean loss: 278.03
 ---- batch: 030 ----
mean loss: 283.29
train mean loss: 280.80
epoch train time: 0:00:00.545967
elapsed time: 0:01:15.077834
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 14:53:37.120995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 281.18
 ---- batch: 020 ----
mean loss: 277.47
 ---- batch: 030 ----
mean loss: 276.13
train mean loss: 278.84
epoch train time: 0:00:00.533565
elapsed time: 0:01:15.611713
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 14:53:37.654853
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.75
 ---- batch: 020 ----
mean loss: 276.68
 ---- batch: 030 ----
mean loss: 283.86
train mean loss: 277.96
epoch train time: 0:00:00.543456
elapsed time: 0:01:16.155487
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 14:53:38.198659
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.04
 ---- batch: 020 ----
mean loss: 278.08
 ---- batch: 030 ----
mean loss: 279.42
train mean loss: 278.08
epoch train time: 0:00:00.532815
elapsed time: 0:01:16.688612
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 14:53:38.731750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.44
 ---- batch: 020 ----
mean loss: 274.86
 ---- batch: 030 ----
mean loss: 277.39
train mean loss: 276.20
epoch train time: 0:00:00.527583
elapsed time: 0:01:17.216698
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 14:53:39.259849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 279.64
 ---- batch: 020 ----
mean loss: 271.63
 ---- batch: 030 ----
mean loss: 275.12
train mean loss: 275.61
epoch train time: 0:00:00.523682
elapsed time: 0:01:17.740672
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 14:53:39.783844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 280.50
 ---- batch: 020 ----
mean loss: 270.95
 ---- batch: 030 ----
mean loss: 271.35
train mean loss: 276.40
epoch train time: 0:00:00.527514
elapsed time: 0:01:18.268497
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 14:53:40.311639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.84
 ---- batch: 020 ----
mean loss: 278.74
 ---- batch: 030 ----
mean loss: 273.59
train mean loss: 274.30
epoch train time: 0:00:00.519305
elapsed time: 0:01:18.788248
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 14:53:40.831360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.92
 ---- batch: 020 ----
mean loss: 271.04
 ---- batch: 030 ----
mean loss: 277.10
train mean loss: 273.19
epoch train time: 0:00:00.506924
elapsed time: 0:01:19.295424
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 14:53:41.338562
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.88
 ---- batch: 020 ----
mean loss: 274.20
 ---- batch: 030 ----
mean loss: 268.77
train mean loss: 271.13
epoch train time: 0:00:00.511216
elapsed time: 0:01:19.806925
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 14:53:41.850064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.06
 ---- batch: 020 ----
mean loss: 272.51
 ---- batch: 030 ----
mean loss: 270.67
train mean loss: 271.45
epoch train time: 0:00:00.513140
elapsed time: 0:01:20.320360
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 14:53:42.363515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.06
 ---- batch: 020 ----
mean loss: 269.50
 ---- batch: 030 ----
mean loss: 279.78
train mean loss: 272.03
epoch train time: 0:00:00.521537
elapsed time: 0:01:20.842197
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 14:53:42.885337
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.70
 ---- batch: 020 ----
mean loss: 275.36
 ---- batch: 030 ----
mean loss: 266.67
train mean loss: 270.12
epoch train time: 0:00:00.530306
elapsed time: 0:01:21.372792
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 14:53:43.415957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.94
 ---- batch: 020 ----
mean loss: 271.50
 ---- batch: 030 ----
mean loss: 270.98
train mean loss: 269.00
epoch train time: 0:00:00.537301
elapsed time: 0:01:21.910417
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 14:53:43.953562
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.78
 ---- batch: 020 ----
mean loss: 265.54
 ---- batch: 030 ----
mean loss: 263.95
train mean loss: 268.06
epoch train time: 0:00:00.526606
elapsed time: 0:01:22.437316
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 14:53:44.480461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.93
 ---- batch: 020 ----
mean loss: 262.53
 ---- batch: 030 ----
mean loss: 271.09
train mean loss: 267.44
epoch train time: 0:00:00.520805
elapsed time: 0:01:22.958395
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 14:53:45.001531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.14
 ---- batch: 020 ----
mean loss: 267.91
 ---- batch: 030 ----
mean loss: 269.41
train mean loss: 266.37
epoch train time: 0:00:00.534319
elapsed time: 0:01:23.492989
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 14:53:45.536132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.44
 ---- batch: 020 ----
mean loss: 264.00
 ---- batch: 030 ----
mean loss: 260.27
train mean loss: 265.52
epoch train time: 0:00:00.523478
elapsed time: 0:01:24.016739
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 14:53:46.059875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.04
 ---- batch: 020 ----
mean loss: 263.34
 ---- batch: 030 ----
mean loss: 268.36
train mean loss: 265.03
epoch train time: 0:00:00.521828
elapsed time: 0:01:24.538844
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 14:53:46.581993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.20
 ---- batch: 020 ----
mean loss: 264.14
 ---- batch: 030 ----
mean loss: 264.60
train mean loss: 264.18
epoch train time: 0:00:00.525186
elapsed time: 0:01:25.064321
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 14:53:47.107464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.74
 ---- batch: 020 ----
mean loss: 262.80
 ---- batch: 030 ----
mean loss: 258.04
train mean loss: 262.97
epoch train time: 0:00:00.534276
elapsed time: 0:01:25.599039
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 14:53:47.642227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.48
 ---- batch: 020 ----
mean loss: 265.87
 ---- batch: 030 ----
mean loss: 256.44
train mean loss: 261.78
epoch train time: 0:00:00.531151
elapsed time: 0:01:26.130531
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 14:53:48.173700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.67
 ---- batch: 020 ----
mean loss: 259.09
 ---- batch: 030 ----
mean loss: 259.36
train mean loss: 261.12
epoch train time: 0:00:00.522680
elapsed time: 0:01:26.653534
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 14:53:48.696697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.03
 ---- batch: 020 ----
mean loss: 262.27
 ---- batch: 030 ----
mean loss: 261.98
train mean loss: 260.43
epoch train time: 0:00:00.520047
elapsed time: 0:01:27.173886
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 14:53:49.217027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.03
 ---- batch: 020 ----
mean loss: 262.83
 ---- batch: 030 ----
mean loss: 259.54
train mean loss: 260.04
epoch train time: 0:00:00.519690
elapsed time: 0:01:27.693871
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 14:53:49.737011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.38
 ---- batch: 020 ----
mean loss: 257.19
 ---- batch: 030 ----
mean loss: 261.39
train mean loss: 258.63
epoch train time: 0:00:00.528900
elapsed time: 0:01:28.223055
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 14:53:50.266203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.32
 ---- batch: 020 ----
mean loss: 264.10
 ---- batch: 030 ----
mean loss: 255.29
train mean loss: 258.29
epoch train time: 0:00:00.543270
elapsed time: 0:01:28.766729
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 14:53:50.809887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.99
 ---- batch: 020 ----
mean loss: 260.52
 ---- batch: 030 ----
mean loss: 254.26
train mean loss: 257.00
epoch train time: 0:00:00.521901
elapsed time: 0:01:29.288912
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 14:53:51.332042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.09
 ---- batch: 020 ----
mean loss: 254.41
 ---- batch: 030 ----
mean loss: 255.06
train mean loss: 256.11
epoch train time: 0:00:00.531217
elapsed time: 0:01:29.820416
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 14:53:51.863560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.41
 ---- batch: 020 ----
mean loss: 255.06
 ---- batch: 030 ----
mean loss: 259.27
train mean loss: 255.91
epoch train time: 0:00:00.520528
elapsed time: 0:01:30.341267
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 14:53:52.384356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.25
 ---- batch: 020 ----
mean loss: 251.08
 ---- batch: 030 ----
mean loss: 263.59
train mean loss: 254.98
epoch train time: 0:00:00.525872
elapsed time: 0:01:30.867373
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 14:53:52.910545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.26
 ---- batch: 020 ----
mean loss: 259.67
 ---- batch: 030 ----
mean loss: 252.64
train mean loss: 254.12
epoch train time: 0:00:00.526871
elapsed time: 0:01:31.394579
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 14:53:53.437742
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.65
 ---- batch: 020 ----
mean loss: 256.24
 ---- batch: 030 ----
mean loss: 252.04
train mean loss: 253.33
epoch train time: 0:00:00.536069
elapsed time: 0:01:31.930963
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 14:53:53.974103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.73
 ---- batch: 020 ----
mean loss: 253.63
 ---- batch: 030 ----
mean loss: 245.91
train mean loss: 252.41
epoch train time: 0:00:00.520720
elapsed time: 0:01:32.451978
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 14:53:54.495134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.86
 ---- batch: 020 ----
mean loss: 251.07
 ---- batch: 030 ----
mean loss: 253.34
train mean loss: 251.78
epoch train time: 0:00:00.535383
elapsed time: 0:01:32.987677
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 14:53:55.030827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.70
 ---- batch: 020 ----
mean loss: 252.79
 ---- batch: 030 ----
mean loss: 252.96
train mean loss: 251.16
epoch train time: 0:00:00.519466
elapsed time: 0:01:33.507426
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 14:53:55.550582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.19
 ---- batch: 020 ----
mean loss: 248.52
 ---- batch: 030 ----
mean loss: 247.99
train mean loss: 251.37
epoch train time: 0:00:00.531148
elapsed time: 0:01:34.038874
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 14:53:56.082018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.71
 ---- batch: 020 ----
mean loss: 250.41
 ---- batch: 030 ----
mean loss: 245.38
train mean loss: 249.41
epoch train time: 0:00:00.536935
elapsed time: 0:01:34.576115
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 14:53:56.619288
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.18
 ---- batch: 020 ----
mean loss: 255.71
 ---- batch: 030 ----
mean loss: 247.81
train mean loss: 248.68
epoch train time: 0:00:00.535492
elapsed time: 0:01:35.111914
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 14:53:57.155050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.41
 ---- batch: 020 ----
mean loss: 243.57
 ---- batch: 030 ----
mean loss: 249.91
train mean loss: 247.51
epoch train time: 0:00:00.530589
elapsed time: 0:01:35.642812
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 14:53:57.685990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.68
 ---- batch: 020 ----
mean loss: 246.39
 ---- batch: 030 ----
mean loss: 246.67
train mean loss: 246.83
epoch train time: 0:00:00.554463
elapsed time: 0:01:36.197589
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 14:53:58.240740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.49
 ---- batch: 020 ----
mean loss: 249.83
 ---- batch: 030 ----
mean loss: 243.89
train mean loss: 245.83
epoch train time: 0:00:00.536780
elapsed time: 0:01:36.734725
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 14:53:58.777871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.50
 ---- batch: 020 ----
mean loss: 244.61
 ---- batch: 030 ----
mean loss: 248.94
train mean loss: 246.03
epoch train time: 0:00:00.534253
elapsed time: 0:01:37.269268
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 14:53:59.312433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.47
 ---- batch: 020 ----
mean loss: 243.75
 ---- batch: 030 ----
mean loss: 248.90
train mean loss: 244.92
epoch train time: 0:00:00.532383
elapsed time: 0:01:37.801975
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 14:53:59.845125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.68
 ---- batch: 020 ----
mean loss: 249.05
 ---- batch: 030 ----
mean loss: 242.48
train mean loss: 243.69
epoch train time: 0:00:00.546819
elapsed time: 0:01:38.349083
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 14:54:00.392223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.34
 ---- batch: 020 ----
mean loss: 247.25
 ---- batch: 030 ----
mean loss: 243.36
train mean loss: 243.42
epoch train time: 0:00:00.527884
elapsed time: 0:01:38.877284
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 14:54:00.920422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.99
 ---- batch: 020 ----
mean loss: 244.82
 ---- batch: 030 ----
mean loss: 240.51
train mean loss: 242.66
epoch train time: 0:00:00.517243
elapsed time: 0:01:39.394806
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 14:54:01.437946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.97
 ---- batch: 020 ----
mean loss: 246.46
 ---- batch: 030 ----
mean loss: 240.83
train mean loss: 242.31
epoch train time: 0:00:00.517714
elapsed time: 0:01:39.912820
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 14:54:01.956000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.07
 ---- batch: 020 ----
mean loss: 237.67
 ---- batch: 030 ----
mean loss: 246.57
train mean loss: 241.30
epoch train time: 0:00:00.516841
elapsed time: 0:01:40.429991
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 14:54:02.473128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.85
 ---- batch: 020 ----
mean loss: 238.94
 ---- batch: 030 ----
mean loss: 240.46
train mean loss: 240.71
epoch train time: 0:00:00.533433
elapsed time: 0:01:40.963761
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 14:54:03.006913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.28
 ---- batch: 020 ----
mean loss: 240.56
 ---- batch: 030 ----
mean loss: 235.62
train mean loss: 240.09
epoch train time: 0:00:00.529170
elapsed time: 0:01:41.493225
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 14:54:03.536368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.28
 ---- batch: 020 ----
mean loss: 240.87
 ---- batch: 030 ----
mean loss: 240.72
train mean loss: 240.31
epoch train time: 0:00:00.535622
elapsed time: 0:01:42.029127
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 14:54:04.072255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.52
 ---- batch: 020 ----
mean loss: 240.52
 ---- batch: 030 ----
mean loss: 239.99
train mean loss: 238.21
epoch train time: 0:00:00.520079
elapsed time: 0:01:42.549470
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 14:54:04.592609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.71
 ---- batch: 020 ----
mean loss: 230.38
 ---- batch: 030 ----
mean loss: 241.39
train mean loss: 238.61
epoch train time: 0:00:00.521681
elapsed time: 0:01:43.071433
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 14:54:05.114598
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.70
 ---- batch: 020 ----
mean loss: 241.68
 ---- batch: 030 ----
mean loss: 231.70
train mean loss: 236.67
epoch train time: 0:00:00.509461
elapsed time: 0:01:43.581222
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 14:54:05.624310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.87
 ---- batch: 020 ----
mean loss: 240.52
 ---- batch: 030 ----
mean loss: 239.31
train mean loss: 236.88
epoch train time: 0:00:00.524609
elapsed time: 0:01:44.106044
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 14:54:06.149180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.24
 ---- batch: 020 ----
mean loss: 236.94
 ---- batch: 030 ----
mean loss: 236.90
train mean loss: 236.88
epoch train time: 0:00:00.511592
elapsed time: 0:01:44.617931
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 14:54:06.661071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.72
 ---- batch: 020 ----
mean loss: 227.93
 ---- batch: 030 ----
mean loss: 242.43
train mean loss: 234.66
epoch train time: 0:00:00.529099
elapsed time: 0:01:45.147334
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 14:54:07.190472
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.99
 ---- batch: 020 ----
mean loss: 229.39
 ---- batch: 030 ----
mean loss: 235.91
train mean loss: 234.91
epoch train time: 0:00:00.523350
elapsed time: 0:01:45.670974
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 14:54:07.714109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.47
 ---- batch: 020 ----
mean loss: 241.76
 ---- batch: 030 ----
mean loss: 227.72
train mean loss: 233.87
epoch train time: 0:00:00.512394
elapsed time: 0:01:46.183673
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 14:54:08.226814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.18
 ---- batch: 020 ----
mean loss: 232.76
 ---- batch: 030 ----
mean loss: 238.40
train mean loss: 233.94
epoch train time: 0:00:00.514300
elapsed time: 0:01:46.698247
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 14:54:08.741438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.07
 ---- batch: 020 ----
mean loss: 236.68
 ---- batch: 030 ----
mean loss: 230.17
train mean loss: 233.53
epoch train time: 0:00:00.519572
elapsed time: 0:01:47.218145
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 14:54:09.261281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.23
 ---- batch: 020 ----
mean loss: 232.82
 ---- batch: 030 ----
mean loss: 231.91
train mean loss: 232.05
epoch train time: 0:00:00.515646
elapsed time: 0:01:47.734055
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 14:54:09.777201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.41
 ---- batch: 020 ----
mean loss: 234.13
 ---- batch: 030 ----
mean loss: 230.88
train mean loss: 231.61
epoch train time: 0:00:00.534501
elapsed time: 0:01:48.268854
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 14:54:10.312008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.12
 ---- batch: 020 ----
mean loss: 227.88
 ---- batch: 030 ----
mean loss: 233.20
train mean loss: 231.20
epoch train time: 0:00:00.525067
elapsed time: 0:01:48.794281
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 14:54:10.837421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.68
 ---- batch: 020 ----
mean loss: 226.18
 ---- batch: 030 ----
mean loss: 229.87
train mean loss: 230.43
epoch train time: 0:00:00.513056
elapsed time: 0:01:49.307606
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 14:54:11.350735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.56
 ---- batch: 020 ----
mean loss: 238.91
 ---- batch: 030 ----
mean loss: 221.43
train mean loss: 229.92
epoch train time: 0:00:00.519755
elapsed time: 0:01:49.827631
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 14:54:11.870781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.96
 ---- batch: 020 ----
mean loss: 233.40
 ---- batch: 030 ----
mean loss: 226.93
train mean loss: 228.96
epoch train time: 0:00:00.512531
elapsed time: 0:01:50.340462
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 14:54:12.383612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.14
 ---- batch: 020 ----
mean loss: 235.12
 ---- batch: 030 ----
mean loss: 229.76
train mean loss: 228.92
epoch train time: 0:00:00.516339
elapsed time: 0:01:50.857105
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 14:54:12.900234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.85
 ---- batch: 020 ----
mean loss: 222.87
 ---- batch: 030 ----
mean loss: 233.49
train mean loss: 228.23
epoch train time: 0:00:00.522513
elapsed time: 0:01:51.379889
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 14:54:13.423024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.47
 ---- batch: 020 ----
mean loss: 230.60
 ---- batch: 030 ----
mean loss: 231.23
train mean loss: 227.20
epoch train time: 0:00:00.517811
elapsed time: 0:01:51.897953
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 14:54:13.941134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.37
 ---- batch: 020 ----
mean loss: 231.12
 ---- batch: 030 ----
mean loss: 226.56
train mean loss: 226.69
epoch train time: 0:00:00.516549
elapsed time: 0:01:52.414828
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 14:54:14.457972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.44
 ---- batch: 020 ----
mean loss: 226.29
 ---- batch: 030 ----
mean loss: 227.20
train mean loss: 225.66
epoch train time: 0:00:00.525249
elapsed time: 0:01:52.940698
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 14:54:14.983846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.89
 ---- batch: 020 ----
mean loss: 230.19
 ---- batch: 030 ----
mean loss: 219.02
train mean loss: 225.13
epoch train time: 0:00:00.523817
elapsed time: 0:01:53.464805
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 14:54:15.507953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.17
 ---- batch: 020 ----
mean loss: 230.63
 ---- batch: 030 ----
mean loss: 222.51
train mean loss: 224.80
epoch train time: 0:00:00.522378
elapsed time: 0:01:53.987472
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 14:54:16.030609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.34
 ---- batch: 020 ----
mean loss: 229.23
 ---- batch: 030 ----
mean loss: 220.18
train mean loss: 224.08
epoch train time: 0:00:00.519823
elapsed time: 0:01:54.507562
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 14:54:16.550695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.56
 ---- batch: 020 ----
mean loss: 221.82
 ---- batch: 030 ----
mean loss: 227.53
train mean loss: 223.96
epoch train time: 0:00:00.516704
elapsed time: 0:01:55.024534
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 14:54:17.067673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.82
 ---- batch: 020 ----
mean loss: 222.21
 ---- batch: 030 ----
mean loss: 219.60
train mean loss: 222.62
epoch train time: 0:00:00.520816
elapsed time: 0:01:55.545671
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 14:54:17.588806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.47
 ---- batch: 020 ----
mean loss: 230.79
 ---- batch: 030 ----
mean loss: 221.17
train mean loss: 222.64
epoch train time: 0:00:00.518707
elapsed time: 0:01:56.064693
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 14:54:18.107861
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.17
 ---- batch: 020 ----
mean loss: 222.98
 ---- batch: 030 ----
mean loss: 222.23
train mean loss: 221.87
epoch train time: 0:00:00.516417
elapsed time: 0:01:56.581417
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 14:54:18.624549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.78
 ---- batch: 020 ----
mean loss: 220.70
 ---- batch: 030 ----
mean loss: 224.73
train mean loss: 221.29
epoch train time: 0:00:00.514487
elapsed time: 0:01:57.096267
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 14:54:19.139476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.14
 ---- batch: 020 ----
mean loss: 221.63
 ---- batch: 030 ----
mean loss: 220.93
train mean loss: 220.78
epoch train time: 0:00:00.512567
elapsed time: 0:01:57.609167
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 14:54:19.652305
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.09
 ---- batch: 020 ----
mean loss: 218.28
 ---- batch: 030 ----
mean loss: 222.76
train mean loss: 220.44
epoch train time: 0:00:00.532591
elapsed time: 0:01:58.142094
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 14:54:20.185199
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.10
 ---- batch: 020 ----
mean loss: 223.83
 ---- batch: 030 ----
mean loss: 223.43
train mean loss: 220.38
epoch train time: 0:00:00.522311
elapsed time: 0:01:58.664642
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 14:54:20.707779
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 225.99
 ---- batch: 020 ----
mean loss: 223.83
 ---- batch: 030 ----
mean loss: 211.36
train mean loss: 220.38
epoch train time: 0:00:00.518321
elapsed time: 0:01:59.183237
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 14:54:21.226376
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.27
 ---- batch: 020 ----
mean loss: 216.09
 ---- batch: 030 ----
mean loss: 226.22
train mean loss: 220.29
epoch train time: 0:00:00.516954
elapsed time: 0:01:59.700483
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 14:54:21.743623
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.70
 ---- batch: 020 ----
mean loss: 221.09
 ---- batch: 030 ----
mean loss: 219.36
train mean loss: 220.17
epoch train time: 0:00:00.527945
elapsed time: 0:02:00.228771
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 14:54:22.271910
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.72
 ---- batch: 020 ----
mean loss: 220.51
 ---- batch: 030 ----
mean loss: 215.89
train mean loss: 220.19
epoch train time: 0:00:00.523395
elapsed time: 0:02:00.752464
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 14:54:22.795611
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.59
 ---- batch: 020 ----
mean loss: 217.80
 ---- batch: 030 ----
mean loss: 225.72
train mean loss: 220.23
epoch train time: 0:00:00.532431
elapsed time: 0:02:01.285180
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 14:54:23.328353
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 219.85
 ---- batch: 020 ----
mean loss: 219.10
 ---- batch: 030 ----
mean loss: 220.79
train mean loss: 220.20
epoch train time: 0:00:00.530356
elapsed time: 0:02:01.815912
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 14:54:23.859056
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.88
 ---- batch: 020 ----
mean loss: 225.72
 ---- batch: 030 ----
mean loss: 218.76
train mean loss: 219.91
epoch train time: 0:00:00.516900
elapsed time: 0:02:02.333097
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 14:54:24.376253
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.01
 ---- batch: 020 ----
mean loss: 217.29
 ---- batch: 030 ----
mean loss: 224.78
train mean loss: 219.79
epoch train time: 0:00:00.524057
elapsed time: 0:02:02.857581
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 14:54:24.900752
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.15
 ---- batch: 020 ----
mean loss: 221.29
 ---- batch: 030 ----
mean loss: 224.16
train mean loss: 219.58
epoch train time: 0:00:00.523121
elapsed time: 0:02:03.381042
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 14:54:25.424180
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 219.45
 ---- batch: 020 ----
mean loss: 225.06
 ---- batch: 030 ----
mean loss: 219.94
train mean loss: 219.58
epoch train time: 0:00:00.527783
elapsed time: 0:02:03.909117
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 14:54:25.952294
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.60
 ---- batch: 020 ----
mean loss: 216.03
 ---- batch: 030 ----
mean loss: 214.91
train mean loss: 219.56
epoch train time: 0:00:00.520538
elapsed time: 0:02:04.430043
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 14:54:26.473212
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 219.07
 ---- batch: 020 ----
mean loss: 220.82
 ---- batch: 030 ----
mean loss: 215.52
train mean loss: 220.05
epoch train time: 0:00:00.518945
elapsed time: 0:02:04.949307
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 14:54:26.992448
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.28
 ---- batch: 020 ----
mean loss: 218.54
 ---- batch: 030 ----
mean loss: 220.60
train mean loss: 220.21
epoch train time: 0:00:00.518960
elapsed time: 0:02:05.468553
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 14:54:27.511690
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.53
 ---- batch: 020 ----
mean loss: 221.88
 ---- batch: 030 ----
mean loss: 218.29
train mean loss: 220.38
epoch train time: 0:00:00.530851
elapsed time: 0:02:05.999703
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 14:54:28.042838
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.91
 ---- batch: 020 ----
mean loss: 216.25
 ---- batch: 030 ----
mean loss: 222.10
train mean loss: 219.61
epoch train time: 0:00:00.528420
elapsed time: 0:02:06.528414
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 14:54:28.571548
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.04
 ---- batch: 020 ----
mean loss: 215.13
 ---- batch: 030 ----
mean loss: 219.36
train mean loss: 220.03
epoch train time: 0:00:00.523034
elapsed time: 0:02:07.051734
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 14:54:29.094888
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 220.41
 ---- batch: 020 ----
mean loss: 219.64
 ---- batch: 030 ----
mean loss: 220.47
train mean loss: 219.42
epoch train time: 0:00:00.513340
elapsed time: 0:02:07.565355
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 14:54:29.608490
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 220.36
 ---- batch: 020 ----
mean loss: 220.54
 ---- batch: 030 ----
mean loss: 214.61
train mean loss: 219.07
epoch train time: 0:00:00.528059
elapsed time: 0:02:08.093674
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 14:54:30.136808
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.04
 ---- batch: 020 ----
mean loss: 222.22
 ---- batch: 030 ----
mean loss: 221.05
train mean loss: 219.64
epoch train time: 0:00:00.507165
elapsed time: 0:02:08.601120
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 14:54:30.644289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 223.98
 ---- batch: 020 ----
mean loss: 213.65
 ---- batch: 030 ----
mean loss: 219.25
train mean loss: 219.34
epoch train time: 0:00:00.520072
elapsed time: 0:02:09.121503
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 14:54:31.164675
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.64
 ---- batch: 020 ----
mean loss: 220.39
 ---- batch: 030 ----
mean loss: 218.70
train mean loss: 219.07
epoch train time: 0:00:00.519988
elapsed time: 0:02:09.641856
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 14:54:31.685007
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 219.04
 ---- batch: 020 ----
mean loss: 220.53
 ---- batch: 030 ----
mean loss: 220.53
train mean loss: 219.22
epoch train time: 0:00:00.511789
elapsed time: 0:02:10.153929
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 14:54:32.197065
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.59
 ---- batch: 020 ----
mean loss: 222.32
 ---- batch: 030 ----
mean loss: 216.98
train mean loss: 219.20
epoch train time: 0:00:00.519989
elapsed time: 0:02:10.674196
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 14:54:32.717334
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.80
 ---- batch: 020 ----
mean loss: 218.86
 ---- batch: 030 ----
mean loss: 216.72
train mean loss: 218.47
epoch train time: 0:00:00.513835
elapsed time: 0:02:11.188296
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 14:54:33.231454
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.37
 ---- batch: 020 ----
mean loss: 221.77
 ---- batch: 030 ----
mean loss: 218.06
train mean loss: 218.97
epoch train time: 0:00:00.516506
elapsed time: 0:02:11.705096
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 14:54:33.748234
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 215.26
 ---- batch: 020 ----
mean loss: 222.80
 ---- batch: 030 ----
mean loss: 216.93
train mean loss: 219.08
epoch train time: 0:00:00.534612
elapsed time: 0:02:12.240001
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 14:54:34.283141
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.63
 ---- batch: 020 ----
mean loss: 217.79
 ---- batch: 030 ----
mean loss: 218.10
train mean loss: 219.13
epoch train time: 0:00:00.523463
elapsed time: 0:02:12.763773
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 14:54:34.806917
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.58
 ---- batch: 020 ----
mean loss: 225.28
 ---- batch: 030 ----
mean loss: 213.47
train mean loss: 218.71
epoch train time: 0:00:00.529722
elapsed time: 0:02:13.293821
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 14:54:35.336981
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 223.07
 ---- batch: 020 ----
mean loss: 213.10
 ---- batch: 030 ----
mean loss: 220.48
train mean loss: 218.60
epoch train time: 0:00:00.537140
elapsed time: 0:02:13.831277
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 14:54:35.874481
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.57
 ---- batch: 020 ----
mean loss: 218.58
 ---- batch: 030 ----
mean loss: 223.33
train mean loss: 219.00
epoch train time: 0:00:00.531480
elapsed time: 0:02:14.363098
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 14:54:36.406240
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.19
 ---- batch: 020 ----
mean loss: 223.80
 ---- batch: 030 ----
mean loss: 219.30
train mean loss: 218.63
epoch train time: 0:00:00.532987
elapsed time: 0:02:14.896431
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 14:54:36.939523
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.47
 ---- batch: 020 ----
mean loss: 215.27
 ---- batch: 030 ----
mean loss: 219.41
train mean loss: 218.98
epoch train time: 0:00:00.528078
elapsed time: 0:02:15.424787
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 14:54:37.467946
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.35
 ---- batch: 020 ----
mean loss: 215.32
 ---- batch: 030 ----
mean loss: 218.91
train mean loss: 218.04
epoch train time: 0:00:00.525770
elapsed time: 0:02:15.950892
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 14:54:37.994082
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.55
 ---- batch: 020 ----
mean loss: 220.03
 ---- batch: 030 ----
mean loss: 216.38
train mean loss: 218.56
epoch train time: 0:00:00.542661
elapsed time: 0:02:16.493947
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 14:54:38.537116
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 218.30
 ---- batch: 020 ----
mean loss: 223.85
 ---- batch: 030 ----
mean loss: 217.09
train mean loss: 218.01
epoch train time: 0:00:00.519658
elapsed time: 0:02:17.013908
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 14:54:39.057057
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.76
 ---- batch: 020 ----
mean loss: 217.41
 ---- batch: 030 ----
mean loss: 214.47
train mean loss: 218.43
epoch train time: 0:00:00.521741
elapsed time: 0:02:17.535952
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 14:54:39.579096
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.80
 ---- batch: 020 ----
mean loss: 223.88
 ---- batch: 030 ----
mean loss: 216.20
train mean loss: 218.64
epoch train time: 0:00:00.538316
elapsed time: 0:02:18.074535
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 14:54:40.117721
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.83
 ---- batch: 020 ----
mean loss: 216.94
 ---- batch: 030 ----
mean loss: 220.21
train mean loss: 218.14
epoch train time: 0:00:00.548094
elapsed time: 0:02:18.623019
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 14:54:40.666213
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 224.19
 ---- batch: 020 ----
mean loss: 216.69
 ---- batch: 030 ----
mean loss: 215.03
train mean loss: 217.81
epoch train time: 0:00:00.530015
elapsed time: 0:02:19.153413
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 14:54:41.196588
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 219.20
 ---- batch: 020 ----
mean loss: 214.88
 ---- batch: 030 ----
mean loss: 220.69
train mean loss: 218.34
epoch train time: 0:00:00.525389
elapsed time: 0:02:19.679211
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 14:54:41.722351
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.84
 ---- batch: 020 ----
mean loss: 222.61
 ---- batch: 030 ----
mean loss: 216.35
train mean loss: 218.14
epoch train time: 0:00:00.525465
elapsed time: 0:02:20.205021
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 14:54:42.248161
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.59
 ---- batch: 020 ----
mean loss: 218.71
 ---- batch: 030 ----
mean loss: 211.79
train mean loss: 218.00
epoch train time: 0:00:00.515276
elapsed time: 0:02:20.720586
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 14:54:42.763740
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 222.30
 ---- batch: 020 ----
mean loss: 212.29
 ---- batch: 030 ----
mean loss: 219.08
train mean loss: 217.89
epoch train time: 0:00:00.510951
elapsed time: 0:02:21.231851
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 14:54:43.274987
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.50
 ---- batch: 020 ----
mean loss: 222.21
 ---- batch: 030 ----
mean loss: 215.69
train mean loss: 217.78
epoch train time: 0:00:00.516539
elapsed time: 0:02:21.748710
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 14:54:43.791860
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.12
 ---- batch: 020 ----
mean loss: 221.16
 ---- batch: 030 ----
mean loss: 211.44
train mean loss: 217.94
epoch train time: 0:00:00.537058
elapsed time: 0:02:22.286105
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 14:54:44.329247
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.05
 ---- batch: 020 ----
mean loss: 216.32
 ---- batch: 030 ----
mean loss: 218.95
train mean loss: 217.81
epoch train time: 0:00:00.537419
elapsed time: 0:02:22.823802
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 14:54:44.866937
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 216.38
 ---- batch: 020 ----
mean loss: 214.92
 ---- batch: 030 ----
mean loss: 219.05
train mean loss: 217.44
epoch train time: 0:00:00.526523
elapsed time: 0:02:23.354418
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_5/checkpoint.pth.tar
**** end time: 2019-09-27 14:54:45.397485 ****
