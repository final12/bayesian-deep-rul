Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_2', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30498
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 15:48:15.975481 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:48:15.983492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3918.39
 ---- batch: 020 ----
mean loss: 2356.59
 ---- batch: 030 ----
mean loss: 801.67
train mean loss: 2100.86
epoch train time: 0:00:12.720685
elapsed time: 0:00:12.731296
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:48:28.706815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 522.10
 ---- batch: 020 ----
mean loss: 481.35
 ---- batch: 030 ----
mean loss: 422.80
train mean loss: 462.24
epoch train time: 0:00:01.520383
elapsed time: 0:00:14.251817
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:48:30.227361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 347.39
 ---- batch: 020 ----
mean loss: 334.92
 ---- batch: 030 ----
mean loss: 305.74
train mean loss: 326.09
epoch train time: 0:00:01.426714
elapsed time: 0:00:15.678699
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:48:31.654233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 279.06
 ---- batch: 020 ----
mean loss: 267.07
 ---- batch: 030 ----
mean loss: 254.73
train mean loss: 263.81
epoch train time: 0:00:01.432061
elapsed time: 0:00:17.110916
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:48:33.086448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.36
 ---- batch: 020 ----
mean loss: 229.60
 ---- batch: 030 ----
mean loss: 223.06
train mean loss: 228.48
epoch train time: 0:00:01.429846
elapsed time: 0:00:18.540934
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:48:34.516471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.60
 ---- batch: 020 ----
mean loss: 210.49
 ---- batch: 030 ----
mean loss: 202.99
train mean loss: 204.09
epoch train time: 0:00:01.434251
elapsed time: 0:00:19.975349
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:48:35.950884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.99
 ---- batch: 020 ----
mean loss: 207.33
 ---- batch: 030 ----
mean loss: 205.25
train mean loss: 202.88
epoch train time: 0:00:01.432480
elapsed time: 0:00:21.407984
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:48:37.383569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.70
 ---- batch: 020 ----
mean loss: 196.13
 ---- batch: 030 ----
mean loss: 198.09
train mean loss: 197.39
epoch train time: 0:00:01.429133
elapsed time: 0:00:22.837377
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:48:38.812950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.24
 ---- batch: 020 ----
mean loss: 187.99
 ---- batch: 030 ----
mean loss: 193.13
train mean loss: 191.97
epoch train time: 0:00:01.436497
elapsed time: 0:00:24.274076
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:48:40.249646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.20
 ---- batch: 020 ----
mean loss: 187.59
 ---- batch: 030 ----
mean loss: 189.20
train mean loss: 188.69
epoch train time: 0:00:01.432642
elapsed time: 0:00:25.706915
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:48:41.682451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.01
 ---- batch: 020 ----
mean loss: 182.56
 ---- batch: 030 ----
mean loss: 185.37
train mean loss: 184.42
epoch train time: 0:00:01.434533
elapsed time: 0:00:27.141606
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:48:43.117138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.45
 ---- batch: 020 ----
mean loss: 187.67
 ---- batch: 030 ----
mean loss: 181.51
train mean loss: 181.49
epoch train time: 0:00:01.431724
elapsed time: 0:00:28.573490
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:48:44.549038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.13
 ---- batch: 020 ----
mean loss: 184.29
 ---- batch: 030 ----
mean loss: 174.89
train mean loss: 179.63
epoch train time: 0:00:01.434515
elapsed time: 0:00:30.008521
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:48:45.984064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.27
 ---- batch: 020 ----
mean loss: 183.75
 ---- batch: 030 ----
mean loss: 190.87
train mean loss: 184.34
epoch train time: 0:00:01.438144
elapsed time: 0:00:31.446829
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:48:47.422365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.56
 ---- batch: 020 ----
mean loss: 172.45
 ---- batch: 030 ----
mean loss: 173.91
train mean loss: 176.11
epoch train time: 0:00:01.440644
elapsed time: 0:00:32.887684
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:48:48.863246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.33
 ---- batch: 020 ----
mean loss: 173.40
 ---- batch: 030 ----
mean loss: 176.52
train mean loss: 175.46
epoch train time: 0:00:01.431187
elapsed time: 0:00:34.319053
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:48:50.294589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.21
 ---- batch: 020 ----
mean loss: 181.69
 ---- batch: 030 ----
mean loss: 179.59
train mean loss: 178.23
epoch train time: 0:00:01.430693
elapsed time: 0:00:35.749933
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:48:51.725480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.66
 ---- batch: 020 ----
mean loss: 170.88
 ---- batch: 030 ----
mean loss: 171.34
train mean loss: 174.03
epoch train time: 0:00:01.433603
elapsed time: 0:00:37.183721
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:48:53.159255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.24
 ---- batch: 020 ----
mean loss: 172.75
 ---- batch: 030 ----
mean loss: 170.10
train mean loss: 173.47
epoch train time: 0:00:01.433681
elapsed time: 0:00:38.617560
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:48:54.593092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.73
 ---- batch: 020 ----
mean loss: 179.83
 ---- batch: 030 ----
mean loss: 173.89
train mean loss: 173.49
epoch train time: 0:00:01.436058
elapsed time: 0:00:40.053773
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:48:56.029347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.51
 ---- batch: 020 ----
mean loss: 168.40
 ---- batch: 030 ----
mean loss: 165.59
train mean loss: 168.92
epoch train time: 0:00:01.437206
elapsed time: 0:00:41.491210
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:48:57.466744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.73
 ---- batch: 020 ----
mean loss: 169.24
 ---- batch: 030 ----
mean loss: 174.39
train mean loss: 170.50
epoch train time: 0:00:01.433169
elapsed time: 0:00:42.924536
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:48:58.900070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.92
 ---- batch: 020 ----
mean loss: 170.08
 ---- batch: 030 ----
mean loss: 166.66
train mean loss: 170.21
epoch train time: 0:00:01.427180
elapsed time: 0:00:44.351895
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:49:00.327432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.21
 ---- batch: 020 ----
mean loss: 172.10
 ---- batch: 030 ----
mean loss: 164.30
train mean loss: 167.51
epoch train time: 0:00:01.433733
elapsed time: 0:00:45.785824
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:49:01.761389
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.89
 ---- batch: 020 ----
mean loss: 163.06
 ---- batch: 030 ----
mean loss: 172.24
train mean loss: 168.41
epoch train time: 0:00:01.432802
elapsed time: 0:00:47.218834
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:49:03.194369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.86
 ---- batch: 020 ----
mean loss: 170.58
 ---- batch: 030 ----
mean loss: 175.33
train mean loss: 172.53
epoch train time: 0:00:01.436425
elapsed time: 0:00:48.655420
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:49:04.630954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.24
 ---- batch: 020 ----
mean loss: 162.94
 ---- batch: 030 ----
mean loss: 164.64
train mean loss: 166.62
epoch train time: 0:00:01.432433
elapsed time: 0:00:50.088044
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:49:06.063595
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.50
 ---- batch: 020 ----
mean loss: 162.58
 ---- batch: 030 ----
mean loss: 162.12
train mean loss: 160.79
epoch train time: 0:00:01.434500
elapsed time: 0:00:51.522743
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:49:07.498325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.92
 ---- batch: 020 ----
mean loss: 158.63
 ---- batch: 030 ----
mean loss: 165.60
train mean loss: 163.03
epoch train time: 0:00:01.433518
elapsed time: 0:00:52.956495
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:49:08.932033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.87
 ---- batch: 020 ----
mean loss: 158.24
 ---- batch: 030 ----
mean loss: 162.56
train mean loss: 159.50
epoch train time: 0:00:01.432695
elapsed time: 0:00:54.389345
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:49:10.364876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.37
 ---- batch: 020 ----
mean loss: 164.85
 ---- batch: 030 ----
mean loss: 162.79
train mean loss: 160.79
epoch train time: 0:00:01.441122
elapsed time: 0:00:55.830621
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:49:11.806157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.85
 ---- batch: 020 ----
mean loss: 163.56
 ---- batch: 030 ----
mean loss: 160.76
train mean loss: 162.12
epoch train time: 0:00:01.434898
elapsed time: 0:00:57.265697
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:49:13.241232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.13
 ---- batch: 020 ----
mean loss: 158.61
 ---- batch: 030 ----
mean loss: 159.22
train mean loss: 158.37
epoch train time: 0:00:01.430358
elapsed time: 0:00:58.696218
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:49:14.671753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.46
 ---- batch: 020 ----
mean loss: 159.94
 ---- batch: 030 ----
mean loss: 158.88
train mean loss: 157.81
epoch train time: 0:00:01.429234
elapsed time: 0:01:00.125627
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:49:16.101189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.54
 ---- batch: 020 ----
mean loss: 156.11
 ---- batch: 030 ----
mean loss: 163.10
train mean loss: 158.26
epoch train time: 0:00:01.436348
elapsed time: 0:01:01.562222
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:49:17.537764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.47
 ---- batch: 020 ----
mean loss: 164.02
 ---- batch: 030 ----
mean loss: 165.50
train mean loss: 162.66
epoch train time: 0:00:01.433623
elapsed time: 0:01:02.996027
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:49:18.971620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.89
 ---- batch: 020 ----
mean loss: 160.55
 ---- batch: 030 ----
mean loss: 151.45
train mean loss: 156.76
epoch train time: 0:00:01.430147
elapsed time: 0:01:04.426397
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:49:20.401934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.76
 ---- batch: 020 ----
mean loss: 160.47
 ---- batch: 030 ----
mean loss: 158.80
train mean loss: 158.78
epoch train time: 0:00:01.437659
elapsed time: 0:01:05.864228
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:49:21.839774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.75
 ---- batch: 020 ----
mean loss: 154.49
 ---- batch: 030 ----
mean loss: 162.41
train mean loss: 155.82
epoch train time: 0:00:01.434483
elapsed time: 0:01:07.298891
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:49:23.274451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.30
 ---- batch: 020 ----
mean loss: 158.93
 ---- batch: 030 ----
mean loss: 157.82
train mean loss: 158.25
epoch train time: 0:00:01.434540
elapsed time: 0:01:08.733665
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:49:24.709198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.75
 ---- batch: 020 ----
mean loss: 156.33
 ---- batch: 030 ----
mean loss: 154.46
train mean loss: 156.67
epoch train time: 0:00:01.434404
elapsed time: 0:01:10.168237
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:49:26.143815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.45
 ---- batch: 020 ----
mean loss: 149.92
 ---- batch: 030 ----
mean loss: 154.45
train mean loss: 154.52
epoch train time: 0:00:01.433144
elapsed time: 0:01:11.601592
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:49:27.577128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.65
 ---- batch: 020 ----
mean loss: 159.48
 ---- batch: 030 ----
mean loss: 160.21
train mean loss: 158.66
epoch train time: 0:00:01.431326
elapsed time: 0:01:13.033089
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:49:29.008625
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.31
 ---- batch: 020 ----
mean loss: 156.71
 ---- batch: 030 ----
mean loss: 156.05
train mean loss: 156.40
epoch train time: 0:00:01.435415
elapsed time: 0:01:14.468668
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:49:30.444205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.03
 ---- batch: 020 ----
mean loss: 154.10
 ---- batch: 030 ----
mean loss: 159.63
train mean loss: 156.84
epoch train time: 0:00:01.431997
elapsed time: 0:01:15.900841
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:49:31.876387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.79
 ---- batch: 020 ----
mean loss: 158.12
 ---- batch: 030 ----
mean loss: 148.64
train mean loss: 153.95
epoch train time: 0:00:01.434564
elapsed time: 0:01:17.335582
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:49:33.311132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.31
 ---- batch: 020 ----
mean loss: 154.06
 ---- batch: 030 ----
mean loss: 157.52
train mean loss: 155.27
epoch train time: 0:00:01.430031
elapsed time: 0:01:18.765803
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:49:34.741354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.39
 ---- batch: 020 ----
mean loss: 156.15
 ---- batch: 030 ----
mean loss: 152.06
train mean loss: 154.59
epoch train time: 0:00:01.433594
elapsed time: 0:01:20.199577
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:49:36.175111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.23
 ---- batch: 020 ----
mean loss: 156.02
 ---- batch: 030 ----
mean loss: 152.76
train mean loss: 152.57
epoch train time: 0:00:01.433338
elapsed time: 0:01:21.633093
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:49:37.608627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.94
 ---- batch: 020 ----
mean loss: 154.69
 ---- batch: 030 ----
mean loss: 156.90
train mean loss: 155.09
epoch train time: 0:00:01.432322
elapsed time: 0:01:23.065578
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:49:39.041114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.19
 ---- batch: 020 ----
mean loss: 154.30
 ---- batch: 030 ----
mean loss: 150.33
train mean loss: 153.10
epoch train time: 0:00:01.437982
elapsed time: 0:01:24.503719
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:49:40.479253
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.42
 ---- batch: 020 ----
mean loss: 162.71
 ---- batch: 030 ----
mean loss: 158.93
train mean loss: 160.33
epoch train time: 0:00:01.434720
elapsed time: 0:01:25.938606
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:49:41.914143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.53
 ---- batch: 020 ----
mean loss: 152.38
 ---- batch: 030 ----
mean loss: 153.09
train mean loss: 152.18
epoch train time: 0:00:01.431275
elapsed time: 0:01:27.370095
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:49:43.345697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.56
 ---- batch: 020 ----
mean loss: 154.02
 ---- batch: 030 ----
mean loss: 157.73
train mean loss: 156.71
epoch train time: 0:00:01.428022
elapsed time: 0:01:28.798381
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:49:44.773913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.44
 ---- batch: 020 ----
mean loss: 156.60
 ---- batch: 030 ----
mean loss: 157.49
train mean loss: 156.56
epoch train time: 0:00:01.432167
elapsed time: 0:01:30.230708
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:49:46.206244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.66
 ---- batch: 020 ----
mean loss: 150.97
 ---- batch: 030 ----
mean loss: 151.73
train mean loss: 153.37
epoch train time: 0:00:01.430769
elapsed time: 0:01:31.661661
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:49:47.637210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.47
 ---- batch: 020 ----
mean loss: 147.74
 ---- batch: 030 ----
mean loss: 152.25
train mean loss: 153.10
epoch train time: 0:00:01.430548
elapsed time: 0:01:33.092402
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:49:49.067953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.35
 ---- batch: 020 ----
mean loss: 157.17
 ---- batch: 030 ----
mean loss: 151.68
train mean loss: 154.20
epoch train time: 0:00:01.434514
elapsed time: 0:01:34.527092
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:49:50.502628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.96
 ---- batch: 020 ----
mean loss: 153.09
 ---- batch: 030 ----
mean loss: 150.75
train mean loss: 152.48
epoch train time: 0:00:01.432380
elapsed time: 0:01:35.959635
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:49:51.935214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.50
 ---- batch: 020 ----
mean loss: 157.99
 ---- batch: 030 ----
mean loss: 159.18
train mean loss: 162.27
epoch train time: 0:00:01.432499
elapsed time: 0:01:37.392332
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:49:53.367867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.82
 ---- batch: 020 ----
mean loss: 148.66
 ---- batch: 030 ----
mean loss: 156.68
train mean loss: 153.04
epoch train time: 0:00:01.433305
elapsed time: 0:01:38.825798
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:49:54.801383
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.57
 ---- batch: 020 ----
mean loss: 148.15
 ---- batch: 030 ----
mean loss: 155.95
train mean loss: 154.36
epoch train time: 0:00:01.430565
elapsed time: 0:01:40.256571
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:49:56.232120
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.39
 ---- batch: 020 ----
mean loss: 150.82
 ---- batch: 030 ----
mean loss: 149.74
train mean loss: 150.94
epoch train time: 0:00:01.432274
elapsed time: 0:01:41.689016
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:49:57.664549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.14
 ---- batch: 020 ----
mean loss: 155.68
 ---- batch: 030 ----
mean loss: 154.54
train mean loss: 155.15
epoch train time: 0:00:01.434378
elapsed time: 0:01:43.123559
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:49:59.099094
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.96
 ---- batch: 020 ----
mean loss: 152.76
 ---- batch: 030 ----
mean loss: 150.96
train mean loss: 152.77
epoch train time: 0:00:01.435756
elapsed time: 0:01:44.559478
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:50:00.535014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.36
 ---- batch: 020 ----
mean loss: 148.67
 ---- batch: 030 ----
mean loss: 148.60
train mean loss: 149.99
epoch train time: 0:00:01.436995
elapsed time: 0:01:45.996681
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:50:01.972218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.67
 ---- batch: 020 ----
mean loss: 154.05
 ---- batch: 030 ----
mean loss: 154.84
train mean loss: 151.58
epoch train time: 0:00:01.433559
elapsed time: 0:01:47.430413
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:50:03.405953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.62
 ---- batch: 020 ----
mean loss: 153.21
 ---- batch: 030 ----
mean loss: 155.27
train mean loss: 151.92
epoch train time: 0:00:01.432835
elapsed time: 0:01:48.863414
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:50:04.838949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.37
 ---- batch: 020 ----
mean loss: 155.48
 ---- batch: 030 ----
mean loss: 148.14
train mean loss: 152.11
epoch train time: 0:00:01.424335
elapsed time: 0:01:50.287921
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:50:06.263463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.71
 ---- batch: 020 ----
mean loss: 149.98
 ---- batch: 030 ----
mean loss: 150.30
train mean loss: 149.07
epoch train time: 0:00:01.433567
elapsed time: 0:01:51.721660
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:50:07.697194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.81
 ---- batch: 020 ----
mean loss: 150.37
 ---- batch: 030 ----
mean loss: 152.27
train mean loss: 151.38
epoch train time: 0:00:01.428526
elapsed time: 0:01:53.150342
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:50:09.125907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.02
 ---- batch: 020 ----
mean loss: 148.58
 ---- batch: 030 ----
mean loss: 148.50
train mean loss: 148.87
epoch train time: 0:00:01.430280
elapsed time: 0:01:54.580823
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:50:10.556359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.80
 ---- batch: 020 ----
mean loss: 147.80
 ---- batch: 030 ----
mean loss: 153.04
train mean loss: 150.21
epoch train time: 0:00:01.429159
elapsed time: 0:01:56.010170
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:50:11.985707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.76
 ---- batch: 020 ----
mean loss: 154.89
 ---- batch: 030 ----
mean loss: 153.03
train mean loss: 150.68
epoch train time: 0:00:01.435706
elapsed time: 0:01:57.446048
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:50:13.421599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.38
 ---- batch: 020 ----
mean loss: 145.64
 ---- batch: 030 ----
mean loss: 153.85
train mean loss: 149.51
epoch train time: 0:00:01.435505
elapsed time: 0:01:58.881749
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:50:14.857288
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.77
 ---- batch: 020 ----
mean loss: 162.43
 ---- batch: 030 ----
mean loss: 155.82
train mean loss: 154.40
epoch train time: 0:00:01.431177
elapsed time: 0:02:00.313082
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:50:16.288614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.49
 ---- batch: 020 ----
mean loss: 152.67
 ---- batch: 030 ----
mean loss: 148.57
train mean loss: 150.62
epoch train time: 0:00:01.426795
elapsed time: 0:02:01.740043
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:50:17.715578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.31
 ---- batch: 020 ----
mean loss: 147.63
 ---- batch: 030 ----
mean loss: 149.96
train mean loss: 147.22
epoch train time: 0:00:01.433738
elapsed time: 0:02:03.173971
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:50:19.149529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.48
 ---- batch: 020 ----
mean loss: 145.51
 ---- batch: 030 ----
mean loss: 149.87
train mean loss: 147.93
epoch train time: 0:00:01.430507
elapsed time: 0:02:04.604657
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:50:20.580193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.30
 ---- batch: 020 ----
mean loss: 148.31
 ---- batch: 030 ----
mean loss: 150.90
train mean loss: 148.61
epoch train time: 0:00:01.426953
elapsed time: 0:02:06.031770
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:50:22.007305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.42
 ---- batch: 020 ----
mean loss: 150.23
 ---- batch: 030 ----
mean loss: 145.92
train mean loss: 148.40
epoch train time: 0:00:01.432208
elapsed time: 0:02:07.464135
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:50:23.439670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.07
 ---- batch: 020 ----
mean loss: 151.66
 ---- batch: 030 ----
mean loss: 149.28
train mean loss: 147.95
epoch train time: 0:00:01.436391
elapsed time: 0:02:08.900701
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:50:24.876268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.29
 ---- batch: 020 ----
mean loss: 148.70
 ---- batch: 030 ----
mean loss: 147.88
train mean loss: 148.42
epoch train time: 0:00:01.434680
elapsed time: 0:02:10.335568
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:50:26.311103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.09
 ---- batch: 020 ----
mean loss: 144.69
 ---- batch: 030 ----
mean loss: 153.20
train mean loss: 147.52
epoch train time: 0:00:01.429655
elapsed time: 0:02:11.765392
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:50:27.740949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.02
 ---- batch: 020 ----
mean loss: 152.01
 ---- batch: 030 ----
mean loss: 152.33
train mean loss: 152.04
epoch train time: 0:00:01.433908
elapsed time: 0:02:13.199508
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:50:29.175047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.62
 ---- batch: 020 ----
mean loss: 153.98
 ---- batch: 030 ----
mean loss: 149.43
train mean loss: 151.47
epoch train time: 0:00:01.436087
elapsed time: 0:02:14.635788
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:50:30.611322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.28
 ---- batch: 020 ----
mean loss: 148.84
 ---- batch: 030 ----
mean loss: 158.35
train mean loss: 153.79
epoch train time: 0:00:01.435601
elapsed time: 0:02:16.071562
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:50:32.047100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.24
 ---- batch: 020 ----
mean loss: 159.29
 ---- batch: 030 ----
mean loss: 145.36
train mean loss: 152.42
epoch train time: 0:00:01.433969
elapsed time: 0:02:17.505694
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:50:33.481246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.88
 ---- batch: 020 ----
mean loss: 146.81
 ---- batch: 030 ----
mean loss: 149.03
train mean loss: 151.56
epoch train time: 0:00:01.437580
elapsed time: 0:02:18.943460
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:50:34.918995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.18
 ---- batch: 020 ----
mean loss: 151.50
 ---- batch: 030 ----
mean loss: 148.91
train mean loss: 149.47
epoch train time: 0:00:01.433545
elapsed time: 0:02:20.377193
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:50:36.352725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.67
 ---- batch: 020 ----
mean loss: 146.85
 ---- batch: 030 ----
mean loss: 148.41
train mean loss: 146.48
epoch train time: 0:00:01.432498
elapsed time: 0:02:21.809850
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:50:37.785385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.62
 ---- batch: 020 ----
mean loss: 151.17
 ---- batch: 030 ----
mean loss: 147.41
train mean loss: 147.90
epoch train time: 0:00:01.432405
elapsed time: 0:02:23.242415
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:50:39.217947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.34
 ---- batch: 020 ----
mean loss: 148.35
 ---- batch: 030 ----
mean loss: 146.85
train mean loss: 147.42
epoch train time: 0:00:01.432855
elapsed time: 0:02:24.675421
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:50:40.650963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.90
 ---- batch: 020 ----
mean loss: 144.17
 ---- batch: 030 ----
mean loss: 153.24
train mean loss: 148.48
epoch train time: 0:00:01.429462
elapsed time: 0:02:26.105046
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:50:42.080587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.21
 ---- batch: 020 ----
mean loss: 154.31
 ---- batch: 030 ----
mean loss: 164.44
train mean loss: 155.32
epoch train time: 0:00:01.436180
elapsed time: 0:02:27.541389
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:50:43.516921
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.90
 ---- batch: 020 ----
mean loss: 142.80
 ---- batch: 030 ----
mean loss: 149.66
train mean loss: 148.15
epoch train time: 0:00:01.432769
elapsed time: 0:02:28.974327
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:50:44.949872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.93
 ---- batch: 020 ----
mean loss: 147.24
 ---- batch: 030 ----
mean loss: 148.40
train mean loss: 146.55
epoch train time: 0:00:01.430741
elapsed time: 0:02:30.405238
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:50:46.380774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.33
 ---- batch: 020 ----
mean loss: 146.47
 ---- batch: 030 ----
mean loss: 147.59
train mean loss: 147.57
epoch train time: 0:00:01.432256
elapsed time: 0:02:31.837653
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:50:47.813200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.48
 ---- batch: 020 ----
mean loss: 145.67
 ---- batch: 030 ----
mean loss: 146.54
train mean loss: 146.09
epoch train time: 0:00:01.434361
elapsed time: 0:02:33.272189
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:50:49.247735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.89
 ---- batch: 020 ----
mean loss: 145.71
 ---- batch: 030 ----
mean loss: 143.95
train mean loss: 147.55
epoch train time: 0:00:01.433257
elapsed time: 0:02:34.705621
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:50:50.681167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.28
 ---- batch: 020 ----
mean loss: 145.68
 ---- batch: 030 ----
mean loss: 144.76
train mean loss: 146.87
epoch train time: 0:00:01.430830
elapsed time: 0:02:36.136625
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:50:52.112193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.56
 ---- batch: 020 ----
mean loss: 148.24
 ---- batch: 030 ----
mean loss: 150.69
train mean loss: 149.57
epoch train time: 0:00:01.434729
elapsed time: 0:02:37.571610
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:50:53.547142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.65
 ---- batch: 020 ----
mean loss: 149.53
 ---- batch: 030 ----
mean loss: 145.64
train mean loss: 145.15
epoch train time: 0:00:01.433041
elapsed time: 0:02:39.004804
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:50:54.980339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.57
 ---- batch: 020 ----
mean loss: 144.45
 ---- batch: 030 ----
mean loss: 145.91
train mean loss: 146.66
epoch train time: 0:00:01.431347
elapsed time: 0:02:40.436318
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:50:56.411870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.27
 ---- batch: 020 ----
mean loss: 143.11
 ---- batch: 030 ----
mean loss: 144.90
train mean loss: 145.88
epoch train time: 0:00:01.432802
elapsed time: 0:02:41.869306
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:50:57.844847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.80
 ---- batch: 020 ----
mean loss: 154.40
 ---- batch: 030 ----
mean loss: 159.26
train mean loss: 152.83
epoch train time: 0:00:01.432828
elapsed time: 0:02:43.302303
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:50:59.277840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.19
 ---- batch: 020 ----
mean loss: 143.40
 ---- batch: 030 ----
mean loss: 150.14
train mean loss: 146.41
epoch train time: 0:00:01.432947
elapsed time: 0:02:44.735420
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:51:00.710937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.22
 ---- batch: 020 ----
mean loss: 148.92
 ---- batch: 030 ----
mean loss: 148.54
train mean loss: 146.42
epoch train time: 0:00:01.430766
elapsed time: 0:02:46.166344
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:51:02.141882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.69
 ---- batch: 020 ----
mean loss: 153.40
 ---- batch: 030 ----
mean loss: 145.58
train mean loss: 150.49
epoch train time: 0:00:01.426846
elapsed time: 0:02:47.593354
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:51:03.568888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.01
 ---- batch: 020 ----
mean loss: 157.24
 ---- batch: 030 ----
mean loss: 146.83
train mean loss: 155.38
epoch train time: 0:00:01.433631
elapsed time: 0:02:49.027150
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:51:05.002683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.12
 ---- batch: 020 ----
mean loss: 149.97
 ---- batch: 030 ----
mean loss: 148.46
train mean loss: 149.37
epoch train time: 0:00:01.431004
elapsed time: 0:02:50.458317
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:51:06.433853
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.03
 ---- batch: 020 ----
mean loss: 142.86
 ---- batch: 030 ----
mean loss: 140.27
train mean loss: 143.71
epoch train time: 0:00:01.436754
elapsed time: 0:02:51.895232
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:51:07.870766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.45
 ---- batch: 020 ----
mean loss: 147.51
 ---- batch: 030 ----
mean loss: 147.47
train mean loss: 150.33
epoch train time: 0:00:01.431942
elapsed time: 0:02:53.327330
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:51:09.302865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.15
 ---- batch: 020 ----
mean loss: 146.92
 ---- batch: 030 ----
mean loss: 144.13
train mean loss: 145.53
epoch train time: 0:00:01.434590
elapsed time: 0:02:54.762100
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:51:10.737669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.43
 ---- batch: 020 ----
mean loss: 148.93
 ---- batch: 030 ----
mean loss: 146.75
train mean loss: 144.52
epoch train time: 0:00:01.436450
elapsed time: 0:02:56.198771
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:51:12.174346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.49
 ---- batch: 020 ----
mean loss: 143.54
 ---- batch: 030 ----
mean loss: 143.25
train mean loss: 143.81
epoch train time: 0:00:01.430488
elapsed time: 0:02:57.629458
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:51:13.604990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.78
 ---- batch: 020 ----
mean loss: 144.61
 ---- batch: 030 ----
mean loss: 145.82
train mean loss: 143.88
epoch train time: 0:00:01.433382
elapsed time: 0:02:59.062994
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:51:15.038542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.72
 ---- batch: 020 ----
mean loss: 147.34
 ---- batch: 030 ----
mean loss: 146.79
train mean loss: 149.07
epoch train time: 0:00:01.432862
elapsed time: 0:03:00.496036
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:51:16.471569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.97
 ---- batch: 020 ----
mean loss: 147.71
 ---- batch: 030 ----
mean loss: 140.45
train mean loss: 144.78
epoch train time: 0:00:01.435310
elapsed time: 0:03:01.931499
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:51:17.907033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.29
 ---- batch: 020 ----
mean loss: 144.46
 ---- batch: 030 ----
mean loss: 141.19
train mean loss: 143.44
epoch train time: 0:00:01.432049
elapsed time: 0:03:03.363701
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:51:19.339232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.56
 ---- batch: 020 ----
mean loss: 147.02
 ---- batch: 030 ----
mean loss: 141.26
train mean loss: 145.58
epoch train time: 0:00:01.428519
elapsed time: 0:03:04.792372
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:51:20.767903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.60
 ---- batch: 020 ----
mean loss: 148.71
 ---- batch: 030 ----
mean loss: 154.36
train mean loss: 149.99
epoch train time: 0:00:01.431371
elapsed time: 0:03:06.223901
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:51:22.199439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.51
 ---- batch: 020 ----
mean loss: 148.30
 ---- batch: 030 ----
mean loss: 140.63
train mean loss: 145.77
epoch train time: 0:00:01.434838
elapsed time: 0:03:07.658914
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:51:23.634450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.11
 ---- batch: 020 ----
mean loss: 143.11
 ---- batch: 030 ----
mean loss: 144.89
train mean loss: 143.64
epoch train time: 0:00:01.435524
elapsed time: 0:03:09.094641
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:51:25.070179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.29
 ---- batch: 020 ----
mean loss: 142.78
 ---- batch: 030 ----
mean loss: 144.74
train mean loss: 144.17
epoch train time: 0:00:01.428985
elapsed time: 0:03:10.523788
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:51:26.499336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.10
 ---- batch: 020 ----
mean loss: 146.12
 ---- batch: 030 ----
mean loss: 142.01
train mean loss: 145.20
epoch train time: 0:00:01.438298
elapsed time: 0:03:11.962279
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:51:27.937819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.69
 ---- batch: 020 ----
mean loss: 145.85
 ---- batch: 030 ----
mean loss: 149.38
train mean loss: 145.50
epoch train time: 0:00:01.433207
elapsed time: 0:03:13.395664
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:51:29.371199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.68
 ---- batch: 020 ----
mean loss: 141.08
 ---- batch: 030 ----
mean loss: 148.11
train mean loss: 144.41
epoch train time: 0:00:01.429374
elapsed time: 0:03:14.825228
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:51:30.800766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.64
 ---- batch: 020 ----
mean loss: 141.47
 ---- batch: 030 ----
mean loss: 146.39
train mean loss: 145.36
epoch train time: 0:00:01.432380
elapsed time: 0:03:16.257822
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:51:32.233367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.08
 ---- batch: 020 ----
mean loss: 143.65
 ---- batch: 030 ----
mean loss: 144.16
train mean loss: 144.47
epoch train time: 0:00:01.433976
elapsed time: 0:03:17.691987
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:51:33.667526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.34
 ---- batch: 020 ----
mean loss: 147.25
 ---- batch: 030 ----
mean loss: 144.48
train mean loss: 144.74
epoch train time: 0:00:01.433014
elapsed time: 0:03:19.125171
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:51:35.100709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.92
 ---- batch: 020 ----
mean loss: 142.57
 ---- batch: 030 ----
mean loss: 142.56
train mean loss: 140.96
epoch train time: 0:00:01.433699
elapsed time: 0:03:20.559045
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:51:36.534588
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.11
 ---- batch: 020 ----
mean loss: 143.49
 ---- batch: 030 ----
mean loss: 139.66
train mean loss: 142.16
epoch train time: 0:00:01.432607
elapsed time: 0:03:21.991860
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:51:37.967423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.14
 ---- batch: 020 ----
mean loss: 143.70
 ---- batch: 030 ----
mean loss: 145.76
train mean loss: 142.83
epoch train time: 0:00:01.431442
elapsed time: 0:03:23.423486
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:51:39.399021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.84
 ---- batch: 020 ----
mean loss: 139.21
 ---- batch: 030 ----
mean loss: 138.78
train mean loss: 139.43
epoch train time: 0:00:01.433888
elapsed time: 0:03:24.857546
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:51:40.833080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.82
 ---- batch: 020 ----
mean loss: 142.92
 ---- batch: 030 ----
mean loss: 146.22
train mean loss: 142.71
epoch train time: 0:00:01.434967
elapsed time: 0:03:26.292678
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:51:42.268216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.14
 ---- batch: 020 ----
mean loss: 139.46
 ---- batch: 030 ----
mean loss: 140.47
train mean loss: 143.22
epoch train time: 0:00:01.434989
elapsed time: 0:03:27.727934
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:51:43.703498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.58
 ---- batch: 020 ----
mean loss: 141.66
 ---- batch: 030 ----
mean loss: 136.11
train mean loss: 140.96
epoch train time: 0:00:01.434619
elapsed time: 0:03:29.162771
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:51:45.138352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.72
 ---- batch: 020 ----
mean loss: 150.19
 ---- batch: 030 ----
mean loss: 141.07
train mean loss: 143.90
epoch train time: 0:00:01.431529
elapsed time: 0:03:30.594504
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:51:46.570037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.66
 ---- batch: 020 ----
mean loss: 140.86
 ---- batch: 030 ----
mean loss: 143.14
train mean loss: 141.27
epoch train time: 0:00:01.437056
elapsed time: 0:03:32.031715
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:51:48.007249
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.39
 ---- batch: 020 ----
mean loss: 142.72
 ---- batch: 030 ----
mean loss: 146.06
train mean loss: 142.34
epoch train time: 0:00:01.431571
elapsed time: 0:03:33.463443
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:51:49.438979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.40
 ---- batch: 020 ----
mean loss: 143.61
 ---- batch: 030 ----
mean loss: 139.53
train mean loss: 142.50
epoch train time: 0:00:01.430154
elapsed time: 0:03:34.893764
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:51:50.869325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.17
 ---- batch: 020 ----
mean loss: 153.56
 ---- batch: 030 ----
mean loss: 148.91
train mean loss: 146.90
epoch train time: 0:00:01.434972
elapsed time: 0:03:36.328922
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:51:52.304458
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.49
 ---- batch: 020 ----
mean loss: 139.10
 ---- batch: 030 ----
mean loss: 143.68
train mean loss: 143.28
epoch train time: 0:00:01.432901
elapsed time: 0:03:37.761981
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:51:53.737524
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.60
 ---- batch: 020 ----
mean loss: 137.93
 ---- batch: 030 ----
mean loss: 140.08
train mean loss: 140.90
epoch train time: 0:00:01.429384
elapsed time: 0:03:39.191540
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:51:55.167073
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.00
 ---- batch: 020 ----
mean loss: 143.78
 ---- batch: 030 ----
mean loss: 136.34
train mean loss: 140.97
epoch train time: 0:00:01.433519
elapsed time: 0:03:40.625216
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:51:56.600749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.19
 ---- batch: 020 ----
mean loss: 142.21
 ---- batch: 030 ----
mean loss: 143.29
train mean loss: 142.02
epoch train time: 0:00:01.435930
elapsed time: 0:03:42.061305
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:51:58.036840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.67
 ---- batch: 020 ----
mean loss: 139.43
 ---- batch: 030 ----
mean loss: 142.43
train mean loss: 140.75
epoch train time: 0:00:01.431699
elapsed time: 0:03:43.493181
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:51:59.468718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.38
 ---- batch: 020 ----
mean loss: 142.74
 ---- batch: 030 ----
mean loss: 142.71
train mean loss: 141.68
epoch train time: 0:00:01.428714
elapsed time: 0:03:44.922170
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:52:00.897697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.26
 ---- batch: 020 ----
mean loss: 144.18
 ---- batch: 030 ----
mean loss: 145.28
train mean loss: 143.84
epoch train time: 0:00:01.433678
elapsed time: 0:03:46.356000
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:52:02.331536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.67
 ---- batch: 020 ----
mean loss: 144.61
 ---- batch: 030 ----
mean loss: 140.72
train mean loss: 140.48
epoch train time: 0:00:01.429945
elapsed time: 0:03:47.786112
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:52:03.761664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.09
 ---- batch: 020 ----
mean loss: 137.94
 ---- batch: 030 ----
mean loss: 142.08
train mean loss: 139.60
epoch train time: 0:00:01.430006
elapsed time: 0:03:49.216293
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:52:05.191830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.04
 ---- batch: 020 ----
mean loss: 144.83
 ---- batch: 030 ----
mean loss: 145.95
train mean loss: 146.38
epoch train time: 0:00:01.430169
elapsed time: 0:03:50.646625
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:52:06.622177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.22
 ---- batch: 020 ----
mean loss: 144.82
 ---- batch: 030 ----
mean loss: 141.55
train mean loss: 144.44
epoch train time: 0:00:01.430632
elapsed time: 0:03:52.077438
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:52:08.052974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.88
 ---- batch: 020 ----
mean loss: 147.15
 ---- batch: 030 ----
mean loss: 136.55
train mean loss: 143.42
epoch train time: 0:00:01.435156
elapsed time: 0:03:53.512772
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:52:09.488310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.55
 ---- batch: 020 ----
mean loss: 143.30
 ---- batch: 030 ----
mean loss: 146.44
train mean loss: 143.72
epoch train time: 0:00:01.428366
elapsed time: 0:03:54.941299
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:52:10.916863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.03
 ---- batch: 020 ----
mean loss: 138.73
 ---- batch: 030 ----
mean loss: 141.37
train mean loss: 140.77
epoch train time: 0:00:01.434079
elapsed time: 0:03:56.375568
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:52:12.351099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.40
 ---- batch: 020 ----
mean loss: 141.81
 ---- batch: 030 ----
mean loss: 138.99
train mean loss: 140.47
epoch train time: 0:00:01.429373
elapsed time: 0:03:57.805099
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:52:13.780631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.74
 ---- batch: 020 ----
mean loss: 142.43
 ---- batch: 030 ----
mean loss: 143.04
train mean loss: 139.24
epoch train time: 0:00:01.434689
elapsed time: 0:03:59.239944
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:52:15.215488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.30
 ---- batch: 020 ----
mean loss: 149.65
 ---- batch: 030 ----
mean loss: 141.64
train mean loss: 145.04
epoch train time: 0:00:01.431191
elapsed time: 0:04:00.671333
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:52:16.646900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.48
 ---- batch: 020 ----
mean loss: 140.19
 ---- batch: 030 ----
mean loss: 142.64
train mean loss: 140.85
epoch train time: 0:00:01.434283
elapsed time: 0:04:02.105802
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:52:18.081332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.97
 ---- batch: 020 ----
mean loss: 134.59
 ---- batch: 030 ----
mean loss: 141.06
train mean loss: 139.84
epoch train time: 0:00:01.428818
elapsed time: 0:04:03.534774
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:52:19.510307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.90
 ---- batch: 020 ----
mean loss: 143.29
 ---- batch: 030 ----
mean loss: 142.17
train mean loss: 141.96
epoch train time: 0:00:01.434071
elapsed time: 0:04:04.969011
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:52:20.944547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.71
 ---- batch: 020 ----
mean loss: 137.25
 ---- batch: 030 ----
mean loss: 140.11
train mean loss: 139.56
epoch train time: 0:00:01.430675
elapsed time: 0:04:06.399852
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:52:22.375388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.75
 ---- batch: 020 ----
mean loss: 141.65
 ---- batch: 030 ----
mean loss: 139.82
train mean loss: 141.57
epoch train time: 0:00:01.431152
elapsed time: 0:04:07.831168
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:52:23.806702
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.44
 ---- batch: 020 ----
mean loss: 138.74
 ---- batch: 030 ----
mean loss: 146.64
train mean loss: 143.10
epoch train time: 0:00:01.432097
elapsed time: 0:04:09.263427
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:52:25.238961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.32
 ---- batch: 020 ----
mean loss: 142.28
 ---- batch: 030 ----
mean loss: 141.20
train mean loss: 140.13
epoch train time: 0:00:01.429456
elapsed time: 0:04:10.693091
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:52:26.668642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.92
 ---- batch: 020 ----
mean loss: 136.63
 ---- batch: 030 ----
mean loss: 142.82
train mean loss: 139.96
epoch train time: 0:00:01.433232
elapsed time: 0:04:12.126504
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:52:28.102040
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.21
 ---- batch: 020 ----
mean loss: 135.75
 ---- batch: 030 ----
mean loss: 134.86
train mean loss: 137.07
epoch train time: 0:00:01.429328
elapsed time: 0:04:13.556002
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:52:29.531570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.80
 ---- batch: 020 ----
mean loss: 141.10
 ---- batch: 030 ----
mean loss: 142.11
train mean loss: 143.05
epoch train time: 0:00:01.430150
elapsed time: 0:04:14.986369
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:52:30.961907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.78
 ---- batch: 020 ----
mean loss: 145.85
 ---- batch: 030 ----
mean loss: 146.32
train mean loss: 143.37
epoch train time: 0:00:01.429444
elapsed time: 0:04:16.416012
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:52:32.391547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.32
 ---- batch: 020 ----
mean loss: 138.69
 ---- batch: 030 ----
mean loss: 137.11
train mean loss: 138.06
epoch train time: 0:00:01.433536
elapsed time: 0:04:17.849714
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:52:33.825250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.09
 ---- batch: 020 ----
mean loss: 130.18
 ---- batch: 030 ----
mean loss: 138.50
train mean loss: 137.43
epoch train time: 0:00:01.433345
elapsed time: 0:04:19.283224
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:52:35.258762
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.86
 ---- batch: 020 ----
mean loss: 145.91
 ---- batch: 030 ----
mean loss: 140.02
train mean loss: 144.14
epoch train time: 0:00:01.434650
elapsed time: 0:04:20.718058
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:52:36.693582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.24
 ---- batch: 020 ----
mean loss: 139.36
 ---- batch: 030 ----
mean loss: 144.93
train mean loss: 139.48
epoch train time: 0:00:01.431299
elapsed time: 0:04:22.149509
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:52:38.125048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.28
 ---- batch: 020 ----
mean loss: 136.72
 ---- batch: 030 ----
mean loss: 137.95
train mean loss: 138.52
epoch train time: 0:00:01.431194
elapsed time: 0:04:23.580869
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:52:39.556406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.11
 ---- batch: 020 ----
mean loss: 142.22
 ---- batch: 030 ----
mean loss: 136.97
train mean loss: 140.26
epoch train time: 0:00:01.432439
elapsed time: 0:04:25.013467
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:52:40.989002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.51
 ---- batch: 020 ----
mean loss: 142.63
 ---- batch: 030 ----
mean loss: 138.40
train mean loss: 139.45
epoch train time: 0:00:01.431810
elapsed time: 0:04:26.445432
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:52:42.420975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.90
 ---- batch: 020 ----
mean loss: 141.36
 ---- batch: 030 ----
mean loss: 136.68
train mean loss: 137.75
epoch train time: 0:00:01.432216
elapsed time: 0:04:27.877828
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:52:43.853373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.92
 ---- batch: 020 ----
mean loss: 136.38
 ---- batch: 030 ----
mean loss: 134.12
train mean loss: 136.44
epoch train time: 0:00:01.432250
elapsed time: 0:04:29.310249
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:52:45.285786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.15
 ---- batch: 020 ----
mean loss: 140.47
 ---- batch: 030 ----
mean loss: 135.92
train mean loss: 137.86
epoch train time: 0:00:01.433052
elapsed time: 0:04:30.743466
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:52:46.719002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.87
 ---- batch: 020 ----
mean loss: 145.77
 ---- batch: 030 ----
mean loss: 134.53
train mean loss: 139.23
epoch train time: 0:00:01.426128
elapsed time: 0:04:32.169764
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:52:48.145300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.78
 ---- batch: 020 ----
mean loss: 141.24
 ---- batch: 030 ----
mean loss: 138.18
train mean loss: 141.77
epoch train time: 0:00:01.433870
elapsed time: 0:04:33.603816
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:52:49.579379
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.47
 ---- batch: 020 ----
mean loss: 142.68
 ---- batch: 030 ----
mean loss: 146.10
train mean loss: 141.74
epoch train time: 0:00:01.430243
elapsed time: 0:04:35.034275
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:52:51.009827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.70
 ---- batch: 020 ----
mean loss: 141.41
 ---- batch: 030 ----
mean loss: 140.29
train mean loss: 140.84
epoch train time: 0:00:01.433501
elapsed time: 0:04:36.467951
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:52:52.443487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.82
 ---- batch: 020 ----
mean loss: 143.09
 ---- batch: 030 ----
mean loss: 138.47
train mean loss: 139.14
epoch train time: 0:00:01.428036
elapsed time: 0:04:37.896157
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:52:53.871700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.53
 ---- batch: 020 ----
mean loss: 137.06
 ---- batch: 030 ----
mean loss: 135.56
train mean loss: 136.61
epoch train time: 0:00:01.431648
elapsed time: 0:04:39.327965
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:52:55.303497
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.22
 ---- batch: 020 ----
mean loss: 141.59
 ---- batch: 030 ----
mean loss: 140.10
train mean loss: 139.59
epoch train time: 0:00:01.430016
elapsed time: 0:04:40.758165
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:52:56.733707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.78
 ---- batch: 020 ----
mean loss: 139.61
 ---- batch: 030 ----
mean loss: 136.46
train mean loss: 137.57
epoch train time: 0:00:01.433383
elapsed time: 0:04:42.191718
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:52:58.167253
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.88
 ---- batch: 020 ----
mean loss: 145.37
 ---- batch: 030 ----
mean loss: 135.77
train mean loss: 138.77
epoch train time: 0:00:01.431681
elapsed time: 0:04:43.623562
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:52:59.599098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.92
 ---- batch: 020 ----
mean loss: 138.19
 ---- batch: 030 ----
mean loss: 142.34
train mean loss: 140.15
epoch train time: 0:00:01.435225
elapsed time: 0:04:45.058957
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:53:01.034494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.83
 ---- batch: 020 ----
mean loss: 135.94
 ---- batch: 030 ----
mean loss: 139.84
train mean loss: 137.90
epoch train time: 0:00:01.429625
elapsed time: 0:04:46.488756
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:53:02.464291
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.20
 ---- batch: 020 ----
mean loss: 135.14
 ---- batch: 030 ----
mean loss: 139.67
train mean loss: 138.41
epoch train time: 0:00:01.429660
elapsed time: 0:04:47.918595
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:53:03.894165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.78
 ---- batch: 020 ----
mean loss: 138.11
 ---- batch: 030 ----
mean loss: 136.35
train mean loss: 135.96
epoch train time: 0:00:01.430818
elapsed time: 0:04:49.349681
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:53:05.325230
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.40
 ---- batch: 020 ----
mean loss: 139.81
 ---- batch: 030 ----
mean loss: 141.63
train mean loss: 141.34
epoch train time: 0:00:01.433705
elapsed time: 0:04:50.783566
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:53:06.759099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.14
 ---- batch: 020 ----
mean loss: 148.24
 ---- batch: 030 ----
mean loss: 138.06
train mean loss: 143.28
epoch train time: 0:00:01.432011
elapsed time: 0:04:52.215730
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:53:08.191295
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.12
 ---- batch: 020 ----
mean loss: 134.04
 ---- batch: 030 ----
mean loss: 134.89
train mean loss: 135.59
epoch train time: 0:00:01.432693
elapsed time: 0:04:53.648641
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:53:09.624191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.75
 ---- batch: 020 ----
mean loss: 139.36
 ---- batch: 030 ----
mean loss: 137.35
train mean loss: 136.83
epoch train time: 0:00:01.433601
elapsed time: 0:04:55.082454
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:53:11.058044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.79
 ---- batch: 020 ----
mean loss: 141.64
 ---- batch: 030 ----
mean loss: 138.67
train mean loss: 139.06
epoch train time: 0:00:01.435717
elapsed time: 0:04:56.518400
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:53:12.493937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.86
 ---- batch: 020 ----
mean loss: 135.36
 ---- batch: 030 ----
mean loss: 144.75
train mean loss: 138.50
epoch train time: 0:00:01.433901
elapsed time: 0:04:57.952480
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:53:13.928022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.59
 ---- batch: 020 ----
mean loss: 133.72
 ---- batch: 030 ----
mean loss: 142.24
train mean loss: 137.00
epoch train time: 0:00:01.434923
elapsed time: 0:04:59.387582
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:53:15.363114
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.90
 ---- batch: 020 ----
mean loss: 134.53
 ---- batch: 030 ----
mean loss: 136.52
train mean loss: 135.93
epoch train time: 0:00:01.434896
elapsed time: 0:05:00.822674
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:53:16.798214
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.96
 ---- batch: 020 ----
mean loss: 139.15
 ---- batch: 030 ----
mean loss: 133.09
train mean loss: 135.79
epoch train time: 0:00:01.433593
elapsed time: 0:05:02.256452
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:53:18.231990
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.22
 ---- batch: 020 ----
mean loss: 133.41
 ---- batch: 030 ----
mean loss: 133.61
train mean loss: 133.76
epoch train time: 0:00:01.432384
elapsed time: 0:05:03.689004
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:53:19.664543
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.92
 ---- batch: 020 ----
mean loss: 131.67
 ---- batch: 030 ----
mean loss: 136.10
train mean loss: 135.27
epoch train time: 0:00:01.434936
elapsed time: 0:05:05.124101
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:53:21.099632
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.40
 ---- batch: 020 ----
mean loss: 132.23
 ---- batch: 030 ----
mean loss: 133.87
train mean loss: 135.19
epoch train time: 0:00:01.430697
elapsed time: 0:05:06.554953
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:53:22.530490
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.14
 ---- batch: 020 ----
mean loss: 136.36
 ---- batch: 030 ----
mean loss: 130.59
train mean loss: 134.01
epoch train time: 0:00:01.428319
elapsed time: 0:05:07.983432
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:53:23.958968
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.61
 ---- batch: 020 ----
mean loss: 135.57
 ---- batch: 030 ----
mean loss: 136.07
train mean loss: 136.24
epoch train time: 0:00:01.429946
elapsed time: 0:05:09.413533
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:53:25.389063
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.36
 ---- batch: 020 ----
mean loss: 132.19
 ---- batch: 030 ----
mean loss: 133.89
train mean loss: 135.41
epoch train time: 0:00:01.434239
elapsed time: 0:05:10.847927
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:53:26.823470
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.31
 ---- batch: 020 ----
mean loss: 135.25
 ---- batch: 030 ----
mean loss: 136.19
train mean loss: 134.72
epoch train time: 0:00:01.427501
elapsed time: 0:05:12.275592
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:53:28.251150
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.69
 ---- batch: 020 ----
mean loss: 131.03
 ---- batch: 030 ----
mean loss: 134.25
train mean loss: 133.10
epoch train time: 0:00:01.431508
elapsed time: 0:05:13.707285
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:53:29.682821
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.47
 ---- batch: 020 ----
mean loss: 137.37
 ---- batch: 030 ----
mean loss: 135.98
train mean loss: 136.07
epoch train time: 0:00:01.429412
elapsed time: 0:05:15.136853
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:53:31.112384
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.88
 ---- batch: 020 ----
mean loss: 138.85
 ---- batch: 030 ----
mean loss: 137.33
train mean loss: 134.90
epoch train time: 0:00:01.432769
elapsed time: 0:05:16.569780
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:53:32.545328
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.75
 ---- batch: 020 ----
mean loss: 134.11
 ---- batch: 030 ----
mean loss: 133.13
train mean loss: 134.91
epoch train time: 0:00:01.426822
elapsed time: 0:05:17.996774
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:53:33.972307
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.21
 ---- batch: 020 ----
mean loss: 135.30
 ---- batch: 030 ----
mean loss: 133.43
train mean loss: 135.38
epoch train time: 0:00:01.431604
elapsed time: 0:05:19.428567
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:53:35.404100
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.87
 ---- batch: 020 ----
mean loss: 130.76
 ---- batch: 030 ----
mean loss: 140.11
train mean loss: 134.90
epoch train time: 0:00:01.435769
elapsed time: 0:05:20.864497
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:53:36.840043
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.13
 ---- batch: 020 ----
mean loss: 135.33
 ---- batch: 030 ----
mean loss: 136.47
train mean loss: 135.37
epoch train time: 0:00:01.431464
elapsed time: 0:05:22.296179
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:53:38.271741
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.47
 ---- batch: 020 ----
mean loss: 131.31
 ---- batch: 030 ----
mean loss: 131.38
train mean loss: 131.91
epoch train time: 0:00:01.436210
elapsed time: 0:05:23.732581
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:53:39.708117
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.63
 ---- batch: 020 ----
mean loss: 131.15
 ---- batch: 030 ----
mean loss: 132.67
train mean loss: 132.95
epoch train time: 0:00:01.427379
elapsed time: 0:05:25.160120
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:53:41.135655
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.85
 ---- batch: 020 ----
mean loss: 136.03
 ---- batch: 030 ----
mean loss: 138.07
train mean loss: 135.65
epoch train time: 0:00:01.433161
elapsed time: 0:05:26.593446
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:53:42.568980
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.47
 ---- batch: 020 ----
mean loss: 137.81
 ---- batch: 030 ----
mean loss: 132.88
train mean loss: 135.67
epoch train time: 0:00:01.433388
elapsed time: 0:05:28.026993
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:53:44.002527
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.87
 ---- batch: 020 ----
mean loss: 133.22
 ---- batch: 030 ----
mean loss: 134.94
train mean loss: 133.77
epoch train time: 0:00:01.435209
elapsed time: 0:05:29.462378
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:53:45.437917
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.44
 ---- batch: 020 ----
mean loss: 133.57
 ---- batch: 030 ----
mean loss: 132.56
train mean loss: 133.61
epoch train time: 0:00:01.428491
elapsed time: 0:05:30.891051
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:53:46.866624
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.46
 ---- batch: 020 ----
mean loss: 135.40
 ---- batch: 030 ----
mean loss: 135.39
train mean loss: 134.42
epoch train time: 0:00:01.432606
elapsed time: 0:05:32.323852
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:53:48.299384
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.08
 ---- batch: 020 ----
mean loss: 134.16
 ---- batch: 030 ----
mean loss: 133.04
train mean loss: 134.13
epoch train time: 0:00:01.429992
elapsed time: 0:05:33.754004
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:53:49.729542
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.32
 ---- batch: 020 ----
mean loss: 134.05
 ---- batch: 030 ----
mean loss: 136.84
train mean loss: 134.25
epoch train time: 0:00:01.431117
elapsed time: 0:05:35.185330
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:53:51.160899
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.20
 ---- batch: 020 ----
mean loss: 135.49
 ---- batch: 030 ----
mean loss: 133.95
train mean loss: 133.50
epoch train time: 0:00:01.432208
elapsed time: 0:05:36.617746
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:53:52.593279
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.14
 ---- batch: 020 ----
mean loss: 137.20
 ---- batch: 030 ----
mean loss: 132.91
train mean loss: 134.36
epoch train time: 0:00:01.434973
elapsed time: 0:05:38.052883
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:53:54.028427
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.54
 ---- batch: 020 ----
mean loss: 133.01
 ---- batch: 030 ----
mean loss: 138.03
train mean loss: 135.51
epoch train time: 0:00:01.432741
elapsed time: 0:05:39.485844
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:53:55.461381
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.03
 ---- batch: 020 ----
mean loss: 135.05
 ---- batch: 030 ----
mean loss: 136.20
train mean loss: 135.69
epoch train time: 0:00:01.428507
elapsed time: 0:05:40.914530
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:53:56.890079
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.99
 ---- batch: 020 ----
mean loss: 138.88
 ---- batch: 030 ----
mean loss: 131.93
train mean loss: 134.64
epoch train time: 0:00:01.424088
elapsed time: 0:05:42.338790
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:53:58.314323
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.58
 ---- batch: 020 ----
mean loss: 135.39
 ---- batch: 030 ----
mean loss: 135.14
train mean loss: 135.55
epoch train time: 0:00:01.431075
elapsed time: 0:05:43.770037
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:53:59.745582
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.87
 ---- batch: 020 ----
mean loss: 137.23
 ---- batch: 030 ----
mean loss: 133.66
train mean loss: 134.61
epoch train time: 0:00:01.432253
elapsed time: 0:05:45.202466
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:54:01.178003
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.08
 ---- batch: 020 ----
mean loss: 137.11
 ---- batch: 030 ----
mean loss: 132.50
train mean loss: 135.08
epoch train time: 0:00:01.431877
elapsed time: 0:05:46.634532
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:54:02.610054
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.67
 ---- batch: 020 ----
mean loss: 135.59
 ---- batch: 030 ----
mean loss: 129.29
train mean loss: 134.23
epoch train time: 0:00:01.431825
elapsed time: 0:05:48.066507
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:54:04.042044
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.60
 ---- batch: 020 ----
mean loss: 135.17
 ---- batch: 030 ----
mean loss: 133.41
train mean loss: 134.92
epoch train time: 0:00:01.431123
elapsed time: 0:05:49.497789
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:54:05.473323
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.92
 ---- batch: 020 ----
mean loss: 132.45
 ---- batch: 030 ----
mean loss: 133.55
train mean loss: 134.32
epoch train time: 0:00:01.433041
elapsed time: 0:05:50.930994
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:54:06.906576
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.23
 ---- batch: 020 ----
mean loss: 131.54
 ---- batch: 030 ----
mean loss: 132.23
train mean loss: 132.93
epoch train time: 0:00:01.429404
elapsed time: 0:05:52.360628
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:54:08.336167
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.16
 ---- batch: 020 ----
mean loss: 133.11
 ---- batch: 030 ----
mean loss: 138.09
train mean loss: 134.43
epoch train time: 0:00:01.432892
elapsed time: 0:05:53.793684
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:54:09.769219
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.79
 ---- batch: 020 ----
mean loss: 132.12
 ---- batch: 030 ----
mean loss: 130.95
train mean loss: 134.25
epoch train time: 0:00:01.437114
elapsed time: 0:05:55.230960
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:54:11.206499
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.87
 ---- batch: 020 ----
mean loss: 135.06
 ---- batch: 030 ----
mean loss: 135.26
train mean loss: 134.00
epoch train time: 0:00:01.426816
elapsed time: 0:05:56.657935
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:54:12.633469
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.48
 ---- batch: 020 ----
mean loss: 134.76
 ---- batch: 030 ----
mean loss: 136.56
train mean loss: 134.68
epoch train time: 0:00:01.431778
elapsed time: 0:05:58.089871
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:54:14.065406
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.08
 ---- batch: 020 ----
mean loss: 136.10
 ---- batch: 030 ----
mean loss: 131.70
train mean loss: 133.94
epoch train time: 0:00:01.431323
elapsed time: 0:05:59.521351
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:54:15.496886
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.66
 ---- batch: 020 ----
mean loss: 135.37
 ---- batch: 030 ----
mean loss: 137.25
train mean loss: 136.03
epoch train time: 0:00:01.436195
elapsed time: 0:06:00.957715
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:54:16.933251
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.78
 ---- batch: 020 ----
mean loss: 134.27
 ---- batch: 030 ----
mean loss: 129.46
train mean loss: 133.48
epoch train time: 0:00:01.432521
elapsed time: 0:06:02.390398
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:54:18.365964
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.25
 ---- batch: 020 ----
mean loss: 131.59
 ---- batch: 030 ----
mean loss: 131.92
train mean loss: 132.88
epoch train time: 0:00:01.433790
elapsed time: 0:06:03.824387
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:54:19.799932
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.41
 ---- batch: 020 ----
mean loss: 134.70
 ---- batch: 030 ----
mean loss: 135.79
train mean loss: 134.59
epoch train time: 0:00:01.434175
elapsed time: 0:06:05.258728
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:54:21.234262
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.94
 ---- batch: 020 ----
mean loss: 132.67
 ---- batch: 030 ----
mean loss: 133.66
train mean loss: 135.00
epoch train time: 0:00:01.430477
elapsed time: 0:06:06.689367
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:54:22.664904
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.78
 ---- batch: 020 ----
mean loss: 133.94
 ---- batch: 030 ----
mean loss: 129.53
train mean loss: 133.20
epoch train time: 0:00:01.428214
elapsed time: 0:06:08.117742
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:54:24.093292
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 126.81
 ---- batch: 020 ----
mean loss: 133.79
 ---- batch: 030 ----
mean loss: 135.47
train mean loss: 132.39
epoch train time: 0:00:01.433626
elapsed time: 0:06:09.554993
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_2/checkpoint.pth.tar
**** end time: 2019-09-27 15:54:25.530491 ****
