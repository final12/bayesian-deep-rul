Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_5', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32258
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 16:57:58.224365 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:57:58.227667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4144.35
 ---- batch: 020 ----
mean loss: 3916.46
 ---- batch: 030 ----
mean loss: 3905.10
train mean loss: 3969.99
epoch train time: 0:00:12.579302
elapsed time: 0:00:12.584895
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:58:10.809301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3794.57
 ---- batch: 020 ----
mean loss: 3701.93
 ---- batch: 030 ----
mean loss: 3676.92
train mean loss: 3717.97
epoch train time: 0:00:00.176510
elapsed time: 0:00:12.761544
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:58:10.985959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3601.78
 ---- batch: 020 ----
mean loss: 3543.99
 ---- batch: 030 ----
mean loss: 3517.20
train mean loss: 3539.02
epoch train time: 0:00:00.174567
elapsed time: 0:00:12.936270
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:58:11.160709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3418.52
 ---- batch: 020 ----
mean loss: 3355.46
 ---- batch: 030 ----
mean loss: 3353.45
train mean loss: 3374.41
epoch train time: 0:00:00.172623
elapsed time: 0:00:13.109071
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:58:11.333477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3225.14
 ---- batch: 020 ----
mean loss: 3175.90
 ---- batch: 030 ----
mean loss: 3252.01
train mean loss: 3206.84
epoch train time: 0:00:00.173824
elapsed time: 0:00:13.283025
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:58:11.507439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3093.68
 ---- batch: 020 ----
mean loss: 3027.47
 ---- batch: 030 ----
mean loss: 3016.85
train mean loss: 3036.01
epoch train time: 0:00:00.175522
elapsed time: 0:00:13.458681
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:58:11.683096
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2951.65
 ---- batch: 020 ----
mean loss: 2878.19
 ---- batch: 030 ----
mean loss: 2828.19
train mean loss: 2875.59
epoch train time: 0:00:00.176931
elapsed time: 0:00:13.635758
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:58:11.860181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2774.91
 ---- batch: 020 ----
mean loss: 2754.16
 ---- batch: 030 ----
mean loss: 2661.82
train mean loss: 2720.59
epoch train time: 0:00:00.173602
elapsed time: 0:00:13.809510
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:58:12.033924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2618.16
 ---- batch: 020 ----
mean loss: 2580.21
 ---- batch: 030 ----
mean loss: 2547.54
train mean loss: 2572.35
epoch train time: 0:00:00.172510
elapsed time: 0:00:13.982160
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:58:12.206577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2498.12
 ---- batch: 020 ----
mean loss: 2437.62
 ---- batch: 030 ----
mean loss: 2414.48
train mean loss: 2437.19
epoch train time: 0:00:00.172743
elapsed time: 0:00:14.155051
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:58:12.379468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2342.73
 ---- batch: 020 ----
mean loss: 2333.92
 ---- batch: 030 ----
mean loss: 2276.98
train mean loss: 2307.71
epoch train time: 0:00:00.172680
elapsed time: 0:00:14.327878
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:58:12.552292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2223.10
 ---- batch: 020 ----
mean loss: 2210.84
 ---- batch: 030 ----
mean loss: 2139.64
train mean loss: 2189.72
epoch train time: 0:00:00.179184
elapsed time: 0:00:14.507218
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:58:12.731633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2124.40
 ---- batch: 020 ----
mean loss: 2068.01
 ---- batch: 030 ----
mean loss: 2072.30
train mean loss: 2073.80
epoch train time: 0:00:00.173157
elapsed time: 0:00:14.680513
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:58:12.904941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2037.81
 ---- batch: 020 ----
mean loss: 1983.26
 ---- batch: 030 ----
mean loss: 1922.97
train mean loss: 1966.78
epoch train time: 0:00:00.173828
elapsed time: 0:00:14.854490
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:58:13.078913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1898.32
 ---- batch: 020 ----
mean loss: 1877.95
 ---- batch: 030 ----
mean loss: 1848.47
train mean loss: 1868.33
epoch train time: 0:00:00.174235
elapsed time: 0:00:15.028886
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:58:13.253302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1797.89
 ---- batch: 020 ----
mean loss: 1771.41
 ---- batch: 030 ----
mean loss: 1759.53
train mean loss: 1770.72
epoch train time: 0:00:00.174605
elapsed time: 0:00:15.203630
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:58:13.428077
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1709.70
 ---- batch: 020 ----
mean loss: 1672.23
 ---- batch: 030 ----
mean loss: 1653.90
train mean loss: 1672.99
epoch train time: 0:00:00.176488
elapsed time: 0:00:15.380296
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:58:13.604730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1618.90
 ---- batch: 020 ----
mean loss: 1588.49
 ---- batch: 030 ----
mean loss: 1538.95
train mean loss: 1581.87
epoch train time: 0:00:00.173870
elapsed time: 0:00:15.554327
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:58:13.778741
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1529.73
 ---- batch: 020 ----
mean loss: 1503.88
 ---- batch: 030 ----
mean loss: 1462.19
train mean loss: 1491.74
epoch train time: 0:00:00.186377
elapsed time: 0:00:15.740849
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:58:13.965259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1441.19
 ---- batch: 020 ----
mean loss: 1406.21
 ---- batch: 030 ----
mean loss: 1384.66
train mean loss: 1404.99
epoch train time: 0:00:00.173562
elapsed time: 0:00:15.915333
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:58:14.139763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1337.65
 ---- batch: 020 ----
mean loss: 1329.72
 ---- batch: 030 ----
mean loss: 1309.42
train mean loss: 1326.47
epoch train time: 0:00:00.186666
elapsed time: 0:00:16.102159
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:58:14.326567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1267.34
 ---- batch: 020 ----
mean loss: 1284.14
 ---- batch: 030 ----
mean loss: 1237.26
train mean loss: 1251.97
epoch train time: 0:00:00.175757
elapsed time: 0:00:16.278091
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:58:14.502506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1216.87
 ---- batch: 020 ----
mean loss: 1188.35
 ---- batch: 030 ----
mean loss: 1172.31
train mean loss: 1182.76
epoch train time: 0:00:00.176511
elapsed time: 0:00:16.454742
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:58:14.679157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1125.35
 ---- batch: 020 ----
mean loss: 1138.50
 ---- batch: 030 ----
mean loss: 1121.15
train mean loss: 1117.34
epoch train time: 0:00:00.175920
elapsed time: 0:00:16.630828
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:58:14.855260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1089.23
 ---- batch: 020 ----
mean loss: 1076.00
 ---- batch: 030 ----
mean loss: 1033.70
train mean loss: 1056.29
epoch train time: 0:00:00.174100
elapsed time: 0:00:16.805114
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:58:15.029653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1004.82
 ---- batch: 020 ----
mean loss: 1020.72
 ---- batch: 030 ----
mean loss: 991.57
train mean loss: 999.39
epoch train time: 0:00:00.174554
elapsed time: 0:00:16.979933
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:58:15.204349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 966.73
 ---- batch: 020 ----
mean loss: 954.26
 ---- batch: 030 ----
mean loss: 912.67
train mean loss: 944.61
epoch train time: 0:00:00.174628
elapsed time: 0:00:17.154707
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:58:15.379135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 914.39
 ---- batch: 020 ----
mean loss: 896.24
 ---- batch: 030 ----
mean loss: 867.81
train mean loss: 889.23
epoch train time: 0:00:00.175410
elapsed time: 0:00:17.330270
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:58:15.554685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 844.95
 ---- batch: 020 ----
mean loss: 862.60
 ---- batch: 030 ----
mean loss: 822.44
train mean loss: 837.06
epoch train time: 0:00:00.183883
elapsed time: 0:00:17.514306
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:58:15.738722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 801.50
 ---- batch: 020 ----
mean loss: 789.06
 ---- batch: 030 ----
mean loss: 776.08
train mean loss: 787.23
epoch train time: 0:00:00.177922
elapsed time: 0:00:17.692373
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:58:15.916813
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 752.15
 ---- batch: 020 ----
mean loss: 727.02
 ---- batch: 030 ----
mean loss: 751.08
train mean loss: 739.23
epoch train time: 0:00:00.177320
elapsed time: 0:00:17.869864
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:58:16.094283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 708.25
 ---- batch: 020 ----
mean loss: 701.45
 ---- batch: 030 ----
mean loss: 680.07
train mean loss: 691.73
epoch train time: 0:00:00.170965
elapsed time: 0:00:18.040978
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:58:16.265395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 668.19
 ---- batch: 020 ----
mean loss: 647.37
 ---- batch: 030 ----
mean loss: 630.60
train mean loss: 649.97
epoch train time: 0:00:00.176183
elapsed time: 0:00:18.217323
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:58:16.441740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 625.65
 ---- batch: 020 ----
mean loss: 627.47
 ---- batch: 030 ----
mean loss: 595.58
train mean loss: 610.87
epoch train time: 0:00:00.172759
elapsed time: 0:00:18.390222
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:58:16.614636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 580.99
 ---- batch: 020 ----
mean loss: 580.27
 ---- batch: 030 ----
mean loss: 568.41
train mean loss: 574.28
epoch train time: 0:00:00.180424
elapsed time: 0:00:18.570797
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:58:16.795215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 547.11
 ---- batch: 020 ----
mean loss: 539.31
 ---- batch: 030 ----
mean loss: 546.54
train mean loss: 541.54
epoch train time: 0:00:00.172100
elapsed time: 0:00:18.743072
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:58:16.967488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 521.48
 ---- batch: 020 ----
mean loss: 510.89
 ---- batch: 030 ----
mean loss: 502.11
train mean loss: 509.23
epoch train time: 0:00:00.175050
elapsed time: 0:00:18.918273
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:58:17.142690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 490.21
 ---- batch: 020 ----
mean loss: 478.25
 ---- batch: 030 ----
mean loss: 476.11
train mean loss: 480.17
epoch train time: 0:00:00.177307
elapsed time: 0:00:19.095724
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:58:17.320140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.69
 ---- batch: 020 ----
mean loss: 456.52
 ---- batch: 030 ----
mean loss: 444.70
train mean loss: 452.99
epoch train time: 0:00:00.176818
elapsed time: 0:00:19.272689
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:58:17.497095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 437.05
 ---- batch: 020 ----
mean loss: 422.14
 ---- batch: 030 ----
mean loss: 425.28
train mean loss: 427.42
epoch train time: 0:00:00.173510
elapsed time: 0:00:19.446329
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:58:17.670743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 416.43
 ---- batch: 020 ----
mean loss: 392.89
 ---- batch: 030 ----
mean loss: 401.71
train mean loss: 404.03
epoch train time: 0:00:00.183556
elapsed time: 0:00:19.630033
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:58:17.854451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 384.78
 ---- batch: 020 ----
mean loss: 377.57
 ---- batch: 030 ----
mean loss: 387.02
train mean loss: 381.25
epoch train time: 0:00:00.185523
elapsed time: 0:00:19.815698
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:58:18.040111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 376.71
 ---- batch: 020 ----
mean loss: 361.74
 ---- batch: 030 ----
mean loss: 345.84
train mean loss: 360.51
epoch train time: 0:00:00.175328
elapsed time: 0:00:19.991188
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:58:18.215613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 342.73
 ---- batch: 020 ----
mean loss: 345.27
 ---- batch: 030 ----
mean loss: 337.32
train mean loss: 341.23
epoch train time: 0:00:00.187991
elapsed time: 0:00:20.179335
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:58:18.403763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.68
 ---- batch: 020 ----
mean loss: 319.33
 ---- batch: 030 ----
mean loss: 321.70
train mean loss: 322.82
epoch train time: 0:00:00.173697
elapsed time: 0:00:20.353183
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:58:18.577599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.18
 ---- batch: 020 ----
mean loss: 300.25
 ---- batch: 030 ----
mean loss: 301.69
train mean loss: 305.91
epoch train time: 0:00:00.174876
elapsed time: 0:00:20.528198
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:58:18.752613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.18
 ---- batch: 020 ----
mean loss: 296.95
 ---- batch: 030 ----
mean loss: 287.15
train mean loss: 289.50
epoch train time: 0:00:00.175129
elapsed time: 0:00:20.703483
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:58:18.927899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 280.99
 ---- batch: 020 ----
mean loss: 276.16
 ---- batch: 030 ----
mean loss: 277.50
train mean loss: 274.87
epoch train time: 0:00:00.174827
elapsed time: 0:00:20.878448
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:58:19.102862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.29
 ---- batch: 020 ----
mean loss: 260.73
 ---- batch: 030 ----
mean loss: 261.35
train mean loss: 261.52
epoch train time: 0:00:00.174764
elapsed time: 0:00:21.053390
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:58:19.277820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.09
 ---- batch: 020 ----
mean loss: 251.96
 ---- batch: 030 ----
mean loss: 243.43
train mean loss: 248.48
epoch train time: 0:00:00.177076
elapsed time: 0:00:21.230622
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:58:19.455035
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.71
 ---- batch: 020 ----
mean loss: 232.55
 ---- batch: 030 ----
mean loss: 237.19
train mean loss: 236.39
epoch train time: 0:00:00.173652
elapsed time: 0:00:21.404408
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:58:19.628820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.73
 ---- batch: 020 ----
mean loss: 226.81
 ---- batch: 030 ----
mean loss: 220.64
train mean loss: 225.33
epoch train time: 0:00:00.174904
elapsed time: 0:00:21.579447
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:58:19.803860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.25
 ---- batch: 020 ----
mean loss: 212.23
 ---- batch: 030 ----
mean loss: 212.88
train mean loss: 214.41
epoch train time: 0:00:00.175037
elapsed time: 0:00:21.754623
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:58:19.979038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 203.57
 ---- batch: 020 ----
mean loss: 209.89
 ---- batch: 030 ----
mean loss: 201.93
train mean loss: 204.91
epoch train time: 0:00:00.174267
elapsed time: 0:00:21.929060
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:58:20.153474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 203.09
 ---- batch: 020 ----
mean loss: 192.58
 ---- batch: 030 ----
mean loss: 195.94
train mean loss: 195.97
epoch train time: 0:00:00.175597
elapsed time: 0:00:22.104807
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:58:20.329234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.52
 ---- batch: 020 ----
mean loss: 188.98
 ---- batch: 030 ----
mean loss: 182.66
train mean loss: 187.78
epoch train time: 0:00:00.173877
elapsed time: 0:00:22.278845
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:58:20.503259
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.26
 ---- batch: 020 ----
mean loss: 184.97
 ---- batch: 030 ----
mean loss: 176.76
train mean loss: 180.08
epoch train time: 0:00:00.180267
elapsed time: 0:00:22.459249
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:58:20.683677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.42
 ---- batch: 020 ----
mean loss: 170.67
 ---- batch: 030 ----
mean loss: 174.97
train mean loss: 172.68
epoch train time: 0:00:00.175017
elapsed time: 0:00:22.634413
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:58:20.858825
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.43
 ---- batch: 020 ----
mean loss: 166.97
 ---- batch: 030 ----
mean loss: 166.63
train mean loss: 166.17
epoch train time: 0:00:00.172539
elapsed time: 0:00:22.807087
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:58:21.031509
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.15
 ---- batch: 020 ----
mean loss: 158.54
 ---- batch: 030 ----
mean loss: 156.89
train mean loss: 159.44
epoch train time: 0:00:00.175604
elapsed time: 0:00:22.982874
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:58:21.207306
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.54
 ---- batch: 020 ----
mean loss: 153.30
 ---- batch: 030 ----
mean loss: 153.05
train mean loss: 153.92
epoch train time: 0:00:00.171170
elapsed time: 0:00:23.154210
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:58:21.378623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.03
 ---- batch: 020 ----
mean loss: 147.87
 ---- batch: 030 ----
mean loss: 151.38
train mean loss: 148.64
epoch train time: 0:00:00.173563
elapsed time: 0:00:23.327907
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:58:21.552320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.84
 ---- batch: 020 ----
mean loss: 144.63
 ---- batch: 030 ----
mean loss: 139.75
train mean loss: 143.31
epoch train time: 0:00:00.178235
elapsed time: 0:00:23.506287
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:58:21.730710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.41
 ---- batch: 020 ----
mean loss: 140.02
 ---- batch: 030 ----
mean loss: 138.58
train mean loss: 138.18
epoch train time: 0:00:00.178224
elapsed time: 0:00:23.684660
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:58:21.909074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.65
 ---- batch: 020 ----
mean loss: 133.17
 ---- batch: 030 ----
mean loss: 133.20
train mean loss: 133.77
epoch train time: 0:00:00.173141
elapsed time: 0:00:23.857936
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:58:22.082349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.58
 ---- batch: 020 ----
mean loss: 129.75
 ---- batch: 030 ----
mean loss: 130.65
train mean loss: 129.63
epoch train time: 0:00:00.171386
elapsed time: 0:00:24.029459
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:58:22.253873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.62
 ---- batch: 020 ----
mean loss: 127.00
 ---- batch: 030 ----
mean loss: 123.72
train mean loss: 125.58
epoch train time: 0:00:00.170255
elapsed time: 0:00:24.199850
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:58:22.424263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.71
 ---- batch: 020 ----
mean loss: 121.59
 ---- batch: 030 ----
mean loss: 122.54
train mean loss: 122.31
epoch train time: 0:00:00.173311
elapsed time: 0:00:24.373319
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:58:22.597735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.96
 ---- batch: 020 ----
mean loss: 117.39
 ---- batch: 030 ----
mean loss: 114.89
train mean loss: 118.69
epoch train time: 0:00:00.173650
elapsed time: 0:00:24.547107
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:58:22.771522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.53
 ---- batch: 020 ----
mean loss: 113.78
 ---- batch: 030 ----
mean loss: 115.87
train mean loss: 115.58
epoch train time: 0:00:00.172541
elapsed time: 0:00:24.719783
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:58:22.944213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.73
 ---- batch: 020 ----
mean loss: 113.99
 ---- batch: 030 ----
mean loss: 112.51
train mean loss: 112.60
epoch train time: 0:00:00.171540
elapsed time: 0:00:24.891473
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:58:23.115886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.77
 ---- batch: 020 ----
mean loss: 110.79
 ---- batch: 030 ----
mean loss: 108.07
train mean loss: 110.55
epoch train time: 0:00:00.173008
elapsed time: 0:00:25.064619
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:58:23.289079
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.99
 ---- batch: 020 ----
mean loss: 108.10
 ---- batch: 030 ----
mean loss: 109.12
train mean loss: 107.28
epoch train time: 0:00:00.172904
elapsed time: 0:00:25.237716
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:58:23.462130
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.59
 ---- batch: 020 ----
mean loss: 106.01
 ---- batch: 030 ----
mean loss: 103.91
train mean loss: 104.45
epoch train time: 0:00:00.178799
elapsed time: 0:00:25.416680
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:58:23.641095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.31
 ---- batch: 020 ----
mean loss: 105.30
 ---- batch: 030 ----
mean loss: 102.03
train mean loss: 102.80
epoch train time: 0:00:00.177129
elapsed time: 0:00:25.593948
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:58:23.818362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.08
 ---- batch: 020 ----
mean loss: 100.03
 ---- batch: 030 ----
mean loss: 102.17
train mean loss: 100.66
epoch train time: 0:00:00.174181
elapsed time: 0:00:25.768285
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:58:23.992730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.84
 ---- batch: 020 ----
mean loss: 97.84
 ---- batch: 030 ----
mean loss: 94.64
train mean loss: 98.62
epoch train time: 0:00:00.172294
elapsed time: 0:00:25.941288
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:58:24.165715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.03
 ---- batch: 020 ----
mean loss: 95.34
 ---- batch: 030 ----
mean loss: 97.52
train mean loss: 96.35
epoch train time: 0:00:00.174039
elapsed time: 0:00:26.115478
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:58:24.339892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.03
 ---- batch: 020 ----
mean loss: 93.08
 ---- batch: 030 ----
mean loss: 97.00
train mean loss: 94.81
epoch train time: 0:00:00.178205
elapsed time: 0:00:26.293823
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:58:24.518238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.58
 ---- batch: 020 ----
mean loss: 93.40
 ---- batch: 030 ----
mean loss: 93.77
train mean loss: 93.14
epoch train time: 0:00:00.173965
elapsed time: 0:00:26.467923
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:58:24.692337
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.68
 ---- batch: 020 ----
mean loss: 89.05
 ---- batch: 030 ----
mean loss: 90.05
train mean loss: 91.41
epoch train time: 0:00:00.180199
elapsed time: 0:00:26.648288
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:58:24.872702
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.57
 ---- batch: 020 ----
mean loss: 91.05
 ---- batch: 030 ----
mean loss: 91.37
train mean loss: 89.98
epoch train time: 0:00:00.173053
elapsed time: 0:00:26.821480
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:58:25.045894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.14
 ---- batch: 020 ----
mean loss: 90.86
 ---- batch: 030 ----
mean loss: 85.57
train mean loss: 88.46
epoch train time: 0:00:00.171948
elapsed time: 0:00:26.993579
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:58:25.217988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.65
 ---- batch: 020 ----
mean loss: 85.54
 ---- batch: 030 ----
mean loss: 87.27
train mean loss: 87.03
epoch train time: 0:00:00.169970
elapsed time: 0:00:27.163707
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:58:25.388156
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.19
 ---- batch: 020 ----
mean loss: 88.38
 ---- batch: 030 ----
mean loss: 85.88
train mean loss: 85.52
epoch train time: 0:00:00.174551
elapsed time: 0:00:27.338426
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:58:25.562869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.14
 ---- batch: 020 ----
mean loss: 85.69
 ---- batch: 030 ----
mean loss: 83.01
train mean loss: 84.32
epoch train time: 0:00:00.174924
elapsed time: 0:00:27.513518
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:58:25.737932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.60
 ---- batch: 020 ----
mean loss: 82.17
 ---- batch: 030 ----
mean loss: 87.11
train mean loss: 83.66
epoch train time: 0:00:00.176127
elapsed time: 0:00:27.689817
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:58:25.914231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.70
 ---- batch: 020 ----
mean loss: 82.78
 ---- batch: 030 ----
mean loss: 79.53
train mean loss: 82.50
epoch train time: 0:00:00.173803
elapsed time: 0:00:27.863813
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:58:26.088289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.01
 ---- batch: 020 ----
mean loss: 77.97
 ---- batch: 030 ----
mean loss: 81.55
train mean loss: 81.02
epoch train time: 0:00:00.172984
elapsed time: 0:00:28.036998
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:58:26.261423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.62
 ---- batch: 020 ----
mean loss: 78.22
 ---- batch: 030 ----
mean loss: 81.43
train mean loss: 80.43
epoch train time: 0:00:00.175543
elapsed time: 0:00:28.212719
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:58:26.437142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.83
 ---- batch: 020 ----
mean loss: 80.28
 ---- batch: 030 ----
mean loss: 78.76
train mean loss: 79.42
epoch train time: 0:00:00.174830
elapsed time: 0:00:28.387695
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:58:26.612116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.86
 ---- batch: 020 ----
mean loss: 79.68
 ---- batch: 030 ----
mean loss: 78.63
train mean loss: 78.20
epoch train time: 0:00:00.175398
elapsed time: 0:00:28.563239
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:58:26.787664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.42
 ---- batch: 020 ----
mean loss: 77.43
 ---- batch: 030 ----
mean loss: 78.58
train mean loss: 78.31
epoch train time: 0:00:00.175106
elapsed time: 0:00:28.738518
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:58:26.962962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.52
 ---- batch: 020 ----
mean loss: 76.13
 ---- batch: 030 ----
mean loss: 77.46
train mean loss: 76.75
epoch train time: 0:00:00.173047
elapsed time: 0:00:28.911733
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:58:27.136148
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.18
 ---- batch: 020 ----
mean loss: 75.68
 ---- batch: 030 ----
mean loss: 76.67
train mean loss: 76.30
epoch train time: 0:00:00.173272
elapsed time: 0:00:29.085142
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:58:27.309556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.06
 ---- batch: 020 ----
mean loss: 74.20
 ---- batch: 030 ----
mean loss: 77.52
train mean loss: 75.69
epoch train time: 0:00:00.174922
elapsed time: 0:00:29.260202
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:58:27.484615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.24
 ---- batch: 020 ----
mean loss: 74.48
 ---- batch: 030 ----
mean loss: 76.41
train mean loss: 74.25
epoch train time: 0:00:00.176687
elapsed time: 0:00:29.437040
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:58:27.661455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.43
 ---- batch: 020 ----
mean loss: 75.54
 ---- batch: 030 ----
mean loss: 75.00
train mean loss: 74.80
epoch train time: 0:00:00.185868
elapsed time: 0:00:29.623054
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:58:27.847486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.64
 ---- batch: 020 ----
mean loss: 73.22
 ---- batch: 030 ----
mean loss: 72.20
train mean loss: 73.42
epoch train time: 0:00:00.172472
elapsed time: 0:00:29.795678
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:58:28.020092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.48
 ---- batch: 020 ----
mean loss: 73.14
 ---- batch: 030 ----
mean loss: 70.86
train mean loss: 73.20
epoch train time: 0:00:00.171204
elapsed time: 0:00:29.967018
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:58:28.191432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.49
 ---- batch: 020 ----
mean loss: 71.59
 ---- batch: 030 ----
mean loss: 68.52
train mean loss: 71.97
epoch train time: 0:00:00.170735
elapsed time: 0:00:30.137883
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:58:28.362294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.36
 ---- batch: 020 ----
mean loss: 70.84
 ---- batch: 030 ----
mean loss: 69.96
train mean loss: 71.13
epoch train time: 0:00:00.168309
elapsed time: 0:00:30.306322
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:58:28.530735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.63
 ---- batch: 020 ----
mean loss: 73.21
 ---- batch: 030 ----
mean loss: 70.15
train mean loss: 70.61
epoch train time: 0:00:00.176117
elapsed time: 0:00:30.482576
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:58:28.706989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.51
 ---- batch: 020 ----
mean loss: 71.13
 ---- batch: 030 ----
mean loss: 68.97
train mean loss: 70.18
epoch train time: 0:00:00.175593
elapsed time: 0:00:30.658304
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:58:28.882717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.53
 ---- batch: 020 ----
mean loss: 67.62
 ---- batch: 030 ----
mean loss: 68.49
train mean loss: 69.76
epoch train time: 0:00:00.173873
elapsed time: 0:00:30.832326
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:58:29.056741
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.76
 ---- batch: 020 ----
mean loss: 67.67
 ---- batch: 030 ----
mean loss: 70.19
train mean loss: 69.40
epoch train time: 0:00:00.176793
elapsed time: 0:00:31.009280
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:58:29.233700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.22
 ---- batch: 020 ----
mean loss: 68.23
 ---- batch: 030 ----
mean loss: 67.21
train mean loss: 68.54
epoch train time: 0:00:00.172426
elapsed time: 0:00:31.181860
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:58:29.406263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.86
 ---- batch: 020 ----
mean loss: 68.51
 ---- batch: 030 ----
mean loss: 70.22
train mean loss: 68.80
epoch train time: 0:00:00.174544
elapsed time: 0:00:31.356527
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:58:29.580954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.29
 ---- batch: 020 ----
mean loss: 69.02
 ---- batch: 030 ----
mean loss: 65.67
train mean loss: 68.43
epoch train time: 0:00:00.175480
elapsed time: 0:00:31.532158
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:58:29.756573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.44
 ---- batch: 020 ----
mean loss: 67.72
 ---- batch: 030 ----
mean loss: 68.38
train mean loss: 67.53
epoch train time: 0:00:00.175680
elapsed time: 0:00:31.707977
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:58:29.932392
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.24
 ---- batch: 020 ----
mean loss: 66.69
 ---- batch: 030 ----
mean loss: 68.89
train mean loss: 66.62
epoch train time: 0:00:00.171919
elapsed time: 0:00:31.880034
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:58:30.104465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.03
 ---- batch: 020 ----
mean loss: 66.25
 ---- batch: 030 ----
mean loss: 66.79
train mean loss: 66.99
epoch train time: 0:00:00.171109
elapsed time: 0:00:32.051337
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:58:30.275752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.14
 ---- batch: 020 ----
mean loss: 66.38
 ---- batch: 030 ----
mean loss: 65.97
train mean loss: 66.39
epoch train time: 0:00:00.185648
elapsed time: 0:00:32.237131
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:58:30.461546
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.40
 ---- batch: 020 ----
mean loss: 64.01
 ---- batch: 030 ----
mean loss: 67.71
train mean loss: 66.05
epoch train time: 0:00:00.176192
elapsed time: 0:00:32.413463
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:58:30.637878
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.03
 ---- batch: 020 ----
mean loss: 63.96
 ---- batch: 030 ----
mean loss: 66.25
train mean loss: 65.29
epoch train time: 0:00:00.176753
elapsed time: 0:00:32.590355
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:58:30.814786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.39
 ---- batch: 020 ----
mean loss: 64.43
 ---- batch: 030 ----
mean loss: 67.99
train mean loss: 65.69
epoch train time: 0:00:00.176175
elapsed time: 0:00:32.766686
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:58:30.991098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.71
 ---- batch: 020 ----
mean loss: 66.11
 ---- batch: 030 ----
mean loss: 67.85
train mean loss: 66.83
epoch train time: 0:00:00.176256
elapsed time: 0:00:32.943100
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:58:31.167542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.89
 ---- batch: 020 ----
mean loss: 64.97
 ---- batch: 030 ----
mean loss: 65.92
train mean loss: 65.12
epoch train time: 0:00:00.174555
elapsed time: 0:00:33.117875
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:58:31.342293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.91
 ---- batch: 020 ----
mean loss: 63.89
 ---- batch: 030 ----
mean loss: 65.95
train mean loss: 64.75
epoch train time: 0:00:00.173537
elapsed time: 0:00:33.291564
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:58:31.515989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.56
 ---- batch: 020 ----
mean loss: 65.55
 ---- batch: 030 ----
mean loss: 66.11
train mean loss: 65.72
epoch train time: 0:00:00.175275
elapsed time: 0:00:33.466989
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:58:31.691414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.27
 ---- batch: 020 ----
mean loss: 64.99
 ---- batch: 030 ----
mean loss: 63.28
train mean loss: 64.70
epoch train time: 0:00:00.178852
elapsed time: 0:00:33.645990
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:58:31.870404
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.75
 ---- batch: 020 ----
mean loss: 63.17
 ---- batch: 030 ----
mean loss: 64.60
train mean loss: 63.34
epoch train time: 0:00:00.168977
elapsed time: 0:00:33.815103
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:58:32.039515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.78
 ---- batch: 020 ----
mean loss: 63.87
 ---- batch: 030 ----
mean loss: 62.13
train mean loss: 62.87
epoch train time: 0:00:00.168248
elapsed time: 0:00:33.983484
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:58:32.207896
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.83
 ---- batch: 020 ----
mean loss: 62.58
 ---- batch: 030 ----
mean loss: 63.17
train mean loss: 62.35
epoch train time: 0:00:00.169969
elapsed time: 0:00:34.153602
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:58:32.378022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.15
 ---- batch: 020 ----
mean loss: 60.62
 ---- batch: 030 ----
mean loss: 63.84
train mean loss: 62.94
epoch train time: 0:00:00.169982
elapsed time: 0:00:34.323725
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:58:32.548191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.58
 ---- batch: 020 ----
mean loss: 60.49
 ---- batch: 030 ----
mean loss: 60.46
train mean loss: 62.40
epoch train time: 0:00:00.171540
elapsed time: 0:00:34.495454
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:58:32.719870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.99
 ---- batch: 020 ----
mean loss: 62.67
 ---- batch: 030 ----
mean loss: 63.71
train mean loss: 62.73
epoch train time: 0:00:00.181540
elapsed time: 0:00:34.677145
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:58:32.901550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.73
 ---- batch: 020 ----
mean loss: 62.57
 ---- batch: 030 ----
mean loss: 63.45
train mean loss: 62.53
epoch train time: 0:00:00.173299
elapsed time: 0:00:34.850582
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:58:33.075004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.78
 ---- batch: 020 ----
mean loss: 62.12
 ---- batch: 030 ----
mean loss: 60.47
train mean loss: 61.80
epoch train time: 0:00:00.173133
elapsed time: 0:00:35.023887
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:58:33.248303
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.71
 ---- batch: 020 ----
mean loss: 63.66
 ---- batch: 030 ----
mean loss: 59.66
train mean loss: 61.34
epoch train time: 0:00:00.172159
elapsed time: 0:00:35.196212
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:58:33.420625
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.74
 ---- batch: 020 ----
mean loss: 61.48
 ---- batch: 030 ----
mean loss: 59.83
train mean loss: 61.41
epoch train time: 0:00:00.173238
elapsed time: 0:00:35.369588
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:58:33.594002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.85
 ---- batch: 020 ----
mean loss: 60.85
 ---- batch: 030 ----
mean loss: 60.39
train mean loss: 60.48
epoch train time: 0:00:00.171928
elapsed time: 0:00:35.541655
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:58:33.766067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.52
 ---- batch: 020 ----
mean loss: 64.02
 ---- batch: 030 ----
mean loss: 57.89
train mean loss: 60.85
epoch train time: 0:00:00.179248
elapsed time: 0:00:35.721064
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:58:33.945479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.99
 ---- batch: 020 ----
mean loss: 61.90
 ---- batch: 030 ----
mean loss: 61.53
train mean loss: 60.96
epoch train time: 0:00:00.171496
elapsed time: 0:00:35.892701
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:58:34.117116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.73
 ---- batch: 020 ----
mean loss: 60.23
 ---- batch: 030 ----
mean loss: 59.60
train mean loss: 60.00
epoch train time: 0:00:00.174900
elapsed time: 0:00:36.067740
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:58:34.292165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.80
 ---- batch: 020 ----
mean loss: 58.19
 ---- batch: 030 ----
mean loss: 60.77
train mean loss: 59.97
epoch train time: 0:00:00.172697
elapsed time: 0:00:36.240594
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:58:34.465009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.30
 ---- batch: 020 ----
mean loss: 60.77
 ---- batch: 030 ----
mean loss: 57.83
train mean loss: 59.90
epoch train time: 0:00:00.172969
elapsed time: 0:00:36.413700
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:58:34.638112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.99
 ---- batch: 020 ----
mean loss: 61.04
 ---- batch: 030 ----
mean loss: 56.80
train mean loss: 59.49
epoch train time: 0:00:00.173589
elapsed time: 0:00:36.587425
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:58:34.811839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.91
 ---- batch: 020 ----
mean loss: 61.22
 ---- batch: 030 ----
mean loss: 60.34
train mean loss: 60.19
epoch train time: 0:00:00.176304
elapsed time: 0:00:36.763869
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:58:34.988299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.35
 ---- batch: 020 ----
mean loss: 61.07
 ---- batch: 030 ----
mean loss: 59.10
train mean loss: 59.18
epoch train time: 0:00:00.172532
elapsed time: 0:00:36.936559
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:58:35.160981
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.72
 ---- batch: 020 ----
mean loss: 60.39
 ---- batch: 030 ----
mean loss: 61.98
train mean loss: 60.35
epoch train time: 0:00:00.172544
elapsed time: 0:00:37.109280
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:58:35.333695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.53
 ---- batch: 020 ----
mean loss: 59.98
 ---- batch: 030 ----
mean loss: 60.92
train mean loss: 59.96
epoch train time: 0:00:00.173980
elapsed time: 0:00:37.283408
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:58:35.507822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.94
 ---- batch: 020 ----
mean loss: 59.34
 ---- batch: 030 ----
mean loss: 59.20
train mean loss: 58.92
epoch train time: 0:00:00.172172
elapsed time: 0:00:37.455715
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:58:35.680129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.89
 ---- batch: 020 ----
mean loss: 57.68
 ---- batch: 030 ----
mean loss: 58.79
train mean loss: 58.07
epoch train time: 0:00:00.174559
elapsed time: 0:00:37.630411
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:58:35.854824
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.97
 ---- batch: 020 ----
mean loss: 57.91
 ---- batch: 030 ----
mean loss: 57.48
train mean loss: 57.85
epoch train time: 0:00:00.171404
elapsed time: 0:00:37.801947
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:58:36.026359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.16
 ---- batch: 020 ----
mean loss: 58.62
 ---- batch: 030 ----
mean loss: 55.82
train mean loss: 57.94
epoch train time: 0:00:00.172993
elapsed time: 0:00:37.975072
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:58:36.199485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.19
 ---- batch: 020 ----
mean loss: 60.23
 ---- batch: 030 ----
mean loss: 56.32
train mean loss: 57.96
epoch train time: 0:00:00.170440
elapsed time: 0:00:38.145650
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:58:36.370064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.34
 ---- batch: 020 ----
mean loss: 57.04
 ---- batch: 030 ----
mean loss: 58.75
train mean loss: 57.43
epoch train time: 0:00:00.173720
elapsed time: 0:00:38.319504
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:58:36.543929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.49
 ---- batch: 020 ----
mean loss: 59.13
 ---- batch: 030 ----
mean loss: 56.37
train mean loss: 57.50
epoch train time: 0:00:00.171745
elapsed time: 0:00:38.491417
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:58:36.715824
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.10
 ---- batch: 020 ----
mean loss: 58.18
 ---- batch: 030 ----
mean loss: 56.08
train mean loss: 57.68
epoch train time: 0:00:00.178025
elapsed time: 0:00:38.669578
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:58:36.894006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.78
 ---- batch: 020 ----
mean loss: 57.52
 ---- batch: 030 ----
mean loss: 56.88
train mean loss: 57.34
epoch train time: 0:00:00.174195
elapsed time: 0:00:38.843941
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:58:37.068356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.62
 ---- batch: 020 ----
mean loss: 57.02
 ---- batch: 030 ----
mean loss: 62.01
train mean loss: 57.96
epoch train time: 0:00:00.173920
elapsed time: 0:00:39.017996
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:58:37.242434
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.97
 ---- batch: 020 ----
mean loss: 58.75
 ---- batch: 030 ----
mean loss: 55.18
train mean loss: 56.74
epoch train time: 0:00:00.171892
elapsed time: 0:00:39.190063
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:58:37.414492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.14
 ---- batch: 020 ----
mean loss: 57.00
 ---- batch: 030 ----
mean loss: 57.85
train mean loss: 57.08
epoch train time: 0:00:00.172389
elapsed time: 0:00:39.362603
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:58:37.587015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.28
 ---- batch: 020 ----
mean loss: 58.77
 ---- batch: 030 ----
mean loss: 57.18
train mean loss: 57.27
epoch train time: 0:00:00.174253
elapsed time: 0:00:39.537046
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:58:37.761462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.67
 ---- batch: 020 ----
mean loss: 56.51
 ---- batch: 030 ----
mean loss: 58.69
train mean loss: 56.40
epoch train time: 0:00:00.178486
elapsed time: 0:00:39.715676
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:58:37.940089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.98
 ---- batch: 020 ----
mean loss: 54.28
 ---- batch: 030 ----
mean loss: 55.57
train mean loss: 55.64
epoch train time: 0:00:00.178547
elapsed time: 0:00:39.894358
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:58:38.118771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.34
 ---- batch: 020 ----
mean loss: 57.52
 ---- batch: 030 ----
mean loss: 58.07
train mean loss: 57.90
epoch train time: 0:00:00.173505
elapsed time: 0:00:40.068016
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:58:38.292430
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.07
 ---- batch: 020 ----
mean loss: 58.91
 ---- batch: 030 ----
mean loss: 54.09
train mean loss: 55.95
epoch train time: 0:00:00.175084
elapsed time: 0:00:40.243249
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:58:38.467666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.38
 ---- batch: 020 ----
mean loss: 53.64
 ---- batch: 030 ----
mean loss: 54.62
train mean loss: 55.01
epoch train time: 0:00:00.179453
elapsed time: 0:00:40.422875
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:58:38.647289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.50
 ---- batch: 020 ----
mean loss: 53.16
 ---- batch: 030 ----
mean loss: 56.97
train mean loss: 55.27
epoch train time: 0:00:00.182195
elapsed time: 0:00:40.605214
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:58:38.829664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.10
 ---- batch: 020 ----
mean loss: 54.67
 ---- batch: 030 ----
mean loss: 54.96
train mean loss: 56.31
epoch train time: 0:00:00.174457
elapsed time: 0:00:40.779901
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:58:39.004314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.62
 ---- batch: 020 ----
mean loss: 54.87
 ---- batch: 030 ----
mean loss: 55.30
train mean loss: 54.52
epoch train time: 0:00:00.172150
elapsed time: 0:00:40.952188
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:58:39.176603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.27
 ---- batch: 020 ----
mean loss: 55.10
 ---- batch: 030 ----
mean loss: 53.78
train mean loss: 54.62
epoch train time: 0:00:00.173369
elapsed time: 0:00:41.125699
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:58:39.350115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.37
 ---- batch: 020 ----
mean loss: 53.04
 ---- batch: 030 ----
mean loss: 53.28
train mean loss: 54.36
epoch train time: 0:00:00.176234
elapsed time: 0:00:41.302073
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:58:39.526488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.87
 ---- batch: 020 ----
mean loss: 52.10
 ---- batch: 030 ----
mean loss: 55.67
train mean loss: 54.16
epoch train time: 0:00:00.171148
elapsed time: 0:00:41.473380
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:58:39.697817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.62
 ---- batch: 020 ----
mean loss: 51.53
 ---- batch: 030 ----
mean loss: 53.48
train mean loss: 53.56
epoch train time: 0:00:00.173838
elapsed time: 0:00:41.647398
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:58:39.871818
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.03
 ---- batch: 020 ----
mean loss: 52.65
 ---- batch: 030 ----
mean loss: 55.80
train mean loss: 54.54
epoch train time: 0:00:00.170698
elapsed time: 0:00:41.818240
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:58:40.042654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.25
 ---- batch: 020 ----
mean loss: 51.81
 ---- batch: 030 ----
mean loss: 52.51
train mean loss: 53.48
epoch train time: 0:00:00.168891
elapsed time: 0:00:41.987281
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:58:40.211694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.56
 ---- batch: 020 ----
mean loss: 55.25
 ---- batch: 030 ----
mean loss: 52.39
train mean loss: 52.97
epoch train time: 0:00:00.172363
elapsed time: 0:00:42.159777
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:58:40.384190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.76
 ---- batch: 020 ----
mean loss: 54.01
 ---- batch: 030 ----
mean loss: 52.94
train mean loss: 52.96
epoch train time: 0:00:00.171320
elapsed time: 0:00:42.331237
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:58:40.555652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.27
 ---- batch: 020 ----
mean loss: 53.43
 ---- batch: 030 ----
mean loss: 51.11
train mean loss: 53.63
epoch train time: 0:00:00.175267
elapsed time: 0:00:42.506641
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:58:40.731053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.95
 ---- batch: 020 ----
mean loss: 50.87
 ---- batch: 030 ----
mean loss: 52.82
train mean loss: 52.79
epoch train time: 0:00:00.172028
elapsed time: 0:00:42.678807
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:58:40.903225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.59
 ---- batch: 020 ----
mean loss: 52.21
 ---- batch: 030 ----
mean loss: 54.30
train mean loss: 53.22
epoch train time: 0:00:00.173622
elapsed time: 0:00:42.852584
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:58:41.076989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.07
 ---- batch: 020 ----
mean loss: 55.37
 ---- batch: 030 ----
mean loss: 54.95
train mean loss: 53.69
epoch train time: 0:00:00.170940
elapsed time: 0:00:43.023674
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:58:41.248117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.56
 ---- batch: 020 ----
mean loss: 50.90
 ---- batch: 030 ----
mean loss: 53.92
train mean loss: 53.51
epoch train time: 0:00:00.169714
elapsed time: 0:00:43.193554
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:58:41.417965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.07
 ---- batch: 020 ----
mean loss: 52.02
 ---- batch: 030 ----
mean loss: 53.10
train mean loss: 52.48
epoch train time: 0:00:00.169002
elapsed time: 0:00:43.362712
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:58:41.587141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.58
 ---- batch: 020 ----
mean loss: 51.85
 ---- batch: 030 ----
mean loss: 54.18
train mean loss: 52.84
epoch train time: 0:00:00.171795
elapsed time: 0:00:43.534655
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:58:41.759067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.24
 ---- batch: 020 ----
mean loss: 51.86
 ---- batch: 030 ----
mean loss: 50.85
train mean loss: 51.46
epoch train time: 0:00:00.174378
elapsed time: 0:00:43.709195
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:58:41.933660
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.44
 ---- batch: 020 ----
mean loss: 51.47
 ---- batch: 030 ----
mean loss: 52.46
train mean loss: 52.39
epoch train time: 0:00:00.177287
elapsed time: 0:00:43.886684
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:58:42.111117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.75
 ---- batch: 020 ----
mean loss: 51.83
 ---- batch: 030 ----
mean loss: 51.66
train mean loss: 50.97
epoch train time: 0:00:00.173143
elapsed time: 0:00:44.059977
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:58:42.284388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.35
 ---- batch: 020 ----
mean loss: 53.40
 ---- batch: 030 ----
mean loss: 51.54
train mean loss: 51.29
epoch train time: 0:00:00.175539
elapsed time: 0:00:44.235656
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:58:42.460071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.11
 ---- batch: 020 ----
mean loss: 53.62
 ---- batch: 030 ----
mean loss: 50.07
train mean loss: 50.68
epoch train time: 0:00:00.174664
elapsed time: 0:00:44.410534
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:58:42.634965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.44
 ---- batch: 020 ----
mean loss: 50.79
 ---- batch: 030 ----
mean loss: 53.08
train mean loss: 51.02
epoch train time: 0:00:00.178682
elapsed time: 0:00:44.589372
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:58:42.813785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.03
 ---- batch: 020 ----
mean loss: 52.22
 ---- batch: 030 ----
mean loss: 50.79
train mean loss: 51.30
epoch train time: 0:00:00.175096
elapsed time: 0:00:44.764604
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:58:42.989021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.41
 ---- batch: 020 ----
mean loss: 49.74
 ---- batch: 030 ----
mean loss: 50.90
train mean loss: 50.80
epoch train time: 0:00:00.169675
elapsed time: 0:00:44.934430
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:58:43.158842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.64
 ---- batch: 020 ----
mean loss: 51.26
 ---- batch: 030 ----
mean loss: 50.58
train mean loss: 51.41
epoch train time: 0:00:00.171557
elapsed time: 0:00:45.106129
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:58:43.330543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.26
 ---- batch: 020 ----
mean loss: 52.04
 ---- batch: 030 ----
mean loss: 53.55
train mean loss: 51.79
epoch train time: 0:00:00.171963
elapsed time: 0:00:45.278228
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:58:43.502641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.48
 ---- batch: 020 ----
mean loss: 49.65
 ---- batch: 030 ----
mean loss: 49.28
train mean loss: 49.94
epoch train time: 0:00:00.172338
elapsed time: 0:00:45.450701
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:58:43.675115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.22
 ---- batch: 020 ----
mean loss: 48.51
 ---- batch: 030 ----
mean loss: 50.26
train mean loss: 49.46
epoch train time: 0:00:00.173456
elapsed time: 0:00:45.624303
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:58:43.848717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.53
 ---- batch: 020 ----
mean loss: 48.30
 ---- batch: 030 ----
mean loss: 49.54
train mean loss: 49.43
epoch train time: 0:00:00.176549
elapsed time: 0:00:45.800986
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:58:44.025400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.08
 ---- batch: 020 ----
mean loss: 48.13
 ---- batch: 030 ----
mean loss: 49.57
train mean loss: 49.24
epoch train time: 0:00:00.172942
elapsed time: 0:00:45.974066
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:58:44.198493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.69
 ---- batch: 020 ----
mean loss: 48.28
 ---- batch: 030 ----
mean loss: 51.00
train mean loss: 49.49
epoch train time: 0:00:00.174406
elapsed time: 0:00:46.148637
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:58:44.373053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.44
 ---- batch: 020 ----
mean loss: 51.19
 ---- batch: 030 ----
mean loss: 49.58
train mean loss: 50.04
epoch train time: 0:00:00.176769
elapsed time: 0:00:46.325562
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:58:44.549995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.31
 ---- batch: 020 ----
mean loss: 49.22
 ---- batch: 030 ----
mean loss: 51.38
train mean loss: 49.94
epoch train time: 0:00:00.173999
elapsed time: 0:00:46.499726
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:58:44.724141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.89
 ---- batch: 020 ----
mean loss: 50.92
 ---- batch: 030 ----
mean loss: 49.47
train mean loss: 49.67
epoch train time: 0:00:00.172663
elapsed time: 0:00:46.672526
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:58:44.896940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.80
 ---- batch: 020 ----
mean loss: 50.97
 ---- batch: 030 ----
mean loss: 46.50
train mean loss: 48.67
epoch train time: 0:00:00.173631
elapsed time: 0:00:46.846305
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:58:45.070717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.13
 ---- batch: 020 ----
mean loss: 49.78
 ---- batch: 030 ----
mean loss: 47.85
train mean loss: 48.71
epoch train time: 0:00:00.170713
elapsed time: 0:00:47.017161
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:58:45.241578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.84
 ---- batch: 020 ----
mean loss: 48.29
 ---- batch: 030 ----
mean loss: 48.43
train mean loss: 48.63
epoch train time: 0:00:00.171800
elapsed time: 0:00:47.189111
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:58:45.413525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.53
 ---- batch: 020 ----
mean loss: 46.37
 ---- batch: 030 ----
mean loss: 49.60
train mean loss: 48.63
epoch train time: 0:00:00.169709
elapsed time: 0:00:47.358968
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:58:45.583379
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.01
 ---- batch: 020 ----
mean loss: 48.71
 ---- batch: 030 ----
mean loss: 50.48
train mean loss: 49.45
epoch train time: 0:00:00.171825
elapsed time: 0:00:47.530928
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:58:45.755344
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.83
 ---- batch: 020 ----
mean loss: 48.82
 ---- batch: 030 ----
mean loss: 48.57
train mean loss: 47.70
epoch train time: 0:00:00.185576
elapsed time: 0:00:47.716660
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:58:45.941065
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.90
 ---- batch: 020 ----
mean loss: 47.81
 ---- batch: 030 ----
mean loss: 46.45
train mean loss: 46.89
epoch train time: 0:00:00.175431
elapsed time: 0:00:47.892217
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:58:46.116659
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.00
 ---- batch: 020 ----
mean loss: 45.53
 ---- batch: 030 ----
mean loss: 46.99
train mean loss: 46.98
epoch train time: 0:00:00.173946
elapsed time: 0:00:48.066328
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:58:46.290742
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.42
 ---- batch: 020 ----
mean loss: 44.87
 ---- batch: 030 ----
mean loss: 47.87
train mean loss: 46.73
epoch train time: 0:00:00.174425
elapsed time: 0:00:48.240892
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:58:46.465307
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.67
 ---- batch: 020 ----
mean loss: 47.75
 ---- batch: 030 ----
mean loss: 46.69
train mean loss: 46.85
epoch train time: 0:00:00.176641
elapsed time: 0:00:48.417674
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:58:46.642089
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.39
 ---- batch: 020 ----
mean loss: 47.39
 ---- batch: 030 ----
mean loss: 46.93
train mean loss: 46.73
epoch train time: 0:00:00.173576
elapsed time: 0:00:48.591424
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:58:46.815866
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.46
 ---- batch: 020 ----
mean loss: 46.58
 ---- batch: 030 ----
mean loss: 47.05
train mean loss: 46.72
epoch train time: 0:00:00.175725
elapsed time: 0:00:48.767316
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:58:46.991731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.76
 ---- batch: 020 ----
mean loss: 45.51
 ---- batch: 030 ----
mean loss: 45.31
train mean loss: 46.77
epoch train time: 0:00:00.175209
elapsed time: 0:00:48.942666
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:58:47.167079
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.92
 ---- batch: 020 ----
mean loss: 46.01
 ---- batch: 030 ----
mean loss: 46.36
train mean loss: 46.60
epoch train time: 0:00:00.176755
elapsed time: 0:00:49.119567
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:58:47.343981
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.17
 ---- batch: 020 ----
mean loss: 47.27
 ---- batch: 030 ----
mean loss: 47.19
train mean loss: 46.82
epoch train time: 0:00:00.172055
elapsed time: 0:00:49.291761
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:58:47.516174
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.85
 ---- batch: 020 ----
mean loss: 45.51
 ---- batch: 030 ----
mean loss: 45.38
train mean loss: 46.53
epoch train time: 0:00:00.171357
elapsed time: 0:00:49.463255
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:58:47.687679
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.70
 ---- batch: 020 ----
mean loss: 47.41
 ---- batch: 030 ----
mean loss: 46.84
train mean loss: 46.62
epoch train time: 0:00:00.187122
elapsed time: 0:00:49.650561
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:58:47.874976
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.88
 ---- batch: 020 ----
mean loss: 44.46
 ---- batch: 030 ----
mean loss: 47.02
train mean loss: 46.70
epoch train time: 0:00:00.171768
elapsed time: 0:00:49.822497
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:58:48.046907
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.08
 ---- batch: 020 ----
mean loss: 47.35
 ---- batch: 030 ----
mean loss: 45.85
train mean loss: 46.73
epoch train time: 0:00:00.178985
elapsed time: 0:00:50.001627
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:58:48.226037
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.20
 ---- batch: 020 ----
mean loss: 46.51
 ---- batch: 030 ----
mean loss: 48.97
train mean loss: 46.53
epoch train time: 0:00:00.170152
elapsed time: 0:00:50.171913
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:58:48.396328
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.96
 ---- batch: 020 ----
mean loss: 46.96
 ---- batch: 030 ----
mean loss: 46.06
train mean loss: 46.66
epoch train time: 0:00:00.175140
elapsed time: 0:00:50.347192
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:58:48.571604
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.54
 ---- batch: 020 ----
mean loss: 47.75
 ---- batch: 030 ----
mean loss: 47.45
train mean loss: 46.46
epoch train time: 0:00:00.173609
elapsed time: 0:00:50.520935
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:58:48.745349
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.30
 ---- batch: 020 ----
mean loss: 47.00
 ---- batch: 030 ----
mean loss: 44.05
train mean loss: 46.58
epoch train time: 0:00:00.172617
elapsed time: 0:00:50.693690
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:58:48.918101
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.97
 ---- batch: 020 ----
mean loss: 47.29
 ---- batch: 030 ----
mean loss: 46.36
train mean loss: 46.50
epoch train time: 0:00:00.173537
elapsed time: 0:00:50.867362
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:58:49.091789
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.76
 ---- batch: 020 ----
mean loss: 47.02
 ---- batch: 030 ----
mean loss: 48.64
train mean loss: 46.56
epoch train time: 0:00:00.176195
elapsed time: 0:00:51.044485
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:58:49.268941
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.49
 ---- batch: 020 ----
mean loss: 45.88
 ---- batch: 030 ----
mean loss: 47.44
train mean loss: 46.44
epoch train time: 0:00:00.178623
elapsed time: 0:00:51.223295
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:58:49.447710
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.89
 ---- batch: 020 ----
mean loss: 47.55
 ---- batch: 030 ----
mean loss: 45.58
train mean loss: 46.53
epoch train time: 0:00:00.172625
elapsed time: 0:00:51.396056
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:58:49.620484
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.83
 ---- batch: 020 ----
mean loss: 45.00
 ---- batch: 030 ----
mean loss: 49.15
train mean loss: 46.43
epoch train time: 0:00:00.172403
elapsed time: 0:00:51.568610
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:58:49.793024
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.11
 ---- batch: 020 ----
mean loss: 44.74
 ---- batch: 030 ----
mean loss: 47.32
train mean loss: 46.43
epoch train time: 0:00:00.174288
elapsed time: 0:00:51.743034
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:58:49.967488
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.16
 ---- batch: 020 ----
mean loss: 45.15
 ---- batch: 030 ----
mean loss: 46.47
train mean loss: 46.44
epoch train time: 0:00:00.171885
elapsed time: 0:00:51.915094
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:58:50.139507
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.44
 ---- batch: 020 ----
mean loss: 45.20
 ---- batch: 030 ----
mean loss: 45.76
train mean loss: 46.42
epoch train time: 0:00:00.168319
elapsed time: 0:00:52.083551
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:58:50.307963
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.12
 ---- batch: 020 ----
mean loss: 48.46
 ---- batch: 030 ----
mean loss: 45.28
train mean loss: 46.37
epoch train time: 0:00:00.168063
elapsed time: 0:00:52.251762
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:58:50.476190
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.65
 ---- batch: 020 ----
mean loss: 46.28
 ---- batch: 030 ----
mean loss: 46.29
train mean loss: 46.34
epoch train time: 0:00:00.171163
elapsed time: 0:00:52.423081
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:58:50.647495
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.74
 ---- batch: 020 ----
mean loss: 45.37
 ---- batch: 030 ----
mean loss: 46.89
train mean loss: 46.17
epoch train time: 0:00:00.177593
elapsed time: 0:00:52.600809
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:58:50.825223
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.41
 ---- batch: 020 ----
mean loss: 48.42
 ---- batch: 030 ----
mean loss: 45.73
train mean loss: 46.33
epoch train time: 0:00:00.174679
elapsed time: 0:00:52.775630
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:58:51.000045
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.39
 ---- batch: 020 ----
mean loss: 46.05
 ---- batch: 030 ----
mean loss: 46.19
train mean loss: 46.25
epoch train time: 0:00:00.174284
elapsed time: 0:00:52.950062
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:58:51.174476
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.17
 ---- batch: 020 ----
mean loss: 47.49
 ---- batch: 030 ----
mean loss: 45.28
train mean loss: 46.15
epoch train time: 0:00:00.170892
elapsed time: 0:00:53.121110
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:58:51.345526
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.77
 ---- batch: 020 ----
mean loss: 45.53
 ---- batch: 030 ----
mean loss: 45.12
train mean loss: 46.29
epoch train time: 0:00:00.176792
elapsed time: 0:00:53.298054
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:58:51.522458
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.05
 ---- batch: 020 ----
mean loss: 47.43
 ---- batch: 030 ----
mean loss: 44.25
train mean loss: 46.34
epoch train time: 0:00:00.174137
elapsed time: 0:00:53.472324
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:58:51.696757
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.79
 ---- batch: 020 ----
mean loss: 46.54
 ---- batch: 030 ----
mean loss: 44.34
train mean loss: 46.24
epoch train time: 0:00:00.176881
elapsed time: 0:00:53.649379
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:58:51.873793
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.36
 ---- batch: 020 ----
mean loss: 44.90
 ---- batch: 030 ----
mean loss: 46.59
train mean loss: 46.11
epoch train time: 0:00:00.171589
elapsed time: 0:00:53.821105
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:58:52.045530
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.92
 ---- batch: 020 ----
mean loss: 45.60
 ---- batch: 030 ----
mean loss: 46.10
train mean loss: 46.21
epoch train time: 0:00:00.174351
elapsed time: 0:00:53.995602
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:58:52.220016
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.55
 ---- batch: 020 ----
mean loss: 45.51
 ---- batch: 030 ----
mean loss: 45.67
train mean loss: 46.19
epoch train time: 0:00:00.170620
elapsed time: 0:00:54.166403
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:58:52.390830
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.86
 ---- batch: 020 ----
mean loss: 45.45
 ---- batch: 030 ----
mean loss: 45.20
train mean loss: 46.15
epoch train time: 0:00:00.171349
elapsed time: 0:00:54.337900
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:58:52.562313
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.70
 ---- batch: 020 ----
mean loss: 46.72
 ---- batch: 030 ----
mean loss: 46.32
train mean loss: 46.29
epoch train time: 0:00:00.175629
elapsed time: 0:00:54.513680
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:58:52.738092
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.41
 ---- batch: 020 ----
mean loss: 44.96
 ---- batch: 030 ----
mean loss: 48.40
train mean loss: 46.07
epoch train time: 0:00:00.175934
elapsed time: 0:00:54.689782
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:58:52.914225
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.75
 ---- batch: 020 ----
mean loss: 45.49
 ---- batch: 030 ----
mean loss: 45.78
train mean loss: 46.07
epoch train time: 0:00:00.175349
elapsed time: 0:00:54.865320
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:58:53.089738
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.43
 ---- batch: 020 ----
mean loss: 46.17
 ---- batch: 030 ----
mean loss: 45.12
train mean loss: 46.01
epoch train time: 0:00:00.179734
elapsed time: 0:00:55.045195
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:58:53.269629
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.47
 ---- batch: 020 ----
mean loss: 46.85
 ---- batch: 030 ----
mean loss: 46.24
train mean loss: 45.93
epoch train time: 0:00:00.175906
elapsed time: 0:00:55.221292
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:58:53.445714
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.94
 ---- batch: 020 ----
mean loss: 45.97
 ---- batch: 030 ----
mean loss: 47.21
train mean loss: 45.99
epoch train time: 0:00:00.177683
elapsed time: 0:00:55.399134
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:58:53.623549
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.60
 ---- batch: 020 ----
mean loss: 44.61
 ---- batch: 030 ----
mean loss: 45.71
train mean loss: 45.85
epoch train time: 0:00:00.174356
elapsed time: 0:00:55.573637
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:58:53.798052
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.00
 ---- batch: 020 ----
mean loss: 45.19
 ---- batch: 030 ----
mean loss: 46.03
train mean loss: 45.86
epoch train time: 0:00:00.176091
elapsed time: 0:00:55.749868
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:58:53.974299
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.44
 ---- batch: 020 ----
mean loss: 46.00
 ---- batch: 030 ----
mean loss: 42.29
train mean loss: 45.96
epoch train time: 0:00:00.176745
elapsed time: 0:00:55.926783
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:58:54.151203
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.74
 ---- batch: 020 ----
mean loss: 47.00
 ---- batch: 030 ----
mean loss: 46.45
train mean loss: 45.97
epoch train time: 0:00:00.175999
elapsed time: 0:00:56.106309
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_5/checkpoint.pth.tar
**** end time: 2019-09-27 16:58:54.330692 ****
