Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_1', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32050
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 16:53:09.225627 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:53:09.228842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4145.60
 ---- batch: 020 ----
mean loss: 3920.00
 ---- batch: 030 ----
mean loss: 3912.06
train mean loss: 3974.59
epoch train time: 0:00:12.503581
elapsed time: 0:00:12.509417
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:53:21.735084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3802.97
 ---- batch: 020 ----
mean loss: 3706.66
 ---- batch: 030 ----
mean loss: 3672.40
train mean loss: 3718.32
epoch train time: 0:00:00.176021
elapsed time: 0:00:12.685567
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:53:21.911254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3576.44
 ---- batch: 020 ----
mean loss: 3505.83
 ---- batch: 030 ----
mean loss: 3467.46
train mean loss: 3498.40
epoch train time: 0:00:00.172593
elapsed time: 0:00:12.858315
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:53:22.083992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3353.02
 ---- batch: 020 ----
mean loss: 3281.08
 ---- batch: 030 ----
mean loss: 3270.63
train mean loss: 3298.08
epoch train time: 0:00:00.167655
elapsed time: 0:00:13.026106
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:53:22.251781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3134.29
 ---- batch: 020 ----
mean loss: 3079.86
 ---- batch: 030 ----
mean loss: 3151.37
train mean loss: 3110.66
epoch train time: 0:00:00.168722
elapsed time: 0:00:13.194964
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:53:22.420647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2996.11
 ---- batch: 020 ----
mean loss: 2932.21
 ---- batch: 030 ----
mean loss: 2920.24
train mean loss: 2939.54
epoch train time: 0:00:00.168904
elapsed time: 0:00:13.364049
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:53:22.589721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2853.95
 ---- batch: 020 ----
mean loss: 2779.78
 ---- batch: 030 ----
mean loss: 2729.52
train mean loss: 2777.26
epoch train time: 0:00:00.181378
elapsed time: 0:00:13.545578
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:53:22.771254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2677.05
 ---- batch: 020 ----
mean loss: 2658.10
 ---- batch: 030 ----
mean loss: 2570.16
train mean loss: 2626.20
epoch train time: 0:00:00.172733
elapsed time: 0:00:13.718462
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:53:22.944155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2531.70
 ---- batch: 020 ----
mean loss: 2496.34
 ---- batch: 030 ----
mean loss: 2466.02
train mean loss: 2488.81
epoch train time: 0:00:00.181717
elapsed time: 0:00:13.900367
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:53:23.126036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2417.14
 ---- batch: 020 ----
mean loss: 2354.20
 ---- batch: 030 ----
mean loss: 2325.03
train mean loss: 2351.58
epoch train time: 0:00:00.171010
elapsed time: 0:00:14.071516
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:53:23.297188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2248.68
 ---- batch: 020 ----
mean loss: 2237.26
 ---- batch: 030 ----
mean loss: 2178.68
train mean loss: 2210.94
epoch train time: 0:00:00.171865
elapsed time: 0:00:14.243515
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:53:23.469190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2122.76
 ---- batch: 020 ----
mean loss: 2107.88
 ---- batch: 030 ----
mean loss: 2035.95
train mean loss: 2086.71
epoch train time: 0:00:00.173004
elapsed time: 0:00:14.416663
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:53:23.642333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2016.81
 ---- batch: 020 ----
mean loss: 1960.19
 ---- batch: 030 ----
mean loss: 1961.75
train mean loss: 1965.13
epoch train time: 0:00:00.174032
elapsed time: 0:00:14.590864
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:53:23.816541
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1924.22
 ---- batch: 020 ----
mean loss: 1869.40
 ---- batch: 030 ----
mean loss: 1808.57
train mean loss: 1852.75
epoch train time: 0:00:00.179673
elapsed time: 0:00:14.770686
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:53:23.996359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1780.03
 ---- batch: 020 ----
mean loss: 1757.06
 ---- batch: 030 ----
mean loss: 1725.01
train mean loss: 1746.74
epoch train time: 0:00:00.169829
elapsed time: 0:00:14.940648
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:53:24.166322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1670.14
 ---- batch: 020 ----
mean loss: 1640.58
 ---- batch: 030 ----
mean loss: 1626.06
train mean loss: 1639.48
epoch train time: 0:00:00.168476
elapsed time: 0:00:15.109259
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:53:24.334935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1574.89
 ---- batch: 020 ----
mean loss: 1537.45
 ---- batch: 030 ----
mean loss: 1517.40
train mean loss: 1537.24
epoch train time: 0:00:00.173845
elapsed time: 0:00:15.283257
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:53:24.508923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1480.24
 ---- batch: 020 ----
mean loss: 1450.23
 ---- batch: 030 ----
mean loss: 1400.89
train mean loss: 1442.99
epoch train time: 0:00:00.172985
elapsed time: 0:00:15.456377
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:53:24.682055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1389.35
 ---- batch: 020 ----
mean loss: 1364.85
 ---- batch: 030 ----
mean loss: 1325.69
train mean loss: 1353.29
epoch train time: 0:00:00.186153
elapsed time: 0:00:15.642670
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:53:24.868344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1304.40
 ---- batch: 020 ----
mean loss: 1271.23
 ---- batch: 030 ----
mean loss: 1250.11
train mean loss: 1269.55
epoch train time: 0:00:00.182268
elapsed time: 0:00:15.825786
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:53:25.051477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1203.97
 ---- batch: 020 ----
mean loss: 1197.09
 ---- batch: 030 ----
mean loss: 1176.02
train mean loss: 1193.02
epoch train time: 0:00:00.178329
elapsed time: 0:00:16.004273
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:53:25.229950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1135.24
 ---- batch: 020 ----
mean loss: 1150.75
 ---- batch: 030 ----
mean loss: 1105.08
train mean loss: 1120.12
epoch train time: 0:00:00.171970
elapsed time: 0:00:16.176445
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:53:25.402143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1085.02
 ---- batch: 020 ----
mean loss: 1057.99
 ---- batch: 030 ----
mean loss: 1041.43
train mean loss: 1052.24
epoch train time: 0:00:00.172969
elapsed time: 0:00:16.349587
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:53:25.575261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 996.39
 ---- batch: 020 ----
mean loss: 1008.04
 ---- batch: 030 ----
mean loss: 990.82
train mean loss: 988.19
epoch train time: 0:00:00.172836
elapsed time: 0:00:16.522569
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:53:25.748243
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 960.23
 ---- batch: 020 ----
mean loss: 946.29
 ---- batch: 030 ----
mean loss: 906.41
train mean loss: 928.30
epoch train time: 0:00:00.176940
elapsed time: 0:00:16.699676
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:53:25.925378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 880.37
 ---- batch: 020 ----
mean loss: 892.13
 ---- batch: 030 ----
mean loss: 864.78
train mean loss: 873.13
epoch train time: 0:00:00.175019
elapsed time: 0:00:16.874863
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:53:26.100538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 841.82
 ---- batch: 020 ----
mean loss: 830.56
 ---- batch: 030 ----
mean loss: 791.62
train mean loss: 821.20
epoch train time: 0:00:00.175322
elapsed time: 0:00:17.050338
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:53:26.276020
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 793.85
 ---- batch: 020 ----
mean loss: 776.54
 ---- batch: 030 ----
mean loss: 751.28
train mean loss: 770.39
epoch train time: 0:00:00.169683
elapsed time: 0:00:17.220166
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:53:26.445840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 730.76
 ---- batch: 020 ----
mean loss: 746.87
 ---- batch: 030 ----
mean loss: 710.35
train mean loss: 723.77
epoch train time: 0:00:00.169577
elapsed time: 0:00:17.389911
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:53:26.615585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 692.58
 ---- batch: 020 ----
mean loss: 682.25
 ---- batch: 030 ----
mean loss: 671.46
train mean loss: 680.82
epoch train time: 0:00:00.191698
elapsed time: 0:00:17.581805
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:53:26.807510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 651.10
 ---- batch: 020 ----
mean loss: 629.86
 ---- batch: 030 ----
mean loss: 651.98
train mean loss: 640.73
epoch train time: 0:00:00.183102
elapsed time: 0:00:17.765080
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:53:26.990763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 615.31
 ---- batch: 020 ----
mean loss: 609.66
 ---- batch: 030 ----
mean loss: 591.16
train mean loss: 601.18
epoch train time: 0:00:00.172610
elapsed time: 0:00:17.937841
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:53:27.163510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 581.54
 ---- batch: 020 ----
mean loss: 563.59
 ---- batch: 030 ----
mean loss: 549.04
train mean loss: 565.93
epoch train time: 0:00:00.171605
elapsed time: 0:00:18.109593
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:53:27.335268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 544.91
 ---- batch: 020 ----
mean loss: 546.37
 ---- batch: 030 ----
mean loss: 520.45
train mean loss: 532.59
epoch train time: 0:00:00.176368
elapsed time: 0:00:18.286096
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:53:27.511770
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 506.17
 ---- batch: 020 ----
mean loss: 506.80
 ---- batch: 030 ----
mean loss: 495.90
train mean loss: 501.06
epoch train time: 0:00:00.169739
elapsed time: 0:00:18.455968
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:53:27.681701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 477.43
 ---- batch: 020 ----
mean loss: 470.11
 ---- batch: 030 ----
mean loss: 476.62
train mean loss: 472.24
epoch train time: 0:00:00.173708
elapsed time: 0:00:18.629892
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:53:27.855568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 454.49
 ---- batch: 020 ----
mean loss: 445.13
 ---- batch: 030 ----
mean loss: 437.48
train mean loss: 443.66
epoch train time: 0:00:00.172397
elapsed time: 0:00:18.802431
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:53:28.028097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 426.58
 ---- batch: 020 ----
mean loss: 415.92
 ---- batch: 030 ----
mean loss: 414.44
train mean loss: 417.79
epoch train time: 0:00:00.182634
elapsed time: 0:00:18.985202
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:53:28.210877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 408.22
 ---- batch: 020 ----
mean loss: 396.69
 ---- batch: 030 ----
mean loss: 386.78
train mean loss: 393.56
epoch train time: 0:00:00.172766
elapsed time: 0:00:19.158110
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:53:28.383785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 379.41
 ---- batch: 020 ----
mean loss: 366.04
 ---- batch: 030 ----
mean loss: 368.09
train mean loss: 370.43
epoch train time: 0:00:00.175095
elapsed time: 0:00:19.333345
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:53:28.559019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 360.94
 ---- batch: 020 ----
mean loss: 340.76
 ---- batch: 030 ----
mean loss: 347.59
train mean loss: 349.94
epoch train time: 0:00:00.176998
elapsed time: 0:00:19.510497
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:53:28.736196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 332.97
 ---- batch: 020 ----
mean loss: 326.29
 ---- batch: 030 ----
mean loss: 334.19
train mean loss: 329.52
epoch train time: 0:00:00.177594
elapsed time: 0:00:19.688252
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:53:28.913936
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.15
 ---- batch: 020 ----
mean loss: 312.18
 ---- batch: 030 ----
mean loss: 298.73
train mean loss: 311.24
epoch train time: 0:00:00.171691
elapsed time: 0:00:19.860089
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:53:29.085763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 295.48
 ---- batch: 020 ----
mean loss: 297.85
 ---- batch: 030 ----
mean loss: 291.36
train mean loss: 294.33
epoch train time: 0:00:00.169554
elapsed time: 0:00:20.029781
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:53:29.255471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.67
 ---- batch: 020 ----
mean loss: 275.25
 ---- batch: 030 ----
mean loss: 277.22
train mean loss: 278.22
epoch train time: 0:00:00.169665
elapsed time: 0:00:20.199596
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:53:29.425284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.45
 ---- batch: 020 ----
mean loss: 259.28
 ---- batch: 030 ----
mean loss: 260.22
train mean loss: 263.70
epoch train time: 0:00:00.170133
elapsed time: 0:00:20.369880
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:53:29.595555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.22
 ---- batch: 020 ----
mean loss: 255.64
 ---- batch: 030 ----
mean loss: 246.83
train mean loss: 249.40
epoch train time: 0:00:00.173575
elapsed time: 0:00:20.543604
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:53:29.769279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.18
 ---- batch: 020 ----
mean loss: 237.59
 ---- batch: 030 ----
mean loss: 238.75
train mean loss: 236.68
epoch train time: 0:00:00.171292
elapsed time: 0:00:20.715049
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:53:29.940724
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.99
 ---- batch: 020 ----
mean loss: 224.10
 ---- batch: 030 ----
mean loss: 225.70
train mean loss: 225.01
epoch train time: 0:00:00.174854
elapsed time: 0:00:20.890095
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:53:30.115786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.75
 ---- batch: 020 ----
mean loss: 216.58
 ---- batch: 030 ----
mean loss: 210.30
train mean loss: 213.96
epoch train time: 0:00:00.175675
elapsed time: 0:00:21.065926
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:53:30.291602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.19
 ---- batch: 020 ----
mean loss: 200.49
 ---- batch: 030 ----
mean loss: 203.81
train mean loss: 203.65
epoch train time: 0:00:00.172282
elapsed time: 0:00:21.238374
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:53:30.464052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.71
 ---- batch: 020 ----
mean loss: 194.89
 ---- batch: 030 ----
mean loss: 189.98
train mean loss: 194.05
epoch train time: 0:00:00.170130
elapsed time: 0:00:21.408649
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:53:30.634322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.47
 ---- batch: 020 ----
mean loss: 182.97
 ---- batch: 030 ----
mean loss: 183.67
train mean loss: 184.72
epoch train time: 0:00:00.173912
elapsed time: 0:00:21.582696
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:53:30.808371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.05
 ---- batch: 020 ----
mean loss: 181.14
 ---- batch: 030 ----
mean loss: 174.83
train mean loss: 176.74
epoch train time: 0:00:00.177589
elapsed time: 0:00:21.760426
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:53:30.986101
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.19
 ---- batch: 020 ----
mean loss: 166.69
 ---- batch: 030 ----
mean loss: 168.54
train mean loss: 168.93
epoch train time: 0:00:00.170797
elapsed time: 0:00:21.931359
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:53:31.157034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.08
 ---- batch: 020 ----
mean loss: 163.15
 ---- batch: 030 ----
mean loss: 157.05
train mean loss: 161.78
epoch train time: 0:00:00.169663
elapsed time: 0:00:22.101166
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:53:31.326841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.51
 ---- batch: 020 ----
mean loss: 158.99
 ---- batch: 030 ----
mean loss: 153.11
train mean loss: 155.06
epoch train time: 0:00:00.171672
elapsed time: 0:00:22.272973
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:53:31.498662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.76
 ---- batch: 020 ----
mean loss: 147.53
 ---- batch: 030 ----
mean loss: 150.87
train mean loss: 148.92
epoch train time: 0:00:00.185496
elapsed time: 0:00:22.458619
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:53:31.684304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.74
 ---- batch: 020 ----
mean loss: 144.18
 ---- batch: 030 ----
mean loss: 144.29
train mean loss: 143.32
epoch train time: 0:00:00.174259
elapsed time: 0:00:22.633026
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:53:31.858701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.35
 ---- batch: 020 ----
mean loss: 135.95
 ---- batch: 030 ----
mean loss: 137.20
train mean loss: 138.09
epoch train time: 0:00:00.171165
elapsed time: 0:00:22.804340
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:53:32.030028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.30
 ---- batch: 020 ----
mean loss: 132.81
 ---- batch: 030 ----
mean loss: 131.97
train mean loss: 133.00
epoch train time: 0:00:00.172776
elapsed time: 0:00:22.977266
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:53:32.202941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.67
 ---- batch: 020 ----
mean loss: 127.76
 ---- batch: 030 ----
mean loss: 131.70
train mean loss: 128.57
epoch train time: 0:00:00.171088
elapsed time: 0:00:23.148572
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:53:32.374278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.02
 ---- batch: 020 ----
mean loss: 125.48
 ---- batch: 030 ----
mean loss: 121.70
train mean loss: 124.44
epoch train time: 0:00:00.168018
elapsed time: 0:00:23.316754
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:53:32.542438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.03
 ---- batch: 020 ----
mean loss: 121.55
 ---- batch: 030 ----
mean loss: 120.34
train mean loss: 120.11
epoch train time: 0:00:00.174419
elapsed time: 0:00:23.491341
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:53:32.717025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.11
 ---- batch: 020 ----
mean loss: 116.15
 ---- batch: 030 ----
mean loss: 115.26
train mean loss: 116.41
epoch train time: 0:00:00.185169
elapsed time: 0:00:23.676657
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:53:32.902333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.01
 ---- batch: 020 ----
mean loss: 112.81
 ---- batch: 030 ----
mean loss: 113.71
train mean loss: 112.94
epoch train time: 0:00:00.171696
elapsed time: 0:00:23.848521
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:53:33.074195
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.82
 ---- batch: 020 ----
mean loss: 110.50
 ---- batch: 030 ----
mean loss: 108.00
train mean loss: 109.70
epoch train time: 0:00:00.168385
elapsed time: 0:00:24.017040
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:53:33.242715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.80
 ---- batch: 020 ----
mean loss: 106.41
 ---- batch: 030 ----
mean loss: 107.23
train mean loss: 107.05
epoch train time: 0:00:00.169459
elapsed time: 0:00:24.186646
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:53:33.412348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.92
 ---- batch: 020 ----
mean loss: 102.19
 ---- batch: 030 ----
mean loss: 101.05
train mean loss: 104.32
epoch train time: 0:00:00.169471
elapsed time: 0:00:24.356299
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:53:33.581978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.49
 ---- batch: 020 ----
mean loss: 100.73
 ---- batch: 030 ----
mean loss: 101.39
train mean loss: 101.81
epoch train time: 0:00:00.171880
elapsed time: 0:00:24.528324
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:53:33.753999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.37
 ---- batch: 020 ----
mean loss: 100.99
 ---- batch: 030 ----
mean loss: 99.47
train mean loss: 99.38
epoch train time: 0:00:00.175784
elapsed time: 0:00:24.704248
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:53:33.929923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.98
 ---- batch: 020 ----
mean loss: 98.30
 ---- batch: 030 ----
mean loss: 95.71
train mean loss: 97.96
epoch train time: 0:00:00.172536
elapsed time: 0:00:24.876934
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:53:34.102610
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.09
 ---- batch: 020 ----
mean loss: 95.89
 ---- batch: 030 ----
mean loss: 97.08
train mean loss: 95.15
epoch train time: 0:00:00.168699
elapsed time: 0:00:25.045775
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:53:34.271488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.36
 ---- batch: 020 ----
mean loss: 95.50
 ---- batch: 030 ----
mean loss: 93.33
train mean loss: 93.25
epoch train time: 0:00:00.172227
elapsed time: 0:00:25.218179
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:53:34.443855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.68
 ---- batch: 020 ----
mean loss: 95.24
 ---- batch: 030 ----
mean loss: 91.73
train mean loss: 91.96
epoch train time: 0:00:00.179613
elapsed time: 0:00:25.397930
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:53:34.623604
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.08
 ---- batch: 020 ----
mean loss: 89.53
 ---- batch: 030 ----
mean loss: 91.89
train mean loss: 90.20
epoch train time: 0:00:00.172813
elapsed time: 0:00:25.570883
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:53:34.796587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.07
 ---- batch: 020 ----
mean loss: 87.46
 ---- batch: 030 ----
mean loss: 86.22
train mean loss: 88.95
epoch train time: 0:00:00.176067
elapsed time: 0:00:25.747113
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:53:34.972787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.66
 ---- batch: 020 ----
mean loss: 85.96
 ---- batch: 030 ----
mean loss: 87.98
train mean loss: 87.13
epoch train time: 0:00:00.168114
elapsed time: 0:00:25.915362
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:53:35.141036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.13
 ---- batch: 020 ----
mean loss: 84.81
 ---- batch: 030 ----
mean loss: 88.82
train mean loss: 86.23
epoch train time: 0:00:00.169149
elapsed time: 0:00:26.084648
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:53:35.310328
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.63
 ---- batch: 020 ----
mean loss: 84.86
 ---- batch: 030 ----
mean loss: 85.64
train mean loss: 85.07
epoch train time: 0:00:00.170504
elapsed time: 0:00:26.255308
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:53:35.480982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.52
 ---- batch: 020 ----
mean loss: 81.44
 ---- batch: 030 ----
mean loss: 82.96
train mean loss: 83.76
epoch train time: 0:00:00.170500
elapsed time: 0:00:26.425943
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:53:35.651621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.32
 ---- batch: 020 ----
mean loss: 84.38
 ---- batch: 030 ----
mean loss: 83.64
train mean loss: 82.83
epoch train time: 0:00:00.177510
elapsed time: 0:00:26.603639
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:53:35.829325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.46
 ---- batch: 020 ----
mean loss: 84.85
 ---- batch: 030 ----
mean loss: 78.59
train mean loss: 81.75
epoch train time: 0:00:00.175059
elapsed time: 0:00:26.778845
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:53:36.004534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.15
 ---- batch: 020 ----
mean loss: 79.23
 ---- batch: 030 ----
mean loss: 80.87
train mean loss: 80.88
epoch train time: 0:00:00.167547
elapsed time: 0:00:26.946546
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:53:36.172212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.74
 ---- batch: 020 ----
mean loss: 83.29
 ---- batch: 030 ----
mean loss: 79.87
train mean loss: 80.10
epoch train time: 0:00:00.171411
elapsed time: 0:00:27.118083
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:53:36.343757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.71
 ---- batch: 020 ----
mean loss: 79.80
 ---- batch: 030 ----
mean loss: 78.71
train mean loss: 79.26
epoch train time: 0:00:00.170306
elapsed time: 0:00:27.288530
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:53:36.514205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.57
 ---- batch: 020 ----
mean loss: 77.55
 ---- batch: 030 ----
mean loss: 83.36
train mean loss: 79.47
epoch train time: 0:00:00.172952
elapsed time: 0:00:27.461632
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:53:36.687305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.72
 ---- batch: 020 ----
mean loss: 78.56
 ---- batch: 030 ----
mean loss: 75.65
train mean loss: 78.12
epoch train time: 0:00:00.179928
elapsed time: 0:00:27.641693
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:53:36.867368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.54
 ---- batch: 020 ----
mean loss: 73.76
 ---- batch: 030 ----
mean loss: 77.88
train mean loss: 77.37
epoch train time: 0:00:00.171121
elapsed time: 0:00:27.812953
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:53:37.038646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.98
 ---- batch: 020 ----
mean loss: 74.76
 ---- batch: 030 ----
mean loss: 78.21
train mean loss: 76.83
epoch train time: 0:00:00.167168
elapsed time: 0:00:27.980275
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:53:37.205950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.59
 ---- batch: 020 ----
mean loss: 76.96
 ---- batch: 030 ----
mean loss: 75.51
train mean loss: 76.03
epoch train time: 0:00:00.166877
elapsed time: 0:00:28.147287
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:53:37.372961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.60
 ---- batch: 020 ----
mean loss: 76.13
 ---- batch: 030 ----
mean loss: 76.31
train mean loss: 75.54
epoch train time: 0:00:00.171982
elapsed time: 0:00:28.319406
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:53:37.545081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.07
 ---- batch: 020 ----
mean loss: 74.75
 ---- batch: 030 ----
mean loss: 77.08
train mean loss: 75.89
epoch train time: 0:00:00.183765
elapsed time: 0:00:28.503309
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:53:37.728982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.61
 ---- batch: 020 ----
mean loss: 74.70
 ---- batch: 030 ----
mean loss: 75.41
train mean loss: 74.38
epoch train time: 0:00:00.178364
elapsed time: 0:00:28.681810
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:53:37.907487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.39
 ---- batch: 020 ----
mean loss: 74.25
 ---- batch: 030 ----
mean loss: 74.46
train mean loss: 74.47
epoch train time: 0:00:00.173944
elapsed time: 0:00:28.855892
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:53:38.081567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.14
 ---- batch: 020 ----
mean loss: 71.53
 ---- batch: 030 ----
mean loss: 76.41
train mean loss: 73.90
epoch train time: 0:00:00.169893
elapsed time: 0:00:29.025920
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:53:38.251596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.98
 ---- batch: 020 ----
mean loss: 73.28
 ---- batch: 030 ----
mean loss: 75.63
train mean loss: 73.20
epoch train time: 0:00:00.172443
elapsed time: 0:00:29.198532
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:53:38.424221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.89
 ---- batch: 020 ----
mean loss: 73.41
 ---- batch: 030 ----
mean loss: 73.23
train mean loss: 73.32
epoch train time: 0:00:00.173815
elapsed time: 0:00:29.372507
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:53:38.598183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.78
 ---- batch: 020 ----
mean loss: 72.77
 ---- batch: 030 ----
mean loss: 72.39
train mean loss: 72.61
epoch train time: 0:00:00.178247
elapsed time: 0:00:29.550909
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:53:38.776587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.47
 ---- batch: 020 ----
mean loss: 73.35
 ---- batch: 030 ----
mean loss: 69.33
train mean loss: 72.33
epoch train time: 0:00:00.179738
elapsed time: 0:00:29.730844
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:53:38.956519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.21
 ---- batch: 020 ----
mean loss: 71.01
 ---- batch: 030 ----
mean loss: 69.72
train mean loss: 72.02
epoch train time: 0:00:00.170445
elapsed time: 0:00:29.901437
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:53:39.127108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.72
 ---- batch: 020 ----
mean loss: 70.60
 ---- batch: 030 ----
mean loss: 71.02
train mean loss: 71.93
epoch train time: 0:00:00.169535
elapsed time: 0:00:30.071104
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:53:39.296781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.25
 ---- batch: 020 ----
mean loss: 73.48
 ---- batch: 030 ----
mean loss: 71.17
train mean loss: 71.75
epoch train time: 0:00:00.173913
elapsed time: 0:00:30.245156
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:53:39.470847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.78
 ---- batch: 020 ----
mean loss: 73.88
 ---- batch: 030 ----
mean loss: 70.14
train mean loss: 71.85
epoch train time: 0:00:00.168623
elapsed time: 0:00:30.413949
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:53:39.639638
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.69
 ---- batch: 020 ----
mean loss: 69.45
 ---- batch: 030 ----
mean loss: 69.59
train mean loss: 71.37
epoch train time: 0:00:00.171064
elapsed time: 0:00:30.585162
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:53:39.810834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.42
 ---- batch: 020 ----
mean loss: 70.71
 ---- batch: 030 ----
mean loss: 72.61
train mean loss: 70.80
epoch train time: 0:00:00.173825
elapsed time: 0:00:30.759122
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:53:39.984802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.24
 ---- batch: 020 ----
mean loss: 70.13
 ---- batch: 030 ----
mean loss: 69.34
train mean loss: 70.41
epoch train time: 0:00:00.171593
elapsed time: 0:00:30.930881
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:53:40.156547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.10
 ---- batch: 020 ----
mean loss: 70.44
 ---- batch: 030 ----
mean loss: 72.06
train mean loss: 70.26
epoch train time: 0:00:00.169091
elapsed time: 0:00:31.100101
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:53:40.325776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.07
 ---- batch: 020 ----
mean loss: 71.14
 ---- batch: 030 ----
mean loss: 65.95
train mean loss: 69.45
epoch train time: 0:00:00.179289
elapsed time: 0:00:31.279531
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:53:40.505206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.92
 ---- batch: 020 ----
mean loss: 70.40
 ---- batch: 030 ----
mean loss: 70.25
train mean loss: 69.87
epoch train time: 0:00:00.173586
elapsed time: 0:00:31.453255
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:53:40.678930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.03
 ---- batch: 020 ----
mean loss: 68.91
 ---- batch: 030 ----
mean loss: 71.99
train mean loss: 69.27
epoch train time: 0:00:00.177335
elapsed time: 0:00:31.630730
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:53:40.856406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.02
 ---- batch: 020 ----
mean loss: 67.34
 ---- batch: 030 ----
mean loss: 67.96
train mean loss: 69.15
epoch train time: 0:00:00.175578
elapsed time: 0:00:31.806449
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:53:41.032124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.22
 ---- batch: 020 ----
mean loss: 69.02
 ---- batch: 030 ----
mean loss: 67.96
train mean loss: 68.75
epoch train time: 0:00:00.173430
elapsed time: 0:00:31.980040
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:53:41.205722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.72
 ---- batch: 020 ----
mean loss: 66.65
 ---- batch: 030 ----
mean loss: 69.68
train mean loss: 68.42
epoch train time: 0:00:00.174753
elapsed time: 0:00:32.154939
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:53:41.380616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.10
 ---- batch: 020 ----
mean loss: 66.13
 ---- batch: 030 ----
mean loss: 69.84
train mean loss: 68.13
epoch train time: 0:00:00.172459
elapsed time: 0:00:32.327569
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:53:41.553262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.41
 ---- batch: 020 ----
mean loss: 66.92
 ---- batch: 030 ----
mean loss: 70.41
train mean loss: 68.63
epoch train time: 0:00:00.172823
elapsed time: 0:00:32.500547
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:53:41.726222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.81
 ---- batch: 020 ----
mean loss: 67.32
 ---- batch: 030 ----
mean loss: 69.57
train mean loss: 68.31
epoch train time: 0:00:00.173152
elapsed time: 0:00:32.673849
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:53:41.899549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.56
 ---- batch: 020 ----
mean loss: 68.07
 ---- batch: 030 ----
mean loss: 69.62
train mean loss: 68.21
epoch train time: 0:00:00.175733
elapsed time: 0:00:32.849744
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:53:42.075428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.15
 ---- batch: 020 ----
mean loss: 66.36
 ---- batch: 030 ----
mean loss: 68.17
train mean loss: 67.44
epoch train time: 0:00:00.168684
elapsed time: 0:00:33.018587
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:53:42.244291
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.91
 ---- batch: 020 ----
mean loss: 68.37
 ---- batch: 030 ----
mean loss: 68.59
train mean loss: 68.15
epoch train time: 0:00:00.170052
elapsed time: 0:00:33.188822
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:53:42.414498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.48
 ---- batch: 020 ----
mean loss: 68.23
 ---- batch: 030 ----
mean loss: 66.01
train mean loss: 67.39
epoch train time: 0:00:00.171042
elapsed time: 0:00:33.360025
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:53:42.585706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.02
 ---- batch: 020 ----
mean loss: 65.67
 ---- batch: 030 ----
mean loss: 69.23
train mean loss: 66.61
epoch train time: 0:00:00.176113
elapsed time: 0:00:33.536283
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:53:42.761967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.44
 ---- batch: 020 ----
mean loss: 67.95
 ---- batch: 030 ----
mean loss: 65.67
train mean loss: 66.44
epoch train time: 0:00:00.174391
elapsed time: 0:00:33.710821
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:53:42.936498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.31
 ---- batch: 020 ----
mean loss: 66.06
 ---- batch: 030 ----
mean loss: 66.18
train mean loss: 66.11
epoch train time: 0:00:00.175146
elapsed time: 0:00:33.886104
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:53:43.111779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.08
 ---- batch: 020 ----
mean loss: 64.31
 ---- batch: 030 ----
mean loss: 68.61
train mean loss: 66.72
epoch train time: 0:00:00.171822
elapsed time: 0:00:34.058070
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:53:43.283755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.47
 ---- batch: 020 ----
mean loss: 64.07
 ---- batch: 030 ----
mean loss: 64.88
train mean loss: 66.08
epoch train time: 0:00:00.169683
elapsed time: 0:00:34.227903
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:53:43.453579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.57
 ---- batch: 020 ----
mean loss: 65.52
 ---- batch: 030 ----
mean loss: 66.88
train mean loss: 66.15
epoch train time: 0:00:00.176864
elapsed time: 0:00:34.404944
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:53:43.630607
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.30
 ---- batch: 020 ----
mean loss: 64.65
 ---- batch: 030 ----
mean loss: 67.31
train mean loss: 65.87
epoch train time: 0:00:00.176789
elapsed time: 0:00:34.581859
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:53:43.807534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.36
 ---- batch: 020 ----
mean loss: 65.78
 ---- batch: 030 ----
mean loss: 64.31
train mean loss: 65.55
epoch train time: 0:00:00.174392
elapsed time: 0:00:34.756391
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:53:43.982066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.90
 ---- batch: 020 ----
mean loss: 65.86
 ---- batch: 030 ----
mean loss: 64.09
train mean loss: 65.13
epoch train time: 0:00:00.171758
elapsed time: 0:00:34.928349
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:53:44.154023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.84
 ---- batch: 020 ----
mean loss: 64.92
 ---- batch: 030 ----
mean loss: 64.31
train mean loss: 65.55
epoch train time: 0:00:00.170846
elapsed time: 0:00:35.099339
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:53:44.325024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.98
 ---- batch: 020 ----
mean loss: 63.25
 ---- batch: 030 ----
mean loss: 65.11
train mean loss: 64.58
epoch train time: 0:00:00.171806
elapsed time: 0:00:35.271304
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:53:44.496977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.32
 ---- batch: 020 ----
mean loss: 66.64
 ---- batch: 030 ----
mean loss: 62.89
train mean loss: 64.77
epoch train time: 0:00:00.168698
elapsed time: 0:00:35.440134
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:53:44.665807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.54
 ---- batch: 020 ----
mean loss: 65.04
 ---- batch: 030 ----
mean loss: 65.46
train mean loss: 65.03
epoch train time: 0:00:00.172066
elapsed time: 0:00:35.612344
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:53:44.838019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.31
 ---- batch: 020 ----
mean loss: 64.51
 ---- batch: 030 ----
mean loss: 63.94
train mean loss: 64.01
epoch train time: 0:00:00.170122
elapsed time: 0:00:35.782602
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:53:45.008276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.65
 ---- batch: 020 ----
mean loss: 62.15
 ---- batch: 030 ----
mean loss: 65.33
train mean loss: 64.12
epoch train time: 0:00:00.172215
elapsed time: 0:00:35.954951
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:53:45.180625
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.79
 ---- batch: 020 ----
mean loss: 64.66
 ---- batch: 030 ----
mean loss: 61.19
train mean loss: 63.58
epoch train time: 0:00:00.170819
elapsed time: 0:00:36.125902
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:53:45.351574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.76
 ---- batch: 020 ----
mean loss: 66.23
 ---- batch: 030 ----
mean loss: 60.49
train mean loss: 63.77
epoch train time: 0:00:00.170808
elapsed time: 0:00:36.296893
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:53:45.522598
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.34
 ---- batch: 020 ----
mean loss: 67.15
 ---- batch: 030 ----
mean loss: 63.08
train mean loss: 64.38
epoch train time: 0:00:00.169705
elapsed time: 0:00:36.466762
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:53:45.692446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.87
 ---- batch: 020 ----
mean loss: 64.47
 ---- batch: 030 ----
mean loss: 63.87
train mean loss: 62.99
epoch train time: 0:00:00.172122
elapsed time: 0:00:36.639044
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:53:45.864721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.32
 ---- batch: 020 ----
mean loss: 63.52
 ---- batch: 030 ----
mean loss: 65.98
train mean loss: 63.90
epoch train time: 0:00:00.176966
elapsed time: 0:00:36.816157
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:53:46.041833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.24
 ---- batch: 020 ----
mean loss: 64.29
 ---- batch: 030 ----
mean loss: 64.20
train mean loss: 63.67
epoch train time: 0:00:00.176789
elapsed time: 0:00:36.993091
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:53:46.218798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.40
 ---- batch: 020 ----
mean loss: 62.57
 ---- batch: 030 ----
mean loss: 64.78
train mean loss: 62.62
epoch train time: 0:00:00.170842
elapsed time: 0:00:37.164114
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:53:46.389789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.05
 ---- batch: 020 ----
mean loss: 62.05
 ---- batch: 030 ----
mean loss: 63.16
train mean loss: 62.33
epoch train time: 0:00:00.168790
elapsed time: 0:00:37.333040
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:53:46.558732
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.61
 ---- batch: 020 ----
mean loss: 61.24
 ---- batch: 030 ----
mean loss: 61.97
train mean loss: 61.92
epoch train time: 0:00:00.175934
elapsed time: 0:00:37.509131
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:53:46.734811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.95
 ---- batch: 020 ----
mean loss: 63.14
 ---- batch: 030 ----
mean loss: 59.96
train mean loss: 62.45
epoch train time: 0:00:00.177143
elapsed time: 0:00:37.686419
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:53:46.912106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.57
 ---- batch: 020 ----
mean loss: 64.46
 ---- batch: 030 ----
mean loss: 59.49
train mean loss: 61.67
epoch train time: 0:00:00.174998
elapsed time: 0:00:37.861563
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:53:47.087246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.01
 ---- batch: 020 ----
mean loss: 61.69
 ---- batch: 030 ----
mean loss: 62.60
train mean loss: 61.45
epoch train time: 0:00:00.168272
elapsed time: 0:00:38.029981
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:53:47.255656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.15
 ---- batch: 020 ----
mean loss: 63.73
 ---- batch: 030 ----
mean loss: 61.31
train mean loss: 61.91
epoch train time: 0:00:00.169355
elapsed time: 0:00:38.199483
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:53:47.425146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.94
 ---- batch: 020 ----
mean loss: 63.02
 ---- batch: 030 ----
mean loss: 61.09
train mean loss: 62.49
epoch train time: 0:00:00.166257
elapsed time: 0:00:38.365864
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:53:47.591538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.01
 ---- batch: 020 ----
mean loss: 61.53
 ---- batch: 030 ----
mean loss: 61.93
train mean loss: 61.54
epoch train time: 0:00:00.176026
elapsed time: 0:00:38.542026
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:53:47.767700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.68
 ---- batch: 020 ----
mean loss: 61.44
 ---- batch: 030 ----
mean loss: 65.40
train mean loss: 61.53
epoch train time: 0:00:00.182790
elapsed time: 0:00:38.725023
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:53:47.950706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.39
 ---- batch: 020 ----
mean loss: 63.67
 ---- batch: 030 ----
mean loss: 57.90
train mean loss: 60.71
epoch train time: 0:00:00.174003
elapsed time: 0:00:38.899180
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:53:48.124890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.53
 ---- batch: 020 ----
mean loss: 61.29
 ---- batch: 030 ----
mean loss: 62.46
train mean loss: 60.77
epoch train time: 0:00:00.173006
elapsed time: 0:00:39.072361
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:53:48.298036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.76
 ---- batch: 020 ----
mean loss: 63.40
 ---- batch: 030 ----
mean loss: 60.03
train mean loss: 61.39
epoch train time: 0:00:00.171022
elapsed time: 0:00:39.243519
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:53:48.469193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.66
 ---- batch: 020 ----
mean loss: 60.74
 ---- batch: 030 ----
mean loss: 63.23
train mean loss: 60.22
epoch train time: 0:00:00.174201
elapsed time: 0:00:39.417862
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:53:48.643534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.80
 ---- batch: 020 ----
mean loss: 58.88
 ---- batch: 030 ----
mean loss: 60.17
train mean loss: 60.11
epoch train time: 0:00:00.173312
elapsed time: 0:00:39.591310
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:53:48.816984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.80
 ---- batch: 020 ----
mean loss: 61.12
 ---- batch: 030 ----
mean loss: 60.85
train mean loss: 61.39
epoch train time: 0:00:00.174602
elapsed time: 0:00:39.766066
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:53:48.991758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.92
 ---- batch: 020 ----
mean loss: 62.30
 ---- batch: 030 ----
mean loss: 58.12
train mean loss: 59.77
epoch train time: 0:00:00.173656
elapsed time: 0:00:39.939908
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:53:49.165582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.91
 ---- batch: 020 ----
mean loss: 57.53
 ---- batch: 030 ----
mean loss: 58.09
train mean loss: 59.28
epoch train time: 0:00:00.169416
elapsed time: 0:00:40.109461
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:53:49.335172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.19
 ---- batch: 020 ----
mean loss: 57.74
 ---- batch: 030 ----
mean loss: 60.87
train mean loss: 59.82
epoch train time: 0:00:00.172389
elapsed time: 0:00:40.282022
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:53:49.507695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.86
 ---- batch: 020 ----
mean loss: 58.50
 ---- batch: 030 ----
mean loss: 59.09
train mean loss: 59.94
epoch train time: 0:00:00.170039
elapsed time: 0:00:40.452195
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:53:49.677867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.53
 ---- batch: 020 ----
mean loss: 59.86
 ---- batch: 030 ----
mean loss: 59.39
train mean loss: 58.78
epoch train time: 0:00:00.173452
elapsed time: 0:00:40.625782
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:53:49.851457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.47
 ---- batch: 020 ----
mean loss: 60.00
 ---- batch: 030 ----
mean loss: 57.89
train mean loss: 58.90
epoch train time: 0:00:00.173648
elapsed time: 0:00:40.799598
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:53:50.025271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.21
 ---- batch: 020 ----
mean loss: 57.69
 ---- batch: 030 ----
mean loss: 57.08
train mean loss: 58.94
epoch train time: 0:00:00.173636
elapsed time: 0:00:40.973366
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:53:50.199042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.13
 ---- batch: 020 ----
mean loss: 56.68
 ---- batch: 030 ----
mean loss: 60.45
train mean loss: 58.54
epoch train time: 0:00:00.169469
elapsed time: 0:00:41.143010
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:53:50.368700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.77
 ---- batch: 020 ----
mean loss: 57.30
 ---- batch: 030 ----
mean loss: 56.37
train mean loss: 58.42
epoch train time: 0:00:00.167463
elapsed time: 0:00:41.310663
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:53:50.536338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.73
 ---- batch: 020 ----
mean loss: 58.01
 ---- batch: 030 ----
mean loss: 60.79
train mean loss: 59.57
epoch train time: 0:00:00.170698
elapsed time: 0:00:41.481500
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:53:50.707174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.25
 ---- batch: 020 ----
mean loss: 56.18
 ---- batch: 030 ----
mean loss: 56.42
train mean loss: 58.35
epoch train time: 0:00:00.174370
elapsed time: 0:00:41.656053
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:53:50.881750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.16
 ---- batch: 020 ----
mean loss: 60.81
 ---- batch: 030 ----
mean loss: 57.44
train mean loss: 57.98
epoch train time: 0:00:00.179223
elapsed time: 0:00:41.835482
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:53:51.061157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.61
 ---- batch: 020 ----
mean loss: 58.84
 ---- batch: 030 ----
mean loss: 58.30
train mean loss: 57.80
epoch train time: 0:00:00.175046
elapsed time: 0:00:42.010679
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:53:51.236355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.77
 ---- batch: 020 ----
mean loss: 58.31
 ---- batch: 030 ----
mean loss: 57.66
train mean loss: 58.72
epoch train time: 0:00:00.173030
elapsed time: 0:00:42.183866
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:53:51.409549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.31
 ---- batch: 020 ----
mean loss: 55.23
 ---- batch: 030 ----
mean loss: 58.64
train mean loss: 57.79
epoch train time: 0:00:00.171985
elapsed time: 0:00:42.356024
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:53:51.581707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.55
 ---- batch: 020 ----
mean loss: 59.34
 ---- batch: 030 ----
mean loss: 57.51
train mean loss: 57.88
epoch train time: 0:00:00.171439
elapsed time: 0:00:42.527624
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:53:51.753289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.32
 ---- batch: 020 ----
mean loss: 58.82
 ---- batch: 030 ----
mean loss: 58.80
train mean loss: 57.09
epoch train time: 0:00:00.180629
elapsed time: 0:00:42.708387
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:53:51.934064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.49
 ---- batch: 020 ----
mean loss: 56.01
 ---- batch: 030 ----
mean loss: 58.29
train mean loss: 57.67
epoch train time: 0:00:00.175597
elapsed time: 0:00:42.884142
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:53:52.109817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.93
 ---- batch: 020 ----
mean loss: 56.01
 ---- batch: 030 ----
mean loss: 58.26
train mean loss: 57.09
epoch train time: 0:00:00.175004
elapsed time: 0:00:43.059289
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:53:52.284965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.40
 ---- batch: 020 ----
mean loss: 56.97
 ---- batch: 030 ----
mean loss: 59.65
train mean loss: 57.86
epoch train time: 0:00:00.170207
elapsed time: 0:00:43.229634
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:53:52.455308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.99
 ---- batch: 020 ----
mean loss: 57.08
 ---- batch: 030 ----
mean loss: 54.73
train mean loss: 56.41
epoch train time: 0:00:00.172682
elapsed time: 0:00:43.402464
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:53:52.628138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.84
 ---- batch: 020 ----
mean loss: 55.17
 ---- batch: 030 ----
mean loss: 56.98
train mean loss: 56.89
epoch train time: 0:00:00.181596
elapsed time: 0:00:43.584207
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:53:52.809900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.92
 ---- batch: 020 ----
mean loss: 56.88
 ---- batch: 030 ----
mean loss: 57.35
train mean loss: 56.23
epoch train time: 0:00:00.178763
elapsed time: 0:00:43.763126
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:53:52.988800
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.55
 ---- batch: 020 ----
mean loss: 59.36
 ---- batch: 030 ----
mean loss: 56.44
train mean loss: 56.78
epoch train time: 0:00:00.169660
elapsed time: 0:00:43.932921
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:53:53.158595
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.50
 ---- batch: 020 ----
mean loss: 59.29
 ---- batch: 030 ----
mean loss: 54.91
train mean loss: 55.68
epoch train time: 0:00:00.167651
elapsed time: 0:00:44.100706
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:53:53.326410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.33
 ---- batch: 020 ----
mean loss: 56.13
 ---- batch: 030 ----
mean loss: 57.61
train mean loss: 56.22
epoch train time: 0:00:00.169646
elapsed time: 0:00:44.270518
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:53:53.496192
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.05
 ---- batch: 020 ----
mean loss: 56.41
 ---- batch: 030 ----
mean loss: 55.74
train mean loss: 56.09
epoch train time: 0:00:00.166509
elapsed time: 0:00:44.437162
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:53:53.662855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.16
 ---- batch: 020 ----
mean loss: 55.16
 ---- batch: 030 ----
mean loss: 55.80
train mean loss: 56.25
epoch train time: 0:00:00.174360
elapsed time: 0:00:44.611680
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:53:53.837354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.83
 ---- batch: 020 ----
mean loss: 58.82
 ---- batch: 030 ----
mean loss: 55.76
train mean loss: 58.21
epoch train time: 0:00:00.170625
elapsed time: 0:00:44.782462
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:53:54.008153
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.47
 ---- batch: 020 ----
mean loss: 55.10
 ---- batch: 030 ----
mean loss: 58.80
train mean loss: 56.09
epoch train time: 0:00:00.168749
elapsed time: 0:00:44.951359
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:53:54.177041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.37
 ---- batch: 020 ----
mean loss: 54.78
 ---- batch: 030 ----
mean loss: 55.62
train mean loss: 55.43
epoch train time: 0:00:00.171718
elapsed time: 0:00:45.123220
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:53:54.348895
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.76
 ---- batch: 020 ----
mean loss: 53.76
 ---- batch: 030 ----
mean loss: 56.62
train mean loss: 55.09
epoch train time: 0:00:00.171913
elapsed time: 0:00:45.295265
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:53:54.520937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.75
 ---- batch: 020 ----
mean loss: 53.22
 ---- batch: 030 ----
mean loss: 55.18
train mean loss: 54.76
epoch train time: 0:00:00.172633
elapsed time: 0:00:45.468093
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:53:54.693794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.66
 ---- batch: 020 ----
mean loss: 53.60
 ---- batch: 030 ----
mean loss: 55.51
train mean loss: 54.52
epoch train time: 0:00:00.181898
elapsed time: 0:00:45.650156
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:53:54.875832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.55
 ---- batch: 020 ----
mean loss: 53.89
 ---- batch: 030 ----
mean loss: 58.13
train mean loss: 54.88
epoch train time: 0:00:00.175824
elapsed time: 0:00:45.826121
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:53:55.051798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.30
 ---- batch: 020 ----
mean loss: 57.66
 ---- batch: 030 ----
mean loss: 53.17
train mean loss: 55.03
epoch train time: 0:00:00.174998
elapsed time: 0:00:46.001258
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:53:55.226934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.42
 ---- batch: 020 ----
mean loss: 54.82
 ---- batch: 030 ----
mean loss: 54.99
train mean loss: 55.00
epoch train time: 0:00:00.173878
elapsed time: 0:00:46.175275
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:53:55.400949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.64
 ---- batch: 020 ----
mean loss: 56.58
 ---- batch: 030 ----
mean loss: 55.50
train mean loss: 55.68
epoch train time: 0:00:00.174544
elapsed time: 0:00:46.349967
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:53:55.575644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.87
 ---- batch: 020 ----
mean loss: 57.09
 ---- batch: 030 ----
mean loss: 51.21
train mean loss: 54.61
epoch train time: 0:00:00.178040
elapsed time: 0:00:46.528165
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:53:55.753848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.57
 ---- batch: 020 ----
mean loss: 55.20
 ---- batch: 030 ----
mean loss: 52.95
train mean loss: 53.90
epoch train time: 0:00:00.174998
elapsed time: 0:00:46.703309
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:53:55.928985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.71
 ---- batch: 020 ----
mean loss: 53.69
 ---- batch: 030 ----
mean loss: 54.04
train mean loss: 53.72
epoch train time: 0:00:00.178479
elapsed time: 0:00:46.881940
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:53:56.107632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.97
 ---- batch: 020 ----
mean loss: 50.68
 ---- batch: 030 ----
mean loss: 54.39
train mean loss: 54.21
epoch train time: 0:00:00.170246
elapsed time: 0:00:47.052342
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:53:56.278017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.33
 ---- batch: 020 ----
mean loss: 54.17
 ---- batch: 030 ----
mean loss: 55.17
train mean loss: 54.57
epoch train time: 0:00:00.177929
elapsed time: 0:00:47.230438
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:53:56.456122
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.35
 ---- batch: 020 ----
mean loss: 53.54
 ---- batch: 030 ----
mean loss: 53.60
train mean loss: 52.70
epoch train time: 0:00:00.169091
elapsed time: 0:00:47.399687
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:53:56.625351
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.47
 ---- batch: 020 ----
mean loss: 52.69
 ---- batch: 030 ----
mean loss: 51.73
train mean loss: 52.48
epoch train time: 0:00:00.177695
elapsed time: 0:00:47.577509
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:53:56.803185
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.74
 ---- batch: 020 ----
mean loss: 51.57
 ---- batch: 030 ----
mean loss: 52.26
train mean loss: 52.65
epoch train time: 0:00:00.181394
elapsed time: 0:00:47.759050
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:53:56.984725
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.29
 ---- batch: 020 ----
mean loss: 50.53
 ---- batch: 030 ----
mean loss: 53.08
train mean loss: 52.42
epoch train time: 0:00:00.173075
elapsed time: 0:00:47.932278
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:53:57.157968
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.59
 ---- batch: 020 ----
mean loss: 53.29
 ---- batch: 030 ----
mean loss: 52.00
train mean loss: 52.53
epoch train time: 0:00:00.170526
elapsed time: 0:00:48.102972
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:53:57.328648
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.98
 ---- batch: 020 ----
mean loss: 52.67
 ---- batch: 030 ----
mean loss: 51.70
train mean loss: 52.34
epoch train time: 0:00:00.171567
elapsed time: 0:00:48.274677
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:53:57.500350
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.94
 ---- batch: 020 ----
mean loss: 52.92
 ---- batch: 030 ----
mean loss: 52.17
train mean loss: 52.33
epoch train time: 0:00:00.167066
elapsed time: 0:00:48.441919
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:53:57.667627
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.49
 ---- batch: 020 ----
mean loss: 51.18
 ---- batch: 030 ----
mean loss: 51.02
train mean loss: 52.36
epoch train time: 0:00:00.173516
elapsed time: 0:00:48.615610
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:53:57.841287
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.55
 ---- batch: 020 ----
mean loss: 51.62
 ---- batch: 030 ----
mean loss: 51.90
train mean loss: 52.25
epoch train time: 0:00:00.174488
elapsed time: 0:00:48.790239
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:53:58.015914
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.53
 ---- batch: 020 ----
mean loss: 52.59
 ---- batch: 030 ----
mean loss: 53.34
train mean loss: 52.45
epoch train time: 0:00:00.174758
elapsed time: 0:00:48.965129
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:53:58.190801
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.63
 ---- batch: 020 ----
mean loss: 50.99
 ---- batch: 030 ----
mean loss: 51.10
train mean loss: 52.19
epoch train time: 0:00:00.170939
elapsed time: 0:00:49.136208
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:53:58.361884
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.62
 ---- batch: 020 ----
mean loss: 53.88
 ---- batch: 030 ----
mean loss: 52.75
train mean loss: 52.27
epoch train time: 0:00:00.174350
elapsed time: 0:00:49.310694
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:53:58.536438
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.02
 ---- batch: 020 ----
mean loss: 50.03
 ---- batch: 030 ----
mean loss: 53.14
train mean loss: 52.32
epoch train time: 0:00:00.173577
elapsed time: 0:00:49.484488
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:53:58.710171
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.56
 ---- batch: 020 ----
mean loss: 52.41
 ---- batch: 030 ----
mean loss: 52.05
train mean loss: 52.39
epoch train time: 0:00:00.187781
elapsed time: 0:00:49.672433
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:53:58.898109
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.59
 ---- batch: 020 ----
mean loss: 51.64
 ---- batch: 030 ----
mean loss: 54.32
train mean loss: 52.14
epoch train time: 0:00:00.173355
elapsed time: 0:00:49.845927
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:53:59.071603
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.93
 ---- batch: 020 ----
mean loss: 52.83
 ---- batch: 030 ----
mean loss: 51.63
train mean loss: 52.33
epoch train time: 0:00:00.172762
elapsed time: 0:00:50.018825
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:53:59.244509
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.39
 ---- batch: 020 ----
mean loss: 52.95
 ---- batch: 030 ----
mean loss: 54.26
train mean loss: 52.17
epoch train time: 0:00:00.173432
elapsed time: 0:00:50.192414
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:53:59.418090
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.65
 ---- batch: 020 ----
mean loss: 52.54
 ---- batch: 030 ----
mean loss: 49.42
train mean loss: 52.23
epoch train time: 0:00:00.174586
elapsed time: 0:00:50.367154
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:53:59.592826
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.97
 ---- batch: 020 ----
mean loss: 52.80
 ---- batch: 030 ----
mean loss: 52.95
train mean loss: 52.24
epoch train time: 0:00:00.172615
elapsed time: 0:00:50.539903
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:53:59.765577
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.11
 ---- batch: 020 ----
mean loss: 53.19
 ---- batch: 030 ----
mean loss: 53.75
train mean loss: 52.27
epoch train time: 0:00:00.172755
elapsed time: 0:00:50.712795
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:53:59.938470
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.97
 ---- batch: 020 ----
mean loss: 51.79
 ---- batch: 030 ----
mean loss: 52.53
train mean loss: 52.17
epoch train time: 0:00:00.171452
elapsed time: 0:00:50.884409
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:54:00.110084
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.93
 ---- batch: 020 ----
mean loss: 51.77
 ---- batch: 030 ----
mean loss: 52.43
train mean loss: 52.19
epoch train time: 0:00:00.170949
elapsed time: 0:00:51.055523
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:54:00.281199
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.61
 ---- batch: 020 ----
mean loss: 50.81
 ---- batch: 030 ----
mean loss: 54.61
train mean loss: 52.09
epoch train time: 0:00:00.172645
elapsed time: 0:00:51.228307
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:54:00.453997
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.57
 ---- batch: 020 ----
mean loss: 50.45
 ---- batch: 030 ----
mean loss: 52.27
train mean loss: 52.07
epoch train time: 0:00:00.171346
elapsed time: 0:00:51.399803
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:54:00.625477
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.00
 ---- batch: 020 ----
mean loss: 50.96
 ---- batch: 030 ----
mean loss: 52.71
train mean loss: 52.09
epoch train time: 0:00:00.172261
elapsed time: 0:00:51.572205
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:54:00.797900
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.76
 ---- batch: 020 ----
mean loss: 50.96
 ---- batch: 030 ----
mean loss: 50.82
train mean loss: 52.06
epoch train time: 0:00:00.177292
elapsed time: 0:00:51.749659
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:54:00.975336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.31
 ---- batch: 020 ----
mean loss: 53.64
 ---- batch: 030 ----
mean loss: 51.19
train mean loss: 52.05
epoch train time: 0:00:00.173800
elapsed time: 0:00:51.923599
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:54:01.149275
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.42
 ---- batch: 020 ----
mean loss: 52.42
 ---- batch: 030 ----
mean loss: 51.60
train mean loss: 52.00
epoch train time: 0:00:00.176176
elapsed time: 0:00:52.099935
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:54:01.325652
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.09
 ---- batch: 020 ----
mean loss: 50.50
 ---- batch: 030 ----
mean loss: 52.81
train mean loss: 51.87
epoch train time: 0:00:00.177372
elapsed time: 0:00:52.277485
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:54:01.503160
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.06
 ---- batch: 020 ----
mean loss: 54.60
 ---- batch: 030 ----
mean loss: 51.25
train mean loss: 52.07
epoch train time: 0:00:00.171698
elapsed time: 0:00:52.449331
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:54:01.675007
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.39
 ---- batch: 020 ----
mean loss: 52.13
 ---- batch: 030 ----
mean loss: 51.81
train mean loss: 51.93
epoch train time: 0:00:00.175436
elapsed time: 0:00:52.624908
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:54:01.850582
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.93
 ---- batch: 020 ----
mean loss: 53.53
 ---- batch: 030 ----
mean loss: 50.54
train mean loss: 51.81
epoch train time: 0:00:00.171964
elapsed time: 0:00:52.797004
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:54:02.022678
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.40
 ---- batch: 020 ----
mean loss: 51.57
 ---- batch: 030 ----
mean loss: 50.37
train mean loss: 51.93
epoch train time: 0:00:00.170547
elapsed time: 0:00:52.967696
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:54:02.193358
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.73
 ---- batch: 020 ----
mean loss: 53.19
 ---- batch: 030 ----
mean loss: 50.43
train mean loss: 51.98
epoch train time: 0:00:00.168836
elapsed time: 0:00:53.136673
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:54:02.362347
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.95
 ---- batch: 020 ----
mean loss: 52.00
 ---- batch: 030 ----
mean loss: 50.24
train mean loss: 51.91
epoch train time: 0:00:00.170810
elapsed time: 0:00:53.307620
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:54:02.533296
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.09
 ---- batch: 020 ----
mean loss: 50.80
 ---- batch: 030 ----
mean loss: 51.90
train mean loss: 51.85
epoch train time: 0:00:00.172957
elapsed time: 0:00:53.480734
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:54:02.706410
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.78
 ---- batch: 020 ----
mean loss: 51.34
 ---- batch: 030 ----
mean loss: 51.33
train mean loss: 51.84
epoch train time: 0:00:00.182263
elapsed time: 0:00:53.663139
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:54:02.888815
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.73
 ---- batch: 020 ----
mean loss: 51.61
 ---- batch: 030 ----
mean loss: 50.81
train mean loss: 51.82
epoch train time: 0:00:00.172279
elapsed time: 0:00:53.835558
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:54:03.061232
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.07
 ---- batch: 020 ----
mean loss: 51.55
 ---- batch: 030 ----
mean loss: 49.80
train mean loss: 51.87
epoch train time: 0:00:00.171842
elapsed time: 0:00:54.007536
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:54:03.233227
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.39
 ---- batch: 020 ----
mean loss: 52.20
 ---- batch: 030 ----
mean loss: 51.68
train mean loss: 51.93
epoch train time: 0:00:00.169574
elapsed time: 0:00:54.177265
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:54:03.402939
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.82
 ---- batch: 020 ----
mean loss: 51.26
 ---- batch: 030 ----
mean loss: 53.46
train mean loss: 51.77
epoch train time: 0:00:00.170427
elapsed time: 0:00:54.347826
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:54:03.573500
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.19
 ---- batch: 020 ----
mean loss: 52.14
 ---- batch: 030 ----
mean loss: 50.71
train mean loss: 51.82
epoch train time: 0:00:00.171117
elapsed time: 0:00:54.519080
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:54:03.744755
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.63
 ---- batch: 020 ----
mean loss: 52.03
 ---- batch: 030 ----
mean loss: 51.36
train mean loss: 51.66
epoch train time: 0:00:00.174300
elapsed time: 0:00:54.693533
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:54:03.919208
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.85
 ---- batch: 020 ----
mean loss: 52.47
 ---- batch: 030 ----
mean loss: 52.41
train mean loss: 51.64
epoch train time: 0:00:00.171958
elapsed time: 0:00:54.865630
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:54:04.091304
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.30
 ---- batch: 020 ----
mean loss: 51.72
 ---- batch: 030 ----
mean loss: 52.71
train mean loss: 51.66
epoch train time: 0:00:00.172932
elapsed time: 0:00:55.038697
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:54:04.264370
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.66
 ---- batch: 020 ----
mean loss: 51.18
 ---- batch: 030 ----
mean loss: 50.64
train mean loss: 51.58
epoch train time: 0:00:00.173382
elapsed time: 0:00:55.212244
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:54:04.437925
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.58
 ---- batch: 020 ----
mean loss: 49.80
 ---- batch: 030 ----
mean loss: 51.35
train mean loss: 51.55
epoch train time: 0:00:00.174463
elapsed time: 0:00:55.386893
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:54:04.612567
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.55
 ---- batch: 020 ----
mean loss: 50.74
 ---- batch: 030 ----
mean loss: 48.99
train mean loss: 51.79
epoch train time: 0:00:00.182083
elapsed time: 0:00:55.569115
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:54:04.794790
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.82
 ---- batch: 020 ----
mean loss: 53.13
 ---- batch: 030 ----
mean loss: 53.16
train mean loss: 51.89
epoch train time: 0:00:00.175430
elapsed time: 0:00:55.748090
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_1/checkpoint.pth.tar
**** end time: 2019-09-27 16:54:04.973734 ****
