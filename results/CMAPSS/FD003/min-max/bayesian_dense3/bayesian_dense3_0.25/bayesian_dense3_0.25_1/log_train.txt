Namespace(batch_size=512, dataset='CMAPSS/FD003', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_1', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.25, resume=False, step_size=200, visualize_step=50)
pid: 23356
use_cuda: True
Dataset: CMAPSS/FD003
Building BayesianDense3...
Done.
**** start time: 2019-10-01 14:41:42.279512 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-10-01 14:41:42.288658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4490.61
train mean loss: 4466.37
epoch train time: 0:00:03.856479
elapsed time: 0:00:03.871750
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-10-01 14:41:46.151331
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4230.58
train mean loss: 4205.82
epoch train time: 0:00:00.168912
elapsed time: 0:00:04.040797
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-10-01 14:41:46.320364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3974.76
train mean loss: 3970.46
epoch train time: 0:00:00.165479
elapsed time: 0:00:04.206403
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-10-01 14:41:46.485958
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3759.71
train mean loss: 3770.63
epoch train time: 0:00:00.164485
elapsed time: 0:00:04.370997
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-10-01 14:41:46.650550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3598.59
train mean loss: 3568.55
epoch train time: 0:00:00.184159
elapsed time: 0:00:04.555288
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-10-01 14:41:46.834856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3412.23
train mean loss: 3416.65
epoch train time: 0:00:00.174438
elapsed time: 0:00:04.729859
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-10-01 14:41:47.009414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3271.73
train mean loss: 3278.68
epoch train time: 0:00:00.172116
elapsed time: 0:00:04.902123
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-10-01 14:41:47.181683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3155.07
train mean loss: 3145.03
epoch train time: 0:00:00.168464
elapsed time: 0:00:05.070729
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-10-01 14:41:47.350297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3048.21
train mean loss: 3036.31
epoch train time: 0:00:00.170434
elapsed time: 0:00:05.241308
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-10-01 14:41:47.520892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2931.70
train mean loss: 2940.98
epoch train time: 0:00:00.171655
elapsed time: 0:00:05.413112
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-10-01 14:41:47.692670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2843.60
train mean loss: 2849.30
epoch train time: 0:00:00.173694
elapsed time: 0:00:05.586939
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-10-01 14:41:47.866514
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2781.72
train mean loss: 2766.77
epoch train time: 0:00:00.171875
elapsed time: 0:00:05.758947
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-10-01 14:41:48.038499
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2708.57
train mean loss: 2696.98
epoch train time: 0:00:00.169499
elapsed time: 0:00:05.928556
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-10-01 14:41:48.208110
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2630.52
train mean loss: 2618.70
epoch train time: 0:00:00.169188
elapsed time: 0:00:06.097865
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-10-01 14:41:48.377421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2561.02
train mean loss: 2567.20
epoch train time: 0:00:00.170494
elapsed time: 0:00:06.268477
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-10-01 14:41:48.548032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2519.94
train mean loss: 2520.27
epoch train time: 0:00:00.177952
elapsed time: 0:00:06.446554
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-10-01 14:41:48.726109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2465.49
train mean loss: 2452.91
epoch train time: 0:00:00.178161
elapsed time: 0:00:06.624850
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-10-01 14:41:48.904409
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2414.44
train mean loss: 2414.82
epoch train time: 0:00:00.172057
elapsed time: 0:00:06.797028
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-10-01 14:41:49.076583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2367.16
train mean loss: 2361.73
epoch train time: 0:00:00.167569
elapsed time: 0:00:06.964714
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-10-01 14:41:49.244264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2331.65
train mean loss: 2320.41
epoch train time: 0:00:00.167104
elapsed time: 0:00:07.131925
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-10-01 14:41:49.411477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2271.83
train mean loss: 2285.51
epoch train time: 0:00:00.166543
elapsed time: 0:00:07.298574
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-10-01 14:41:49.578129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2243.59
train mean loss: 2235.19
epoch train time: 0:00:00.170105
elapsed time: 0:00:07.468821
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-10-01 14:41:49.748376
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2202.36
train mean loss: 2192.90
epoch train time: 0:00:00.171033
elapsed time: 0:00:07.639990
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-10-01 14:41:49.919560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2151.52
train mean loss: 2151.53
epoch train time: 0:00:00.180626
elapsed time: 0:00:07.820768
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-10-01 14:41:50.100326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2121.25
train mean loss: 2117.89
epoch train time: 0:00:00.166342
elapsed time: 0:00:07.987253
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-10-01 14:41:50.266809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2084.88
train mean loss: 2078.27
epoch train time: 0:00:00.168755
elapsed time: 0:00:08.156126
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-10-01 14:41:50.435679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2058.51
train mean loss: 2049.80
epoch train time: 0:00:00.168932
elapsed time: 0:00:08.325183
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-10-01 14:41:50.604761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2021.68
train mean loss: 2018.05
epoch train time: 0:00:00.171534
elapsed time: 0:00:08.496863
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-10-01 14:41:50.776420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1983.87
train mean loss: 1984.55
epoch train time: 0:00:00.179111
elapsed time: 0:00:08.676103
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-10-01 14:41:50.955661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1941.61
train mean loss: 1957.42
epoch train time: 0:00:00.174292
elapsed time: 0:00:08.850534
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-10-01 14:41:51.130093
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1917.45
train mean loss: 1922.45
epoch train time: 0:00:00.167874
elapsed time: 0:00:09.018526
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-10-01 14:41:51.298081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1877.28
train mean loss: 1879.17
epoch train time: 0:00:00.168477
elapsed time: 0:00:09.187118
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-10-01 14:41:51.466673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1844.59
train mean loss: 1849.40
epoch train time: 0:00:00.167745
elapsed time: 0:00:09.354987
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-10-01 14:41:51.634547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1827.16
train mean loss: 1825.55
epoch train time: 0:00:00.169881
elapsed time: 0:00:09.525006
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-10-01 14:41:51.804559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1797.27
train mean loss: 1794.91
epoch train time: 0:00:00.179262
elapsed time: 0:00:09.704389
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-10-01 14:41:51.983945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1759.36
train mean loss: 1763.34
epoch train time: 0:00:00.168729
elapsed time: 0:00:09.873248
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-10-01 14:41:52.152811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1729.85
train mean loss: 1729.42
epoch train time: 0:00:00.163763
elapsed time: 0:00:10.037137
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-10-01 14:41:52.316689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1701.22
train mean loss: 1708.49
epoch train time: 0:00:00.165505
elapsed time: 0:00:10.202751
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-10-01 14:41:52.482304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1673.01
train mean loss: 1672.46
epoch train time: 0:00:00.165317
elapsed time: 0:00:10.368212
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-10-01 14:41:52.647766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1636.46
train mean loss: 1646.91
epoch train time: 0:00:00.169558
elapsed time: 0:00:10.537901
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-10-01 14:41:52.817479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1617.04
train mean loss: 1623.30
epoch train time: 0:00:00.172785
elapsed time: 0:00:10.710837
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-10-01 14:41:52.990399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1590.15
train mean loss: 1591.49
epoch train time: 0:00:00.170501
elapsed time: 0:00:10.881514
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-10-01 14:41:53.161084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1564.73
train mean loss: 1566.63
epoch train time: 0:00:00.172810
elapsed time: 0:00:11.054510
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-10-01 14:41:53.334067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1541.00
train mean loss: 1535.77
epoch train time: 0:00:00.177096
elapsed time: 0:00:11.231730
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-10-01 14:41:53.511288
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1513.89
train mean loss: 1521.24
epoch train time: 0:00:00.185285
elapsed time: 0:00:11.417145
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-10-01 14:41:53.696723
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1490.14
train mean loss: 1495.12
epoch train time: 0:00:00.184823
elapsed time: 0:00:11.602118
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-10-01 14:41:53.881677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1473.87
train mean loss: 1472.29
epoch train time: 0:00:00.172705
elapsed time: 0:00:11.774977
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-10-01 14:41:54.054536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1453.95
train mean loss: 1448.90
epoch train time: 0:00:00.174448
elapsed time: 0:00:11.949567
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-10-01 14:41:54.229138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1427.50
train mean loss: 1433.59
epoch train time: 0:00:00.174409
elapsed time: 0:00:12.124114
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-10-01 14:41:54.403686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1408.91
train mean loss: 1404.88
epoch train time: 0:00:00.172003
elapsed time: 0:00:12.296250
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-10-01 14:41:54.575803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1378.63
train mean loss: 1384.96
epoch train time: 0:00:00.174325
elapsed time: 0:00:12.470695
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-10-01 14:41:54.750251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1365.40
train mean loss: 1366.66
epoch train time: 0:00:00.172042
elapsed time: 0:00:12.642859
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-10-01 14:41:54.922416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1354.75
train mean loss: 1348.10
epoch train time: 0:00:00.173790
elapsed time: 0:00:12.816776
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-10-01 14:41:55.096332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1332.42
train mean loss: 1329.20
epoch train time: 0:00:00.178563
elapsed time: 0:00:12.995464
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-10-01 14:41:55.275020
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1304.87
train mean loss: 1305.32
epoch train time: 0:00:00.177257
elapsed time: 0:00:13.172853
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-10-01 14:41:55.452411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1283.44
train mean loss: 1288.99
epoch train time: 0:00:00.176071
elapsed time: 0:00:13.349048
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-10-01 14:41:55.628603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1258.55
train mean loss: 1260.21
epoch train time: 0:00:00.206521
elapsed time: 0:00:13.555717
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-10-01 14:41:55.835345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1226.33
train mean loss: 1222.02
epoch train time: 0:00:00.177403
elapsed time: 0:00:13.733342
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-10-01 14:41:56.012901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1196.04
train mean loss: 1191.34
epoch train time: 0:00:00.176387
elapsed time: 0:00:13.909863
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-10-01 14:41:56.189419
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1151.01
train mean loss: 1153.77
epoch train time: 0:00:00.174202
elapsed time: 0:00:14.084184
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-10-01 14:41:56.363745
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1134.00
train mean loss: 1136.65
epoch train time: 0:00:00.172826
elapsed time: 0:00:14.257134
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-10-01 14:41:56.536688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1113.47
train mean loss: 1108.50
epoch train time: 0:00:00.179179
elapsed time: 0:00:14.436435
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-10-01 14:41:56.715993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1086.46
train mean loss: 1092.13
epoch train time: 0:00:00.179901
elapsed time: 0:00:14.616465
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-10-01 14:41:56.896045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1066.22
train mean loss: 1064.63
epoch train time: 0:00:00.180485
elapsed time: 0:00:14.797099
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-10-01 14:41:57.076654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1047.66
train mean loss: 1048.27
epoch train time: 0:00:00.177469
elapsed time: 0:00:14.974692
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-10-01 14:41:57.254257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1027.81
train mean loss: 1031.23
epoch train time: 0:00:00.174075
elapsed time: 0:00:15.148922
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-10-01 14:41:57.428493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1011.91
train mean loss: 1008.14
epoch train time: 0:00:00.174392
elapsed time: 0:00:15.323469
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-10-01 14:41:57.603025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 996.42
train mean loss: 994.19
epoch train time: 0:00:00.172862
elapsed time: 0:00:15.496480
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-10-01 14:41:57.776049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 971.29
train mean loss: 970.97
epoch train time: 0:00:00.188399
elapsed time: 0:00:15.685037
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-10-01 14:41:57.964614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 960.34
train mean loss: 955.77
epoch train time: 0:00:00.172891
elapsed time: 0:00:15.858069
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-10-01 14:41:58.137626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 938.83
train mean loss: 938.12
epoch train time: 0:00:00.177673
elapsed time: 0:00:16.035879
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-10-01 14:41:58.315438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 917.08
train mean loss: 922.31
epoch train time: 0:00:00.176281
elapsed time: 0:00:16.212305
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-10-01 14:41:58.491894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 900.78
train mean loss: 899.74
epoch train time: 0:00:00.175622
elapsed time: 0:00:16.388098
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-10-01 14:41:58.667655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 888.08
train mean loss: 888.15
epoch train time: 0:00:00.177967
elapsed time: 0:00:16.566189
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-10-01 14:41:58.845743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.03
train mean loss: 871.59
epoch train time: 0:00:00.174753
elapsed time: 0:00:16.741062
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-10-01 14:41:59.020616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 855.93
train mean loss: 854.92
epoch train time: 0:00:00.170084
elapsed time: 0:00:16.911274
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-10-01 14:41:59.190827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 843.49
train mean loss: 840.41
epoch train time: 0:00:00.173443
elapsed time: 0:00:17.084847
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-10-01 14:41:59.364404
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 825.38
train mean loss: 825.45
epoch train time: 0:00:00.170618
elapsed time: 0:00:17.255583
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-10-01 14:41:59.535139
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 812.84
train mean loss: 813.37
epoch train time: 0:00:00.170416
elapsed time: 0:00:17.426123
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-10-01 14:41:59.705678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 801.87
train mean loss: 793.68
epoch train time: 0:00:00.180223
elapsed time: 0:00:17.606467
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-10-01 14:41:59.886022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 783.50
train mean loss: 784.28
epoch train time: 0:00:00.172058
elapsed time: 0:00:17.778647
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-10-01 14:42:00.058218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 769.97
train mean loss: 768.28
epoch train time: 0:00:00.168817
elapsed time: 0:00:17.947592
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-10-01 14:42:00.227143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 755.64
train mean loss: 753.11
epoch train time: 0:00:00.173530
elapsed time: 0:00:18.121254
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-10-01 14:42:00.400807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 741.97
train mean loss: 739.60
epoch train time: 0:00:00.170309
elapsed time: 0:00:18.291675
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-10-01 14:42:00.571229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 722.88
train mean loss: 728.72
epoch train time: 0:00:00.189875
elapsed time: 0:00:18.481681
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-10-01 14:42:00.761239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 714.35
train mean loss: 716.24
epoch train time: 0:00:00.181496
elapsed time: 0:00:18.663334
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-10-01 14:42:00.942888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 698.82
train mean loss: 701.99
epoch train time: 0:00:00.169502
elapsed time: 0:00:18.832951
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-10-01 14:42:01.112505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 687.35
train mean loss: 682.61
epoch train time: 0:00:00.166465
elapsed time: 0:00:18.999528
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-10-01 14:42:01.279083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 675.71
train mean loss: 675.70
epoch train time: 0:00:00.172785
elapsed time: 0:00:19.172464
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-10-01 14:42:01.452037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 660.14
train mean loss: 662.74
epoch train time: 0:00:00.168432
elapsed time: 0:00:19.341032
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-10-01 14:42:01.620594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 654.26
train mean loss: 647.00
epoch train time: 0:00:00.182801
elapsed time: 0:00:19.523975
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-10-01 14:42:01.803540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 638.98
train mean loss: 639.96
epoch train time: 0:00:00.179233
elapsed time: 0:00:19.703344
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-10-01 14:42:01.982903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 627.77
train mean loss: 625.65
epoch train time: 0:00:00.172137
elapsed time: 0:00:19.875607
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-10-01 14:42:02.155163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 620.87
train mean loss: 617.85
epoch train time: 0:00:00.170213
elapsed time: 0:00:20.045938
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-10-01 14:42:02.325493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 605.27
train mean loss: 605.60
epoch train time: 0:00:00.176009
elapsed time: 0:00:20.222085
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-10-01 14:42:02.501644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 600.76
train mean loss: 594.77
epoch train time: 0:00:00.174880
elapsed time: 0:00:20.397110
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-10-01 14:42:02.676667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 581.49
train mean loss: 581.24
epoch train time: 0:00:00.185591
elapsed time: 0:00:20.582833
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-10-01 14:42:02.862395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 568.30
train mean loss: 574.82
epoch train time: 0:00:00.171669
elapsed time: 0:00:20.754632
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-10-01 14:42:03.034206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 561.60
train mean loss: 562.86
epoch train time: 0:00:00.171809
elapsed time: 0:00:20.926580
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-10-01 14:42:03.206138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.57
train mean loss: 548.84
epoch train time: 0:00:00.170956
elapsed time: 0:00:21.097662
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-10-01 14:42:03.377234
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 543.94
train mean loss: 543.42
epoch train time: 0:00:00.176489
elapsed time: 0:00:21.274341
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-10-01 14:42:03.553903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 527.62
train mean loss: 529.13
epoch train time: 0:00:00.173031
elapsed time: 0:00:21.447505
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-10-01 14:42:03.727064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 521.88
train mean loss: 520.27
epoch train time: 0:00:00.175430
elapsed time: 0:00:21.623057
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-10-01 14:42:03.902609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 506.30
train mean loss: 509.10
epoch train time: 0:00:00.171821
elapsed time: 0:00:21.794994
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-10-01 14:42:04.074550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 500.10
train mean loss: 497.86
epoch train time: 0:00:00.170367
elapsed time: 0:00:21.965479
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-10-01 14:42:04.245033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 490.90
train mean loss: 489.90
epoch train time: 0:00:00.170664
elapsed time: 0:00:22.136268
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-10-01 14:42:04.415828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 481.80
train mean loss: 481.31
epoch train time: 0:00:00.173514
elapsed time: 0:00:22.309936
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-10-01 14:42:04.589485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 472.17
train mean loss: 472.75
epoch train time: 0:00:00.172954
elapsed time: 0:00:22.483002
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-10-01 14:42:04.762557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 465.76
train mean loss: 464.21
epoch train time: 0:00:00.171983
elapsed time: 0:00:22.655103
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-10-01 14:42:04.934658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 456.89
train mean loss: 454.66
epoch train time: 0:00:00.164795
elapsed time: 0:00:22.820013
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-10-01 14:42:05.099565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 448.92
train mean loss: 448.68
epoch train time: 0:00:00.162501
elapsed time: 0:00:22.982628
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-10-01 14:42:05.262180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 433.00
train mean loss: 439.27
epoch train time: 0:00:00.162151
elapsed time: 0:00:23.144939
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-10-01 14:42:05.424512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 432.12
train mean loss: 431.74
epoch train time: 0:00:00.169614
elapsed time: 0:00:23.314696
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-10-01 14:42:05.594261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 425.87
train mean loss: 424.05
epoch train time: 0:00:00.165242
elapsed time: 0:00:23.480063
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-10-01 14:42:05.759618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 416.35
train mean loss: 416.36
epoch train time: 0:00:00.181348
elapsed time: 0:00:23.661635
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-10-01 14:42:05.941207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 408.60
train mean loss: 407.24
epoch train time: 0:00:00.169618
elapsed time: 0:00:23.831404
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-10-01 14:42:06.110960
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 402.82
train mean loss: 399.04
epoch train time: 0:00:00.168534
elapsed time: 0:00:24.000051
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-10-01 14:42:06.279632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 395.47
train mean loss: 394.62
epoch train time: 0:00:00.176395
elapsed time: 0:00:24.176614
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-10-01 14:42:06.456205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 387.00
train mean loss: 387.11
epoch train time: 0:00:00.177973
elapsed time: 0:00:24.354764
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-10-01 14:42:06.634326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 379.90
train mean loss: 376.85
epoch train time: 0:00:00.182914
elapsed time: 0:00:24.537822
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-10-01 14:42:06.817381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.04
train mean loss: 369.21
epoch train time: 0:00:00.172277
elapsed time: 0:00:24.710239
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-10-01 14:42:06.989835
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.69
train mean loss: 364.54
epoch train time: 0:00:00.168816
elapsed time: 0:00:24.879219
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-10-01 14:42:07.158790
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 360.83
train mean loss: 358.10
epoch train time: 0:00:00.166730
elapsed time: 0:00:25.046077
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-10-01 14:42:07.325639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 354.93
train mean loss: 355.57
epoch train time: 0:00:00.173176
elapsed time: 0:00:25.219381
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-10-01 14:42:07.498938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.36
train mean loss: 351.71
epoch train time: 0:00:00.174056
elapsed time: 0:00:25.393561
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-10-01 14:42:07.673118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.36
train mean loss: 340.57
epoch train time: 0:00:00.173302
elapsed time: 0:00:25.566984
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-10-01 14:42:07.846548
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 336.45
train mean loss: 335.69
epoch train time: 0:00:00.169715
elapsed time: 0:00:25.736857
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-10-01 14:42:08.016406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.45
train mean loss: 330.00
epoch train time: 0:00:00.168550
elapsed time: 0:00:25.905520
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-10-01 14:42:08.185073
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.61
train mean loss: 325.21
epoch train time: 0:00:00.167421
elapsed time: 0:00:26.073084
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-10-01 14:42:08.352639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.92
train mean loss: 317.62
epoch train time: 0:00:00.169798
elapsed time: 0:00:26.243019
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-10-01 14:42:08.522578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 310.51
train mean loss: 312.61
epoch train time: 0:00:00.174206
elapsed time: 0:00:26.417397
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-10-01 14:42:08.696983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.00
train mean loss: 310.45
epoch train time: 0:00:00.170129
elapsed time: 0:00:26.587679
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-10-01 14:42:08.867236
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 304.20
train mean loss: 301.85
epoch train time: 0:00:00.165291
elapsed time: 0:00:26.753092
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-10-01 14:42:09.032659
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.35
train mean loss: 298.21
epoch train time: 0:00:00.166151
elapsed time: 0:00:26.919374
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-10-01 14:42:09.198938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.38
train mean loss: 292.61
epoch train time: 0:00:00.170340
elapsed time: 0:00:27.089844
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-10-01 14:42:09.369399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.20
train mean loss: 288.32
epoch train time: 0:00:00.168872
elapsed time: 0:00:27.258859
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-10-01 14:42:09.538429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.61
train mean loss: 282.43
epoch train time: 0:00:00.170723
elapsed time: 0:00:27.429768
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-10-01 14:42:09.709338
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.79
train mean loss: 281.07
epoch train time: 0:00:00.176743
elapsed time: 0:00:27.606650
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-10-01 14:42:09.886205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.51
train mean loss: 273.66
epoch train time: 0:00:00.169111
elapsed time: 0:00:27.775880
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-10-01 14:42:10.055438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.87
train mean loss: 265.76
epoch train time: 0:00:00.168535
elapsed time: 0:00:27.944531
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-10-01 14:42:10.224086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.89
train mean loss: 265.63
epoch train time: 0:00:00.168106
elapsed time: 0:00:28.112751
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-10-01 14:42:10.392304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.83
train mean loss: 259.99
epoch train time: 0:00:00.166825
elapsed time: 0:00:28.279687
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-10-01 14:42:10.559239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.18
train mean loss: 255.06
epoch train time: 0:00:00.177193
elapsed time: 0:00:28.457016
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-10-01 14:42:10.736592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.99
train mean loss: 252.63
epoch train time: 0:00:00.165387
elapsed time: 0:00:28.622558
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-10-01 14:42:10.902111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.87
train mean loss: 248.01
epoch train time: 0:00:00.163640
elapsed time: 0:00:28.786336
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-10-01 14:42:11.065891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.08
train mean loss: 239.96
epoch train time: 0:00:00.163117
elapsed time: 0:00:28.949579
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-10-01 14:42:11.229161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.69
train mean loss: 240.03
epoch train time: 0:00:00.163811
elapsed time: 0:00:29.113529
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-10-01 14:42:11.393081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.29
train mean loss: 237.16
epoch train time: 0:00:00.162720
elapsed time: 0:00:29.276416
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-10-01 14:42:11.555985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.11
train mean loss: 232.46
epoch train time: 0:00:00.174037
elapsed time: 0:00:29.450606
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-10-01 14:42:11.730156
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.54
train mean loss: 230.75
epoch train time: 0:00:00.186148
elapsed time: 0:00:29.636869
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-10-01 14:42:11.916423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.55
train mean loss: 227.04
epoch train time: 0:00:00.170101
elapsed time: 0:00:29.807093
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-10-01 14:42:12.086651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.60
train mean loss: 220.85
epoch train time: 0:00:00.168214
elapsed time: 0:00:29.975453
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-10-01 14:42:12.255007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.43
train mean loss: 220.71
epoch train time: 0:00:00.168927
elapsed time: 0:00:30.144497
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-10-01 14:42:12.424048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.10
train mean loss: 216.11
epoch train time: 0:00:00.169929
elapsed time: 0:00:30.314544
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-10-01 14:42:12.594112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.55
train mean loss: 213.65
epoch train time: 0:00:00.174610
elapsed time: 0:00:30.489322
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-10-01 14:42:12.768911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.67
train mean loss: 209.98
epoch train time: 0:00:00.168706
elapsed time: 0:00:30.658175
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-10-01 14:42:12.937730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.07
train mean loss: 207.54
epoch train time: 0:00:00.164634
elapsed time: 0:00:30.822933
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-10-01 14:42:13.102486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.14
train mean loss: 204.98
epoch train time: 0:00:00.165440
elapsed time: 0:00:30.988485
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-10-01 14:42:13.268038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 200.40
train mean loss: 199.94
epoch train time: 0:00:00.166267
elapsed time: 0:00:31.154859
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-10-01 14:42:13.434422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.15
train mean loss: 196.88
epoch train time: 0:00:00.164696
elapsed time: 0:00:31.319671
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-10-01 14:42:13.599225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.37
train mean loss: 195.54
epoch train time: 0:00:00.189558
elapsed time: 0:00:31.509350
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-10-01 14:42:13.788917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.17
train mean loss: 190.88
epoch train time: 0:00:00.173360
elapsed time: 0:00:31.682841
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-10-01 14:42:13.962395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.82
train mean loss: 187.44
epoch train time: 0:00:00.172049
elapsed time: 0:00:31.855006
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-10-01 14:42:14.134560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.69
train mean loss: 187.65
epoch train time: 0:00:00.171485
elapsed time: 0:00:32.026609
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-10-01 14:42:14.306165
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.38
train mean loss: 184.18
epoch train time: 0:00:00.172201
elapsed time: 0:00:32.198932
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-10-01 14:42:14.478490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.38
train mean loss: 179.82
epoch train time: 0:00:00.171925
elapsed time: 0:00:32.370984
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-10-01 14:42:14.650542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.72
train mean loss: 180.07
epoch train time: 0:00:00.176466
elapsed time: 0:00:32.547596
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-10-01 14:42:14.827150
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.61
train mean loss: 177.29
epoch train time: 0:00:00.176026
elapsed time: 0:00:32.723755
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-10-01 14:42:15.003314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.12
train mean loss: 173.25
epoch train time: 0:00:00.173230
elapsed time: 0:00:32.897109
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-10-01 14:42:15.176667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.69
train mean loss: 172.76
epoch train time: 0:00:00.171439
elapsed time: 0:00:33.068664
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-10-01 14:42:15.348221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.32
train mean loss: 170.51
epoch train time: 0:00:00.173518
elapsed time: 0:00:33.242357
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-10-01 14:42:15.521929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.06
train mean loss: 167.58
epoch train time: 0:00:00.185550
elapsed time: 0:00:33.428042
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-10-01 14:42:15.707598
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.46
train mean loss: 166.05
epoch train time: 0:00:00.185913
elapsed time: 0:00:33.614082
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-10-01 14:42:15.893675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.03
train mean loss: 162.68
epoch train time: 0:00:00.168024
elapsed time: 0:00:33.782297
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-10-01 14:42:16.061849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.50
train mean loss: 161.49
epoch train time: 0:00:00.166112
elapsed time: 0:00:33.948517
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-10-01 14:42:16.228070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.17
train mean loss: 158.66
epoch train time: 0:00:00.165994
elapsed time: 0:00:34.114631
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-10-01 14:42:16.394205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.11
train mean loss: 156.62
epoch train time: 0:00:00.168439
elapsed time: 0:00:34.283252
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-10-01 14:42:16.562822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.61
train mean loss: 153.92
epoch train time: 0:00:00.174978
elapsed time: 0:00:34.458368
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-10-01 14:42:16.737923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.47
train mean loss: 152.21
epoch train time: 0:00:00.174488
elapsed time: 0:00:34.633031
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-10-01 14:42:16.912589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.45
train mean loss: 150.33
epoch train time: 0:00:00.172982
elapsed time: 0:00:34.806134
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-10-01 14:42:17.085688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.86
train mean loss: 148.67
epoch train time: 0:00:00.171441
elapsed time: 0:00:34.977730
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-10-01 14:42:17.257318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.90
train mean loss: 146.24
epoch train time: 0:00:00.172123
elapsed time: 0:00:35.150041
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-10-01 14:42:17.429631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.21
train mean loss: 147.53
epoch train time: 0:00:00.173541
elapsed time: 0:00:35.323754
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-10-01 14:42:17.603312
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.99
train mean loss: 144.44
epoch train time: 0:00:00.172739
elapsed time: 0:00:35.496622
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-10-01 14:42:17.776179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.28
train mean loss: 143.85
epoch train time: 0:00:00.176460
elapsed time: 0:00:35.673223
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-10-01 14:42:17.952778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.15
train mean loss: 142.55
epoch train time: 0:00:00.166806
elapsed time: 0:00:35.840140
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-10-01 14:42:18.119693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.38
train mean loss: 139.17
epoch train time: 0:00:00.164780
elapsed time: 0:00:36.005031
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-10-01 14:42:18.284583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.95
train mean loss: 137.47
epoch train time: 0:00:00.166742
elapsed time: 0:00:36.171890
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-10-01 14:42:18.451445
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.62
train mean loss: 134.08
epoch train time: 0:00:00.166793
elapsed time: 0:00:36.338801
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-10-01 14:42:18.618355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.18
train mean loss: 135.27
epoch train time: 0:00:00.170118
elapsed time: 0:00:36.509054
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-10-01 14:42:18.788630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.54
train mean loss: 133.41
epoch train time: 0:00:00.167396
elapsed time: 0:00:36.676593
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-10-01 14:42:18.956147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.52
train mean loss: 132.41
epoch train time: 0:00:00.165790
elapsed time: 0:00:36.842499
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-10-01 14:42:19.122072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.77
train mean loss: 129.88
epoch train time: 0:00:00.163844
elapsed time: 0:00:37.006485
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-10-01 14:42:19.286043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.10
train mean loss: 130.40
epoch train time: 0:00:00.163162
elapsed time: 0:00:37.169760
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-10-01 14:42:19.449313
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.61
train mean loss: 128.75
epoch train time: 0:00:00.168927
elapsed time: 0:00:37.338804
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-10-01 14:42:19.618360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.60
train mean loss: 127.22
epoch train time: 0:00:00.177839
elapsed time: 0:00:37.516768
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-10-01 14:42:19.796327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.65
train mean loss: 122.46
epoch train time: 0:00:00.174144
elapsed time: 0:00:37.691042
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-10-01 14:42:19.970602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.49
train mean loss: 124.00
epoch train time: 0:00:00.174033
elapsed time: 0:00:37.865202
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-10-01 14:42:20.144761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.36
train mean loss: 121.51
epoch train time: 0:00:00.169472
elapsed time: 0:00:38.034813
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-10-01 14:42:20.314371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.65
train mean loss: 122.90
epoch train time: 0:00:00.169962
elapsed time: 0:00:38.204900
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-10-01 14:42:20.484456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.04
train mean loss: 121.00
epoch train time: 0:00:00.174174
elapsed time: 0:00:38.379209
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-10-01 14:42:20.658782
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 119.22
train mean loss: 118.18
epoch train time: 0:00:00.177127
elapsed time: 0:00:38.556487
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-10-01 14:42:20.836038
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 118.81
train mean loss: 119.31
epoch train time: 0:00:00.177786
elapsed time: 0:00:38.734425
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-10-01 14:42:21.013988
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 120.31
train mean loss: 119.99
epoch train time: 0:00:00.171984
elapsed time: 0:00:38.906536
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-10-01 14:42:21.186090
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 118.83
train mean loss: 119.79
epoch train time: 0:00:00.170692
elapsed time: 0:00:39.077350
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-10-01 14:42:21.356908
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 117.97
train mean loss: 117.71
epoch train time: 0:00:00.171452
elapsed time: 0:00:39.248936
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-10-01 14:42:21.528488
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 118.86
train mean loss: 118.50
epoch train time: 0:00:00.172029
elapsed time: 0:00:39.421111
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-10-01 14:42:21.700676
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 118.64
train mean loss: 118.63
epoch train time: 0:00:00.171892
elapsed time: 0:00:39.593150
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-10-01 14:42:21.872731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.30
train mean loss: 117.01
epoch train time: 0:00:00.173825
elapsed time: 0:00:39.767143
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-10-01 14:42:22.046701
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.75
train mean loss: 115.80
epoch train time: 0:00:00.171192
elapsed time: 0:00:39.938469
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-10-01 14:42:22.218044
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 117.39
train mean loss: 116.37
epoch train time: 0:00:00.169526
elapsed time: 0:00:40.108133
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-10-01 14:42:22.387715
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 120.05
train mean loss: 120.79
epoch train time: 0:00:00.169188
elapsed time: 0:00:40.277463
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-10-01 14:42:22.557015
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 117.01
train mean loss: 116.86
epoch train time: 0:00:00.175432
elapsed time: 0:00:40.453030
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-10-01 14:42:22.732612
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.87
train mean loss: 116.56
epoch train time: 0:00:00.187104
elapsed time: 0:00:40.640289
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-10-01 14:42:22.919846
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.78
train mean loss: 117.02
epoch train time: 0:00:00.177416
elapsed time: 0:00:40.817832
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-10-01 14:42:23.097388
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 117.95
train mean loss: 117.49
epoch train time: 0:00:00.170290
elapsed time: 0:00:40.988249
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-10-01 14:42:23.267805
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 114.53
train mean loss: 114.60
epoch train time: 0:00:00.170281
elapsed time: 0:00:41.158655
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-10-01 14:42:23.438213
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.98
train mean loss: 117.65
epoch train time: 0:00:00.171006
elapsed time: 0:00:41.329781
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-10-01 14:42:23.609345
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 113.61
train mean loss: 115.42
epoch train time: 0:00:00.171324
elapsed time: 0:00:41.501247
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-10-01 14:42:23.780814
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 117.64
train mean loss: 117.21
epoch train time: 0:00:00.172338
elapsed time: 0:00:41.673717
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-10-01 14:42:23.953272
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.04
train mean loss: 115.52
epoch train time: 0:00:00.172831
elapsed time: 0:00:41.846675
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-10-01 14:42:24.126234
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.53
train mean loss: 116.84
epoch train time: 0:00:00.173080
elapsed time: 0:00:42.019876
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-10-01 14:42:24.299429
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.75
train mean loss: 115.44
epoch train time: 0:00:00.172727
elapsed time: 0:00:42.192724
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-10-01 14:42:24.472297
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 117.77
train mean loss: 116.80
epoch train time: 0:00:00.173875
elapsed time: 0:00:42.366740
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-10-01 14:42:24.646306
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 117.94
train mean loss: 117.01
epoch train time: 0:00:00.176322
elapsed time: 0:00:42.543196
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-10-01 14:42:24.822765
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.44
train mean loss: 114.10
epoch train time: 0:00:00.178248
elapsed time: 0:00:42.721592
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-10-01 14:42:25.001148
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.56
train mean loss: 116.48
epoch train time: 0:00:00.171904
elapsed time: 0:00:42.893620
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-10-01 14:42:25.173209
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.11
train mean loss: 115.68
epoch train time: 0:00:00.169702
elapsed time: 0:00:43.063483
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-10-01 14:42:25.343052
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 116.32
train mean loss: 115.70
epoch train time: 0:00:00.170084
elapsed time: 0:00:43.233702
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-10-01 14:42:25.513266
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.31
train mean loss: 115.13
epoch train time: 0:00:00.172046
elapsed time: 0:00:43.405881
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-10-01 14:42:25.685438
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.25
train mean loss: 116.37
epoch train time: 0:00:00.174173
elapsed time: 0:00:43.580186
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-10-01 14:42:25.859757
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.42
train mean loss: 114.46
epoch train time: 0:00:00.186830
elapsed time: 0:00:43.767153
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-10-01 14:42:26.046709
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.51
train mean loss: 114.87
epoch train time: 0:00:00.175225
elapsed time: 0:00:43.942510
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-10-01 14:42:26.222071
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.70
train mean loss: 115.98
epoch train time: 0:00:00.173478
elapsed time: 0:00:44.116146
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-10-01 14:42:26.395694
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 113.67
train mean loss: 113.83
epoch train time: 0:00:00.174058
elapsed time: 0:00:44.290352
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-10-01 14:42:26.569909
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 113.49
train mean loss: 113.03
epoch train time: 0:00:00.176228
elapsed time: 0:00:44.466702
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-10-01 14:42:26.746255
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 113.94
train mean loss: 113.60
epoch train time: 0:00:00.185976
elapsed time: 0:00:44.652804
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-10-01 14:42:26.932360
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 114.23
train mean loss: 112.83
epoch train time: 0:00:00.171896
elapsed time: 0:00:44.824827
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-10-01 14:42:27.104384
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 110.69
train mean loss: 110.89
epoch train time: 0:00:00.173075
elapsed time: 0:00:44.998026
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-10-01 14:42:27.277581
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 114.75
train mean loss: 112.93
epoch train time: 0:00:00.171056
elapsed time: 0:00:45.169225
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-10-01 14:42:27.448790
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 114.04
train mean loss: 114.75
epoch train time: 0:00:00.170780
elapsed time: 0:00:45.340139
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-10-01 14:42:27.619695
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 114.65
train mean loss: 114.11
epoch train time: 0:00:00.174411
elapsed time: 0:00:45.514686
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-10-01 14:42:27.794242
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 115.68
train mean loss: 115.75
epoch train time: 0:00:00.173211
elapsed time: 0:00:45.688039
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-10-01 14:42:27.967595
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 111.65
train mean loss: 110.66
epoch train time: 0:00:00.171674
elapsed time: 0:00:45.859838
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-10-01 14:42:28.139394
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 114.11
train mean loss: 113.88
epoch train time: 0:00:00.174451
elapsed time: 0:00:46.034419
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-10-01 14:42:28.313974
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 113.07
train mean loss: 113.30
epoch train time: 0:00:00.172567
elapsed time: 0:00:46.207111
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-10-01 14:42:28.486666
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 114.65
train mean loss: 113.83
epoch train time: 0:00:00.172252
elapsed time: 0:00:46.379486
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-10-01 14:42:28.659059
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 112.34
train mean loss: 112.42
epoch train time: 0:00:00.177161
elapsed time: 0:00:46.556793
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-10-01 14:42:28.836351
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 113.96
train mean loss: 114.75
epoch train time: 0:00:00.173520
elapsed time: 0:00:46.730446
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-10-01 14:42:29.010004
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 113.03
train mean loss: 112.86
epoch train time: 0:00:00.174625
elapsed time: 0:00:46.912711
checkpoint saved in file: log/CMAPSS/FD003/min-max/bayesian_dense3/bayesian_dense3_0.25/bayesian_dense3_0.25_1/checkpoint.pth.tar
**** end time: 2019-10-01 14:42:29.192240 ****
