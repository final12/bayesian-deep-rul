Namespace(batch_size=512, dataset='CMAPSS/FD004', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD004/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_6', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=0.125, resume=False, step_size=200, visualize_step=50)
pid: 11669
use_cuda: True
Dataset: CMAPSS/FD004
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-26 19:50:38.773509 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 16, 24]             200
           Sigmoid-2           [-1, 10, 16, 24]               0
    BayesianConv2d-3           [-1, 10, 15, 24]           2,000
           Sigmoid-4           [-1, 10, 15, 24]               0
    BayesianConv2d-5           [-1, 10, 16, 24]           2,000
           Sigmoid-6           [-1, 10, 16, 24]               0
    BayesianConv2d-7           [-1, 10, 15, 24]           2,000
           Sigmoid-8           [-1, 10, 15, 24]               0
    BayesianConv2d-9            [-1, 1, 15, 24]              60
         Softplus-10            [-1, 1, 15, 24]               0
          Flatten-11                  [-1, 360]               0
   BayesianLinear-12                  [-1, 100]          72,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 78,460
Trainable params: 78,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-26 19:50:38.791948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3458.86
train mean loss: 2798.17
epoch train time: 0:00:05.740700
elapsed time: 0:00:05.766912
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-26 19:50:44.540469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1443.51
train mean loss: 1362.82
epoch train time: 0:00:01.988123
elapsed time: 0:00:07.755653
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-26 19:50:46.529300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1196.08
train mean loss: 1164.74
epoch train time: 0:00:01.977306
elapsed time: 0:00:09.733573
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-26 19:50:48.507206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1117.14
train mean loss: 1094.51
epoch train time: 0:00:01.970587
elapsed time: 0:00:11.704783
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-26 19:50:50.478422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1043.91
train mean loss: 1056.87
epoch train time: 0:00:01.998792
elapsed time: 0:00:13.704224
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-26 19:50:52.477869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1046.42
train mean loss: 1062.24
epoch train time: 0:00:01.977556
elapsed time: 0:00:15.682440
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-26 19:50:54.456106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1023.89
train mean loss: 1022.72
epoch train time: 0:00:01.978346
elapsed time: 0:00:17.661413
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-26 19:50:56.435071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1015.51
train mean loss: 1012.90
epoch train time: 0:00:01.980399
elapsed time: 0:00:19.642560
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-26 19:50:58.416201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1013.56
train mean loss: 981.08
epoch train time: 0:00:01.985246
elapsed time: 0:00:21.628475
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-26 19:51:00.402138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 965.89
train mean loss: 967.54
epoch train time: 0:00:01.999651
elapsed time: 0:00:23.628864
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-26 19:51:02.402560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 980.16
train mean loss: 987.06
epoch train time: 0:00:01.998610
elapsed time: 0:00:25.628205
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-26 19:51:04.401872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 983.95
train mean loss: 979.10
epoch train time: 0:00:01.991956
elapsed time: 0:00:27.620926
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-26 19:51:06.394573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 952.67
train mean loss: 948.65
epoch train time: 0:00:01.981874
elapsed time: 0:00:29.603418
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-26 19:51:08.377067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 953.57
train mean loss: 949.57
epoch train time: 0:00:01.975906
elapsed time: 0:00:31.579972
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-26 19:51:10.353623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 953.97
train mean loss: 962.47
epoch train time: 0:00:01.986579
elapsed time: 0:00:33.567235
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-26 19:51:12.340884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 948.42
train mean loss: 955.61
epoch train time: 0:00:01.984247
elapsed time: 0:00:35.552149
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-26 19:51:14.325811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.56
train mean loss: 946.93
epoch train time: 0:00:01.990215
elapsed time: 0:00:37.543195
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-26 19:51:16.316853
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 931.96
train mean loss: 926.26
epoch train time: 0:00:01.989566
elapsed time: 0:00:39.533417
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-26 19:51:18.307068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.99
train mean loss: 927.23
epoch train time: 0:00:01.996032
elapsed time: 0:00:41.530103
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-26 19:51:20.303763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 945.69
train mean loss: 934.89
epoch train time: 0:00:01.982725
elapsed time: 0:00:43.513463
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-26 19:51:22.287129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 924.74
train mean loss: 930.80
epoch train time: 0:00:01.989938
elapsed time: 0:00:45.504240
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-26 19:51:24.277911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.61
train mean loss: 920.89
epoch train time: 0:00:01.990420
elapsed time: 0:00:47.495340
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-26 19:51:26.269011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 927.83
train mean loss: 911.45
epoch train time: 0:00:01.988326
elapsed time: 0:00:49.484665
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-26 19:51:28.258329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 924.02
train mean loss: 939.22
epoch train time: 0:00:01.982470
elapsed time: 0:00:51.467824
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-26 19:51:30.241474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 927.16
train mean loss: 909.03
epoch train time: 0:00:01.985650
elapsed time: 0:00:53.454120
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-26 19:51:32.227788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 911.89
train mean loss: 916.82
epoch train time: 0:00:01.971357
elapsed time: 0:00:55.426141
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-26 19:51:34.199777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 909.75
train mean loss: 924.72
epoch train time: 0:00:01.976438
elapsed time: 0:00:57.403201
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-26 19:51:36.176849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 913.41
train mean loss: 920.56
epoch train time: 0:00:01.979080
elapsed time: 0:00:59.382913
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-26 19:51:38.156560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 911.41
train mean loss: 917.84
epoch train time: 0:00:01.975951
elapsed time: 0:01:01.359496
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-26 19:51:40.133168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 909.22
train mean loss: 916.88
epoch train time: 0:00:01.973273
elapsed time: 0:01:03.333434
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-26 19:51:42.107089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.88
train mean loss: 919.54
epoch train time: 0:00:01.990028
elapsed time: 0:01:05.324196
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-26 19:51:44.097855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 907.25
train mean loss: 909.35
epoch train time: 0:00:01.988132
elapsed time: 0:01:07.312972
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-26 19:51:46.086616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 901.90
train mean loss: 909.75
epoch train time: 0:00:01.987705
elapsed time: 0:01:09.301288
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-26 19:51:48.074928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 920.28
train mean loss: 900.97
epoch train time: 0:00:01.984146
elapsed time: 0:01:11.286083
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-26 19:51:50.059757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 914.36
train mean loss: 909.76
epoch train time: 0:00:01.983960
elapsed time: 0:01:13.270821
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-26 19:51:52.044464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 920.56
train mean loss: 912.40
epoch train time: 0:00:01.982038
elapsed time: 0:01:15.253524
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-26 19:51:54.027166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 896.27
train mean loss: 915.73
epoch train time: 0:00:01.986058
elapsed time: 0:01:17.240351
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-26 19:51:56.014010
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 898.97
train mean loss: 907.12
epoch train time: 0:00:01.985664
elapsed time: 0:01:19.226692
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-26 19:51:58.000335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 901.48
train mean loss: 884.85
epoch train time: 0:00:02.002946
elapsed time: 0:01:21.230370
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-26 19:52:00.004051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 894.76
train mean loss: 905.95
epoch train time: 0:00:01.989234
elapsed time: 0:01:23.220308
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-26 19:52:01.993954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 894.86
train mean loss: 900.88
epoch train time: 0:00:01.982163
elapsed time: 0:01:25.203108
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-26 19:52:03.976750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 893.19
train mean loss: 888.88
epoch train time: 0:00:01.991441
elapsed time: 0:01:27.195264
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-26 19:52:05.968922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 906.78
train mean loss: 914.03
epoch train time: 0:00:01.986685
elapsed time: 0:01:29.182623
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-26 19:52:07.956266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 878.14
train mean loss: 900.48
epoch train time: 0:00:01.984216
elapsed time: 0:01:31.167525
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-26 19:52:09.941164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 889.10
train mean loss: 878.88
epoch train time: 0:00:01.988645
elapsed time: 0:01:33.156784
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-26 19:52:11.930431
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 897.49
train mean loss: 897.13
epoch train time: 0:00:01.985926
elapsed time: 0:01:35.143360
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-26 19:52:13.917066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 887.95
train mean loss: 882.88
epoch train time: 0:00:01.981558
elapsed time: 0:01:37.125682
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-26 19:52:15.899358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 882.77
train mean loss: 889.55
epoch train time: 0:00:01.992499
elapsed time: 0:01:39.118861
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-26 19:52:17.892557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 886.20
train mean loss: 896.58
epoch train time: 0:00:01.993874
elapsed time: 0:01:41.113464
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-26 19:52:19.887115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 896.32
train mean loss: 878.82
epoch train time: 0:00:01.990339
elapsed time: 0:01:43.104461
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-26 19:52:21.878106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 891.19
train mean loss: 894.53
epoch train time: 0:00:01.987408
elapsed time: 0:01:45.092539
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-26 19:52:23.866191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 881.80
train mean loss: 897.76
epoch train time: 0:00:01.994108
elapsed time: 0:01:47.087377
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-26 19:52:25.861042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 882.12
train mean loss: 888.67
epoch train time: 0:00:01.991250
elapsed time: 0:01:49.079304
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-26 19:52:27.852950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 886.90
train mean loss: 877.73
epoch train time: 0:00:01.989227
elapsed time: 0:01:51.069188
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-26 19:52:29.842850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 896.33
train mean loss: 880.20
epoch train time: 0:00:01.979029
elapsed time: 0:01:53.048923
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-26 19:52:31.822561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 880.71
train mean loss: 879.75
epoch train time: 0:00:02.015770
elapsed time: 0:01:55.065337
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-26 19:52:33.838967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 869.95
train mean loss: 876.29
epoch train time: 0:00:01.986372
elapsed time: 0:01:57.052473
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-26 19:52:35.826157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 860.95
train mean loss: 863.07
epoch train time: 0:00:01.989179
elapsed time: 0:01:59.042383
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-26 19:52:37.816070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.69
train mean loss: 866.16
epoch train time: 0:00:02.015682
elapsed time: 0:02:01.058792
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-26 19:52:39.832530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 875.74
train mean loss: 881.52
epoch train time: 0:00:02.013023
elapsed time: 0:02:03.072619
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-26 19:52:41.846280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 869.55
train mean loss: 865.28
epoch train time: 0:00:02.002543
elapsed time: 0:02:05.075913
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-26 19:52:43.849670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 863.36
train mean loss: 870.59
epoch train time: 0:00:02.000278
elapsed time: 0:02:07.076992
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-26 19:52:45.850632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 867.49
train mean loss: 857.83
epoch train time: 0:00:02.004369
elapsed time: 0:02:09.082120
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-26 19:52:47.855786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 851.52
train mean loss: 863.05
epoch train time: 0:00:01.988957
elapsed time: 0:02:11.071841
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-26 19:52:49.845506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 872.54
train mean loss: 860.37
epoch train time: 0:00:01.981648
elapsed time: 0:02:13.054330
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-26 19:52:51.827995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 875.07
train mean loss: 886.05
epoch train time: 0:00:01.993690
elapsed time: 0:02:15.048827
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-26 19:52:53.822486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 875.30
train mean loss: 862.60
epoch train time: 0:00:01.978617
elapsed time: 0:02:17.028229
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-26 19:52:55.801876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 862.66
train mean loss: 858.94
epoch train time: 0:00:01.994927
elapsed time: 0:02:19.023845
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-26 19:52:57.797513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 858.33
train mean loss: 859.37
epoch train time: 0:00:02.000850
elapsed time: 0:02:21.025376
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-26 19:52:59.799024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 852.38
train mean loss: 882.26
epoch train time: 0:00:02.006790
elapsed time: 0:02:23.032825
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-26 19:53:01.806470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 838.62
train mean loss: 863.60
epoch train time: 0:00:01.985597
elapsed time: 0:02:25.019141
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-26 19:53:03.792780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 859.46
train mean loss: 859.18
epoch train time: 0:00:01.991718
elapsed time: 0:02:27.011558
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-26 19:53:05.785203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 854.18
train mean loss: 852.70
epoch train time: 0:00:01.988346
elapsed time: 0:02:29.000582
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-26 19:53:07.774221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 863.91
train mean loss: 855.01
epoch train time: 0:00:01.999068
elapsed time: 0:02:31.000340
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-26 19:53:09.774028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 852.38
train mean loss: 857.36
epoch train time: 0:00:01.989424
elapsed time: 0:02:32.990513
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-26 19:53:11.764160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 857.01
train mean loss: 852.58
epoch train time: 0:00:01.982879
elapsed time: 0:02:34.974127
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-26 19:53:13.747770
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 848.90
train mean loss: 853.48
epoch train time: 0:00:01.981761
elapsed time: 0:02:36.956563
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-26 19:53:15.730223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 847.23
train mean loss: 867.32
epoch train time: 0:00:01.991047
elapsed time: 0:02:38.948306
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-26 19:53:17.721989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 843.05
train mean loss: 853.11
epoch train time: 0:00:01.990338
elapsed time: 0:02:40.939344
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-26 19:53:19.713038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 842.70
train mean loss: 853.31
epoch train time: 0:00:01.991577
elapsed time: 0:02:42.931630
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-26 19:53:21.705276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 849.92
train mean loss: 835.11
epoch train time: 0:00:01.998724
elapsed time: 0:02:44.931001
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-26 19:53:23.704662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 834.41
train mean loss: 826.13
epoch train time: 0:00:01.975351
elapsed time: 0:02:46.907133
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-26 19:53:25.680785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 837.70
train mean loss: 840.38
epoch train time: 0:00:01.984290
elapsed time: 0:02:48.892123
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-26 19:53:27.665781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 843.00
train mean loss: 834.41
epoch train time: 0:00:01.991644
elapsed time: 0:02:50.884522
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-26 19:53:29.658224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 823.37
train mean loss: 841.25
epoch train time: 0:00:02.001558
elapsed time: 0:02:52.886854
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-26 19:53:31.660503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 826.55
train mean loss: 824.59
epoch train time: 0:00:01.988994
elapsed time: 0:02:54.876517
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-26 19:53:33.650163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 833.76
train mean loss: 829.37
epoch train time: 0:00:01.982977
elapsed time: 0:02:56.860194
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-26 19:53:35.633852
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 832.80
train mean loss: 821.23
epoch train time: 0:00:01.993612
elapsed time: 0:02:58.854536
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-26 19:53:37.628173
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 830.53
train mean loss: 820.04
epoch train time: 0:00:01.987820
elapsed time: 0:03:00.843061
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-26 19:53:39.616694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 827.11
train mean loss: 818.64
epoch train time: 0:00:01.992299
elapsed time: 0:03:02.836170
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-26 19:53:41.609820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 831.94
train mean loss: 809.36
epoch train time: 0:00:01.984339
elapsed time: 0:03:04.821191
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-26 19:53:43.594834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 821.11
train mean loss: 807.04
epoch train time: 0:00:01.993095
elapsed time: 0:03:06.814929
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-26 19:53:45.588576
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 822.38
train mean loss: 812.19
epoch train time: 0:00:01.985603
elapsed time: 0:03:08.801211
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-26 19:53:47.574904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 798.19
train mean loss: 798.57
epoch train time: 0:00:01.990482
elapsed time: 0:03:10.792471
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-26 19:53:49.566120
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 802.95
train mean loss: 804.24
epoch train time: 0:00:01.988676
elapsed time: 0:03:12.781835
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-26 19:53:51.555477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 788.23
train mean loss: 797.05
epoch train time: 0:00:01.997671
elapsed time: 0:03:14.780174
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-26 19:53:53.553839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 809.50
train mean loss: 804.58
epoch train time: 0:00:01.995878
elapsed time: 0:03:16.776710
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-26 19:53:55.550353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 799.43
train mean loss: 804.59
epoch train time: 0:00:01.981822
elapsed time: 0:03:18.759188
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-26 19:53:57.532833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 810.54
train mean loss: 812.08
epoch train time: 0:00:01.999920
elapsed time: 0:03:20.759845
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-26 19:53:59.533504
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 786.32
train mean loss: 803.41
epoch train time: 0:00:01.992062
elapsed time: 0:03:22.752574
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-26 19:54:01.526216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 788.01
train mean loss: 786.70
epoch train time: 0:00:01.998220
elapsed time: 0:03:24.751448
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-26 19:54:03.525092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 759.69
train mean loss: 768.81
epoch train time: 0:00:01.997053
elapsed time: 0:03:26.749170
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-26 19:54:05.522893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 775.29
train mean loss: 791.56
epoch train time: 0:00:02.020255
elapsed time: 0:03:28.770122
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-26 19:54:07.543763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 769.24
train mean loss: 762.97
epoch train time: 0:00:02.019959
elapsed time: 0:03:30.790726
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-26 19:54:09.564372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 763.84
train mean loss: 768.91
epoch train time: 0:00:02.011597
elapsed time: 0:03:32.803012
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-26 19:54:11.576655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 760.64
train mean loss: 763.50
epoch train time: 0:00:02.008601
elapsed time: 0:03:34.812295
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-26 19:54:13.585971
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 761.62
train mean loss: 749.21
epoch train time: 0:00:02.004040
elapsed time: 0:03:36.817237
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-26 19:54:15.590795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 733.41
train mean loss: 721.80
epoch train time: 0:00:01.977811
elapsed time: 0:03:38.795620
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-26 19:54:17.569255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 726.13
train mean loss: 725.30
epoch train time: 0:00:01.982384
elapsed time: 0:03:40.778712
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-26 19:54:19.552361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 720.81
train mean loss: 710.34
epoch train time: 0:00:01.989293
elapsed time: 0:03:42.768626
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-26 19:54:21.542267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 701.07
train mean loss: 694.89
epoch train time: 0:00:01.981730
elapsed time: 0:03:44.751117
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-26 19:54:23.524778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 685.10
train mean loss: 688.61
epoch train time: 0:00:01.999813
elapsed time: 0:03:46.751583
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-26 19:54:25.525225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 702.04
train mean loss: 679.44
epoch train time: 0:00:01.988698
elapsed time: 0:03:48.740943
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-26 19:54:27.514582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 677.57
train mean loss: 672.85
epoch train time: 0:00:01.987532
elapsed time: 0:03:50.729155
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-26 19:54:29.502814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 677.39
train mean loss: 686.12
epoch train time: 0:00:01.990582
elapsed time: 0:03:52.720387
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-26 19:54:31.494033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 642.64
train mean loss: 658.70
epoch train time: 0:00:01.984993
elapsed time: 0:03:54.706065
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-26 19:54:33.479697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 658.31
train mean loss: 667.77
epoch train time: 0:00:01.989472
elapsed time: 0:03:56.696206
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-26 19:54:35.469862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 654.27
train mean loss: 647.31
epoch train time: 0:00:01.998391
elapsed time: 0:03:58.695271
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-26 19:54:37.468916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 656.83
train mean loss: 643.35
epoch train time: 0:00:01.987011
elapsed time: 0:04:00.682943
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-26 19:54:39.456610
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 650.13
train mean loss: 648.42
epoch train time: 0:00:01.989667
elapsed time: 0:04:02.673293
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-26 19:54:41.446964
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 637.93
train mean loss: 638.30
epoch train time: 0:00:01.998754
elapsed time: 0:04:04.672918
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-26 19:54:43.446585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 618.87
train mean loss: 615.47
epoch train time: 0:00:01.990280
elapsed time: 0:04:06.663896
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-26 19:54:45.437533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 616.06
train mean loss: 623.06
epoch train time: 0:00:01.990172
elapsed time: 0:04:08.654782
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-26 19:54:47.428428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 618.28
train mean loss: 618.88
epoch train time: 0:00:02.000193
elapsed time: 0:04:10.655624
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-26 19:54:49.429264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 605.75
train mean loss: 613.88
epoch train time: 0:00:01.991074
elapsed time: 0:04:12.647362
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-26 19:54:51.421023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 609.57
train mean loss: 608.86
epoch train time: 0:00:01.996556
elapsed time: 0:04:14.644610
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-26 19:54:53.418280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 595.63
train mean loss: 597.67
epoch train time: 0:00:01.996232
elapsed time: 0:04:16.641686
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-26 19:54:55.415242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 595.38
train mean loss: 598.32
epoch train time: 0:00:01.991383
elapsed time: 0:04:18.633724
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-26 19:54:57.407372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 579.06
train mean loss: 593.04
epoch train time: 0:00:01.991591
elapsed time: 0:04:20.625986
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-26 19:54:59.399651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 587.19
train mean loss: 578.72
epoch train time: 0:00:01.986305
elapsed time: 0:04:22.613049
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-26 19:55:01.386694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 581.10
train mean loss: 586.80
epoch train time: 0:00:02.010091
elapsed time: 0:04:24.623822
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-26 19:55:03.397466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 573.48
train mean loss: 569.54
epoch train time: 0:00:01.987797
elapsed time: 0:04:26.612284
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-26 19:55:05.385929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 560.73
train mean loss: 572.07
epoch train time: 0:00:02.013331
elapsed time: 0:04:28.626261
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-26 19:55:07.399923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 570.45
train mean loss: 563.93
epoch train time: 0:00:02.020241
elapsed time: 0:04:30.647225
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-26 19:55:09.420878
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 578.98
train mean loss: 570.62
epoch train time: 0:00:01.980825
elapsed time: 0:04:32.628822
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-26 19:55:11.402482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 560.01
train mean loss: 554.35
epoch train time: 0:00:02.033566
elapsed time: 0:04:34.663064
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-26 19:55:13.436710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 554.36
train mean loss: 554.99
epoch train time: 0:00:02.009512
elapsed time: 0:04:36.673244
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-26 19:55:15.446906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 550.75
train mean loss: 549.58
epoch train time: 0:00:01.997554
elapsed time: 0:04:38.671514
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-26 19:55:17.445433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.48
train mean loss: 539.67
epoch train time: 0:00:02.013961
elapsed time: 0:04:40.686383
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-26 19:55:19.460075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 550.08
train mean loss: 551.04
epoch train time: 0:00:01.990744
elapsed time: 0:04:42.677840
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-26 19:55:21.451479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 536.39
train mean loss: 539.79
epoch train time: 0:00:02.003634
elapsed time: 0:04:44.682187
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-26 19:55:23.455841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 542.32
train mean loss: 532.89
epoch train time: 0:00:02.004735
elapsed time: 0:04:46.687557
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-26 19:55:25.461199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 525.61
train mean loss: 530.75
epoch train time: 0:00:01.994904
elapsed time: 0:04:48.683229
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-26 19:55:27.456893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 522.06
train mean loss: 521.33
epoch train time: 0:00:01.995801
elapsed time: 0:04:50.679724
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-26 19:55:29.453366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 520.53
train mean loss: 522.37
epoch train time: 0:00:01.995877
elapsed time: 0:04:52.676304
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-26 19:55:31.449980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 524.94
train mean loss: 530.35
epoch train time: 0:00:02.003559
elapsed time: 0:04:54.680567
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-26 19:55:33.454209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 513.70
train mean loss: 523.76
epoch train time: 0:00:01.994884
elapsed time: 0:04:56.676144
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-26 19:55:35.449784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 503.43
train mean loss: 508.04
epoch train time: 0:00:01.980755
elapsed time: 0:04:58.657514
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-26 19:55:37.431168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 511.55
train mean loss: 510.58
epoch train time: 0:00:01.984977
elapsed time: 0:05:00.643319
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-26 19:55:39.416874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 515.09
train mean loss: 506.06
epoch train time: 0:00:02.000933
elapsed time: 0:05:02.644896
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-26 19:55:41.418542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 493.01
train mean loss: 493.13
epoch train time: 0:00:02.002343
elapsed time: 0:05:04.647874
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-26 19:55:43.421518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 515.53
train mean loss: 513.75
epoch train time: 0:00:01.994560
elapsed time: 0:05:06.643065
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-26 19:55:45.416708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 503.26
train mean loss: 502.62
epoch train time: 0:00:01.991741
elapsed time: 0:05:08.635455
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-26 19:55:47.409103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 505.47
train mean loss: 506.17
epoch train time: 0:00:02.002393
elapsed time: 0:05:10.638562
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-26 19:55:49.412201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 503.73
train mean loss: 503.00
epoch train time: 0:00:02.001340
elapsed time: 0:05:12.640672
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-26 19:55:51.414327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 504.30
train mean loss: 493.71
epoch train time: 0:00:02.000230
elapsed time: 0:05:14.641606
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-26 19:55:53.415272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 492.95
train mean loss: 499.49
epoch train time: 0:00:02.010588
elapsed time: 0:05:16.652911
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-26 19:55:55.426593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 488.52
train mean loss: 483.63
epoch train time: 0:00:02.007042
elapsed time: 0:05:18.660650
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-26 19:55:57.434296
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 475.86
train mean loss: 481.52
epoch train time: 0:00:01.994513
elapsed time: 0:05:20.655919
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-26 19:55:59.429576
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 483.84
train mean loss: 485.21
epoch train time: 0:00:02.006011
elapsed time: 0:05:22.662681
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-26 19:56:01.436335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 480.50
train mean loss: 483.81
epoch train time: 0:00:01.994565
elapsed time: 0:05:24.657964
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-26 19:56:03.431605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 477.11
train mean loss: 471.84
epoch train time: 0:00:01.989719
elapsed time: 0:05:26.648357
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-26 19:56:05.422004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 468.86
train mean loss: 479.58
epoch train time: 0:00:01.991036
elapsed time: 0:05:28.640053
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-26 19:56:07.413710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.99
train mean loss: 466.81
epoch train time: 0:00:01.986735
elapsed time: 0:05:30.627474
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-26 19:56:09.401107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.82
train mean loss: 474.00
epoch train time: 0:00:01.994031
elapsed time: 0:05:32.622147
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-26 19:56:11.395792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.90
train mean loss: 480.21
epoch train time: 0:00:01.984673
elapsed time: 0:05:34.607629
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-26 19:56:13.381281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 463.01
train mean loss: 453.94
epoch train time: 0:00:01.984411
elapsed time: 0:05:36.592757
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-26 19:56:15.366408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 464.62
train mean loss: 459.80
epoch train time: 0:00:01.986933
elapsed time: 0:05:38.580401
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-26 19:56:17.354043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 458.47
train mean loss: 447.56
epoch train time: 0:00:01.982171
elapsed time: 0:05:40.563205
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-26 19:56:19.336867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 453.16
train mean loss: 464.32
epoch train time: 0:00:01.985528
elapsed time: 0:05:42.549523
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-26 19:56:21.323176
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 453.55
train mean loss: 451.59
epoch train time: 0:00:01.986337
elapsed time: 0:05:44.536545
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-26 19:56:23.310207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 448.50
train mean loss: 448.29
epoch train time: 0:00:01.992650
elapsed time: 0:05:46.529864
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-26 19:56:25.303501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 455.70
train mean loss: 453.58
epoch train time: 0:00:01.987569
elapsed time: 0:05:48.518133
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-26 19:56:27.291834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 452.45
train mean loss: 451.77
epoch train time: 0:00:01.983601
elapsed time: 0:05:50.502592
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-26 19:56:29.276166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 450.94
train mean loss: 442.95
epoch train time: 0:00:01.992912
elapsed time: 0:05:52.496091
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-26 19:56:31.269744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 439.83
train mean loss: 446.97
epoch train time: 0:00:01.988315
elapsed time: 0:05:54.485140
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-26 19:56:33.258814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 440.98
train mean loss: 434.88
epoch train time: 0:00:01.981462
elapsed time: 0:05:56.467280
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-26 19:56:35.240926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 434.38
train mean loss: 433.16
epoch train time: 0:00:01.977615
elapsed time: 0:05:58.445553
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-26 19:56:37.219242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 421.73
train mean loss: 426.26
epoch train time: 0:00:01.986611
elapsed time: 0:06:00.432870
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-26 19:56:39.206520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 433.90
train mean loss: 417.09
epoch train time: 0:00:01.993723
elapsed time: 0:06:02.427241
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-26 19:56:41.200885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 435.53
train mean loss: 430.66
epoch train time: 0:00:01.994596
elapsed time: 0:06:04.422470
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-26 19:56:43.196114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 438.84
train mean loss: 432.70
epoch train time: 0:00:01.987745
elapsed time: 0:06:06.410867
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-26 19:56:45.184565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 413.06
train mean loss: 411.40
epoch train time: 0:00:01.985981
elapsed time: 0:06:08.397692
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-26 19:56:47.171340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 432.94
train mean loss: 429.90
epoch train time: 0:00:01.989446
elapsed time: 0:06:10.387762
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-26 19:56:49.161401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 426.05
train mean loss: 422.46
epoch train time: 0:00:01.999456
elapsed time: 0:06:12.387844
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-26 19:56:51.161484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 417.97
train mean loss: 414.43
epoch train time: 0:00:01.986835
elapsed time: 0:06:14.375331
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-26 19:56:53.148978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 429.70
train mean loss: 423.55
epoch train time: 0:00:01.993557
elapsed time: 0:06:16.369533
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-26 19:56:55.143188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 401.28
train mean loss: 424.92
epoch train time: 0:00:01.999420
elapsed time: 0:06:18.369637
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-26 19:56:57.143286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.62
train mean loss: 422.15
epoch train time: 0:00:01.988380
elapsed time: 0:06:20.358699
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-26 19:56:59.132351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 411.27
train mean loss: 407.06
epoch train time: 0:00:01.983405
elapsed time: 0:06:22.342752
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-26 19:57:01.116397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.44
train mean loss: 408.84
epoch train time: 0:00:01.993543
elapsed time: 0:06:24.337076
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-26 19:57:03.110806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.23
train mean loss: 395.67
epoch train time: 0:00:01.988946
elapsed time: 0:06:26.326747
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-26 19:57:05.100405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 417.33
train mean loss: 401.49
epoch train time: 0:00:01.998940
elapsed time: 0:06:28.326383
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-26 19:57:07.100054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 404.62
train mean loss: 400.61
epoch train time: 0:00:01.986499
elapsed time: 0:06:30.313647
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-26 19:57:09.087318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 411.56
train mean loss: 416.19
epoch train time: 0:00:01.989452
elapsed time: 0:06:32.303774
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-26 19:57:11.077474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 400.18
train mean loss: 412.75
epoch train time: 0:00:02.003300
elapsed time: 0:06:34.307792
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-26 19:57:13.081439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 396.85
train mean loss: 401.66
epoch train time: 0:00:01.995779
elapsed time: 0:06:36.304216
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-26 19:57:15.077862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 404.10
train mean loss: 393.57
epoch train time: 0:00:01.996697
elapsed time: 0:06:38.301563
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-26 19:57:17.075247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 394.05
train mean loss: 389.19
epoch train time: 0:00:01.984997
elapsed time: 0:06:40.287309
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-26 19:57:19.060944
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 396.28
train mean loss: 402.05
epoch train time: 0:00:01.984249
elapsed time: 0:06:42.272212
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-26 19:57:21.045859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 390.24
train mean loss: 382.10
epoch train time: 0:00:01.990935
elapsed time: 0:06:44.263779
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-26 19:57:23.037421
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.81
train mean loss: 385.32
epoch train time: 0:00:01.997332
elapsed time: 0:06:46.261875
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-26 19:57:25.035442
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 381.67
train mean loss: 382.16
epoch train time: 0:00:01.986911
elapsed time: 0:06:48.249321
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-26 19:57:27.022984
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 392.74
train mean loss: 387.14
epoch train time: 0:00:01.992433
elapsed time: 0:06:50.242451
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-26 19:57:29.016101
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 384.10
train mean loss: 390.44
epoch train time: 0:00:01.983061
elapsed time: 0:06:52.226192
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-26 19:57:30.999877
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 386.78
train mean loss: 381.27
epoch train time: 0:00:01.986207
elapsed time: 0:06:54.213064
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-26 19:57:32.986706
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 387.79
train mean loss: 386.08
epoch train time: 0:00:01.972582
elapsed time: 0:06:56.186293
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-26 19:57:34.959939
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.21
train mean loss: 379.23
epoch train time: 0:00:01.980769
elapsed time: 0:06:58.167677
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-26 19:57:36.941308
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 389.41
train mean loss: 387.93
epoch train time: 0:00:01.995776
elapsed time: 0:07:00.164124
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-26 19:57:38.937776
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 378.71
train mean loss: 383.29
epoch train time: 0:00:01.988780
elapsed time: 0:07:02.153594
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-26 19:57:40.927242
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 383.24
train mean loss: 391.88
epoch train time: 0:00:01.995485
elapsed time: 0:07:04.149749
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-26 19:57:42.923399
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 391.80
train mean loss: 396.44
epoch train time: 0:00:02.013680
elapsed time: 0:07:06.164113
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-26 19:57:44.937783
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 388.70
train mean loss: 379.96
epoch train time: 0:00:02.019298
elapsed time: 0:07:08.184087
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-26 19:57:46.957746
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.70
train mean loss: 387.40
epoch train time: 0:00:02.011300
elapsed time: 0:07:10.196060
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-26 19:57:48.969731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.21
train mean loss: 385.58
epoch train time: 0:00:02.000580
elapsed time: 0:07:12.198029
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-26 19:57:50.971716
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.50
train mean loss: 380.47
epoch train time: 0:00:01.997881
elapsed time: 0:07:14.196636
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-26 19:57:52.970271
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 384.36
train mean loss: 378.98
epoch train time: 0:00:01.990567
elapsed time: 0:07:16.187818
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-26 19:57:54.961485
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.71
train mean loss: 394.02
epoch train time: 0:00:01.992600
elapsed time: 0:07:18.181146
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-26 19:57:56.954801
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.22
train mean loss: 381.39
epoch train time: 0:00:01.994615
elapsed time: 0:07:20.176484
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-26 19:57:58.950141
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 392.97
train mean loss: 382.49
epoch train time: 0:00:02.006778
elapsed time: 0:07:22.183975
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-26 19:58:00.957657
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 384.97
train mean loss: 391.05
epoch train time: 0:00:02.006497
elapsed time: 0:07:24.191159
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-26 19:58:02.964844
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 382.46
train mean loss: 382.31
epoch train time: 0:00:01.990730
elapsed time: 0:07:26.182563
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-26 19:58:04.956205
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 386.01
train mean loss: 386.22
epoch train time: 0:00:01.985206
elapsed time: 0:07:28.168458
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-26 19:58:06.942099
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 384.00
train mean loss: 389.45
epoch train time: 0:00:01.985609
elapsed time: 0:07:30.154697
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-26 19:58:08.928341
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 379.84
train mean loss: 384.75
epoch train time: 0:00:01.993374
elapsed time: 0:07:32.148791
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-26 19:58:10.922439
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 386.75
train mean loss: 385.24
epoch train time: 0:00:02.006108
elapsed time: 0:07:34.155611
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-26 19:58:12.929253
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 382.03
train mean loss: 374.69
epoch train time: 0:00:02.002133
elapsed time: 0:07:36.158408
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-26 19:58:14.932053
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 382.15
train mean loss: 377.02
epoch train time: 0:00:02.004934
elapsed time: 0:07:38.163980
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-26 19:58:16.937663
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 384.40
train mean loss: 386.15
epoch train time: 0:00:02.003877
elapsed time: 0:07:40.168556
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-26 19:58:18.942206
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 376.69
train mean loss: 374.76
epoch train time: 0:00:02.000855
elapsed time: 0:07:42.170071
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-26 19:58:20.943753
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 383.30
train mean loss: 382.97
epoch train time: 0:00:02.005670
elapsed time: 0:07:44.176438
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-26 19:58:22.950090
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.91
train mean loss: 377.94
epoch train time: 0:00:01.999341
elapsed time: 0:07:46.176463
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-26 19:58:24.950114
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 381.94
train mean loss: 380.30
epoch train time: 0:00:02.003668
elapsed time: 0:07:48.180780
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-26 19:58:26.954447
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 383.01
train mean loss: 383.65
epoch train time: 0:00:01.999911
elapsed time: 0:07:50.181490
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-26 19:58:28.955046
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 377.40
train mean loss: 387.82
epoch train time: 0:00:01.996366
elapsed time: 0:07:52.178401
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-26 19:58:30.952051
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 379.46
train mean loss: 372.62
epoch train time: 0:00:02.003656
elapsed time: 0:07:54.182739
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-26 19:58:32.956435
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 383.78
train mean loss: 380.13
epoch train time: 0:00:01.981871
elapsed time: 0:07:56.165438
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-26 19:58:34.939090
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 386.04
train mean loss: 381.41
epoch train time: 0:00:01.990142
elapsed time: 0:07:58.156280
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-26 19:58:36.929934
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 377.12
train mean loss: 376.69
epoch train time: 0:00:01.993685
elapsed time: 0:08:00.150677
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-26 19:58:38.924341
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 381.87
train mean loss: 378.47
epoch train time: 0:00:02.024553
elapsed time: 0:08:02.175932
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-26 19:58:40.949577
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 383.87
train mean loss: 386.60
epoch train time: 0:00:01.999521
elapsed time: 0:08:04.176151
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-26 19:58:42.949807
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 384.85
train mean loss: 388.84
epoch train time: 0:00:01.990264
elapsed time: 0:08:06.167174
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-26 19:58:44.940827
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 388.61
train mean loss: 380.58
epoch train time: 0:00:01.998344
elapsed time: 0:08:08.166177
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-26 19:58:46.939818
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 380.40
train mean loss: 380.37
epoch train time: 0:00:01.991774
elapsed time: 0:08:10.158643
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-26 19:58:48.932290
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 379.12
train mean loss: 382.60
epoch train time: 0:00:01.982704
elapsed time: 0:08:12.142029
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-26 19:58:50.915676
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 384.35
train mean loss: 389.54
epoch train time: 0:00:01.994040
elapsed time: 0:08:14.136835
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-26 19:58:52.910491
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 379.91
train mean loss: 376.31
epoch train time: 0:00:01.992969
elapsed time: 0:08:16.130458
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-26 19:58:54.904096
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 385.52
train mean loss: 378.14
epoch train time: 0:00:01.988801
elapsed time: 0:08:18.119972
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-26 19:58:56.893658
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 378.99
train mean loss: 379.94
epoch train time: 0:00:02.002590
elapsed time: 0:08:20.123257
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-26 19:58:58.896941
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 383.39
train mean loss: 380.38
epoch train time: 0:00:01.993448
elapsed time: 0:08:22.126199
checkpoint saved in file: log/CMAPSS/FD004/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_0.125/bayesian_conv5_dense1_0.125_6/checkpoint.pth.tar
**** end time: 2019-09-26 19:59:00.899728 ****
