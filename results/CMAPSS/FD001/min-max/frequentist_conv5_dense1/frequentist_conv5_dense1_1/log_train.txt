Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_1', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30388
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 15:41:50.706859 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:41:50.715945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3849.57
 ---- batch: 020 ----
mean loss: 1774.26
 ---- batch: 030 ----
mean loss: 651.84
train mean loss: 1883.95
epoch train time: 0:00:12.546382
elapsed time: 0:00:12.557944
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:42:03.264841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 484.67
 ---- batch: 020 ----
mean loss: 420.84
 ---- batch: 030 ----
mean loss: 387.31
train mean loss: 424.68
epoch train time: 0:00:01.521993
elapsed time: 0:00:14.080081
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:42:04.787014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.99
 ---- batch: 020 ----
mean loss: 357.47
 ---- batch: 030 ----
mean loss: 344.95
train mean loss: 353.65
epoch train time: 0:00:01.439103
elapsed time: 0:00:15.519392
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:42:06.226305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.20
 ---- batch: 020 ----
mean loss: 316.09
 ---- batch: 030 ----
mean loss: 304.12
train mean loss: 311.62
epoch train time: 0:00:01.429446
elapsed time: 0:00:16.949000
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:42:07.655915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.55
 ---- batch: 020 ----
mean loss: 274.79
 ---- batch: 030 ----
mean loss: 260.58
train mean loss: 268.38
epoch train time: 0:00:01.431509
elapsed time: 0:00:18.380668
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:42:09.087580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.20
 ---- batch: 020 ----
mean loss: 247.09
 ---- batch: 030 ----
mean loss: 240.15
train mean loss: 240.57
epoch train time: 0:00:01.431370
elapsed time: 0:00:19.812221
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:42:10.519169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.12
 ---- batch: 020 ----
mean loss: 228.08
 ---- batch: 030 ----
mean loss: 229.13
train mean loss: 231.06
epoch train time: 0:00:01.433897
elapsed time: 0:00:21.246307
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:42:11.953233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.81
 ---- batch: 020 ----
mean loss: 216.73
 ---- batch: 030 ----
mean loss: 215.85
train mean loss: 218.88
epoch train time: 0:00:01.427676
elapsed time: 0:00:22.674204
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:42:13.381128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.33
 ---- batch: 020 ----
mean loss: 208.66
 ---- batch: 030 ----
mean loss: 208.60
train mean loss: 210.90
epoch train time: 0:00:01.429605
elapsed time: 0:00:24.103984
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:42:14.810924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.45
 ---- batch: 020 ----
mean loss: 206.41
 ---- batch: 030 ----
mean loss: 208.03
train mean loss: 208.01
epoch train time: 0:00:01.434154
elapsed time: 0:00:25.538315
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:42:16.245225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.06
 ---- batch: 020 ----
mean loss: 201.28
 ---- batch: 030 ----
mean loss: 202.49
train mean loss: 205.81
epoch train time: 0:00:01.429966
elapsed time: 0:00:26.968488
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:42:17.675420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.96
 ---- batch: 020 ----
mean loss: 204.57
 ---- batch: 030 ----
mean loss: 196.05
train mean loss: 199.82
epoch train time: 0:00:01.431713
elapsed time: 0:00:28.400389
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:42:19.107298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.31
 ---- batch: 020 ----
mean loss: 200.50
 ---- batch: 030 ----
mean loss: 191.46
train mean loss: 194.79
epoch train time: 0:00:01.434065
elapsed time: 0:00:29.834601
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:42:20.541511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.57
 ---- batch: 020 ----
mean loss: 200.26
 ---- batch: 030 ----
mean loss: 203.86
train mean loss: 199.58
epoch train time: 0:00:01.437949
elapsed time: 0:00:31.272714
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:42:21.979630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.75
 ---- batch: 020 ----
mean loss: 187.69
 ---- batch: 030 ----
mean loss: 188.76
train mean loss: 188.98
epoch train time: 0:00:01.436483
elapsed time: 0:00:32.709350
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:42:23.416261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.70
 ---- batch: 020 ----
mean loss: 184.47
 ---- batch: 030 ----
mean loss: 184.77
train mean loss: 183.50
epoch train time: 0:00:01.434536
elapsed time: 0:00:34.144049
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:42:24.850990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.22
 ---- batch: 020 ----
mean loss: 192.19
 ---- batch: 030 ----
mean loss: 183.75
train mean loss: 184.58
epoch train time: 0:00:01.436795
elapsed time: 0:00:35.581059
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:42:26.287988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.91
 ---- batch: 020 ----
mean loss: 179.79
 ---- batch: 030 ----
mean loss: 181.16
train mean loss: 182.37
epoch train time: 0:00:01.434192
elapsed time: 0:00:37.015429
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:42:27.722346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.18
 ---- batch: 020 ----
mean loss: 183.69
 ---- batch: 030 ----
mean loss: 183.86
train mean loss: 183.55
epoch train time: 0:00:01.435402
elapsed time: 0:00:38.451003
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:42:29.157918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.60
 ---- batch: 020 ----
mean loss: 185.08
 ---- batch: 030 ----
mean loss: 192.86
train mean loss: 184.34
epoch train time: 0:00:01.431955
elapsed time: 0:00:39.883116
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:42:30.590054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.45
 ---- batch: 020 ----
mean loss: 187.13
 ---- batch: 030 ----
mean loss: 177.22
train mean loss: 182.70
epoch train time: 0:00:01.433167
elapsed time: 0:00:41.316537
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:42:32.023450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.25
 ---- batch: 020 ----
mean loss: 179.64
 ---- batch: 030 ----
mean loss: 178.32
train mean loss: 178.22
epoch train time: 0:00:01.431872
elapsed time: 0:00:42.748566
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:42:33.455490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.46
 ---- batch: 020 ----
mean loss: 180.70
 ---- batch: 030 ----
mean loss: 174.30
train mean loss: 178.34
epoch train time: 0:00:01.434133
elapsed time: 0:00:44.182890
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:42:34.889803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.87
 ---- batch: 020 ----
mean loss: 179.80
 ---- batch: 030 ----
mean loss: 177.46
train mean loss: 176.89
epoch train time: 0:00:01.435485
elapsed time: 0:00:45.618551
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:42:36.325463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.84
 ---- batch: 020 ----
mean loss: 179.20
 ---- batch: 030 ----
mean loss: 174.86
train mean loss: 175.18
epoch train time: 0:00:01.436172
elapsed time: 0:00:47.054882
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:42:37.761799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.54
 ---- batch: 020 ----
mean loss: 172.43
 ---- batch: 030 ----
mean loss: 175.96
train mean loss: 175.19
epoch train time: 0:00:01.434086
elapsed time: 0:00:48.489135
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:42:39.196059
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.50
 ---- batch: 020 ----
mean loss: 173.77
 ---- batch: 030 ----
mean loss: 179.38
train mean loss: 176.61
epoch train time: 0:00:01.432548
elapsed time: 0:00:49.921855
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:42:40.628765
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.24
 ---- batch: 020 ----
mean loss: 170.22
 ---- batch: 030 ----
mean loss: 168.49
train mean loss: 171.90
epoch train time: 0:00:01.434720
elapsed time: 0:00:51.356770
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:42:42.063725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.78
 ---- batch: 020 ----
mean loss: 173.43
 ---- batch: 030 ----
mean loss: 170.81
train mean loss: 173.76
epoch train time: 0:00:01.429164
elapsed time: 0:00:52.786134
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:42:43.493048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.69
 ---- batch: 020 ----
mean loss: 168.77
 ---- batch: 030 ----
mean loss: 169.01
train mean loss: 171.66
epoch train time: 0:00:01.432873
elapsed time: 0:00:54.219169
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:42:44.926081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.94
 ---- batch: 020 ----
mean loss: 169.95
 ---- batch: 030 ----
mean loss: 167.62
train mean loss: 168.09
epoch train time: 0:00:01.431058
elapsed time: 0:00:55.650398
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:42:46.357322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.95
 ---- batch: 020 ----
mean loss: 163.68
 ---- batch: 030 ----
mean loss: 167.73
train mean loss: 166.20
epoch train time: 0:00:01.427215
elapsed time: 0:00:57.077824
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:42:47.784781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.75
 ---- batch: 020 ----
mean loss: 164.51
 ---- batch: 030 ----
mean loss: 168.98
train mean loss: 167.61
epoch train time: 0:00:01.436044
elapsed time: 0:00:58.514079
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:42:49.221016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.87
 ---- batch: 020 ----
mean loss: 169.74
 ---- batch: 030 ----
mean loss: 164.03
train mean loss: 167.28
epoch train time: 0:00:01.432691
elapsed time: 0:00:59.946954
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:42:50.653893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.65
 ---- batch: 020 ----
mean loss: 161.04
 ---- batch: 030 ----
mean loss: 169.06
train mean loss: 164.16
epoch train time: 0:00:01.429456
elapsed time: 0:01:01.376595
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:42:52.083509
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.57
 ---- batch: 020 ----
mean loss: 165.47
 ---- batch: 030 ----
mean loss: 164.72
train mean loss: 166.63
epoch train time: 0:00:01.436875
elapsed time: 0:01:02.813629
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:42:53.520541
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.87
 ---- batch: 020 ----
mean loss: 169.14
 ---- batch: 030 ----
mean loss: 166.29
train mean loss: 169.36
epoch train time: 0:00:01.434031
elapsed time: 0:01:04.247819
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:42:54.954761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.69
 ---- batch: 020 ----
mean loss: 163.57
 ---- batch: 030 ----
mean loss: 163.49
train mean loss: 164.39
epoch train time: 0:00:01.430830
elapsed time: 0:01:05.678854
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:42:56.385768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.27
 ---- batch: 020 ----
mean loss: 163.54
 ---- batch: 030 ----
mean loss: 173.15
train mean loss: 167.29
epoch train time: 0:00:01.435543
elapsed time: 0:01:07.114586
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:42:57.821511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.59
 ---- batch: 020 ----
mean loss: 165.24
 ---- batch: 030 ----
mean loss: 164.92
train mean loss: 165.13
epoch train time: 0:00:01.429066
elapsed time: 0:01:08.543842
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:42:59.250790
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.54
 ---- batch: 020 ----
mean loss: 158.83
 ---- batch: 030 ----
mean loss: 160.71
train mean loss: 161.17
epoch train time: 0:00:01.432703
elapsed time: 0:01:09.976737
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:43:00.683649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.06
 ---- batch: 020 ----
mean loss: 162.13
 ---- batch: 030 ----
mean loss: 161.77
train mean loss: 161.21
epoch train time: 0:00:01.433179
elapsed time: 0:01:11.410072
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:43:02.116983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.18
 ---- batch: 020 ----
mean loss: 162.12
 ---- batch: 030 ----
mean loss: 166.67
train mean loss: 160.93
epoch train time: 0:00:01.428219
elapsed time: 0:01:12.838442
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:43:03.545352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.14
 ---- batch: 020 ----
mean loss: 167.23
 ---- batch: 030 ----
mean loss: 157.29
train mean loss: 159.80
epoch train time: 0:00:01.430864
elapsed time: 0:01:14.269465
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:43:04.976380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.89
 ---- batch: 020 ----
mean loss: 158.90
 ---- batch: 030 ----
mean loss: 166.43
train mean loss: 161.32
epoch train time: 0:00:01.428088
elapsed time: 0:01:15.697741
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:43:06.404653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.53
 ---- batch: 020 ----
mean loss: 158.67
 ---- batch: 030 ----
mean loss: 161.83
train mean loss: 158.43
epoch train time: 0:00:01.429038
elapsed time: 0:01:17.126946
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:43:07.833863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.41
 ---- batch: 020 ----
mean loss: 159.70
 ---- batch: 030 ----
mean loss: 160.87
train mean loss: 162.34
epoch train time: 0:00:01.431992
elapsed time: 0:01:18.559098
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:43:09.266024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.61
 ---- batch: 020 ----
mean loss: 154.58
 ---- batch: 030 ----
mean loss: 163.69
train mean loss: 161.55
epoch train time: 0:00:01.428117
elapsed time: 0:01:19.987387
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:43:10.694297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.90
 ---- batch: 020 ----
mean loss: 156.34
 ---- batch: 030 ----
mean loss: 159.86
train mean loss: 157.91
epoch train time: 0:00:01.434674
elapsed time: 0:01:21.422219
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:43:12.129129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.87
 ---- batch: 020 ----
mean loss: 156.14
 ---- batch: 030 ----
mean loss: 152.66
train mean loss: 154.00
epoch train time: 0:00:01.430021
elapsed time: 0:01:22.852390
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:43:13.559304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.40
 ---- batch: 020 ----
mean loss: 163.31
 ---- batch: 030 ----
mean loss: 159.50
train mean loss: 159.92
epoch train time: 0:00:01.431534
elapsed time: 0:01:24.284084
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:43:14.991001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.37
 ---- batch: 020 ----
mean loss: 156.70
 ---- batch: 030 ----
mean loss: 158.46
train mean loss: 155.72
epoch train time: 0:00:01.428717
elapsed time: 0:01:25.712960
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:43:16.419869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.67
 ---- batch: 020 ----
mean loss: 152.98
 ---- batch: 030 ----
mean loss: 150.43
train mean loss: 151.24
epoch train time: 0:00:01.433466
elapsed time: 0:01:27.146583
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:43:17.853495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.99
 ---- batch: 020 ----
mean loss: 154.56
 ---- batch: 030 ----
mean loss: 156.13
train mean loss: 157.23
epoch train time: 0:00:01.426668
elapsed time: 0:01:28.573408
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:43:19.280321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.96
 ---- batch: 020 ----
mean loss: 159.86
 ---- batch: 030 ----
mean loss: 153.96
train mean loss: 156.87
epoch train time: 0:00:01.429554
elapsed time: 0:01:30.003121
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:43:20.710034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.06
 ---- batch: 020 ----
mean loss: 154.58
 ---- batch: 030 ----
mean loss: 155.83
train mean loss: 153.23
epoch train time: 0:00:01.428072
elapsed time: 0:01:31.431353
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:43:22.138298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.79
 ---- batch: 020 ----
mean loss: 152.17
 ---- batch: 030 ----
mean loss: 151.22
train mean loss: 152.75
epoch train time: 0:00:01.431633
elapsed time: 0:01:32.863179
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:43:23.570106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.84
 ---- batch: 020 ----
mean loss: 156.68
 ---- batch: 030 ----
mean loss: 148.28
train mean loss: 153.98
epoch train time: 0:00:01.435110
elapsed time: 0:01:34.298490
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:43:25.005403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.58
 ---- batch: 020 ----
mean loss: 157.53
 ---- batch: 030 ----
mean loss: 150.32
train mean loss: 150.54
epoch train time: 0:00:01.429440
elapsed time: 0:01:35.728090
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:43:26.435002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.42
 ---- batch: 020 ----
mean loss: 143.24
 ---- batch: 030 ----
mean loss: 157.29
train mean loss: 152.11
epoch train time: 0:00:01.428324
elapsed time: 0:01:37.156606
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:43:27.863589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.11
 ---- batch: 020 ----
mean loss: 145.15
 ---- batch: 030 ----
mean loss: 152.25
train mean loss: 149.92
epoch train time: 0:00:01.431505
elapsed time: 0:01:38.588358
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:43:29.295279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.21
 ---- batch: 020 ----
mean loss: 153.87
 ---- batch: 030 ----
mean loss: 157.03
train mean loss: 157.09
epoch train time: 0:00:01.436418
elapsed time: 0:01:40.024945
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:43:30.731858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.56
 ---- batch: 020 ----
mean loss: 150.23
 ---- batch: 030 ----
mean loss: 149.98
train mean loss: 151.38
epoch train time: 0:00:01.427172
elapsed time: 0:01:41.452269
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:43:32.159182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.10
 ---- batch: 020 ----
mean loss: 149.56
 ---- batch: 030 ----
mean loss: 155.02
train mean loss: 151.66
epoch train time: 0:00:01.431943
elapsed time: 0:01:42.884379
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:43:33.591292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.75
 ---- batch: 020 ----
mean loss: 155.44
 ---- batch: 030 ----
mean loss: 149.30
train mean loss: 154.42
epoch train time: 0:00:01.437287
elapsed time: 0:01:44.321829
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:43:35.028745
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.73
 ---- batch: 020 ----
mean loss: 144.49
 ---- batch: 030 ----
mean loss: 148.28
train mean loss: 149.75
epoch train time: 0:00:01.432419
elapsed time: 0:01:45.754412
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:43:36.461344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.65
 ---- batch: 020 ----
mean loss: 150.71
 ---- batch: 030 ----
mean loss: 156.15
train mean loss: 151.20
epoch train time: 0:00:01.430307
elapsed time: 0:01:47.184894
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:43:37.891805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.36
 ---- batch: 020 ----
mean loss: 149.45
 ---- batch: 030 ----
mean loss: 153.65
train mean loss: 151.23
epoch train time: 0:00:01.429362
elapsed time: 0:01:48.614413
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:43:39.321329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.90
 ---- batch: 020 ----
mean loss: 147.70
 ---- batch: 030 ----
mean loss: 150.75
train mean loss: 150.33
epoch train time: 0:00:01.430726
elapsed time: 0:01:50.045302
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:43:40.752219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.18
 ---- batch: 020 ----
mean loss: 151.61
 ---- batch: 030 ----
mean loss: 152.38
train mean loss: 149.14
epoch train time: 0:00:01.432825
elapsed time: 0:01:51.478325
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:43:42.185241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.06
 ---- batch: 020 ----
mean loss: 152.82
 ---- batch: 030 ----
mean loss: 151.91
train mean loss: 151.05
epoch train time: 0:00:01.427504
elapsed time: 0:01:52.906086
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:43:43.612999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.97
 ---- batch: 020 ----
mean loss: 145.25
 ---- batch: 030 ----
mean loss: 143.31
train mean loss: 145.73
epoch train time: 0:00:01.431472
elapsed time: 0:01:54.337716
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:43:45.044663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.99
 ---- batch: 020 ----
mean loss: 155.05
 ---- batch: 030 ----
mean loss: 148.59
train mean loss: 152.41
epoch train time: 0:00:01.427801
elapsed time: 0:01:55.765704
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:43:46.472615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.84
 ---- batch: 020 ----
mean loss: 151.53
 ---- batch: 030 ----
mean loss: 154.97
train mean loss: 148.43
epoch train time: 0:00:01.432323
elapsed time: 0:01:57.198193
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:43:47.905159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.68
 ---- batch: 020 ----
mean loss: 148.41
 ---- batch: 030 ----
mean loss: 143.90
train mean loss: 145.37
epoch train time: 0:00:01.428510
elapsed time: 0:01:58.626929
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:43:49.333841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.80
 ---- batch: 020 ----
mean loss: 151.07
 ---- batch: 030 ----
mean loss: 154.17
train mean loss: 149.67
epoch train time: 0:00:01.430520
elapsed time: 0:02:00.057628
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:43:50.764544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.63
 ---- batch: 020 ----
mean loss: 153.79
 ---- batch: 030 ----
mean loss: 151.05
train mean loss: 150.10
epoch train time: 0:00:01.432975
elapsed time: 0:02:01.490778
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:43:52.197695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.82
 ---- batch: 020 ----
mean loss: 150.27
 ---- batch: 030 ----
mean loss: 147.10
train mean loss: 148.79
epoch train time: 0:00:01.429972
elapsed time: 0:02:02.920913
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:43:53.627825
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.58
 ---- batch: 020 ----
mean loss: 147.36
 ---- batch: 030 ----
mean loss: 148.03
train mean loss: 147.94
epoch train time: 0:00:01.433454
elapsed time: 0:02:04.354522
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:43:55.061432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.79
 ---- batch: 020 ----
mean loss: 143.67
 ---- batch: 030 ----
mean loss: 146.51
train mean loss: 143.70
epoch train time: 0:00:01.430501
elapsed time: 0:02:05.785191
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:43:56.492105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.93
 ---- batch: 020 ----
mean loss: 148.53
 ---- batch: 030 ----
mean loss: 145.59
train mean loss: 146.11
epoch train time: 0:00:01.432816
elapsed time: 0:02:07.218171
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:43:57.925089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.31
 ---- batch: 020 ----
mean loss: 148.36
 ---- batch: 030 ----
mean loss: 141.97
train mean loss: 144.78
epoch train time: 0:00:01.429265
elapsed time: 0:02:08.647654
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:43:59.354567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.88
 ---- batch: 020 ----
mean loss: 141.74
 ---- batch: 030 ----
mean loss: 145.76
train mean loss: 144.01
epoch train time: 0:00:01.434223
elapsed time: 0:02:10.082080
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:44:00.788990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.54
 ---- batch: 020 ----
mean loss: 142.73
 ---- batch: 030 ----
mean loss: 145.63
train mean loss: 145.07
epoch train time: 0:00:01.430904
elapsed time: 0:02:11.513136
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:44:02.220048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.63
 ---- batch: 020 ----
mean loss: 155.96
 ---- batch: 030 ----
mean loss: 147.30
train mean loss: 147.30
epoch train time: 0:00:01.429603
elapsed time: 0:02:12.942905
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:44:03.649820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.23
 ---- batch: 020 ----
mean loss: 149.55
 ---- batch: 030 ----
mean loss: 143.96
train mean loss: 146.36
epoch train time: 0:00:01.445709
elapsed time: 0:02:14.388801
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:44:05.095731
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.65
 ---- batch: 020 ----
mean loss: 140.84
 ---- batch: 030 ----
mean loss: 146.20
train mean loss: 144.91
epoch train time: 0:00:01.426621
elapsed time: 0:02:15.815614
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:44:06.522554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.22
 ---- batch: 020 ----
mean loss: 150.74
 ---- batch: 030 ----
mean loss: 144.49
train mean loss: 148.34
epoch train time: 0:00:01.433077
elapsed time: 0:02:17.248908
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:44:07.955824
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.48
 ---- batch: 020 ----
mean loss: 143.63
 ---- batch: 030 ----
mean loss: 147.29
train mean loss: 148.41
epoch train time: 0:00:01.432732
elapsed time: 0:02:18.681899
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:44:09.388809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.28
 ---- batch: 020 ----
mean loss: 159.65
 ---- batch: 030 ----
mean loss: 155.03
train mean loss: 156.36
epoch train time: 0:00:01.430734
elapsed time: 0:02:20.112800
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:44:10.819722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.62
 ---- batch: 020 ----
mean loss: 146.15
 ---- batch: 030 ----
mean loss: 142.37
train mean loss: 145.70
epoch train time: 0:00:01.431492
elapsed time: 0:02:21.544456
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:44:12.251368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.46
 ---- batch: 020 ----
mean loss: 148.48
 ---- batch: 030 ----
mean loss: 147.76
train mean loss: 147.07
epoch train time: 0:00:01.429545
elapsed time: 0:02:22.974159
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:44:13.681070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.29
 ---- batch: 020 ----
mean loss: 152.02
 ---- batch: 030 ----
mean loss: 149.05
train mean loss: 147.87
epoch train time: 0:00:01.435183
elapsed time: 0:02:24.409516
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:44:15.116442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.44
 ---- batch: 020 ----
mean loss: 140.50
 ---- batch: 030 ----
mean loss: 150.13
train mean loss: 144.11
epoch train time: 0:00:01.426348
elapsed time: 0:02:25.836036
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:44:16.542948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.34
 ---- batch: 020 ----
mean loss: 146.72
 ---- batch: 030 ----
mean loss: 154.22
train mean loss: 147.86
epoch train time: 0:00:01.430809
elapsed time: 0:02:27.267009
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:44:17.973935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.68
 ---- batch: 020 ----
mean loss: 140.65
 ---- batch: 030 ----
mean loss: 148.71
train mean loss: 144.16
epoch train time: 0:00:01.429857
elapsed time: 0:02:28.697058
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:44:19.403984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.49
 ---- batch: 020 ----
mean loss: 142.04
 ---- batch: 030 ----
mean loss: 155.67
train mean loss: 146.77
epoch train time: 0:00:01.435142
elapsed time: 0:02:30.132376
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:44:20.839290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.10
 ---- batch: 020 ----
mean loss: 141.67
 ---- batch: 030 ----
mean loss: 144.62
train mean loss: 146.99
epoch train time: 0:00:01.431830
elapsed time: 0:02:31.564364
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:44:22.271276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.23
 ---- batch: 020 ----
mean loss: 146.36
 ---- batch: 030 ----
mean loss: 147.54
train mean loss: 147.52
epoch train time: 0:00:01.438379
elapsed time: 0:02:33.002916
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:44:23.709840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.03
 ---- batch: 020 ----
mean loss: 148.70
 ---- batch: 030 ----
mean loss: 144.43
train mean loss: 145.64
epoch train time: 0:00:01.430760
elapsed time: 0:02:34.433840
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:44:25.140750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.29
 ---- batch: 020 ----
mean loss: 138.55
 ---- batch: 030 ----
mean loss: 141.61
train mean loss: 142.92
epoch train time: 0:00:01.433377
elapsed time: 0:02:35.867410
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:44:26.574346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.66
 ---- batch: 020 ----
mean loss: 147.10
 ---- batch: 030 ----
mean loss: 149.36
train mean loss: 146.92
epoch train time: 0:00:01.433795
elapsed time: 0:02:37.301404
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:44:28.008319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.57
 ---- batch: 020 ----
mean loss: 148.85
 ---- batch: 030 ----
mean loss: 147.35
train mean loss: 146.79
epoch train time: 0:00:01.432082
elapsed time: 0:02:38.733640
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:44:29.440549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.48
 ---- batch: 020 ----
mean loss: 146.36
 ---- batch: 030 ----
mean loss: 139.97
train mean loss: 145.20
epoch train time: 0:00:01.432891
elapsed time: 0:02:40.166690
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:44:30.873623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.97
 ---- batch: 020 ----
mean loss: 143.77
 ---- batch: 030 ----
mean loss: 138.92
train mean loss: 141.39
epoch train time: 0:00:01.431069
elapsed time: 0:02:41.597936
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:44:32.304849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.96
 ---- batch: 020 ----
mean loss: 144.39
 ---- batch: 030 ----
mean loss: 145.72
train mean loss: 144.46
epoch train time: 0:00:01.430213
elapsed time: 0:02:43.028364
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:44:33.735299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.97
 ---- batch: 020 ----
mean loss: 143.05
 ---- batch: 030 ----
mean loss: 148.23
train mean loss: 146.22
epoch train time: 0:00:01.432241
elapsed time: 0:02:44.460804
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:44:35.167704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.23
 ---- batch: 020 ----
mean loss: 144.18
 ---- batch: 030 ----
mean loss: 141.92
train mean loss: 143.63
epoch train time: 0:00:01.429833
elapsed time: 0:02:45.890801
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:44:36.597717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.76
 ---- batch: 020 ----
mean loss: 144.27
 ---- batch: 030 ----
mean loss: 142.47
train mean loss: 144.10
epoch train time: 0:00:01.428899
elapsed time: 0:02:47.319870
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:44:38.026780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.60
 ---- batch: 020 ----
mean loss: 146.09
 ---- batch: 030 ----
mean loss: 144.28
train mean loss: 147.62
epoch train time: 0:00:01.430670
elapsed time: 0:02:48.750694
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:44:39.457633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.20
 ---- batch: 020 ----
mean loss: 146.66
 ---- batch: 030 ----
mean loss: 143.09
train mean loss: 143.12
epoch train time: 0:00:01.431230
elapsed time: 0:02:50.182116
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:44:40.889027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.85
 ---- batch: 020 ----
mean loss: 141.62
 ---- batch: 030 ----
mean loss: 140.02
train mean loss: 143.81
epoch train time: 0:00:01.431495
elapsed time: 0:02:51.613763
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:44:42.320706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.72
 ---- batch: 020 ----
mean loss: 152.95
 ---- batch: 030 ----
mean loss: 147.84
train mean loss: 150.30
epoch train time: 0:00:01.431200
elapsed time: 0:02:53.045184
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:44:43.752100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.69
 ---- batch: 020 ----
mean loss: 143.37
 ---- batch: 030 ----
mean loss: 151.03
train mean loss: 147.14
epoch train time: 0:00:01.431413
elapsed time: 0:02:54.476753
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:44:45.183686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.01
 ---- batch: 020 ----
mean loss: 144.76
 ---- batch: 030 ----
mean loss: 143.49
train mean loss: 144.84
epoch train time: 0:00:01.430214
elapsed time: 0:02:55.907145
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:44:46.614057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.72
 ---- batch: 020 ----
mean loss: 144.31
 ---- batch: 030 ----
mean loss: 143.83
train mean loss: 144.64
epoch train time: 0:00:01.429990
elapsed time: 0:02:57.337289
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:44:48.044202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.03
 ---- batch: 020 ----
mean loss: 146.18
 ---- batch: 030 ----
mean loss: 140.98
train mean loss: 143.42
epoch train time: 0:00:01.432203
elapsed time: 0:02:58.769659
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:44:49.476574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.44
 ---- batch: 020 ----
mean loss: 139.38
 ---- batch: 030 ----
mean loss: 144.93
train mean loss: 141.94
epoch train time: 0:00:01.434017
elapsed time: 0:03:00.203856
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:44:50.910767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.88
 ---- batch: 020 ----
mean loss: 139.99
 ---- batch: 030 ----
mean loss: 139.98
train mean loss: 141.52
epoch train time: 0:00:01.428942
elapsed time: 0:03:01.632969
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:44:52.339911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.54
 ---- batch: 020 ----
mean loss: 143.56
 ---- batch: 030 ----
mean loss: 143.10
train mean loss: 142.56
epoch train time: 0:00:01.434690
elapsed time: 0:03:03.067858
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:44:53.774779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.05
 ---- batch: 020 ----
mean loss: 141.12
 ---- batch: 030 ----
mean loss: 135.06
train mean loss: 141.50
epoch train time: 0:00:01.438369
elapsed time: 0:03:04.506395
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:44:55.213310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.55
 ---- batch: 020 ----
mean loss: 140.23
 ---- batch: 030 ----
mean loss: 150.98
train mean loss: 143.60
epoch train time: 0:00:01.433291
elapsed time: 0:03:05.939855
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:44:56.646773
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.50
 ---- batch: 020 ----
mean loss: 149.56
 ---- batch: 030 ----
mean loss: 147.30
train mean loss: 145.73
epoch train time: 0:00:01.434026
elapsed time: 0:03:07.374063
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:44:58.080975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.22
 ---- batch: 020 ----
mean loss: 146.68
 ---- batch: 030 ----
mean loss: 145.76
train mean loss: 145.27
epoch train time: 0:00:01.429970
elapsed time: 0:03:08.804206
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:44:59.511124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.54
 ---- batch: 020 ----
mean loss: 141.70
 ---- batch: 030 ----
mean loss: 143.09
train mean loss: 143.15
epoch train time: 0:00:01.434720
elapsed time: 0:03:10.239102
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:45:00.946016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.16
 ---- batch: 020 ----
mean loss: 145.86
 ---- batch: 030 ----
mean loss: 143.74
train mean loss: 144.81
epoch train time: 0:00:01.427228
elapsed time: 0:03:11.666519
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:45:02.373435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.32
 ---- batch: 020 ----
mean loss: 140.10
 ---- batch: 030 ----
mean loss: 142.55
train mean loss: 142.00
epoch train time: 0:00:01.430104
elapsed time: 0:03:13.096811
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:45:03.803710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.41
 ---- batch: 020 ----
mean loss: 145.98
 ---- batch: 030 ----
mean loss: 142.33
train mean loss: 142.25
epoch train time: 0:00:01.432058
elapsed time: 0:03:14.529013
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:45:05.235945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.71
 ---- batch: 020 ----
mean loss: 144.34
 ---- batch: 030 ----
mean loss: 143.06
train mean loss: 144.51
epoch train time: 0:00:01.429569
elapsed time: 0:03:15.958831
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:45:06.665840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.59
 ---- batch: 020 ----
mean loss: 141.14
 ---- batch: 030 ----
mean loss: 141.90
train mean loss: 141.88
epoch train time: 0:00:01.436543
elapsed time: 0:03:17.395665
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:45:08.102577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.14
 ---- batch: 020 ----
mean loss: 142.89
 ---- batch: 030 ----
mean loss: 143.44
train mean loss: 143.51
epoch train time: 0:00:01.427579
elapsed time: 0:03:18.823438
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:45:09.530351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.24
 ---- batch: 020 ----
mean loss: 139.99
 ---- batch: 030 ----
mean loss: 143.80
train mean loss: 142.13
epoch train time: 0:00:01.434812
elapsed time: 0:03:20.258408
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:45:10.965325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.64
 ---- batch: 020 ----
mean loss: 145.25
 ---- batch: 030 ----
mean loss: 141.01
train mean loss: 142.85
epoch train time: 0:00:01.426853
elapsed time: 0:03:21.685421
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:45:12.392363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.43
 ---- batch: 020 ----
mean loss: 148.44
 ---- batch: 030 ----
mean loss: 148.69
train mean loss: 147.99
epoch train time: 0:00:01.432320
elapsed time: 0:03:23.117930
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:45:13.824842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.57
 ---- batch: 020 ----
mean loss: 144.47
 ---- batch: 030 ----
mean loss: 149.98
train mean loss: 143.97
epoch train time: 0:00:01.433996
elapsed time: 0:03:24.552163
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:45:15.259093
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.86
 ---- batch: 020 ----
mean loss: 139.15
 ---- batch: 030 ----
mean loss: 145.62
train mean loss: 142.37
epoch train time: 0:00:01.429310
elapsed time: 0:03:25.981705
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:45:16.688618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.40
 ---- batch: 020 ----
mean loss: 142.71
 ---- batch: 030 ----
mean loss: 141.16
train mean loss: 143.40
epoch train time: 0:00:01.429234
elapsed time: 0:03:27.411107
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:45:18.118020
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.92
 ---- batch: 020 ----
mean loss: 144.46
 ---- batch: 030 ----
mean loss: 143.87
train mean loss: 142.93
epoch train time: 0:00:01.430606
elapsed time: 0:03:28.841875
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:45:19.548797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.43
 ---- batch: 020 ----
mean loss: 150.01
 ---- batch: 030 ----
mean loss: 151.78
train mean loss: 147.86
epoch train time: 0:00:01.445331
elapsed time: 0:03:30.287375
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:45:20.994304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.13
 ---- batch: 020 ----
mean loss: 139.29
 ---- batch: 030 ----
mean loss: 139.79
train mean loss: 142.05
epoch train time: 0:00:01.430777
elapsed time: 0:03:31.718353
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:45:22.425267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.32
 ---- batch: 020 ----
mean loss: 143.97
 ---- batch: 030 ----
mean loss: 145.99
train mean loss: 143.73
epoch train time: 0:00:01.433177
elapsed time: 0:03:33.151692
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:45:23.858625
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.24
 ---- batch: 020 ----
mean loss: 135.96
 ---- batch: 030 ----
mean loss: 141.97
train mean loss: 141.87
epoch train time: 0:00:01.438125
elapsed time: 0:03:34.589994
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:45:25.296943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.20
 ---- batch: 020 ----
mean loss: 146.27
 ---- batch: 030 ----
mean loss: 155.32
train mean loss: 147.72
epoch train time: 0:00:01.434743
elapsed time: 0:03:36.024986
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:45:26.731899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.98
 ---- batch: 020 ----
mean loss: 143.70
 ---- batch: 030 ----
mean loss: 147.43
train mean loss: 144.99
epoch train time: 0:00:01.427976
elapsed time: 0:03:37.453116
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:45:28.160025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.00
 ---- batch: 020 ----
mean loss: 141.94
 ---- batch: 030 ----
mean loss: 139.19
train mean loss: 141.12
epoch train time: 0:00:01.426111
elapsed time: 0:03:38.879386
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:45:29.586298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.46
 ---- batch: 020 ----
mean loss: 141.48
 ---- batch: 030 ----
mean loss: 137.74
train mean loss: 140.86
epoch train time: 0:00:01.429365
elapsed time: 0:03:40.308953
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:45:31.015866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.18
 ---- batch: 020 ----
mean loss: 142.56
 ---- batch: 030 ----
mean loss: 141.80
train mean loss: 142.12
epoch train time: 0:00:01.434618
elapsed time: 0:03:41.743729
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:45:32.450640
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.46
 ---- batch: 020 ----
mean loss: 143.50
 ---- batch: 030 ----
mean loss: 143.33
train mean loss: 143.11
epoch train time: 0:00:01.429448
elapsed time: 0:03:43.173359
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:45:33.880275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.17
 ---- batch: 020 ----
mean loss: 143.05
 ---- batch: 030 ----
mean loss: 140.73
train mean loss: 140.15
epoch train time: 0:00:01.427010
elapsed time: 0:03:44.600543
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:45:35.307457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.16
 ---- batch: 020 ----
mean loss: 144.43
 ---- batch: 030 ----
mean loss: 143.89
train mean loss: 143.55
epoch train time: 0:00:01.427551
elapsed time: 0:03:46.028260
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:45:36.735201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.99
 ---- batch: 020 ----
mean loss: 142.62
 ---- batch: 030 ----
mean loss: 140.72
train mean loss: 141.98
epoch train time: 0:00:01.428965
elapsed time: 0:03:47.457418
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:45:38.164350
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.83
 ---- batch: 020 ----
mean loss: 140.65
 ---- batch: 030 ----
mean loss: 141.50
train mean loss: 141.04
epoch train time: 0:00:01.430475
elapsed time: 0:03:48.888083
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:45:39.594996
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.95
 ---- batch: 020 ----
mean loss: 148.14
 ---- batch: 030 ----
mean loss: 134.41
train mean loss: 142.37
epoch train time: 0:00:01.426742
elapsed time: 0:03:50.314981
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:45:41.021894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.81
 ---- batch: 020 ----
mean loss: 140.52
 ---- batch: 030 ----
mean loss: 145.31
train mean loss: 142.86
epoch train time: 0:00:01.433130
elapsed time: 0:03:51.748269
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:45:42.455200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.21
 ---- batch: 020 ----
mean loss: 143.92
 ---- batch: 030 ----
mean loss: 143.06
train mean loss: 143.73
epoch train time: 0:00:01.435535
elapsed time: 0:03:53.184053
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:45:43.890998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.13
 ---- batch: 020 ----
mean loss: 141.22
 ---- batch: 030 ----
mean loss: 141.53
train mean loss: 140.72
epoch train time: 0:00:01.432364
elapsed time: 0:03:54.616606
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:45:45.323541
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.41
 ---- batch: 020 ----
mean loss: 144.25
 ---- batch: 030 ----
mean loss: 141.33
train mean loss: 142.16
epoch train time: 0:00:01.427312
elapsed time: 0:03:56.044100
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:45:46.751024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.84
 ---- batch: 020 ----
mean loss: 137.05
 ---- batch: 030 ----
mean loss: 142.30
train mean loss: 142.29
epoch train time: 0:00:01.431125
elapsed time: 0:03:57.475395
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:45:48.182307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.38
 ---- batch: 020 ----
mean loss: 133.06
 ---- batch: 030 ----
mean loss: 141.35
train mean loss: 139.28
epoch train time: 0:00:01.433421
elapsed time: 0:03:58.908983
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:45:49.615894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.33
 ---- batch: 020 ----
mean loss: 151.69
 ---- batch: 030 ----
mean loss: 146.39
train mean loss: 148.30
epoch train time: 0:00:01.431276
elapsed time: 0:04:00.340451
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:45:51.047363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.70
 ---- batch: 020 ----
mean loss: 143.90
 ---- batch: 030 ----
mean loss: 139.66
train mean loss: 143.43
epoch train time: 0:00:01.432571
elapsed time: 0:04:01.773172
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:45:52.480085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.55
 ---- batch: 020 ----
mean loss: 137.88
 ---- batch: 030 ----
mean loss: 137.34
train mean loss: 140.53
epoch train time: 0:00:01.431423
elapsed time: 0:04:03.204768
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:45:53.911680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.47
 ---- batch: 020 ----
mean loss: 145.26
 ---- batch: 030 ----
mean loss: 139.12
train mean loss: 142.56
epoch train time: 0:00:01.431341
elapsed time: 0:04:04.636270
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:45:55.343182
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.52
 ---- batch: 020 ----
mean loss: 145.78
 ---- batch: 030 ----
mean loss: 141.82
train mean loss: 142.23
epoch train time: 0:00:01.429185
elapsed time: 0:04:06.065618
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:45:56.772528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.12
 ---- batch: 020 ----
mean loss: 140.50
 ---- batch: 030 ----
mean loss: 139.37
train mean loss: 141.24
epoch train time: 0:00:01.428317
elapsed time: 0:04:07.494091
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:45:58.201004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.61
 ---- batch: 020 ----
mean loss: 144.19
 ---- batch: 030 ----
mean loss: 146.89
train mean loss: 143.43
epoch train time: 0:00:01.432160
elapsed time: 0:04:08.926439
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:45:59.633373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.24
 ---- batch: 020 ----
mean loss: 139.23
 ---- batch: 030 ----
mean loss: 138.16
train mean loss: 140.55
epoch train time: 0:00:01.432801
elapsed time: 0:04:10.359440
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:46:01.066352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.40
 ---- batch: 020 ----
mean loss: 139.28
 ---- batch: 030 ----
mean loss: 143.78
train mean loss: 142.51
epoch train time: 0:00:01.430783
elapsed time: 0:04:11.790406
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:46:02.497347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.14
 ---- batch: 020 ----
mean loss: 137.27
 ---- batch: 030 ----
mean loss: 144.38
train mean loss: 142.77
epoch train time: 0:00:01.430323
elapsed time: 0:04:13.220984
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:46:03.927919
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.73
 ---- batch: 020 ----
mean loss: 146.54
 ---- batch: 030 ----
mean loss: 143.48
train mean loss: 144.60
epoch train time: 0:00:01.431024
elapsed time: 0:04:14.652182
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:46:05.359090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.82
 ---- batch: 020 ----
mean loss: 138.73
 ---- batch: 030 ----
mean loss: 142.63
train mean loss: 141.79
epoch train time: 0:00:01.430498
elapsed time: 0:04:16.082878
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:46:06.789791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.18
 ---- batch: 020 ----
mean loss: 140.63
 ---- batch: 030 ----
mean loss: 141.11
train mean loss: 141.25
epoch train time: 0:00:01.429547
elapsed time: 0:04:17.512583
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:46:08.219498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.13
 ---- batch: 020 ----
mean loss: 138.44
 ---- batch: 030 ----
mean loss: 142.55
train mean loss: 140.89
epoch train time: 0:00:01.429181
elapsed time: 0:04:18.941938
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:46:09.648866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.40
 ---- batch: 020 ----
mean loss: 145.05
 ---- batch: 030 ----
mean loss: 136.74
train mean loss: 141.61
epoch train time: 0:00:01.430283
elapsed time: 0:04:20.372443
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:46:11.079342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.75
 ---- batch: 020 ----
mean loss: 139.96
 ---- batch: 030 ----
mean loss: 138.40
train mean loss: 138.32
epoch train time: 0:00:01.431075
elapsed time: 0:04:21.803661
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:46:12.510573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.30
 ---- batch: 020 ----
mean loss: 139.19
 ---- batch: 030 ----
mean loss: 136.83
train mean loss: 139.33
epoch train time: 0:00:01.432116
elapsed time: 0:04:23.235927
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:46:13.942840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.24
 ---- batch: 020 ----
mean loss: 144.03
 ---- batch: 030 ----
mean loss: 139.85
train mean loss: 141.61
epoch train time: 0:00:01.429513
elapsed time: 0:04:24.665604
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:46:15.372517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.97
 ---- batch: 020 ----
mean loss: 140.74
 ---- batch: 030 ----
mean loss: 139.59
train mean loss: 140.61
epoch train time: 0:00:01.430164
elapsed time: 0:04:26.095922
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:46:16.802834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.62
 ---- batch: 020 ----
mean loss: 145.64
 ---- batch: 030 ----
mean loss: 140.11
train mean loss: 144.59
epoch train time: 0:00:01.427589
elapsed time: 0:04:27.523662
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:46:18.230571
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.45
 ---- batch: 020 ----
mean loss: 140.27
 ---- batch: 030 ----
mean loss: 141.11
train mean loss: 143.04
epoch train time: 0:00:01.430040
elapsed time: 0:04:28.953861
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:46:19.660776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.01
 ---- batch: 020 ----
mean loss: 144.07
 ---- batch: 030 ----
mean loss: 138.86
train mean loss: 139.79
epoch train time: 0:00:01.430385
elapsed time: 0:04:30.384409
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:46:21.091321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.91
 ---- batch: 020 ----
mean loss: 142.69
 ---- batch: 030 ----
mean loss: 147.21
train mean loss: 143.79
epoch train time: 0:00:01.432406
elapsed time: 0:04:31.816963
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:46:22.523888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.26
 ---- batch: 020 ----
mean loss: 141.11
 ---- batch: 030 ----
mean loss: 140.60
train mean loss: 140.86
epoch train time: 0:00:01.430692
elapsed time: 0:04:33.247824
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:46:23.954759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.61
 ---- batch: 020 ----
mean loss: 138.43
 ---- batch: 030 ----
mean loss: 138.38
train mean loss: 141.09
epoch train time: 0:00:01.433412
elapsed time: 0:04:34.681410
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:46:25.388320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.73
 ---- batch: 020 ----
mean loss: 138.80
 ---- batch: 030 ----
mean loss: 140.27
train mean loss: 141.20
epoch train time: 0:00:01.433957
elapsed time: 0:04:36.115527
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:46:26.822440
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.46
 ---- batch: 020 ----
mean loss: 141.77
 ---- batch: 030 ----
mean loss: 135.31
train mean loss: 140.26
epoch train time: 0:00:01.429855
elapsed time: 0:04:37.545538
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:46:28.252447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.76
 ---- batch: 020 ----
mean loss: 140.83
 ---- batch: 030 ----
mean loss: 140.37
train mean loss: 140.05
epoch train time: 0:00:01.429097
elapsed time: 0:04:38.974822
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:46:29.681767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.19
 ---- batch: 020 ----
mean loss: 143.54
 ---- batch: 030 ----
mean loss: 141.80
train mean loss: 141.62
epoch train time: 0:00:01.429225
elapsed time: 0:04:40.404235
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:46:31.111147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.41
 ---- batch: 020 ----
mean loss: 138.04
 ---- batch: 030 ----
mean loss: 142.64
train mean loss: 141.11
epoch train time: 0:00:01.426812
elapsed time: 0:04:41.831202
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:46:32.538114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.38
 ---- batch: 020 ----
mean loss: 143.63
 ---- batch: 030 ----
mean loss: 141.43
train mean loss: 142.78
epoch train time: 0:00:01.435408
elapsed time: 0:04:43.266793
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:46:33.973720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.58
 ---- batch: 020 ----
mean loss: 144.48
 ---- batch: 030 ----
mean loss: 147.85
train mean loss: 145.89
epoch train time: 0:00:01.431430
elapsed time: 0:04:44.698400
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:46:35.405329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.19
 ---- batch: 020 ----
mean loss: 136.90
 ---- batch: 030 ----
mean loss: 142.80
train mean loss: 140.96
epoch train time: 0:00:01.448054
elapsed time: 0:04:46.146635
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:46:36.853549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.51
 ---- batch: 020 ----
mean loss: 139.08
 ---- batch: 030 ----
mean loss: 142.11
train mean loss: 140.03
epoch train time: 0:00:01.432506
elapsed time: 0:04:47.579309
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:46:38.286222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.00
 ---- batch: 020 ----
mean loss: 135.75
 ---- batch: 030 ----
mean loss: 141.29
train mean loss: 138.70
epoch train time: 0:00:01.429106
elapsed time: 0:04:49.008599
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:46:39.715515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.32
 ---- batch: 020 ----
mean loss: 144.02
 ---- batch: 030 ----
mean loss: 136.13
train mean loss: 139.89
epoch train time: 0:00:01.430957
elapsed time: 0:04:50.439718
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:46:41.146650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.53
 ---- batch: 020 ----
mean loss: 143.88
 ---- batch: 030 ----
mean loss: 138.37
train mean loss: 140.38
epoch train time: 0:00:01.431860
elapsed time: 0:04:51.871750
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:46:42.578661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.14
 ---- batch: 020 ----
mean loss: 140.74
 ---- batch: 030 ----
mean loss: 137.13
train mean loss: 140.85
epoch train time: 0:00:01.435755
elapsed time: 0:04:53.307659
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:46:44.014570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.77
 ---- batch: 020 ----
mean loss: 138.96
 ---- batch: 030 ----
mean loss: 140.28
train mean loss: 139.45
epoch train time: 0:00:01.433477
elapsed time: 0:04:54.741290
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:46:45.448204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.20
 ---- batch: 020 ----
mean loss: 141.28
 ---- batch: 030 ----
mean loss: 143.45
train mean loss: 140.91
epoch train time: 0:00:01.431245
elapsed time: 0:04:56.172693
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:46:46.879603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.66
 ---- batch: 020 ----
mean loss: 142.38
 ---- batch: 030 ----
mean loss: 144.32
train mean loss: 142.02
epoch train time: 0:00:01.431623
elapsed time: 0:04:57.604479
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:46:48.311388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.65
 ---- batch: 020 ----
mean loss: 139.57
 ---- batch: 030 ----
mean loss: 145.84
train mean loss: 141.62
epoch train time: 0:00:01.432756
elapsed time: 0:04:59.037390
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:46:49.744319
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.62
 ---- batch: 020 ----
mean loss: 139.42
 ---- batch: 030 ----
mean loss: 138.91
train mean loss: 138.97
epoch train time: 0:00:01.429873
elapsed time: 0:05:00.467530
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:46:51.174470
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.94
 ---- batch: 020 ----
mean loss: 137.80
 ---- batch: 030 ----
mean loss: 136.41
train mean loss: 135.93
epoch train time: 0:00:01.433450
elapsed time: 0:05:01.901161
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:46:52.608070
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.66
 ---- batch: 020 ----
mean loss: 136.29
 ---- batch: 030 ----
mean loss: 139.88
train mean loss: 136.57
epoch train time: 0:00:01.435309
elapsed time: 0:05:03.336630
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:46:54.043546
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 143.14
 ---- batch: 020 ----
mean loss: 135.06
 ---- batch: 030 ----
mean loss: 136.16
train mean loss: 137.83
epoch train time: 0:00:01.432537
elapsed time: 0:05:04.769324
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:46:55.476237
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.93
 ---- batch: 020 ----
mean loss: 135.53
 ---- batch: 030 ----
mean loss: 138.00
train mean loss: 138.38
epoch train time: 0:00:01.427615
elapsed time: 0:05:06.197101
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:46:56.904016
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.84
 ---- batch: 020 ----
mean loss: 136.84
 ---- batch: 030 ----
mean loss: 134.06
train mean loss: 135.64
epoch train time: 0:00:01.434197
elapsed time: 0:05:07.631474
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:46:58.338385
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.78
 ---- batch: 020 ----
mean loss: 138.59
 ---- batch: 030 ----
mean loss: 138.35
train mean loss: 138.68
epoch train time: 0:00:01.427374
elapsed time: 0:05:09.059006
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:46:59.765931
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.80
 ---- batch: 020 ----
mean loss: 132.27
 ---- batch: 030 ----
mean loss: 137.09
train mean loss: 137.12
epoch train time: 0:00:01.432069
elapsed time: 0:05:10.491247
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:47:01.198180
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.77
 ---- batch: 020 ----
mean loss: 134.23
 ---- batch: 030 ----
mean loss: 140.29
train mean loss: 136.26
epoch train time: 0:00:01.424938
elapsed time: 0:05:11.916408
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:47:02.623340
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.53
 ---- batch: 020 ----
mean loss: 137.98
 ---- batch: 030 ----
mean loss: 138.14
train mean loss: 137.92
epoch train time: 0:00:01.429569
elapsed time: 0:05:13.346191
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:47:04.053105
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.45
 ---- batch: 020 ----
mean loss: 135.93
 ---- batch: 030 ----
mean loss: 137.74
train mean loss: 137.84
epoch train time: 0:00:01.425835
elapsed time: 0:05:14.772185
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:47:05.479096
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.03
 ---- batch: 020 ----
mean loss: 138.78
 ---- batch: 030 ----
mean loss: 136.00
train mean loss: 137.30
epoch train time: 0:00:01.430831
elapsed time: 0:05:16.203176
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:47:06.910101
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.36
 ---- batch: 020 ----
mean loss: 131.31
 ---- batch: 030 ----
mean loss: 139.14
train mean loss: 136.45
epoch train time: 0:00:01.429583
elapsed time: 0:05:17.632933
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:47:08.339845
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.13
 ---- batch: 020 ----
mean loss: 137.39
 ---- batch: 030 ----
mean loss: 136.19
train mean loss: 138.53
epoch train time: 0:00:01.426113
elapsed time: 0:05:19.059266
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:47:09.766177
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.02
 ---- batch: 020 ----
mean loss: 132.97
 ---- batch: 030 ----
mean loss: 139.24
train mean loss: 136.53
epoch train time: 0:00:01.431446
elapsed time: 0:05:20.490926
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:47:11.197867
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.36
 ---- batch: 020 ----
mean loss: 135.27
 ---- batch: 030 ----
mean loss: 135.41
train mean loss: 135.74
epoch train time: 0:00:01.428281
elapsed time: 0:05:21.919405
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:47:12.626316
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.77
 ---- batch: 020 ----
mean loss: 139.12
 ---- batch: 030 ----
mean loss: 141.47
train mean loss: 138.32
epoch train time: 0:00:01.428161
elapsed time: 0:05:23.347722
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:47:14.054634
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.22
 ---- batch: 020 ----
mean loss: 136.25
 ---- batch: 030 ----
mean loss: 136.76
train mean loss: 138.96
epoch train time: 0:00:01.431559
elapsed time: 0:05:24.779434
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:47:15.486342
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.99
 ---- batch: 020 ----
mean loss: 136.35
 ---- batch: 030 ----
mean loss: 140.01
train mean loss: 137.15
epoch train time: 0:00:01.429951
elapsed time: 0:05:26.209588
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:47:16.916533
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.31
 ---- batch: 020 ----
mean loss: 138.24
 ---- batch: 030 ----
mean loss: 136.64
train mean loss: 135.37
epoch train time: 0:00:01.429493
elapsed time: 0:05:27.639278
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:47:18.346204
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.72
 ---- batch: 020 ----
mean loss: 136.31
 ---- batch: 030 ----
mean loss: 137.86
train mean loss: 138.31
epoch train time: 0:00:01.428883
elapsed time: 0:05:29.068374
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:47:19.775336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.56
 ---- batch: 020 ----
mean loss: 138.07
 ---- batch: 030 ----
mean loss: 136.32
train mean loss: 138.10
epoch train time: 0:00:01.431553
elapsed time: 0:05:30.500135
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:47:21.207047
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.89
 ---- batch: 020 ----
mean loss: 137.13
 ---- batch: 030 ----
mean loss: 140.10
train mean loss: 136.88
epoch train time: 0:00:01.437070
elapsed time: 0:05:31.937393
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:47:22.644336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.18
 ---- batch: 020 ----
mean loss: 136.46
 ---- batch: 030 ----
mean loss: 137.72
train mean loss: 137.73
epoch train time: 0:00:01.423095
elapsed time: 0:05:33.360678
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:47:24.067590
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.11
 ---- batch: 020 ----
mean loss: 140.23
 ---- batch: 030 ----
mean loss: 139.27
train mean loss: 138.02
epoch train time: 0:00:01.429377
elapsed time: 0:05:34.790243
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:47:25.497154
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.33
 ---- batch: 020 ----
mean loss: 138.78
 ---- batch: 030 ----
mean loss: 140.66
train mean loss: 138.65
epoch train time: 0:00:01.430789
elapsed time: 0:05:36.221198
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:47:26.928112
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 142.65
 ---- batch: 020 ----
mean loss: 143.80
 ---- batch: 030 ----
mean loss: 135.78
train mean loss: 140.31
epoch train time: 0:00:01.430981
elapsed time: 0:05:37.652358
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:47:28.359286
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.92
 ---- batch: 020 ----
mean loss: 138.14
 ---- batch: 030 ----
mean loss: 137.84
train mean loss: 137.20
epoch train time: 0:00:01.431868
elapsed time: 0:05:39.084435
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:47:29.791349
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.42
 ---- batch: 020 ----
mean loss: 138.46
 ---- batch: 030 ----
mean loss: 135.05
train mean loss: 136.57
epoch train time: 0:00:01.426293
elapsed time: 0:05:40.510919
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:47:31.217832
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.19
 ---- batch: 020 ----
mean loss: 141.97
 ---- batch: 030 ----
mean loss: 133.53
train mean loss: 138.31
epoch train time: 0:00:01.433159
elapsed time: 0:05:41.944237
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:47:32.651151
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.15
 ---- batch: 020 ----
mean loss: 135.50
 ---- batch: 030 ----
mean loss: 136.92
train mean loss: 136.14
epoch train time: 0:00:01.431913
elapsed time: 0:05:43.376337
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:47:34.083249
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.39
 ---- batch: 020 ----
mean loss: 140.42
 ---- batch: 030 ----
mean loss: 134.88
train mean loss: 138.48
epoch train time: 0:00:01.431891
elapsed time: 0:05:44.808402
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:47:35.515321
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.82
 ---- batch: 020 ----
mean loss: 139.74
 ---- batch: 030 ----
mean loss: 135.55
train mean loss: 138.12
epoch train time: 0:00:01.427956
elapsed time: 0:05:46.236542
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:47:36.943443
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.05
 ---- batch: 020 ----
mean loss: 136.27
 ---- batch: 030 ----
mean loss: 134.90
train mean loss: 136.80
epoch train time: 0:00:01.431743
elapsed time: 0:05:47.668448
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:47:38.375363
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.09
 ---- batch: 020 ----
mean loss: 135.80
 ---- batch: 030 ----
mean loss: 137.16
train mean loss: 137.34
epoch train time: 0:00:01.431165
elapsed time: 0:05:49.099782
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:47:39.806721
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.17
 ---- batch: 020 ----
mean loss: 134.41
 ---- batch: 030 ----
mean loss: 137.86
train mean loss: 137.29
epoch train time: 0:00:01.430515
elapsed time: 0:05:50.530526
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:47:41.237464
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.29
 ---- batch: 020 ----
mean loss: 137.08
 ---- batch: 030 ----
mean loss: 140.21
train mean loss: 138.03
epoch train time: 0:00:01.430007
elapsed time: 0:05:51.960725
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:47:42.667655
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.55
 ---- batch: 020 ----
mean loss: 138.70
 ---- batch: 030 ----
mean loss: 136.28
train mean loss: 136.97
epoch train time: 0:00:01.431210
elapsed time: 0:05:53.392118
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:47:44.099029
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.26
 ---- batch: 020 ----
mean loss: 134.41
 ---- batch: 030 ----
mean loss: 137.41
train mean loss: 136.83
epoch train time: 0:00:01.429900
elapsed time: 0:05:54.822171
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:47:45.529082
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.99
 ---- batch: 020 ----
mean loss: 141.69
 ---- batch: 030 ----
mean loss: 138.54
train mean loss: 138.99
epoch train time: 0:00:01.431111
elapsed time: 0:05:56.253440
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:47:46.960353
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.60
 ---- batch: 020 ----
mean loss: 137.17
 ---- batch: 030 ----
mean loss: 135.74
train mean loss: 135.80
epoch train time: 0:00:01.427565
elapsed time: 0:05:57.681158
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:47:48.388072
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.89
 ---- batch: 020 ----
mean loss: 137.53
 ---- batch: 030 ----
mean loss: 132.57
train mean loss: 134.76
epoch train time: 0:00:01.435454
elapsed time: 0:05:59.116785
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:47:49.823696
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.58
 ---- batch: 020 ----
mean loss: 138.81
 ---- batch: 030 ----
mean loss: 136.61
train mean loss: 136.88
epoch train time: 0:00:01.434603
elapsed time: 0:06:00.551552
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:47:51.258465
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.21
 ---- batch: 020 ----
mean loss: 141.14
 ---- batch: 030 ----
mean loss: 130.90
train mean loss: 137.73
epoch train time: 0:00:01.427522
elapsed time: 0:06:01.979245
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:47:52.686160
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.27
 ---- batch: 020 ----
mean loss: 134.75
 ---- batch: 030 ----
mean loss: 139.75
train mean loss: 137.22
epoch train time: 0:00:01.425563
elapsed time: 0:06:03.404972
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:47:54.111885
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.41
 ---- batch: 020 ----
mean loss: 137.72
 ---- batch: 030 ----
mean loss: 136.39
train mean loss: 137.91
epoch train time: 0:00:01.428339
elapsed time: 0:06:04.833466
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:47:55.540379
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.60
 ---- batch: 020 ----
mean loss: 134.16
 ---- batch: 030 ----
mean loss: 136.12
train mean loss: 136.72
epoch train time: 0:00:01.427524
elapsed time: 0:06:06.261157
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:47:56.968086
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.73
 ---- batch: 020 ----
mean loss: 136.12
 ---- batch: 030 ----
mean loss: 134.80
train mean loss: 137.35
epoch train time: 0:00:01.426678
elapsed time: 0:06:07.688005
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:47:58.394945
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.05
 ---- batch: 020 ----
mean loss: 143.03
 ---- batch: 030 ----
mean loss: 136.37
train mean loss: 137.14
epoch train time: 0:00:01.431291
elapsed time: 0:06:09.123161
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_1/checkpoint.pth.tar
**** end time: 2019-09-27 15:47:59.830038 ****
