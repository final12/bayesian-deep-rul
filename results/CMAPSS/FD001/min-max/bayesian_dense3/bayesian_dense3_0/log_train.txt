Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_0', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29509
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:05:52.364630 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:05:52.374558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3784.70
 ---- batch: 020 ----
mean loss: 3420.28
 ---- batch: 030 ----
mean loss: 3255.55
train mean loss: 3433.94
epoch train time: 0:00:13.057208
elapsed time: 0:00:13.074204
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:06:05.438875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2973.81
 ---- batch: 020 ----
mean loss: 2783.03
 ---- batch: 030 ----
mean loss: 2668.54
train mean loss: 2779.38
epoch train time: 0:00:00.594595
elapsed time: 0:00:13.669092
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:06:06.033838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2470.99
 ---- batch: 020 ----
mean loss: 2364.26
 ---- batch: 030 ----
mean loss: 2289.50
train mean loss: 2349.77
epoch train time: 0:00:00.589984
elapsed time: 0:00:14.259439
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:06:06.624171
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2157.83
 ---- batch: 020 ----
mean loss: 2080.21
 ---- batch: 030 ----
mean loss: 2049.72
train mean loss: 2088.18
epoch train time: 0:00:00.581836
elapsed time: 0:00:14.841595
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:06:07.206321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1954.01
 ---- batch: 020 ----
mean loss: 1902.55
 ---- batch: 030 ----
mean loss: 1946.42
train mean loss: 1925.26
epoch train time: 0:00:00.582024
elapsed time: 0:00:15.423953
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:06:07.788687
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1848.41
 ---- batch: 020 ----
mean loss: 1811.24
 ---- batch: 030 ----
mean loss: 1797.66
train mean loss: 1813.91
epoch train time: 0:00:00.593570
elapsed time: 0:00:16.017881
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:06:08.382612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1760.28
 ---- batch: 020 ----
mean loss: 1706.44
 ---- batch: 030 ----
mean loss: 1684.22
train mean loss: 1710.89
epoch train time: 0:00:00.590018
elapsed time: 0:00:16.608245
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:06:08.972987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1649.90
 ---- batch: 020 ----
mean loss: 1639.96
 ---- batch: 030 ----
mean loss: 1578.50
train mean loss: 1616.24
epoch train time: 0:00:00.590100
elapsed time: 0:00:17.198684
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:06:09.563418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1557.56
 ---- batch: 020 ----
mean loss: 1532.27
 ---- batch: 030 ----
mean loss: 1515.73
train mean loss: 1527.41
epoch train time: 0:00:00.591736
elapsed time: 0:00:17.790919
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:06:10.155619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1483.17
 ---- batch: 020 ----
mean loss: 1452.09
 ---- batch: 030 ----
mean loss: 1427.41
train mean loss: 1445.68
epoch train time: 0:00:00.603815
elapsed time: 0:00:18.395056
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:06:10.759811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1382.26
 ---- batch: 020 ----
mean loss: 1386.81
 ---- batch: 030 ----
mean loss: 1351.71
train mean loss: 1367.72
epoch train time: 0:00:00.601694
elapsed time: 0:00:18.997186
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:06:11.361933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1318.26
 ---- batch: 020 ----
mean loss: 1312.70
 ---- batch: 030 ----
mean loss: 1268.16
train mean loss: 1299.09
epoch train time: 0:00:00.590007
elapsed time: 0:00:19.587533
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:06:11.952264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1257.67
 ---- batch: 020 ----
mean loss: 1223.51
 ---- batch: 030 ----
mean loss: 1229.39
train mean loss: 1228.97
epoch train time: 0:00:00.576074
elapsed time: 0:00:20.163941
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:06:12.528678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1212.89
 ---- batch: 020 ----
mean loss: 1177.86
 ---- batch: 030 ----
mean loss: 1138.97
train mean loss: 1167.41
epoch train time: 0:00:00.596267
elapsed time: 0:00:20.760553
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:06:13.125286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1124.41
 ---- batch: 020 ----
mean loss: 1111.91
 ---- batch: 030 ----
mean loss: 1098.24
train mean loss: 1107.49
epoch train time: 0:00:00.588432
elapsed time: 0:00:21.349333
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:06:13.714073
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1068.20
 ---- batch: 020 ----
mean loss: 1050.31
 ---- batch: 030 ----
mean loss: 1045.66
train mean loss: 1051.22
epoch train time: 0:00:00.599925
elapsed time: 0:00:21.949778
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:06:14.314500
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1020.35
 ---- batch: 020 ----
mean loss: 998.24
 ---- batch: 030 ----
mean loss: 984.55
train mean loss: 996.68
epoch train time: 0:00:00.601778
elapsed time: 0:00:22.551906
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:06:14.916653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 962.44
 ---- batch: 020 ----
mean loss: 948.83
 ---- batch: 030 ----
mean loss: 914.82
train mean loss: 942.30
epoch train time: 0:00:00.610190
elapsed time: 0:00:23.162582
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:06:15.527330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 915.49
 ---- batch: 020 ----
mean loss: 902.37
 ---- batch: 030 ----
mean loss: 877.21
train mean loss: 894.03
epoch train time: 0:00:00.595880
elapsed time: 0:00:23.758949
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:06:16.123659
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 862.95
 ---- batch: 020 ----
mean loss: 842.09
 ---- batch: 030 ----
mean loss: 833.75
train mean loss: 843.15
epoch train time: 0:00:00.605153
elapsed time: 0:00:24.364490
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:06:16.729298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 802.84
 ---- batch: 020 ----
mean loss: 799.70
 ---- batch: 030 ----
mean loss: 786.94
train mean loss: 797.21
epoch train time: 0:00:00.590258
elapsed time: 0:00:24.955180
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:06:17.319930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 760.88
 ---- batch: 020 ----
mean loss: 774.57
 ---- batch: 030 ----
mean loss: 740.90
train mean loss: 752.30
epoch train time: 0:00:00.590577
elapsed time: 0:00:25.546171
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:06:17.910943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 726.88
 ---- batch: 020 ----
mean loss: 710.74
 ---- batch: 030 ----
mean loss: 703.00
train mean loss: 708.09
epoch train time: 0:00:00.595950
elapsed time: 0:00:26.142555
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:06:18.507285
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 671.60
 ---- batch: 020 ----
mean loss: 686.35
 ---- batch: 030 ----
mean loss: 675.70
train mean loss: 671.67
epoch train time: 0:00:00.595950
elapsed time: 0:00:26.738873
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:06:19.103641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 657.10
 ---- batch: 020 ----
mean loss: 644.90
 ---- batch: 030 ----
mean loss: 620.23
train mean loss: 635.40
epoch train time: 0:00:00.597426
elapsed time: 0:00:27.336723
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:06:19.701476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 604.46
 ---- batch: 020 ----
mean loss: 615.44
 ---- batch: 030 ----
mean loss: 595.29
train mean loss: 600.79
epoch train time: 0:00:00.603484
elapsed time: 0:00:27.940567
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:06:20.305305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 581.98
 ---- batch: 020 ----
mean loss: 576.59
 ---- batch: 030 ----
mean loss: 551.42
train mean loss: 570.00
epoch train time: 0:00:00.593893
elapsed time: 0:00:28.534810
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:06:20.899551
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 555.32
 ---- batch: 020 ----
mean loss: 541.58
 ---- batch: 030 ----
mean loss: 531.42
train mean loss: 540.75
epoch train time: 0:00:00.589534
elapsed time: 0:00:29.124731
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:06:21.489473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 511.09
 ---- batch: 020 ----
mean loss: 525.81
 ---- batch: 030 ----
mean loss: 501.30
train mean loss: 509.01
epoch train time: 0:00:00.587662
elapsed time: 0:00:29.712757
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:06:22.077494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 489.30
 ---- batch: 020 ----
mean loss: 482.68
 ---- batch: 030 ----
mean loss: 476.71
train mean loss: 482.76
epoch train time: 0:00:00.590258
elapsed time: 0:00:30.303388
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:06:22.668126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 464.20
 ---- batch: 020 ----
mean loss: 449.87
 ---- batch: 030 ----
mean loss: 466.56
train mean loss: 457.11
epoch train time: 0:00:00.594009
elapsed time: 0:00:30.897743
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:06:23.262475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 444.48
 ---- batch: 020 ----
mean loss: 438.73
 ---- batch: 030 ----
mean loss: 433.04
train mean loss: 435.60
epoch train time: 0:00:00.586091
elapsed time: 0:00:31.484229
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:06:23.848992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 420.13
 ---- batch: 020 ----
mean loss: 409.21
 ---- batch: 030 ----
mean loss: 400.34
train mean loss: 411.49
epoch train time: 0:00:00.575676
elapsed time: 0:00:32.060277
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:06:24.425017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 397.85
 ---- batch: 020 ----
mean loss: 403.19
 ---- batch: 030 ----
mean loss: 383.86
train mean loss: 391.34
epoch train time: 0:00:00.589049
elapsed time: 0:00:32.649698
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:06:25.014429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.24
 ---- batch: 020 ----
mean loss: 369.95
 ---- batch: 030 ----
mean loss: 368.76
train mean loss: 370.03
epoch train time: 0:00:00.589195
elapsed time: 0:00:33.239207
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:06:25.603941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 359.38
 ---- batch: 020 ----
mean loss: 351.88
 ---- batch: 030 ----
mean loss: 356.06
train mean loss: 354.42
epoch train time: 0:00:00.596201
elapsed time: 0:00:33.835727
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:06:26.200473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 345.14
 ---- batch: 020 ----
mean loss: 337.56
 ---- batch: 030 ----
mean loss: 332.51
train mean loss: 336.43
epoch train time: 0:00:00.591127
elapsed time: 0:00:34.427334
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:06:26.792117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 326.97
 ---- batch: 020 ----
mean loss: 321.18
 ---- batch: 030 ----
mean loss: 318.87
train mean loss: 322.19
epoch train time: 0:00:00.595726
elapsed time: 0:00:35.023438
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:06:27.388169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.83
 ---- batch: 020 ----
mean loss: 306.87
 ---- batch: 030 ----
mean loss: 303.53
train mean loss: 305.80
epoch train time: 0:00:00.582129
elapsed time: 0:00:35.605890
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:06:27.970615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.52
 ---- batch: 020 ----
mean loss: 287.27
 ---- batch: 030 ----
mean loss: 288.42
train mean loss: 290.22
epoch train time: 0:00:00.588778
elapsed time: 0:00:36.195103
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:06:28.559839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.11
 ---- batch: 020 ----
mean loss: 271.06
 ---- batch: 030 ----
mean loss: 276.57
train mean loss: 277.70
epoch train time: 0:00:00.597158
elapsed time: 0:00:36.792635
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:06:29.157361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.40
 ---- batch: 020 ----
mean loss: 261.73
 ---- batch: 030 ----
mean loss: 271.19
train mean loss: 266.44
epoch train time: 0:00:00.599205
elapsed time: 0:00:37.392230
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:06:29.756977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.83
 ---- batch: 020 ----
mean loss: 253.13
 ---- batch: 030 ----
mean loss: 245.70
train mean loss: 254.03
epoch train time: 0:00:00.584247
elapsed time: 0:00:37.976938
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:06:30.341727
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.35
 ---- batch: 020 ----
mean loss: 243.43
 ---- batch: 030 ----
mean loss: 244.00
train mean loss: 242.92
epoch train time: 0:00:00.593659
elapsed time: 0:00:38.571003
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:06:30.935740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.26
 ---- batch: 020 ----
mean loss: 229.77
 ---- batch: 030 ----
mean loss: 233.98
train mean loss: 232.22
epoch train time: 0:00:00.591820
elapsed time: 0:00:39.163247
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:06:31.528038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.87
 ---- batch: 020 ----
mean loss: 218.70
 ---- batch: 030 ----
mean loss: 223.14
train mean loss: 222.92
epoch train time: 0:00:00.601150
elapsed time: 0:00:39.764790
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:06:32.129520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.00
 ---- batch: 020 ----
mean loss: 217.64
 ---- batch: 030 ----
mean loss: 212.12
train mean loss: 214.06
epoch train time: 0:00:00.611136
elapsed time: 0:00:40.376307
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:06:32.741046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.28
 ---- batch: 020 ----
mean loss: 205.56
 ---- batch: 030 ----
mean loss: 209.30
train mean loss: 205.60
epoch train time: 0:00:00.604105
elapsed time: 0:00:40.980778
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:06:33.345518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 201.20
 ---- batch: 020 ----
mean loss: 197.10
 ---- batch: 030 ----
mean loss: 198.64
train mean loss: 197.77
epoch train time: 0:00:00.620326
elapsed time: 0:00:41.601489
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:06:33.966224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.93
 ---- batch: 020 ----
mean loss: 194.09
 ---- batch: 030 ----
mean loss: 188.06
train mean loss: 189.84
epoch train time: 0:00:00.599785
elapsed time: 0:00:42.201637
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:06:34.566370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.77
 ---- batch: 020 ----
mean loss: 180.95
 ---- batch: 030 ----
mean loss: 183.13
train mean loss: 184.06
epoch train time: 0:00:00.590570
elapsed time: 0:00:42.792538
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:06:35.157301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.73
 ---- batch: 020 ----
mean loss: 178.61
 ---- batch: 030 ----
mean loss: 175.81
train mean loss: 177.82
epoch train time: 0:00:00.588603
elapsed time: 0:00:43.381532
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:06:35.746266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.65
 ---- batch: 020 ----
mean loss: 169.80
 ---- batch: 030 ----
mean loss: 171.12
train mean loss: 171.70
epoch train time: 0:00:00.589410
elapsed time: 0:00:43.971291
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:06:36.336028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.14
 ---- batch: 020 ----
mean loss: 171.13
 ---- batch: 030 ----
mean loss: 165.80
train mean loss: 167.25
epoch train time: 0:00:00.591460
elapsed time: 0:00:44.563105
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:06:36.927843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.16
 ---- batch: 020 ----
mean loss: 159.33
 ---- batch: 030 ----
mean loss: 159.99
train mean loss: 159.99
epoch train time: 0:00:00.602572
elapsed time: 0:00:45.166101
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:06:37.530868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.97
 ---- batch: 020 ----
mean loss: 156.25
 ---- batch: 030 ----
mean loss: 153.26
train mean loss: 155.96
epoch train time: 0:00:00.595815
elapsed time: 0:00:45.762405
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:06:38.127146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.85
 ---- batch: 020 ----
mean loss: 154.28
 ---- batch: 030 ----
mean loss: 148.35
train mean loss: 150.54
epoch train time: 0:00:00.602292
elapsed time: 0:00:46.365113
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:06:38.729906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.28
 ---- batch: 020 ----
mean loss: 147.28
 ---- batch: 030 ----
mean loss: 149.84
train mean loss: 147.45
epoch train time: 0:00:00.584764
elapsed time: 0:00:46.950274
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:06:39.315009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.45
 ---- batch: 020 ----
mean loss: 143.55
 ---- batch: 030 ----
mean loss: 143.17
train mean loss: 142.97
epoch train time: 0:00:00.608018
elapsed time: 0:00:47.558651
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:06:39.923385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.02
 ---- batch: 020 ----
mean loss: 135.74
 ---- batch: 030 ----
mean loss: 137.91
train mean loss: 139.33
epoch train time: 0:00:00.597663
elapsed time: 0:00:48.156670
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:06:40.521416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.46
 ---- batch: 020 ----
mean loss: 134.56
 ---- batch: 030 ----
mean loss: 133.89
train mean loss: 135.22
epoch train time: 0:00:00.597988
elapsed time: 0:00:48.755047
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:06:41.119796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.09
 ---- batch: 020 ----
mean loss: 131.01
 ---- batch: 030 ----
mean loss: 133.94
train mean loss: 132.39
epoch train time: 0:00:00.619979
elapsed time: 0:00:49.375415
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:06:41.740149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.14
 ---- batch: 020 ----
mean loss: 130.02
 ---- batch: 030 ----
mean loss: 125.66
train mean loss: 128.98
epoch train time: 0:00:00.602094
elapsed time: 0:00:49.977876
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:06:42.342614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.80
 ---- batch: 020 ----
mean loss: 129.37
 ---- batch: 030 ----
mean loss: 126.72
train mean loss: 127.40
epoch train time: 0:00:00.597741
elapsed time: 0:00:50.576012
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:06:42.940781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.92
 ---- batch: 020 ----
mean loss: 122.53
 ---- batch: 030 ----
mean loss: 123.48
train mean loss: 123.99
epoch train time: 0:00:00.582523
elapsed time: 0:00:51.158922
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:06:43.523659
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.47
 ---- batch: 020 ----
mean loss: 121.36
 ---- batch: 030 ----
mean loss: 122.49
train mean loss: 120.98
epoch train time: 0:00:00.608252
elapsed time: 0:00:51.767538
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:06:44.132275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.82
 ---- batch: 020 ----
mean loss: 118.40
 ---- batch: 030 ----
mean loss: 116.44
train mean loss: 118.39
epoch train time: 0:00:00.600682
elapsed time: 0:00:52.368647
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:06:44.733414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.91
 ---- batch: 020 ----
mean loss: 116.85
 ---- batch: 030 ----
mean loss: 117.05
train mean loss: 116.50
epoch train time: 0:00:00.606822
elapsed time: 0:00:52.975945
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:06:45.340679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.90
 ---- batch: 020 ----
mean loss: 110.87
 ---- batch: 030 ----
mean loss: 112.28
train mean loss: 114.43
epoch train time: 0:00:00.607317
elapsed time: 0:00:53.583725
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:06:45.948460
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.16
 ---- batch: 020 ----
mean loss: 111.49
 ---- batch: 030 ----
mean loss: 111.87
train mean loss: 112.50
epoch train time: 0:00:00.593432
elapsed time: 0:00:54.177635
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:06:46.542374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.61
 ---- batch: 020 ----
mean loss: 110.56
 ---- batch: 030 ----
mean loss: 111.53
train mean loss: 110.43
epoch train time: 0:00:00.603920
elapsed time: 0:00:54.781905
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:06:47.146712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.51
 ---- batch: 020 ----
mean loss: 109.22
 ---- batch: 030 ----
mean loss: 106.54
train mean loss: 108.63
epoch train time: 0:00:00.595263
elapsed time: 0:00:55.377637
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:06:47.742370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.01
 ---- batch: 020 ----
mean loss: 105.67
 ---- batch: 030 ----
mean loss: 107.39
train mean loss: 106.14
epoch train time: 0:00:00.607791
elapsed time: 0:00:55.985769
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:06:48.350506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.12
 ---- batch: 020 ----
mean loss: 105.60
 ---- batch: 030 ----
mean loss: 105.27
train mean loss: 105.51
epoch train time: 0:00:00.602910
elapsed time: 0:00:56.589061
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:06:48.953802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.08
 ---- batch: 020 ----
mean loss: 103.83
 ---- batch: 030 ----
mean loss: 103.71
train mean loss: 102.59
epoch train time: 0:00:00.605919
elapsed time: 0:00:57.195410
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:06:49.560169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.50
 ---- batch: 020 ----
mean loss: 100.63
 ---- batch: 030 ----
mean loss: 104.24
train mean loss: 101.62
epoch train time: 0:00:00.586208
elapsed time: 0:00:57.782008
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:06:50.146748
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.18
 ---- batch: 020 ----
mean loss: 98.52
 ---- batch: 030 ----
mean loss: 98.33
train mean loss: 100.44
epoch train time: 0:00:00.582272
elapsed time: 0:00:58.364690
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:06:50.729415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.26
 ---- batch: 020 ----
mean loss: 97.42
 ---- batch: 030 ----
mean loss: 100.01
train mean loss: 98.28
epoch train time: 0:00:00.604670
elapsed time: 0:00:58.969709
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:06:51.334473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.68
 ---- batch: 020 ----
mean loss: 97.93
 ---- batch: 030 ----
mean loss: 100.13
train mean loss: 98.19
epoch train time: 0:00:00.599176
elapsed time: 0:00:59.569265
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:06:51.933998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.18
 ---- batch: 020 ----
mean loss: 96.53
 ---- batch: 030 ----
mean loss: 95.70
train mean loss: 95.57
epoch train time: 0:00:00.592834
elapsed time: 0:01:00.162543
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:06:52.527282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.19
 ---- batch: 020 ----
mean loss: 95.21
 ---- batch: 030 ----
mean loss: 93.98
train mean loss: 96.13
epoch train time: 0:00:00.594621
elapsed time: 0:01:00.757535
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:06:53.122271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.61
 ---- batch: 020 ----
mean loss: 96.68
 ---- batch: 030 ----
mean loss: 93.63
train mean loss: 93.66
epoch train time: 0:00:00.597122
elapsed time: 0:01:01.355021
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:06:53.719759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.05
 ---- batch: 020 ----
mean loss: 96.62
 ---- batch: 030 ----
mean loss: 90.68
train mean loss: 93.55
epoch train time: 0:00:00.591703
elapsed time: 0:01:01.947071
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:06:54.311807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.91
 ---- batch: 020 ----
mean loss: 91.27
 ---- batch: 030 ----
mean loss: 92.50
train mean loss: 92.86
epoch train time: 0:00:00.585503
elapsed time: 0:01:02.532941
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:06:54.897706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.33
 ---- batch: 020 ----
mean loss: 93.13
 ---- batch: 030 ----
mean loss: 90.98
train mean loss: 90.76
epoch train time: 0:00:00.603287
elapsed time: 0:01:03.136745
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:06:55.501490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.14
 ---- batch: 020 ----
mean loss: 91.32
 ---- batch: 030 ----
mean loss: 89.90
train mean loss: 90.06
epoch train time: 0:00:00.607851
elapsed time: 0:01:03.745128
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:06:56.109875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.33
 ---- batch: 020 ----
mean loss: 91.47
 ---- batch: 030 ----
mean loss: 92.19
train mean loss: 90.57
epoch train time: 0:00:00.598855
elapsed time: 0:01:04.344399
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:06:56.709132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.59
 ---- batch: 020 ----
mean loss: 89.70
 ---- batch: 030 ----
mean loss: 84.85
train mean loss: 88.85
epoch train time: 0:00:00.587498
elapsed time: 0:01:04.932261
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:06:57.297057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.21
 ---- batch: 020 ----
mean loss: 83.90
 ---- batch: 030 ----
mean loss: 87.56
train mean loss: 87.44
epoch train time: 0:00:00.593919
elapsed time: 0:01:05.526620
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:06:57.891353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.86
 ---- batch: 020 ----
mean loss: 84.20
 ---- batch: 030 ----
mean loss: 88.36
train mean loss: 86.79
epoch train time: 0:00:00.579535
elapsed time: 0:01:06.106477
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:06:58.471208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.51
 ---- batch: 020 ----
mean loss: 85.54
 ---- batch: 030 ----
mean loss: 86.48
train mean loss: 86.20
epoch train time: 0:00:00.583516
elapsed time: 0:01:06.690317
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:06:59.055076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.75
 ---- batch: 020 ----
mean loss: 86.64
 ---- batch: 030 ----
mean loss: 84.60
train mean loss: 85.16
epoch train time: 0:00:00.585115
elapsed time: 0:01:07.275863
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:06:59.640593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.34
 ---- batch: 020 ----
mean loss: 84.02
 ---- batch: 030 ----
mean loss: 85.43
train mean loss: 85.02
epoch train time: 0:00:00.603597
elapsed time: 0:01:07.879821
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:07:00.244567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.11
 ---- batch: 020 ----
mean loss: 83.22
 ---- batch: 030 ----
mean loss: 82.34
train mean loss: 83.19
epoch train time: 0:00:00.594047
elapsed time: 0:01:08.474242
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:07:00.839031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.19
 ---- batch: 020 ----
mean loss: 82.18
 ---- batch: 030 ----
mean loss: 84.19
train mean loss: 83.45
epoch train time: 0:00:00.590393
elapsed time: 0:01:09.065043
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:07:01.429775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.18
 ---- batch: 020 ----
mean loss: 79.39
 ---- batch: 030 ----
mean loss: 84.05
train mean loss: 82.09
epoch train time: 0:00:00.585765
elapsed time: 0:01:09.651251
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:07:02.016014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.29
 ---- batch: 020 ----
mean loss: 82.86
 ---- batch: 030 ----
mean loss: 82.40
train mean loss: 81.74
epoch train time: 0:00:00.579331
elapsed time: 0:01:10.230943
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:07:02.595675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.59
 ---- batch: 020 ----
mean loss: 82.22
 ---- batch: 030 ----
mean loss: 80.95
train mean loss: 81.56
epoch train time: 0:00:00.591833
elapsed time: 0:01:10.823176
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:07:03.187908
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.27
 ---- batch: 020 ----
mean loss: 80.21
 ---- batch: 030 ----
mean loss: 81.85
train mean loss: 81.30
epoch train time: 0:00:00.618392
elapsed time: 0:01:11.441941
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:07:03.806674
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.45
 ---- batch: 020 ----
mean loss: 80.66
 ---- batch: 030 ----
mean loss: 77.13
train mean loss: 80.01
epoch train time: 0:00:00.604037
elapsed time: 0:01:12.046313
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:07:04.411047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.11
 ---- batch: 020 ----
mean loss: 79.42
 ---- batch: 030 ----
mean loss: 75.75
train mean loss: 79.71
epoch train time: 0:00:00.608613
elapsed time: 0:01:12.655305
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:07:05.020038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.12
 ---- batch: 020 ----
mean loss: 76.68
 ---- batch: 030 ----
mean loss: 76.91
train mean loss: 78.10
epoch train time: 0:00:00.593076
elapsed time: 0:01:13.248705
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:07:05.613475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.41
 ---- batch: 020 ----
mean loss: 80.26
 ---- batch: 030 ----
mean loss: 77.83
train mean loss: 78.56
epoch train time: 0:00:00.594974
elapsed time: 0:01:13.844046
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:07:06.208781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.52
 ---- batch: 020 ----
mean loss: 79.42
 ---- batch: 030 ----
mean loss: 75.95
train mean loss: 78.11
epoch train time: 0:00:00.589400
elapsed time: 0:01:14.433779
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:07:06.798512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.81
 ---- batch: 020 ----
mean loss: 74.05
 ---- batch: 030 ----
mean loss: 76.08
train mean loss: 76.95
epoch train time: 0:00:00.588795
elapsed time: 0:01:15.022919
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:07:07.387670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.01
 ---- batch: 020 ----
mean loss: 74.94
 ---- batch: 030 ----
mean loss: 77.61
train mean loss: 75.87
epoch train time: 0:00:00.589108
elapsed time: 0:01:15.612401
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:07:07.977137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.69
 ---- batch: 020 ----
mean loss: 78.59
 ---- batch: 030 ----
mean loss: 75.24
train mean loss: 77.16
epoch train time: 0:00:00.594145
elapsed time: 0:01:16.206954
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:07:08.571668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.72
 ---- batch: 020 ----
mean loss: 75.04
 ---- batch: 030 ----
mean loss: 77.17
train mean loss: 75.46
epoch train time: 0:00:00.596671
elapsed time: 0:01:16.803964
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:07:09.168733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.11
 ---- batch: 020 ----
mean loss: 76.13
 ---- batch: 030 ----
mean loss: 70.51
train mean loss: 73.83
epoch train time: 0:00:00.594544
elapsed time: 0:01:17.398882
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:07:09.763651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.55
 ---- batch: 020 ----
mean loss: 75.25
 ---- batch: 030 ----
mean loss: 74.47
train mean loss: 74.87
epoch train time: 0:00:00.604351
elapsed time: 0:01:18.003610
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:07:10.368348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.10
 ---- batch: 020 ----
mean loss: 73.80
 ---- batch: 030 ----
mean loss: 76.32
train mean loss: 73.78
epoch train time: 0:00:00.613458
elapsed time: 0:01:18.617433
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:07:10.982164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.10
 ---- batch: 020 ----
mean loss: 73.13
 ---- batch: 030 ----
mean loss: 71.95
train mean loss: 73.43
epoch train time: 0:00:00.593703
elapsed time: 0:01:19.211635
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:07:11.576380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.50
 ---- batch: 020 ----
mean loss: 74.60
 ---- batch: 030 ----
mean loss: 73.31
train mean loss: 73.82
epoch train time: 0:00:00.583284
elapsed time: 0:01:19.795382
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:07:12.160112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.60
 ---- batch: 020 ----
mean loss: 70.64
 ---- batch: 030 ----
mean loss: 72.74
train mean loss: 72.41
epoch train time: 0:00:00.584008
elapsed time: 0:01:20.379727
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:07:12.744459
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.21
 ---- batch: 020 ----
mean loss: 70.63
 ---- batch: 030 ----
mean loss: 73.28
train mean loss: 72.64
epoch train time: 0:00:00.589052
elapsed time: 0:01:20.969198
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:07:13.333931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.18
 ---- batch: 020 ----
mean loss: 72.04
 ---- batch: 030 ----
mean loss: 70.72
train mean loss: 71.60
epoch train time: 0:00:00.593678
elapsed time: 0:01:21.563252
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:07:13.927985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.46
 ---- batch: 020 ----
mean loss: 72.26
 ---- batch: 030 ----
mean loss: 72.17
train mean loss: 71.45
epoch train time: 0:00:00.579500
elapsed time: 0:01:22.143173
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:07:14.507949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.31
 ---- batch: 020 ----
mean loss: 72.12
 ---- batch: 030 ----
mean loss: 73.16
train mean loss: 71.74
epoch train time: 0:00:00.607700
elapsed time: 0:01:22.751269
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:07:15.116007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.51
 ---- batch: 020 ----
mean loss: 68.57
 ---- batch: 030 ----
mean loss: 71.02
train mean loss: 69.72
epoch train time: 0:00:00.603412
elapsed time: 0:01:23.355032
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:07:15.719783
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.21
 ---- batch: 020 ----
mean loss: 68.82
 ---- batch: 030 ----
mean loss: 71.85
train mean loss: 70.06
epoch train time: 0:00:00.578628
elapsed time: 0:01:23.933992
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:07:16.298721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.75
 ---- batch: 020 ----
mean loss: 69.59
 ---- batch: 030 ----
mean loss: 68.07
train mean loss: 70.03
epoch train time: 0:00:00.610063
elapsed time: 0:01:24.544454
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:07:16.909191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.77
 ---- batch: 020 ----
mean loss: 68.89
 ---- batch: 030 ----
mean loss: 70.56
train mean loss: 68.89
epoch train time: 0:00:00.583905
elapsed time: 0:01:25.128696
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:07:17.493418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.45
 ---- batch: 020 ----
mean loss: 68.90
 ---- batch: 030 ----
mean loss: 67.51
train mean loss: 67.98
epoch train time: 0:00:00.588789
elapsed time: 0:01:25.717797
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:07:18.082533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.41
 ---- batch: 020 ----
mean loss: 66.88
 ---- batch: 030 ----
mean loss: 67.46
train mean loss: 67.37
epoch train time: 0:00:00.582289
elapsed time: 0:01:26.300504
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:07:18.665235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.46
 ---- batch: 020 ----
mean loss: 64.29
 ---- batch: 030 ----
mean loss: 67.21
train mean loss: 66.72
epoch train time: 0:00:00.610417
elapsed time: 0:01:26.911285
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:07:19.276033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.44
 ---- batch: 020 ----
mean loss: 65.70
 ---- batch: 030 ----
mean loss: 64.70
train mean loss: 66.55
epoch train time: 0:00:00.608592
elapsed time: 0:01:27.520232
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:07:19.884980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.32
 ---- batch: 020 ----
mean loss: 67.33
 ---- batch: 030 ----
mean loss: 67.67
train mean loss: 66.74
epoch train time: 0:00:00.595985
elapsed time: 0:01:28.116632
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:07:20.481321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.01
 ---- batch: 020 ----
mean loss: 65.36
 ---- batch: 030 ----
mean loss: 66.44
train mean loss: 66.27
epoch train time: 0:00:00.613970
elapsed time: 0:01:28.730893
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:07:21.095646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.38
 ---- batch: 020 ----
mean loss: 65.73
 ---- batch: 030 ----
mean loss: 64.52
train mean loss: 65.92
epoch train time: 0:00:00.589742
elapsed time: 0:01:29.321051
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:07:21.685791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.84
 ---- batch: 020 ----
mean loss: 68.86
 ---- batch: 030 ----
mean loss: 64.68
train mean loss: 64.81
epoch train time: 0:00:00.612672
elapsed time: 0:01:29.934080
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:07:22.298831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.64
 ---- batch: 020 ----
mean loss: 63.12
 ---- batch: 030 ----
mean loss: 64.30
train mean loss: 64.58
epoch train time: 0:00:00.595056
elapsed time: 0:01:30.529505
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:07:22.894267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.09
 ---- batch: 020 ----
mean loss: 64.13
 ---- batch: 030 ----
mean loss: 65.51
train mean loss: 64.64
epoch train time: 0:00:00.591514
elapsed time: 0:01:31.121421
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:07:23.486159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.47
 ---- batch: 020 ----
mean loss: 66.60
 ---- batch: 030 ----
mean loss: 61.88
train mean loss: 63.82
epoch train time: 0:00:00.610728
elapsed time: 0:01:31.732543
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:07:24.097323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.02
 ---- batch: 020 ----
mean loss: 64.25
 ---- batch: 030 ----
mean loss: 63.32
train mean loss: 63.19
epoch train time: 0:00:00.592243
elapsed time: 0:01:32.325271
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:07:24.690016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.14
 ---- batch: 020 ----
mean loss: 63.60
 ---- batch: 030 ----
mean loss: 62.18
train mean loss: 62.49
epoch train time: 0:00:00.585900
elapsed time: 0:01:32.911590
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:07:25.276314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.22
 ---- batch: 020 ----
mean loss: 59.76
 ---- batch: 030 ----
mean loss: 63.19
train mean loss: 61.82
epoch train time: 0:00:00.600232
elapsed time: 0:01:33.512215
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:07:25.876975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.96
 ---- batch: 020 ----
mean loss: 61.87
 ---- batch: 030 ----
mean loss: 60.91
train mean loss: 62.09
epoch train time: 0:00:00.590676
elapsed time: 0:01:34.103253
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:07:26.467987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.76
 ---- batch: 020 ----
mean loss: 62.90
 ---- batch: 030 ----
mean loss: 58.63
train mean loss: 61.00
epoch train time: 0:00:00.615419
elapsed time: 0:01:34.719016
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:07:27.083795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.69
 ---- batch: 020 ----
mean loss: 62.56
 ---- batch: 030 ----
mean loss: 61.09
train mean loss: 61.01
epoch train time: 0:00:00.602467
elapsed time: 0:01:35.321874
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:07:27.686609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.10
 ---- batch: 020 ----
mean loss: 62.77
 ---- batch: 030 ----
mean loss: 60.07
train mean loss: 60.42
epoch train time: 0:00:00.602300
elapsed time: 0:01:35.924576
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:07:28.289315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.29
 ---- batch: 020 ----
mean loss: 58.65
 ---- batch: 030 ----
mean loss: 62.34
train mean loss: 60.29
epoch train time: 0:00:00.603254
elapsed time: 0:01:36.528253
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:07:28.892984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.32
 ---- batch: 020 ----
mean loss: 58.23
 ---- batch: 030 ----
mean loss: 60.34
train mean loss: 59.11
epoch train time: 0:00:00.580170
elapsed time: 0:01:37.108746
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:07:29.473480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.68
 ---- batch: 020 ----
mean loss: 59.21
 ---- batch: 030 ----
mean loss: 60.00
train mean loss: 58.83
epoch train time: 0:00:00.602577
elapsed time: 0:01:37.711673
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:07:30.076406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.54
 ---- batch: 020 ----
mean loss: 55.94
 ---- batch: 030 ----
mean loss: 59.82
train mean loss: 58.10
epoch train time: 0:00:00.578929
elapsed time: 0:01:38.290934
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:07:30.655680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.46
 ---- batch: 020 ----
mean loss: 58.15
 ---- batch: 030 ----
mean loss: 58.07
train mean loss: 58.41
epoch train time: 0:00:00.590120
elapsed time: 0:01:38.881495
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:07:31.246237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.86
 ---- batch: 020 ----
mean loss: 58.93
 ---- batch: 030 ----
mean loss: 57.01
train mean loss: 58.45
epoch train time: 0:00:00.590711
elapsed time: 0:01:39.472654
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:07:31.837472
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.65
 ---- batch: 020 ----
mean loss: 60.06
 ---- batch: 030 ----
mean loss: 55.72
train mean loss: 57.24
epoch train time: 0:00:00.599748
elapsed time: 0:01:40.072832
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:07:32.437596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.05
 ---- batch: 020 ----
mean loss: 56.88
 ---- batch: 030 ----
mean loss: 57.36
train mean loss: 56.57
epoch train time: 0:00:00.595523
elapsed time: 0:01:40.668771
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:07:33.033558
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.22
 ---- batch: 020 ----
mean loss: 56.29
 ---- batch: 030 ----
mean loss: 56.03
train mean loss: 56.74
epoch train time: 0:00:00.596278
elapsed time: 0:01:41.265501
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:07:33.630175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.23
 ---- batch: 020 ----
mean loss: 56.59
 ---- batch: 030 ----
mean loss: 54.96
train mean loss: 56.58
epoch train time: 0:00:00.596569
elapsed time: 0:01:41.862362
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:07:34.227094
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.26
 ---- batch: 020 ----
mean loss: 55.93
 ---- batch: 030 ----
mean loss: 55.72
train mean loss: 55.59
epoch train time: 0:00:00.598299
elapsed time: 0:01:42.461175
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:07:34.825932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.33
 ---- batch: 020 ----
mean loss: 55.08
 ---- batch: 030 ----
mean loss: 56.35
train mean loss: 54.65
epoch train time: 0:00:00.588387
elapsed time: 0:01:43.049914
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:07:35.414647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.20
 ---- batch: 020 ----
mean loss: 55.95
 ---- batch: 030 ----
mean loss: 53.08
train mean loss: 54.83
epoch train time: 0:00:00.589807
elapsed time: 0:01:43.640114
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:07:36.004848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.07
 ---- batch: 020 ----
mean loss: 53.48
 ---- batch: 030 ----
mean loss: 53.43
train mean loss: 53.42
epoch train time: 0:00:00.593151
elapsed time: 0:01:44.233617
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:07:36.598356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.54
 ---- batch: 020 ----
mean loss: 54.39
 ---- batch: 030 ----
mean loss: 53.48
train mean loss: 53.62
epoch train time: 0:00:00.596398
elapsed time: 0:01:44.830341
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:07:37.195070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.83
 ---- batch: 020 ----
mean loss: 53.63
 ---- batch: 030 ----
mean loss: 56.31
train mean loss: 53.42
epoch train time: 0:00:00.580582
elapsed time: 0:01:45.411250
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:07:37.776007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.04
 ---- batch: 020 ----
mean loss: 50.83
 ---- batch: 030 ----
mean loss: 52.75
train mean loss: 52.72
epoch train time: 0:00:00.589704
elapsed time: 0:01:46.001324
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:07:38.366055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.84
 ---- batch: 020 ----
mean loss: 52.63
 ---- batch: 030 ----
mean loss: 52.61
train mean loss: 52.29
epoch train time: 0:00:00.600407
elapsed time: 0:01:46.602088
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:07:38.966843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.66
 ---- batch: 020 ----
mean loss: 51.92
 ---- batch: 030 ----
mean loss: 51.24
train mean loss: 51.54
epoch train time: 0:00:00.591062
elapsed time: 0:01:47.193559
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:07:39.558319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.99
 ---- batch: 020 ----
mean loss: 48.34
 ---- batch: 030 ----
mean loss: 49.11
train mean loss: 50.98
epoch train time: 0:00:00.590661
elapsed time: 0:01:47.784665
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:07:40.149410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.09
 ---- batch: 020 ----
mean loss: 48.61
 ---- batch: 030 ----
mean loss: 52.59
train mean loss: 50.84
epoch train time: 0:00:00.615940
elapsed time: 0:01:48.401111
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:07:40.765860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.38
 ---- batch: 020 ----
mean loss: 49.07
 ---- batch: 030 ----
mean loss: 47.83
train mean loss: 49.96
epoch train time: 0:00:00.608841
elapsed time: 0:01:49.010391
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:07:41.375153
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.18
 ---- batch: 020 ----
mean loss: 51.48
 ---- batch: 030 ----
mean loss: 50.29
train mean loss: 50.03
epoch train time: 0:00:00.595244
elapsed time: 0:01:49.606022
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:07:41.970756
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.99
 ---- batch: 020 ----
mean loss: 49.92
 ---- batch: 030 ----
mean loss: 48.90
train mean loss: 49.65
epoch train time: 0:00:00.596712
elapsed time: 0:01:50.203108
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:07:42.567844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.27
 ---- batch: 020 ----
mean loss: 47.83
 ---- batch: 030 ----
mean loss: 49.00
train mean loss: 48.90
epoch train time: 0:00:00.594769
elapsed time: 0:01:50.798217
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:07:43.162947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.32
 ---- batch: 020 ----
mean loss: 46.65
 ---- batch: 030 ----
mean loss: 48.98
train mean loss: 48.22
epoch train time: 0:00:00.619106
elapsed time: 0:01:51.417708
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:07:43.782440
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.46
 ---- batch: 020 ----
mean loss: 48.88
 ---- batch: 030 ----
mean loss: 48.14
train mean loss: 49.09
epoch train time: 0:00:00.597946
elapsed time: 0:01:52.015999
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:07:44.380778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.10
 ---- batch: 020 ----
mean loss: 48.82
 ---- batch: 030 ----
mean loss: 48.77
train mean loss: 48.86
epoch train time: 0:00:00.595886
elapsed time: 0:01:52.612270
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:07:44.977008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.22
 ---- batch: 020 ----
mean loss: 46.57
 ---- batch: 030 ----
mean loss: 45.89
train mean loss: 46.86
epoch train time: 0:00:00.592688
elapsed time: 0:01:53.205321
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:07:45.570053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.07
 ---- batch: 020 ----
mean loss: 48.13
 ---- batch: 030 ----
mean loss: 46.62
train mean loss: 46.77
epoch train time: 0:00:00.611826
elapsed time: 0:01:53.817500
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:07:46.182235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.69
 ---- batch: 020 ----
mean loss: 46.82
 ---- batch: 030 ----
mean loss: 46.67
train mean loss: 46.11
epoch train time: 0:00:00.591698
elapsed time: 0:01:54.409614
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:07:46.774357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.47
 ---- batch: 020 ----
mean loss: 46.96
 ---- batch: 030 ----
mean loss: 43.96
train mean loss: 46.40
epoch train time: 0:00:00.604974
elapsed time: 0:01:55.014951
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:07:47.379694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.26
 ---- batch: 020 ----
mean loss: 44.59
 ---- batch: 030 ----
mean loss: 45.03
train mean loss: 45.53
epoch train time: 0:00:00.591968
elapsed time: 0:01:55.607259
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:07:47.971992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.84
 ---- batch: 020 ----
mean loss: 46.81
 ---- batch: 030 ----
mean loss: 43.90
train mean loss: 44.87
epoch train time: 0:00:00.596322
elapsed time: 0:01:56.204020
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:07:48.568740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.40
 ---- batch: 020 ----
mean loss: 46.09
 ---- batch: 030 ----
mean loss: 44.99
train mean loss: 44.45
epoch train time: 0:00:00.593324
elapsed time: 0:01:56.797684
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:07:49.162448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.62
 ---- batch: 020 ----
mean loss: 43.20
 ---- batch: 030 ----
mean loss: 47.11
train mean loss: 44.84
epoch train time: 0:00:00.585745
elapsed time: 0:01:57.383848
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:07:49.748589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.65
 ---- batch: 020 ----
mean loss: 43.77
 ---- batch: 030 ----
mean loss: 44.52
train mean loss: 43.99
epoch train time: 0:00:00.587311
elapsed time: 0:01:57.971523
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:07:50.336271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.22
 ---- batch: 020 ----
mean loss: 44.11
 ---- batch: 030 ----
mean loss: 44.62
train mean loss: 43.73
epoch train time: 0:00:00.589884
elapsed time: 0:01:58.561808
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:07:50.926576
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.85
 ---- batch: 020 ----
mean loss: 43.08
 ---- batch: 030 ----
mean loss: 41.09
train mean loss: 42.39
epoch train time: 0:00:00.586085
elapsed time: 0:01:59.148281
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:07:51.513015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.26
 ---- batch: 020 ----
mean loss: 41.18
 ---- batch: 030 ----
mean loss: 43.05
train mean loss: 42.57
epoch train time: 0:00:00.598058
elapsed time: 0:01:59.746776
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:07:52.111513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.53
 ---- batch: 020 ----
mean loss: 41.77
 ---- batch: 030 ----
mean loss: 41.94
train mean loss: 41.80
epoch train time: 0:00:00.611096
elapsed time: 0:02:00.358268
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:07:52.723011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.49
 ---- batch: 020 ----
mean loss: 45.45
 ---- batch: 030 ----
mean loss: 41.95
train mean loss: 42.73
epoch train time: 0:00:00.600080
elapsed time: 0:02:00.958744
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:07:53.323483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.52
 ---- batch: 020 ----
mean loss: 42.05
 ---- batch: 030 ----
mean loss: 40.67
train mean loss: 41.02
epoch train time: 0:00:00.601743
elapsed time: 0:02:01.560909
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:07:53.925666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.75
 ---- batch: 020 ----
mean loss: 42.73
 ---- batch: 030 ----
mean loss: 44.33
train mean loss: 41.96
epoch train time: 0:00:00.582242
elapsed time: 0:02:02.143625
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:07:54.508370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.26
 ---- batch: 020 ----
mean loss: 40.88
 ---- batch: 030 ----
mean loss: 39.83
train mean loss: 40.25
epoch train time: 0:00:00.610931
elapsed time: 0:02:02.754920
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:07:55.119658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.74
 ---- batch: 020 ----
mean loss: 39.38
 ---- batch: 030 ----
mean loss: 41.04
train mean loss: 41.00
epoch train time: 0:00:00.599768
elapsed time: 0:02:03.355083
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:07:55.719816
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 41.12
 ---- batch: 020 ----
mean loss: 39.95
 ---- batch: 030 ----
mean loss: 39.23
train mean loss: 40.13
epoch train time: 0:00:00.589734
elapsed time: 0:02:03.945173
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:07:56.309942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.11
 ---- batch: 020 ----
mean loss: 38.57
 ---- batch: 030 ----
mean loss: 42.41
train mean loss: 39.75
epoch train time: 0:00:00.586904
elapsed time: 0:02:04.532589
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:07:56.897325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.84
 ---- batch: 020 ----
mean loss: 38.92
 ---- batch: 030 ----
mean loss: 39.86
train mean loss: 39.38
epoch train time: 0:00:00.612638
elapsed time: 0:02:05.145679
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:07:57.510426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.41
 ---- batch: 020 ----
mean loss: 38.22
 ---- batch: 030 ----
mean loss: 39.49
train mean loss: 39.07
epoch train time: 0:00:00.608573
elapsed time: 0:02:05.754601
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:07:58.119329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.14
 ---- batch: 020 ----
mean loss: 38.80
 ---- batch: 030 ----
mean loss: 38.49
train mean loss: 38.76
epoch train time: 0:00:00.606991
elapsed time: 0:02:06.361973
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:07:58.726712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.85
 ---- batch: 020 ----
mean loss: 37.29
 ---- batch: 030 ----
mean loss: 38.67
train mean loss: 37.98
epoch train time: 0:00:00.609100
elapsed time: 0:02:06.971445
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:07:59.336173
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 35.90
 ---- batch: 020 ----
mean loss: 37.07
 ---- batch: 030 ----
mean loss: 40.30
train mean loss: 37.94
epoch train time: 0:00:00.596176
elapsed time: 0:02:07.567999
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:07:59.932734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.47
 ---- batch: 020 ----
mean loss: 37.72
 ---- batch: 030 ----
mean loss: 37.15
train mean loss: 37.29
epoch train time: 0:00:00.578496
elapsed time: 0:02:08.146971
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:08:00.511711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.62
 ---- batch: 020 ----
mean loss: 36.23
 ---- batch: 030 ----
mean loss: 38.19
train mean loss: 36.85
epoch train time: 0:00:00.609688
elapsed time: 0:02:08.757104
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:08:01.121848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.90
 ---- batch: 020 ----
mean loss: 39.09
 ---- batch: 030 ----
mean loss: 36.49
train mean loss: 37.92
epoch train time: 0:00:00.583367
elapsed time: 0:02:09.340912
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:08:01.705662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.39
 ---- batch: 020 ----
mean loss: 38.40
 ---- batch: 030 ----
mean loss: 34.83
train mean loss: 36.46
epoch train time: 0:00:00.589357
elapsed time: 0:02:09.930656
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:08:02.295390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 34.85
 ---- batch: 020 ----
mean loss: 36.05
 ---- batch: 030 ----
mean loss: 36.40
train mean loss: 35.83
epoch train time: 0:00:00.603297
elapsed time: 0:02:10.534356
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:08:02.899099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 35.30
 ---- batch: 020 ----
mean loss: 36.39
 ---- batch: 030 ----
mean loss: 34.91
train mean loss: 35.58
epoch train time: 0:00:00.605294
elapsed time: 0:02:11.140015
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:08:03.504745
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.22
 ---- batch: 020 ----
mean loss: 34.01
 ---- batch: 030 ----
mean loss: 36.28
train mean loss: 35.57
epoch train time: 0:00:00.592838
elapsed time: 0:02:11.733307
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:08:04.098039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.61
 ---- batch: 020 ----
mean loss: 34.43
 ---- batch: 030 ----
mean loss: 36.03
train mean loss: 35.31
epoch train time: 0:00:00.603439
elapsed time: 0:02:12.337222
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:08:04.701995
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.39
 ---- batch: 020 ----
mean loss: 34.39
 ---- batch: 030 ----
mean loss: 35.72
train mean loss: 34.21
epoch train time: 0:00:00.605834
elapsed time: 0:02:12.943528
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:08:05.308201
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.87
 ---- batch: 020 ----
mean loss: 35.44
 ---- batch: 030 ----
mean loss: 32.62
train mean loss: 34.09
epoch train time: 0:00:00.595002
elapsed time: 0:02:13.538841
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:08:05.903563
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.21
 ---- batch: 020 ----
mean loss: 33.27
 ---- batch: 030 ----
mean loss: 34.26
train mean loss: 34.15
epoch train time: 0:00:00.581017
elapsed time: 0:02:14.120189
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:08:06.484915
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.27
 ---- batch: 020 ----
mean loss: 33.31
 ---- batch: 030 ----
mean loss: 34.82
train mean loss: 33.80
epoch train time: 0:00:00.610805
elapsed time: 0:02:14.731360
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:08:07.096089
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.89
 ---- batch: 020 ----
mean loss: 34.68
 ---- batch: 030 ----
mean loss: 34.10
train mean loss: 33.98
epoch train time: 0:00:00.596423
elapsed time: 0:02:15.328192
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:08:07.692967
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.71
 ---- batch: 020 ----
mean loss: 34.04
 ---- batch: 030 ----
mean loss: 34.91
train mean loss: 33.84
epoch train time: 0:00:00.625956
elapsed time: 0:02:15.954570
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:08:08.319300
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.58
 ---- batch: 020 ----
mean loss: 33.33
 ---- batch: 030 ----
mean loss: 34.28
train mean loss: 33.85
epoch train time: 0:00:00.592580
elapsed time: 0:02:16.547520
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:08:08.912257
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.55
 ---- batch: 020 ----
mean loss: 34.43
 ---- batch: 030 ----
mean loss: 34.31
train mean loss: 34.02
epoch train time: 0:00:00.594010
elapsed time: 0:02:17.141867
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:08:09.506602
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.96
 ---- batch: 020 ----
mean loss: 34.70
 ---- batch: 030 ----
mean loss: 32.59
train mean loss: 33.67
epoch train time: 0:00:00.594431
elapsed time: 0:02:17.736636
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:08:10.101371
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.95
 ---- batch: 020 ----
mean loss: 32.83
 ---- batch: 030 ----
mean loss: 34.93
train mean loss: 33.47
epoch train time: 0:00:00.592881
elapsed time: 0:02:18.329846
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:08:10.694582
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.46
 ---- batch: 020 ----
mean loss: 33.34
 ---- batch: 030 ----
mean loss: 32.70
train mean loss: 33.77
epoch train time: 0:00:00.584053
elapsed time: 0:02:18.914234
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:08:11.278975
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.44
 ---- batch: 020 ----
mean loss: 34.43
 ---- batch: 030 ----
mean loss: 34.10
train mean loss: 33.33
epoch train time: 0:00:00.593282
elapsed time: 0:02:19.507864
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:08:11.872608
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.26
 ---- batch: 020 ----
mean loss: 32.30
 ---- batch: 030 ----
mean loss: 34.61
train mean loss: 33.71
epoch train time: 0:00:00.580133
elapsed time: 0:02:20.088342
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:08:12.453083
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.31
 ---- batch: 020 ----
mean loss: 34.43
 ---- batch: 030 ----
mean loss: 33.34
train mean loss: 33.76
epoch train time: 0:00:00.624051
elapsed time: 0:02:20.712744
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:08:13.077497
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.28
 ---- batch: 020 ----
mean loss: 34.43
 ---- batch: 030 ----
mean loss: 34.91
train mean loss: 33.62
epoch train time: 0:00:00.591024
elapsed time: 0:02:21.304158
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:08:13.668935
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.90
 ---- batch: 020 ----
mean loss: 33.21
 ---- batch: 030 ----
mean loss: 33.19
train mean loss: 33.69
epoch train time: 0:00:00.598297
elapsed time: 0:02:21.902840
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:08:14.267577
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.99
 ---- batch: 020 ----
mean loss: 32.52
 ---- batch: 030 ----
mean loss: 34.89
train mean loss: 33.24
epoch train time: 0:00:00.596283
elapsed time: 0:02:22.499463
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:08:14.864198
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.00
 ---- batch: 020 ----
mean loss: 34.76
 ---- batch: 030 ----
mean loss: 32.01
train mean loss: 33.44
epoch train time: 0:00:00.582071
elapsed time: 0:02:23.081876
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:08:15.446665
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.32
 ---- batch: 020 ----
mean loss: 34.57
 ---- batch: 030 ----
mean loss: 32.98
train mean loss: 33.40
epoch train time: 0:00:00.582506
elapsed time: 0:02:23.664780
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:08:16.029513
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.63
 ---- batch: 020 ----
mean loss: 32.60
 ---- batch: 030 ----
mean loss: 35.34
train mean loss: 33.76
epoch train time: 0:00:00.578718
elapsed time: 0:02:24.243884
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:08:16.608638
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.88
 ---- batch: 020 ----
mean loss: 32.86
 ---- batch: 030 ----
mean loss: 33.56
train mean loss: 33.54
epoch train time: 0:00:00.616342
elapsed time: 0:02:24.860645
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:08:17.225391
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.12
 ---- batch: 020 ----
mean loss: 33.49
 ---- batch: 030 ----
mean loss: 32.90
train mean loss: 33.20
epoch train time: 0:00:00.617509
elapsed time: 0:02:25.478547
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:08:17.843280
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.71
 ---- batch: 020 ----
mean loss: 32.32
 ---- batch: 030 ----
mean loss: 35.59
train mean loss: 33.42
epoch train time: 0:00:00.591201
elapsed time: 0:02:26.070097
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:08:18.434830
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.59
 ---- batch: 020 ----
mean loss: 32.66
 ---- batch: 030 ----
mean loss: 33.46
train mean loss: 33.18
epoch train time: 0:00:00.598108
elapsed time: 0:02:26.668559
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:08:19.033297
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.21
 ---- batch: 020 ----
mean loss: 33.03
 ---- batch: 030 ----
mean loss: 33.45
train mean loss: 33.42
epoch train time: 0:00:00.602466
elapsed time: 0:02:27.271418
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:08:19.636192
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.89
 ---- batch: 020 ----
mean loss: 32.14
 ---- batch: 030 ----
mean loss: 31.71
train mean loss: 32.96
epoch train time: 0:00:00.592223
elapsed time: 0:02:27.864001
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:08:20.228728
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.60
 ---- batch: 020 ----
mean loss: 33.51
 ---- batch: 030 ----
mean loss: 32.50
train mean loss: 33.29
epoch train time: 0:00:00.602434
elapsed time: 0:02:28.466780
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:08:20.831614
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.32
 ---- batch: 020 ----
mean loss: 33.21
 ---- batch: 030 ----
mean loss: 33.36
train mean loss: 33.31
epoch train time: 0:00:00.604255
elapsed time: 0:02:29.071465
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:08:21.436207
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.57
 ---- batch: 020 ----
mean loss: 32.00
 ---- batch: 030 ----
mean loss: 32.85
train mean loss: 33.03
epoch train time: 0:00:00.613938
elapsed time: 0:02:29.685773
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:08:22.050523
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.05
 ---- batch: 020 ----
mean loss: 34.70
 ---- batch: 030 ----
mean loss: 32.42
train mean loss: 33.06
epoch train time: 0:00:00.597628
elapsed time: 0:02:30.283816
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:08:22.648572
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.19
 ---- batch: 020 ----
mean loss: 32.48
 ---- batch: 030 ----
mean loss: 32.67
train mean loss: 33.17
epoch train time: 0:00:00.600109
elapsed time: 0:02:30.884269
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:08:23.249016
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.12
 ---- batch: 020 ----
mean loss: 33.33
 ---- batch: 030 ----
mean loss: 32.51
train mean loss: 32.75
epoch train time: 0:00:00.595326
elapsed time: 0:02:31.479942
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:08:23.844680
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.37
 ---- batch: 020 ----
mean loss: 31.93
 ---- batch: 030 ----
mean loss: 32.34
train mean loss: 32.88
epoch train time: 0:00:00.584040
elapsed time: 0:02:32.064437
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:08:24.429111
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.71
 ---- batch: 020 ----
mean loss: 34.27
 ---- batch: 030 ----
mean loss: 30.99
train mean loss: 33.00
epoch train time: 0:00:00.607011
elapsed time: 0:02:32.671771
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:08:25.036528
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.92
 ---- batch: 020 ----
mean loss: 32.85
 ---- batch: 030 ----
mean loss: 32.97
train mean loss: 33.01
epoch train time: 0:00:00.602207
elapsed time: 0:02:33.274325
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:08:25.639070
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.52
 ---- batch: 020 ----
mean loss: 32.27
 ---- batch: 030 ----
mean loss: 32.90
train mean loss: 32.73
epoch train time: 0:00:00.596739
elapsed time: 0:02:33.871467
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:08:26.236202
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.81
 ---- batch: 020 ----
mean loss: 32.60
 ---- batch: 030 ----
mean loss: 31.77
train mean loss: 32.90
epoch train time: 0:00:00.583487
elapsed time: 0:02:34.455377
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:08:26.820114
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.22
 ---- batch: 020 ----
mean loss: 31.70
 ---- batch: 030 ----
mean loss: 33.14
train mean loss: 32.66
epoch train time: 0:00:00.586774
elapsed time: 0:02:35.042532
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:08:27.407278
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.13
 ---- batch: 020 ----
mean loss: 32.89
 ---- batch: 030 ----
mean loss: 30.60
train mean loss: 32.77
epoch train time: 0:00:00.589404
elapsed time: 0:02:35.632266
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:08:27.996998
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.39
 ---- batch: 020 ----
mean loss: 32.04
 ---- batch: 030 ----
mean loss: 31.44
train mean loss: 32.78
epoch train time: 0:00:00.579918
elapsed time: 0:02:36.212518
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:08:28.577253
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.02
 ---- batch: 020 ----
mean loss: 31.77
 ---- batch: 030 ----
mean loss: 33.53
train mean loss: 32.45
epoch train time: 0:00:00.583308
elapsed time: 0:02:36.796171
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:08:29.160921
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.42
 ---- batch: 020 ----
mean loss: 32.63
 ---- batch: 030 ----
mean loss: 32.10
train mean loss: 32.51
epoch train time: 0:00:00.590616
elapsed time: 0:02:37.387195
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:08:29.751972
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.53
 ---- batch: 020 ----
mean loss: 33.97
 ---- batch: 030 ----
mean loss: 30.67
train mean loss: 32.39
epoch train time: 0:00:00.599826
elapsed time: 0:02:37.987446
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:08:30.352202
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.06
 ---- batch: 020 ----
mean loss: 33.53
 ---- batch: 030 ----
mean loss: 33.38
train mean loss: 32.68
epoch train time: 0:00:00.617869
elapsed time: 0:02:38.605692
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:08:30.970437
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.97
 ---- batch: 020 ----
mean loss: 32.25
 ---- batch: 030 ----
mean loss: 33.18
train mean loss: 32.45
epoch train time: 0:00:00.594381
elapsed time: 0:02:39.200480
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:08:31.565238
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.72
 ---- batch: 020 ----
mean loss: 31.16
 ---- batch: 030 ----
mean loss: 33.18
train mean loss: 32.36
epoch train time: 0:00:00.593441
elapsed time: 0:02:39.794305
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:08:32.159043
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.06
 ---- batch: 020 ----
mean loss: 30.56
 ---- batch: 030 ----
mean loss: 32.46
train mean loss: 32.36
epoch train time: 0:00:00.590500
elapsed time: 0:02:40.385176
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:08:32.749911
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.19
 ---- batch: 020 ----
mean loss: 33.00
 ---- batch: 030 ----
mean loss: 30.44
train mean loss: 32.53
epoch train time: 0:00:00.595921
elapsed time: 0:02:40.981452
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:08:33.346188
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 30.62
 ---- batch: 020 ----
mean loss: 33.26
 ---- batch: 030 ----
mean loss: 33.66
train mean loss: 32.42
epoch train time: 0:00:00.598927
elapsed time: 0:02:41.588229
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_0/checkpoint.pth.tar
**** end time: 2019-09-27 15:08:33.952877 ****
