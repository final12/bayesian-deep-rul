Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_9', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29439
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 15:03:09.107867 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:03:09.118104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4003.93
 ---- batch: 020 ----
mean loss: 3835.04
 ---- batch: 030 ----
mean loss: 3871.11
train mean loss: 3895.11
epoch train time: 0:00:12.908784
elapsed time: 0:00:12.922000
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:03:22.029906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3785.05
 ---- batch: 020 ----
mean loss: 3682.65
 ---- batch: 030 ----
mean loss: 3635.68
train mean loss: 3689.05
epoch train time: 0:00:00.530702
elapsed time: 0:00:13.452937
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:03:22.560910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3520.90
 ---- batch: 020 ----
mean loss: 3427.21
 ---- batch: 030 ----
mean loss: 3364.75
train mean loss: 3415.69
epoch train time: 0:00:00.531723
elapsed time: 0:00:13.985237
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:03:23.093223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3222.93
 ---- batch: 020 ----
mean loss: 3138.99
 ---- batch: 030 ----
mean loss: 3100.77
train mean loss: 3145.82
epoch train time: 0:00:00.531743
elapsed time: 0:00:14.517374
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:03:23.625336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2939.75
 ---- batch: 020 ----
mean loss: 2873.64
 ---- batch: 030 ----
mean loss: 2934.87
train mean loss: 2901.50
epoch train time: 0:00:00.537697
elapsed time: 0:00:15.055373
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:03:24.163335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2767.75
 ---- batch: 020 ----
mean loss: 2684.05
 ---- batch: 030 ----
mean loss: 2670.16
train mean loss: 2695.45
epoch train time: 0:00:00.534027
elapsed time: 0:00:15.589698
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:03:24.697703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2589.96
 ---- batch: 020 ----
mean loss: 2509.03
 ---- batch: 030 ----
mean loss: 2453.26
train mean loss: 2505.20
epoch train time: 0:00:00.536547
elapsed time: 0:00:16.126570
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:03:25.234529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2401.27
 ---- batch: 020 ----
mean loss: 2385.08
 ---- batch: 030 ----
mean loss: 2294.13
train mean loss: 2350.42
epoch train time: 0:00:00.543395
elapsed time: 0:00:16.670257
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:03:25.778241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2245.91
 ---- batch: 020 ----
mean loss: 2209.89
 ---- batch: 030 ----
mean loss: 2185.69
train mean loss: 2204.32
epoch train time: 0:00:00.540124
elapsed time: 0:00:17.210694
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:03:26.318653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2137.95
 ---- batch: 020 ----
mean loss: 2072.54
 ---- batch: 030 ----
mean loss: 2049.92
train mean loss: 2074.55
epoch train time: 0:00:00.532856
elapsed time: 0:00:17.743903
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:03:26.851869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1977.66
 ---- batch: 020 ----
mean loss: 1983.18
 ---- batch: 030 ----
mean loss: 1920.80
train mean loss: 1952.69
epoch train time: 0:00:00.521990
elapsed time: 0:00:18.266228
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:03:27.374193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1878.71
 ---- batch: 020 ----
mean loss: 1868.08
 ---- batch: 030 ----
mean loss: 1795.90
train mean loss: 1847.04
epoch train time: 0:00:00.527289
elapsed time: 0:00:18.793894
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:03:27.901858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1797.58
 ---- batch: 020 ----
mean loss: 1745.64
 ---- batch: 030 ----
mean loss: 1753.79
train mean loss: 1752.44
epoch train time: 0:00:00.534100
elapsed time: 0:00:19.328299
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:03:28.436273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1719.76
 ---- batch: 020 ----
mean loss: 1669.86
 ---- batch: 030 ----
mean loss: 1611.95
train mean loss: 1653.26
epoch train time: 0:00:00.534348
elapsed time: 0:00:19.862945
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:03:28.970903
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1592.83
 ---- batch: 020 ----
mean loss: 1569.32
 ---- batch: 030 ----
mean loss: 1554.70
train mean loss: 1569.01
epoch train time: 0:00:00.519297
elapsed time: 0:00:20.382533
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:03:29.490490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1516.80
 ---- batch: 020 ----
mean loss: 1493.78
 ---- batch: 030 ----
mean loss: 1478.75
train mean loss: 1492.32
epoch train time: 0:00:00.529684
elapsed time: 0:00:20.912501
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:03:30.020461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1439.47
 ---- batch: 020 ----
mean loss: 1407.45
 ---- batch: 030 ----
mean loss: 1404.47
train mean loss: 1412.86
epoch train time: 0:00:00.532865
elapsed time: 0:00:21.445668
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:03:30.553654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1368.70
 ---- batch: 020 ----
mean loss: 1349.40
 ---- batch: 030 ----
mean loss: 1308.81
train mean loss: 1343.66
epoch train time: 0:00:00.541003
elapsed time: 0:00:21.986985
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:03:31.094944
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1304.64
 ---- batch: 020 ----
mean loss: 1286.80
 ---- batch: 030 ----
mean loss: 1257.73
train mean loss: 1278.20
epoch train time: 0:00:00.522104
elapsed time: 0:00:22.509356
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:03:31.617349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1247.50
 ---- batch: 020 ----
mean loss: 1214.13
 ---- batch: 030 ----
mean loss: 1198.71
train mean loss: 1216.21
epoch train time: 0:00:00.535277
elapsed time: 0:00:23.044965
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:03:32.152939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1164.56
 ---- batch: 020 ----
mean loss: 1154.08
 ---- batch: 030 ----
mean loss: 1135.06
train mean loss: 1154.27
epoch train time: 0:00:00.515478
elapsed time: 0:00:23.560753
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:03:32.668729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1102.15
 ---- batch: 020 ----
mean loss: 1116.36
 ---- batch: 030 ----
mean loss: 1083.24
train mean loss: 1091.15
epoch train time: 0:00:00.529347
elapsed time: 0:00:24.090428
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:03:33.198388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1064.97
 ---- batch: 020 ----
mean loss: 1031.64
 ---- batch: 030 ----
mean loss: 1026.20
train mean loss: 1032.64
epoch train time: 0:00:00.529067
elapsed time: 0:00:24.619790
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:03:33.727781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 984.01
 ---- batch: 020 ----
mean loss: 997.27
 ---- batch: 030 ----
mean loss: 977.50
train mean loss: 977.32
epoch train time: 0:00:00.527279
elapsed time: 0:00:25.147406
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:03:34.255364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 957.06
 ---- batch: 020 ----
mean loss: 936.78
 ---- batch: 030 ----
mean loss: 907.64
train mean loss: 927.84
epoch train time: 0:00:00.529490
elapsed time: 0:00:25.677198
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:03:34.785162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 875.35
 ---- batch: 020 ----
mean loss: 894.00
 ---- batch: 030 ----
mean loss: 869.05
train mean loss: 874.93
epoch train time: 0:00:00.525412
elapsed time: 0:00:26.202904
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:03:35.310887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 860.02
 ---- batch: 020 ----
mean loss: 842.68
 ---- batch: 030 ----
mean loss: 811.07
train mean loss: 838.55
epoch train time: 0:00:00.536783
elapsed time: 0:00:26.740001
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:03:35.847977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 812.55
 ---- batch: 020 ----
mean loss: 796.41
 ---- batch: 030 ----
mean loss: 782.35
train mean loss: 794.72
epoch train time: 0:00:00.531582
elapsed time: 0:00:27.271878
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:03:36.379839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 764.04
 ---- batch: 020 ----
mean loss: 783.91
 ---- batch: 030 ----
mean loss: 749.22
train mean loss: 760.96
epoch train time: 0:00:00.529787
elapsed time: 0:00:27.801960
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:03:36.909921
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 743.92
 ---- batch: 020 ----
mean loss: 732.56
 ---- batch: 030 ----
mean loss: 722.70
train mean loss: 733.17
epoch train time: 0:00:00.525474
elapsed time: 0:00:28.327727
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:03:37.435706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 710.41
 ---- batch: 020 ----
mean loss: 689.58
 ---- batch: 030 ----
mean loss: 712.70
train mean loss: 702.69
epoch train time: 0:00:00.533143
elapsed time: 0:00:28.861195
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:03:37.969155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 683.87
 ---- batch: 020 ----
mean loss: 679.74
 ---- batch: 030 ----
mean loss: 669.45
train mean loss: 674.71
epoch train time: 0:00:00.545382
elapsed time: 0:00:29.406884
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:03:38.514854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 664.10
 ---- batch: 020 ----
mean loss: 649.11
 ---- batch: 030 ----
mean loss: 634.99
train mean loss: 651.36
epoch train time: 0:00:00.538188
elapsed time: 0:00:29.945396
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:03:39.053356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 642.03
 ---- batch: 020 ----
mean loss: 639.79
 ---- batch: 030 ----
mean loss: 619.62
train mean loss: 631.02
epoch train time: 0:00:00.527211
elapsed time: 0:00:30.472886
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:03:39.580866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 613.26
 ---- batch: 020 ----
mean loss: 614.39
 ---- batch: 030 ----
mean loss: 606.58
train mean loss: 610.57
epoch train time: 0:00:00.534482
elapsed time: 0:00:31.007702
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:03:40.115660
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 595.13
 ---- batch: 020 ----
mean loss: 585.31
 ---- batch: 030 ----
mean loss: 599.22
train mean loss: 592.16
epoch train time: 0:00:00.522717
elapsed time: 0:00:31.531177
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:03:40.639153
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 581.69
 ---- batch: 020 ----
mean loss: 579.13
 ---- batch: 030 ----
mean loss: 569.71
train mean loss: 572.89
epoch train time: 0:00:00.529858
elapsed time: 0:00:32.061331
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:03:41.169287
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 560.24
 ---- batch: 020 ----
mean loss: 553.00
 ---- batch: 030 ----
mean loss: 561.48
train mean loss: 557.73
epoch train time: 0:00:00.527810
elapsed time: 0:00:32.589422
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:03:41.697411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.31
 ---- batch: 020 ----
mean loss: 550.53
 ---- batch: 030 ----
mean loss: 535.53
train mean loss: 544.88
epoch train time: 0:00:00.517335
elapsed time: 0:00:33.107064
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:03:42.215021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 534.59
 ---- batch: 020 ----
mean loss: 525.92
 ---- batch: 030 ----
mean loss: 529.85
train mean loss: 529.62
epoch train time: 0:00:00.521283
elapsed time: 0:00:33.628659
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:03:42.736647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 520.17
 ---- batch: 020 ----
mean loss: 516.10
 ---- batch: 030 ----
mean loss: 518.14
train mean loss: 518.75
epoch train time: 0:00:00.533796
elapsed time: 0:00:34.162773
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:03:43.270766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 512.30
 ---- batch: 020 ----
mean loss: 502.78
 ---- batch: 030 ----
mean loss: 508.33
train mean loss: 507.43
epoch train time: 0:00:00.528371
elapsed time: 0:00:34.691480
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:03:43.799439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 503.78
 ---- batch: 020 ----
mean loss: 492.81
 ---- batch: 030 ----
mean loss: 494.04
train mean loss: 496.70
epoch train time: 0:00:00.529594
elapsed time: 0:00:35.221413
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:03:44.329387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 485.13
 ---- batch: 020 ----
mean loss: 500.70
 ---- batch: 030 ----
mean loss: 484.38
train mean loss: 488.09
epoch train time: 0:00:00.525797
elapsed time: 0:00:35.747535
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:03:44.855507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 481.31
 ---- batch: 020 ----
mean loss: 472.06
 ---- batch: 030 ----
mean loss: 483.03
train mean loss: 479.06
epoch train time: 0:00:00.519819
elapsed time: 0:00:36.267650
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:03:45.375613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 471.18
 ---- batch: 020 ----
mean loss: 470.09
 ---- batch: 030 ----
mean loss: 465.65
train mean loss: 470.21
epoch train time: 0:00:00.532954
elapsed time: 0:00:36.800955
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:03:45.908917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 464.25
 ---- batch: 020 ----
mean loss: 465.27
 ---- batch: 030 ----
mean loss: 461.67
train mean loss: 463.23
epoch train time: 0:00:00.525881
elapsed time: 0:00:37.327124
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:03:46.435082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 462.87
 ---- batch: 020 ----
mean loss: 459.18
 ---- batch: 030 ----
mean loss: 458.96
train mean loss: 458.01
epoch train time: 0:00:00.538449
elapsed time: 0:00:37.865868
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:03:46.973848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 458.34
 ---- batch: 020 ----
mean loss: 448.84
 ---- batch: 030 ----
mean loss: 442.94
train mean loss: 448.37
epoch train time: 0:00:00.533944
elapsed time: 0:00:38.400147
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:03:47.508105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 450.09
 ---- batch: 020 ----
mean loss: 442.10
 ---- batch: 030 ----
mean loss: 440.87
train mean loss: 442.69
epoch train time: 0:00:00.534095
elapsed time: 0:00:38.934534
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:03:48.042496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 436.89
 ---- batch: 020 ----
mean loss: 433.84
 ---- batch: 030 ----
mean loss: 443.14
train mean loss: 436.63
epoch train time: 0:00:00.537055
elapsed time: 0:00:39.471949
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:03:48.579906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 435.95
 ---- batch: 020 ----
mean loss: 429.11
 ---- batch: 030 ----
mean loss: 433.43
train mean loss: 432.38
epoch train time: 0:00:00.541397
elapsed time: 0:00:40.013621
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:03:49.121576
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 427.97
 ---- batch: 020 ----
mean loss: 432.75
 ---- batch: 030 ----
mean loss: 417.24
train mean loss: 426.24
epoch train time: 0:00:00.532349
elapsed time: 0:00:40.546270
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:03:49.654326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 420.31
 ---- batch: 020 ----
mean loss: 422.25
 ---- batch: 030 ----
mean loss: 421.19
train mean loss: 420.58
epoch train time: 0:00:00.543948
elapsed time: 0:00:41.090614
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:03:50.198574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 419.49
 ---- batch: 020 ----
mean loss: 415.85
 ---- batch: 030 ----
mean loss: 408.03
train mean loss: 413.72
epoch train time: 0:00:00.534150
elapsed time: 0:00:41.625421
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:03:50.733387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 414.14
 ---- batch: 020 ----
mean loss: 409.85
 ---- batch: 030 ----
mean loss: 407.55
train mean loss: 409.81
epoch train time: 0:00:00.528327
elapsed time: 0:00:42.154062
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:03:51.262042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.67
 ---- batch: 020 ----
mean loss: 410.71
 ---- batch: 030 ----
mean loss: 397.50
train mean loss: 403.91
epoch train time: 0:00:00.531855
elapsed time: 0:00:42.686527
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:03:51.794503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.12
 ---- batch: 020 ----
mean loss: 399.77
 ---- batch: 030 ----
mean loss: 400.73
train mean loss: 400.39
epoch train time: 0:00:00.536089
elapsed time: 0:00:43.222923
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:03:52.330880
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 391.57
 ---- batch: 020 ----
mean loss: 403.20
 ---- batch: 030 ----
mean loss: 394.65
train mean loss: 394.24
epoch train time: 0:00:00.538627
elapsed time: 0:00:43.761879
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:03:52.869844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 399.23
 ---- batch: 020 ----
mean loss: 396.10
 ---- batch: 030 ----
mean loss: 384.86
train mean loss: 391.82
epoch train time: 0:00:00.539020
elapsed time: 0:00:44.301199
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:03:53.409157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 393.10
 ---- batch: 020 ----
mean loss: 383.31
 ---- batch: 030 ----
mean loss: 382.81
train mean loss: 387.87
epoch train time: 0:00:00.538741
elapsed time: 0:00:44.840262
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:03:53.948244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 377.65
 ---- batch: 020 ----
mean loss: 380.32
 ---- batch: 030 ----
mean loss: 388.17
train mean loss: 382.69
epoch train time: 0:00:00.542857
elapsed time: 0:00:45.383448
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:03:54.491425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 375.95
 ---- batch: 020 ----
mean loss: 381.32
 ---- batch: 030 ----
mean loss: 377.16
train mean loss: 379.90
epoch train time: 0:00:00.543704
elapsed time: 0:00:45.927509
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:03:55.035483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 376.75
 ---- batch: 020 ----
mean loss: 378.57
 ---- batch: 030 ----
mean loss: 375.35
train mean loss: 376.88
epoch train time: 0:00:00.550684
elapsed time: 0:00:46.478525
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:03:55.586486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 381.53
 ---- batch: 020 ----
mean loss: 370.24
 ---- batch: 030 ----
mean loss: 373.54
train mean loss: 374.47
epoch train time: 0:00:00.543627
elapsed time: 0:00:47.022529
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:03:56.130494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 370.78
 ---- batch: 020 ----
mean loss: 365.11
 ---- batch: 030 ----
mean loss: 367.78
train mean loss: 369.60
epoch train time: 0:00:00.548339
elapsed time: 0:00:47.571170
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:03:56.679169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.38
 ---- batch: 020 ----
mean loss: 368.49
 ---- batch: 030 ----
mean loss: 364.11
train mean loss: 367.83
epoch train time: 0:00:00.549721
elapsed time: 0:00:48.121350
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:03:57.229358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 368.85
 ---- batch: 020 ----
mean loss: 366.12
 ---- batch: 030 ----
mean loss: 369.51
train mean loss: 368.49
epoch train time: 0:00:00.539702
elapsed time: 0:00:48.661410
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:03:57.769371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 361.30
 ---- batch: 020 ----
mean loss: 365.45
 ---- batch: 030 ----
mean loss: 361.97
train mean loss: 361.59
epoch train time: 0:00:00.523565
elapsed time: 0:00:49.185355
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:03:58.293332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.37
 ---- batch: 020 ----
mean loss: 361.52
 ---- batch: 030 ----
mean loss: 362.49
train mean loss: 362.26
epoch train time: 0:00:00.529963
elapsed time: 0:00:49.715790
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:03:58.823757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.21
 ---- batch: 020 ----
mean loss: 350.66
 ---- batch: 030 ----
mean loss: 362.02
train mean loss: 359.04
epoch train time: 0:00:00.530381
elapsed time: 0:00:50.246489
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:03:59.354478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 363.70
 ---- batch: 020 ----
mean loss: 354.33
 ---- batch: 030 ----
mean loss: 352.98
train mean loss: 357.46
epoch train time: 0:00:00.545860
elapsed time: 0:00:50.792734
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:03:59.900693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.87
 ---- batch: 020 ----
mean loss: 353.67
 ---- batch: 030 ----
mean loss: 350.82
train mean loss: 353.28
epoch train time: 0:00:00.529298
elapsed time: 0:00:51.322335
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:04:00.430325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 351.99
 ---- batch: 020 ----
mean loss: 357.38
 ---- batch: 030 ----
mean loss: 352.69
train mean loss: 352.30
epoch train time: 0:00:00.525511
elapsed time: 0:00:51.848154
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:04:00.956146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 355.77
 ---- batch: 020 ----
mean loss: 348.58
 ---- batch: 030 ----
mean loss: 351.36
train mean loss: 351.23
epoch train time: 0:00:00.519448
elapsed time: 0:00:52.367932
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:04:01.475925
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.93
 ---- batch: 020 ----
mean loss: 355.01
 ---- batch: 030 ----
mean loss: 348.04
train mean loss: 349.58
epoch train time: 0:00:00.532735
elapsed time: 0:00:52.901022
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:04:02.009010
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 351.05
 ---- batch: 020 ----
mean loss: 344.87
 ---- batch: 030 ----
mean loss: 345.56
train mean loss: 347.39
epoch train time: 0:00:00.533196
elapsed time: 0:00:53.434580
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:04:02.542559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 338.30
 ---- batch: 020 ----
mean loss: 347.90
 ---- batch: 030 ----
mean loss: 346.29
train mean loss: 345.01
epoch train time: 0:00:00.526983
elapsed time: 0:00:53.961898
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:04:03.069876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 351.39
 ---- batch: 020 ----
mean loss: 339.80
 ---- batch: 030 ----
mean loss: 337.57
train mean loss: 344.49
epoch train time: 0:00:00.525856
elapsed time: 0:00:54.488075
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:04:03.596041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 340.71
 ---- batch: 020 ----
mean loss: 342.77
 ---- batch: 030 ----
mean loss: 345.48
train mean loss: 342.51
epoch train time: 0:00:00.548797
elapsed time: 0:00:55.037162
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:04:04.145125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 335.33
 ---- batch: 020 ----
mean loss: 337.98
 ---- batch: 030 ----
mean loss: 353.95
train mean loss: 341.30
epoch train time: 0:00:00.527474
elapsed time: 0:00:55.564969
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:04:04.672928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 333.43
 ---- batch: 020 ----
mean loss: 344.44
 ---- batch: 030 ----
mean loss: 337.77
train mean loss: 340.07
epoch train time: 0:00:00.530639
elapsed time: 0:00:56.095915
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:04:05.203877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 341.36
 ---- batch: 020 ----
mean loss: 333.06
 ---- batch: 030 ----
mean loss: 338.10
train mean loss: 338.24
epoch train time: 0:00:00.531009
elapsed time: 0:00:56.627239
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:04:05.735221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.02
 ---- batch: 020 ----
mean loss: 340.14
 ---- batch: 030 ----
mean loss: 334.89
train mean loss: 336.55
epoch train time: 0:00:00.538073
elapsed time: 0:00:57.165642
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:04:06.273645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.41
 ---- batch: 020 ----
mean loss: 332.20
 ---- batch: 030 ----
mean loss: 336.44
train mean loss: 335.63
epoch train time: 0:00:00.544992
elapsed time: 0:00:57.711084
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:04:06.819044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.71
 ---- batch: 020 ----
mean loss: 337.78
 ---- batch: 030 ----
mean loss: 330.81
train mean loss: 332.44
epoch train time: 0:00:00.546235
elapsed time: 0:00:58.257653
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:04:07.365636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 332.18
 ---- batch: 020 ----
mean loss: 333.81
 ---- batch: 030 ----
mean loss: 328.74
train mean loss: 331.93
epoch train time: 0:00:00.550076
elapsed time: 0:00:58.808092
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:04:07.916054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 333.79
 ---- batch: 020 ----
mean loss: 340.98
 ---- batch: 030 ----
mean loss: 321.63
train mean loss: 331.10
epoch train time: 0:00:00.542917
elapsed time: 0:00:59.351359
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:04:08.459323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.41
 ---- batch: 020 ----
mean loss: 324.88
 ---- batch: 030 ----
mean loss: 323.55
train mean loss: 330.13
epoch train time: 0:00:00.544066
elapsed time: 0:00:59.895746
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:04:09.003727
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.82
 ---- batch: 020 ----
mean loss: 324.02
 ---- batch: 030 ----
mean loss: 330.25
train mean loss: 327.36
epoch train time: 0:00:00.543484
elapsed time: 0:01:00.439553
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:04:09.547540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.15
 ---- batch: 020 ----
mean loss: 330.94
 ---- batch: 030 ----
mean loss: 328.56
train mean loss: 327.30
epoch train time: 0:00:00.542780
elapsed time: 0:01:00.982665
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:04:10.090622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.55
 ---- batch: 020 ----
mean loss: 325.98
 ---- batch: 030 ----
mean loss: 328.67
train mean loss: 325.23
epoch train time: 0:00:00.542973
elapsed time: 0:01:01.525948
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:04:10.633919
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.40
 ---- batch: 020 ----
mean loss: 326.04
 ---- batch: 030 ----
mean loss: 320.39
train mean loss: 324.65
epoch train time: 0:00:00.544725
elapsed time: 0:01:02.071019
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:04:11.179022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.18
 ---- batch: 020 ----
mean loss: 321.32
 ---- batch: 030 ----
mean loss: 323.07
train mean loss: 323.63
epoch train time: 0:00:00.535733
elapsed time: 0:01:02.607163
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:04:11.715124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.39
 ---- batch: 020 ----
mean loss: 318.66
 ---- batch: 030 ----
mean loss: 331.01
train mean loss: 322.61
epoch train time: 0:00:00.532240
elapsed time: 0:01:03.139701
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:04:12.247697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 318.09
 ---- batch: 020 ----
mean loss: 317.02
 ---- batch: 030 ----
mean loss: 324.21
train mean loss: 319.53
epoch train time: 0:00:00.546012
elapsed time: 0:01:03.686079
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:04:12.794156
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 316.07
 ---- batch: 020 ----
mean loss: 317.25
 ---- batch: 030 ----
mean loss: 323.94
train mean loss: 318.54
epoch train time: 0:00:00.548905
elapsed time: 0:01:04.235394
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:04:13.343354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.04
 ---- batch: 020 ----
mean loss: 315.87
 ---- batch: 030 ----
mean loss: 314.52
train mean loss: 317.62
epoch train time: 0:00:00.537405
elapsed time: 0:01:04.773108
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:04:13.881079
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.91
 ---- batch: 020 ----
mean loss: 314.92
 ---- batch: 030 ----
mean loss: 316.37
train mean loss: 317.91
epoch train time: 0:00:00.536785
elapsed time: 0:01:05.310218
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:04:14.418197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.70
 ---- batch: 020 ----
mean loss: 311.70
 ---- batch: 030 ----
mean loss: 317.93
train mean loss: 315.97
epoch train time: 0:00:00.532903
elapsed time: 0:01:05.843417
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:04:14.951421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.84
 ---- batch: 020 ----
mean loss: 315.17
 ---- batch: 030 ----
mean loss: 308.01
train mean loss: 314.59
epoch train time: 0:00:00.530002
elapsed time: 0:01:06.373810
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:04:15.481774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.11
 ---- batch: 020 ----
mean loss: 319.34
 ---- batch: 030 ----
mean loss: 315.02
train mean loss: 314.46
epoch train time: 0:00:00.533996
elapsed time: 0:01:06.908204
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:04:16.016190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.58
 ---- batch: 020 ----
mean loss: 313.20
 ---- batch: 030 ----
mean loss: 314.10
train mean loss: 312.11
epoch train time: 0:00:00.532650
elapsed time: 0:01:07.441179
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:04:16.549142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 307.58
 ---- batch: 020 ----
mean loss: 316.81
 ---- batch: 030 ----
mean loss: 310.53
train mean loss: 310.95
epoch train time: 0:00:00.531159
elapsed time: 0:01:07.972630
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:04:17.080586
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.01
 ---- batch: 020 ----
mean loss: 314.83
 ---- batch: 030 ----
mean loss: 312.42
train mean loss: 309.87
epoch train time: 0:00:00.522871
elapsed time: 0:01:08.495799
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:04:17.603761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 302.32
 ---- batch: 020 ----
mean loss: 310.43
 ---- batch: 030 ----
mean loss: 315.71
train mean loss: 309.32
epoch train time: 0:00:00.536054
elapsed time: 0:01:09.032167
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:04:18.140129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 305.96
 ---- batch: 020 ----
mean loss: 311.04
 ---- batch: 030 ----
mean loss: 306.94
train mean loss: 307.86
epoch train time: 0:00:00.529106
elapsed time: 0:01:09.561660
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:04:18.669578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 310.60
 ---- batch: 020 ----
mean loss: 300.92
 ---- batch: 030 ----
mean loss: 309.87
train mean loss: 306.43
epoch train time: 0:00:00.535935
elapsed time: 0:01:10.097861
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:04:19.205854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 305.66
 ---- batch: 020 ----
mean loss: 313.24
 ---- batch: 030 ----
mean loss: 299.46
train mean loss: 306.30
epoch train time: 0:00:00.524924
elapsed time: 0:01:10.623105
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:04:19.731074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 305.95
 ---- batch: 020 ----
mean loss: 300.18
 ---- batch: 030 ----
mean loss: 306.46
train mean loss: 304.16
epoch train time: 0:00:00.560887
elapsed time: 0:01:11.184323
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:04:20.292294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 304.44
 ---- batch: 020 ----
mean loss: 305.11
 ---- batch: 030 ----
mean loss: 304.49
train mean loss: 303.12
epoch train time: 0:00:00.536606
elapsed time: 0:01:11.721277
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:04:20.829264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.12
 ---- batch: 020 ----
mean loss: 299.77
 ---- batch: 030 ----
mean loss: 302.98
train mean loss: 302.80
epoch train time: 0:00:00.526825
elapsed time: 0:01:12.248482
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:04:21.356443
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.35
 ---- batch: 020 ----
mean loss: 300.67
 ---- batch: 030 ----
mean loss: 298.11
train mean loss: 301.97
epoch train time: 0:00:00.552335
elapsed time: 0:01:12.801183
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:04:21.909148
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.69
 ---- batch: 020 ----
mean loss: 300.90
 ---- batch: 030 ----
mean loss: 303.75
train mean loss: 301.10
epoch train time: 0:00:00.536747
elapsed time: 0:01:13.338233
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:04:22.446191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.94
 ---- batch: 020 ----
mean loss: 302.10
 ---- batch: 030 ----
mean loss: 305.81
train mean loss: 299.21
epoch train time: 0:00:00.533358
elapsed time: 0:01:13.871898
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:04:22.979859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.37
 ---- batch: 020 ----
mean loss: 302.33
 ---- batch: 030 ----
mean loss: 297.81
train mean loss: 299.25
epoch train time: 0:00:00.530089
elapsed time: 0:01:14.402317
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:04:23.510292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.46
 ---- batch: 020 ----
mean loss: 300.11
 ---- batch: 030 ----
mean loss: 300.58
train mean loss: 298.11
epoch train time: 0:00:00.540784
elapsed time: 0:01:14.943456
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:04:24.051413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.88
 ---- batch: 020 ----
mean loss: 300.45
 ---- batch: 030 ----
mean loss: 297.40
train mean loss: 295.89
epoch train time: 0:00:00.525210
elapsed time: 0:01:15.468935
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:04:24.576891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.25
 ---- batch: 020 ----
mean loss: 297.61
 ---- batch: 030 ----
mean loss: 295.78
train mean loss: 295.92
epoch train time: 0:00:00.532419
elapsed time: 0:01:16.001763
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:04:25.109735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.77
 ---- batch: 020 ----
mean loss: 293.25
 ---- batch: 030 ----
mean loss: 296.01
train mean loss: 295.28
epoch train time: 0:00:00.551243
elapsed time: 0:01:16.553394
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:04:25.661361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.58
 ---- batch: 020 ----
mean loss: 291.87
 ---- batch: 030 ----
mean loss: 290.67
train mean loss: 293.21
epoch train time: 0:00:00.549579
elapsed time: 0:01:17.103287
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:04:26.211249
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.90
 ---- batch: 020 ----
mean loss: 291.16
 ---- batch: 030 ----
mean loss: 298.47
train mean loss: 293.00
epoch train time: 0:00:00.532775
elapsed time: 0:01:17.636357
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:04:26.744317
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.07
 ---- batch: 020 ----
mean loss: 290.34
 ---- batch: 030 ----
mean loss: 292.42
train mean loss: 291.25
epoch train time: 0:00:00.532046
elapsed time: 0:01:18.168764
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:04:27.276726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.36
 ---- batch: 020 ----
mean loss: 289.00
 ---- batch: 030 ----
mean loss: 291.25
train mean loss: 290.36
epoch train time: 0:00:00.531973
elapsed time: 0:01:18.701045
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:04:27.809044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.54
 ---- batch: 020 ----
mean loss: 284.71
 ---- batch: 030 ----
mean loss: 291.22
train mean loss: 289.57
epoch train time: 0:00:00.532411
elapsed time: 0:01:19.233820
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:04:28.341785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.04
 ---- batch: 020 ----
mean loss: 284.57
 ---- batch: 030 ----
mean loss: 281.96
train mean loss: 288.93
epoch train time: 0:00:00.534022
elapsed time: 0:01:19.768233
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:04:28.876205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.02
 ---- batch: 020 ----
mean loss: 291.20
 ---- batch: 030 ----
mean loss: 287.18
train mean loss: 287.76
epoch train time: 0:00:00.538105
elapsed time: 0:01:20.306779
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:04:29.414734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.57
 ---- batch: 020 ----
mean loss: 283.80
 ---- batch: 030 ----
mean loss: 289.53
train mean loss: 286.23
epoch train time: 0:00:00.543227
elapsed time: 0:01:20.850305
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:04:29.958281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 285.38
 ---- batch: 020 ----
mean loss: 287.24
 ---- batch: 030 ----
mean loss: 283.84
train mean loss: 285.00
epoch train time: 0:00:00.530243
elapsed time: 0:01:21.380886
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:04:30.488884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.45
 ---- batch: 020 ----
mean loss: 286.31
 ---- batch: 030 ----
mean loss: 285.65
train mean loss: 285.11
epoch train time: 0:00:00.543063
elapsed time: 0:01:21.924311
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:04:31.032275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.35
 ---- batch: 020 ----
mean loss: 284.36
 ---- batch: 030 ----
mean loss: 291.26
train mean loss: 284.47
epoch train time: 0:00:00.535110
elapsed time: 0:01:22.459718
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:04:31.567683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.68
 ---- batch: 020 ----
mean loss: 289.98
 ---- batch: 030 ----
mean loss: 280.79
train mean loss: 282.69
epoch train time: 0:00:00.529415
elapsed time: 0:01:22.989414
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:04:32.097373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.23
 ---- batch: 020 ----
mean loss: 284.29
 ---- batch: 030 ----
mean loss: 284.15
train mean loss: 282.16
epoch train time: 0:00:00.552937
elapsed time: 0:01:23.542683
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:04:32.650645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.00
 ---- batch: 020 ----
mean loss: 278.04
 ---- batch: 030 ----
mean loss: 275.80
train mean loss: 281.18
epoch train time: 0:00:00.539048
elapsed time: 0:01:24.082034
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:04:33.190003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.55
 ---- batch: 020 ----
mean loss: 276.07
 ---- batch: 030 ----
mean loss: 283.97
train mean loss: 280.99
epoch train time: 0:00:00.532475
elapsed time: 0:01:24.614817
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:04:33.722780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.47
 ---- batch: 020 ----
mean loss: 280.69
 ---- batch: 030 ----
mean loss: 285.14
train mean loss: 279.79
epoch train time: 0:00:00.530019
elapsed time: 0:01:25.145123
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:04:34.253099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.49
 ---- batch: 020 ----
mean loss: 278.24
 ---- batch: 030 ----
mean loss: 272.54
train mean loss: 278.79
epoch train time: 0:00:00.533219
elapsed time: 0:01:25.678676
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:04:34.786633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.82
 ---- batch: 020 ----
mean loss: 276.46
 ---- batch: 030 ----
mean loss: 281.89
train mean loss: 278.20
epoch train time: 0:00:00.535859
elapsed time: 0:01:26.214865
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:04:35.322826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.51
 ---- batch: 020 ----
mean loss: 276.15
 ---- batch: 030 ----
mean loss: 278.67
train mean loss: 276.95
epoch train time: 0:00:00.534771
elapsed time: 0:01:26.749975
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:04:35.857980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 279.42
 ---- batch: 020 ----
mean loss: 275.63
 ---- batch: 030 ----
mean loss: 271.48
train mean loss: 276.67
epoch train time: 0:00:00.528007
elapsed time: 0:01:27.278334
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:04:36.386292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.95
 ---- batch: 020 ----
mean loss: 278.41
 ---- batch: 030 ----
mean loss: 269.66
train mean loss: 275.58
epoch train time: 0:00:00.522419
elapsed time: 0:01:27.801025
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:04:36.908983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.26
 ---- batch: 020 ----
mean loss: 273.27
 ---- batch: 030 ----
mean loss: 273.50
train mean loss: 274.88
epoch train time: 0:00:00.546682
elapsed time: 0:01:28.347999
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:04:37.455963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.06
 ---- batch: 020 ----
mean loss: 275.88
 ---- batch: 030 ----
mean loss: 274.78
train mean loss: 273.01
epoch train time: 0:00:00.548008
elapsed time: 0:01:28.896304
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:04:38.004285
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.70
 ---- batch: 020 ----
mean loss: 275.12
 ---- batch: 030 ----
mean loss: 271.49
train mean loss: 272.28
epoch train time: 0:00:00.535400
elapsed time: 0:01:29.432049
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:04:38.540023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 272.05
 ---- batch: 020 ----
mean loss: 270.13
 ---- batch: 030 ----
mean loss: 275.04
train mean loss: 271.92
epoch train time: 0:00:00.550370
elapsed time: 0:01:29.982735
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:04:39.090694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.94
 ---- batch: 020 ----
mean loss: 275.95
 ---- batch: 030 ----
mean loss: 267.19
train mean loss: 271.20
epoch train time: 0:00:00.534184
elapsed time: 0:01:30.517204
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:04:39.625163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.17
 ---- batch: 020 ----
mean loss: 273.24
 ---- batch: 030 ----
mean loss: 267.79
train mean loss: 269.99
epoch train time: 0:00:00.534074
elapsed time: 0:01:31.051599
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:04:40.159559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.83
 ---- batch: 020 ----
mean loss: 268.39
 ---- batch: 030 ----
mean loss: 266.59
train mean loss: 268.66
epoch train time: 0:00:00.534330
elapsed time: 0:01:31.586236
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:04:40.694198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.38
 ---- batch: 020 ----
mean loss: 266.55
 ---- batch: 030 ----
mean loss: 272.36
train mean loss: 267.98
epoch train time: 0:00:00.535516
elapsed time: 0:01:32.122217
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:04:41.230159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.89
 ---- batch: 020 ----
mean loss: 264.62
 ---- batch: 030 ----
mean loss: 275.40
train mean loss: 267.07
epoch train time: 0:00:00.530878
elapsed time: 0:01:32.653362
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:04:41.761341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.55
 ---- batch: 020 ----
mean loss: 271.96
 ---- batch: 030 ----
mean loss: 264.76
train mean loss: 266.55
epoch train time: 0:00:00.534979
elapsed time: 0:01:33.188656
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:04:42.296614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.23
 ---- batch: 020 ----
mean loss: 269.59
 ---- batch: 030 ----
mean loss: 265.14
train mean loss: 265.93
epoch train time: 0:00:00.536304
elapsed time: 0:01:33.725345
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:04:42.833311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.79
 ---- batch: 020 ----
mean loss: 266.14
 ---- batch: 030 ----
mean loss: 260.04
train mean loss: 265.40
epoch train time: 0:00:00.537250
elapsed time: 0:01:34.262904
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:04:43.370862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.80
 ---- batch: 020 ----
mean loss: 263.52
 ---- batch: 030 ----
mean loss: 265.49
train mean loss: 264.02
epoch train time: 0:00:00.529506
elapsed time: 0:01:34.792718
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:04:43.900704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.33
 ---- batch: 020 ----
mean loss: 266.32
 ---- batch: 030 ----
mean loss: 266.74
train mean loss: 263.98
epoch train time: 0:00:00.536794
elapsed time: 0:01:35.329850
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:04:44.437814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.73
 ---- batch: 020 ----
mean loss: 259.97
 ---- batch: 030 ----
mean loss: 260.41
train mean loss: 262.41
epoch train time: 0:00:00.533559
elapsed time: 0:01:35.863853
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:04:44.971895
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.21
 ---- batch: 020 ----
mean loss: 263.15
 ---- batch: 030 ----
mean loss: 255.97
train mean loss: 261.79
epoch train time: 0:00:00.540985
elapsed time: 0:01:36.405285
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:04:45.513244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.50
 ---- batch: 020 ----
mean loss: 266.38
 ---- batch: 030 ----
mean loss: 259.85
train mean loss: 260.95
epoch train time: 0:00:00.533264
elapsed time: 0:01:36.938844
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:04:46.046815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.92
 ---- batch: 020 ----
mean loss: 256.21
 ---- batch: 030 ----
mean loss: 262.49
train mean loss: 259.97
epoch train time: 0:00:00.534138
elapsed time: 0:01:37.473294
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:04:46.581255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.75
 ---- batch: 020 ----
mean loss: 260.45
 ---- batch: 030 ----
mean loss: 259.79
train mean loss: 259.83
epoch train time: 0:00:00.541129
elapsed time: 0:01:38.014731
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:04:47.122710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.91
 ---- batch: 020 ----
mean loss: 262.90
 ---- batch: 030 ----
mean loss: 257.53
train mean loss: 258.34
epoch train time: 0:00:00.546863
elapsed time: 0:01:38.561968
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:04:47.669975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.64
 ---- batch: 020 ----
mean loss: 254.79
 ---- batch: 030 ----
mean loss: 260.34
train mean loss: 257.39
epoch train time: 0:00:00.546270
elapsed time: 0:01:39.108590
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:04:48.216548
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.82
 ---- batch: 020 ----
mean loss: 256.63
 ---- batch: 030 ----
mean loss: 260.90
train mean loss: 256.97
epoch train time: 0:00:00.533029
elapsed time: 0:01:39.641924
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:04:48.749887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.68
 ---- batch: 020 ----
mean loss: 261.24
 ---- batch: 030 ----
mean loss: 254.90
train mean loss: 255.88
epoch train time: 0:00:00.538894
elapsed time: 0:01:40.181111
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:04:49.289076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.87
 ---- batch: 020 ----
mean loss: 260.81
 ---- batch: 030 ----
mean loss: 255.05
train mean loss: 255.93
epoch train time: 0:00:00.546516
elapsed time: 0:01:40.727930
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:04:49.835905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.75
 ---- batch: 020 ----
mean loss: 256.34
 ---- batch: 030 ----
mean loss: 251.58
train mean loss: 254.96
epoch train time: 0:00:00.528292
elapsed time: 0:01:41.256518
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:04:50.364479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.28
 ---- batch: 020 ----
mean loss: 256.99
 ---- batch: 030 ----
mean loss: 252.96
train mean loss: 253.30
epoch train time: 0:00:00.530356
elapsed time: 0:01:41.787179
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:04:50.895152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.87
 ---- batch: 020 ----
mean loss: 247.39
 ---- batch: 030 ----
mean loss: 258.58
train mean loss: 252.79
epoch train time: 0:00:00.535761
elapsed time: 0:01:42.323247
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:04:51.431206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.04
 ---- batch: 020 ----
mean loss: 249.42
 ---- batch: 030 ----
mean loss: 252.31
train mean loss: 251.70
epoch train time: 0:00:00.545761
elapsed time: 0:01:42.869322
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:04:51.977308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.11
 ---- batch: 020 ----
mean loss: 252.02
 ---- batch: 030 ----
mean loss: 247.09
train mean loss: 251.23
epoch train time: 0:00:00.536187
elapsed time: 0:01:43.405903
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:04:52.513901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.90
 ---- batch: 020 ----
mean loss: 251.55
 ---- batch: 030 ----
mean loss: 250.54
train mean loss: 251.16
epoch train time: 0:00:00.546664
elapsed time: 0:01:43.952902
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:04:53.060867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.40
 ---- batch: 020 ----
mean loss: 252.35
 ---- batch: 030 ----
mean loss: 253.98
train mean loss: 250.12
epoch train time: 0:00:00.518724
elapsed time: 0:01:44.471918
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:04:53.579872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.02
 ---- batch: 020 ----
mean loss: 241.62
 ---- batch: 030 ----
mean loss: 252.68
train mean loss: 249.47
epoch train time: 0:00:00.534521
elapsed time: 0:01:45.006725
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:04:54.114689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.99
 ---- batch: 020 ----
mean loss: 253.23
 ---- batch: 030 ----
mean loss: 243.64
train mean loss: 248.63
epoch train time: 0:00:00.530657
elapsed time: 0:01:45.537730
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:04:54.645687
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.66
 ---- batch: 020 ----
mean loss: 250.85
 ---- batch: 030 ----
mean loss: 250.36
train mean loss: 248.02
epoch train time: 0:00:00.532449
elapsed time: 0:01:46.070480
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:04:55.178457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.52
 ---- batch: 020 ----
mean loss: 246.20
 ---- batch: 030 ----
mean loss: 248.45
train mean loss: 247.57
epoch train time: 0:00:00.536847
elapsed time: 0:01:46.607652
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:04:55.715613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.38
 ---- batch: 020 ----
mean loss: 239.72
 ---- batch: 030 ----
mean loss: 254.04
train mean loss: 246.57
epoch train time: 0:00:00.527965
elapsed time: 0:01:47.135937
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:04:56.243939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 248.12
 ---- batch: 020 ----
mean loss: 240.20
 ---- batch: 030 ----
mean loss: 245.75
train mean loss: 245.63
epoch train time: 0:00:00.529904
elapsed time: 0:01:47.666174
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:04:56.774137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.23
 ---- batch: 020 ----
mean loss: 253.14
 ---- batch: 030 ----
mean loss: 239.72
train mean loss: 245.38
epoch train time: 0:00:00.522220
elapsed time: 0:01:48.188689
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:04:57.296652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.42
 ---- batch: 020 ----
mean loss: 244.19
 ---- batch: 030 ----
mean loss: 247.71
train mean loss: 244.19
epoch train time: 0:00:00.531772
elapsed time: 0:01:48.720818
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:04:57.828774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.97
 ---- batch: 020 ----
mean loss: 247.07
 ---- batch: 030 ----
mean loss: 241.46
train mean loss: 244.48
epoch train time: 0:00:00.523778
elapsed time: 0:01:49.244870
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:04:58.352845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.20
 ---- batch: 020 ----
mean loss: 243.13
 ---- batch: 030 ----
mean loss: 243.29
train mean loss: 242.95
epoch train time: 0:00:00.521031
elapsed time: 0:01:49.766206
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:04:58.874168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.88
 ---- batch: 020 ----
mean loss: 241.87
 ---- batch: 030 ----
mean loss: 241.54
train mean loss: 241.91
epoch train time: 0:00:00.525760
elapsed time: 0:01:50.292367
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:04:59.400369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.29
 ---- batch: 020 ----
mean loss: 239.59
 ---- batch: 030 ----
mean loss: 243.90
train mean loss: 241.86
epoch train time: 0:00:00.537504
elapsed time: 0:01:50.830243
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:04:59.938203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.19
 ---- batch: 020 ----
mean loss: 235.82
 ---- batch: 030 ----
mean loss: 239.66
train mean loss: 240.97
epoch train time: 0:00:00.528941
elapsed time: 0:01:51.359478
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:05:00.467449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.61
 ---- batch: 020 ----
mean loss: 250.77
 ---- batch: 030 ----
mean loss: 232.02
train mean loss: 240.23
epoch train time: 0:00:00.531061
elapsed time: 0:01:51.890841
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:05:00.998799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.64
 ---- batch: 020 ----
mean loss: 243.62
 ---- batch: 030 ----
mean loss: 238.30
train mean loss: 239.58
epoch train time: 0:00:00.530490
elapsed time: 0:01:52.421611
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:05:01.529582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.86
 ---- batch: 020 ----
mean loss: 246.39
 ---- batch: 030 ----
mean loss: 239.67
train mean loss: 239.25
epoch train time: 0:00:00.533809
elapsed time: 0:01:52.955773
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:05:02.063740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.93
 ---- batch: 020 ----
mean loss: 232.73
 ---- batch: 030 ----
mean loss: 244.35
train mean loss: 238.19
epoch train time: 0:00:00.531774
elapsed time: 0:01:53.487864
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:05:02.595826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.22
 ---- batch: 020 ----
mean loss: 241.37
 ---- batch: 030 ----
mean loss: 241.74
train mean loss: 237.32
epoch train time: 0:00:00.537731
elapsed time: 0:01:54.025955
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:05:03.133924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.39
 ---- batch: 020 ----
mean loss: 241.25
 ---- batch: 030 ----
mean loss: 235.89
train mean loss: 236.79
epoch train time: 0:00:00.527818
elapsed time: 0:01:54.554070
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:05:03.662028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.71
 ---- batch: 020 ----
mean loss: 236.84
 ---- batch: 030 ----
mean loss: 237.72
train mean loss: 236.45
epoch train time: 0:00:00.543038
elapsed time: 0:01:55.097387
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:05:04.205347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.67
 ---- batch: 020 ----
mean loss: 240.56
 ---- batch: 030 ----
mean loss: 230.13
train mean loss: 235.39
epoch train time: 0:00:00.539754
elapsed time: 0:01:55.637517
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:05:04.745493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.28
 ---- batch: 020 ----
mean loss: 239.19
 ---- batch: 030 ----
mean loss: 232.26
train mean loss: 234.70
epoch train time: 0:00:00.540397
elapsed time: 0:01:56.178225
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:05:05.286201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.82
 ---- batch: 020 ----
mean loss: 239.64
 ---- batch: 030 ----
mean loss: 231.27
train mean loss: 234.30
epoch train time: 0:00:00.534919
elapsed time: 0:01:56.713465
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:05:05.821435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.63
 ---- batch: 020 ----
mean loss: 231.21
 ---- batch: 030 ----
mean loss: 236.14
train mean loss: 233.69
epoch train time: 0:00:00.533912
elapsed time: 0:01:57.247721
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:05:06.355695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.67
 ---- batch: 020 ----
mean loss: 231.88
 ---- batch: 030 ----
mean loss: 229.50
train mean loss: 232.46
epoch train time: 0:00:00.537103
elapsed time: 0:01:57.785298
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:05:06.893286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.94
 ---- batch: 020 ----
mean loss: 240.78
 ---- batch: 030 ----
mean loss: 230.16
train mean loss: 232.58
epoch train time: 0:00:00.529930
elapsed time: 0:01:58.315537
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:05:07.423498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.11
 ---- batch: 020 ----
mean loss: 232.97
 ---- batch: 030 ----
mean loss: 231.74
train mean loss: 231.57
epoch train time: 0:00:00.528141
elapsed time: 0:01:58.843962
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:05:07.951920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.03
 ---- batch: 020 ----
mean loss: 230.37
 ---- batch: 030 ----
mean loss: 233.54
train mean loss: 230.50
epoch train time: 0:00:00.532409
elapsed time: 0:01:59.376677
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:05:08.484639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.58
 ---- batch: 020 ----
mean loss: 231.44
 ---- batch: 030 ----
mean loss: 232.04
train mean loss: 230.47
epoch train time: 0:00:00.542862
elapsed time: 0:01:59.919839
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:05:09.027800
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 230.66
 ---- batch: 020 ----
mean loss: 228.64
 ---- batch: 030 ----
mean loss: 232.37
train mean loss: 229.97
epoch train time: 0:00:00.537434
elapsed time: 0:02:00.457670
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:05:09.565591
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 220.82
 ---- batch: 020 ----
mean loss: 232.55
 ---- batch: 030 ----
mean loss: 234.25
train mean loss: 229.97
epoch train time: 0:00:00.537649
elapsed time: 0:02:00.995558
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:05:10.103532
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 235.19
 ---- batch: 020 ----
mean loss: 234.34
 ---- batch: 030 ----
mean loss: 222.09
train mean loss: 230.22
epoch train time: 0:00:00.521222
elapsed time: 0:02:01.517069
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:05:10.625038
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.16
 ---- batch: 020 ----
mean loss: 224.75
 ---- batch: 030 ----
mean loss: 234.49
train mean loss: 229.27
epoch train time: 0:00:00.522667
elapsed time: 0:02:02.040058
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:05:11.148031
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 230.90
 ---- batch: 020 ----
mean loss: 229.54
 ---- batch: 030 ----
mean loss: 229.49
train mean loss: 229.39
epoch train time: 0:00:00.526353
elapsed time: 0:02:02.566788
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:05:11.674786
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.04
 ---- batch: 020 ----
mean loss: 230.76
 ---- batch: 030 ----
mean loss: 226.09
train mean loss: 230.40
epoch train time: 0:00:00.540093
elapsed time: 0:02:03.107266
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:05:12.215306
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.05
 ---- batch: 020 ----
mean loss: 227.32
 ---- batch: 030 ----
mean loss: 234.18
train mean loss: 229.29
epoch train time: 0:00:00.556086
elapsed time: 0:02:03.663760
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:05:12.771720
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.91
 ---- batch: 020 ----
mean loss: 227.91
 ---- batch: 030 ----
mean loss: 230.67
train mean loss: 229.68
epoch train time: 0:00:00.538748
elapsed time: 0:02:04.202880
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:05:13.310840
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.41
 ---- batch: 020 ----
mean loss: 235.77
 ---- batch: 030 ----
mean loss: 229.26
train mean loss: 229.55
epoch train time: 0:00:00.538711
elapsed time: 0:02:04.741917
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:05:13.849898
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.83
 ---- batch: 020 ----
mean loss: 226.08
 ---- batch: 030 ----
mean loss: 236.38
train mean loss: 229.61
epoch train time: 0:00:00.531033
elapsed time: 0:02:05.273314
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:05:14.381275
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.01
 ---- batch: 020 ----
mean loss: 230.05
 ---- batch: 030 ----
mean loss: 234.83
train mean loss: 229.40
epoch train time: 0:00:00.529053
elapsed time: 0:02:05.802686
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:05:14.910646
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.30
 ---- batch: 020 ----
mean loss: 235.74
 ---- batch: 030 ----
mean loss: 229.16
train mean loss: 229.21
epoch train time: 0:00:00.522234
elapsed time: 0:02:06.325238
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:05:15.433198
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 238.80
 ---- batch: 020 ----
mean loss: 225.38
 ---- batch: 030 ----
mean loss: 225.15
train mean loss: 229.60
epoch train time: 0:00:00.527092
elapsed time: 0:02:06.852662
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:05:15.960623
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.97
 ---- batch: 020 ----
mean loss: 228.69
 ---- batch: 030 ----
mean loss: 225.93
train mean loss: 229.66
epoch train time: 0:00:00.534421
elapsed time: 0:02:07.387433
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:05:16.495396
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.61
 ---- batch: 020 ----
mean loss: 227.77
 ---- batch: 030 ----
mean loss: 229.45
train mean loss: 229.40
epoch train time: 0:00:00.540202
elapsed time: 0:02:07.928080
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:05:17.036050
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.62
 ---- batch: 020 ----
mean loss: 230.22
 ---- batch: 030 ----
mean loss: 227.68
train mean loss: 229.49
epoch train time: 0:00:00.535019
elapsed time: 0:02:08.463471
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:05:17.571432
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.80
 ---- batch: 020 ----
mean loss: 226.07
 ---- batch: 030 ----
mean loss: 231.46
train mean loss: 229.45
epoch train time: 0:00:00.547642
elapsed time: 0:02:09.011444
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:05:18.119444
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.83
 ---- batch: 020 ----
mean loss: 225.39
 ---- batch: 030 ----
mean loss: 228.43
train mean loss: 230.02
epoch train time: 0:00:00.542320
elapsed time: 0:02:09.554119
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:05:18.662082
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 230.01
 ---- batch: 020 ----
mean loss: 228.90
 ---- batch: 030 ----
mean loss: 230.35
train mean loss: 228.81
epoch train time: 0:00:00.527942
elapsed time: 0:02:10.082356
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:05:19.190318
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.65
 ---- batch: 020 ----
mean loss: 230.25
 ---- batch: 030 ----
mean loss: 224.61
train mean loss: 228.37
epoch train time: 0:00:00.532959
elapsed time: 0:02:10.615663
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:05:19.723659
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.83
 ---- batch: 020 ----
mean loss: 231.64
 ---- batch: 030 ----
mean loss: 229.60
train mean loss: 229.15
epoch train time: 0:00:00.543974
elapsed time: 0:02:11.159992
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:05:20.267964
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 233.24
 ---- batch: 020 ----
mean loss: 222.06
 ---- batch: 030 ----
mean loss: 229.06
train mean loss: 228.69
epoch train time: 0:00:00.551488
elapsed time: 0:02:11.711829
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:05:20.819808
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.72
 ---- batch: 020 ----
mean loss: 229.38
 ---- batch: 030 ----
mean loss: 228.33
train mean loss: 228.58
epoch train time: 0:00:00.537685
elapsed time: 0:02:12.249848
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:05:21.357829
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 229.11
 ---- batch: 020 ----
mean loss: 228.77
 ---- batch: 030 ----
mean loss: 230.88
train mean loss: 228.91
epoch train time: 0:00:00.537705
elapsed time: 0:02:12.787866
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:05:21.895823
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.80
 ---- batch: 020 ----
mean loss: 231.64
 ---- batch: 030 ----
mean loss: 227.14
train mean loss: 228.84
epoch train time: 0:00:00.527172
elapsed time: 0:02:13.315351
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:05:22.423315
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.42
 ---- batch: 020 ----
mean loss: 228.21
 ---- batch: 030 ----
mean loss: 226.38
train mean loss: 228.20
epoch train time: 0:00:00.534540
elapsed time: 0:02:13.850217
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:05:22.958176
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.09
 ---- batch: 020 ----
mean loss: 230.15
 ---- batch: 030 ----
mean loss: 227.00
train mean loss: 228.36
epoch train time: 0:00:00.542962
elapsed time: 0:02:14.393479
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:05:23.501443
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 223.93
 ---- batch: 020 ----
mean loss: 231.95
 ---- batch: 030 ----
mean loss: 226.91
train mean loss: 228.25
epoch train time: 0:00:00.556142
elapsed time: 0:02:14.950025
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:05:24.057989
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 224.72
 ---- batch: 020 ----
mean loss: 226.89
 ---- batch: 030 ----
mean loss: 227.81
train mean loss: 228.08
epoch train time: 0:00:00.534865
elapsed time: 0:02:15.485178
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:05:24.593152
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.22
 ---- batch: 020 ----
mean loss: 234.47
 ---- batch: 030 ----
mean loss: 222.28
train mean loss: 227.93
epoch train time: 0:00:00.533901
elapsed time: 0:02:16.019389
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:05:25.127349
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 233.13
 ---- batch: 020 ----
mean loss: 222.54
 ---- batch: 030 ----
mean loss: 230.14
train mean loss: 228.11
epoch train time: 0:00:00.548393
elapsed time: 0:02:16.568081
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:05:25.676056
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.53
 ---- batch: 020 ----
mean loss: 227.44
 ---- batch: 030 ----
mean loss: 232.54
train mean loss: 228.33
epoch train time: 0:00:00.541300
elapsed time: 0:02:17.109830
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:05:26.217812
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 225.01
 ---- batch: 020 ----
mean loss: 232.77
 ---- batch: 030 ----
mean loss: 228.47
train mean loss: 227.72
epoch train time: 0:00:00.549015
elapsed time: 0:02:17.659243
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:05:26.767162
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.33
 ---- batch: 020 ----
mean loss: 225.31
 ---- batch: 030 ----
mean loss: 228.05
train mean loss: 228.15
epoch train time: 0:00:00.533556
elapsed time: 0:02:18.193114
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:05:27.301076
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 227.58
 ---- batch: 020 ----
mean loss: 225.79
 ---- batch: 030 ----
mean loss: 228.08
train mean loss: 227.72
epoch train time: 0:00:00.530976
elapsed time: 0:02:18.724423
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:05:27.832396
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.95
 ---- batch: 020 ----
mean loss: 229.63
 ---- batch: 030 ----
mean loss: 225.76
train mean loss: 228.11
epoch train time: 0:00:00.546264
elapsed time: 0:02:19.271050
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:05:28.379032
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.21
 ---- batch: 020 ----
mean loss: 233.08
 ---- batch: 030 ----
mean loss: 226.89
train mean loss: 227.65
epoch train time: 0:00:00.546690
elapsed time: 0:02:19.818079
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:05:28.926067
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.79
 ---- batch: 020 ----
mean loss: 228.59
 ---- batch: 030 ----
mean loss: 222.41
train mean loss: 227.77
epoch train time: 0:00:00.523615
elapsed time: 0:02:20.342044
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:05:29.450025
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 220.65
 ---- batch: 020 ----
mean loss: 233.23
 ---- batch: 030 ----
mean loss: 225.91
train mean loss: 227.91
epoch train time: 0:00:00.553382
elapsed time: 0:02:20.895742
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:05:30.003703
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.66
 ---- batch: 020 ----
mean loss: 225.23
 ---- batch: 030 ----
mean loss: 229.02
train mean loss: 226.90
epoch train time: 0:00:00.525698
elapsed time: 0:02:21.421733
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:05:30.529783
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 233.62
 ---- batch: 020 ----
mean loss: 225.15
 ---- batch: 030 ----
mean loss: 224.25
train mean loss: 226.81
epoch train time: 0:00:00.537128
elapsed time: 0:02:21.959248
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:05:31.067213
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 228.90
 ---- batch: 020 ----
mean loss: 224.07
 ---- batch: 030 ----
mean loss: 229.86
train mean loss: 227.63
epoch train time: 0:00:00.535583
elapsed time: 0:02:22.495128
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:05:31.603096
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.15
 ---- batch: 020 ----
mean loss: 231.86
 ---- batch: 030 ----
mean loss: 225.70
train mean loss: 226.95
epoch train time: 0:00:00.540682
elapsed time: 0:02:23.036199
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:05:32.144164
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.45
 ---- batch: 020 ----
mean loss: 228.27
 ---- batch: 030 ----
mean loss: 219.81
train mean loss: 227.19
epoch train time: 0:00:00.535147
elapsed time: 0:02:23.571670
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:05:32.679635
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 232.16
 ---- batch: 020 ----
mean loss: 222.75
 ---- batch: 030 ----
mean loss: 227.34
train mean loss: 227.22
epoch train time: 0:00:00.533882
elapsed time: 0:02:24.105979
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:05:33.213977
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 221.07
 ---- batch: 020 ----
mean loss: 232.40
 ---- batch: 030 ----
mean loss: 223.71
train mean loss: 227.10
epoch train time: 0:00:00.541548
elapsed time: 0:02:24.647925
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:05:33.755887
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.43
 ---- batch: 020 ----
mean loss: 230.07
 ---- batch: 030 ----
mean loss: 220.50
train mean loss: 227.26
epoch train time: 0:00:00.524181
elapsed time: 0:02:25.172416
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:05:34.280373
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 231.06
 ---- batch: 020 ----
mean loss: 224.78
 ---- batch: 030 ----
mean loss: 229.21
train mean loss: 227.08
epoch train time: 0:00:00.528553
elapsed time: 0:02:25.701277
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:05:34.809247
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 226.06
 ---- batch: 020 ----
mean loss: 224.53
 ---- batch: 030 ----
mean loss: 228.94
train mean loss: 226.75
epoch train time: 0:00:00.535744
elapsed time: 0:02:26.241126
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_9/checkpoint.pth.tar
**** end time: 2019-09-27 15:05:35.349010 ****
