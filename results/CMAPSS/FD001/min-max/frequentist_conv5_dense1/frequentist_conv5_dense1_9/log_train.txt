Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_9', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 31336
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 16:33:22.977726 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:33:22.986175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3651.98
 ---- batch: 020 ----
mean loss: 1442.27
 ---- batch: 030 ----
mean loss: 685.89
train mean loss: 1738.42
epoch train time: 0:00:13.045376
elapsed time: 0:00:13.056385
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:33:36.034152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 459.65
 ---- batch: 020 ----
mean loss: 402.09
 ---- batch: 030 ----
mean loss: 367.58
train mean loss: 403.79
epoch train time: 0:00:01.505349
elapsed time: 0:00:14.561896
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:33:37.539697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 349.14
 ---- batch: 020 ----
mean loss: 343.51
 ---- batch: 030 ----
mean loss: 333.04
train mean loss: 340.43
epoch train time: 0:00:01.441270
elapsed time: 0:00:16.003351
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:33:38.981133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.29
 ---- batch: 020 ----
mean loss: 314.28
 ---- batch: 030 ----
mean loss: 299.60
train mean loss: 309.35
epoch train time: 0:00:01.440745
elapsed time: 0:00:17.444293
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:33:40.422078
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.97
 ---- batch: 020 ----
mean loss: 278.96
 ---- batch: 030 ----
mean loss: 267.81
train mean loss: 273.73
epoch train time: 0:00:01.438511
elapsed time: 0:00:18.882972
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:33:41.860753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.13
 ---- batch: 020 ----
mean loss: 253.80
 ---- batch: 030 ----
mean loss: 238.03
train mean loss: 242.27
epoch train time: 0:00:01.441468
elapsed time: 0:00:20.324608
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:33:43.302390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.32
 ---- batch: 020 ----
mean loss: 225.35
 ---- batch: 030 ----
mean loss: 227.30
train mean loss: 229.03
epoch train time: 0:00:01.437995
elapsed time: 0:00:21.762813
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:33:44.740597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.55
 ---- batch: 020 ----
mean loss: 220.61
 ---- batch: 030 ----
mean loss: 213.32
train mean loss: 218.39
epoch train time: 0:00:01.438451
elapsed time: 0:00:23.201459
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:33:46.179238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.56
 ---- batch: 020 ----
mean loss: 210.42
 ---- batch: 030 ----
mean loss: 216.05
train mean loss: 213.23
epoch train time: 0:00:01.438446
elapsed time: 0:00:24.640081
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:33:47.617876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.52
 ---- batch: 020 ----
mean loss: 212.79
 ---- batch: 030 ----
mean loss: 210.12
train mean loss: 210.62
epoch train time: 0:00:01.440150
elapsed time: 0:00:26.080407
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:33:49.058187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 206.09
 ---- batch: 020 ----
mean loss: 197.27
 ---- batch: 030 ----
mean loss: 199.90
train mean loss: 200.73
epoch train time: 0:00:01.442564
elapsed time: 0:00:27.523170
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:33:50.500963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.08
 ---- batch: 020 ----
mean loss: 198.78
 ---- batch: 030 ----
mean loss: 196.66
train mean loss: 196.19
epoch train time: 0:00:01.441083
elapsed time: 0:00:28.964433
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:33:51.942237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.41
 ---- batch: 020 ----
mean loss: 189.41
 ---- batch: 030 ----
mean loss: 187.70
train mean loss: 190.47
epoch train time: 0:00:01.442587
elapsed time: 0:00:30.407204
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:33:53.384984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.88
 ---- batch: 020 ----
mean loss: 199.31
 ---- batch: 030 ----
mean loss: 196.85
train mean loss: 196.82
epoch train time: 0:00:01.443366
elapsed time: 0:00:31.850737
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:33:54.828520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.74
 ---- batch: 020 ----
mean loss: 191.18
 ---- batch: 030 ----
mean loss: 192.01
train mean loss: 191.47
epoch train time: 0:00:01.442051
elapsed time: 0:00:33.292958
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:33:56.270742
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.53
 ---- batch: 020 ----
mean loss: 188.60
 ---- batch: 030 ----
mean loss: 195.69
train mean loss: 190.89
epoch train time: 0:00:01.441069
elapsed time: 0:00:34.734219
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:33:57.712000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.39
 ---- batch: 020 ----
mean loss: 185.75
 ---- batch: 030 ----
mean loss: 191.91
train mean loss: 187.42
epoch train time: 0:00:01.443421
elapsed time: 0:00:36.177838
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:33:59.155621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.13
 ---- batch: 020 ----
mean loss: 183.38
 ---- batch: 030 ----
mean loss: 184.19
train mean loss: 186.65
epoch train time: 0:00:01.441330
elapsed time: 0:00:37.619418
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:34:00.597232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.83
 ---- batch: 020 ----
mean loss: 190.70
 ---- batch: 030 ----
mean loss: 187.69
train mean loss: 189.45
epoch train time: 0:00:01.441166
elapsed time: 0:00:39.060785
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:34:02.038566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.35
 ---- batch: 020 ----
mean loss: 187.74
 ---- batch: 030 ----
mean loss: 188.34
train mean loss: 185.25
epoch train time: 0:00:01.443175
elapsed time: 0:00:40.504127
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:34:03.481909
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.12
 ---- batch: 020 ----
mean loss: 187.33
 ---- batch: 030 ----
mean loss: 182.76
train mean loss: 184.79
epoch train time: 0:00:01.440792
elapsed time: 0:00:41.945102
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:34:04.922881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.91
 ---- batch: 020 ----
mean loss: 184.08
 ---- batch: 030 ----
mean loss: 188.17
train mean loss: 184.53
epoch train time: 0:00:01.438682
elapsed time: 0:00:43.383965
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:34:06.361766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.06
 ---- batch: 020 ----
mean loss: 182.02
 ---- batch: 030 ----
mean loss: 181.44
train mean loss: 184.00
epoch train time: 0:00:01.440935
elapsed time: 0:00:44.825112
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:34:07.802900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.49
 ---- batch: 020 ----
mean loss: 182.82
 ---- batch: 030 ----
mean loss: 185.56
train mean loss: 182.78
epoch train time: 0:00:01.440126
elapsed time: 0:00:46.265410
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:34:09.243191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.13
 ---- batch: 020 ----
mean loss: 178.77
 ---- batch: 030 ----
mean loss: 179.97
train mean loss: 178.51
epoch train time: 0:00:01.439479
elapsed time: 0:00:47.705065
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:34:10.682882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.52
 ---- batch: 020 ----
mean loss: 179.91
 ---- batch: 030 ----
mean loss: 190.60
train mean loss: 185.80
epoch train time: 0:00:01.440983
elapsed time: 0:00:49.146261
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:34:12.124047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.64
 ---- batch: 020 ----
mean loss: 184.32
 ---- batch: 030 ----
mean loss: 184.41
train mean loss: 185.50
epoch train time: 0:00:01.442775
elapsed time: 0:00:50.589242
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:34:13.567022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.22
 ---- batch: 020 ----
mean loss: 180.71
 ---- batch: 030 ----
mean loss: 181.70
train mean loss: 179.01
epoch train time: 0:00:01.439420
elapsed time: 0:00:52.028827
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:34:15.006605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.85
 ---- batch: 020 ----
mean loss: 179.29
 ---- batch: 030 ----
mean loss: 176.52
train mean loss: 180.28
epoch train time: 0:00:01.442714
elapsed time: 0:00:53.471746
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:34:16.449528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.40
 ---- batch: 020 ----
mean loss: 174.94
 ---- batch: 030 ----
mean loss: 179.00
train mean loss: 178.96
epoch train time: 0:00:01.437295
elapsed time: 0:00:54.909222
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:34:17.887026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.45
 ---- batch: 020 ----
mean loss: 175.21
 ---- batch: 030 ----
mean loss: 179.91
train mean loss: 176.30
epoch train time: 0:00:01.441455
elapsed time: 0:00:56.350866
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:34:19.328657
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.92
 ---- batch: 020 ----
mean loss: 178.93
 ---- batch: 030 ----
mean loss: 180.65
train mean loss: 179.02
epoch train time: 0:00:01.440115
elapsed time: 0:00:57.791159
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:34:20.768954
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.25
 ---- batch: 020 ----
mean loss: 174.26
 ---- batch: 030 ----
mean loss: 178.27
train mean loss: 177.92
epoch train time: 0:00:01.441556
elapsed time: 0:00:59.232890
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:34:22.210674
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.84
 ---- batch: 020 ----
mean loss: 177.49
 ---- batch: 030 ----
mean loss: 183.46
train mean loss: 177.67
epoch train time: 0:00:01.440251
elapsed time: 0:01:00.673311
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:34:23.651125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.24
 ---- batch: 020 ----
mean loss: 177.47
 ---- batch: 030 ----
mean loss: 175.23
train mean loss: 176.36
epoch train time: 0:00:01.440954
elapsed time: 0:01:02.114460
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:34:25.092241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.29
 ---- batch: 020 ----
mean loss: 179.54
 ---- batch: 030 ----
mean loss: 178.91
train mean loss: 180.17
epoch train time: 0:00:01.440362
elapsed time: 0:01:03.554999
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:34:26.532784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.70
 ---- batch: 020 ----
mean loss: 174.00
 ---- batch: 030 ----
mean loss: 169.71
train mean loss: 172.98
epoch train time: 0:00:01.440418
elapsed time: 0:01:04.995586
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:34:27.973368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.79
 ---- batch: 020 ----
mean loss: 177.14
 ---- batch: 030 ----
mean loss: 181.52
train mean loss: 179.95
epoch train time: 0:00:01.441596
elapsed time: 0:01:06.437358
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:34:29.415136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.48
 ---- batch: 020 ----
mean loss: 174.59
 ---- batch: 030 ----
mean loss: 180.65
train mean loss: 176.61
epoch train time: 0:00:01.438144
elapsed time: 0:01:07.875706
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:34:30.853517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.87
 ---- batch: 020 ----
mean loss: 176.73
 ---- batch: 030 ----
mean loss: 178.24
train mean loss: 175.26
epoch train time: 0:00:01.440358
elapsed time: 0:01:09.316258
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:34:32.294039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.93
 ---- batch: 020 ----
mean loss: 169.43
 ---- batch: 030 ----
mean loss: 170.76
train mean loss: 171.98
epoch train time: 0:00:01.440282
elapsed time: 0:01:10.756703
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:34:33.734482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.72
 ---- batch: 020 ----
mean loss: 169.84
 ---- batch: 030 ----
mean loss: 167.37
train mean loss: 169.69
epoch train time: 0:00:01.437822
elapsed time: 0:01:12.194685
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:34:35.172491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.05
 ---- batch: 020 ----
mean loss: 171.12
 ---- batch: 030 ----
mean loss: 169.62
train mean loss: 167.76
epoch train time: 0:00:01.439538
elapsed time: 0:01:13.634404
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:34:36.612181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.82
 ---- batch: 020 ----
mean loss: 167.01
 ---- batch: 030 ----
mean loss: 171.41
train mean loss: 169.82
epoch train time: 0:00:01.438917
elapsed time: 0:01:15.073484
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:34:38.051252
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.26
 ---- batch: 020 ----
mean loss: 168.26
 ---- batch: 030 ----
mean loss: 172.62
train mean loss: 169.56
epoch train time: 0:00:01.437572
elapsed time: 0:01:16.511229
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:34:39.489010
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.32
 ---- batch: 020 ----
mean loss: 166.28
 ---- batch: 030 ----
mean loss: 170.45
train mean loss: 165.67
epoch train time: 0:00:01.441951
elapsed time: 0:01:17.953378
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:34:40.931161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.69
 ---- batch: 020 ----
mean loss: 171.42
 ---- batch: 030 ----
mean loss: 162.67
train mean loss: 167.84
epoch train time: 0:00:01.437845
elapsed time: 0:01:19.391400
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:34:42.369184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.52
 ---- batch: 020 ----
mean loss: 161.10
 ---- batch: 030 ----
mean loss: 163.28
train mean loss: 163.45
epoch train time: 0:00:01.442234
elapsed time: 0:01:20.833821
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:34:43.811593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.78
 ---- batch: 020 ----
mean loss: 157.44
 ---- batch: 030 ----
mean loss: 162.56
train mean loss: 159.61
epoch train time: 0:00:01.439865
elapsed time: 0:01:22.273845
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:34:45.251624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.94
 ---- batch: 020 ----
mean loss: 164.74
 ---- batch: 030 ----
mean loss: 160.02
train mean loss: 161.72
epoch train time: 0:00:01.439196
elapsed time: 0:01:23.713231
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:34:46.691017
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.56
 ---- batch: 020 ----
mean loss: 155.26
 ---- batch: 030 ----
mean loss: 163.22
train mean loss: 161.91
epoch train time: 0:00:01.439152
elapsed time: 0:01:25.152553
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:34:48.130333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.56
 ---- batch: 020 ----
mean loss: 160.50
 ---- batch: 030 ----
mean loss: 163.54
train mean loss: 161.06
epoch train time: 0:00:01.438601
elapsed time: 0:01:26.591382
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:34:49.569215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.46
 ---- batch: 020 ----
mean loss: 156.34
 ---- batch: 030 ----
mean loss: 157.89
train mean loss: 158.49
epoch train time: 0:00:01.440407
elapsed time: 0:01:28.032011
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:34:51.009793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.16
 ---- batch: 020 ----
mean loss: 163.35
 ---- batch: 030 ----
mean loss: 156.52
train mean loss: 158.91
epoch train time: 0:00:01.440395
elapsed time: 0:01:29.472569
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:34:52.450347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.74
 ---- batch: 020 ----
mean loss: 161.39
 ---- batch: 030 ----
mean loss: 159.40
train mean loss: 159.12
epoch train time: 0:00:01.437792
elapsed time: 0:01:30.910527
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:34:53.888316
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.16
 ---- batch: 020 ----
mean loss: 153.68
 ---- batch: 030 ----
mean loss: 158.74
train mean loss: 155.84
epoch train time: 0:00:01.441815
elapsed time: 0:01:32.352516
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:34:55.330297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.28
 ---- batch: 020 ----
mean loss: 153.72
 ---- batch: 030 ----
mean loss: 161.88
train mean loss: 157.98
epoch train time: 0:00:01.441141
elapsed time: 0:01:33.793822
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:34:56.771603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.49
 ---- batch: 020 ----
mean loss: 156.01
 ---- batch: 030 ----
mean loss: 156.37
train mean loss: 154.97
epoch train time: 0:00:01.438208
elapsed time: 0:01:35.232200
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:34:58.209982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.49
 ---- batch: 020 ----
mean loss: 155.31
 ---- batch: 030 ----
mean loss: 155.65
train mean loss: 154.02
epoch train time: 0:00:01.439389
elapsed time: 0:01:36.671771
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:34:59.649555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.36
 ---- batch: 020 ----
mean loss: 160.88
 ---- batch: 030 ----
mean loss: 158.76
train mean loss: 160.07
epoch train time: 0:00:01.438524
elapsed time: 0:01:38.110473
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:35:01.088262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.37
 ---- batch: 020 ----
mean loss: 155.05
 ---- batch: 030 ----
mean loss: 155.63
train mean loss: 155.07
epoch train time: 0:00:01.437611
elapsed time: 0:01:39.548268
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:35:02.526062
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.01
 ---- batch: 020 ----
mean loss: 155.32
 ---- batch: 030 ----
mean loss: 160.83
train mean loss: 155.05
epoch train time: 0:00:01.440930
elapsed time: 0:01:40.989375
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:35:03.967172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.97
 ---- batch: 020 ----
mean loss: 156.97
 ---- batch: 030 ----
mean loss: 154.81
train mean loss: 156.11
epoch train time: 0:00:01.440098
elapsed time: 0:01:42.429664
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:35:05.407448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.05
 ---- batch: 020 ----
mean loss: 157.61
 ---- batch: 030 ----
mean loss: 155.32
train mean loss: 154.33
epoch train time: 0:00:01.438772
elapsed time: 0:01:43.868609
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:35:06.846411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.41
 ---- batch: 020 ----
mean loss: 153.88
 ---- batch: 030 ----
mean loss: 148.22
train mean loss: 150.62
epoch train time: 0:00:01.439788
elapsed time: 0:01:45.308584
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:35:08.286364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.52
 ---- batch: 020 ----
mean loss: 149.96
 ---- batch: 030 ----
mean loss: 153.40
train mean loss: 151.37
epoch train time: 0:00:01.440468
elapsed time: 0:01:46.749226
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:35:09.727038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.93
 ---- batch: 020 ----
mean loss: 153.93
 ---- batch: 030 ----
mean loss: 150.51
train mean loss: 152.73
epoch train time: 0:00:01.439219
elapsed time: 0:01:48.188651
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:35:11.166441
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.85
 ---- batch: 020 ----
mean loss: 152.90
 ---- batch: 030 ----
mean loss: 156.97
train mean loss: 153.64
epoch train time: 0:00:01.439105
elapsed time: 0:01:49.627962
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:35:12.605748
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.21
 ---- batch: 020 ----
mean loss: 159.76
 ---- batch: 030 ----
mean loss: 145.55
train mean loss: 153.86
epoch train time: 0:00:01.443190
elapsed time: 0:01:51.071338
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:35:14.049118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.18
 ---- batch: 020 ----
mean loss: 148.87
 ---- batch: 030 ----
mean loss: 155.76
train mean loss: 152.31
epoch train time: 0:00:01.441384
elapsed time: 0:01:52.512905
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:35:15.490688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.67
 ---- batch: 020 ----
mean loss: 148.85
 ---- batch: 030 ----
mean loss: 147.39
train mean loss: 149.16
epoch train time: 0:00:01.440255
elapsed time: 0:01:53.953352
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:35:16.931146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.36
 ---- batch: 020 ----
mean loss: 150.78
 ---- batch: 030 ----
mean loss: 150.43
train mean loss: 151.28
epoch train time: 0:00:01.442583
elapsed time: 0:01:55.396120
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:35:18.373897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.06
 ---- batch: 020 ----
mean loss: 154.18
 ---- batch: 030 ----
mean loss: 149.25
train mean loss: 151.14
epoch train time: 0:00:01.440633
elapsed time: 0:01:56.836921
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:35:19.814704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.79
 ---- batch: 020 ----
mean loss: 152.55
 ---- batch: 030 ----
mean loss: 148.67
train mean loss: 148.07
epoch train time: 0:00:01.442765
elapsed time: 0:01:58.279849
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:35:21.257650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.83
 ---- batch: 020 ----
mean loss: 149.48
 ---- batch: 030 ----
mean loss: 154.01
train mean loss: 149.13
epoch train time: 0:00:01.439694
elapsed time: 0:01:59.719746
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:35:22.697528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.75
 ---- batch: 020 ----
mean loss: 152.44
 ---- batch: 030 ----
mean loss: 147.00
train mean loss: 148.96
epoch train time: 0:00:01.442553
elapsed time: 0:02:01.162481
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:35:24.140277
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.05
 ---- batch: 020 ----
mean loss: 147.64
 ---- batch: 030 ----
mean loss: 147.26
train mean loss: 149.33
epoch train time: 0:00:01.440958
elapsed time: 0:02:02.603624
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:35:25.581407
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.77
 ---- batch: 020 ----
mean loss: 143.94
 ---- batch: 030 ----
mean loss: 150.99
train mean loss: 146.35
epoch train time: 0:00:01.439836
elapsed time: 0:02:04.043633
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:35:27.021428
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.97
 ---- batch: 020 ----
mean loss: 145.96
 ---- batch: 030 ----
mean loss: 148.40
train mean loss: 145.93
epoch train time: 0:00:01.440563
elapsed time: 0:02:05.484369
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:35:28.462170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.39
 ---- batch: 020 ----
mean loss: 144.30
 ---- batch: 030 ----
mean loss: 147.63
train mean loss: 144.87
epoch train time: 0:00:01.443191
elapsed time: 0:02:06.927759
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:35:29.905547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.89
 ---- batch: 020 ----
mean loss: 149.21
 ---- batch: 030 ----
mean loss: 149.37
train mean loss: 148.41
epoch train time: 0:00:01.437150
elapsed time: 0:02:08.365097
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:35:31.342882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.83
 ---- batch: 020 ----
mean loss: 147.49
 ---- batch: 030 ----
mean loss: 149.13
train mean loss: 146.01
epoch train time: 0:00:01.439326
elapsed time: 0:02:09.804596
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:35:32.782376
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.23
 ---- batch: 020 ----
mean loss: 143.28
 ---- batch: 030 ----
mean loss: 147.64
train mean loss: 146.40
epoch train time: 0:00:01.442505
elapsed time: 0:02:11.247267
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:35:34.225050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.47
 ---- batch: 020 ----
mean loss: 148.06
 ---- batch: 030 ----
mean loss: 148.39
train mean loss: 146.68
epoch train time: 0:00:01.439646
elapsed time: 0:02:12.687092
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:35:35.664890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.40
 ---- batch: 020 ----
mean loss: 147.96
 ---- batch: 030 ----
mean loss: 149.63
train mean loss: 144.95
epoch train time: 0:00:01.444431
elapsed time: 0:02:14.131717
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:35:37.109501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.32
 ---- batch: 020 ----
mean loss: 148.73
 ---- batch: 030 ----
mean loss: 142.04
train mean loss: 144.87
epoch train time: 0:00:01.440860
elapsed time: 0:02:15.572752
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:35:38.550536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.40
 ---- batch: 020 ----
mean loss: 142.97
 ---- batch: 030 ----
mean loss: 147.39
train mean loss: 145.72
epoch train time: 0:00:01.472433
elapsed time: 0:02:17.045354
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:35:40.023136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.57
 ---- batch: 020 ----
mean loss: 146.89
 ---- batch: 030 ----
mean loss: 143.75
train mean loss: 146.86
epoch train time: 0:00:01.439462
elapsed time: 0:02:18.484979
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:35:41.462763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.13
 ---- batch: 020 ----
mean loss: 145.88
 ---- batch: 030 ----
mean loss: 145.12
train mean loss: 147.61
epoch train time: 0:00:01.441967
elapsed time: 0:02:19.927113
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:35:42.904923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.66
 ---- batch: 020 ----
mean loss: 143.27
 ---- batch: 030 ----
mean loss: 150.21
train mean loss: 146.19
epoch train time: 0:00:01.439710
elapsed time: 0:02:21.367027
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:35:44.344816
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.70
 ---- batch: 020 ----
mean loss: 142.21
 ---- batch: 030 ----
mean loss: 148.40
train mean loss: 144.54
epoch train time: 0:00:01.443339
elapsed time: 0:02:22.810538
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:35:45.788319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.50
 ---- batch: 020 ----
mean loss: 148.26
 ---- batch: 030 ----
mean loss: 148.44
train mean loss: 145.50
epoch train time: 0:00:01.434374
elapsed time: 0:02:24.245107
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:35:47.222940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.70
 ---- batch: 020 ----
mean loss: 146.69
 ---- batch: 030 ----
mean loss: 141.97
train mean loss: 143.95
epoch train time: 0:00:01.442109
elapsed time: 0:02:25.687466
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:35:48.665265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.96
 ---- batch: 020 ----
mean loss: 142.44
 ---- batch: 030 ----
mean loss: 146.39
train mean loss: 145.35
epoch train time: 0:00:01.440804
elapsed time: 0:02:27.128457
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:35:50.106235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.89
 ---- batch: 020 ----
mean loss: 140.84
 ---- batch: 030 ----
mean loss: 149.36
train mean loss: 144.19
epoch train time: 0:00:01.448021
elapsed time: 0:02:28.576641
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:35:51.554435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.61
 ---- batch: 020 ----
mean loss: 140.28
 ---- batch: 030 ----
mean loss: 148.37
train mean loss: 145.52
epoch train time: 0:00:01.445162
elapsed time: 0:02:30.021996
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:35:52.999777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.78
 ---- batch: 020 ----
mean loss: 144.85
 ---- batch: 030 ----
mean loss: 145.85
train mean loss: 145.23
epoch train time: 0:00:01.445319
elapsed time: 0:02:31.467487
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:35:54.445270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.95
 ---- batch: 020 ----
mean loss: 140.52
 ---- batch: 030 ----
mean loss: 141.49
train mean loss: 141.13
epoch train time: 0:00:01.438142
elapsed time: 0:02:32.905848
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:35:55.883629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.03
 ---- batch: 020 ----
mean loss: 145.93
 ---- batch: 030 ----
mean loss: 145.49
train mean loss: 145.75
epoch train time: 0:00:01.438907
elapsed time: 0:02:34.344953
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:35:57.322754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.70
 ---- batch: 020 ----
mean loss: 141.52
 ---- batch: 030 ----
mean loss: 137.94
train mean loss: 142.03
epoch train time: 0:00:01.438431
elapsed time: 0:02:35.783566
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:35:58.761345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.84
 ---- batch: 020 ----
mean loss: 144.40
 ---- batch: 030 ----
mean loss: 137.67
train mean loss: 145.03
epoch train time: 0:00:01.440252
elapsed time: 0:02:37.224000
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:36:00.201782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.15
 ---- batch: 020 ----
mean loss: 145.92
 ---- batch: 030 ----
mean loss: 145.10
train mean loss: 144.38
epoch train time: 0:00:01.441665
elapsed time: 0:02:38.665864
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:36:01.643655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.09
 ---- batch: 020 ----
mean loss: 149.33
 ---- batch: 030 ----
mean loss: 151.02
train mean loss: 148.35
epoch train time: 0:00:01.440516
elapsed time: 0:02:40.106573
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:36:03.084356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.25
 ---- batch: 020 ----
mean loss: 144.66
 ---- batch: 030 ----
mean loss: 143.25
train mean loss: 145.40
epoch train time: 0:00:01.441550
elapsed time: 0:02:41.548309
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:36:04.526090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.26
 ---- batch: 020 ----
mean loss: 143.85
 ---- batch: 030 ----
mean loss: 145.95
train mean loss: 144.42
epoch train time: 0:00:01.440783
elapsed time: 0:02:42.989297
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:36:05.967078
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.60
 ---- batch: 020 ----
mean loss: 145.98
 ---- batch: 030 ----
mean loss: 144.86
train mean loss: 145.40
epoch train time: 0:00:01.440065
elapsed time: 0:02:44.429539
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:36:07.407343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.16
 ---- batch: 020 ----
mean loss: 139.47
 ---- batch: 030 ----
mean loss: 139.96
train mean loss: 142.85
epoch train time: 0:00:01.438217
elapsed time: 0:02:45.868008
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:36:08.845796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.77
 ---- batch: 020 ----
mean loss: 141.39
 ---- batch: 030 ----
mean loss: 145.06
train mean loss: 143.26
epoch train time: 0:00:01.438715
elapsed time: 0:02:47.306899
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:36:10.284688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.07
 ---- batch: 020 ----
mean loss: 144.83
 ---- batch: 030 ----
mean loss: 136.95
train mean loss: 142.77
epoch train time: 0:00:01.442194
elapsed time: 0:02:48.749263
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:36:11.727043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.01
 ---- batch: 020 ----
mean loss: 143.38
 ---- batch: 030 ----
mean loss: 140.66
train mean loss: 143.12
epoch train time: 0:00:01.440179
elapsed time: 0:02:50.189604
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:36:13.167402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.78
 ---- batch: 020 ----
mean loss: 143.57
 ---- batch: 030 ----
mean loss: 141.43
train mean loss: 140.26
epoch train time: 0:00:01.444764
elapsed time: 0:02:51.634552
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:36:14.612333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.52
 ---- batch: 020 ----
mean loss: 139.64
 ---- batch: 030 ----
mean loss: 139.92
train mean loss: 142.62
epoch train time: 0:00:01.441708
elapsed time: 0:02:53.076422
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:36:16.054204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.67
 ---- batch: 020 ----
mean loss: 149.69
 ---- batch: 030 ----
mean loss: 142.41
train mean loss: 145.78
epoch train time: 0:00:01.440847
elapsed time: 0:02:54.517469
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:36:17.495254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.83
 ---- batch: 020 ----
mean loss: 143.45
 ---- batch: 030 ----
mean loss: 146.04
train mean loss: 142.47
epoch train time: 0:00:01.439916
elapsed time: 0:02:55.957558
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:36:18.935340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.83
 ---- batch: 020 ----
mean loss: 146.29
 ---- batch: 030 ----
mean loss: 142.04
train mean loss: 144.52
epoch train time: 0:00:01.440912
elapsed time: 0:02:57.398636
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:36:20.376414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.40
 ---- batch: 020 ----
mean loss: 140.24
 ---- batch: 030 ----
mean loss: 147.24
train mean loss: 144.18
epoch train time: 0:00:01.439414
elapsed time: 0:02:58.838227
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:36:21.816012
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.02
 ---- batch: 020 ----
mean loss: 143.34
 ---- batch: 030 ----
mean loss: 145.03
train mean loss: 145.24
epoch train time: 0:00:01.436522
elapsed time: 0:03:00.274925
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:36:23.252721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.86
 ---- batch: 020 ----
mean loss: 140.75
 ---- batch: 030 ----
mean loss: 138.99
train mean loss: 140.32
epoch train time: 0:00:01.442272
elapsed time: 0:03:01.717398
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:36:24.695238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.11
 ---- batch: 020 ----
mean loss: 140.91
 ---- batch: 030 ----
mean loss: 142.85
train mean loss: 140.32
epoch train time: 0:00:01.442704
elapsed time: 0:03:03.160345
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:36:26.138128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.35
 ---- batch: 020 ----
mean loss: 141.22
 ---- batch: 030 ----
mean loss: 141.64
train mean loss: 139.67
epoch train time: 0:00:01.441506
elapsed time: 0:03:04.602031
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:36:27.579832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.00
 ---- batch: 020 ----
mean loss: 139.64
 ---- batch: 030 ----
mean loss: 134.50
train mean loss: 139.28
epoch train time: 0:00:01.441553
elapsed time: 0:03:06.043777
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:36:29.021564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.58
 ---- batch: 020 ----
mean loss: 138.77
 ---- batch: 030 ----
mean loss: 147.84
train mean loss: 142.48
epoch train time: 0:00:01.440471
elapsed time: 0:03:07.484413
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:36:30.462193
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.46
 ---- batch: 020 ----
mean loss: 150.44
 ---- batch: 030 ----
mean loss: 143.44
train mean loss: 143.21
epoch train time: 0:00:01.441226
elapsed time: 0:03:08.925849
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:36:31.903643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.51
 ---- batch: 020 ----
mean loss: 143.24
 ---- batch: 030 ----
mean loss: 140.47
train mean loss: 141.90
epoch train time: 0:00:01.442426
elapsed time: 0:03:10.368450
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:36:33.346231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.83
 ---- batch: 020 ----
mean loss: 139.63
 ---- batch: 030 ----
mean loss: 148.12
train mean loss: 143.24
epoch train time: 0:00:01.440646
elapsed time: 0:03:11.809258
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:36:34.787042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.34
 ---- batch: 020 ----
mean loss: 141.14
 ---- batch: 030 ----
mean loss: 144.44
train mean loss: 144.49
epoch train time: 0:00:01.440413
elapsed time: 0:03:13.249843
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:36:36.227632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.56
 ---- batch: 020 ----
mean loss: 141.24
 ---- batch: 030 ----
mean loss: 140.59
train mean loss: 141.63
epoch train time: 0:00:01.437780
elapsed time: 0:03:14.687832
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:36:37.665640
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.24
 ---- batch: 020 ----
mean loss: 148.53
 ---- batch: 030 ----
mean loss: 151.69
train mean loss: 147.21
epoch train time: 0:00:01.440565
elapsed time: 0:03:16.128627
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:36:39.106413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.79
 ---- batch: 020 ----
mean loss: 143.07
 ---- batch: 030 ----
mean loss: 139.34
train mean loss: 141.33
epoch train time: 0:00:01.443139
elapsed time: 0:03:17.571995
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:36:40.549788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.14
 ---- batch: 020 ----
mean loss: 143.00
 ---- batch: 030 ----
mean loss: 137.70
train mean loss: 141.07
epoch train time: 0:00:01.437390
elapsed time: 0:03:19.009562
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:36:41.987343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.99
 ---- batch: 020 ----
mean loss: 145.15
 ---- batch: 030 ----
mean loss: 149.29
train mean loss: 146.82
epoch train time: 0:00:01.438854
elapsed time: 0:03:20.448579
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:36:43.426360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.91
 ---- batch: 020 ----
mean loss: 143.34
 ---- batch: 030 ----
mean loss: 142.80
train mean loss: 142.29
epoch train time: 0:00:01.439830
elapsed time: 0:03:21.888571
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:36:44.866353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.31
 ---- batch: 020 ----
mean loss: 141.93
 ---- batch: 030 ----
mean loss: 140.16
train mean loss: 140.61
epoch train time: 0:00:01.442201
elapsed time: 0:03:23.330955
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:36:46.308756
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.01
 ---- batch: 020 ----
mean loss: 143.97
 ---- batch: 030 ----
mean loss: 142.79
train mean loss: 141.63
epoch train time: 0:00:01.436500
elapsed time: 0:03:24.767643
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:36:47.745435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.44
 ---- batch: 020 ----
mean loss: 139.14
 ---- batch: 030 ----
mean loss: 142.79
train mean loss: 139.07
epoch train time: 0:00:01.441197
elapsed time: 0:03:26.209027
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:36:49.186805
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.99
 ---- batch: 020 ----
mean loss: 136.10
 ---- batch: 030 ----
mean loss: 142.36
train mean loss: 139.41
epoch train time: 0:00:01.440349
elapsed time: 0:03:27.649581
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:36:50.627380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.43
 ---- batch: 020 ----
mean loss: 139.50
 ---- batch: 030 ----
mean loss: 141.06
train mean loss: 139.07
epoch train time: 0:00:01.439169
elapsed time: 0:03:29.088929
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:36:52.066725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.36
 ---- batch: 020 ----
mean loss: 140.24
 ---- batch: 030 ----
mean loss: 139.69
train mean loss: 138.83
epoch train time: 0:00:01.442334
elapsed time: 0:03:30.531484
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:36:53.509264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.01
 ---- batch: 020 ----
mean loss: 141.98
 ---- batch: 030 ----
mean loss: 140.57
train mean loss: 140.69
epoch train time: 0:00:01.439499
elapsed time: 0:03:31.971155
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:36:54.948947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.82
 ---- batch: 020 ----
mean loss: 136.64
 ---- batch: 030 ----
mean loss: 136.05
train mean loss: 138.54
epoch train time: 0:00:01.465936
elapsed time: 0:03:33.437283
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:36:56.415061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.54
 ---- batch: 020 ----
mean loss: 138.85
 ---- batch: 030 ----
mean loss: 144.54
train mean loss: 141.59
epoch train time: 0:00:01.439068
elapsed time: 0:03:34.876517
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:36:57.854301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.45
 ---- batch: 020 ----
mean loss: 135.47
 ---- batch: 030 ----
mean loss: 135.86
train mean loss: 138.49
epoch train time: 0:00:01.439734
elapsed time: 0:03:36.316425
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:36:59.294207
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.63
 ---- batch: 020 ----
mean loss: 143.98
 ---- batch: 030 ----
mean loss: 152.48
train mean loss: 145.40
epoch train time: 0:00:01.442455
elapsed time: 0:03:37.759084
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:37:00.736868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.61
 ---- batch: 020 ----
mean loss: 142.64
 ---- batch: 030 ----
mean loss: 138.45
train mean loss: 141.91
epoch train time: 0:00:01.438698
elapsed time: 0:03:39.198007
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:37:02.175786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.64
 ---- batch: 020 ----
mean loss: 135.36
 ---- batch: 030 ----
mean loss: 139.91
train mean loss: 138.83
epoch train time: 0:00:01.438999
elapsed time: 0:03:40.637192
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:37:03.614975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.35
 ---- batch: 020 ----
mean loss: 136.56
 ---- batch: 030 ----
mean loss: 136.58
train mean loss: 139.14
epoch train time: 0:00:01.442874
elapsed time: 0:03:42.080237
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:37:05.058018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.50
 ---- batch: 020 ----
mean loss: 139.22
 ---- batch: 030 ----
mean loss: 138.68
train mean loss: 140.84
epoch train time: 0:00:01.442639
elapsed time: 0:03:43.523079
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:37:06.500916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.36
 ---- batch: 020 ----
mean loss: 138.98
 ---- batch: 030 ----
mean loss: 139.25
train mean loss: 138.17
epoch train time: 0:00:01.446630
elapsed time: 0:03:44.969968
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:37:07.947753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.02
 ---- batch: 020 ----
mean loss: 138.17
 ---- batch: 030 ----
mean loss: 141.13
train mean loss: 139.13
epoch train time: 0:00:01.442742
elapsed time: 0:03:46.412903
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:37:09.390675
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.49
 ---- batch: 020 ----
mean loss: 137.27
 ---- batch: 030 ----
mean loss: 143.00
train mean loss: 139.57
epoch train time: 0:00:01.444933
elapsed time: 0:03:47.857996
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:37:10.835779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.67
 ---- batch: 020 ----
mean loss: 138.20
 ---- batch: 030 ----
mean loss: 141.31
train mean loss: 139.22
epoch train time: 0:00:01.445854
elapsed time: 0:03:49.304099
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:37:12.281911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.73
 ---- batch: 020 ----
mean loss: 137.16
 ---- batch: 030 ----
mean loss: 144.57
train mean loss: 139.42
epoch train time: 0:00:01.438324
elapsed time: 0:03:50.742702
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:37:13.720513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.44
 ---- batch: 020 ----
mean loss: 140.76
 ---- batch: 030 ----
mean loss: 147.51
train mean loss: 142.04
epoch train time: 0:00:01.440089
elapsed time: 0:03:52.182993
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:37:15.160788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.67
 ---- batch: 020 ----
mean loss: 138.65
 ---- batch: 030 ----
mean loss: 142.61
train mean loss: 140.30
epoch train time: 0:00:01.442272
elapsed time: 0:03:53.625480
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:37:16.603264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.09
 ---- batch: 020 ----
mean loss: 140.80
 ---- batch: 030 ----
mean loss: 142.16
train mean loss: 143.41
epoch train time: 0:00:01.440350
elapsed time: 0:03:55.066010
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:37:18.043791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.38
 ---- batch: 020 ----
mean loss: 135.32
 ---- batch: 030 ----
mean loss: 137.16
train mean loss: 136.24
epoch train time: 0:00:01.440877
elapsed time: 0:03:56.507052
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:37:19.484881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.07
 ---- batch: 020 ----
mean loss: 140.43
 ---- batch: 030 ----
mean loss: 138.16
train mean loss: 138.91
epoch train time: 0:00:01.439150
elapsed time: 0:03:57.946433
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:37:20.924215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.44
 ---- batch: 020 ----
mean loss: 138.57
 ---- batch: 030 ----
mean loss: 136.83
train mean loss: 139.34
epoch train time: 0:00:01.440954
elapsed time: 0:03:59.387551
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:37:22.365332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.44
 ---- batch: 020 ----
mean loss: 139.91
 ---- batch: 030 ----
mean loss: 141.90
train mean loss: 140.04
epoch train time: 0:00:01.439996
elapsed time: 0:04:00.827731
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:37:23.805522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.40
 ---- batch: 020 ----
mean loss: 143.63
 ---- batch: 030 ----
mean loss: 140.57
train mean loss: 141.83
epoch train time: 0:00:01.440206
elapsed time: 0:04:02.268105
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:37:25.245917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.50
 ---- batch: 020 ----
mean loss: 141.49
 ---- batch: 030 ----
mean loss: 135.98
train mean loss: 138.74
epoch train time: 0:00:01.440425
elapsed time: 0:04:03.708733
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:37:26.686527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.78
 ---- batch: 020 ----
mean loss: 136.34
 ---- batch: 030 ----
mean loss: 138.15
train mean loss: 136.47
epoch train time: 0:00:01.439338
elapsed time: 0:04:05.148268
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:37:28.126049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.26
 ---- batch: 020 ----
mean loss: 138.01
 ---- batch: 030 ----
mean loss: 135.68
train mean loss: 136.82
epoch train time: 0:00:01.444089
elapsed time: 0:04:06.592594
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:37:29.570376
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.28
 ---- batch: 020 ----
mean loss: 140.78
 ---- batch: 030 ----
mean loss: 139.57
train mean loss: 139.74
epoch train time: 0:00:01.436498
elapsed time: 0:04:08.029282
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:37:31.007065
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.02
 ---- batch: 020 ----
mean loss: 137.38
 ---- batch: 030 ----
mean loss: 136.48
train mean loss: 139.36
epoch train time: 0:00:01.443510
elapsed time: 0:04:09.472956
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:37:32.450739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.25
 ---- batch: 020 ----
mean loss: 142.36
 ---- batch: 030 ----
mean loss: 139.74
train mean loss: 138.12
epoch train time: 0:00:01.435928
elapsed time: 0:04:10.909067
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:37:33.886859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.26
 ---- batch: 020 ----
mean loss: 140.52
 ---- batch: 030 ----
mean loss: 140.91
train mean loss: 142.37
epoch train time: 0:00:01.440092
elapsed time: 0:04:12.349403
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:37:35.327194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.48
 ---- batch: 020 ----
mean loss: 133.62
 ---- batch: 030 ----
mean loss: 138.44
train mean loss: 138.26
epoch train time: 0:00:01.439612
elapsed time: 0:04:13.789225
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:37:36.767197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.41
 ---- batch: 020 ----
mean loss: 134.11
 ---- batch: 030 ----
mean loss: 140.55
train mean loss: 138.72
epoch train time: 0:00:01.440532
elapsed time: 0:04:15.230123
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:37:38.207918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.85
 ---- batch: 020 ----
mean loss: 138.27
 ---- batch: 030 ----
mean loss: 138.22
train mean loss: 138.56
epoch train time: 0:00:01.441953
elapsed time: 0:04:16.672261
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:37:39.650041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.06
 ---- batch: 020 ----
mean loss: 136.30
 ---- batch: 030 ----
mean loss: 136.43
train mean loss: 138.37
epoch train time: 0:00:01.444555
elapsed time: 0:04:18.116975
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:37:41.094756
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.85
 ---- batch: 020 ----
mean loss: 137.27
 ---- batch: 030 ----
mean loss: 140.66
train mean loss: 139.75
epoch train time: 0:00:01.438688
elapsed time: 0:04:19.555905
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:37:42.533736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.35
 ---- batch: 020 ----
mean loss: 140.74
 ---- batch: 030 ----
mean loss: 142.56
train mean loss: 140.48
epoch train time: 0:00:01.440034
elapsed time: 0:04:20.996174
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:37:43.973955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.78
 ---- batch: 020 ----
mean loss: 142.00
 ---- batch: 030 ----
mean loss: 134.64
train mean loss: 139.71
epoch train time: 0:00:01.439899
elapsed time: 0:04:22.436286
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:37:45.414070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.73
 ---- batch: 020 ----
mean loss: 138.38
 ---- batch: 030 ----
mean loss: 142.90
train mean loss: 137.67
epoch train time: 0:00:01.439106
elapsed time: 0:04:23.875553
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:37:46.853331
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.79
 ---- batch: 020 ----
mean loss: 137.92
 ---- batch: 030 ----
mean loss: 136.48
train mean loss: 137.36
epoch train time: 0:00:01.442431
elapsed time: 0:04:25.318139
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:37:48.295921
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.18
 ---- batch: 020 ----
mean loss: 140.32
 ---- batch: 030 ----
mean loss: 143.45
train mean loss: 139.96
epoch train time: 0:00:01.437502
elapsed time: 0:04:26.755806
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:37:49.733587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.02
 ---- batch: 020 ----
mean loss: 131.61
 ---- batch: 030 ----
mean loss: 139.44
train mean loss: 136.37
epoch train time: 0:00:01.443305
elapsed time: 0:04:28.199306
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:37:51.177087
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.25
 ---- batch: 020 ----
mean loss: 135.67
 ---- batch: 030 ----
mean loss: 137.79
train mean loss: 137.91
epoch train time: 0:00:01.440731
elapsed time: 0:04:29.640203
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:37:52.618015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.91
 ---- batch: 020 ----
mean loss: 136.34
 ---- batch: 030 ----
mean loss: 136.45
train mean loss: 138.23
epoch train time: 0:00:01.440849
elapsed time: 0:04:31.081247
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:37:54.059029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.69
 ---- batch: 020 ----
mean loss: 142.05
 ---- batch: 030 ----
mean loss: 137.14
train mean loss: 139.09
epoch train time: 0:00:01.435995
elapsed time: 0:04:32.517445
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:37:55.495232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.33
 ---- batch: 020 ----
mean loss: 142.46
 ---- batch: 030 ----
mean loss: 135.70
train mean loss: 137.48
epoch train time: 0:00:01.436829
elapsed time: 0:04:33.954445
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:37:56.932227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.17
 ---- batch: 020 ----
mean loss: 135.96
 ---- batch: 030 ----
mean loss: 138.48
train mean loss: 137.25
epoch train time: 0:00:01.441597
elapsed time: 0:04:35.396241
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:37:58.374046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.68
 ---- batch: 020 ----
mean loss: 139.93
 ---- batch: 030 ----
mean loss: 143.13
train mean loss: 140.45
epoch train time: 0:00:01.438865
elapsed time: 0:04:36.835302
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:37:59.813084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.01
 ---- batch: 020 ----
mean loss: 137.52
 ---- batch: 030 ----
mean loss: 137.85
train mean loss: 137.49
epoch train time: 0:00:01.439532
elapsed time: 0:04:38.275012
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:38:01.252795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.03
 ---- batch: 020 ----
mean loss: 139.82
 ---- batch: 030 ----
mean loss: 134.66
train mean loss: 135.85
epoch train time: 0:00:01.439200
elapsed time: 0:04:39.714382
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:38:02.692163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.45
 ---- batch: 020 ----
mean loss: 137.44
 ---- batch: 030 ----
mean loss: 140.93
train mean loss: 137.81
epoch train time: 0:00:01.441189
elapsed time: 0:04:41.155738
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:38:04.133538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.89
 ---- batch: 020 ----
mean loss: 147.07
 ---- batch: 030 ----
mean loss: 145.70
train mean loss: 144.62
epoch train time: 0:00:01.441529
elapsed time: 0:04:42.597466
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:38:05.575250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.12
 ---- batch: 020 ----
mean loss: 139.47
 ---- batch: 030 ----
mean loss: 143.59
train mean loss: 141.73
epoch train time: 0:00:01.436007
elapsed time: 0:04:44.033645
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:38:07.011438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.90
 ---- batch: 020 ----
mean loss: 140.15
 ---- batch: 030 ----
mean loss: 142.48
train mean loss: 139.21
epoch train time: 0:00:01.438655
elapsed time: 0:04:45.472488
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:38:08.450282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.74
 ---- batch: 020 ----
mean loss: 136.80
 ---- batch: 030 ----
mean loss: 138.77
train mean loss: 139.61
epoch train time: 0:00:01.441474
elapsed time: 0:04:46.914142
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:38:09.891940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.70
 ---- batch: 020 ----
mean loss: 142.26
 ---- batch: 030 ----
mean loss: 140.65
train mean loss: 141.42
epoch train time: 0:00:01.435742
elapsed time: 0:04:48.350083
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:38:11.327874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.61
 ---- batch: 020 ----
mean loss: 137.88
 ---- batch: 030 ----
mean loss: 138.64
train mean loss: 137.73
epoch train time: 0:00:01.464563
elapsed time: 0:04:49.814835
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:38:12.792616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.35
 ---- batch: 020 ----
mean loss: 142.13
 ---- batch: 030 ----
mean loss: 130.03
train mean loss: 136.41
epoch train time: 0:00:01.437335
elapsed time: 0:04:51.252347
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:38:14.230131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.25
 ---- batch: 020 ----
mean loss: 138.02
 ---- batch: 030 ----
mean loss: 131.46
train mean loss: 135.27
epoch train time: 0:00:01.439878
elapsed time: 0:04:52.692403
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:38:15.670185
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.38
 ---- batch: 020 ----
mean loss: 138.61
 ---- batch: 030 ----
mean loss: 133.67
train mean loss: 136.65
epoch train time: 0:00:01.443284
elapsed time: 0:04:54.135851
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:38:17.113678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.32
 ---- batch: 020 ----
mean loss: 139.93
 ---- batch: 030 ----
mean loss: 134.17
train mean loss: 138.12
epoch train time: 0:00:01.445492
elapsed time: 0:04:55.581560
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:38:18.559345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.29
 ---- batch: 020 ----
mean loss: 139.39
 ---- batch: 030 ----
mean loss: 138.01
train mean loss: 137.74
epoch train time: 0:00:01.442160
elapsed time: 0:04:57.023919
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:38:20.001708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.77
 ---- batch: 020 ----
mean loss: 138.57
 ---- batch: 030 ----
mean loss: 137.69
train mean loss: 135.21
epoch train time: 0:00:01.445810
elapsed time: 0:04:58.469933
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:38:21.447717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.90
 ---- batch: 020 ----
mean loss: 138.93
 ---- batch: 030 ----
mean loss: 139.88
train mean loss: 138.99
epoch train time: 0:00:01.445840
elapsed time: 0:04:59.915968
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:38:22.893754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.84
 ---- batch: 020 ----
mean loss: 136.84
 ---- batch: 030 ----
mean loss: 145.05
train mean loss: 139.50
epoch train time: 0:00:01.442649
elapsed time: 0:05:01.358873
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:38:24.336714
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.50
 ---- batch: 020 ----
mean loss: 136.20
 ---- batch: 030 ----
mean loss: 134.74
train mean loss: 136.37
epoch train time: 0:00:01.443586
elapsed time: 0:05:02.802726
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:38:25.780522
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.54
 ---- batch: 020 ----
mean loss: 135.48
 ---- batch: 030 ----
mean loss: 135.38
train mean loss: 135.58
epoch train time: 0:00:01.445998
elapsed time: 0:05:04.248945
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:38:27.226725
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.07
 ---- batch: 020 ----
mean loss: 134.29
 ---- batch: 030 ----
mean loss: 132.60
train mean loss: 133.71
epoch train time: 0:00:01.447322
elapsed time: 0:05:05.696446
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:38:28.674258
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.75
 ---- batch: 020 ----
mean loss: 131.26
 ---- batch: 030 ----
mean loss: 128.95
train mean loss: 134.12
epoch train time: 0:00:01.440445
elapsed time: 0:05:07.137100
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:38:30.114882
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.95
 ---- batch: 020 ----
mean loss: 136.88
 ---- batch: 030 ----
mean loss: 134.97
train mean loss: 135.80
epoch train time: 0:00:01.444130
elapsed time: 0:05:08.581391
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:38:31.559170
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.40
 ---- batch: 020 ----
mean loss: 138.76
 ---- batch: 030 ----
mean loss: 137.80
train mean loss: 135.10
epoch train time: 0:00:01.441424
elapsed time: 0:05:10.022979
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:38:33.000760
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.91
 ---- batch: 020 ----
mean loss: 132.96
 ---- batch: 030 ----
mean loss: 134.33
train mean loss: 134.34
epoch train time: 0:00:01.440618
elapsed time: 0:05:11.463761
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:38:34.441540
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.97
 ---- batch: 020 ----
mean loss: 127.23
 ---- batch: 030 ----
mean loss: 133.76
train mean loss: 133.87
epoch train time: 0:00:01.440860
elapsed time: 0:05:12.904800
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:38:35.882586
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.21
 ---- batch: 020 ----
mean loss: 136.47
 ---- batch: 030 ----
mean loss: 130.51
train mean loss: 134.33
epoch train time: 0:00:01.437275
elapsed time: 0:05:14.342239
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:38:37.320039
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.89
 ---- batch: 020 ----
mean loss: 131.09
 ---- batch: 030 ----
mean loss: 136.03
train mean loss: 133.93
epoch train time: 0:00:01.439932
elapsed time: 0:05:15.782375
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:38:38.760177
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.55
 ---- batch: 020 ----
mean loss: 136.52
 ---- batch: 030 ----
mean loss: 133.39
train mean loss: 134.98
epoch train time: 0:00:01.439397
elapsed time: 0:05:17.221952
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:38:40.199731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.53
 ---- batch: 020 ----
mean loss: 139.24
 ---- batch: 030 ----
mean loss: 135.94
train mean loss: 134.43
epoch train time: 0:00:01.441552
elapsed time: 0:05:18.663672
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:38:41.641456
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.04
 ---- batch: 020 ----
mean loss: 132.08
 ---- batch: 030 ----
mean loss: 132.76
train mean loss: 133.29
epoch train time: 0:00:01.442440
elapsed time: 0:05:20.106309
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:38:43.084108
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.96
 ---- batch: 020 ----
mean loss: 136.37
 ---- batch: 030 ----
mean loss: 134.31
train mean loss: 134.60
epoch train time: 0:00:01.439402
elapsed time: 0:05:21.545890
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:38:44.523684
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.08
 ---- batch: 020 ----
mean loss: 130.38
 ---- batch: 030 ----
mean loss: 135.24
train mean loss: 133.78
epoch train time: 0:00:01.440688
elapsed time: 0:05:22.986756
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:38:45.964536
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.25
 ---- batch: 020 ----
mean loss: 133.79
 ---- batch: 030 ----
mean loss: 136.89
train mean loss: 135.23
epoch train time: 0:00:01.441607
elapsed time: 0:05:24.428524
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:38:47.406303
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.99
 ---- batch: 020 ----
mean loss: 134.06
 ---- batch: 030 ----
mean loss: 132.17
train mean loss: 132.40
epoch train time: 0:00:01.439621
elapsed time: 0:05:25.868312
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:38:48.846093
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.15
 ---- batch: 020 ----
mean loss: 132.35
 ---- batch: 030 ----
mean loss: 135.03
train mean loss: 134.26
epoch train time: 0:00:01.438614
elapsed time: 0:05:27.307082
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:38:50.284862
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.40
 ---- batch: 020 ----
mean loss: 133.69
 ---- batch: 030 ----
mean loss: 131.17
train mean loss: 132.61
epoch train time: 0:00:01.441873
elapsed time: 0:05:28.749136
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:38:51.726930
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.27
 ---- batch: 020 ----
mean loss: 133.30
 ---- batch: 030 ----
mean loss: 134.77
train mean loss: 134.03
epoch train time: 0:00:01.440158
elapsed time: 0:05:30.189482
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:38:53.167261
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.43
 ---- batch: 020 ----
mean loss: 133.66
 ---- batch: 030 ----
mean loss: 131.13
train mean loss: 133.72
epoch train time: 0:00:01.438674
elapsed time: 0:05:31.628320
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:38:54.606104
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.01
 ---- batch: 020 ----
mean loss: 130.60
 ---- batch: 030 ----
mean loss: 131.38
train mean loss: 133.53
epoch train time: 0:00:01.438931
elapsed time: 0:05:33.067419
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:38:56.045200
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.34
 ---- batch: 020 ----
mean loss: 133.10
 ---- batch: 030 ----
mean loss: 138.15
train mean loss: 134.90
epoch train time: 0:00:01.438397
elapsed time: 0:05:34.505994
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:38:57.483777
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.85
 ---- batch: 020 ----
mean loss: 133.29
 ---- batch: 030 ----
mean loss: 129.86
train mean loss: 133.66
epoch train time: 0:00:01.440713
elapsed time: 0:05:35.946879
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:38:58.924661
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.22
 ---- batch: 020 ----
mean loss: 132.88
 ---- batch: 030 ----
mean loss: 136.92
train mean loss: 134.76
epoch train time: 0:00:01.440770
elapsed time: 0:05:37.387816
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:39:00.365599
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.67
 ---- batch: 020 ----
mean loss: 135.21
 ---- batch: 030 ----
mean loss: 136.11
train mean loss: 134.62
epoch train time: 0:00:01.437275
elapsed time: 0:05:38.825260
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:39:01.803061
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.20
 ---- batch: 020 ----
mean loss: 136.61
 ---- batch: 030 ----
mean loss: 134.57
train mean loss: 135.37
epoch train time: 0:00:01.441493
elapsed time: 0:05:40.266966
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:39:03.244783
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.87
 ---- batch: 020 ----
mean loss: 133.70
 ---- batch: 030 ----
mean loss: 133.66
train mean loss: 133.66
epoch train time: 0:00:01.438400
elapsed time: 0:05:41.705584
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:39:04.683365
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.66
 ---- batch: 020 ----
mean loss: 134.86
 ---- batch: 030 ----
mean loss: 130.87
train mean loss: 132.38
epoch train time: 0:00:01.439770
elapsed time: 0:05:43.145518
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:39:06.123301
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.39
 ---- batch: 020 ----
mean loss: 136.02
 ---- batch: 030 ----
mean loss: 131.62
train mean loss: 132.79
epoch train time: 0:00:01.439373
elapsed time: 0:05:44.585055
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:39:07.562836
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.47
 ---- batch: 020 ----
mean loss: 134.87
 ---- batch: 030 ----
mean loss: 131.96
train mean loss: 133.77
epoch train time: 0:00:01.438436
elapsed time: 0:05:46.023655
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:39:09.001435
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.40
 ---- batch: 020 ----
mean loss: 131.62
 ---- batch: 030 ----
mean loss: 135.45
train mean loss: 133.58
epoch train time: 0:00:01.439151
elapsed time: 0:05:47.462978
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:39:10.440765
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.83
 ---- batch: 020 ----
mean loss: 134.30
 ---- batch: 030 ----
mean loss: 135.04
train mean loss: 134.10
epoch train time: 0:00:01.441046
elapsed time: 0:05:48.904209
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:39:11.881985
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 141.06
 ---- batch: 020 ----
mean loss: 133.71
 ---- batch: 030 ----
mean loss: 131.71
train mean loss: 135.46
epoch train time: 0:00:01.442426
elapsed time: 0:05:50.346821
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:39:13.324605
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.88
 ---- batch: 020 ----
mean loss: 131.15
 ---- batch: 030 ----
mean loss: 133.52
train mean loss: 134.21
epoch train time: 0:00:01.439623
elapsed time: 0:05:51.786618
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:39:14.764420
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.68
 ---- batch: 020 ----
mean loss: 132.97
 ---- batch: 030 ----
mean loss: 131.98
train mean loss: 133.85
epoch train time: 0:00:01.439384
elapsed time: 0:05:53.226182
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:39:16.203984
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.73
 ---- batch: 020 ----
mean loss: 133.25
 ---- batch: 030 ----
mean loss: 134.84
train mean loss: 133.78
epoch train time: 0:00:01.440660
elapsed time: 0:05:54.667034
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:39:17.644818
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.93
 ---- batch: 020 ----
mean loss: 133.24
 ---- batch: 030 ----
mean loss: 133.28
train mean loss: 133.60
epoch train time: 0:00:01.439108
elapsed time: 0:05:56.106302
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:39:19.084081
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.68
 ---- batch: 020 ----
mean loss: 134.95
 ---- batch: 030 ----
mean loss: 130.18
train mean loss: 133.53
epoch train time: 0:00:01.437326
elapsed time: 0:05:57.543805
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:39:20.521581
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.14
 ---- batch: 020 ----
mean loss: 136.24
 ---- batch: 030 ----
mean loss: 136.12
train mean loss: 133.67
epoch train time: 0:00:01.440809
elapsed time: 0:05:58.984776
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:39:21.962584
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.64
 ---- batch: 020 ----
mean loss: 132.77
 ---- batch: 030 ----
mean loss: 132.91
train mean loss: 134.08
epoch train time: 0:00:01.437267
elapsed time: 0:06:00.422279
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:39:23.400077
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.34
 ---- batch: 020 ----
mean loss: 135.03
 ---- batch: 030 ----
mean loss: 131.67
train mean loss: 133.68
epoch train time: 0:00:01.441376
elapsed time: 0:06:01.863842
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:39:24.841661
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.89
 ---- batch: 020 ----
mean loss: 139.66
 ---- batch: 030 ----
mean loss: 132.86
train mean loss: 134.98
epoch train time: 0:00:01.440309
elapsed time: 0:06:03.304377
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:39:26.282173
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.84
 ---- batch: 020 ----
mean loss: 132.20
 ---- batch: 030 ----
mean loss: 131.23
train mean loss: 133.32
epoch train time: 0:00:01.445093
elapsed time: 0:06:04.749732
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:39:27.727520
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.19
 ---- batch: 020 ----
mean loss: 131.71
 ---- batch: 030 ----
mean loss: 134.99
train mean loss: 134.98
epoch train time: 0:00:01.438564
elapsed time: 0:06:06.188469
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:39:29.166253
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.73
 ---- batch: 020 ----
mean loss: 136.75
 ---- batch: 030 ----
mean loss: 132.89
train mean loss: 135.53
epoch train time: 0:00:01.435962
elapsed time: 0:06:07.624596
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:39:30.602382
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.02
 ---- batch: 020 ----
mean loss: 135.40
 ---- batch: 030 ----
mean loss: 133.13
train mean loss: 135.17
epoch train time: 0:00:01.441291
elapsed time: 0:06:09.066061
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:39:32.043843
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.52
 ---- batch: 020 ----
mean loss: 132.91
 ---- batch: 030 ----
mean loss: 129.99
train mean loss: 133.14
epoch train time: 0:00:01.436444
elapsed time: 0:06:10.502703
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:39:33.480488
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 129.76
 ---- batch: 020 ----
mean loss: 134.82
 ---- batch: 030 ----
mean loss: 136.40
train mean loss: 134.06
epoch train time: 0:00:01.445734
elapsed time: 0:06:11.952190
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_9/checkpoint.pth.tar
**** end time: 2019-09-27 16:39:34.929935 ****
