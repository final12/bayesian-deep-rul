Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_6', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 23214
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-27 08:37:42.249509 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 31, 14]             200
           Sigmoid-2           [-1, 10, 31, 14]               0
    BayesianConv2d-3           [-1, 10, 30, 14]           2,000
           Sigmoid-4           [-1, 10, 30, 14]               0
    BayesianConv2d-5           [-1, 10, 31, 14]           2,000
           Sigmoid-6           [-1, 10, 31, 14]               0
    BayesianConv2d-7           [-1, 10, 30, 14]           2,000
           Sigmoid-8           [-1, 10, 30, 14]               0
    BayesianConv2d-9            [-1, 1, 30, 14]              60
         Softplus-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
   BayesianLinear-12                  [-1, 100]          84,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 90,460
Trainable params: 90,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 08:37:42.266528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2305.12
 ---- batch: 020 ----
mean loss: 1558.39
 ---- batch: 030 ----
mean loss: 1329.42
train mean loss: 1674.16
epoch train time: 0:00:17.414745
elapsed time: 0:00:17.439977
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 08:37:59.689583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1206.72
 ---- batch: 020 ----
mean loss: 1144.16
 ---- batch: 030 ----
mean loss: 1171.53
train mean loss: 1174.47
epoch train time: 0:00:07.179524
elapsed time: 0:00:24.620340
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 08:38:06.870020
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1128.28
 ---- batch: 020 ----
mean loss: 1091.74
 ---- batch: 030 ----
mean loss: 1114.02
train mean loss: 1105.63
epoch train time: 0:00:07.062446
elapsed time: 0:00:31.683562
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 08:38:13.933239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1067.09
 ---- batch: 020 ----
mean loss: 1088.06
 ---- batch: 030 ----
mean loss: 1060.27
train mean loss: 1070.96
epoch train time: 0:00:07.100522
elapsed time: 0:00:38.784861
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 08:38:21.034565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1059.73
 ---- batch: 020 ----
mean loss: 1035.20
 ---- batch: 030 ----
mean loss: 1042.78
train mean loss: 1041.73
epoch train time: 0:00:07.028026
elapsed time: 0:00:45.813658
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 08:38:28.063370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1024.27
 ---- batch: 020 ----
mean loss: 1041.35
 ---- batch: 030 ----
mean loss: 1002.04
train mean loss: 1023.44
epoch train time: 0:00:07.061651
elapsed time: 0:00:52.876163
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 08:38:35.125860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1002.67
 ---- batch: 020 ----
mean loss: 952.42
 ---- batch: 030 ----
mean loss: 901.67
train mean loss: 942.63
epoch train time: 0:00:07.108589
elapsed time: 0:00:59.985560
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 08:38:42.235240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 811.37
 ---- batch: 020 ----
mean loss: 767.74
 ---- batch: 030 ----
mean loss: 700.92
train mean loss: 745.13
epoch train time: 0:00:07.055176
elapsed time: 0:01:07.041511
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 08:38:49.291173
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 633.42
 ---- batch: 020 ----
mean loss: 590.49
 ---- batch: 030 ----
mean loss: 556.92
train mean loss: 586.41
epoch train time: 0:00:07.219225
elapsed time: 0:01:14.261583
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 08:38:56.511244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 526.47
 ---- batch: 020 ----
mean loss: 493.28
 ---- batch: 030 ----
mean loss: 489.10
train mean loss: 500.22
epoch train time: 0:00:06.973811
elapsed time: 0:01:21.236287
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 08:39:03.485981
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 471.42
 ---- batch: 020 ----
mean loss: 494.60
 ---- batch: 030 ----
mean loss: 460.98
train mean loss: 472.08
epoch train time: 0:00:07.119503
elapsed time: 0:01:28.356717
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 08:39:10.606396
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 457.47
 ---- batch: 020 ----
mean loss: 460.90
 ---- batch: 030 ----
mean loss: 445.43
train mean loss: 455.24
epoch train time: 0:00:07.015775
elapsed time: 0:01:35.373265
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 08:39:17.622931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 425.64
 ---- batch: 020 ----
mean loss: 453.20
 ---- batch: 030 ----
mean loss: 426.52
train mean loss: 433.33
epoch train time: 0:00:07.099529
elapsed time: 0:01:42.473577
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 08:39:24.723290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 430.72
 ---- batch: 020 ----
mean loss: 426.31
 ---- batch: 030 ----
mean loss: 423.79
train mean loss: 426.19
epoch train time: 0:00:07.123422
elapsed time: 0:01:49.597884
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 08:39:31.847562
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.36
 ---- batch: 020 ----
mean loss: 423.09
 ---- batch: 030 ----
mean loss: 431.29
train mean loss: 423.46
epoch train time: 0:00:06.968876
elapsed time: 0:01:56.567505
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 08:39:38.817208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 410.23
 ---- batch: 020 ----
mean loss: 407.10
 ---- batch: 030 ----
mean loss: 412.84
train mean loss: 409.82
epoch train time: 0:00:07.121052
elapsed time: 0:02:03.689419
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 08:39:45.939086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 390.37
 ---- batch: 020 ----
mean loss: 408.66
 ---- batch: 030 ----
mean loss: 401.03
train mean loss: 399.25
epoch train time: 0:00:06.993630
elapsed time: 0:02:10.683961
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 08:39:52.933636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 400.58
 ---- batch: 020 ----
mean loss: 407.66
 ---- batch: 030 ----
mean loss: 386.11
train mean loss: 398.27
epoch train time: 0:00:07.098668
elapsed time: 0:02:17.783528
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 08:40:00.033238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 388.83
 ---- batch: 020 ----
mean loss: 386.40
 ---- batch: 030 ----
mean loss: 380.69
train mean loss: 383.93
epoch train time: 0:00:07.012698
elapsed time: 0:02:24.797080
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 08:40:07.046749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 388.39
 ---- batch: 020 ----
mean loss: 393.95
 ---- batch: 030 ----
mean loss: 369.31
train mean loss: 384.98
epoch train time: 0:00:07.070077
elapsed time: 0:02:31.867952
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 08:40:14.117637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 379.25
 ---- batch: 020 ----
mean loss: 378.05
 ---- batch: 030 ----
mean loss: 374.62
train mean loss: 379.15
epoch train time: 0:00:07.026433
elapsed time: 0:02:38.895160
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 08:40:21.144841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 365.10
 ---- batch: 020 ----
mean loss: 372.58
 ---- batch: 030 ----
mean loss: 365.44
train mean loss: 365.65
epoch train time: 0:00:07.081694
elapsed time: 0:02:45.977688
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 08:40:28.227348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 367.81
 ---- batch: 020 ----
mean loss: 365.34
 ---- batch: 030 ----
mean loss: 355.35
train mean loss: 363.72
epoch train time: 0:00:07.026877
elapsed time: 0:02:53.005310
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 08:40:35.254986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 354.38
 ---- batch: 020 ----
mean loss: 351.09
 ---- batch: 030 ----
mean loss: 347.18
train mean loss: 350.83
epoch train time: 0:00:07.098934
elapsed time: 0:03:00.105005
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 08:40:42.354670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 351.92
 ---- batch: 020 ----
mean loss: 343.59
 ---- batch: 030 ----
mean loss: 353.23
train mean loss: 348.63
epoch train time: 0:00:07.163825
elapsed time: 0:03:07.269708
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 08:40:49.519404
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 349.10
 ---- batch: 020 ----
mean loss: 339.21
 ---- batch: 030 ----
mean loss: 354.26
train mean loss: 345.47
epoch train time: 0:00:06.963146
elapsed time: 0:03:14.233742
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 08:40:56.483413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 339.59
 ---- batch: 020 ----
mean loss: 338.82
 ---- batch: 030 ----
mean loss: 329.97
train mean loss: 336.79
epoch train time: 0:00:07.121117
elapsed time: 0:03:21.355654
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 08:41:03.605323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 334.06
 ---- batch: 020 ----
mean loss: 321.55
 ---- batch: 030 ----
mean loss: 325.36
train mean loss: 324.33
epoch train time: 0:00:06.982091
elapsed time: 0:03:28.338485
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 08:41:10.588143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.14
 ---- batch: 020 ----
mean loss: 313.02
 ---- batch: 030 ----
mean loss: 315.82
train mean loss: 313.83
epoch train time: 0:00:07.093207
elapsed time: 0:03:35.432591
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 08:41:17.682254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.32
 ---- batch: 020 ----
mean loss: 308.30
 ---- batch: 030 ----
mean loss: 308.61
train mean loss: 309.16
epoch train time: 0:00:07.045279
elapsed time: 0:03:42.478700
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 08:41:24.728376
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 301.22
 ---- batch: 020 ----
mean loss: 293.70
 ---- batch: 030 ----
mean loss: 297.19
train mean loss: 298.36
epoch train time: 0:00:07.059817
elapsed time: 0:03:49.539321
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 08:41:31.788987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.77
 ---- batch: 020 ----
mean loss: 288.52
 ---- batch: 030 ----
mean loss: 287.28
train mean loss: 286.26
epoch train time: 0:00:07.118753
elapsed time: 0:03:56.658823
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 08:41:38.908508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.75
 ---- batch: 020 ----
mean loss: 274.82
 ---- batch: 030 ----
mean loss: 284.40
train mean loss: 279.10
epoch train time: 0:00:07.023409
elapsed time: 0:04:03.683105
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 08:41:45.932759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.32
 ---- batch: 020 ----
mean loss: 276.00
 ---- batch: 030 ----
mean loss: 267.71
train mean loss: 271.72
epoch train time: 0:00:07.171629
elapsed time: 0:04:10.855468
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 08:41:53.105129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.07
 ---- batch: 020 ----
mean loss: 265.63
 ---- batch: 030 ----
mean loss: 264.92
train mean loss: 265.26
epoch train time: 0:00:06.982444
elapsed time: 0:04:17.838648
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 08:42:00.088319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.52
 ---- batch: 020 ----
mean loss: 257.61
 ---- batch: 030 ----
mean loss: 250.46
train mean loss: 253.13
epoch train time: 0:00:07.112813
elapsed time: 0:04:24.952458
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 08:42:07.202138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.73
 ---- batch: 020 ----
mean loss: 250.02
 ---- batch: 030 ----
mean loss: 234.54
train mean loss: 246.79
epoch train time: 0:00:06.981108
elapsed time: 0:04:31.934320
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 08:42:14.183998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.25
 ---- batch: 020 ----
mean loss: 231.96
 ---- batch: 030 ----
mean loss: 253.78
train mean loss: 241.36
epoch train time: 0:00:07.081448
elapsed time: 0:04:39.016596
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 08:42:21.266265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.07
 ---- batch: 020 ----
mean loss: 232.85
 ---- batch: 030 ----
mean loss: 230.83
train mean loss: 230.20
epoch train time: 0:00:07.094355
elapsed time: 0:04:46.111737
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 08:42:28.361417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.46
 ---- batch: 020 ----
mean loss: 223.54
 ---- batch: 030 ----
mean loss: 216.83
train mean loss: 221.11
epoch train time: 0:00:06.984818
elapsed time: 0:04:53.097343
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 08:42:35.347009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.24
 ---- batch: 020 ----
mean loss: 219.52
 ---- batch: 030 ----
mean loss: 213.46
train mean loss: 221.35
epoch train time: 0:00:07.033789
elapsed time: 0:05:00.131870
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 08:42:42.381560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.39
 ---- batch: 020 ----
mean loss: 220.45
 ---- batch: 030 ----
mean loss: 213.62
train mean loss: 214.23
epoch train time: 0:00:06.995653
elapsed time: 0:05:07.128376
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 08:42:49.378055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.92
 ---- batch: 020 ----
mean loss: 201.62
 ---- batch: 030 ----
mean loss: 208.98
train mean loss: 207.64
epoch train time: 0:00:06.884711
elapsed time: 0:05:14.013975
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 08:42:56.263647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.26
 ---- batch: 020 ----
mean loss: 207.95
 ---- batch: 030 ----
mean loss: 208.79
train mean loss: 207.68
epoch train time: 0:00:06.924279
elapsed time: 0:05:20.939020
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 08:43:03.188704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.52
 ---- batch: 020 ----
mean loss: 204.60
 ---- batch: 030 ----
mean loss: 210.27
train mean loss: 205.34
epoch train time: 0:00:06.829307
elapsed time: 0:05:27.769153
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 08:43:10.018846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.81
 ---- batch: 020 ----
mean loss: 202.02
 ---- batch: 030 ----
mean loss: 197.97
train mean loss: 199.18
epoch train time: 0:00:06.934578
elapsed time: 0:05:34.704516
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 08:43:16.954188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.76
 ---- batch: 020 ----
mean loss: 193.85
 ---- batch: 030 ----
mean loss: 196.85
train mean loss: 194.98
epoch train time: 0:00:06.937636
elapsed time: 0:05:41.642941
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 08:43:23.892640
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.02
 ---- batch: 020 ----
mean loss: 196.01
 ---- batch: 030 ----
mean loss: 194.05
train mean loss: 193.09
epoch train time: 0:00:06.857557
elapsed time: 0:05:48.501312
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 08:43:30.750977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.25
 ---- batch: 020 ----
mean loss: 196.27
 ---- batch: 030 ----
mean loss: 194.51
train mean loss: 192.98
epoch train time: 0:00:06.894818
elapsed time: 0:05:55.396839
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 08:43:37.646544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.51
 ---- batch: 020 ----
mean loss: 189.74
 ---- batch: 030 ----
mean loss: 186.37
train mean loss: 189.11
epoch train time: 0:00:06.833935
elapsed time: 0:06:02.231580
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 08:43:44.481244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.06
 ---- batch: 020 ----
mean loss: 181.95
 ---- batch: 030 ----
mean loss: 186.16
train mean loss: 185.60
epoch train time: 0:00:06.894254
elapsed time: 0:06:09.126568
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 08:43:51.376229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.29
 ---- batch: 020 ----
mean loss: 184.58
 ---- batch: 030 ----
mean loss: 182.14
train mean loss: 183.24
epoch train time: 0:00:06.821177
elapsed time: 0:06:15.948504
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 08:43:58.198199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.71
 ---- batch: 020 ----
mean loss: 184.27
 ---- batch: 030 ----
mean loss: 176.14
train mean loss: 181.02
epoch train time: 0:00:06.974147
elapsed time: 0:06:22.923708
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 08:44:05.173381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.08
 ---- batch: 020 ----
mean loss: 185.99
 ---- batch: 030 ----
mean loss: 178.61
train mean loss: 182.20
epoch train time: 0:00:06.910601
elapsed time: 0:06:29.835218
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 08:44:12.084887
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.68
 ---- batch: 020 ----
mean loss: 178.36
 ---- batch: 030 ----
mean loss: 178.98
train mean loss: 176.89
epoch train time: 0:00:07.024888
elapsed time: 0:06:36.860918
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 08:44:19.110590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.28
 ---- batch: 020 ----
mean loss: 172.15
 ---- batch: 030 ----
mean loss: 173.00
train mean loss: 174.51
epoch train time: 0:00:06.899828
elapsed time: 0:06:43.761569
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 08:44:26.011246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.45
 ---- batch: 020 ----
mean loss: 173.28
 ---- batch: 030 ----
mean loss: 170.03
train mean loss: 172.98
epoch train time: 0:00:07.025972
elapsed time: 0:06:50.788320
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 08:44:33.037987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.49
 ---- batch: 020 ----
mean loss: 169.72
 ---- batch: 030 ----
mean loss: 169.82
train mean loss: 170.46
epoch train time: 0:00:06.934606
elapsed time: 0:06:57.723697
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 08:44:39.973357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.63
 ---- batch: 020 ----
mean loss: 167.65
 ---- batch: 030 ----
mean loss: 171.96
train mean loss: 168.81
epoch train time: 0:00:07.058367
elapsed time: 0:07:04.782893
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 08:44:47.032577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.53
 ---- batch: 020 ----
mean loss: 168.69
 ---- batch: 030 ----
mean loss: 169.78
train mean loss: 169.72
epoch train time: 0:00:06.898812
elapsed time: 0:07:11.682534
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 08:44:53.932264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.73
 ---- batch: 020 ----
mean loss: 164.95
 ---- batch: 030 ----
mean loss: 173.05
train mean loss: 168.28
epoch train time: 0:00:07.042620
elapsed time: 0:07:18.725944
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 08:45:00.975600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.11
 ---- batch: 020 ----
mean loss: 163.52
 ---- batch: 030 ----
mean loss: 167.81
train mean loss: 165.83
epoch train time: 0:00:06.874747
elapsed time: 0:07:25.601452
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 08:45:07.851106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.96
 ---- batch: 020 ----
mean loss: 163.46
 ---- batch: 030 ----
mean loss: 158.17
train mean loss: 163.33
epoch train time: 0:00:06.973337
elapsed time: 0:07:32.575688
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 08:45:14.825408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.16
 ---- batch: 020 ----
mean loss: 165.74
 ---- batch: 030 ----
mean loss: 161.59
train mean loss: 161.22
epoch train time: 0:00:06.910726
elapsed time: 0:07:39.487226
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 08:45:21.736907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.48
 ---- batch: 020 ----
mean loss: 159.15
 ---- batch: 030 ----
mean loss: 159.49
train mean loss: 160.51
epoch train time: 0:00:06.932333
elapsed time: 0:07:46.420496
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 08:45:28.670212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.06
 ---- batch: 020 ----
mean loss: 158.70
 ---- batch: 030 ----
mean loss: 164.01
train mean loss: 160.42
epoch train time: 0:00:06.891250
elapsed time: 0:07:53.312538
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 08:45:35.562209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.02
 ---- batch: 020 ----
mean loss: 162.03
 ---- batch: 030 ----
mean loss: 160.01
train mean loss: 159.82
epoch train time: 0:00:06.903140
elapsed time: 0:08:00.216442
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 08:45:42.466104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.91
 ---- batch: 020 ----
mean loss: 159.04
 ---- batch: 030 ----
mean loss: 155.80
train mean loss: 156.58
epoch train time: 0:00:07.011737
elapsed time: 0:08:07.229072
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 08:45:49.478820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.68
 ---- batch: 020 ----
mean loss: 151.06
 ---- batch: 030 ----
mean loss: 151.04
train mean loss: 155.66
epoch train time: 0:00:06.923925
elapsed time: 0:08:14.153821
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 08:45:56.403542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.18
 ---- batch: 020 ----
mean loss: 157.02
 ---- batch: 030 ----
mean loss: 154.94
train mean loss: 154.87
epoch train time: 0:00:06.967334
elapsed time: 0:08:21.121960
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 08:46:03.371665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.06
 ---- batch: 020 ----
mean loss: 150.09
 ---- batch: 030 ----
mean loss: 153.45
train mean loss: 152.71
epoch train time: 0:00:07.012547
elapsed time: 0:08:28.135355
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 08:46:10.385038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.81
 ---- batch: 020 ----
mean loss: 149.00
 ---- batch: 030 ----
mean loss: 149.46
train mean loss: 148.51
epoch train time: 0:00:06.849751
elapsed time: 0:08:34.985888
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 08:46:17.235577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.11
 ---- batch: 020 ----
mean loss: 152.65
 ---- batch: 030 ----
mean loss: 148.11
train mean loss: 151.75
epoch train time: 0:00:06.945099
elapsed time: 0:08:41.931772
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 08:46:24.181475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.75
 ---- batch: 020 ----
mean loss: 153.91
 ---- batch: 030 ----
mean loss: 152.51
train mean loss: 150.58
epoch train time: 0:00:06.940956
elapsed time: 0:08:48.873510
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 08:46:31.123175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.45
 ---- batch: 020 ----
mean loss: 147.98
 ---- batch: 030 ----
mean loss: 145.75
train mean loss: 145.74
epoch train time: 0:00:06.857621
elapsed time: 0:08:55.731890
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 08:46:37.981578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.93
 ---- batch: 020 ----
mean loss: 146.33
 ---- batch: 030 ----
mean loss: 148.55
train mean loss: 146.88
epoch train time: 0:00:06.943305
elapsed time: 0:09:02.675924
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 08:46:44.925664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.04
 ---- batch: 020 ----
mean loss: 144.97
 ---- batch: 030 ----
mean loss: 142.79
train mean loss: 145.88
epoch train time: 0:00:06.851980
elapsed time: 0:09:09.528785
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 08:46:51.778481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.68
 ---- batch: 020 ----
mean loss: 143.01
 ---- batch: 030 ----
mean loss: 148.95
train mean loss: 147.15
epoch train time: 0:00:06.955409
elapsed time: 0:09:16.484985
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 08:46:58.734673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.43
 ---- batch: 020 ----
mean loss: 141.24
 ---- batch: 030 ----
mean loss: 143.97
train mean loss: 145.39
epoch train time: 0:00:07.004041
elapsed time: 0:09:23.489806
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 08:47:05.739492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.41
 ---- batch: 020 ----
mean loss: 145.99
 ---- batch: 030 ----
mean loss: 141.51
train mean loss: 143.30
epoch train time: 0:00:06.900452
elapsed time: 0:09:30.391048
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 08:47:12.640716
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.36
 ---- batch: 020 ----
mean loss: 141.85
 ---- batch: 030 ----
mean loss: 142.19
train mean loss: 142.55
epoch train time: 0:00:06.944378
elapsed time: 0:09:37.336186
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 08:47:19.585867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.45
 ---- batch: 020 ----
mean loss: 141.37
 ---- batch: 030 ----
mean loss: 141.03
train mean loss: 140.78
epoch train time: 0:00:06.872271
elapsed time: 0:09:44.209250
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 08:47:26.458918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.92
 ---- batch: 020 ----
mean loss: 141.37
 ---- batch: 030 ----
mean loss: 141.43
train mean loss: 140.89
epoch train time: 0:00:06.944260
elapsed time: 0:09:51.154256
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 08:47:33.403928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.07
 ---- batch: 020 ----
mean loss: 136.34
 ---- batch: 030 ----
mean loss: 142.96
train mean loss: 140.84
epoch train time: 0:00:06.883219
elapsed time: 0:09:58.038262
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 08:47:40.287930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.69
 ---- batch: 020 ----
mean loss: 139.20
 ---- batch: 030 ----
mean loss: 138.24
train mean loss: 135.84
epoch train time: 0:00:07.066123
elapsed time: 0:10:05.105199
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 08:47:47.354937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.95
 ---- batch: 020 ----
mean loss: 137.58
 ---- batch: 030 ----
mean loss: 134.70
train mean loss: 137.03
epoch train time: 0:00:06.883835
elapsed time: 0:10:11.989883
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 08:47:54.239609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.31
 ---- batch: 020 ----
mean loss: 135.79
 ---- batch: 030 ----
mean loss: 140.65
train mean loss: 137.15
epoch train time: 0:00:06.915693
elapsed time: 0:10:18.906383
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 08:48:01.156052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.01
 ---- batch: 020 ----
mean loss: 136.45
 ---- batch: 030 ----
mean loss: 129.44
train mean loss: 135.48
epoch train time: 0:00:06.988349
elapsed time: 0:10:25.895557
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 08:48:08.145262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.37
 ---- batch: 020 ----
mean loss: 132.30
 ---- batch: 030 ----
mean loss: 131.94
train mean loss: 134.76
epoch train time: 0:00:06.902663
elapsed time: 0:10:32.799029
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 08:48:15.048703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.53
 ---- batch: 020 ----
mean loss: 129.83
 ---- batch: 030 ----
mean loss: 137.97
train mean loss: 135.98
epoch train time: 0:00:06.898479
elapsed time: 0:10:39.698292
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 08:48:21.948005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.71
 ---- batch: 020 ----
mean loss: 130.08
 ---- batch: 030 ----
mean loss: 137.64
train mean loss: 134.30
epoch train time: 0:00:06.948582
elapsed time: 0:10:46.647906
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 08:48:28.897626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.73
 ---- batch: 020 ----
mean loss: 134.88
 ---- batch: 030 ----
mean loss: 134.35
train mean loss: 133.68
epoch train time: 0:00:06.895962
elapsed time: 0:10:53.544707
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 08:48:35.794368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.85
 ---- batch: 020 ----
mean loss: 133.15
 ---- batch: 030 ----
mean loss: 132.41
train mean loss: 132.62
epoch train time: 0:00:06.876468
elapsed time: 0:11:00.422055
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 08:48:42.671713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.64
 ---- batch: 020 ----
mean loss: 131.43
 ---- batch: 030 ----
mean loss: 134.27
train mean loss: 133.63
epoch train time: 0:00:06.966879
elapsed time: 0:11:07.389777
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 08:48:49.639478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.04
 ---- batch: 020 ----
mean loss: 133.08
 ---- batch: 030 ----
mean loss: 131.62
train mean loss: 133.61
epoch train time: 0:00:06.883587
elapsed time: 0:11:14.274265
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 08:48:56.523928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.29
 ---- batch: 020 ----
mean loss: 126.16
 ---- batch: 030 ----
mean loss: 136.63
train mean loss: 130.81
epoch train time: 0:00:06.928557
elapsed time: 0:11:21.203581
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 08:49:03.453254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.96
 ---- batch: 020 ----
mean loss: 129.56
 ---- batch: 030 ----
mean loss: 133.11
train mean loss: 130.82
epoch train time: 0:00:06.978444
elapsed time: 0:11:28.182850
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 08:49:10.432533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.87
 ---- batch: 020 ----
mean loss: 128.64
 ---- batch: 030 ----
mean loss: 130.85
train mean loss: 128.47
epoch train time: 0:00:06.887574
elapsed time: 0:11:35.071246
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 08:49:17.320926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.83
 ---- batch: 020 ----
mean loss: 131.20
 ---- batch: 030 ----
mean loss: 128.76
train mean loss: 130.41
epoch train time: 0:00:06.901814
elapsed time: 0:11:41.973918
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 08:49:24.223594
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.28
 ---- batch: 020 ----
mean loss: 127.29
 ---- batch: 030 ----
mean loss: 130.06
train mean loss: 130.83
epoch train time: 0:00:06.966727
elapsed time: 0:11:48.941501
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 08:49:31.191243
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.34
 ---- batch: 020 ----
mean loss: 126.63
 ---- batch: 030 ----
mean loss: 125.46
train mean loss: 126.87
epoch train time: 0:00:06.759183
elapsed time: 0:11:55.701587
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 08:49:37.951248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.39
 ---- batch: 020 ----
mean loss: 125.25
 ---- batch: 030 ----
mean loss: 129.26
train mean loss: 127.75
epoch train time: 0:00:06.861960
elapsed time: 0:12:02.564315
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 08:49:44.813980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.35
 ---- batch: 020 ----
mean loss: 128.35
 ---- batch: 030 ----
mean loss: 129.63
train mean loss: 127.50
epoch train time: 0:00:06.824046
elapsed time: 0:12:09.389084
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 08:49:51.638740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.83
 ---- batch: 020 ----
mean loss: 126.66
 ---- batch: 030 ----
mean loss: 123.04
train mean loss: 124.08
epoch train time: 0:00:06.766694
elapsed time: 0:12:16.156572
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 08:49:58.406224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.51
 ---- batch: 020 ----
mean loss: 122.06
 ---- batch: 030 ----
mean loss: 123.51
train mean loss: 125.10
epoch train time: 0:00:06.929496
elapsed time: 0:12:23.086797
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 08:50:05.336496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.12
 ---- batch: 020 ----
mean loss: 124.60
 ---- batch: 030 ----
mean loss: 127.30
train mean loss: 125.94
epoch train time: 0:00:06.941872
elapsed time: 0:12:30.029565
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 08:50:12.279254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.88
 ---- batch: 020 ----
mean loss: 123.77
 ---- batch: 030 ----
mean loss: 123.39
train mean loss: 123.82
epoch train time: 0:00:06.843110
elapsed time: 0:12:36.873542
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 08:50:19.123108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.32
 ---- batch: 020 ----
mean loss: 122.85
 ---- batch: 030 ----
mean loss: 123.86
train mean loss: 122.67
epoch train time: 0:00:06.939689
elapsed time: 0:12:43.813942
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 08:50:26.063613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.55
 ---- batch: 020 ----
mean loss: 123.26
 ---- batch: 030 ----
mean loss: 119.53
train mean loss: 122.81
epoch train time: 0:00:06.836753
elapsed time: 0:12:50.651476
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 08:50:32.901187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.90
 ---- batch: 020 ----
mean loss: 121.73
 ---- batch: 030 ----
mean loss: 121.36
train mean loss: 121.76
epoch train time: 0:00:06.925787
elapsed time: 0:12:57.578066
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 08:50:39.827736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.59
 ---- batch: 020 ----
mean loss: 119.33
 ---- batch: 030 ----
mean loss: 123.14
train mean loss: 120.03
epoch train time: 0:00:06.882478
elapsed time: 0:13:04.461297
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 08:50:46.710965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.74
 ---- batch: 020 ----
mean loss: 121.00
 ---- batch: 030 ----
mean loss: 119.19
train mean loss: 121.32
epoch train time: 0:00:06.950838
elapsed time: 0:13:11.412875
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 08:50:53.662544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.24
 ---- batch: 020 ----
mean loss: 119.95
 ---- batch: 030 ----
mean loss: 120.58
train mean loss: 120.74
epoch train time: 0:00:06.964858
elapsed time: 0:13:18.378544
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 08:51:00.628232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.28
 ---- batch: 020 ----
mean loss: 122.95
 ---- batch: 030 ----
mean loss: 122.14
train mean loss: 121.37
epoch train time: 0:00:06.989801
elapsed time: 0:13:25.369146
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 08:51:07.618807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.31
 ---- batch: 020 ----
mean loss: 123.33
 ---- batch: 030 ----
mean loss: 117.83
train mean loss: 121.34
epoch train time: 0:00:06.945358
elapsed time: 0:13:32.315339
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 08:51:14.565031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.55
 ---- batch: 020 ----
mean loss: 118.96
 ---- batch: 030 ----
mean loss: 121.07
train mean loss: 119.62
epoch train time: 0:00:06.799885
elapsed time: 0:13:39.116027
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 08:51:21.365722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.73
 ---- batch: 020 ----
mean loss: 122.26
 ---- batch: 030 ----
mean loss: 118.01
train mean loss: 119.16
epoch train time: 0:00:06.872893
elapsed time: 0:13:45.989771
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 08:51:28.239425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.71
 ---- batch: 020 ----
mean loss: 118.16
 ---- batch: 030 ----
mean loss: 118.10
train mean loss: 118.08
epoch train time: 0:00:06.805896
elapsed time: 0:13:52.796408
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 08:51:35.046075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.94
 ---- batch: 020 ----
mean loss: 117.17
 ---- batch: 030 ----
mean loss: 119.08
train mean loss: 119.36
epoch train time: 0:00:06.809126
elapsed time: 0:13:59.606296
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 08:51:41.855957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.84
 ---- batch: 020 ----
mean loss: 119.22
 ---- batch: 030 ----
mean loss: 125.11
train mean loss: 121.41
epoch train time: 0:00:06.899976
elapsed time: 0:14:06.507088
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 08:51:48.756785
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.49
 ---- batch: 020 ----
mean loss: 117.19
 ---- batch: 030 ----
mean loss: 113.82
train mean loss: 116.81
epoch train time: 0:00:06.968275
elapsed time: 0:14:13.476244
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 08:51:55.725920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.51
 ---- batch: 020 ----
mean loss: 114.34
 ---- batch: 030 ----
mean loss: 118.54
train mean loss: 115.77
epoch train time: 0:00:06.999315
elapsed time: 0:14:20.476356
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 08:52:02.726036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.39
 ---- batch: 020 ----
mean loss: 121.30
 ---- batch: 030 ----
mean loss: 117.45
train mean loss: 118.21
epoch train time: 0:00:06.884808
elapsed time: 0:14:27.361929
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 08:52:09.611600
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.54
 ---- batch: 020 ----
mean loss: 115.32
 ---- batch: 030 ----
mean loss: 117.65
train mean loss: 115.92
epoch train time: 0:00:06.982904
elapsed time: 0:14:34.345685
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 08:52:16.595346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.03
 ---- batch: 020 ----
mean loss: 115.37
 ---- batch: 030 ----
mean loss: 116.18
train mean loss: 115.93
epoch train time: 0:00:07.030016
elapsed time: 0:14:41.376474
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 08:52:23.626267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.90
 ---- batch: 020 ----
mean loss: 115.12
 ---- batch: 030 ----
mean loss: 112.46
train mean loss: 115.41
epoch train time: 0:00:06.889473
elapsed time: 0:14:48.266897
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 08:52:30.516591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.71
 ---- batch: 020 ----
mean loss: 114.63
 ---- batch: 030 ----
mean loss: 113.07
train mean loss: 113.86
epoch train time: 0:00:06.988436
elapsed time: 0:14:55.256422
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 08:52:37.506033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.23
 ---- batch: 020 ----
mean loss: 114.68
 ---- batch: 030 ----
mean loss: 121.18
train mean loss: 114.94
epoch train time: 0:00:06.946800
elapsed time: 0:15:02.203974
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 08:52:44.453666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.55
 ---- batch: 020 ----
mean loss: 115.24
 ---- batch: 030 ----
mean loss: 113.91
train mean loss: 114.88
epoch train time: 0:00:06.926682
elapsed time: 0:15:09.131467
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 08:52:51.381141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.51
 ---- batch: 020 ----
mean loss: 111.65
 ---- batch: 030 ----
mean loss: 110.83
train mean loss: 113.88
epoch train time: 0:00:07.035462
elapsed time: 0:15:16.167854
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 08:52:58.417534
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.29
 ---- batch: 020 ----
mean loss: 113.02
 ---- batch: 030 ----
mean loss: 116.39
train mean loss: 114.40
epoch train time: 0:00:06.859660
elapsed time: 0:15:23.028308
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 08:53:05.277960
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.60
 ---- batch: 020 ----
mean loss: 114.86
 ---- batch: 030 ----
mean loss: 114.40
train mean loss: 114.03
epoch train time: 0:00:07.005566
elapsed time: 0:15:30.034615
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 08:53:12.284279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.21
 ---- batch: 020 ----
mean loss: 115.21
 ---- batch: 030 ----
mean loss: 110.29
train mean loss: 113.67
epoch train time: 0:00:06.925967
elapsed time: 0:15:36.961318
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 08:53:19.210979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.79
 ---- batch: 020 ----
mean loss: 112.05
 ---- batch: 030 ----
mean loss: 113.70
train mean loss: 113.24
epoch train time: 0:00:06.967756
elapsed time: 0:15:43.929892
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 08:53:26.179604
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.77
 ---- batch: 020 ----
mean loss: 115.24
 ---- batch: 030 ----
mean loss: 112.85
train mean loss: 113.66
epoch train time: 0:00:06.985236
elapsed time: 0:15:50.915930
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 08:53:33.165590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.38
 ---- batch: 020 ----
mean loss: 106.41
 ---- batch: 030 ----
mean loss: 113.85
train mean loss: 110.77
epoch train time: 0:00:06.924265
elapsed time: 0:15:57.841064
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 08:53:40.090732
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.13
 ---- batch: 020 ----
mean loss: 108.99
 ---- batch: 030 ----
mean loss: 111.10
train mean loss: 110.73
epoch train time: 0:00:06.943212
elapsed time: 0:16:04.785008
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 08:53:47.034671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.14
 ---- batch: 020 ----
mean loss: 114.68
 ---- batch: 030 ----
mean loss: 109.33
train mean loss: 112.35
epoch train time: 0:00:06.965167
elapsed time: 0:16:11.751007
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 08:53:54.000682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.52
 ---- batch: 020 ----
mean loss: 115.00
 ---- batch: 030 ----
mean loss: 110.32
train mean loss: 112.26
epoch train time: 0:00:06.942613
elapsed time: 0:16:18.694378
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 08:54:00.944053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.11
 ---- batch: 020 ----
mean loss: 111.45
 ---- batch: 030 ----
mean loss: 109.08
train mean loss: 109.68
epoch train time: 0:00:06.912699
elapsed time: 0:16:25.607898
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 08:54:07.857590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.45
 ---- batch: 020 ----
mean loss: 111.14
 ---- batch: 030 ----
mean loss: 113.03
train mean loss: 112.31
epoch train time: 0:00:07.008877
elapsed time: 0:16:32.617682
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 08:54:14.867340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.73
 ---- batch: 020 ----
mean loss: 109.77
 ---- batch: 030 ----
mean loss: 107.00
train mean loss: 110.98
epoch train time: 0:00:06.951889
elapsed time: 0:16:39.570341
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 08:54:21.820044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.64
 ---- batch: 020 ----
mean loss: 110.70
 ---- batch: 030 ----
mean loss: 112.08
train mean loss: 110.17
epoch train time: 0:00:07.075830
elapsed time: 0:16:46.647008
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 08:54:28.896723
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.65
 ---- batch: 020 ----
mean loss: 108.46
 ---- batch: 030 ----
mean loss: 110.29
train mean loss: 108.78
epoch train time: 0:00:06.873472
elapsed time: 0:16:53.521298
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 08:54:35.770969
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.41
 ---- batch: 020 ----
mean loss: 107.66
 ---- batch: 030 ----
mean loss: 112.35
train mean loss: 109.05
epoch train time: 0:00:07.011927
elapsed time: 0:17:00.533997
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 08:54:42.783688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.40
 ---- batch: 020 ----
mean loss: 111.05
 ---- batch: 030 ----
mean loss: 108.30
train mean loss: 109.18
epoch train time: 0:00:07.015857
elapsed time: 0:17:07.550785
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 08:54:49.800454
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.50
 ---- batch: 020 ----
mean loss: 109.52
 ---- batch: 030 ----
mean loss: 106.31
train mean loss: 107.62
epoch train time: 0:00:06.910182
elapsed time: 0:17:14.461921
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 08:54:56.711621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.62
 ---- batch: 020 ----
mean loss: 107.31
 ---- batch: 030 ----
mean loss: 106.44
train mean loss: 106.87
epoch train time: 0:00:06.975489
elapsed time: 0:17:21.438180
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 08:55:03.687847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.79
 ---- batch: 020 ----
mean loss: 109.20
 ---- batch: 030 ----
mean loss: 108.10
train mean loss: 108.81
epoch train time: 0:00:06.939903
elapsed time: 0:17:28.379003
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 08:55:10.628564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.29
 ---- batch: 020 ----
mean loss: 105.74
 ---- batch: 030 ----
mean loss: 105.55
train mean loss: 107.45
epoch train time: 0:00:06.948269
elapsed time: 0:17:35.327951
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 08:55:17.577641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.84
 ---- batch: 020 ----
mean loss: 110.73
 ---- batch: 030 ----
mean loss: 107.78
train mean loss: 108.09
epoch train time: 0:00:06.964882
elapsed time: 0:17:42.293600
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 08:55:24.543273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.37
 ---- batch: 020 ----
mean loss: 107.44
 ---- batch: 030 ----
mean loss: 109.89
train mean loss: 107.51
epoch train time: 0:00:06.930273
elapsed time: 0:17:49.224675
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 08:55:31.474345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.46
 ---- batch: 020 ----
mean loss: 109.99
 ---- batch: 030 ----
mean loss: 100.31
train mean loss: 106.34
epoch train time: 0:00:06.983943
elapsed time: 0:17:56.209367
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 08:55:38.459052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.57
 ---- batch: 020 ----
mean loss: 105.26
 ---- batch: 030 ----
mean loss: 108.57
train mean loss: 106.35
epoch train time: 0:00:06.953416
elapsed time: 0:18:03.163698
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 08:55:45.413398
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.21
 ---- batch: 020 ----
mean loss: 105.45
 ---- batch: 030 ----
mean loss: 105.42
train mean loss: 105.21
epoch train time: 0:00:06.917153
elapsed time: 0:18:10.081733
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 08:55:52.332019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.90
 ---- batch: 020 ----
mean loss: 105.92
 ---- batch: 030 ----
mean loss: 106.33
train mean loss: 105.27
epoch train time: 0:00:07.025866
elapsed time: 0:18:17.108990
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 08:55:59.358658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.95
 ---- batch: 020 ----
mean loss: 105.74
 ---- batch: 030 ----
mean loss: 104.34
train mean loss: 105.69
epoch train time: 0:00:07.015495
elapsed time: 0:18:24.125195
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 08:56:06.374855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.69
 ---- batch: 020 ----
mean loss: 106.96
 ---- batch: 030 ----
mean loss: 105.78
train mean loss: 105.77
epoch train time: 0:00:06.958778
elapsed time: 0:18:31.084782
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 08:56:13.334452
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.89
 ---- batch: 020 ----
mean loss: 105.56
 ---- batch: 030 ----
mean loss: 104.75
train mean loss: 104.73
epoch train time: 0:00:06.999762
elapsed time: 0:18:38.085288
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 08:56:20.334950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.57
 ---- batch: 020 ----
mean loss: 101.74
 ---- batch: 030 ----
mean loss: 102.38
train mean loss: 103.76
epoch train time: 0:00:06.942000
elapsed time: 0:18:45.028112
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 08:56:27.277773
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.86
 ---- batch: 020 ----
mean loss: 102.14
 ---- batch: 030 ----
mean loss: 104.94
train mean loss: 104.89
epoch train time: 0:00:07.015884
elapsed time: 0:18:52.044746
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 08:56:34.294420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.82
 ---- batch: 020 ----
mean loss: 102.86
 ---- batch: 030 ----
mean loss: 102.48
train mean loss: 104.24
epoch train time: 0:00:06.899637
elapsed time: 0:18:58.945126
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 08:56:41.194791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.99
 ---- batch: 020 ----
mean loss: 104.11
 ---- batch: 030 ----
mean loss: 105.53
train mean loss: 103.16
epoch train time: 0:00:06.990595
elapsed time: 0:19:05.936589
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 08:56:48.186276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.43
 ---- batch: 020 ----
mean loss: 103.46
 ---- batch: 030 ----
mean loss: 101.51
train mean loss: 103.25
epoch train time: 0:00:06.943132
elapsed time: 0:19:12.880520
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 08:56:55.130184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.85
 ---- batch: 020 ----
mean loss: 99.75
 ---- batch: 030 ----
mean loss: 102.37
train mean loss: 102.03
epoch train time: 0:00:06.908438
elapsed time: 0:19:19.789713
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 08:57:02.039424
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.24
 ---- batch: 020 ----
mean loss: 99.57
 ---- batch: 030 ----
mean loss: 105.31
train mean loss: 101.84
epoch train time: 0:00:07.014479
elapsed time: 0:19:26.804996
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 08:57:09.054658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.82
 ---- batch: 020 ----
mean loss: 101.20
 ---- batch: 030 ----
mean loss: 102.18
train mean loss: 102.50
epoch train time: 0:00:06.904028
elapsed time: 0:19:33.709771
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 08:57:15.959448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.40
 ---- batch: 020 ----
mean loss: 100.97
 ---- batch: 030 ----
mean loss: 104.56
train mean loss: 103.14
epoch train time: 0:00:06.998114
elapsed time: 0:19:40.708629
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 08:57:22.958286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.31
 ---- batch: 020 ----
mean loss: 99.60
 ---- batch: 030 ----
mean loss: 100.89
train mean loss: 101.98
epoch train time: 0:00:06.998574
elapsed time: 0:19:47.707957
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 08:57:29.957671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.15
 ---- batch: 020 ----
mean loss: 100.46
 ---- batch: 030 ----
mean loss: 100.07
train mean loss: 101.46
epoch train time: 0:00:06.996071
elapsed time: 0:19:54.704808
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 08:57:36.954497
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.70
 ---- batch: 020 ----
mean loss: 101.37
 ---- batch: 030 ----
mean loss: 99.96
train mean loss: 100.52
epoch train time: 0:00:06.952371
elapsed time: 0:20:01.658060
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 08:57:43.907730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.36
 ---- batch: 020 ----
mean loss: 100.52
 ---- batch: 030 ----
mean loss: 100.71
train mean loss: 101.98
epoch train time: 0:00:06.997257
elapsed time: 0:20:08.656204
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 08:57:50.905942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.35
 ---- batch: 020 ----
mean loss: 98.51
 ---- batch: 030 ----
mean loss: 102.26
train mean loss: 101.43
epoch train time: 0:00:06.924648
elapsed time: 0:20:15.581692
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 08:57:57.831407
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.63
 ---- batch: 020 ----
mean loss: 103.47
 ---- batch: 030 ----
mean loss: 99.79
train mean loss: 101.46
epoch train time: 0:00:06.963889
elapsed time: 0:20:22.546603
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 08:58:04.796163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.03
 ---- batch: 020 ----
mean loss: 101.24
 ---- batch: 030 ----
mean loss: 101.84
train mean loss: 100.44
epoch train time: 0:00:07.005595
elapsed time: 0:20:29.552808
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 08:58:11.802477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.86
 ---- batch: 020 ----
mean loss: 99.31
 ---- batch: 030 ----
mean loss: 101.10
train mean loss: 101.59
epoch train time: 0:00:06.912036
elapsed time: 0:20:36.465648
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 08:58:18.715305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.41
 ---- batch: 020 ----
mean loss: 100.41
 ---- batch: 030 ----
mean loss: 101.46
train mean loss: 100.31
epoch train time: 0:00:06.937470
elapsed time: 0:20:43.403850
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 08:58:25.653529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.03
 ---- batch: 020 ----
mean loss: 99.55
 ---- batch: 030 ----
mean loss: 101.60
train mean loss: 100.67
epoch train time: 0:00:06.813983
elapsed time: 0:20:50.218574
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 08:58:32.468238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.24
 ---- batch: 020 ----
mean loss: 100.91
 ---- batch: 030 ----
mean loss: 95.85
train mean loss: 98.98
epoch train time: 0:00:06.957755
elapsed time: 0:20:57.177092
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 08:58:39.426764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.24
 ---- batch: 020 ----
mean loss: 98.59
 ---- batch: 030 ----
mean loss: 99.74
train mean loss: 99.57
epoch train time: 0:00:06.937190
elapsed time: 0:21:04.115013
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 08:58:46.364678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.19
 ---- batch: 020 ----
mean loss: 101.27
 ---- batch: 030 ----
mean loss: 98.86
train mean loss: 98.49
epoch train time: 0:00:06.725676
elapsed time: 0:21:10.841451
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 08:58:53.091162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.49
 ---- batch: 020 ----
mean loss: 101.32
 ---- batch: 030 ----
mean loss: 97.97
train mean loss: 98.56
epoch train time: 0:00:06.797666
elapsed time: 0:21:17.639910
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 08:58:59.889574
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.50
 ---- batch: 020 ----
mean loss: 99.52
 ---- batch: 030 ----
mean loss: 97.95
train mean loss: 98.95
epoch train time: 0:00:06.731128
elapsed time: 0:21:24.371902
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 08:59:06.621572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.25
 ---- batch: 020 ----
mean loss: 100.83
 ---- batch: 030 ----
mean loss: 101.39
train mean loss: 100.32
epoch train time: 0:00:06.748168
elapsed time: 0:21:31.120912
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 08:59:13.370579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.07
 ---- batch: 020 ----
mean loss: 98.23
 ---- batch: 030 ----
mean loss: 99.98
train mean loss: 98.70
epoch train time: 0:00:06.805019
elapsed time: 0:21:37.926795
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 08:59:20.176465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.05
 ---- batch: 020 ----
mean loss: 101.36
 ---- batch: 030 ----
mean loss: 92.72
train mean loss: 98.42
epoch train time: 0:00:06.847477
elapsed time: 0:21:44.775028
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 08:59:27.024686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.44
 ---- batch: 020 ----
mean loss: 100.39
 ---- batch: 030 ----
mean loss: 95.83
train mean loss: 99.33
epoch train time: 0:00:06.914631
elapsed time: 0:21:51.690423
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 08:59:33.940097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.78
 ---- batch: 020 ----
mean loss: 99.07
 ---- batch: 030 ----
mean loss: 101.38
train mean loss: 97.92
epoch train time: 0:00:06.923101
elapsed time: 0:21:58.614283
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 08:59:40.863952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.77
 ---- batch: 020 ----
mean loss: 97.64
 ---- batch: 030 ----
mean loss: 99.09
train mean loss: 97.17
epoch train time: 0:00:06.885886
elapsed time: 0:22:05.500955
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 08:59:47.750622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.97
 ---- batch: 020 ----
mean loss: 98.10
 ---- batch: 030 ----
mean loss: 100.43
train mean loss: 97.11
epoch train time: 0:00:06.999192
elapsed time: 0:22:12.501023
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 08:59:54.750701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.24
 ---- batch: 020 ----
mean loss: 95.81
 ---- batch: 030 ----
mean loss: 97.45
train mean loss: 97.66
epoch train time: 0:00:06.871270
elapsed time: 0:22:19.373088
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 09:00:01.622755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.69
 ---- batch: 020 ----
mean loss: 97.24
 ---- batch: 030 ----
mean loss: 96.13
train mean loss: 97.56
epoch train time: 0:00:06.867004
elapsed time: 0:22:26.240851
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 09:00:08.490528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.83
 ---- batch: 020 ----
mean loss: 96.33
 ---- batch: 030 ----
mean loss: 98.71
train mean loss: 96.99
epoch train time: 0:00:06.877449
elapsed time: 0:22:33.119123
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 09:00:15.368787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.52
 ---- batch: 020 ----
mean loss: 98.61
 ---- batch: 030 ----
mean loss: 94.01
train mean loss: 96.86
epoch train time: 0:00:06.811435
elapsed time: 0:22:39.931296
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 09:00:22.180984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.57
 ---- batch: 020 ----
mean loss: 97.42
 ---- batch: 030 ----
mean loss: 94.18
train mean loss: 96.05
epoch train time: 0:00:06.766202
elapsed time: 0:22:46.698354
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 09:00:28.948060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.83
 ---- batch: 020 ----
mean loss: 99.26
 ---- batch: 030 ----
mean loss: 95.58
train mean loss: 97.84
epoch train time: 0:00:06.831079
elapsed time: 0:22:53.530238
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 09:00:35.779914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.48
 ---- batch: 020 ----
mean loss: 97.30
 ---- batch: 030 ----
mean loss: 93.23
train mean loss: 96.05
epoch train time: 0:00:06.813872
elapsed time: 0:23:00.344911
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 09:00:42.594596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.19
 ---- batch: 020 ----
mean loss: 96.87
 ---- batch: 030 ----
mean loss: 96.32
train mean loss: 96.61
epoch train time: 0:00:06.949366
elapsed time: 0:23:07.295191
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 09:00:49.544871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.16
 ---- batch: 020 ----
mean loss: 96.04
 ---- batch: 030 ----
mean loss: 96.93
train mean loss: 95.71
epoch train time: 0:00:06.768585
elapsed time: 0:23:14.064544
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 09:00:56.314208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.43
 ---- batch: 020 ----
mean loss: 95.25
 ---- batch: 030 ----
mean loss: 96.84
train mean loss: 96.44
epoch train time: 0:00:06.843186
elapsed time: 0:23:20.908500
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 09:01:03.158169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.08
 ---- batch: 020 ----
mean loss: 96.35
 ---- batch: 030 ----
mean loss: 98.76
train mean loss: 96.00
epoch train time: 0:00:06.889919
elapsed time: 0:23:27.799194
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 09:01:10.048868
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.50
 ---- batch: 020 ----
mean loss: 94.64
 ---- batch: 030 ----
mean loss: 95.12
train mean loss: 94.48
epoch train time: 0:00:06.801023
elapsed time: 0:23:34.601293
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 09:01:16.850864
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.53
 ---- batch: 020 ----
mean loss: 93.35
 ---- batch: 030 ----
mean loss: 95.54
train mean loss: 94.79
epoch train time: 0:00:06.857752
elapsed time: 0:23:41.459696
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 09:01:23.709360
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.67
 ---- batch: 020 ----
mean loss: 94.49
 ---- batch: 030 ----
mean loss: 95.15
train mean loss: 95.05
epoch train time: 0:00:06.892973
elapsed time: 0:23:48.353386
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 09:01:30.603048
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.34
 ---- batch: 020 ----
mean loss: 91.68
 ---- batch: 030 ----
mean loss: 94.30
train mean loss: 93.87
epoch train time: 0:00:06.763605
elapsed time: 0:23:55.117746
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 09:01:37.367419
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.99
 ---- batch: 020 ----
mean loss: 94.62
 ---- batch: 030 ----
mean loss: 93.35
train mean loss: 94.93
epoch train time: 0:00:06.876239
elapsed time: 0:24:01.994808
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 09:01:44.244506
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.16
 ---- batch: 020 ----
mean loss: 93.86
 ---- batch: 030 ----
mean loss: 93.82
train mean loss: 94.75
epoch train time: 0:00:06.878053
elapsed time: 0:24:08.873678
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 09:01:51.123394
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.73
 ---- batch: 020 ----
mean loss: 94.86
 ---- batch: 030 ----
mean loss: 95.47
train mean loss: 95.35
epoch train time: 0:00:06.906622
elapsed time: 0:24:15.781297
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 09:01:58.031009
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 98.02
 ---- batch: 020 ----
mean loss: 89.91
 ---- batch: 030 ----
mean loss: 95.29
train mean loss: 95.01
epoch train time: 0:00:06.924982
elapsed time: 0:24:22.707104
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 09:02:04.956778
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.30
 ---- batch: 020 ----
mean loss: 96.38
 ---- batch: 030 ----
mean loss: 94.36
train mean loss: 94.90
epoch train time: 0:00:06.792879
elapsed time: 0:24:29.500816
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 09:02:11.750520
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.64
 ---- batch: 020 ----
mean loss: 93.23
 ---- batch: 030 ----
mean loss: 95.73
train mean loss: 94.44
epoch train time: 0:00:06.861632
elapsed time: 0:24:36.363263
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 09:02:18.612929
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.73
 ---- batch: 020 ----
mean loss: 94.48
 ---- batch: 030 ----
mean loss: 92.23
train mean loss: 94.36
epoch train time: 0:00:06.913362
elapsed time: 0:24:43.277373
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 09:02:25.527054
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.34
 ---- batch: 020 ----
mean loss: 97.55
 ---- batch: 030 ----
mean loss: 93.58
train mean loss: 94.08
epoch train time: 0:00:06.811197
elapsed time: 0:24:50.089345
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 09:02:32.339019
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.32
 ---- batch: 020 ----
mean loss: 90.97
 ---- batch: 030 ----
mean loss: 95.32
train mean loss: 94.37
epoch train time: 0:00:06.946618
elapsed time: 0:24:57.036752
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 09:02:39.286425
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.76
 ---- batch: 020 ----
mean loss: 95.51
 ---- batch: 030 ----
mean loss: 92.37
train mean loss: 94.77
epoch train time: 0:00:06.906837
elapsed time: 0:25:03.944386
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 09:02:46.194042
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.86
 ---- batch: 020 ----
mean loss: 89.80
 ---- batch: 030 ----
mean loss: 97.35
train mean loss: 93.75
epoch train time: 0:00:06.864348
elapsed time: 0:25:10.809493
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 09:02:53.059153
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.84
 ---- batch: 020 ----
mean loss: 96.91
 ---- batch: 030 ----
mean loss: 93.51
train mean loss: 94.91
epoch train time: 0:00:06.828676
elapsed time: 0:25:17.638993
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 09:02:59.888690
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.92
 ---- batch: 020 ----
mean loss: 95.04
 ---- batch: 030 ----
mean loss: 95.71
train mean loss: 94.61
epoch train time: 0:00:06.904068
elapsed time: 0:25:24.544088
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 09:03:06.793819
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.33
 ---- batch: 020 ----
mean loss: 93.27
 ---- batch: 030 ----
mean loss: 94.17
train mean loss: 94.77
epoch train time: 0:00:06.775330
elapsed time: 0:25:31.320407
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 09:03:13.570084
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.48
 ---- batch: 020 ----
mean loss: 96.67
 ---- batch: 030 ----
mean loss: 96.52
train mean loss: 94.46
epoch train time: 0:00:06.870814
elapsed time: 0:25:38.192043
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 09:03:20.441759
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.36
 ---- batch: 020 ----
mean loss: 96.01
 ---- batch: 030 ----
mean loss: 97.19
train mean loss: 95.56
epoch train time: 0:00:06.820928
elapsed time: 0:25:45.013823
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 09:03:27.263484
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.60
 ---- batch: 020 ----
mean loss: 94.65
 ---- batch: 030 ----
mean loss: 95.07
train mean loss: 94.63
epoch train time: 0:00:06.825231
elapsed time: 0:25:51.839842
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 09:03:34.089535
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.28
 ---- batch: 020 ----
mean loss: 94.20
 ---- batch: 030 ----
mean loss: 90.57
train mean loss: 94.08
epoch train time: 0:00:06.821390
elapsed time: 0:25:58.662240
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 09:03:40.911909
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.06
 ---- batch: 020 ----
mean loss: 92.39
 ---- batch: 030 ----
mean loss: 97.03
train mean loss: 94.64
epoch train time: 0:00:06.792820
elapsed time: 0:26:05.455898
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 09:03:47.705580
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.40
 ---- batch: 020 ----
mean loss: 92.72
 ---- batch: 030 ----
mean loss: 91.94
train mean loss: 93.82
epoch train time: 0:00:06.894778
elapsed time: 0:26:12.351410
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 09:03:54.601097
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.65
 ---- batch: 020 ----
mean loss: 92.03
 ---- batch: 030 ----
mean loss: 95.74
train mean loss: 93.62
epoch train time: 0:00:06.743271
elapsed time: 0:26:19.095488
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 09:04:01.345153
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.16
 ---- batch: 020 ----
mean loss: 95.10
 ---- batch: 030 ----
mean loss: 95.85
train mean loss: 94.19
epoch train time: 0:00:06.838864
elapsed time: 0:26:25.935121
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 09:04:08.184820
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.23
 ---- batch: 020 ----
mean loss: 96.11
 ---- batch: 030 ----
mean loss: 93.57
train mean loss: 94.90
epoch train time: 0:00:06.864545
elapsed time: 0:26:32.800489
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 09:04:15.050174
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.71
 ---- batch: 020 ----
mean loss: 93.18
 ---- batch: 030 ----
mean loss: 95.68
train mean loss: 94.27
epoch train time: 0:00:06.752983
elapsed time: 0:26:39.554279
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 09:04:21.803949
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.19
 ---- batch: 020 ----
mean loss: 95.03
 ---- batch: 030 ----
mean loss: 92.66
train mean loss: 94.50
epoch train time: 0:00:06.893324
elapsed time: 0:26:46.448375
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 09:04:28.698054
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.21
 ---- batch: 020 ----
mean loss: 94.83
 ---- batch: 030 ----
mean loss: 93.41
train mean loss: 93.80
epoch train time: 0:00:06.878949
elapsed time: 0:26:53.328056
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 09:04:35.577733
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.41
 ---- batch: 020 ----
mean loss: 94.06
 ---- batch: 030 ----
mean loss: 91.12
train mean loss: 93.90
epoch train time: 0:00:06.680371
elapsed time: 0:27:00.009187
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 09:04:42.258868
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.48
 ---- batch: 020 ----
mean loss: 96.83
 ---- batch: 030 ----
mean loss: 92.68
train mean loss: 93.98
epoch train time: 0:00:06.737830
elapsed time: 0:27:06.747779
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 09:04:48.997450
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.45
 ---- batch: 020 ----
mean loss: 94.31
 ---- batch: 030 ----
mean loss: 91.41
train mean loss: 93.50
epoch train time: 0:00:06.729105
elapsed time: 0:27:13.477758
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 09:04:55.727327
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 98.25
 ---- batch: 020 ----
mean loss: 93.49
 ---- batch: 030 ----
mean loss: 91.65
train mean loss: 94.04
epoch train time: 0:00:06.771850
elapsed time: 0:27:20.250262
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 09:05:02.499938
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.47
 ---- batch: 020 ----
mean loss: 92.46
 ---- batch: 030 ----
mean loss: 90.77
train mean loss: 94.04
epoch train time: 0:00:06.885358
elapsed time: 0:27:27.136459
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 09:05:09.386138
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.20
 ---- batch: 020 ----
mean loss: 92.34
 ---- batch: 030 ----
mean loss: 94.24
train mean loss: 94.56
epoch train time: 0:00:06.960479
elapsed time: 0:27:34.097695
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 09:05:16.347358
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.90
 ---- batch: 020 ----
mean loss: 93.79
 ---- batch: 030 ----
mean loss: 93.09
train mean loss: 93.79
epoch train time: 0:00:06.862788
elapsed time: 0:27:40.961229
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 09:05:23.210887
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.03
 ---- batch: 020 ----
mean loss: 93.85
 ---- batch: 030 ----
mean loss: 92.15
train mean loss: 93.67
epoch train time: 0:00:06.988363
elapsed time: 0:27:47.950415
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 09:05:30.200097
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.72
 ---- batch: 020 ----
mean loss: 93.30
 ---- batch: 030 ----
mean loss: 92.44
train mean loss: 94.19
epoch train time: 0:00:06.970757
elapsed time: 0:27:54.922029
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 09:05:37.171704
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.44
 ---- batch: 020 ----
mean loss: 93.93
 ---- batch: 030 ----
mean loss: 94.97
train mean loss: 93.54
epoch train time: 0:00:06.881793
elapsed time: 0:28:01.804611
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 09:05:44.054270
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.74
 ---- batch: 020 ----
mean loss: 93.93
 ---- batch: 030 ----
mean loss: 95.81
train mean loss: 94.08
epoch train time: 0:00:06.958323
elapsed time: 0:28:08.763776
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 09:05:51.013442
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.00
 ---- batch: 020 ----
mean loss: 93.28
 ---- batch: 030 ----
mean loss: 92.88
train mean loss: 93.63
epoch train time: 0:00:06.854344
elapsed time: 0:28:15.619017
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 09:05:57.868694
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.45
 ---- batch: 020 ----
mean loss: 94.36
 ---- batch: 030 ----
mean loss: 92.64
train mean loss: 93.82
epoch train time: 0:00:06.951386
elapsed time: 0:28:22.571264
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 09:06:04.820970
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.35
 ---- batch: 020 ----
mean loss: 92.31
 ---- batch: 030 ----
mean loss: 90.70
train mean loss: 93.42
epoch train time: 0:00:06.942608
elapsed time: 0:28:29.514662
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 09:06:11.764331
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.80
 ---- batch: 020 ----
mean loss: 92.34
 ---- batch: 030 ----
mean loss: 93.20
train mean loss: 93.97
epoch train time: 0:00:06.781932
elapsed time: 0:28:36.297451
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 09:06:18.547128
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.96
 ---- batch: 020 ----
mean loss: 96.39
 ---- batch: 030 ----
mean loss: 93.65
train mean loss: 94.46
epoch train time: 0:00:06.801316
elapsed time: 0:28:43.099551
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 09:06:25.349211
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.29
 ---- batch: 020 ----
mean loss: 93.12
 ---- batch: 030 ----
mean loss: 92.08
train mean loss: 93.39
epoch train time: 0:00:06.775105
elapsed time: 0:28:49.875476
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 09:06:32.125154
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.21
 ---- batch: 020 ----
mean loss: 94.79
 ---- batch: 030 ----
mean loss: 92.12
train mean loss: 94.77
epoch train time: 0:00:06.853400
elapsed time: 0:28:56.729694
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 09:06:38.979390
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.35
 ---- batch: 020 ----
mean loss: 96.12
 ---- batch: 030 ----
mean loss: 96.78
train mean loss: 93.85
epoch train time: 0:00:06.830096
elapsed time: 0:29:03.569933
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_6/checkpoint.pth.tar
**** end time: 2019-09-27 09:06:45.819468 ****
