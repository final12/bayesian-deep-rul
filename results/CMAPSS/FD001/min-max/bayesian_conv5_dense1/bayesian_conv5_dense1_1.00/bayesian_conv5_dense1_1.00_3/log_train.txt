Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_3', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 22108
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-27 07:09:41.826708 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 31, 14]             200
           Sigmoid-2           [-1, 10, 31, 14]               0
    BayesianConv2d-3           [-1, 10, 30, 14]           2,000
           Sigmoid-4           [-1, 10, 30, 14]               0
    BayesianConv2d-5           [-1, 10, 31, 14]           2,000
           Sigmoid-6           [-1, 10, 31, 14]               0
    BayesianConv2d-7           [-1, 10, 30, 14]           2,000
           Sigmoid-8           [-1, 10, 30, 14]               0
    BayesianConv2d-9            [-1, 1, 30, 14]              60
         Softplus-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
   BayesianLinear-12                  [-1, 100]          84,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 90,460
Trainable params: 90,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 07:09:41.845233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3083.68
 ---- batch: 020 ----
mean loss: 1504.64
 ---- batch: 030 ----
mean loss: 1273.21
train mean loss: 1852.79
epoch train time: 0:00:17.259907
elapsed time: 0:00:17.286696
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 07:09:59.113474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1154.73
 ---- batch: 020 ----
mean loss: 1096.82
 ---- batch: 030 ----
mean loss: 1104.88
train mean loss: 1109.08
epoch train time: 0:00:07.083696
elapsed time: 0:00:24.371159
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 07:10:06.198079
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1047.10
 ---- batch: 020 ----
mean loss: 1006.93
 ---- batch: 030 ----
mean loss: 1052.69
train mean loss: 1033.76
epoch train time: 0:00:07.095675
elapsed time: 0:00:31.467609
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 07:10:13.294477
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1040.85
 ---- batch: 020 ----
mean loss: 1033.00
 ---- batch: 030 ----
mean loss: 975.74
train mean loss: 1006.81
epoch train time: 0:00:07.000469
elapsed time: 0:00:38.468889
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 07:10:20.295750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1003.72
 ---- batch: 020 ----
mean loss: 985.64
 ---- batch: 030 ----
mean loss: 961.82
train mean loss: 982.48
epoch train time: 0:00:07.095644
elapsed time: 0:00:45.565303
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 07:10:27.392170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 976.91
 ---- batch: 020 ----
mean loss: 978.34
 ---- batch: 030 ----
mean loss: 945.73
train mean loss: 968.23
epoch train time: 0:00:06.985001
elapsed time: 0:00:52.551111
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 07:10:34.377965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 959.93
 ---- batch: 020 ----
mean loss: 932.74
 ---- batch: 030 ----
mean loss: 923.75
train mean loss: 937.71
epoch train time: 0:00:07.060234
elapsed time: 0:00:59.612183
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 07:10:41.439081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 879.07
 ---- batch: 020 ----
mean loss: 840.81
 ---- batch: 030 ----
mean loss: 780.96
train mean loss: 818.04
epoch train time: 0:00:07.010592
elapsed time: 0:01:06.623680
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 07:10:48.450559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 678.86
 ---- batch: 020 ----
mean loss: 587.51
 ---- batch: 030 ----
mean loss: 531.90
train mean loss: 582.18
epoch train time: 0:00:07.027127
elapsed time: 0:01:13.651595
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 07:10:55.478464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 465.47
 ---- batch: 020 ----
mean loss: 411.12
 ---- batch: 030 ----
mean loss: 409.84
train mean loss: 423.56
epoch train time: 0:00:07.116922
elapsed time: 0:01:20.769337
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 07:11:02.596198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 402.82
 ---- batch: 020 ----
mean loss: 384.15
 ---- batch: 030 ----
mean loss: 378.63
train mean loss: 388.59
epoch train time: 0:00:06.961848
elapsed time: 0:01:27.731945
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 07:11:09.558806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.96
 ---- batch: 020 ----
mean loss: 378.33
 ---- batch: 030 ----
mean loss: 362.47
train mean loss: 370.93
epoch train time: 0:00:07.009772
elapsed time: 0:01:34.742474
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 07:11:16.569351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.76
 ---- batch: 020 ----
mean loss: 362.67
 ---- batch: 030 ----
mean loss: 352.53
train mean loss: 360.13
epoch train time: 0:00:06.825879
elapsed time: 0:01:41.569136
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 07:11:23.396074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 346.06
 ---- batch: 020 ----
mean loss: 359.49
 ---- batch: 030 ----
mean loss: 339.67
train mean loss: 348.57
epoch train time: 0:00:06.860944
elapsed time: 0:01:48.431009
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 07:11:30.257880
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 343.68
 ---- batch: 020 ----
mean loss: 339.98
 ---- batch: 030 ----
mean loss: 341.73
train mean loss: 342.50
epoch train time: 0:00:06.963414
elapsed time: 0:01:55.395208
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 07:11:37.222090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 339.44
 ---- batch: 020 ----
mean loss: 331.97
 ---- batch: 030 ----
mean loss: 335.59
train mean loss: 334.90
epoch train time: 0:00:06.878802
elapsed time: 0:02:02.274831
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 07:11:44.101728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.15
 ---- batch: 020 ----
mean loss: 338.25
 ---- batch: 030 ----
mean loss: 334.90
train mean loss: 331.44
epoch train time: 0:00:06.933173
elapsed time: 0:02:09.208847
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 07:11:51.035713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.36
 ---- batch: 020 ----
mean loss: 331.21
 ---- batch: 030 ----
mean loss: 319.10
train mean loss: 324.02
epoch train time: 0:00:06.832488
elapsed time: 0:02:16.042126
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 07:11:57.869008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.75
 ---- batch: 020 ----
mean loss: 317.33
 ---- batch: 030 ----
mean loss: 314.53
train mean loss: 316.60
epoch train time: 0:00:06.996203
elapsed time: 0:02:23.039158
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 07:12:04.866029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 318.62
 ---- batch: 020 ----
mean loss: 307.01
 ---- batch: 030 ----
mean loss: 306.99
train mean loss: 310.12
epoch train time: 0:00:06.853021
elapsed time: 0:02:29.893028
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 07:12:11.719888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 307.39
 ---- batch: 020 ----
mean loss: 311.47
 ---- batch: 030 ----
mean loss: 304.39
train mean loss: 305.51
epoch train time: 0:00:06.934889
elapsed time: 0:02:36.828705
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 07:12:18.655584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.33
 ---- batch: 020 ----
mean loss: 302.58
 ---- batch: 030 ----
mean loss: 301.71
train mean loss: 299.11
epoch train time: 0:00:06.905225
elapsed time: 0:02:43.734696
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 07:12:25.561566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.31
 ---- batch: 020 ----
mean loss: 294.50
 ---- batch: 030 ----
mean loss: 290.24
train mean loss: 292.76
epoch train time: 0:00:06.980640
elapsed time: 0:02:50.716116
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 07:12:32.542982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 285.34
 ---- batch: 020 ----
mean loss: 287.19
 ---- batch: 030 ----
mean loss: 286.88
train mean loss: 285.97
epoch train time: 0:00:07.070932
elapsed time: 0:02:57.787896
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 07:12:39.614808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 280.92
 ---- batch: 020 ----
mean loss: 277.55
 ---- batch: 030 ----
mean loss: 275.86
train mean loss: 276.87
epoch train time: 0:00:06.921882
elapsed time: 0:03:04.710592
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 07:12:46.537466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.50
 ---- batch: 020 ----
mean loss: 266.11
 ---- batch: 030 ----
mean loss: 271.93
train mean loss: 271.90
epoch train time: 0:00:06.948568
elapsed time: 0:03:11.659949
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 07:12:53.486821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.31
 ---- batch: 020 ----
mean loss: 257.76
 ---- batch: 030 ----
mean loss: 258.45
train mean loss: 259.95
epoch train time: 0:00:06.998179
elapsed time: 0:03:18.658978
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 07:13:00.485891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.25
 ---- batch: 020 ----
mean loss: 253.34
 ---- batch: 030 ----
mean loss: 245.91
train mean loss: 250.68
epoch train time: 0:00:06.895359
elapsed time: 0:03:25.555223
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 07:13:07.382111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.99
 ---- batch: 020 ----
mean loss: 235.81
 ---- batch: 030 ----
mean loss: 232.42
train mean loss: 238.55
epoch train time: 0:00:07.002171
elapsed time: 0:03:32.558277
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 07:13:14.385146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.56
 ---- batch: 020 ----
mean loss: 226.33
 ---- batch: 030 ----
mean loss: 221.31
train mean loss: 225.69
epoch train time: 0:00:06.919084
elapsed time: 0:03:39.478175
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 07:13:21.305091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.72
 ---- batch: 020 ----
mean loss: 221.29
 ---- batch: 030 ----
mean loss: 217.99
train mean loss: 217.74
epoch train time: 0:00:06.919545
elapsed time: 0:03:46.398811
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 07:13:28.225699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.04
 ---- batch: 020 ----
mean loss: 211.27
 ---- batch: 030 ----
mean loss: 209.56
train mean loss: 210.15
epoch train time: 0:00:06.987647
elapsed time: 0:03:53.387258
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 07:13:35.214146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.30
 ---- batch: 020 ----
mean loss: 196.10
 ---- batch: 030 ----
mean loss: 211.79
train mean loss: 204.86
epoch train time: 0:00:06.881235
elapsed time: 0:04:00.269340
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 07:13:42.096227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.46
 ---- batch: 020 ----
mean loss: 197.66
 ---- batch: 030 ----
mean loss: 202.10
train mean loss: 197.91
epoch train time: 0:00:06.997334
elapsed time: 0:04:07.267586
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 07:13:49.094488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.82
 ---- batch: 020 ----
mean loss: 200.84
 ---- batch: 030 ----
mean loss: 197.24
train mean loss: 197.31
epoch train time: 0:00:06.874374
elapsed time: 0:04:14.142810
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 07:13:55.969718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.64
 ---- batch: 020 ----
mean loss: 188.21
 ---- batch: 030 ----
mean loss: 189.66
train mean loss: 190.91
epoch train time: 0:00:06.981580
elapsed time: 0:04:21.125245
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 07:14:02.952124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.14
 ---- batch: 020 ----
mean loss: 187.67
 ---- batch: 030 ----
mean loss: 173.97
train mean loss: 182.77
epoch train time: 0:00:06.944462
elapsed time: 0:04:28.070511
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 07:14:09.897389
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.10
 ---- batch: 020 ----
mean loss: 181.27
 ---- batch: 030 ----
mean loss: 182.06
train mean loss: 180.80
epoch train time: 0:00:06.929017
elapsed time: 0:04:35.000389
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 07:14:16.827257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.35
 ---- batch: 020 ----
mean loss: 175.78
 ---- batch: 030 ----
mean loss: 182.91
train mean loss: 177.99
epoch train time: 0:00:06.916275
elapsed time: 0:04:41.917624
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 07:14:23.744536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.20
 ---- batch: 020 ----
mean loss: 177.67
 ---- batch: 030 ----
mean loss: 175.25
train mean loss: 176.26
epoch train time: 0:00:06.778820
elapsed time: 0:04:48.697268
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 07:14:30.524146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.74
 ---- batch: 020 ----
mean loss: 171.37
 ---- batch: 030 ----
mean loss: 170.19
train mean loss: 171.44
epoch train time: 0:00:07.014262
elapsed time: 0:04:55.712351
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 07:14:37.539229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.10
 ---- batch: 020 ----
mean loss: 169.93
 ---- batch: 030 ----
mean loss: 170.65
train mean loss: 169.59
epoch train time: 0:00:06.903840
elapsed time: 0:05:02.617104
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 07:14:44.444002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.05
 ---- batch: 020 ----
mean loss: 169.08
 ---- batch: 030 ----
mean loss: 165.63
train mean loss: 168.24
epoch train time: 0:00:06.918374
elapsed time: 0:05:09.536360
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 07:14:51.363238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.62
 ---- batch: 020 ----
mean loss: 167.52
 ---- batch: 030 ----
mean loss: 167.03
train mean loss: 166.92
epoch train time: 0:00:07.009837
elapsed time: 0:05:16.547310
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 07:14:58.374200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.42
 ---- batch: 020 ----
mean loss: 164.63
 ---- batch: 030 ----
mean loss: 166.16
train mean loss: 164.42
epoch train time: 0:00:06.847221
elapsed time: 0:05:23.395441
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 07:15:05.222304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.44
 ---- batch: 020 ----
mean loss: 160.01
 ---- batch: 030 ----
mean loss: 161.20
train mean loss: 159.86
epoch train time: 0:00:06.953141
elapsed time: 0:05:30.349391
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 07:15:12.176281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.80
 ---- batch: 020 ----
mean loss: 153.89
 ---- batch: 030 ----
mean loss: 159.31
train mean loss: 156.59
epoch train time: 0:00:06.907378
elapsed time: 0:05:37.257790
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 07:15:19.084664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.21
 ---- batch: 020 ----
mean loss: 155.27
 ---- batch: 030 ----
mean loss: 157.29
train mean loss: 156.37
epoch train time: 0:00:06.963657
elapsed time: 0:05:44.222231
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 07:15:26.049114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.47
 ---- batch: 020 ----
mean loss: 152.68
 ---- batch: 030 ----
mean loss: 153.79
train mean loss: 152.39
epoch train time: 0:00:06.972632
elapsed time: 0:05:51.195695
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 07:15:33.022567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.44
 ---- batch: 020 ----
mean loss: 153.76
 ---- batch: 030 ----
mean loss: 150.68
train mean loss: 151.05
epoch train time: 0:00:07.002942
elapsed time: 0:05:58.199447
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 07:15:40.026326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.41
 ---- batch: 020 ----
mean loss: 150.62
 ---- batch: 030 ----
mean loss: 151.58
train mean loss: 150.05
epoch train time: 0:00:06.886325
elapsed time: 0:06:05.086611
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 07:15:46.913489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.30
 ---- batch: 020 ----
mean loss: 155.56
 ---- batch: 030 ----
mean loss: 149.49
train mean loss: 150.73
epoch train time: 0:00:06.979063
elapsed time: 0:06:12.066488
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 07:15:53.893348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.98
 ---- batch: 020 ----
mean loss: 148.77
 ---- batch: 030 ----
mean loss: 151.09
train mean loss: 149.40
epoch train time: 0:00:06.894785
elapsed time: 0:06:18.962048
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 07:16:00.788922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.16
 ---- batch: 020 ----
mean loss: 148.55
 ---- batch: 030 ----
mean loss: 144.50
train mean loss: 146.29
epoch train time: 0:00:06.944548
elapsed time: 0:06:25.907411
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 07:16:07.734277
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.15
 ---- batch: 020 ----
mean loss: 139.96
 ---- batch: 030 ----
mean loss: 147.11
train mean loss: 143.28
epoch train time: 0:00:06.968857
elapsed time: 0:06:32.877031
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 07:16:14.703942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.71
 ---- batch: 020 ----
mean loss: 143.13
 ---- batch: 030 ----
mean loss: 140.98
train mean loss: 143.71
epoch train time: 0:00:06.901760
elapsed time: 0:06:39.779649
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 07:16:21.606518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.00
 ---- batch: 020 ----
mean loss: 145.72
 ---- batch: 030 ----
mean loss: 141.79
train mean loss: 143.90
epoch train time: 0:00:06.969382
elapsed time: 0:06:46.749797
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 07:16:28.576668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.94
 ---- batch: 020 ----
mean loss: 141.95
 ---- batch: 030 ----
mean loss: 142.78
train mean loss: 140.78
epoch train time: 0:00:06.893601
elapsed time: 0:06:53.644212
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 07:16:35.471076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.27
 ---- batch: 020 ----
mean loss: 139.22
 ---- batch: 030 ----
mean loss: 140.50
train mean loss: 139.96
epoch train time: 0:00:06.946957
elapsed time: 0:07:00.592043
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 07:16:42.418929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.08
 ---- batch: 020 ----
mean loss: 137.87
 ---- batch: 030 ----
mean loss: 141.00
train mean loss: 141.56
epoch train time: 0:00:06.971159
elapsed time: 0:07:07.563980
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 07:16:49.390850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.31
 ---- batch: 020 ----
mean loss: 134.16
 ---- batch: 030 ----
mean loss: 142.00
train mean loss: 138.61
epoch train time: 0:00:06.889641
elapsed time: 0:07:14.454446
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 07:16:56.281387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.77
 ---- batch: 020 ----
mean loss: 133.15
 ---- batch: 030 ----
mean loss: 135.60
train mean loss: 134.88
epoch train time: 0:00:06.946855
elapsed time: 0:07:21.402202
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 07:17:03.229080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.08
 ---- batch: 020 ----
mean loss: 135.89
 ---- batch: 030 ----
mean loss: 137.56
train mean loss: 137.49
epoch train time: 0:00:07.005778
elapsed time: 0:07:28.408864
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 07:17:10.235726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.02
 ---- batch: 020 ----
mean loss: 138.49
 ---- batch: 030 ----
mean loss: 136.07
train mean loss: 134.90
epoch train time: 0:00:06.848917
elapsed time: 0:07:35.258582
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 07:17:17.085453
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.42
 ---- batch: 020 ----
mean loss: 130.81
 ---- batch: 030 ----
mean loss: 137.91
train mean loss: 135.42
epoch train time: 0:00:06.963067
elapsed time: 0:07:42.222487
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 07:17:24.049427
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.29
 ---- batch: 020 ----
mean loss: 128.96
 ---- batch: 030 ----
mean loss: 136.68
train mean loss: 136.36
epoch train time: 0:00:06.829241
elapsed time: 0:07:49.052558
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 07:17:30.879434
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.36
 ---- batch: 020 ----
mean loss: 139.56
 ---- batch: 030 ----
mean loss: 135.64
train mean loss: 138.02
epoch train time: 0:00:06.926596
elapsed time: 0:07:55.979924
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 07:17:37.806787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.49
 ---- batch: 020 ----
mean loss: 129.07
 ---- batch: 030 ----
mean loss: 133.47
train mean loss: 130.74
epoch train time: 0:00:06.782770
elapsed time: 0:08:02.763475
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 07:17:44.590385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.17
 ---- batch: 020 ----
mean loss: 129.41
 ---- batch: 030 ----
mean loss: 126.52
train mean loss: 131.79
epoch train time: 0:00:07.044602
elapsed time: 0:08:09.809060
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 07:17:51.635962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.30
 ---- batch: 020 ----
mean loss: 128.63
 ---- batch: 030 ----
mean loss: 131.04
train mean loss: 130.06
epoch train time: 0:00:06.981971
elapsed time: 0:08:16.791828
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 07:17:58.618682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.44
 ---- batch: 020 ----
mean loss: 133.78
 ---- batch: 030 ----
mean loss: 127.70
train mean loss: 130.32
epoch train time: 0:00:06.898016
elapsed time: 0:08:23.690595
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 07:18:05.517466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.69
 ---- batch: 020 ----
mean loss: 126.58
 ---- batch: 030 ----
mean loss: 128.02
train mean loss: 129.04
epoch train time: 0:00:06.960720
elapsed time: 0:08:30.652067
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 07:18:12.478944
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.76
 ---- batch: 020 ----
mean loss: 129.43
 ---- batch: 030 ----
mean loss: 126.24
train mean loss: 127.70
epoch train time: 0:00:06.886548
elapsed time: 0:08:37.539486
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 07:18:19.366368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.98
 ---- batch: 020 ----
mean loss: 130.01
 ---- batch: 030 ----
mean loss: 130.59
train mean loss: 128.90
epoch train time: 0:00:06.958865
elapsed time: 0:08:44.499206
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 07:18:26.326071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.71
 ---- batch: 020 ----
mean loss: 128.87
 ---- batch: 030 ----
mean loss: 131.38
train mean loss: 128.72
epoch train time: 0:00:06.913650
elapsed time: 0:08:51.413682
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 07:18:33.240551
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.25
 ---- batch: 020 ----
mean loss: 128.57
 ---- batch: 030 ----
mean loss: 129.25
train mean loss: 127.67
epoch train time: 0:00:06.894252
elapsed time: 0:08:58.308832
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 07:18:40.135721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.50
 ---- batch: 020 ----
mean loss: 125.90
 ---- batch: 030 ----
mean loss: 123.30
train mean loss: 127.11
epoch train time: 0:00:06.837444
elapsed time: 0:09:05.147175
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 07:18:46.974046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.74
 ---- batch: 020 ----
mean loss: 120.80
 ---- batch: 030 ----
mean loss: 127.85
train mean loss: 125.26
epoch train time: 0:00:06.917697
elapsed time: 0:09:12.065654
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 07:18:53.892535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.24
 ---- batch: 020 ----
mean loss: 123.79
 ---- batch: 030 ----
mean loss: 127.98
train mean loss: 125.60
epoch train time: 0:00:06.940841
elapsed time: 0:09:19.007342
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 07:19:00.834215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.54
 ---- batch: 020 ----
mean loss: 126.36
 ---- batch: 030 ----
mean loss: 124.35
train mean loss: 124.38
epoch train time: 0:00:06.744324
elapsed time: 0:09:25.752476
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 07:19:07.579341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.02
 ---- batch: 020 ----
mean loss: 120.10
 ---- batch: 030 ----
mean loss: 122.74
train mean loss: 123.38
epoch train time: 0:00:06.896296
elapsed time: 0:09:32.649556
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 07:19:14.476418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.29
 ---- batch: 020 ----
mean loss: 126.41
 ---- batch: 030 ----
mean loss: 125.15
train mean loss: 124.20
epoch train time: 0:00:06.854259
elapsed time: 0:09:39.504589
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 07:19:21.331468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.32
 ---- batch: 020 ----
mean loss: 123.97
 ---- batch: 030 ----
mean loss: 123.33
train mean loss: 123.45
epoch train time: 0:00:06.760898
elapsed time: 0:09:46.266262
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 07:19:28.093132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.16
 ---- batch: 020 ----
mean loss: 118.90
 ---- batch: 030 ----
mean loss: 122.91
train mean loss: 121.51
epoch train time: 0:00:06.859715
elapsed time: 0:09:53.126779
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 07:19:34.953673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.72
 ---- batch: 020 ----
mean loss: 123.28
 ---- batch: 030 ----
mean loss: 121.66
train mean loss: 120.83
epoch train time: 0:00:06.738685
elapsed time: 0:09:59.866256
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 07:19:41.693118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.27
 ---- batch: 020 ----
mean loss: 119.58
 ---- batch: 030 ----
mean loss: 123.33
train mean loss: 122.48
epoch train time: 0:00:06.885649
elapsed time: 0:10:06.752660
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 07:19:48.579560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.73
 ---- batch: 020 ----
mean loss: 122.24
 ---- batch: 030 ----
mean loss: 124.20
train mean loss: 121.01
epoch train time: 0:00:06.797183
elapsed time: 0:10:13.550674
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 07:19:55.377532
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.91
 ---- batch: 020 ----
mean loss: 119.60
 ---- batch: 030 ----
mean loss: 113.62
train mean loss: 119.06
epoch train time: 0:00:06.871723
elapsed time: 0:10:20.423213
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 07:20:02.250124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.63
 ---- batch: 020 ----
mean loss: 119.38
 ---- batch: 030 ----
mean loss: 116.25
train mean loss: 120.12
epoch train time: 0:00:06.888892
elapsed time: 0:10:27.312980
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 07:20:09.139894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.00
 ---- batch: 020 ----
mean loss: 119.71
 ---- batch: 030 ----
mean loss: 122.15
train mean loss: 119.98
epoch train time: 0:00:06.948157
elapsed time: 0:10:34.262026
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 07:20:16.088928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.23
 ---- batch: 020 ----
mean loss: 117.50
 ---- batch: 030 ----
mean loss: 120.72
train mean loss: 119.87
epoch train time: 0:00:06.818779
elapsed time: 0:10:41.081607
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 07:20:22.908474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.30
 ---- batch: 020 ----
mean loss: 117.08
 ---- batch: 030 ----
mean loss: 119.46
train mean loss: 118.01
epoch train time: 0:00:06.913685
elapsed time: 0:10:47.996125
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 07:20:29.823048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.03
 ---- batch: 020 ----
mean loss: 116.42
 ---- batch: 030 ----
mean loss: 118.95
train mean loss: 118.26
epoch train time: 0:00:06.836636
elapsed time: 0:10:54.833646
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 07:20:36.660507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.82
 ---- batch: 020 ----
mean loss: 119.24
 ---- batch: 030 ----
mean loss: 117.14
train mean loss: 119.77
epoch train time: 0:00:06.683039
elapsed time: 0:11:01.517416
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 07:20:43.344287
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.43
 ---- batch: 020 ----
mean loss: 119.76
 ---- batch: 030 ----
mean loss: 116.58
train mean loss: 116.70
epoch train time: 0:00:06.944901
elapsed time: 0:11:08.463153
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 07:20:50.290041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.85
 ---- batch: 020 ----
mean loss: 117.83
 ---- batch: 030 ----
mean loss: 122.05
train mean loss: 117.60
epoch train time: 0:00:06.822314
elapsed time: 0:11:15.286464
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 07:20:57.113393
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.49
 ---- batch: 020 ----
mean loss: 115.45
 ---- batch: 030 ----
mean loss: 119.55
train mean loss: 116.00
epoch train time: 0:00:06.868076
elapsed time: 0:11:22.155491
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 07:21:03.982374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.56
 ---- batch: 020 ----
mean loss: 114.88
 ---- batch: 030 ----
mean loss: 118.84
train mean loss: 116.41
epoch train time: 0:00:06.843987
elapsed time: 0:11:29.000325
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 07:21:10.827307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.09
 ---- batch: 020 ----
mean loss: 118.48
 ---- batch: 030 ----
mean loss: 114.96
train mean loss: 116.78
epoch train time: 0:00:06.765365
elapsed time: 0:11:35.766578
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 07:21:17.593426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.81
 ---- batch: 020 ----
mean loss: 113.67
 ---- batch: 030 ----
mean loss: 111.30
train mean loss: 115.65
epoch train time: 0:00:06.880865
elapsed time: 0:11:42.648210
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 07:21:24.475082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.78
 ---- batch: 020 ----
mean loss: 114.57
 ---- batch: 030 ----
mean loss: 114.49
train mean loss: 113.83
epoch train time: 0:00:06.774987
elapsed time: 0:11:49.424023
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 07:21:31.250928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.19
 ---- batch: 020 ----
mean loss: 113.53
 ---- batch: 030 ----
mean loss: 118.68
train mean loss: 115.53
epoch train time: 0:00:06.998103
elapsed time: 0:11:56.423013
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 07:21:38.250004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.72
 ---- batch: 020 ----
mean loss: 115.48
 ---- batch: 030 ----
mean loss: 114.48
train mean loss: 114.50
epoch train time: 0:00:07.008452
elapsed time: 0:12:03.432350
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 07:21:45.259221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.97
 ---- batch: 020 ----
mean loss: 116.71
 ---- batch: 030 ----
mean loss: 113.61
train mean loss: 113.79
epoch train time: 0:00:06.860935
elapsed time: 0:12:10.294052
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 07:21:52.120917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.44
 ---- batch: 020 ----
mean loss: 114.23
 ---- batch: 030 ----
mean loss: 113.80
train mean loss: 114.08
epoch train time: 0:00:06.905169
elapsed time: 0:12:17.199980
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 07:21:59.026868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.47
 ---- batch: 020 ----
mean loss: 114.54
 ---- batch: 030 ----
mean loss: 111.37
train mean loss: 112.91
epoch train time: 0:00:06.849128
elapsed time: 0:12:24.049924
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 07:22:05.876788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.05
 ---- batch: 020 ----
mean loss: 112.85
 ---- batch: 030 ----
mean loss: 111.77
train mean loss: 113.18
epoch train time: 0:00:06.878854
elapsed time: 0:12:30.929623
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 07:22:12.756392
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.00
 ---- batch: 020 ----
mean loss: 112.28
 ---- batch: 030 ----
mean loss: 112.68
train mean loss: 111.21
epoch train time: 0:00:06.893654
elapsed time: 0:12:37.824030
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 07:22:19.650899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.83
 ---- batch: 020 ----
mean loss: 112.82
 ---- batch: 030 ----
mean loss: 109.04
train mean loss: 111.72
epoch train time: 0:00:06.930014
elapsed time: 0:12:44.754804
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 07:22:26.581731
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.16
 ---- batch: 020 ----
mean loss: 110.34
 ---- batch: 030 ----
mean loss: 112.28
train mean loss: 110.81
epoch train time: 0:00:06.790188
elapsed time: 0:12:51.545888
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 07:22:33.372774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.65
 ---- batch: 020 ----
mean loss: 107.85
 ---- batch: 030 ----
mean loss: 114.07
train mean loss: 110.69
epoch train time: 0:00:06.936984
elapsed time: 0:12:58.483653
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 07:22:40.310526
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.01
 ---- batch: 020 ----
mean loss: 109.15
 ---- batch: 030 ----
mean loss: 107.42
train mean loss: 109.52
epoch train time: 0:00:06.933985
elapsed time: 0:13:05.418436
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 07:22:47.245305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.12
 ---- batch: 020 ----
mean loss: 109.11
 ---- batch: 030 ----
mean loss: 109.00
train mean loss: 110.17
epoch train time: 0:00:06.766449
elapsed time: 0:13:12.185693
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 07:22:54.012557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.95
 ---- batch: 020 ----
mean loss: 111.80
 ---- batch: 030 ----
mean loss: 108.99
train mean loss: 110.92
epoch train time: 0:00:06.929810
elapsed time: 0:13:19.116299
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 07:23:00.943170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.14
 ---- batch: 020 ----
mean loss: 112.53
 ---- batch: 030 ----
mean loss: 108.50
train mean loss: 110.56
epoch train time: 0:00:06.823736
elapsed time: 0:13:25.940908
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 07:23:07.767791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.80
 ---- batch: 020 ----
mean loss: 105.52
 ---- batch: 030 ----
mean loss: 111.25
train mean loss: 107.95
epoch train time: 0:00:06.842244
elapsed time: 0:13:32.783998
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 07:23:14.610867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.21
 ---- batch: 020 ----
mean loss: 105.98
 ---- batch: 030 ----
mean loss: 111.05
train mean loss: 108.13
epoch train time: 0:00:06.878877
elapsed time: 0:13:39.663680
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 07:23:21.490549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.79
 ---- batch: 020 ----
mean loss: 110.44
 ---- batch: 030 ----
mean loss: 113.20
train mean loss: 110.68
epoch train time: 0:00:06.821649
elapsed time: 0:13:46.486243
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 07:23:28.313097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.05
 ---- batch: 020 ----
mean loss: 110.37
 ---- batch: 030 ----
mean loss: 111.55
train mean loss: 110.36
epoch train time: 0:00:06.894471
elapsed time: 0:13:53.381497
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 07:23:35.208361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.36
 ---- batch: 020 ----
mean loss: 108.85
 ---- batch: 030 ----
mean loss: 109.10
train mean loss: 108.79
epoch train time: 0:00:06.800366
elapsed time: 0:14:00.182712
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 07:23:42.009584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.78
 ---- batch: 020 ----
mean loss: 109.71
 ---- batch: 030 ----
mean loss: 104.99
train mean loss: 109.30
epoch train time: 0:00:06.684361
elapsed time: 0:14:06.867873
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 07:23:48.694739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.17
 ---- batch: 020 ----
mean loss: 107.86
 ---- batch: 030 ----
mean loss: 109.08
train mean loss: 107.19
epoch train time: 0:00:07.001829
elapsed time: 0:14:13.870485
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 07:23:55.697352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.04
 ---- batch: 020 ----
mean loss: 109.34
 ---- batch: 030 ----
mean loss: 109.45
train mean loss: 107.87
epoch train time: 0:00:06.836906
elapsed time: 0:14:20.708606
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 07:24:02.535607
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.53
 ---- batch: 020 ----
mean loss: 106.32
 ---- batch: 030 ----
mean loss: 106.61
train mean loss: 106.85
epoch train time: 0:00:06.854033
elapsed time: 0:14:27.563628
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 07:24:09.390556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.49
 ---- batch: 020 ----
mean loss: 103.52
 ---- batch: 030 ----
mean loss: 108.10
train mean loss: 106.33
epoch train time: 0:00:06.892228
elapsed time: 0:14:34.456658
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 07:24:16.283520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.04
 ---- batch: 020 ----
mean loss: 109.93
 ---- batch: 030 ----
mean loss: 100.99
train mean loss: 107.24
epoch train time: 0:00:06.795050
elapsed time: 0:14:41.252508
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 07:24:23.079390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.39
 ---- batch: 020 ----
mean loss: 106.66
 ---- batch: 030 ----
mean loss: 107.11
train mean loss: 106.61
epoch train time: 0:00:06.897980
elapsed time: 0:14:48.151501
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 07:24:29.978289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.09
 ---- batch: 020 ----
mean loss: 105.13
 ---- batch: 030 ----
mean loss: 111.66
train mean loss: 106.72
epoch train time: 0:00:06.911423
elapsed time: 0:14:55.063635
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 07:24:36.890524
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.52
 ---- batch: 020 ----
mean loss: 106.46
 ---- batch: 030 ----
mean loss: 102.69
train mean loss: 105.28
epoch train time: 0:00:06.756839
elapsed time: 0:15:01.821267
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 07:24:43.648206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.59
 ---- batch: 020 ----
mean loss: 105.58
 ---- batch: 030 ----
mean loss: 106.40
train mean loss: 106.80
epoch train time: 0:00:06.882034
elapsed time: 0:15:08.704203
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 07:24:50.531064
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.66
 ---- batch: 020 ----
mean loss: 104.20
 ---- batch: 030 ----
mean loss: 104.34
train mean loss: 104.53
epoch train time: 0:00:06.883215
elapsed time: 0:15:15.588216
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 07:24:57.415080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.77
 ---- batch: 020 ----
mean loss: 104.71
 ---- batch: 030 ----
mean loss: 104.90
train mean loss: 104.74
epoch train time: 0:00:06.827489
elapsed time: 0:15:22.416486
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 07:25:04.243355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.02
 ---- batch: 020 ----
mean loss: 109.28
 ---- batch: 030 ----
mean loss: 101.13
train mean loss: 106.81
epoch train time: 0:00:06.884872
elapsed time: 0:15:29.302192
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 07:25:11.129066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.98
 ---- batch: 020 ----
mean loss: 106.10
 ---- batch: 030 ----
mean loss: 105.26
train mean loss: 105.49
epoch train time: 0:00:06.899106
elapsed time: 0:15:36.202097
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 07:25:18.028993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.16
 ---- batch: 020 ----
mean loss: 101.49
 ---- batch: 030 ----
mean loss: 103.62
train mean loss: 103.67
epoch train time: 0:00:06.815323
elapsed time: 0:15:43.018305
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 07:25:24.845200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.33
 ---- batch: 020 ----
mean loss: 99.20
 ---- batch: 030 ----
mean loss: 105.67
train mean loss: 103.33
epoch train time: 0:00:06.906676
elapsed time: 0:15:49.925769
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 07:25:31.752663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.94
 ---- batch: 020 ----
mean loss: 102.88
 ---- batch: 030 ----
mean loss: 103.26
train mean loss: 103.95
epoch train time: 0:00:06.776344
elapsed time: 0:15:56.703069
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 07:25:38.530032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.62
 ---- batch: 020 ----
mean loss: 104.10
 ---- batch: 030 ----
mean loss: 101.01
train mean loss: 102.66
epoch train time: 0:00:06.886379
elapsed time: 0:16:03.590351
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 07:25:45.417209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.57
 ---- batch: 020 ----
mean loss: 104.01
 ---- batch: 030 ----
mean loss: 101.73
train mean loss: 102.36
epoch train time: 0:00:06.797929
elapsed time: 0:16:10.389052
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 07:25:52.215920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.34
 ---- batch: 020 ----
mean loss: 104.25
 ---- batch: 030 ----
mean loss: 105.10
train mean loss: 103.78
epoch train time: 0:00:06.910273
elapsed time: 0:16:17.300155
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 07:25:59.127107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.15
 ---- batch: 020 ----
mean loss: 102.76
 ---- batch: 030 ----
mean loss: 105.28
train mean loss: 104.09
epoch train time: 0:00:06.798405
elapsed time: 0:16:24.099523
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 07:26:05.926405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.41
 ---- batch: 020 ----
mean loss: 104.76
 ---- batch: 030 ----
mean loss: 106.46
train mean loss: 106.93
epoch train time: 0:00:06.799828
elapsed time: 0:16:30.900205
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 07:26:12.727159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.23
 ---- batch: 020 ----
mean loss: 104.14
 ---- batch: 030 ----
mean loss: 105.53
train mean loss: 104.49
epoch train time: 0:00:06.841617
elapsed time: 0:16:37.742981
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 07:26:19.569881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.05
 ---- batch: 020 ----
mean loss: 102.48
 ---- batch: 030 ----
mean loss: 101.79
train mean loss: 101.16
epoch train time: 0:00:06.902319
elapsed time: 0:16:44.646075
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 07:26:26.472955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.83
 ---- batch: 020 ----
mean loss: 98.72
 ---- batch: 030 ----
mean loss: 101.53
train mean loss: 100.06
epoch train time: 0:00:06.768344
elapsed time: 0:16:51.415259
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 07:26:33.242142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.73
 ---- batch: 020 ----
mean loss: 103.05
 ---- batch: 030 ----
mean loss: 95.70
train mean loss: 100.76
epoch train time: 0:00:06.881103
elapsed time: 0:16:58.297199
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 07:26:40.124084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.12
 ---- batch: 020 ----
mean loss: 102.44
 ---- batch: 030 ----
mean loss: 100.20
train mean loss: 101.56
epoch train time: 0:00:06.896490
elapsed time: 0:17:05.194713
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 07:26:47.021596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.09
 ---- batch: 020 ----
mean loss: 101.14
 ---- batch: 030 ----
mean loss: 101.81
train mean loss: 101.17
epoch train time: 0:00:06.803594
elapsed time: 0:17:11.999282
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 07:26:53.826203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.12
 ---- batch: 020 ----
mean loss: 101.33
 ---- batch: 030 ----
mean loss: 99.74
train mean loss: 100.91
epoch train time: 0:00:06.843955
elapsed time: 0:17:18.844165
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 07:27:00.670938
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.46
 ---- batch: 020 ----
mean loss: 100.38
 ---- batch: 030 ----
mean loss: 100.38
train mean loss: 101.69
epoch train time: 0:00:06.694184
elapsed time: 0:17:25.539133
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 07:27:07.366033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.76
 ---- batch: 020 ----
mean loss: 105.91
 ---- batch: 030 ----
mean loss: 102.29
train mean loss: 102.49
epoch train time: 0:00:06.899255
elapsed time: 0:17:32.439252
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 07:27:14.266138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.32
 ---- batch: 020 ----
mean loss: 101.04
 ---- batch: 030 ----
mean loss: 106.20
train mean loss: 102.53
epoch train time: 0:00:06.891250
elapsed time: 0:17:39.331284
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 07:27:21.158150
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.69
 ---- batch: 020 ----
mean loss: 104.22
 ---- batch: 030 ----
mean loss: 96.15
train mean loss: 100.11
epoch train time: 0:00:06.809228
elapsed time: 0:17:46.141283
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 07:27:27.968147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.96
 ---- batch: 020 ----
mean loss: 98.07
 ---- batch: 030 ----
mean loss: 101.96
train mean loss: 99.88
epoch train time: 0:00:06.870362
elapsed time: 0:17:53.012430
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 07:27:34.839306
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.43
 ---- batch: 020 ----
mean loss: 99.60
 ---- batch: 030 ----
mean loss: 98.64
train mean loss: 99.45
epoch train time: 0:00:06.851227
elapsed time: 0:17:59.864448
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 07:27:41.691339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.59
 ---- batch: 020 ----
mean loss: 100.98
 ---- batch: 030 ----
mean loss: 102.39
train mean loss: 100.27
epoch train time: 0:00:06.846134
elapsed time: 0:18:06.711449
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 07:27:48.538305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.60
 ---- batch: 020 ----
mean loss: 97.63
 ---- batch: 030 ----
mean loss: 98.76
train mean loss: 98.99
epoch train time: 0:00:06.899230
elapsed time: 0:18:13.611457
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 07:27:55.438324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.30
 ---- batch: 020 ----
mean loss: 98.79
 ---- batch: 030 ----
mean loss: 101.79
train mean loss: 99.68
epoch train time: 0:00:06.800253
elapsed time: 0:18:20.412498
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 07:28:02.239363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.34
 ---- batch: 020 ----
mean loss: 100.63
 ---- batch: 030 ----
mean loss: 99.30
train mean loss: 98.84
epoch train time: 0:00:06.943316
elapsed time: 0:18:27.356640
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 07:28:09.183501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.90
 ---- batch: 020 ----
mean loss: 96.23
 ---- batch: 030 ----
mean loss: 97.32
train mean loss: 98.30
epoch train time: 0:00:06.864391
elapsed time: 0:18:34.221779
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 07:28:16.048649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.24
 ---- batch: 020 ----
mean loss: 98.94
 ---- batch: 030 ----
mean loss: 98.86
train mean loss: 99.33
epoch train time: 0:00:06.857464
elapsed time: 0:18:41.080028
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 07:28:22.906930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.90
 ---- batch: 020 ----
mean loss: 101.06
 ---- batch: 030 ----
mean loss: 99.62
train mean loss: 101.00
epoch train time: 0:00:06.860221
elapsed time: 0:18:47.941041
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 07:28:29.767902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.03
 ---- batch: 020 ----
mean loss: 100.91
 ---- batch: 030 ----
mean loss: 99.40
train mean loss: 98.63
epoch train time: 0:00:06.805112
elapsed time: 0:18:54.746971
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 07:28:36.573842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.71
 ---- batch: 020 ----
mean loss: 97.79
 ---- batch: 030 ----
mean loss: 95.79
train mean loss: 97.55
epoch train time: 0:00:06.922289
elapsed time: 0:19:01.670028
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 07:28:43.496916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.91
 ---- batch: 020 ----
mean loss: 94.88
 ---- batch: 030 ----
mean loss: 97.61
train mean loss: 97.16
epoch train time: 0:00:06.767845
elapsed time: 0:19:08.438681
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 07:28:50.265545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.32
 ---- batch: 020 ----
mean loss: 96.71
 ---- batch: 030 ----
mean loss: 101.37
train mean loss: 97.79
epoch train time: 0:00:06.906629
elapsed time: 0:19:15.346205
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 07:28:57.173104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.25
 ---- batch: 020 ----
mean loss: 97.90
 ---- batch: 030 ----
mean loss: 97.71
train mean loss: 98.44
epoch train time: 0:00:06.867900
elapsed time: 0:19:22.214916
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 07:29:04.041773
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.97
 ---- batch: 020 ----
mean loss: 96.29
 ---- batch: 030 ----
mean loss: 98.72
train mean loss: 98.07
epoch train time: 0:00:06.821557
elapsed time: 0:19:29.037232
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 07:29:10.864102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.86
 ---- batch: 020 ----
mean loss: 93.53
 ---- batch: 030 ----
mean loss: 94.58
train mean loss: 96.50
epoch train time: 0:00:06.914089
elapsed time: 0:19:35.952116
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 07:29:17.778985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.64
 ---- batch: 020 ----
mean loss: 96.28
 ---- batch: 030 ----
mean loss: 97.91
train mean loss: 97.55
epoch train time: 0:00:06.799904
elapsed time: 0:19:42.752834
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 07:29:24.579696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.71
 ---- batch: 020 ----
mean loss: 97.72
 ---- batch: 030 ----
mean loss: 95.08
train mean loss: 97.25
epoch train time: 0:00:06.879070
elapsed time: 0:19:49.632744
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 07:29:31.459642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.04
 ---- batch: 020 ----
mean loss: 95.16
 ---- batch: 030 ----
mean loss: 95.83
train mean loss: 97.06
epoch train time: 0:00:06.850501
elapsed time: 0:19:56.484035
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 07:29:38.310898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.35
 ---- batch: 020 ----
mean loss: 93.41
 ---- batch: 030 ----
mean loss: 96.10
train mean loss: 94.98
epoch train time: 0:00:06.838473
elapsed time: 0:20:03.323353
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 07:29:45.150270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.47
 ---- batch: 020 ----
mean loss: 99.13
 ---- batch: 030 ----
mean loss: 97.76
train mean loss: 97.79
epoch train time: 0:00:06.890273
elapsed time: 0:20:10.214589
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 07:29:52.041361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.57
 ---- batch: 020 ----
mean loss: 96.86
 ---- batch: 030 ----
mean loss: 97.08
train mean loss: 96.64
epoch train time: 0:00:06.913834
elapsed time: 0:20:17.129093
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 07:29:58.955975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.13
 ---- batch: 020 ----
mean loss: 93.65
 ---- batch: 030 ----
mean loss: 95.52
train mean loss: 95.83
epoch train time: 0:00:06.800590
elapsed time: 0:20:23.930518
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 07:30:05.757386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.67
 ---- batch: 020 ----
mean loss: 94.82
 ---- batch: 030 ----
mean loss: 96.26
train mean loss: 94.61
epoch train time: 0:00:06.879972
elapsed time: 0:20:30.811278
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 07:30:12.638159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.79
 ---- batch: 020 ----
mean loss: 94.75
 ---- batch: 030 ----
mean loss: 97.48
train mean loss: 96.31
epoch train time: 0:00:06.729862
elapsed time: 0:20:37.541896
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 07:30:19.368750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.83
 ---- batch: 020 ----
mean loss: 95.92
 ---- batch: 030 ----
mean loss: 92.46
train mean loss: 94.26
epoch train time: 0:00:06.794662
elapsed time: 0:20:44.337425
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 07:30:26.164311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.33
 ---- batch: 020 ----
mean loss: 92.07
 ---- batch: 030 ----
mean loss: 96.22
train mean loss: 95.10
epoch train time: 0:00:07.104538
elapsed time: 0:20:51.442809
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 07:30:33.269711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.80
 ---- batch: 020 ----
mean loss: 97.53
 ---- batch: 030 ----
mean loss: 95.21
train mean loss: 95.12
epoch train time: 0:00:06.879665
elapsed time: 0:20:58.323532
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 07:30:40.150416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.77
 ---- batch: 020 ----
mean loss: 97.27
 ---- batch: 030 ----
mean loss: 95.86
train mean loss: 94.49
epoch train time: 0:00:07.012410
elapsed time: 0:21:05.336861
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 07:30:47.163729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.60
 ---- batch: 020 ----
mean loss: 92.96
 ---- batch: 030 ----
mean loss: 93.96
train mean loss: 93.63
epoch train time: 0:00:06.918135
elapsed time: 0:21:12.255754
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 07:30:54.082696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.44
 ---- batch: 020 ----
mean loss: 94.35
 ---- batch: 030 ----
mean loss: 96.28
train mean loss: 95.17
epoch train time: 0:00:06.931340
elapsed time: 0:21:19.187944
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 07:31:01.014815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.65
 ---- batch: 020 ----
mean loss: 93.47
 ---- batch: 030 ----
mean loss: 93.52
train mean loss: 93.82
epoch train time: 0:00:06.930997
elapsed time: 0:21:26.119749
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 07:31:07.946625
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.65
 ---- batch: 020 ----
mean loss: 96.12
 ---- batch: 030 ----
mean loss: 89.37
train mean loss: 94.12
epoch train time: 0:00:06.875053
elapsed time: 0:21:32.995603
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 07:31:14.822552
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.27
 ---- batch: 020 ----
mean loss: 95.59
 ---- batch: 030 ----
mean loss: 92.60
train mean loss: 94.70
epoch train time: 0:00:06.843977
elapsed time: 0:21:39.840464
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 07:31:21.667346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.97
 ---- batch: 020 ----
mean loss: 95.77
 ---- batch: 030 ----
mean loss: 95.81
train mean loss: 93.36
epoch train time: 0:00:06.945485
elapsed time: 0:21:46.786770
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 07:31:28.613717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.89
 ---- batch: 020 ----
mean loss: 91.53
 ---- batch: 030 ----
mean loss: 98.42
train mean loss: 94.31
epoch train time: 0:00:06.811579
elapsed time: 0:21:53.599239
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 07:31:35.426115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.75
 ---- batch: 020 ----
mean loss: 92.39
 ---- batch: 030 ----
mean loss: 96.27
train mean loss: 93.15
epoch train time: 0:00:06.928569
elapsed time: 0:22:00.528744
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 07:31:42.355642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.47
 ---- batch: 020 ----
mean loss: 92.35
 ---- batch: 030 ----
mean loss: 93.04
train mean loss: 93.43
epoch train time: 0:00:06.812130
elapsed time: 0:22:07.341706
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 07:31:49.168631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.08
 ---- batch: 020 ----
mean loss: 91.73
 ---- batch: 030 ----
mean loss: 92.82
train mean loss: 93.40
epoch train time: 0:00:06.897802
elapsed time: 0:22:14.240337
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 07:31:56.067228
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.17
 ---- batch: 020 ----
mean loss: 91.05
 ---- batch: 030 ----
mean loss: 95.23
train mean loss: 93.47
epoch train time: 0:00:06.879087
elapsed time: 0:22:21.120205
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 07:32:02.947081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.28
 ---- batch: 020 ----
mean loss: 94.95
 ---- batch: 030 ----
mean loss: 91.38
train mean loss: 92.98
epoch train time: 0:00:06.889834
elapsed time: 0:22:28.010874
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 07:32:09.837783
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.16
 ---- batch: 020 ----
mean loss: 94.87
 ---- batch: 030 ----
mean loss: 92.49
train mean loss: 93.15
epoch train time: 0:00:06.939426
elapsed time: 0:22:34.951153
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 07:32:16.778028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.32
 ---- batch: 020 ----
mean loss: 96.04
 ---- batch: 030 ----
mean loss: 91.01
train mean loss: 94.04
epoch train time: 0:00:06.830293
elapsed time: 0:22:41.782236
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 07:32:23.609112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.34
 ---- batch: 020 ----
mean loss: 95.38
 ---- batch: 030 ----
mean loss: 89.10
train mean loss: 92.89
epoch train time: 0:00:06.906578
elapsed time: 0:22:48.689648
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 07:32:30.516533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.48
 ---- batch: 020 ----
mean loss: 94.63
 ---- batch: 030 ----
mean loss: 91.52
train mean loss: 92.48
epoch train time: 0:00:06.892747
elapsed time: 0:22:55.583207
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 07:32:37.410084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.63
 ---- batch: 020 ----
mean loss: 91.38
 ---- batch: 030 ----
mean loss: 94.24
train mean loss: 91.85
epoch train time: 0:00:06.877570
elapsed time: 0:23:02.461634
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 07:32:44.288489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.64
 ---- batch: 020 ----
mean loss: 92.51
 ---- batch: 030 ----
mean loss: 93.95
train mean loss: 93.05
epoch train time: 0:00:06.841605
elapsed time: 0:23:09.304030
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 07:32:51.130899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.27
 ---- batch: 020 ----
mean loss: 91.12
 ---- batch: 030 ----
mean loss: 94.18
train mean loss: 91.74
epoch train time: 0:00:06.883942
elapsed time: 0:23:16.188792
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 07:32:58.015671
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.18
 ---- batch: 020 ----
mean loss: 90.66
 ---- batch: 030 ----
mean loss: 93.57
train mean loss: 91.57
epoch train time: 0:00:06.892486
elapsed time: 0:23:23.082193
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 07:33:04.908968
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.22
 ---- batch: 020 ----
mean loss: 88.96
 ---- batch: 030 ----
mean loss: 92.26
train mean loss: 90.83
epoch train time: 0:00:06.803849
elapsed time: 0:23:29.886778
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 07:33:11.713680
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.47
 ---- batch: 020 ----
mean loss: 90.04
 ---- batch: 030 ----
mean loss: 91.74
train mean loss: 90.99
epoch train time: 0:00:06.871441
elapsed time: 0:23:36.759210
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 07:33:18.586083
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.03
 ---- batch: 020 ----
mean loss: 87.14
 ---- batch: 030 ----
mean loss: 91.44
train mean loss: 90.87
epoch train time: 0:00:06.798507
elapsed time: 0:23:43.558496
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 07:33:25.385405
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.80
 ---- batch: 020 ----
mean loss: 90.22
 ---- batch: 030 ----
mean loss: 90.29
train mean loss: 90.94
epoch train time: 0:00:06.732159
elapsed time: 0:23:50.291465
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 07:33:32.118337
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.24
 ---- batch: 020 ----
mean loss: 91.73
 ---- batch: 030 ----
mean loss: 88.11
train mean loss: 91.05
epoch train time: 0:00:06.818556
elapsed time: 0:23:57.110808
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 07:33:38.937704
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.46
 ---- batch: 020 ----
mean loss: 89.58
 ---- batch: 030 ----
mean loss: 90.33
train mean loss: 90.55
epoch train time: 0:00:06.939673
elapsed time: 0:24:04.051302
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 07:33:45.878164
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.05
 ---- batch: 020 ----
mean loss: 86.59
 ---- batch: 030 ----
mean loss: 90.90
train mean loss: 90.91
epoch train time: 0:00:06.800216
elapsed time: 0:24:10.852298
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 07:33:52.679177
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.10
 ---- batch: 020 ----
mean loss: 92.19
 ---- batch: 030 ----
mean loss: 89.00
train mean loss: 91.18
epoch train time: 0:00:06.896673
elapsed time: 0:24:17.749856
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 07:33:59.576695
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.38
 ---- batch: 020 ----
mean loss: 89.69
 ---- batch: 030 ----
mean loss: 92.58
train mean loss: 91.37
epoch train time: 0:00:06.871824
elapsed time: 0:24:24.622416
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 07:34:06.449285
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.59
 ---- batch: 020 ----
mean loss: 91.11
 ---- batch: 030 ----
mean loss: 90.06
train mean loss: 91.57
epoch train time: 0:00:06.760505
elapsed time: 0:24:31.383668
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 07:34:13.210570
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.37
 ---- batch: 020 ----
mean loss: 93.23
 ---- batch: 030 ----
mean loss: 90.10
train mean loss: 90.34
epoch train time: 0:00:06.864589
elapsed time: 0:24:38.249225
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 07:34:20.076093
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.06
 ---- batch: 020 ----
mean loss: 88.41
 ---- batch: 030 ----
mean loss: 91.29
train mean loss: 90.43
epoch train time: 0:00:06.873474
elapsed time: 0:24:45.123508
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 07:34:26.950378
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.30
 ---- batch: 020 ----
mean loss: 93.61
 ---- batch: 030 ----
mean loss: 87.54
train mean loss: 91.75
epoch train time: 0:00:06.787013
elapsed time: 0:24:51.911347
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 07:34:33.738216
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.76
 ---- batch: 020 ----
mean loss: 87.43
 ---- batch: 030 ----
mean loss: 96.05
train mean loss: 90.97
epoch train time: 0:00:06.868768
elapsed time: 0:24:58.780934
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 07:34:40.607820
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.83
 ---- batch: 020 ----
mean loss: 92.35
 ---- batch: 030 ----
mean loss: 88.68
train mean loss: 90.91
epoch train time: 0:00:06.847692
elapsed time: 0:25:05.629617
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 07:34:47.456493
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.82
 ---- batch: 020 ----
mean loss: 91.12
 ---- batch: 030 ----
mean loss: 92.24
train mean loss: 90.39
epoch train time: 0:00:06.787518
elapsed time: 0:25:12.417993
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 07:34:54.244992
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.17
 ---- batch: 020 ----
mean loss: 89.67
 ---- batch: 030 ----
mean loss: 91.20
train mean loss: 91.00
epoch train time: 0:00:06.890105
elapsed time: 0:25:19.308950
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 07:35:01.135799
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.95
 ---- batch: 020 ----
mean loss: 92.35
 ---- batch: 030 ----
mean loss: 90.33
train mean loss: 90.40
epoch train time: 0:00:06.739714
elapsed time: 0:25:26.049418
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 07:35:07.876291
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.81
 ---- batch: 020 ----
mean loss: 90.15
 ---- batch: 030 ----
mean loss: 90.85
train mean loss: 90.42
epoch train time: 0:00:06.806730
elapsed time: 0:25:32.856985
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 07:35:14.683855
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.81
 ---- batch: 020 ----
mean loss: 91.52
 ---- batch: 030 ----
mean loss: 89.62
train mean loss: 90.24
epoch train time: 0:00:06.758193
elapsed time: 0:25:39.615936
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 07:35:21.442813
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.78
 ---- batch: 020 ----
mean loss: 90.97
 ---- batch: 030 ----
mean loss: 87.72
train mean loss: 90.58
epoch train time: 0:00:06.805099
elapsed time: 0:25:46.421804
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 07:35:28.248663
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.51
 ---- batch: 020 ----
mean loss: 89.96
 ---- batch: 030 ----
mean loss: 92.71
train mean loss: 90.64
epoch train time: 0:00:06.759927
elapsed time: 0:25:53.182551
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 07:35:35.009491
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.92
 ---- batch: 020 ----
mean loss: 90.87
 ---- batch: 030 ----
mean loss: 87.85
train mean loss: 90.55
epoch train time: 0:00:06.816281
elapsed time: 0:25:59.999690
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 07:35:41.826560
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.61
 ---- batch: 020 ----
mean loss: 89.36
 ---- batch: 030 ----
mean loss: 92.72
train mean loss: 90.38
epoch train time: 0:00:06.877363
elapsed time: 0:26:06.877930
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 07:35:48.704800
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.41
 ---- batch: 020 ----
mean loss: 92.36
 ---- batch: 030 ----
mean loss: 91.63
train mean loss: 90.37
epoch train time: 0:00:06.776836
elapsed time: 0:26:13.655663
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 07:35:55.482521
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.51
 ---- batch: 020 ----
mean loss: 95.18
 ---- batch: 030 ----
mean loss: 88.10
train mean loss: 90.61
epoch train time: 0:00:06.852973
elapsed time: 0:26:20.509395
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 07:36:02.336261
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.56
 ---- batch: 020 ----
mean loss: 90.67
 ---- batch: 030 ----
mean loss: 90.94
train mean loss: 90.17
epoch train time: 0:00:06.764960
elapsed time: 0:26:27.275143
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 07:36:09.102012
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.08
 ---- batch: 020 ----
mean loss: 90.24
 ---- batch: 030 ----
mean loss: 88.82
train mean loss: 90.47
epoch train time: 0:00:06.819134
elapsed time: 0:26:34.095209
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 07:36:15.922077
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.14
 ---- batch: 020 ----
mean loss: 91.76
 ---- batch: 030 ----
mean loss: 90.02
train mean loss: 90.62
epoch train time: 0:00:06.829611
elapsed time: 0:26:40.925584
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 07:36:22.752499
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.18
 ---- batch: 020 ----
mean loss: 89.18
 ---- batch: 030 ----
mean loss: 89.25
train mean loss: 90.25
epoch train time: 0:00:06.822017
elapsed time: 0:26:47.748371
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 07:36:29.575331
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.49
 ---- batch: 020 ----
mean loss: 91.43
 ---- batch: 030 ----
mean loss: 90.65
train mean loss: 90.62
epoch train time: 0:00:06.786809
elapsed time: 0:26:54.536089
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 07:36:36.362970
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.84
 ---- batch: 020 ----
mean loss: 92.43
 ---- batch: 030 ----
mean loss: 90.04
train mean loss: 91.04
epoch train time: 0:00:06.833379
elapsed time: 0:27:01.370514
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 07:36:43.197288
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.75
 ---- batch: 020 ----
mean loss: 90.78
 ---- batch: 030 ----
mean loss: 89.25
train mean loss: 90.55
epoch train time: 0:00:06.835415
elapsed time: 0:27:08.206643
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 07:36:50.033504
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.72
 ---- batch: 020 ----
mean loss: 89.51
 ---- batch: 030 ----
mean loss: 88.00
train mean loss: 90.10
epoch train time: 0:00:06.681855
elapsed time: 0:27:14.889281
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 07:36:56.716144
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.14
 ---- batch: 020 ----
mean loss: 88.61
 ---- batch: 030 ----
mean loss: 89.84
train mean loss: 90.74
epoch train time: 0:00:06.651337
elapsed time: 0:27:21.541407
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 07:37:03.368276
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.35
 ---- batch: 020 ----
mean loss: 90.32
 ---- batch: 030 ----
mean loss: 89.16
train mean loss: 90.34
epoch train time: 0:00:06.864108
elapsed time: 0:27:28.406300
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 07:37:10.233204
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.74
 ---- batch: 020 ----
mean loss: 89.25
 ---- batch: 030 ----
mean loss: 89.61
train mean loss: 90.51
epoch train time: 0:00:06.869559
elapsed time: 0:27:35.276695
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 07:37:17.103558
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.11
 ---- batch: 020 ----
mean loss: 90.54
 ---- batch: 030 ----
mean loss: 88.72
train mean loss: 90.97
epoch train time: 0:00:06.882127
elapsed time: 0:27:42.159696
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 07:37:23.986573
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.62
 ---- batch: 020 ----
mean loss: 91.24
 ---- batch: 030 ----
mean loss: 93.29
train mean loss: 90.69
epoch train time: 0:00:06.879768
elapsed time: 0:27:49.040239
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 07:37:30.867152
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.30
 ---- batch: 020 ----
mean loss: 90.53
 ---- batch: 030 ----
mean loss: 91.57
train mean loss: 90.42
epoch train time: 0:00:06.875535
elapsed time: 0:27:55.916637
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 07:37:37.743507
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.32
 ---- batch: 020 ----
mean loss: 90.54
 ---- batch: 030 ----
mean loss: 87.93
train mean loss: 90.51
epoch train time: 0:00:06.971512
elapsed time: 0:28:02.889030
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 07:37:44.715924
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.71
 ---- batch: 020 ----
mean loss: 92.18
 ---- batch: 030 ----
mean loss: 89.71
train mean loss: 90.79
epoch train time: 0:00:06.818622
elapsed time: 0:28:09.708563
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 07:37:51.535431
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.08
 ---- batch: 020 ----
mean loss: 88.62
 ---- batch: 030 ----
mean loss: 87.48
train mean loss: 89.68
epoch train time: 0:00:06.905851
elapsed time: 0:28:16.615305
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 07:37:58.442185
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.53
 ---- batch: 020 ----
mean loss: 88.28
 ---- batch: 030 ----
mean loss: 89.23
train mean loss: 90.42
epoch train time: 0:00:06.870141
elapsed time: 0:28:23.486258
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 07:38:05.313212
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.93
 ---- batch: 020 ----
mean loss: 91.49
 ---- batch: 030 ----
mean loss: 90.09
train mean loss: 90.52
epoch train time: 0:00:06.938626
elapsed time: 0:28:30.425855
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 07:38:12.252743
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.05
 ---- batch: 020 ----
mean loss: 88.90
 ---- batch: 030 ----
mean loss: 89.19
train mean loss: 90.57
epoch train time: 0:00:06.924572
elapsed time: 0:28:37.351229
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 07:38:19.178098
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.50
 ---- batch: 020 ----
mean loss: 91.69
 ---- batch: 030 ----
mean loss: 89.22
train mean loss: 90.95
epoch train time: 0:00:06.842189
elapsed time: 0:28:44.194198
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 07:38:26.021073
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.32
 ---- batch: 020 ----
mean loss: 93.01
 ---- batch: 030 ----
mean loss: 92.02
train mean loss: 90.28
epoch train time: 0:00:06.997641
elapsed time: 0:28:51.201621
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_3/checkpoint.pth.tar
**** end time: 2019-09-27 07:38:33.028351 ****
