Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_7', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32364
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 17:00:22.429889 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 17:00:22.433104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4109.09
 ---- batch: 020 ----
mean loss: 3881.08
 ---- batch: 030 ----
mean loss: 3867.42
train mean loss: 3933.75
epoch train time: 0:00:12.480946
elapsed time: 0:00:12.487094
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 17:00:34.917028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3757.55
 ---- batch: 020 ----
mean loss: 3662.72
 ---- batch: 030 ----
mean loss: 3632.80
train mean loss: 3676.57
epoch train time: 0:00:00.175929
elapsed time: 0:00:12.663206
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 17:00:35.093151
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3547.31
 ---- batch: 020 ----
mean loss: 3481.02
 ---- batch: 030 ----
mean loss: 3444.31
train mean loss: 3473.13
epoch train time: 0:00:00.171900
elapsed time: 0:00:12.835257
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 17:00:35.265187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3329.18
 ---- batch: 020 ----
mean loss: 3253.06
 ---- batch: 030 ----
mean loss: 3236.18
train mean loss: 3267.69
epoch train time: 0:00:00.169803
elapsed time: 0:00:13.005188
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 17:00:35.435137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3090.29
 ---- batch: 020 ----
mean loss: 3030.52
 ---- batch: 030 ----
mean loss: 3096.14
train mean loss: 3059.95
epoch train time: 0:00:00.170565
elapsed time: 0:00:13.175912
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 17:00:35.605840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2935.08
 ---- batch: 020 ----
mean loss: 2868.32
 ---- batch: 030 ----
mean loss: 2852.99
train mean loss: 2874.94
epoch train time: 0:00:00.171093
elapsed time: 0:00:13.347132
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 17:00:35.777070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2783.51
 ---- batch: 020 ----
mean loss: 2704.90
 ---- batch: 030 ----
mean loss: 2650.23
train mean loss: 2701.26
epoch train time: 0:00:00.172090
elapsed time: 0:00:13.519361
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 17:00:35.949299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2591.29
 ---- batch: 020 ----
mean loss: 2568.23
 ---- batch: 030 ----
mean loss: 2477.14
train mean loss: 2535.53
epoch train time: 0:00:00.171435
elapsed time: 0:00:13.690934
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 17:00:36.120868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2431.68
 ---- batch: 020 ----
mean loss: 2392.05
 ---- batch: 030 ----
mean loss: 2358.65
train mean loss: 2384.07
epoch train time: 0:00:00.172615
elapsed time: 0:00:13.863702
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 17:00:36.293681
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2307.51
 ---- batch: 020 ----
mean loss: 2245.85
 ---- batch: 030 ----
mean loss: 2217.08
train mean loss: 2243.50
epoch train time: 0:00:00.174214
elapsed time: 0:00:14.038111
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 17:00:36.468041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2144.86
 ---- batch: 020 ----
mean loss: 2133.95
 ---- batch: 030 ----
mean loss: 2076.04
train mean loss: 2107.82
epoch train time: 0:00:00.170064
elapsed time: 0:00:14.208336
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 17:00:36.638272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2019.98
 ---- batch: 020 ----
mean loss: 2002.59
 ---- batch: 030 ----
mean loss: 1930.91
train mean loss: 1981.88
epoch train time: 0:00:00.173100
elapsed time: 0:00:14.381576
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 17:00:36.811514
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1908.39
 ---- batch: 020 ----
mean loss: 1851.06
 ---- batch: 030 ----
mean loss: 1847.80
train mean loss: 1854.27
epoch train time: 0:00:00.181129
elapsed time: 0:00:14.562859
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 17:00:36.992796
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1806.20
 ---- batch: 020 ----
mean loss: 1749.55
 ---- batch: 030 ----
mean loss: 1687.95
train mean loss: 1733.11
epoch train time: 0:00:00.177947
elapsed time: 0:00:14.740950
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 17:00:37.170901
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1656.85
 ---- batch: 020 ----
mean loss: 1633.82
 ---- batch: 030 ----
mean loss: 1601.56
train mean loss: 1623.52
epoch train time: 0:00:00.176596
elapsed time: 0:00:14.917716
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 17:00:37.347648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1549.59
 ---- batch: 020 ----
mean loss: 1521.17
 ---- batch: 030 ----
mean loss: 1507.83
train mean loss: 1520.40
epoch train time: 0:00:00.177435
elapsed time: 0:00:15.095287
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 17:00:37.525226
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1459.73
 ---- batch: 020 ----
mean loss: 1424.52
 ---- batch: 030 ----
mean loss: 1406.35
train mean loss: 1424.56
epoch train time: 0:00:00.178677
elapsed time: 0:00:15.274103
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 17:00:37.704056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1371.32
 ---- batch: 020 ----
mean loss: 1344.08
 ---- batch: 030 ----
mean loss: 1298.34
train mean loss: 1337.22
epoch train time: 0:00:00.172397
elapsed time: 0:00:15.446652
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 17:00:37.876590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1287.74
 ---- batch: 020 ----
mean loss: 1265.34
 ---- batch: 030 ----
mean loss: 1229.12
train mean loss: 1254.67
epoch train time: 0:00:00.170577
elapsed time: 0:00:15.617378
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 17:00:38.047330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1209.19
 ---- batch: 020 ----
mean loss: 1179.31
 ---- batch: 030 ----
mean loss: 1159.97
train mean loss: 1177.65
epoch train time: 0:00:00.170904
elapsed time: 0:00:15.788434
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 17:00:38.218369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1116.30
 ---- batch: 020 ----
mean loss: 1108.52
 ---- batch: 030 ----
mean loss: 1087.71
train mean loss: 1104.27
epoch train time: 0:00:00.171631
elapsed time: 0:00:15.960202
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 17:00:38.390155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1049.38
 ---- batch: 020 ----
mean loss: 1061.59
 ---- batch: 030 ----
mean loss: 1018.88
train mean loss: 1033.56
epoch train time: 0:00:00.169419
elapsed time: 0:00:16.129793
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 17:00:38.559729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 998.69
 ---- batch: 020 ----
mean loss: 973.07
 ---- batch: 030 ----
mean loss: 957.47
train mean loss: 967.61
epoch train time: 0:00:00.167646
elapsed time: 0:00:16.297575
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 17:00:38.727521
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 914.39
 ---- batch: 020 ----
mean loss: 923.89
 ---- batch: 030 ----
mean loss: 905.48
train mean loss: 904.87
epoch train time: 0:00:00.175833
elapsed time: 0:00:16.473550
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 17:00:38.903487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 876.06
 ---- batch: 020 ----
mean loss: 862.74
 ---- batch: 030 ----
mean loss: 825.58
train mean loss: 846.06
epoch train time: 0:00:00.168965
elapsed time: 0:00:16.642648
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 17:00:39.072599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 798.99
 ---- batch: 020 ----
mean loss: 810.57
 ---- batch: 030 ----
mean loss: 783.44
train mean loss: 791.98
epoch train time: 0:00:00.174228
elapsed time: 0:00:16.817026
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 17:00:39.246977
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 761.29
 ---- batch: 020 ----
mean loss: 749.85
 ---- batch: 030 ----
mean loss: 714.21
train mean loss: 741.41
epoch train time: 0:00:00.170836
elapsed time: 0:00:16.988017
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 17:00:39.417976
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 714.28
 ---- batch: 020 ----
mean loss: 697.91
 ---- batch: 030 ----
mean loss: 674.72
train mean loss: 692.50
epoch train time: 0:00:00.169637
elapsed time: 0:00:17.157836
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 17:00:39.587765
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 654.71
 ---- batch: 020 ----
mean loss: 668.91
 ---- batch: 030 ----
mean loss: 635.24
train mean loss: 647.82
epoch train time: 0:00:00.169463
elapsed time: 0:00:17.327425
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 17:00:39.757362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 617.98
 ---- batch: 020 ----
mean loss: 608.64
 ---- batch: 030 ----
mean loss: 598.31
train mean loss: 607.02
epoch train time: 0:00:00.172798
elapsed time: 0:00:17.500962
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 17:00:39.930911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 579.03
 ---- batch: 020 ----
mean loss: 560.01
 ---- batch: 030 ----
mean loss: 578.67
train mean loss: 569.22
epoch train time: 0:00:00.175657
elapsed time: 0:00:17.676778
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 17:00:40.106719
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 545.79
 ---- batch: 020 ----
mean loss: 539.82
 ---- batch: 030 ----
mean loss: 522.86
train mean loss: 532.32
epoch train time: 0:00:00.175248
elapsed time: 0:00:17.852175
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 17:00:40.282113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 513.81
 ---- batch: 020 ----
mean loss: 497.31
 ---- batch: 030 ----
mean loss: 484.22
train mean loss: 499.42
epoch train time: 0:00:00.173785
elapsed time: 0:00:18.026100
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 17:00:40.456038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 479.66
 ---- batch: 020 ----
mean loss: 480.46
 ---- batch: 030 ----
mean loss: 458.59
train mean loss: 468.72
epoch train time: 0:00:00.171373
elapsed time: 0:00:18.197622
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 17:00:40.627557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 444.18
 ---- batch: 020 ----
mean loss: 445.31
 ---- batch: 030 ----
mean loss: 434.95
train mean loss: 439.75
epoch train time: 0:00:00.177874
elapsed time: 0:00:18.375639
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 17:00:40.805585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.57
 ---- batch: 020 ----
mean loss: 411.51
 ---- batch: 030 ----
mean loss: 416.97
train mean loss: 413.44
epoch train time: 0:00:00.176128
elapsed time: 0:00:18.551930
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 17:00:40.981866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 397.61
 ---- batch: 020 ----
mean loss: 389.09
 ---- batch: 030 ----
mean loss: 382.05
train mean loss: 387.67
epoch train time: 0:00:00.177971
elapsed time: 0:00:18.730049
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 17:00:41.159988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.44
 ---- batch: 020 ----
mean loss: 362.95
 ---- batch: 030 ----
mean loss: 361.66
train mean loss: 364.58
epoch train time: 0:00:00.175124
elapsed time: 0:00:18.905331
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 17:00:41.335269
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 355.18
 ---- batch: 020 ----
mean loss: 345.73
 ---- batch: 030 ----
mean loss: 337.65
train mean loss: 343.11
epoch train time: 0:00:00.172205
elapsed time: 0:00:19.077673
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 17:00:41.507608
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 330.77
 ---- batch: 020 ----
mean loss: 319.31
 ---- batch: 030 ----
mean loss: 320.50
train mean loss: 322.77
epoch train time: 0:00:00.170522
elapsed time: 0:00:19.248331
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 17:00:41.678286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 314.85
 ---- batch: 020 ----
mean loss: 296.41
 ---- batch: 030 ----
mean loss: 302.29
train mean loss: 304.62
epoch train time: 0:00:00.173403
elapsed time: 0:00:19.421889
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 17:00:41.851842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.56
 ---- batch: 020 ----
mean loss: 284.06
 ---- batch: 030 ----
mean loss: 290.68
train mean loss: 287.04
epoch train time: 0:00:00.169136
elapsed time: 0:00:19.591215
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 17:00:42.021151
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.97
 ---- batch: 020 ----
mean loss: 271.83
 ---- batch: 030 ----
mean loss: 260.86
train mean loss: 271.23
epoch train time: 0:00:00.170535
elapsed time: 0:00:19.761884
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 17:00:42.191820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.71
 ---- batch: 020 ----
mean loss: 259.20
 ---- batch: 030 ----
mean loss: 254.49
train mean loss: 256.79
epoch train time: 0:00:00.171327
elapsed time: 0:00:19.933344
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 17:00:42.363281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.90
 ---- batch: 020 ----
mean loss: 240.67
 ---- batch: 030 ----
mean loss: 242.46
train mean loss: 242.98
epoch train time: 0:00:00.170192
elapsed time: 0:00:20.103680
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 17:00:42.533641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.78
 ---- batch: 020 ----
mean loss: 226.74
 ---- batch: 030 ----
mean loss: 227.85
train mean loss: 230.61
epoch train time: 0:00:00.170108
elapsed time: 0:00:20.273959
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 17:00:42.703898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.28
 ---- batch: 020 ----
mean loss: 223.99
 ---- batch: 030 ----
mean loss: 216.30
train mean loss: 218.63
epoch train time: 0:00:00.175296
elapsed time: 0:00:20.449412
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 17:00:42.879366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.50
 ---- batch: 020 ----
mean loss: 208.54
 ---- batch: 030 ----
mean loss: 209.77
train mean loss: 208.32
epoch train time: 0:00:00.169795
elapsed time: 0:00:20.619354
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 17:00:43.049291
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.49
 ---- batch: 020 ----
mean loss: 197.38
 ---- batch: 030 ----
mean loss: 200.04
train mean loss: 198.64
epoch train time: 0:00:00.168777
elapsed time: 0:00:20.788283
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 17:00:43.218220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.57
 ---- batch: 020 ----
mean loss: 191.81
 ---- batch: 030 ----
mean loss: 187.34
train mean loss: 189.62
epoch train time: 0:00:00.170385
elapsed time: 0:00:20.958802
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 17:00:43.388751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.91
 ---- batch: 020 ----
mean loss: 178.07
 ---- batch: 030 ----
mean loss: 180.96
train mean loss: 181.11
epoch train time: 0:00:00.167545
elapsed time: 0:00:21.126490
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 17:00:43.556421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.21
 ---- batch: 020 ----
mean loss: 174.45
 ---- batch: 030 ----
mean loss: 170.10
train mean loss: 173.58
epoch train time: 0:00:00.174985
elapsed time: 0:00:21.301607
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 17:00:43.731545
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.40
 ---- batch: 020 ----
mean loss: 164.80
 ---- batch: 030 ----
mean loss: 165.29
train mean loss: 166.13
epoch train time: 0:00:00.178334
elapsed time: 0:00:21.480085
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 17:00:43.910022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.78
 ---- batch: 020 ----
mean loss: 164.41
 ---- batch: 030 ----
mean loss: 158.44
train mean loss: 159.79
epoch train time: 0:00:00.172249
elapsed time: 0:00:21.652471
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 17:00:44.082426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.60
 ---- batch: 020 ----
mean loss: 151.35
 ---- batch: 030 ----
mean loss: 153.13
train mean loss: 153.60
epoch train time: 0:00:00.172619
elapsed time: 0:00:21.825260
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 17:00:44.255200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.60
 ---- batch: 020 ----
mean loss: 149.89
 ---- batch: 030 ----
mean loss: 144.38
train mean loss: 148.38
epoch train time: 0:00:00.172712
elapsed time: 0:00:21.998111
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 17:00:44.428047
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.57
 ---- batch: 020 ----
mean loss: 146.11
 ---- batch: 030 ----
mean loss: 141.68
train mean loss: 143.23
epoch train time: 0:00:00.170742
elapsed time: 0:00:22.168988
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 17:00:44.598937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.42
 ---- batch: 020 ----
mean loss: 136.98
 ---- batch: 030 ----
mean loss: 140.60
train mean loss: 138.29
epoch train time: 0:00:00.174147
elapsed time: 0:00:22.343293
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 17:00:44.773232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.94
 ---- batch: 020 ----
mean loss: 134.77
 ---- batch: 030 ----
mean loss: 135.38
train mean loss: 134.09
epoch train time: 0:00:00.175362
elapsed time: 0:00:22.519466
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 17:00:44.949445
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.24
 ---- batch: 020 ----
mean loss: 128.15
 ---- batch: 030 ----
mean loss: 129.09
train mean loss: 129.78
epoch train time: 0:00:00.171895
elapsed time: 0:00:22.691538
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 17:00:45.121476
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.60
 ---- batch: 020 ----
mean loss: 125.67
 ---- batch: 030 ----
mean loss: 125.94
train mean loss: 126.71
epoch train time: 0:00:00.172648
elapsed time: 0:00:22.864326
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 17:00:45.294265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.13
 ---- batch: 020 ----
mean loss: 122.38
 ---- batch: 030 ----
mean loss: 125.24
train mean loss: 123.14
epoch train time: 0:00:00.170715
elapsed time: 0:00:23.035181
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 17:00:45.465118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.06
 ---- batch: 020 ----
mean loss: 121.19
 ---- batch: 030 ----
mean loss: 116.93
train mean loss: 119.76
epoch train time: 0:00:00.170938
elapsed time: 0:00:23.206258
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 17:00:45.636208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.75
 ---- batch: 020 ----
mean loss: 117.53
 ---- batch: 030 ----
mean loss: 116.87
train mean loss: 116.57
epoch train time: 0:00:00.170146
elapsed time: 0:00:23.376570
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 17:00:45.806507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.78
 ---- batch: 020 ----
mean loss: 113.09
 ---- batch: 030 ----
mean loss: 112.89
train mean loss: 113.97
epoch train time: 0:00:00.177564
elapsed time: 0:00:23.554269
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 17:00:45.984204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.72
 ---- batch: 020 ----
mean loss: 111.72
 ---- batch: 030 ----
mean loss: 112.49
train mean loss: 111.46
epoch train time: 0:00:00.167956
elapsed time: 0:00:23.722355
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 17:00:46.152305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.16
 ---- batch: 020 ----
mean loss: 109.24
 ---- batch: 030 ----
mean loss: 107.61
train mean loss: 108.96
epoch train time: 0:00:00.171980
elapsed time: 0:00:23.894512
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 17:00:46.324447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.51
 ---- batch: 020 ----
mean loss: 106.13
 ---- batch: 030 ----
mean loss: 109.09
train mean loss: 107.62
epoch train time: 0:00:00.169193
elapsed time: 0:00:24.063840
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 17:00:46.493792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.68
 ---- batch: 020 ----
mean loss: 103.23
 ---- batch: 030 ----
mean loss: 101.68
train mean loss: 104.92
epoch train time: 0:00:00.166570
elapsed time: 0:00:24.230560
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 17:00:46.660496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.98
 ---- batch: 020 ----
mean loss: 100.95
 ---- batch: 030 ----
mean loss: 103.19
train mean loss: 102.93
epoch train time: 0:00:00.176283
elapsed time: 0:00:24.406980
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 17:00:46.836916
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.45
 ---- batch: 020 ----
mean loss: 102.88
 ---- batch: 030 ----
mean loss: 100.92
train mean loss: 101.21
epoch train time: 0:00:00.177037
elapsed time: 0:00:24.584157
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 17:00:47.014095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.91
 ---- batch: 020 ----
mean loss: 100.00
 ---- batch: 030 ----
mean loss: 97.28
train mean loss: 99.62
epoch train time: 0:00:00.173477
elapsed time: 0:00:24.757772
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 17:00:47.187708
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.16
 ---- batch: 020 ----
mean loss: 98.36
 ---- batch: 030 ----
mean loss: 99.96
train mean loss: 97.97
epoch train time: 0:00:00.172622
elapsed time: 0:00:24.930532
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 17:00:47.360469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.56
 ---- batch: 020 ----
mean loss: 99.38
 ---- batch: 030 ----
mean loss: 95.14
train mean loss: 96.35
epoch train time: 0:00:00.172994
elapsed time: 0:00:25.103677
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 17:00:47.533637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.92
 ---- batch: 020 ----
mean loss: 96.76
 ---- batch: 030 ----
mean loss: 94.54
train mean loss: 94.93
epoch train time: 0:00:00.174658
elapsed time: 0:00:25.278491
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 17:00:47.708439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.01
 ---- batch: 020 ----
mean loss: 93.05
 ---- batch: 030 ----
mean loss: 95.68
train mean loss: 93.84
epoch train time: 0:00:00.176840
elapsed time: 0:00:25.455485
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 17:00:47.885448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.21
 ---- batch: 020 ----
mean loss: 91.83
 ---- batch: 030 ----
mean loss: 88.59
train mean loss: 92.43
epoch train time: 0:00:00.182810
elapsed time: 0:00:25.638454
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 17:00:48.068390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.46
 ---- batch: 020 ----
mean loss: 90.11
 ---- batch: 030 ----
mean loss: 92.55
train mean loss: 91.15
epoch train time: 0:00:00.170186
elapsed time: 0:00:25.808774
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 17:00:48.238711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.47
 ---- batch: 020 ----
mean loss: 88.63
 ---- batch: 030 ----
mean loss: 93.31
train mean loss: 90.93
epoch train time: 0:00:00.171639
elapsed time: 0:00:25.980567
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 17:00:48.410506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.80
 ---- batch: 020 ----
mean loss: 90.90
 ---- batch: 030 ----
mean loss: 90.11
train mean loss: 89.67
epoch train time: 0:00:00.169822
elapsed time: 0:00:26.150526
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 17:00:48.580462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.09
 ---- batch: 020 ----
mean loss: 86.36
 ---- batch: 030 ----
mean loss: 86.93
train mean loss: 88.34
epoch train time: 0:00:00.173208
elapsed time: 0:00:26.323871
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 17:00:48.753828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.30
 ---- batch: 020 ----
mean loss: 89.07
 ---- batch: 030 ----
mean loss: 89.26
train mean loss: 87.60
epoch train time: 0:00:00.170307
elapsed time: 0:00:26.494336
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 17:00:48.924290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.03
 ---- batch: 020 ----
mean loss: 88.28
 ---- batch: 030 ----
mean loss: 84.62
train mean loss: 86.70
epoch train time: 0:00:00.176813
elapsed time: 0:00:26.671331
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 17:00:49.101268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.32
 ---- batch: 020 ----
mean loss: 83.70
 ---- batch: 030 ----
mean loss: 85.40
train mean loss: 85.75
epoch train time: 0:00:00.172700
elapsed time: 0:00:26.844168
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 17:00:49.274106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.71
 ---- batch: 020 ----
mean loss: 88.26
 ---- batch: 030 ----
mean loss: 85.38
train mean loss: 85.05
epoch train time: 0:00:00.174319
elapsed time: 0:00:27.018688
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 17:00:49.448620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.67
 ---- batch: 020 ----
mean loss: 85.88
 ---- batch: 030 ----
mean loss: 82.82
train mean loss: 84.19
epoch train time: 0:00:00.169925
elapsed time: 0:00:27.188744
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 17:00:49.618680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.59
 ---- batch: 020 ----
mean loss: 83.55
 ---- batch: 030 ----
mean loss: 88.74
train mean loss: 84.64
epoch train time: 0:00:00.168641
elapsed time: 0:00:27.357519
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 17:00:49.787466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.88
 ---- batch: 020 ----
mean loss: 83.78
 ---- batch: 030 ----
mean loss: 79.44
train mean loss: 83.24
epoch train time: 0:00:00.168139
elapsed time: 0:00:27.526444
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 17:00:49.956403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.52
 ---- batch: 020 ----
mean loss: 79.38
 ---- batch: 030 ----
mean loss: 82.11
train mean loss: 82.01
epoch train time: 0:00:00.168345
elapsed time: 0:00:27.694949
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 17:00:50.124886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.46
 ---- batch: 020 ----
mean loss: 79.22
 ---- batch: 030 ----
mean loss: 82.66
train mean loss: 81.34
epoch train time: 0:00:00.169122
elapsed time: 0:00:27.864207
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 17:00:50.294143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.49
 ---- batch: 020 ----
mean loss: 80.69
 ---- batch: 030 ----
mean loss: 80.68
train mean loss: 80.23
epoch train time: 0:00:00.169118
elapsed time: 0:00:28.033477
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 17:00:50.463413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.52
 ---- batch: 020 ----
mean loss: 80.97
 ---- batch: 030 ----
mean loss: 79.69
train mean loss: 79.52
epoch train time: 0:00:00.167054
elapsed time: 0:00:28.200673
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 17:00:50.630611
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.06
 ---- batch: 020 ----
mean loss: 78.80
 ---- batch: 030 ----
mean loss: 80.48
train mean loss: 79.99
epoch train time: 0:00:00.173516
elapsed time: 0:00:28.374325
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 17:00:50.804292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.20
 ---- batch: 020 ----
mean loss: 77.89
 ---- batch: 030 ----
mean loss: 79.44
train mean loss: 78.13
epoch train time: 0:00:00.172396
elapsed time: 0:00:28.546890
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 17:00:50.976827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.07
 ---- batch: 020 ----
mean loss: 76.96
 ---- batch: 030 ----
mean loss: 78.30
train mean loss: 77.90
epoch train time: 0:00:00.168897
elapsed time: 0:00:28.715939
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 17:00:51.145893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.72
 ---- batch: 020 ----
mean loss: 74.93
 ---- batch: 030 ----
mean loss: 78.96
train mean loss: 77.17
epoch train time: 0:00:00.169004
elapsed time: 0:00:28.885093
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 17:00:51.315044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.17
 ---- batch: 020 ----
mean loss: 77.16
 ---- batch: 030 ----
mean loss: 78.05
train mean loss: 76.22
epoch train time: 0:00:00.171174
elapsed time: 0:00:29.056415
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 17:00:51.486352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.46
 ---- batch: 020 ----
mean loss: 76.88
 ---- batch: 030 ----
mean loss: 77.27
train mean loss: 76.63
epoch train time: 0:00:00.167442
elapsed time: 0:00:29.223992
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 17:00:51.653928
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.64
 ---- batch: 020 ----
mean loss: 75.85
 ---- batch: 030 ----
mean loss: 74.50
train mean loss: 75.59
epoch train time: 0:00:00.185385
elapsed time: 0:00:29.409514
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 17:00:51.839451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.33
 ---- batch: 020 ----
mean loss: 74.57
 ---- batch: 030 ----
mean loss: 71.84
train mean loss: 75.04
epoch train time: 0:00:00.175025
elapsed time: 0:00:29.584678
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 17:00:52.014616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.08
 ---- batch: 020 ----
mean loss: 73.80
 ---- batch: 030 ----
mean loss: 71.33
train mean loss: 74.04
epoch train time: 0:00:00.172718
elapsed time: 0:00:29.757534
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 17:00:52.187529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.90
 ---- batch: 020 ----
mean loss: 72.93
 ---- batch: 030 ----
mean loss: 72.79
train mean loss: 73.74
epoch train time: 0:00:00.170597
elapsed time: 0:00:29.928327
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 17:00:52.358265
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.09
 ---- batch: 020 ----
mean loss: 75.61
 ---- batch: 030 ----
mean loss: 72.00
train mean loss: 73.11
epoch train time: 0:00:00.174075
elapsed time: 0:00:30.102539
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 17:00:52.532474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.07
 ---- batch: 020 ----
mean loss: 73.50
 ---- batch: 030 ----
mean loss: 71.77
train mean loss: 72.55
epoch train time: 0:00:00.169238
elapsed time: 0:00:30.271934
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 17:00:52.701870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.28
 ---- batch: 020 ----
mean loss: 70.02
 ---- batch: 030 ----
mean loss: 70.60
train mean loss: 72.24
epoch train time: 0:00:00.176822
elapsed time: 0:00:30.448891
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 17:00:52.878826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.44
 ---- batch: 020 ----
mean loss: 70.75
 ---- batch: 030 ----
mean loss: 72.89
train mean loss: 71.62
epoch train time: 0:00:00.170632
elapsed time: 0:00:30.619654
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 17:00:53.049590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.68
 ---- batch: 020 ----
mean loss: 71.28
 ---- batch: 030 ----
mean loss: 69.67
train mean loss: 71.12
epoch train time: 0:00:00.169916
elapsed time: 0:00:30.789773
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 17:00:53.219701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.95
 ---- batch: 020 ----
mean loss: 71.08
 ---- batch: 030 ----
mean loss: 72.49
train mean loss: 71.09
epoch train time: 0:00:00.171079
elapsed time: 0:00:30.960978
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 17:00:53.390939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.61
 ---- batch: 020 ----
mean loss: 71.99
 ---- batch: 030 ----
mean loss: 67.41
train mean loss: 70.80
epoch train time: 0:00:00.170744
elapsed time: 0:00:31.131885
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 17:00:53.561852
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.82
 ---- batch: 020 ----
mean loss: 71.00
 ---- batch: 030 ----
mean loss: 71.36
train mean loss: 70.52
epoch train time: 0:00:00.169564
elapsed time: 0:00:31.301617
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 17:00:53.731553
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.77
 ---- batch: 020 ----
mean loss: 69.46
 ---- batch: 030 ----
mean loss: 71.36
train mean loss: 69.34
epoch train time: 0:00:00.171767
elapsed time: 0:00:31.473520
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 17:00:53.903456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.32
 ---- batch: 020 ----
mean loss: 69.15
 ---- batch: 030 ----
mean loss: 68.78
train mean loss: 69.78
epoch train time: 0:00:00.169067
elapsed time: 0:00:31.642721
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 17:00:54.072688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.37
 ---- batch: 020 ----
mean loss: 70.39
 ---- batch: 030 ----
mean loss: 68.88
train mean loss: 69.59
epoch train time: 0:00:00.170017
elapsed time: 0:00:31.812904
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 17:00:54.242841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.53
 ---- batch: 020 ----
mean loss: 66.35
 ---- batch: 030 ----
mean loss: 69.63
train mean loss: 68.44
epoch train time: 0:00:00.169648
elapsed time: 0:00:31.982690
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 17:00:54.412627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.26
 ---- batch: 020 ----
mean loss: 66.28
 ---- batch: 030 ----
mean loss: 69.23
train mean loss: 68.12
epoch train time: 0:00:00.173289
elapsed time: 0:00:32.156149
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 17:00:54.586086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.74
 ---- batch: 020 ----
mean loss: 66.85
 ---- batch: 030 ----
mean loss: 70.50
train mean loss: 68.54
epoch train time: 0:00:00.174621
elapsed time: 0:00:32.330923
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 17:00:54.760915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.06
 ---- batch: 020 ----
mean loss: 68.85
 ---- batch: 030 ----
mean loss: 69.72
train mean loss: 69.25
epoch train time: 0:00:00.177479
elapsed time: 0:00:32.508606
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 17:00:54.938622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.41
 ---- batch: 020 ----
mean loss: 67.48
 ---- batch: 030 ----
mean loss: 68.50
train mean loss: 67.82
epoch train time: 0:00:00.178393
elapsed time: 0:00:32.687224
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 17:00:55.117180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.90
 ---- batch: 020 ----
mean loss: 67.07
 ---- batch: 030 ----
mean loss: 68.65
train mean loss: 67.82
epoch train time: 0:00:00.172543
elapsed time: 0:00:32.859928
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 17:00:55.289866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.05
 ---- batch: 020 ----
mean loss: 68.79
 ---- batch: 030 ----
mean loss: 68.94
train mean loss: 68.84
epoch train time: 0:00:00.173447
elapsed time: 0:00:33.033514
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 17:00:55.463451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.84
 ---- batch: 020 ----
mean loss: 67.82
 ---- batch: 030 ----
mean loss: 64.95
train mean loss: 67.48
epoch train time: 0:00:00.176680
elapsed time: 0:00:33.210333
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 17:00:55.640270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.28
 ---- batch: 020 ----
mean loss: 66.42
 ---- batch: 030 ----
mean loss: 68.49
train mean loss: 66.60
epoch train time: 0:00:00.175237
elapsed time: 0:00:33.385707
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 17:00:55.815662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.02
 ---- batch: 020 ----
mean loss: 66.42
 ---- batch: 030 ----
mean loss: 66.30
train mean loss: 66.21
epoch train time: 0:00:00.172658
elapsed time: 0:00:33.558558
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 17:00:55.988496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.47
 ---- batch: 020 ----
mean loss: 65.20
 ---- batch: 030 ----
mean loss: 66.33
train mean loss: 65.87
epoch train time: 0:00:00.169987
elapsed time: 0:00:33.728698
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 17:00:56.158636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.06
 ---- batch: 020 ----
mean loss: 64.29
 ---- batch: 030 ----
mean loss: 67.24
train mean loss: 66.18
epoch train time: 0:00:00.170840
elapsed time: 0:00:33.899676
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 17:00:56.329636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.07
 ---- batch: 020 ----
mean loss: 63.41
 ---- batch: 030 ----
mean loss: 63.91
train mean loss: 65.83
epoch train time: 0:00:00.171349
elapsed time: 0:00:34.071185
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 17:00:56.501124
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.37
 ---- batch: 020 ----
mean loss: 65.45
 ---- batch: 030 ----
mean loss: 67.31
train mean loss: 65.77
epoch train time: 0:00:00.174149
elapsed time: 0:00:34.245487
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 17:00:56.675422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.14
 ---- batch: 020 ----
mean loss: 65.91
 ---- batch: 030 ----
mean loss: 67.08
train mean loss: 66.13
epoch train time: 0:00:00.175415
elapsed time: 0:00:34.421037
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 17:00:56.850974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.78
 ---- batch: 020 ----
mean loss: 65.12
 ---- batch: 030 ----
mean loss: 64.41
train mean loss: 65.50
epoch train time: 0:00:00.172567
elapsed time: 0:00:34.593756
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 17:00:57.023695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.54
 ---- batch: 020 ----
mean loss: 66.27
 ---- batch: 030 ----
mean loss: 63.83
train mean loss: 64.91
epoch train time: 0:00:00.172794
elapsed time: 0:00:34.766687
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 17:00:57.196623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.39
 ---- batch: 020 ----
mean loss: 64.82
 ---- batch: 030 ----
mean loss: 64.26
train mean loss: 65.27
epoch train time: 0:00:00.170955
elapsed time: 0:00:34.937776
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 17:00:57.367714
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.34
 ---- batch: 020 ----
mean loss: 64.55
 ---- batch: 030 ----
mean loss: 64.58
train mean loss: 64.38
epoch train time: 0:00:00.171776
elapsed time: 0:00:35.109689
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 17:00:57.539645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.65
 ---- batch: 020 ----
mean loss: 66.93
 ---- batch: 030 ----
mean loss: 62.33
train mean loss: 64.48
epoch train time: 0:00:00.170181
elapsed time: 0:00:35.280037
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 17:00:57.709976
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.49
 ---- batch: 020 ----
mean loss: 65.46
 ---- batch: 030 ----
mean loss: 65.70
train mean loss: 65.00
epoch train time: 0:00:00.171002
elapsed time: 0:00:35.451177
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 17:00:57.881115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.52
 ---- batch: 020 ----
mean loss: 63.95
 ---- batch: 030 ----
mean loss: 64.42
train mean loss: 63.99
epoch train time: 0:00:00.171262
elapsed time: 0:00:35.622578
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 17:00:58.052515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.67
 ---- batch: 020 ----
mean loss: 62.63
 ---- batch: 030 ----
mean loss: 64.57
train mean loss: 64.00
epoch train time: 0:00:00.169905
elapsed time: 0:00:35.792619
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 17:00:58.222573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.91
 ---- batch: 020 ----
mean loss: 64.23
 ---- batch: 030 ----
mean loss: 61.91
train mean loss: 64.08
epoch train time: 0:00:00.168230
elapsed time: 0:00:35.960999
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 17:00:58.390948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.01
 ---- batch: 020 ----
mean loss: 65.98
 ---- batch: 030 ----
mean loss: 61.48
train mean loss: 64.29
epoch train time: 0:00:00.168938
elapsed time: 0:00:36.130085
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 17:00:58.560022
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.88
 ---- batch: 020 ----
mean loss: 67.33
 ---- batch: 030 ----
mean loss: 64.22
train mean loss: 65.00
epoch train time: 0:00:00.171676
elapsed time: 0:00:36.301900
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 17:00:58.731839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.58
 ---- batch: 020 ----
mean loss: 64.95
 ---- batch: 030 ----
mean loss: 63.47
train mean loss: 63.30
epoch train time: 0:00:00.174809
elapsed time: 0:00:36.476859
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 17:00:58.906800
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.04
 ---- batch: 020 ----
mean loss: 64.79
 ---- batch: 030 ----
mean loss: 66.77
train mean loss: 64.72
epoch train time: 0:00:00.174099
elapsed time: 0:00:36.651104
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 17:00:59.081043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.16
 ---- batch: 020 ----
mean loss: 64.75
 ---- batch: 030 ----
mean loss: 65.01
train mean loss: 64.37
epoch train time: 0:00:00.175389
elapsed time: 0:00:36.826648
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 17:00:59.256586
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.51
 ---- batch: 020 ----
mean loss: 63.59
 ---- batch: 030 ----
mean loss: 64.49
train mean loss: 63.14
epoch train time: 0:00:00.172130
elapsed time: 0:00:36.998913
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 17:00:59.428849
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.10
 ---- batch: 020 ----
mean loss: 62.17
 ---- batch: 030 ----
mean loss: 63.97
train mean loss: 62.69
epoch train time: 0:00:00.178410
elapsed time: 0:00:37.177463
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 17:00:59.607417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.97
 ---- batch: 020 ----
mean loss: 62.00
 ---- batch: 030 ----
mean loss: 62.65
train mean loss: 62.45
epoch train time: 0:00:00.177545
elapsed time: 0:00:37.355192
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 17:00:59.785129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.18
 ---- batch: 020 ----
mean loss: 63.63
 ---- batch: 030 ----
mean loss: 60.27
train mean loss: 62.78
epoch train time: 0:00:00.172679
elapsed time: 0:00:37.528027
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 17:00:59.957966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.52
 ---- batch: 020 ----
mean loss: 65.05
 ---- batch: 030 ----
mean loss: 61.50
train mean loss: 62.70
epoch train time: 0:00:00.173598
elapsed time: 0:00:37.701760
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 17:01:00.131698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.41
 ---- batch: 020 ----
mean loss: 62.08
 ---- batch: 030 ----
mean loss: 63.44
train mean loss: 62.08
epoch train time: 0:00:00.172566
elapsed time: 0:00:37.874463
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 17:01:00.304401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.25
 ---- batch: 020 ----
mean loss: 64.39
 ---- batch: 030 ----
mean loss: 62.04
train mean loss: 62.75
epoch train time: 0:00:00.169040
elapsed time: 0:00:38.043652
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 17:01:00.473579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.10
 ---- batch: 020 ----
mean loss: 63.44
 ---- batch: 030 ----
mean loss: 61.65
train mean loss: 63.27
epoch train time: 0:00:00.173091
elapsed time: 0:00:38.216886
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 17:01:00.646839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.79
 ---- batch: 020 ----
mean loss: 62.11
 ---- batch: 030 ----
mean loss: 61.20
train mean loss: 61.89
epoch train time: 0:00:00.172587
elapsed time: 0:00:38.389626
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 17:01:00.819564
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.81
 ---- batch: 020 ----
mean loss: 61.56
 ---- batch: 030 ----
mean loss: 65.90
train mean loss: 62.27
epoch train time: 0:00:00.172778
elapsed time: 0:00:38.562554
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 17:01:00.992491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.08
 ---- batch: 020 ----
mean loss: 63.63
 ---- batch: 030 ----
mean loss: 59.52
train mean loss: 61.59
epoch train time: 0:00:00.173201
elapsed time: 0:00:38.735955
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 17:01:01.165906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.70
 ---- batch: 020 ----
mean loss: 61.59
 ---- batch: 030 ----
mean loss: 62.94
train mean loss: 61.64
epoch train time: 0:00:00.172116
elapsed time: 0:00:38.908225
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 17:01:01.338163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.20
 ---- batch: 020 ----
mean loss: 64.22
 ---- batch: 030 ----
mean loss: 61.25
train mean loss: 62.21
epoch train time: 0:00:00.171997
elapsed time: 0:00:39.080364
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 17:01:01.510301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.47
 ---- batch: 020 ----
mean loss: 61.41
 ---- batch: 030 ----
mean loss: 63.79
train mean loss: 61.30
epoch train time: 0:00:00.175445
elapsed time: 0:00:39.255949
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 17:01:01.685889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.51
 ---- batch: 020 ----
mean loss: 60.52
 ---- batch: 030 ----
mean loss: 61.12
train mean loss: 61.35
epoch train time: 0:00:00.174743
elapsed time: 0:00:39.430833
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 17:01:01.860770
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.71
 ---- batch: 020 ----
mean loss: 63.42
 ---- batch: 030 ----
mean loss: 61.77
train mean loss: 62.84
epoch train time: 0:00:00.167292
elapsed time: 0:00:39.598270
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 17:01:02.028204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.41
 ---- batch: 020 ----
mean loss: 62.53
 ---- batch: 030 ----
mean loss: 59.50
train mean loss: 60.87
epoch train time: 0:00:00.173619
elapsed time: 0:00:39.772039
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 17:01:02.201980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.26
 ---- batch: 020 ----
mean loss: 59.24
 ---- batch: 030 ----
mean loss: 58.70
train mean loss: 60.59
epoch train time: 0:00:00.176393
elapsed time: 0:00:39.948585
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 17:01:02.378521
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.42
 ---- batch: 020 ----
mean loss: 58.33
 ---- batch: 030 ----
mean loss: 63.35
train mean loss: 61.26
epoch train time: 0:00:00.173556
elapsed time: 0:00:40.122277
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 17:01:02.552213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.16
 ---- batch: 020 ----
mean loss: 59.46
 ---- batch: 030 ----
mean loss: 59.96
train mean loss: 61.57
epoch train time: 0:00:00.175206
elapsed time: 0:00:40.297615
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 17:01:02.727579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.85
 ---- batch: 020 ----
mean loss: 59.98
 ---- batch: 030 ----
mean loss: 62.29
train mean loss: 60.42
epoch train time: 0:00:00.177395
elapsed time: 0:00:40.475174
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 17:01:02.905114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.27
 ---- batch: 020 ----
mean loss: 61.34
 ---- batch: 030 ----
mean loss: 58.96
train mean loss: 60.23
epoch train time: 0:00:00.176591
elapsed time: 0:00:40.651966
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 17:01:03.081920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.12
 ---- batch: 020 ----
mean loss: 59.54
 ---- batch: 030 ----
mean loss: 59.22
train mean loss: 60.39
epoch train time: 0:00:00.172697
elapsed time: 0:00:40.824818
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 17:01:03.254757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.42
 ---- batch: 020 ----
mean loss: 57.40
 ---- batch: 030 ----
mean loss: 61.90
train mean loss: 59.86
epoch train time: 0:00:00.174904
elapsed time: 0:00:40.999863
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 17:01:03.429815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.24
 ---- batch: 020 ----
mean loss: 59.54
 ---- batch: 030 ----
mean loss: 58.23
train mean loss: 59.73
epoch train time: 0:00:00.175689
elapsed time: 0:00:41.175703
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 17:01:03.605667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.87
 ---- batch: 020 ----
mean loss: 59.60
 ---- batch: 030 ----
mean loss: 63.14
train mean loss: 61.52
epoch train time: 0:00:00.175670
elapsed time: 0:00:41.351546
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 17:01:03.781501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.68
 ---- batch: 020 ----
mean loss: 58.30
 ---- batch: 030 ----
mean loss: 58.23
train mean loss: 60.04
epoch train time: 0:00:00.175584
elapsed time: 0:00:41.527285
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 17:01:03.957224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.04
 ---- batch: 020 ----
mean loss: 62.29
 ---- batch: 030 ----
mean loss: 59.24
train mean loss: 59.68
epoch train time: 0:00:00.176611
elapsed time: 0:00:41.704037
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 17:01:04.133975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.00
 ---- batch: 020 ----
mean loss: 60.12
 ---- batch: 030 ----
mean loss: 59.63
train mean loss: 59.80
epoch train time: 0:00:00.172991
elapsed time: 0:00:41.877196
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 17:01:04.307134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.86
 ---- batch: 020 ----
mean loss: 60.78
 ---- batch: 030 ----
mean loss: 60.50
train mean loss: 61.51
epoch train time: 0:00:00.175152
elapsed time: 0:00:42.052518
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 17:01:04.482457
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.92
 ---- batch: 020 ----
mean loss: 57.90
 ---- batch: 030 ----
mean loss: 59.26
train mean loss: 59.59
epoch train time: 0:00:00.173171
elapsed time: 0:00:42.225829
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 17:01:04.655786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.78
 ---- batch: 020 ----
mean loss: 60.72
 ---- batch: 030 ----
mean loss: 59.35
train mean loss: 59.55
epoch train time: 0:00:00.180880
elapsed time: 0:00:42.406890
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 17:01:04.836818
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.48
 ---- batch: 020 ----
mean loss: 60.80
 ---- batch: 030 ----
mean loss: 60.31
train mean loss: 59.02
epoch train time: 0:00:00.174033
elapsed time: 0:00:42.581583
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 17:01:05.011539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.02
 ---- batch: 020 ----
mean loss: 57.82
 ---- batch: 030 ----
mean loss: 59.40
train mean loss: 59.33
epoch train time: 0:00:00.168108
elapsed time: 0:00:42.749845
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 17:01:05.179794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.40
 ---- batch: 020 ----
mean loss: 57.67
 ---- batch: 030 ----
mean loss: 60.92
train mean loss: 59.45
epoch train time: 0:00:00.170390
elapsed time: 0:00:42.920386
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 17:01:05.350341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.09
 ---- batch: 020 ----
mean loss: 58.71
 ---- batch: 030 ----
mean loss: 61.83
train mean loss: 59.71
epoch train time: 0:00:00.173913
elapsed time: 0:00:43.094448
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 17:01:05.524383
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.83
 ---- batch: 020 ----
mean loss: 58.92
 ---- batch: 030 ----
mean loss: 57.10
train mean loss: 58.36
epoch train time: 0:00:00.171188
elapsed time: 0:00:43.265773
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 17:01:05.695710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.43
 ---- batch: 020 ----
mean loss: 57.48
 ---- batch: 030 ----
mean loss: 58.72
train mean loss: 58.42
epoch train time: 0:00:00.173513
elapsed time: 0:00:43.439432
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 17:01:05.869366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.11
 ---- batch: 020 ----
mean loss: 58.86
 ---- batch: 030 ----
mean loss: 58.31
train mean loss: 58.00
epoch train time: 0:00:00.174368
elapsed time: 0:00:43.613935
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 17:01:06.043872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.93
 ---- batch: 020 ----
mean loss: 61.39
 ---- batch: 030 ----
mean loss: 58.57
train mean loss: 58.84
epoch train time: 0:00:00.169641
elapsed time: 0:00:43.783784
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 17:01:06.213725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.01
 ---- batch: 020 ----
mean loss: 61.31
 ---- batch: 030 ----
mean loss: 56.95
train mean loss: 57.63
epoch train time: 0:00:00.173198
elapsed time: 0:00:43.957130
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 17:01:06.387070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.38
 ---- batch: 020 ----
mean loss: 57.65
 ---- batch: 030 ----
mean loss: 60.55
train mean loss: 58.36
epoch train time: 0:00:00.173066
elapsed time: 0:00:44.130332
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 17:01:06.560267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.69
 ---- batch: 020 ----
mean loss: 58.24
 ---- batch: 030 ----
mean loss: 58.72
train mean loss: 57.62
epoch train time: 0:00:00.177126
elapsed time: 0:00:44.307620
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 17:01:06.737557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.96
 ---- batch: 020 ----
mean loss: 57.69
 ---- batch: 030 ----
mean loss: 56.90
train mean loss: 58.19
epoch train time: 0:00:00.171186
elapsed time: 0:00:44.478939
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 17:01:06.908875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.54
 ---- batch: 020 ----
mean loss: 60.12
 ---- batch: 030 ----
mean loss: 58.83
train mean loss: 60.04
epoch train time: 0:00:00.173770
elapsed time: 0:00:44.652859
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 17:01:07.082795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.79
 ---- batch: 020 ----
mean loss: 57.01
 ---- batch: 030 ----
mean loss: 59.99
train mean loss: 57.95
epoch train time: 0:00:00.169816
elapsed time: 0:00:44.822808
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 17:01:07.252744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.11
 ---- batch: 020 ----
mean loss: 56.71
 ---- batch: 030 ----
mean loss: 57.51
train mean loss: 57.35
epoch train time: 0:00:00.170580
elapsed time: 0:00:44.993520
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 17:01:07.423455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.98
 ---- batch: 020 ----
mean loss: 56.19
 ---- batch: 030 ----
mean loss: 58.81
train mean loss: 57.26
epoch train time: 0:00:00.176386
elapsed time: 0:00:45.170041
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 17:01:07.599978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.87
 ---- batch: 020 ----
mean loss: 55.60
 ---- batch: 030 ----
mean loss: 57.21
train mean loss: 56.96
epoch train time: 0:00:00.187263
elapsed time: 0:00:45.357449
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 17:01:07.787425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.24
 ---- batch: 020 ----
mean loss: 55.71
 ---- batch: 030 ----
mean loss: 57.43
train mean loss: 56.71
epoch train time: 0:00:00.180831
elapsed time: 0:00:45.538458
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 17:01:07.968396
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.71
 ---- batch: 020 ----
mean loss: 56.81
 ---- batch: 030 ----
mean loss: 60.49
train mean loss: 57.36
epoch train time: 0:00:00.177944
elapsed time: 0:00:45.716545
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 17:01:08.146484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.08
 ---- batch: 020 ----
mean loss: 58.88
 ---- batch: 030 ----
mean loss: 56.30
train mean loss: 56.89
epoch train time: 0:00:00.174504
elapsed time: 0:00:45.891189
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 17:01:08.321140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.29
 ---- batch: 020 ----
mean loss: 57.32
 ---- batch: 030 ----
mean loss: 58.06
train mean loss: 57.32
epoch train time: 0:00:00.171935
elapsed time: 0:00:46.063296
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 17:01:08.493235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.88
 ---- batch: 020 ----
mean loss: 59.18
 ---- batch: 030 ----
mean loss: 58.45
train mean loss: 58.45
epoch train time: 0:00:00.178946
elapsed time: 0:00:46.242394
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 17:01:08.672340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.65
 ---- batch: 020 ----
mean loss: 59.26
 ---- batch: 030 ----
mean loss: 53.88
train mean loss: 56.78
epoch train time: 0:00:00.173643
elapsed time: 0:00:46.416184
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 17:01:08.846121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.07
 ---- batch: 020 ----
mean loss: 57.36
 ---- batch: 030 ----
mean loss: 55.51
train mean loss: 56.37
epoch train time: 0:00:00.171819
elapsed time: 0:00:46.588142
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 17:01:09.018080
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.81
 ---- batch: 020 ----
mean loss: 56.50
 ---- batch: 030 ----
mean loss: 56.14
train mean loss: 56.08
epoch train time: 0:00:00.164315
elapsed time: 0:00:46.752602
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 17:01:09.182539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.29
 ---- batch: 020 ----
mean loss: 53.47
 ---- batch: 030 ----
mean loss: 57.80
train mean loss: 56.62
epoch train time: 0:00:00.164598
elapsed time: 0:00:46.917335
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 17:01:09.347272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.88
 ---- batch: 020 ----
mean loss: 56.06
 ---- batch: 030 ----
mean loss: 57.33
train mean loss: 56.83
epoch train time: 0:00:00.166642
elapsed time: 0:00:47.084117
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 17:01:09.514056
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.81
 ---- batch: 020 ----
mean loss: 56.31
 ---- batch: 030 ----
mean loss: 56.13
train mean loss: 55.03
epoch train time: 0:00:00.164086
elapsed time: 0:00:47.248362
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 17:01:09.678289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.52
 ---- batch: 020 ----
mean loss: 55.51
 ---- batch: 030 ----
mean loss: 54.70
train mean loss: 54.79
epoch train time: 0:00:00.171442
elapsed time: 0:00:47.419955
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 17:01:09.849894
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.04
 ---- batch: 020 ----
mean loss: 53.42
 ---- batch: 030 ----
mean loss: 55.31
train mean loss: 54.98
epoch train time: 0:00:00.165218
elapsed time: 0:00:47.585786
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 17:01:10.015734
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.94
 ---- batch: 020 ----
mean loss: 53.36
 ---- batch: 030 ----
mean loss: 54.71
train mean loss: 54.73
epoch train time: 0:00:00.164402
elapsed time: 0:00:47.750336
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 17:01:10.180289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.85
 ---- batch: 020 ----
mean loss: 55.48
 ---- batch: 030 ----
mean loss: 54.20
train mean loss: 54.86
epoch train time: 0:00:00.164003
elapsed time: 0:00:47.914490
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 17:01:10.344427
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.62
 ---- batch: 020 ----
mean loss: 54.65
 ---- batch: 030 ----
mean loss: 54.08
train mean loss: 54.67
epoch train time: 0:00:00.164279
elapsed time: 0:00:48.078907
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 17:01:10.508843
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.26
 ---- batch: 020 ----
mean loss: 55.23
 ---- batch: 030 ----
mean loss: 54.82
train mean loss: 54.70
epoch train time: 0:00:00.165025
elapsed time: 0:00:48.244070
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 17:01:10.674007
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.20
 ---- batch: 020 ----
mean loss: 53.60
 ---- batch: 030 ----
mean loss: 53.76
train mean loss: 54.73
epoch train time: 0:00:00.169365
elapsed time: 0:00:48.413585
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 17:01:10.843523
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.07
 ---- batch: 020 ----
mean loss: 55.19
 ---- batch: 030 ----
mean loss: 53.66
train mean loss: 54.60
epoch train time: 0:00:00.168586
elapsed time: 0:00:48.582312
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 17:01:11.012251
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.29
 ---- batch: 020 ----
mean loss: 55.04
 ---- batch: 030 ----
mean loss: 55.96
train mean loss: 54.78
epoch train time: 0:00:00.168681
elapsed time: 0:00:48.751132
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 17:01:11.181068
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.54
 ---- batch: 020 ----
mean loss: 53.11
 ---- batch: 030 ----
mean loss: 53.01
train mean loss: 54.51
epoch train time: 0:00:00.166949
elapsed time: 0:00:48.918219
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 17:01:11.348155
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.81
 ---- batch: 020 ----
mean loss: 56.25
 ---- batch: 030 ----
mean loss: 55.20
train mean loss: 54.59
epoch train time: 0:00:00.168913
elapsed time: 0:00:49.087270
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 17:01:11.517226
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.83
 ---- batch: 020 ----
mean loss: 52.22
 ---- batch: 030 ----
mean loss: 55.14
train mean loss: 54.68
epoch train time: 0:00:00.166749
elapsed time: 0:00:49.254177
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 17:01:11.684115
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.21
 ---- batch: 020 ----
mean loss: 55.04
 ---- batch: 030 ----
mean loss: 53.50
train mean loss: 54.71
epoch train time: 0:00:00.177063
elapsed time: 0:00:49.431382
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 17:01:11.861322
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.19
 ---- batch: 020 ----
mean loss: 54.51
 ---- batch: 030 ----
mean loss: 57.14
train mean loss: 54.46
epoch train time: 0:00:00.173272
elapsed time: 0:00:49.604794
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 17:01:12.034730
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.16
 ---- batch: 020 ----
mean loss: 55.49
 ---- batch: 030 ----
mean loss: 53.55
train mean loss: 54.65
epoch train time: 0:00:00.176234
elapsed time: 0:00:49.781176
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 17:01:12.211113
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.97
 ---- batch: 020 ----
mean loss: 56.04
 ---- batch: 030 ----
mean loss: 56.08
train mean loss: 54.50
epoch train time: 0:00:00.176985
elapsed time: 0:00:49.958299
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 17:01:12.388257
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.41
 ---- batch: 020 ----
mean loss: 54.61
 ---- batch: 030 ----
mean loss: 52.51
train mean loss: 54.58
epoch train time: 0:00:00.174426
elapsed time: 0:00:50.132884
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 17:01:12.562822
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.10
 ---- batch: 020 ----
mean loss: 54.66
 ---- batch: 030 ----
mean loss: 55.64
train mean loss: 54.53
epoch train time: 0:00:00.178748
elapsed time: 0:00:50.311794
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 17:01:12.741738
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.47
 ---- batch: 020 ----
mean loss: 55.21
 ---- batch: 030 ----
mean loss: 56.90
train mean loss: 54.62
epoch train time: 0:00:00.177069
elapsed time: 0:00:50.489040
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 17:01:12.918995
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.70
 ---- batch: 020 ----
mean loss: 54.80
 ---- batch: 030 ----
mean loss: 55.37
train mean loss: 54.52
epoch train time: 0:00:00.177786
elapsed time: 0:00:50.666983
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 17:01:13.096921
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.92
 ---- batch: 020 ----
mean loss: 54.55
 ---- batch: 030 ----
mean loss: 53.80
train mean loss: 54.53
epoch train time: 0:00:00.173863
elapsed time: 0:00:50.840984
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 17:01:13.270932
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.95
 ---- batch: 020 ----
mean loss: 53.33
 ---- batch: 030 ----
mean loss: 56.84
train mean loss: 54.45
epoch train time: 0:00:00.176882
elapsed time: 0:00:51.018017
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 17:01:13.447956
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.90
 ---- batch: 020 ----
mean loss: 53.02
 ---- batch: 030 ----
mean loss: 54.83
train mean loss: 54.47
epoch train time: 0:00:00.176348
elapsed time: 0:00:51.194513
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 17:01:13.624450
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.67
 ---- batch: 020 ----
mean loss: 53.40
 ---- batch: 030 ----
mean loss: 54.60
train mean loss: 54.39
epoch train time: 0:00:00.180216
elapsed time: 0:00:51.374871
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 17:01:13.804812
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.27
 ---- batch: 020 ----
mean loss: 53.73
 ---- batch: 030 ----
mean loss: 53.59
train mean loss: 54.34
epoch train time: 0:00:00.177327
elapsed time: 0:00:51.552354
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 17:01:13.982292
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.39
 ---- batch: 020 ----
mean loss: 56.90
 ---- batch: 030 ----
mean loss: 52.90
train mean loss: 54.36
epoch train time: 0:00:00.176320
elapsed time: 0:00:51.728831
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 17:01:14.158769
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.34
 ---- batch: 020 ----
mean loss: 54.47
 ---- batch: 030 ----
mean loss: 54.47
train mean loss: 54.34
epoch train time: 0:00:00.174825
elapsed time: 0:00:51.903817
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 17:01:14.333755
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.44
 ---- batch: 020 ----
mean loss: 53.64
 ---- batch: 030 ----
mean loss: 53.92
train mean loss: 54.19
epoch train time: 0:00:00.175101
elapsed time: 0:00:52.079060
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 17:01:14.508998
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.38
 ---- batch: 020 ----
mean loss: 56.49
 ---- batch: 030 ----
mean loss: 53.69
train mean loss: 54.37
epoch train time: 0:00:00.177486
elapsed time: 0:00:52.256708
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 17:01:14.686687
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.69
 ---- batch: 020 ----
mean loss: 53.51
 ---- batch: 030 ----
mean loss: 54.55
train mean loss: 54.24
epoch train time: 0:00:00.186646
elapsed time: 0:00:52.443537
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 17:01:14.873500
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.45
 ---- batch: 020 ----
mean loss: 56.37
 ---- batch: 030 ----
mean loss: 52.70
train mean loss: 54.13
epoch train time: 0:00:00.176295
elapsed time: 0:00:52.619997
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 17:01:15.049937
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.46
 ---- batch: 020 ----
mean loss: 54.20
 ---- batch: 030 ----
mean loss: 52.94
train mean loss: 54.29
epoch train time: 0:00:00.177911
elapsed time: 0:00:52.798072
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 17:01:15.228002
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.40
 ---- batch: 020 ----
mean loss: 55.37
 ---- batch: 030 ----
mean loss: 52.24
train mean loss: 54.33
epoch train time: 0:00:00.181466
elapsed time: 0:00:52.979700
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 17:01:15.409663
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.05
 ---- batch: 020 ----
mean loss: 54.56
 ---- batch: 030 ----
mean loss: 52.28
train mean loss: 54.22
epoch train time: 0:00:00.179431
elapsed time: 0:00:53.159294
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 17:01:15.589233
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.80
 ---- batch: 020 ----
mean loss: 53.66
 ---- batch: 030 ----
mean loss: 54.71
train mean loss: 54.16
epoch train time: 0:00:00.176059
elapsed time: 0:00:53.335515
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 17:01:15.765486
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.90
 ---- batch: 020 ----
mean loss: 53.93
 ---- batch: 030 ----
mean loss: 53.72
train mean loss: 54.20
epoch train time: 0:00:00.182645
elapsed time: 0:00:53.518350
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 17:01:15.948336
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.59
 ---- batch: 020 ----
mean loss: 53.60
 ---- batch: 030 ----
mean loss: 53.45
train mean loss: 54.12
epoch train time: 0:00:00.178545
elapsed time: 0:00:53.697098
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 17:01:16.127036
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.30
 ---- batch: 020 ----
mean loss: 54.02
 ---- batch: 030 ----
mean loss: 51.99
train mean loss: 54.23
epoch train time: 0:00:00.182205
elapsed time: 0:00:53.879453
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 17:01:16.309392
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.71
 ---- batch: 020 ----
mean loss: 54.89
 ---- batch: 030 ----
mean loss: 53.71
train mean loss: 54.39
epoch train time: 0:00:00.177650
elapsed time: 0:00:54.057243
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 17:01:16.487181
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.84
 ---- batch: 020 ----
mean loss: 53.39
 ---- batch: 030 ----
mean loss: 56.02
train mean loss: 54.07
epoch train time: 0:00:00.178453
elapsed time: 0:00:54.235837
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 17:01:16.665777
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 55.18
 ---- batch: 020 ----
mean loss: 54.58
 ---- batch: 030 ----
mean loss: 52.27
train mean loss: 54.11
epoch train time: 0:00:00.182067
elapsed time: 0:00:54.418064
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 17:01:16.848002
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.01
 ---- batch: 020 ----
mean loss: 54.22
 ---- batch: 030 ----
mean loss: 53.73
train mean loss: 54.06
epoch train time: 0:00:00.172524
elapsed time: 0:00:54.590727
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 17:01:17.020663
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.92
 ---- batch: 020 ----
mean loss: 54.91
 ---- batch: 030 ----
mean loss: 54.71
train mean loss: 53.97
epoch train time: 0:00:00.175550
elapsed time: 0:00:54.766412
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 17:01:17.196347
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.69
 ---- batch: 020 ----
mean loss: 53.91
 ---- batch: 030 ----
mean loss: 54.90
train mean loss: 53.96
epoch train time: 0:00:00.172380
elapsed time: 0:00:54.938925
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 17:01:17.368884
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.35
 ---- batch: 020 ----
mean loss: 52.98
 ---- batch: 030 ----
mean loss: 53.09
train mean loss: 53.88
epoch train time: 0:00:00.175709
elapsed time: 0:00:55.114840
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 17:01:17.544791
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 54.80
 ---- batch: 020 ----
mean loss: 52.78
 ---- batch: 030 ----
mean loss: 53.54
train mean loss: 53.89
epoch train time: 0:00:00.181569
elapsed time: 0:00:55.296608
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 17:01:17.726556
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 56.94
 ---- batch: 020 ----
mean loss: 53.20
 ---- batch: 030 ----
mean loss: 50.29
train mean loss: 54.06
epoch train time: 0:00:00.176206
elapsed time: 0:00:55.472968
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 17:01:17.902918
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.92
 ---- batch: 020 ----
mean loss: 54.37
 ---- batch: 030 ----
mean loss: 55.83
train mean loss: 54.11
epoch train time: 0:00:00.176851
elapsed time: 0:00:55.653102
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_7/checkpoint.pth.tar
**** end time: 2019-09-27 17:01:18.083009 ****
