Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_4', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 30747
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistConv5Dense1...
Done.
**** start time: 2019-09-27 16:01:07.943122 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 31, 14]             100
              Tanh-2           [-1, 10, 31, 14]               0
            Conv2d-3           [-1, 10, 30, 14]           1,000
              Tanh-4           [-1, 10, 30, 14]               0
            Conv2d-5           [-1, 10, 31, 14]           1,000
              Tanh-6           [-1, 10, 31, 14]               0
            Conv2d-7           [-1, 10, 30, 14]           1,000
              Tanh-8           [-1, 10, 30, 14]               0
            Conv2d-9            [-1, 1, 30, 14]              30
             Tanh-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
          Dropout-12                  [-1, 420]               0
           Linear-13                  [-1, 100]          42,000
           Linear-14                    [-1, 1]             100
================================================================
Total params: 45,230
Trainable params: 45,230
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:01:07.951263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3729.90
 ---- batch: 020 ----
mean loss: 1459.41
 ---- batch: 030 ----
mean loss: 683.30
train mean loss: 1763.49
epoch train time: 0:00:12.939596
elapsed time: 0:00:12.950307
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:01:20.893473
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 449.03
 ---- batch: 020 ----
mean loss: 395.98
 ---- batch: 030 ----
mean loss: 359.81
train mean loss: 397.29
epoch train time: 0:00:01.504715
elapsed time: 0:00:14.455191
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:01:22.398381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.81
 ---- batch: 020 ----
mean loss: 345.24
 ---- batch: 030 ----
mean loss: 336.50
train mean loss: 342.43
epoch train time: 0:00:01.428983
elapsed time: 0:00:15.884370
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:01:23.827550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.85
 ---- batch: 020 ----
mean loss: 316.14
 ---- batch: 030 ----
mean loss: 305.64
train mean loss: 313.09
epoch train time: 0:00:01.432258
elapsed time: 0:00:17.316833
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:01:25.260013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 285.30
 ---- batch: 020 ----
mean loss: 287.52
 ---- batch: 030 ----
mean loss: 281.22
train mean loss: 283.98
epoch train time: 0:00:01.433426
elapsed time: 0:00:18.750463
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:01:26.693677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.89
 ---- batch: 020 ----
mean loss: 255.59
 ---- batch: 030 ----
mean loss: 252.06
train mean loss: 249.19
epoch train time: 0:00:01.428657
elapsed time: 0:00:20.179345
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:01:28.122525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.33
 ---- batch: 020 ----
mean loss: 231.36
 ---- batch: 030 ----
mean loss: 225.64
train mean loss: 231.42
epoch train time: 0:00:01.435523
elapsed time: 0:00:21.615065
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:01:29.558244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.27
 ---- batch: 020 ----
mean loss: 222.66
 ---- batch: 030 ----
mean loss: 226.67
train mean loss: 224.29
epoch train time: 0:00:01.436257
elapsed time: 0:00:23.051522
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:01:30.994718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.60
 ---- batch: 020 ----
mean loss: 211.68
 ---- batch: 030 ----
mean loss: 221.48
train mean loss: 217.78
epoch train time: 0:00:01.436153
elapsed time: 0:00:24.487876
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:01:32.431072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.89
 ---- batch: 020 ----
mean loss: 209.64
 ---- batch: 030 ----
mean loss: 215.63
train mean loss: 211.95
epoch train time: 0:00:01.429466
elapsed time: 0:00:25.917601
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:01:33.860792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.18
 ---- batch: 020 ----
mean loss: 203.04
 ---- batch: 030 ----
mean loss: 206.97
train mean loss: 207.71
epoch train time: 0:00:01.439166
elapsed time: 0:00:27.357018
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:01:35.300196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 200.82
 ---- batch: 020 ----
mean loss: 206.30
 ---- batch: 030 ----
mean loss: 201.18
train mean loss: 202.50
epoch train time: 0:00:01.434910
elapsed time: 0:00:28.792108
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:01:36.735290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.15
 ---- batch: 020 ----
mean loss: 202.39
 ---- batch: 030 ----
mean loss: 197.58
train mean loss: 200.03
epoch train time: 0:00:01.434345
elapsed time: 0:00:30.226655
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:01:38.169830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.05
 ---- batch: 020 ----
mean loss: 194.46
 ---- batch: 030 ----
mean loss: 194.99
train mean loss: 196.09
epoch train time: 0:00:01.436826
elapsed time: 0:00:31.663646
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:01:39.606840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.01
 ---- batch: 020 ----
mean loss: 191.14
 ---- batch: 030 ----
mean loss: 192.61
train mean loss: 191.27
epoch train time: 0:00:01.444617
elapsed time: 0:00:33.108455
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:01:41.051633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.00
 ---- batch: 020 ----
mean loss: 187.85
 ---- batch: 030 ----
mean loss: 185.30
train mean loss: 186.79
epoch train time: 0:00:01.434414
elapsed time: 0:00:34.543044
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:01:42.486225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.43
 ---- batch: 020 ----
mean loss: 186.31
 ---- batch: 030 ----
mean loss: 193.34
train mean loss: 188.40
epoch train time: 0:00:01.437998
elapsed time: 0:00:35.981247
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:01:43.924435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.82
 ---- batch: 020 ----
mean loss: 184.76
 ---- batch: 030 ----
mean loss: 186.10
train mean loss: 185.67
epoch train time: 0:00:01.434730
elapsed time: 0:00:37.416197
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:01:45.359387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.75
 ---- batch: 020 ----
mean loss: 183.69
 ---- batch: 030 ----
mean loss: 184.93
train mean loss: 188.27
epoch train time: 0:00:01.435567
elapsed time: 0:00:38.851959
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:01:46.795138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.40
 ---- batch: 020 ----
mean loss: 192.23
 ---- batch: 030 ----
mean loss: 194.31
train mean loss: 191.16
epoch train time: 0:00:01.433149
elapsed time: 0:00:40.285278
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:01:48.228461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.45
 ---- batch: 020 ----
mean loss: 179.13
 ---- batch: 030 ----
mean loss: 176.49
train mean loss: 178.37
epoch train time: 0:00:01.433857
elapsed time: 0:00:41.719346
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:01:49.662536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.68
 ---- batch: 020 ----
mean loss: 175.72
 ---- batch: 030 ----
mean loss: 193.91
train mean loss: 181.70
epoch train time: 0:00:01.436210
elapsed time: 0:00:43.155745
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:01:51.098939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 180.37
 ---- batch: 020 ----
mean loss: 190.50
 ---- batch: 030 ----
mean loss: 179.77
train mean loss: 182.90
epoch train time: 0:00:01.432510
elapsed time: 0:00:44.588448
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:01:52.531629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.85
 ---- batch: 020 ----
mean loss: 187.90
 ---- batch: 030 ----
mean loss: 186.00
train mean loss: 182.23
epoch train time: 0:00:01.434754
elapsed time: 0:00:46.023402
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:01:53.966579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.55
 ---- batch: 020 ----
mean loss: 181.98
 ---- batch: 030 ----
mean loss: 185.38
train mean loss: 180.28
epoch train time: 0:00:01.436555
elapsed time: 0:00:47.460137
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:01:55.403317
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.75
 ---- batch: 020 ----
mean loss: 175.40
 ---- batch: 030 ----
mean loss: 184.03
train mean loss: 179.53
epoch train time: 0:00:01.432165
elapsed time: 0:00:48.892477
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:01:56.835654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.80
 ---- batch: 020 ----
mean loss: 175.29
 ---- batch: 030 ----
mean loss: 179.93
train mean loss: 179.08
epoch train time: 0:00:01.430571
elapsed time: 0:00:50.323232
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:01:58.266413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.54
 ---- batch: 020 ----
mean loss: 169.91
 ---- batch: 030 ----
mean loss: 175.04
train mean loss: 172.91
epoch train time: 0:00:01.432310
elapsed time: 0:00:51.755729
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:01:59.698927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.64
 ---- batch: 020 ----
mean loss: 178.40
 ---- batch: 030 ----
mean loss: 170.33
train mean loss: 175.36
epoch train time: 0:00:01.436606
elapsed time: 0:00:53.192537
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:02:01.135721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.78
 ---- batch: 020 ----
mean loss: 174.24
 ---- batch: 030 ----
mean loss: 178.77
train mean loss: 176.67
epoch train time: 0:00:01.438343
elapsed time: 0:00:54.631067
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:02:02.574245
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 175.90
 ---- batch: 020 ----
mean loss: 178.47
 ---- batch: 030 ----
mean loss: 176.02
train mean loss: 176.02
epoch train time: 0:00:01.434364
elapsed time: 0:00:56.065611
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:02:04.008793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.06
 ---- batch: 020 ----
mean loss: 171.77
 ---- batch: 030 ----
mean loss: 172.49
train mean loss: 171.51
epoch train time: 0:00:01.436859
elapsed time: 0:00:57.502657
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:02:05.445852
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.80
 ---- batch: 020 ----
mean loss: 174.39
 ---- batch: 030 ----
mean loss: 171.11
train mean loss: 171.51
epoch train time: 0:00:01.428896
elapsed time: 0:00:58.931758
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:02:06.874937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.93
 ---- batch: 020 ----
mean loss: 167.37
 ---- batch: 030 ----
mean loss: 168.95
train mean loss: 167.87
epoch train time: 0:00:01.434525
elapsed time: 0:01:00.366447
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:02:08.309648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.98
 ---- batch: 020 ----
mean loss: 164.33
 ---- batch: 030 ----
mean loss: 163.89
train mean loss: 163.96
epoch train time: 0:00:01.431286
elapsed time: 0:01:01.797951
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:02:09.741141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.43
 ---- batch: 020 ----
mean loss: 166.83
 ---- batch: 030 ----
mean loss: 163.98
train mean loss: 166.23
epoch train time: 0:00:01.427028
elapsed time: 0:01:03.225148
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:02:11.168320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.67
 ---- batch: 020 ----
mean loss: 165.02
 ---- batch: 030 ----
mean loss: 168.21
train mean loss: 168.75
epoch train time: 0:00:01.433965
elapsed time: 0:01:04.659266
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:02:12.602449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.63
 ---- batch: 020 ----
mean loss: 161.68
 ---- batch: 030 ----
mean loss: 162.42
train mean loss: 164.15
epoch train time: 0:00:01.436167
elapsed time: 0:01:06.095611
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:02:14.038835
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.41
 ---- batch: 020 ----
mean loss: 151.35
 ---- batch: 030 ----
mean loss: 187.59
train mean loss: 168.61
epoch train time: 0:00:01.431578
elapsed time: 0:01:07.527409
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:02:15.470587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.25
 ---- batch: 020 ----
mean loss: 171.46
 ---- batch: 030 ----
mean loss: 166.45
train mean loss: 171.39
epoch train time: 0:00:01.434888
elapsed time: 0:01:08.962465
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:02:16.905661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.67
 ---- batch: 020 ----
mean loss: 157.79
 ---- batch: 030 ----
mean loss: 161.34
train mean loss: 161.31
epoch train time: 0:00:01.443675
elapsed time: 0:01:10.406342
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:02:18.349520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.03
 ---- batch: 020 ----
mean loss: 158.87
 ---- batch: 030 ----
mean loss: 161.63
train mean loss: 159.17
epoch train time: 0:00:01.437878
elapsed time: 0:01:11.844407
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:02:19.787589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.60
 ---- batch: 020 ----
mean loss: 167.00
 ---- batch: 030 ----
mean loss: 162.43
train mean loss: 163.05
epoch train time: 0:00:01.429281
elapsed time: 0:01:13.273882
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:02:21.217058
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.81
 ---- batch: 020 ----
mean loss: 163.46
 ---- batch: 030 ----
mean loss: 164.44
train mean loss: 166.25
epoch train time: 0:00:01.435776
elapsed time: 0:01:14.709840
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:02:22.653021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.05
 ---- batch: 020 ----
mean loss: 160.56
 ---- batch: 030 ----
mean loss: 160.03
train mean loss: 158.94
epoch train time: 0:00:01.436081
elapsed time: 0:01:16.146097
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:02:24.089276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.04
 ---- batch: 020 ----
mean loss: 164.64
 ---- batch: 030 ----
mean loss: 153.16
train mean loss: 158.56
epoch train time: 0:00:01.432463
elapsed time: 0:01:17.578749
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:02:25.521926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.24
 ---- batch: 020 ----
mean loss: 151.76
 ---- batch: 030 ----
mean loss: 156.38
train mean loss: 155.72
epoch train time: 0:00:01.429204
elapsed time: 0:01:19.008124
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:02:26.951301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.80
 ---- batch: 020 ----
mean loss: 157.29
 ---- batch: 030 ----
mean loss: 161.73
train mean loss: 161.07
epoch train time: 0:00:01.432025
elapsed time: 0:01:20.440319
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:02:28.383496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.04
 ---- batch: 020 ----
mean loss: 158.77
 ---- batch: 030 ----
mean loss: 160.49
train mean loss: 157.31
epoch train time: 0:00:01.434982
elapsed time: 0:01:21.875535
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:02:29.818759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.18
 ---- batch: 020 ----
mean loss: 150.13
 ---- batch: 030 ----
mean loss: 153.93
train mean loss: 152.80
epoch train time: 0:00:01.429522
elapsed time: 0:01:23.305274
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:02:31.248452
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.95
 ---- batch: 020 ----
mean loss: 163.39
 ---- batch: 030 ----
mean loss: 158.18
train mean loss: 161.39
epoch train time: 0:00:01.435089
elapsed time: 0:01:24.740537
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:02:32.683713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.37
 ---- batch: 020 ----
mean loss: 159.10
 ---- batch: 030 ----
mean loss: 157.62
train mean loss: 156.90
epoch train time: 0:00:01.435869
elapsed time: 0:01:26.176574
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:02:34.119755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.64
 ---- batch: 020 ----
mean loss: 152.01
 ---- batch: 030 ----
mean loss: 158.25
train mean loss: 156.64
epoch train time: 0:00:01.432443
elapsed time: 0:01:27.609191
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:02:35.552372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.99
 ---- batch: 020 ----
mean loss: 163.70
 ---- batch: 030 ----
mean loss: 148.31
train mean loss: 162.20
epoch train time: 0:00:01.432571
elapsed time: 0:01:29.041957
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:02:36.985151
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.62
 ---- batch: 020 ----
mean loss: 158.01
 ---- batch: 030 ----
mean loss: 151.97
train mean loss: 156.74
epoch train time: 0:00:01.435024
elapsed time: 0:01:30.477171
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:02:38.420350
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.05
 ---- batch: 020 ----
mean loss: 152.35
 ---- batch: 030 ----
mean loss: 151.03
train mean loss: 150.80
epoch train time: 0:00:01.435942
elapsed time: 0:01:31.913335
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:02:39.856550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.63
 ---- batch: 020 ----
mean loss: 151.30
 ---- batch: 030 ----
mean loss: 152.82
train mean loss: 151.56
epoch train time: 0:00:01.432381
elapsed time: 0:01:33.345917
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:02:41.289091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.17
 ---- batch: 020 ----
mean loss: 156.32
 ---- batch: 030 ----
mean loss: 146.71
train mean loss: 150.59
epoch train time: 0:00:01.438263
elapsed time: 0:01:34.784353
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:02:42.727530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.64
 ---- batch: 020 ----
mean loss: 154.44
 ---- batch: 030 ----
mean loss: 147.66
train mean loss: 150.10
epoch train time: 0:00:01.434470
elapsed time: 0:01:36.219016
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:02:44.162195
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.92
 ---- batch: 020 ----
mean loss: 148.19
 ---- batch: 030 ----
mean loss: 155.65
train mean loss: 154.98
epoch train time: 0:00:01.435627
elapsed time: 0:01:37.654827
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:02:45.598013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 157.51
 ---- batch: 020 ----
mean loss: 149.86
 ---- batch: 030 ----
mean loss: 148.24
train mean loss: 151.99
epoch train time: 0:00:01.436347
elapsed time: 0:01:39.091394
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:02:47.034587
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.91
 ---- batch: 020 ----
mean loss: 152.86
 ---- batch: 030 ----
mean loss: 152.51
train mean loss: 152.01
epoch train time: 0:00:01.433396
elapsed time: 0:01:40.525004
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:02:48.468201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.79
 ---- batch: 020 ----
mean loss: 154.47
 ---- batch: 030 ----
mean loss: 153.74
train mean loss: 154.70
epoch train time: 0:00:01.435636
elapsed time: 0:01:41.960909
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:02:49.904116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.02
 ---- batch: 020 ----
mean loss: 159.65
 ---- batch: 030 ----
mean loss: 155.76
train mean loss: 155.17
epoch train time: 0:00:01.431797
elapsed time: 0:01:43.392911
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:02:51.336106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.99
 ---- batch: 020 ----
mean loss: 154.71
 ---- batch: 030 ----
mean loss: 148.09
train mean loss: 149.40
epoch train time: 0:00:01.435254
elapsed time: 0:01:44.828385
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:02:52.771567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.37
 ---- batch: 020 ----
mean loss: 146.64
 ---- batch: 030 ----
mean loss: 150.05
train mean loss: 148.46
epoch train time: 0:00:01.432442
elapsed time: 0:01:46.260994
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:02:54.204183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.96
 ---- batch: 020 ----
mean loss: 148.29
 ---- batch: 030 ----
mean loss: 146.34
train mean loss: 146.92
epoch train time: 0:00:01.427907
elapsed time: 0:01:47.689092
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:02:55.632272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.90
 ---- batch: 020 ----
mean loss: 148.02
 ---- batch: 030 ----
mean loss: 149.58
train mean loss: 147.77
epoch train time: 0:00:01.434564
elapsed time: 0:01:49.123829
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:02:57.067006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.95
 ---- batch: 020 ----
mean loss: 146.28
 ---- batch: 030 ----
mean loss: 150.54
train mean loss: 150.76
epoch train time: 0:00:01.429189
elapsed time: 0:01:50.553181
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:02:58.496358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.03
 ---- batch: 020 ----
mean loss: 146.30
 ---- batch: 030 ----
mean loss: 147.37
train mean loss: 145.36
epoch train time: 0:00:01.436367
elapsed time: 0:01:51.989713
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:02:59.932904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.12
 ---- batch: 020 ----
mean loss: 152.82
 ---- batch: 030 ----
mean loss: 147.84
train mean loss: 149.78
epoch train time: 0:00:01.429797
elapsed time: 0:01:53.419686
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:03:01.362864
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.55
 ---- batch: 020 ----
mean loss: 148.34
 ---- batch: 030 ----
mean loss: 148.13
train mean loss: 149.64
epoch train time: 0:00:01.432441
elapsed time: 0:01:54.852314
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:03:02.795511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.31
 ---- batch: 020 ----
mean loss: 148.17
 ---- batch: 030 ----
mean loss: 148.63
train mean loss: 146.48
epoch train time: 0:00:01.429157
elapsed time: 0:01:56.281703
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:03:04.224879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.13
 ---- batch: 020 ----
mean loss: 150.50
 ---- batch: 030 ----
mean loss: 148.77
train mean loss: 146.88
epoch train time: 0:00:01.431616
elapsed time: 0:01:57.713484
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:03:05.656663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.15
 ---- batch: 020 ----
mean loss: 141.85
 ---- batch: 030 ----
mean loss: 149.31
train mean loss: 147.34
epoch train time: 0:00:01.427644
elapsed time: 0:01:59.141324
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:03:07.084538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.46
 ---- batch: 020 ----
mean loss: 145.55
 ---- batch: 030 ----
mean loss: 148.75
train mean loss: 147.11
epoch train time: 0:00:01.435956
elapsed time: 0:02:00.577488
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:03:08.520684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.75
 ---- batch: 020 ----
mean loss: 140.91
 ---- batch: 030 ----
mean loss: 144.14
train mean loss: 145.13
epoch train time: 0:00:01.430216
elapsed time: 0:02:02.007917
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:03:09.951109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.89
 ---- batch: 020 ----
mean loss: 139.44
 ---- batch: 030 ----
mean loss: 150.08
train mean loss: 144.99
epoch train time: 0:00:01.427660
elapsed time: 0:02:03.435770
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:03:11.378962
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.75
 ---- batch: 020 ----
mean loss: 142.04
 ---- batch: 030 ----
mean loss: 143.50
train mean loss: 143.83
epoch train time: 0:00:01.437877
elapsed time: 0:02:04.873864
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:03:12.817054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.99
 ---- batch: 020 ----
mean loss: 142.84
 ---- batch: 030 ----
mean loss: 141.13
train mean loss: 141.32
epoch train time: 0:00:01.435137
elapsed time: 0:02:06.309181
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:03:14.252373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.60
 ---- batch: 020 ----
mean loss: 143.90
 ---- batch: 030 ----
mean loss: 143.50
train mean loss: 142.53
epoch train time: 0:00:01.431797
elapsed time: 0:02:07.741216
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:03:15.684395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.56
 ---- batch: 020 ----
mean loss: 145.71
 ---- batch: 030 ----
mean loss: 150.46
train mean loss: 146.77
epoch train time: 0:00:01.429027
elapsed time: 0:02:09.170417
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:03:17.113596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.54
 ---- batch: 020 ----
mean loss: 151.86
 ---- batch: 030 ----
mean loss: 146.33
train mean loss: 148.79
epoch train time: 0:00:01.433560
elapsed time: 0:02:10.604140
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:03:18.547317
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.54
 ---- batch: 020 ----
mean loss: 142.41
 ---- batch: 030 ----
mean loss: 143.69
train mean loss: 143.17
epoch train time: 0:00:01.427111
elapsed time: 0:02:12.031455
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:03:19.974634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.90
 ---- batch: 020 ----
mean loss: 146.64
 ---- batch: 030 ----
mean loss: 142.30
train mean loss: 142.42
epoch train time: 0:00:01.429890
elapsed time: 0:02:13.461518
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:03:21.404699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.05
 ---- batch: 020 ----
mean loss: 149.20
 ---- batch: 030 ----
mean loss: 141.93
train mean loss: 143.46
epoch train time: 0:00:01.437113
elapsed time: 0:02:14.898849
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:03:22.842032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.24
 ---- batch: 020 ----
mean loss: 148.97
 ---- batch: 030 ----
mean loss: 144.95
train mean loss: 144.60
epoch train time: 0:00:01.439011
elapsed time: 0:02:16.338039
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:03:24.281218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.23
 ---- batch: 020 ----
mean loss: 151.98
 ---- batch: 030 ----
mean loss: 144.96
train mean loss: 148.00
epoch train time: 0:00:01.432597
elapsed time: 0:02:17.770814
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:03:25.713995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.33
 ---- batch: 020 ----
mean loss: 140.61
 ---- batch: 030 ----
mean loss: 139.91
train mean loss: 143.64
epoch train time: 0:00:01.434432
elapsed time: 0:02:19.205432
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:03:27.148635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.20
 ---- batch: 020 ----
mean loss: 147.29
 ---- batch: 030 ----
mean loss: 149.08
train mean loss: 148.27
epoch train time: 0:00:01.432755
elapsed time: 0:02:20.638404
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:03:28.581584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.58
 ---- batch: 020 ----
mean loss: 152.84
 ---- batch: 030 ----
mean loss: 154.43
train mean loss: 147.95
epoch train time: 0:00:01.435671
elapsed time: 0:02:22.074260
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:03:30.017448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.60
 ---- batch: 020 ----
mean loss: 149.35
 ---- batch: 030 ----
mean loss: 148.23
train mean loss: 145.30
epoch train time: 0:00:01.431788
elapsed time: 0:02:23.506263
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:03:31.449440
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.33
 ---- batch: 020 ----
mean loss: 146.38
 ---- batch: 030 ----
mean loss: 143.58
train mean loss: 144.88
epoch train time: 0:00:01.439111
elapsed time: 0:02:24.945578
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:03:32.888778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.19
 ---- batch: 020 ----
mean loss: 139.96
 ---- batch: 030 ----
mean loss: 143.05
train mean loss: 142.28
epoch train time: 0:00:01.444285
elapsed time: 0:02:26.390061
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:03:34.333240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.58
 ---- batch: 020 ----
mean loss: 138.59
 ---- batch: 030 ----
mean loss: 144.04
train mean loss: 140.80
epoch train time: 0:00:01.429451
elapsed time: 0:02:27.819693
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:03:35.762873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.56
 ---- batch: 020 ----
mean loss: 141.19
 ---- batch: 030 ----
mean loss: 141.68
train mean loss: 143.56
epoch train time: 0:00:01.434880
elapsed time: 0:02:29.254764
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:03:37.197944
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.21
 ---- batch: 020 ----
mean loss: 140.99
 ---- batch: 030 ----
mean loss: 144.85
train mean loss: 142.24
epoch train time: 0:00:01.444239
elapsed time: 0:02:30.699223
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:03:38.642421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.92
 ---- batch: 020 ----
mean loss: 147.63
 ---- batch: 030 ----
mean loss: 144.17
train mean loss: 145.82
epoch train time: 0:00:01.441831
elapsed time: 0:02:32.141284
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:03:40.084462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.77
 ---- batch: 020 ----
mean loss: 142.47
 ---- batch: 030 ----
mean loss: 146.47
train mean loss: 144.09
epoch train time: 0:00:01.435431
elapsed time: 0:02:33.576908
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:03:41.520104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.01
 ---- batch: 020 ----
mean loss: 140.40
 ---- batch: 030 ----
mean loss: 142.57
train mean loss: 144.07
epoch train time: 0:00:01.440211
elapsed time: 0:02:35.017329
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:03:42.960522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.26
 ---- batch: 020 ----
mean loss: 141.47
 ---- batch: 030 ----
mean loss: 139.12
train mean loss: 142.20
epoch train time: 0:00:01.442537
elapsed time: 0:02:36.460048
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:03:44.403241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.27
 ---- batch: 020 ----
mean loss: 140.03
 ---- batch: 030 ----
mean loss: 138.22
train mean loss: 141.44
epoch train time: 0:00:01.434643
elapsed time: 0:02:37.894966
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:03:45.838145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.29
 ---- batch: 020 ----
mean loss: 148.03
 ---- batch: 030 ----
mean loss: 143.74
train mean loss: 143.93
epoch train time: 0:00:01.437618
elapsed time: 0:02:39.332768
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:03:47.275983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.71
 ---- batch: 020 ----
mean loss: 149.01
 ---- batch: 030 ----
mean loss: 143.08
train mean loss: 144.25
epoch train time: 0:00:01.437705
elapsed time: 0:02:40.770735
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:03:48.713932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.54
 ---- batch: 020 ----
mean loss: 145.05
 ---- batch: 030 ----
mean loss: 143.18
train mean loss: 145.24
epoch train time: 0:00:01.439172
elapsed time: 0:02:42.210113
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:03:50.153293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.31
 ---- batch: 020 ----
mean loss: 145.26
 ---- batch: 030 ----
mean loss: 155.69
train mean loss: 147.11
epoch train time: 0:00:01.437950
elapsed time: 0:02:43.648250
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:03:51.591447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.77
 ---- batch: 020 ----
mean loss: 142.23
 ---- batch: 030 ----
mean loss: 139.56
train mean loss: 143.60
epoch train time: 0:00:01.441097
elapsed time: 0:02:45.089567
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:03:53.032735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.69
 ---- batch: 020 ----
mean loss: 140.25
 ---- batch: 030 ----
mean loss: 143.09
train mean loss: 142.16
epoch train time: 0:00:01.435982
elapsed time: 0:02:46.525730
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:03:54.468910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.22
 ---- batch: 020 ----
mean loss: 145.95
 ---- batch: 030 ----
mean loss: 143.82
train mean loss: 145.09
epoch train time: 0:00:01.438324
elapsed time: 0:02:47.964252
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:03:55.907430
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.99
 ---- batch: 020 ----
mean loss: 140.41
 ---- batch: 030 ----
mean loss: 146.80
train mean loss: 142.27
epoch train time: 0:00:01.437798
elapsed time: 0:02:49.402228
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:03:57.345405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.36
 ---- batch: 020 ----
mean loss: 137.41
 ---- batch: 030 ----
mean loss: 142.69
train mean loss: 139.84
epoch train time: 0:00:01.435101
elapsed time: 0:02:50.837507
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:03:58.780686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.55
 ---- batch: 020 ----
mean loss: 137.76
 ---- batch: 030 ----
mean loss: 138.32
train mean loss: 140.95
epoch train time: 0:00:01.436679
elapsed time: 0:02:52.274360
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:04:00.217540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.75
 ---- batch: 020 ----
mean loss: 150.33
 ---- batch: 030 ----
mean loss: 145.01
train mean loss: 148.51
epoch train time: 0:00:01.438899
elapsed time: 0:02:53.713450
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:04:01.656630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.03
 ---- batch: 020 ----
mean loss: 142.54
 ---- batch: 030 ----
mean loss: 144.37
train mean loss: 140.30
epoch train time: 0:00:01.435442
elapsed time: 0:02:55.149088
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:04:03.092268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.74
 ---- batch: 020 ----
mean loss: 142.78
 ---- batch: 030 ----
mean loss: 143.83
train mean loss: 141.88
epoch train time: 0:00:01.431254
elapsed time: 0:02:56.580518
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:04:04.523712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.42
 ---- batch: 020 ----
mean loss: 141.90
 ---- batch: 030 ----
mean loss: 140.83
train mean loss: 140.65
epoch train time: 0:00:01.428481
elapsed time: 0:02:58.009202
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:04:05.952397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.93
 ---- batch: 020 ----
mean loss: 145.09
 ---- batch: 030 ----
mean loss: 144.14
train mean loss: 143.08
epoch train time: 0:00:01.437411
elapsed time: 0:02:59.446826
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:04:07.390023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.80
 ---- batch: 020 ----
mean loss: 141.04
 ---- batch: 030 ----
mean loss: 139.26
train mean loss: 140.42
epoch train time: 0:00:01.436485
elapsed time: 0:03:00.883524
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:04:08.826721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.08
 ---- batch: 020 ----
mean loss: 142.96
 ---- batch: 030 ----
mean loss: 145.27
train mean loss: 145.65
epoch train time: 0:00:01.431119
elapsed time: 0:03:02.314846
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:04:10.258030
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.37
 ---- batch: 020 ----
mean loss: 143.27
 ---- batch: 030 ----
mean loss: 139.73
train mean loss: 141.48
epoch train time: 0:00:01.442877
elapsed time: 0:03:03.757908
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:04:11.701097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.99
 ---- batch: 020 ----
mean loss: 145.00
 ---- batch: 030 ----
mean loss: 138.54
train mean loss: 142.73
epoch train time: 0:00:01.430287
elapsed time: 0:03:05.188377
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:04:13.131556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.13
 ---- batch: 020 ----
mean loss: 141.73
 ---- batch: 030 ----
mean loss: 146.63
train mean loss: 142.25
epoch train time: 0:00:01.428688
elapsed time: 0:03:06.617229
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:04:14.560427
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.70
 ---- batch: 020 ----
mean loss: 145.30
 ---- batch: 030 ----
mean loss: 145.27
train mean loss: 144.97
epoch train time: 0:00:01.430267
elapsed time: 0:03:08.047708
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:04:15.990883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.10
 ---- batch: 020 ----
mean loss: 143.86
 ---- batch: 030 ----
mean loss: 141.05
train mean loss: 143.82
epoch train time: 0:00:01.434400
elapsed time: 0:03:09.482268
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:04:17.425463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.16
 ---- batch: 020 ----
mean loss: 140.07
 ---- batch: 030 ----
mean loss: 139.93
train mean loss: 141.49
epoch train time: 0:00:01.428944
elapsed time: 0:03:10.911404
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:04:18.854584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.77
 ---- batch: 020 ----
mean loss: 138.02
 ---- batch: 030 ----
mean loss: 139.03
train mean loss: 140.22
epoch train time: 0:00:01.430508
elapsed time: 0:03:12.342076
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:04:20.285260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.05
 ---- batch: 020 ----
mean loss: 152.82
 ---- batch: 030 ----
mean loss: 150.15
train mean loss: 149.16
epoch train time: 0:00:01.425621
elapsed time: 0:03:13.767909
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:04:21.711097
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.87
 ---- batch: 020 ----
mean loss: 143.24
 ---- batch: 030 ----
mean loss: 146.77
train mean loss: 143.21
epoch train time: 0:00:01.433152
elapsed time: 0:03:15.201244
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:04:23.144435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.03
 ---- batch: 020 ----
mean loss: 141.91
 ---- batch: 030 ----
mean loss: 140.28
train mean loss: 141.44
epoch train time: 0:00:01.435389
elapsed time: 0:03:16.636862
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:04:24.580044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.90
 ---- batch: 020 ----
mean loss: 141.13
 ---- batch: 030 ----
mean loss: 139.35
train mean loss: 139.57
epoch train time: 0:00:01.434193
elapsed time: 0:03:18.071241
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:04:26.014444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.23
 ---- batch: 020 ----
mean loss: 139.59
 ---- batch: 030 ----
mean loss: 140.50
train mean loss: 140.35
epoch train time: 0:00:01.432130
elapsed time: 0:03:19.503561
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:04:27.446740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.69
 ---- batch: 020 ----
mean loss: 136.43
 ---- batch: 030 ----
mean loss: 140.09
train mean loss: 139.12
epoch train time: 0:00:01.433173
elapsed time: 0:03:20.936905
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:04:28.880083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.67
 ---- batch: 020 ----
mean loss: 142.49
 ---- batch: 030 ----
mean loss: 137.01
train mean loss: 140.29
epoch train time: 0:00:01.429973
elapsed time: 0:03:22.367051
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:04:30.310241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.51
 ---- batch: 020 ----
mean loss: 140.38
 ---- batch: 030 ----
mean loss: 147.36
train mean loss: 141.22
epoch train time: 0:00:01.434051
elapsed time: 0:03:23.801320
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:04:31.744516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.60
 ---- batch: 020 ----
mean loss: 142.44
 ---- batch: 030 ----
mean loss: 143.77
train mean loss: 141.24
epoch train time: 0:00:01.431745
elapsed time: 0:03:25.233260
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:04:33.176436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.66
 ---- batch: 020 ----
mean loss: 137.19
 ---- batch: 030 ----
mean loss: 143.37
train mean loss: 141.73
epoch train time: 0:00:01.431490
elapsed time: 0:03:26.664920
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:04:34.608099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.26
 ---- batch: 020 ----
mean loss: 138.93
 ---- batch: 030 ----
mean loss: 138.17
train mean loss: 140.18
epoch train time: 0:00:01.431123
elapsed time: 0:03:28.096222
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:04:36.039402
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.20
 ---- batch: 020 ----
mean loss: 139.46
 ---- batch: 030 ----
mean loss: 137.09
train mean loss: 137.34
epoch train time: 0:00:01.430901
elapsed time: 0:03:29.527311
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:04:37.470498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.10
 ---- batch: 020 ----
mean loss: 142.17
 ---- batch: 030 ----
mean loss: 136.27
train mean loss: 139.90
epoch train time: 0:00:01.428696
elapsed time: 0:03:30.956185
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:04:38.899361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.03
 ---- batch: 020 ----
mean loss: 139.40
 ---- batch: 030 ----
mean loss: 139.55
train mean loss: 138.19
epoch train time: 0:00:01.429708
elapsed time: 0:03:32.386064
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:04:40.329252
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.86
 ---- batch: 020 ----
mean loss: 144.41
 ---- batch: 030 ----
mean loss: 149.00
train mean loss: 144.38
epoch train time: 0:00:01.433792
elapsed time: 0:03:33.820056
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:04:41.763247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.46
 ---- batch: 020 ----
mean loss: 141.72
 ---- batch: 030 ----
mean loss: 142.22
train mean loss: 146.32
epoch train time: 0:00:01.433786
elapsed time: 0:03:35.254061
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:04:43.197238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.48
 ---- batch: 020 ----
mean loss: 147.98
 ---- batch: 030 ----
mean loss: 151.86
train mean loss: 146.27
epoch train time: 0:00:01.424965
elapsed time: 0:03:36.679334
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:04:44.622537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.10
 ---- batch: 020 ----
mean loss: 145.40
 ---- batch: 030 ----
mean loss: 143.57
train mean loss: 143.95
epoch train time: 0:00:01.433482
elapsed time: 0:03:38.113009
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:04:46.056189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.42
 ---- batch: 020 ----
mean loss: 141.19
 ---- batch: 030 ----
mean loss: 137.93
train mean loss: 141.31
epoch train time: 0:00:01.429793
elapsed time: 0:03:39.542991
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:04:47.486169
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.10
 ---- batch: 020 ----
mean loss: 143.89
 ---- batch: 030 ----
mean loss: 134.30
train mean loss: 140.83
epoch train time: 0:00:01.431309
elapsed time: 0:03:40.974460
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:04:48.917671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.71
 ---- batch: 020 ----
mean loss: 137.49
 ---- batch: 030 ----
mean loss: 143.98
train mean loss: 141.63
epoch train time: 0:00:01.433998
elapsed time: 0:03:42.408683
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:04:50.351865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.51
 ---- batch: 020 ----
mean loss: 146.13
 ---- batch: 030 ----
mean loss: 138.16
train mean loss: 143.35
epoch train time: 0:00:01.431321
elapsed time: 0:03:43.840186
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:04:51.783370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.51
 ---- batch: 020 ----
mean loss: 140.25
 ---- batch: 030 ----
mean loss: 137.54
train mean loss: 139.00
epoch train time: 0:00:01.437807
elapsed time: 0:03:45.278198
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:04:53.221372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.04
 ---- batch: 020 ----
mean loss: 136.72
 ---- batch: 030 ----
mean loss: 135.62
train mean loss: 137.98
epoch train time: 0:00:01.434911
elapsed time: 0:03:46.713293
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:04:54.656486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.61
 ---- batch: 020 ----
mean loss: 143.10
 ---- batch: 030 ----
mean loss: 137.80
train mean loss: 141.87
epoch train time: 0:00:01.431295
elapsed time: 0:03:48.144814
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:04:56.087994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.14
 ---- batch: 020 ----
mean loss: 144.08
 ---- batch: 030 ----
mean loss: 141.45
train mean loss: 142.57
epoch train time: 0:00:01.434555
elapsed time: 0:03:49.579539
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:04:57.522717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.91
 ---- batch: 020 ----
mean loss: 146.22
 ---- batch: 030 ----
mean loss: 140.46
train mean loss: 143.68
epoch train time: 0:00:01.433359
elapsed time: 0:03:51.013077
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:04:58.956257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.75
 ---- batch: 020 ----
mean loss: 139.44
 ---- batch: 030 ----
mean loss: 136.85
train mean loss: 137.52
epoch train time: 0:00:01.430438
elapsed time: 0:03:52.443685
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:05:00.386862
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.03
 ---- batch: 020 ----
mean loss: 140.02
 ---- batch: 030 ----
mean loss: 134.27
train mean loss: 138.57
epoch train time: 0:00:01.427367
elapsed time: 0:03:53.871233
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:05:01.814415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.04
 ---- batch: 020 ----
mean loss: 137.77
 ---- batch: 030 ----
mean loss: 142.94
train mean loss: 138.00
epoch train time: 0:00:01.433790
elapsed time: 0:03:55.305200
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:05:03.248399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.32
 ---- batch: 020 ----
mean loss: 140.54
 ---- batch: 030 ----
mean loss: 137.27
train mean loss: 138.76
epoch train time: 0:00:01.434212
elapsed time: 0:03:56.739610
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:05:04.682809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.51
 ---- batch: 020 ----
mean loss: 138.74
 ---- batch: 030 ----
mean loss: 139.59
train mean loss: 139.87
epoch train time: 0:00:01.437973
elapsed time: 0:03:58.177792
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:05:06.120972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.65
 ---- batch: 020 ----
mean loss: 149.41
 ---- batch: 030 ----
mean loss: 151.64
train mean loss: 146.61
epoch train time: 0:00:01.435068
elapsed time: 0:03:59.613102
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:05:07.556298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.54
 ---- batch: 020 ----
mean loss: 142.69
 ---- batch: 030 ----
mean loss: 133.58
train mean loss: 142.07
epoch train time: 0:00:01.432663
elapsed time: 0:04:01.045957
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:05:08.989134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.70
 ---- batch: 020 ----
mean loss: 139.67
 ---- batch: 030 ----
mean loss: 142.80
train mean loss: 140.81
epoch train time: 0:00:01.437894
elapsed time: 0:04:02.484040
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:05:10.427216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.31
 ---- batch: 020 ----
mean loss: 137.47
 ---- batch: 030 ----
mean loss: 135.32
train mean loss: 136.04
epoch train time: 0:00:01.439062
elapsed time: 0:04:03.923314
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:05:11.866513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.81
 ---- batch: 020 ----
mean loss: 144.46
 ---- batch: 030 ----
mean loss: 142.07
train mean loss: 140.53
epoch train time: 0:00:01.439026
elapsed time: 0:04:05.362555
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:05:13.305739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.54
 ---- batch: 020 ----
mean loss: 140.57
 ---- batch: 030 ----
mean loss: 142.88
train mean loss: 140.40
epoch train time: 0:00:01.431758
elapsed time: 0:04:06.794527
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:05:14.737711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.41
 ---- batch: 020 ----
mean loss: 139.22
 ---- batch: 030 ----
mean loss: 134.80
train mean loss: 139.43
epoch train time: 0:00:01.430943
elapsed time: 0:04:08.225636
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:05:16.168810
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.29
 ---- batch: 020 ----
mean loss: 138.35
 ---- batch: 030 ----
mean loss: 144.78
train mean loss: 139.83
epoch train time: 0:00:01.435069
elapsed time: 0:04:09.660873
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:05:17.604085
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.21
 ---- batch: 020 ----
mean loss: 141.73
 ---- batch: 030 ----
mean loss: 142.54
train mean loss: 142.52
epoch train time: 0:00:01.434429
elapsed time: 0:04:11.095506
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:05:19.038686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.77
 ---- batch: 020 ----
mean loss: 136.09
 ---- batch: 030 ----
mean loss: 138.25
train mean loss: 138.84
epoch train time: 0:00:01.434793
elapsed time: 0:04:12.530568
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:05:20.473750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.47
 ---- batch: 020 ----
mean loss: 135.05
 ---- batch: 030 ----
mean loss: 137.69
train mean loss: 137.72
epoch train time: 0:00:01.433591
elapsed time: 0:04:13.964351
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:05:21.907531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.56
 ---- batch: 020 ----
mean loss: 142.40
 ---- batch: 030 ----
mean loss: 138.36
train mean loss: 141.17
epoch train time: 0:00:01.439458
elapsed time: 0:04:15.404007
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:05:23.347219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.39
 ---- batch: 020 ----
mean loss: 136.84
 ---- batch: 030 ----
mean loss: 140.72
train mean loss: 139.06
epoch train time: 0:00:01.442256
elapsed time: 0:04:16.846527
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:05:24.789709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.83
 ---- batch: 020 ----
mean loss: 140.73
 ---- batch: 030 ----
mean loss: 142.88
train mean loss: 142.35
epoch train time: 0:00:01.443762
elapsed time: 0:04:18.290501
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:05:26.233689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.49
 ---- batch: 020 ----
mean loss: 137.84
 ---- batch: 030 ----
mean loss: 142.82
train mean loss: 139.23
epoch train time: 0:00:01.439577
elapsed time: 0:04:19.730309
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:05:27.673501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.50
 ---- batch: 020 ----
mean loss: 142.10
 ---- batch: 030 ----
mean loss: 137.16
train mean loss: 140.37
epoch train time: 0:00:01.437480
elapsed time: 0:04:21.167997
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:05:29.111178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.45
 ---- batch: 020 ----
mean loss: 136.24
 ---- batch: 030 ----
mean loss: 141.56
train mean loss: 136.48
epoch train time: 0:00:01.436552
elapsed time: 0:04:22.604732
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:05:30.547913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.41
 ---- batch: 020 ----
mean loss: 140.03
 ---- batch: 030 ----
mean loss: 134.11
train mean loss: 139.10
epoch train time: 0:00:01.428705
elapsed time: 0:04:24.033620
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:05:31.976800
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.86
 ---- batch: 020 ----
mean loss: 141.10
 ---- batch: 030 ----
mean loss: 141.42
train mean loss: 139.47
epoch train time: 0:00:01.431746
elapsed time: 0:04:25.465543
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:05:33.408726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.98
 ---- batch: 020 ----
mean loss: 135.20
 ---- batch: 030 ----
mean loss: 139.82
train mean loss: 137.43
epoch train time: 0:00:01.439604
elapsed time: 0:04:26.905348
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:05:34.848539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.58
 ---- batch: 020 ----
mean loss: 141.52
 ---- batch: 030 ----
mean loss: 141.56
train mean loss: 140.95
epoch train time: 0:00:01.432081
elapsed time: 0:04:28.337617
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:05:36.280795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.69
 ---- batch: 020 ----
mean loss: 137.79
 ---- batch: 030 ----
mean loss: 140.94
train mean loss: 139.68
epoch train time: 0:00:01.433516
elapsed time: 0:04:29.771304
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:05:37.714481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.27
 ---- batch: 020 ----
mean loss: 141.18
 ---- batch: 030 ----
mean loss: 140.01
train mean loss: 137.82
epoch train time: 0:00:01.434677
elapsed time: 0:04:31.206162
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:05:39.149344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.39
 ---- batch: 020 ----
mean loss: 145.11
 ---- batch: 030 ----
mean loss: 136.08
train mean loss: 138.99
epoch train time: 0:00:01.435813
elapsed time: 0:04:32.642149
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:05:40.585344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.43
 ---- batch: 020 ----
mean loss: 138.75
 ---- batch: 030 ----
mean loss: 137.95
train mean loss: 138.33
epoch train time: 0:00:01.430281
elapsed time: 0:04:34.072621
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:05:42.015826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.29
 ---- batch: 020 ----
mean loss: 137.47
 ---- batch: 030 ----
mean loss: 138.42
train mean loss: 138.30
epoch train time: 0:00:01.431132
elapsed time: 0:04:35.503949
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:05:43.447150
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.01
 ---- batch: 020 ----
mean loss: 135.90
 ---- batch: 030 ----
mean loss: 132.87
train mean loss: 137.22
epoch train time: 0:00:01.431866
elapsed time: 0:04:36.936032
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:05:44.879213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.71
 ---- batch: 020 ----
mean loss: 134.52
 ---- batch: 030 ----
mean loss: 136.57
train mean loss: 136.65
epoch train time: 0:00:01.431252
elapsed time: 0:04:38.367467
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:05:46.310647
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.04
 ---- batch: 020 ----
mean loss: 137.46
 ---- batch: 030 ----
mean loss: 141.12
train mean loss: 138.82
epoch train time: 0:00:01.435492
elapsed time: 0:04:39.803141
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:05:47.746320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.38
 ---- batch: 020 ----
mean loss: 137.56
 ---- batch: 030 ----
mean loss: 140.20
train mean loss: 138.75
epoch train time: 0:00:01.430895
elapsed time: 0:04:41.234201
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:05:49.177379
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.76
 ---- batch: 020 ----
mean loss: 131.42
 ---- batch: 030 ----
mean loss: 136.27
train mean loss: 135.76
epoch train time: 0:00:01.431372
elapsed time: 0:04:42.665758
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:05:50.608951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.94
 ---- batch: 020 ----
mean loss: 139.38
 ---- batch: 030 ----
mean loss: 141.25
train mean loss: 138.63
epoch train time: 0:00:01.427006
elapsed time: 0:04:44.092972
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:05:52.036152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.06
 ---- batch: 020 ----
mean loss: 131.73
 ---- batch: 030 ----
mean loss: 139.11
train mean loss: 137.11
epoch train time: 0:00:01.435732
elapsed time: 0:04:45.528880
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:05:53.472055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.86
 ---- batch: 020 ----
mean loss: 134.42
 ---- batch: 030 ----
mean loss: 134.37
train mean loss: 135.73
epoch train time: 0:00:01.428653
elapsed time: 0:04:46.957724
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:05:54.900906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.88
 ---- batch: 020 ----
mean loss: 146.12
 ---- batch: 030 ----
mean loss: 144.88
train mean loss: 145.77
epoch train time: 0:00:01.437985
elapsed time: 0:04:48.395902
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:05:56.339082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.37
 ---- batch: 020 ----
mean loss: 140.64
 ---- batch: 030 ----
mean loss: 133.08
train mean loss: 137.76
epoch train time: 0:00:01.429139
elapsed time: 0:04:49.825216
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:05:57.768410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.58
 ---- batch: 020 ----
mean loss: 141.28
 ---- batch: 030 ----
mean loss: 136.07
train mean loss: 138.65
epoch train time: 0:00:01.436352
elapsed time: 0:04:51.261747
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:05:59.204924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.81
 ---- batch: 020 ----
mean loss: 138.25
 ---- batch: 030 ----
mean loss: 140.50
train mean loss: 139.11
epoch train time: 0:00:01.432342
elapsed time: 0:04:52.694264
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:06:00.637444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.38
 ---- batch: 020 ----
mean loss: 136.00
 ---- batch: 030 ----
mean loss: 133.82
train mean loss: 138.17
epoch train time: 0:00:01.432514
elapsed time: 0:04:54.126939
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:06:02.070136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.17
 ---- batch: 020 ----
mean loss: 139.94
 ---- batch: 030 ----
mean loss: 139.34
train mean loss: 139.06
epoch train time: 0:00:01.434526
elapsed time: 0:04:55.561649
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:06:03.504826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.46
 ---- batch: 020 ----
mean loss: 141.44
 ---- batch: 030 ----
mean loss: 138.75
train mean loss: 136.83
epoch train time: 0:00:01.432337
elapsed time: 0:04:56.994161
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:06:04.937359
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.35
 ---- batch: 020 ----
mean loss: 140.55
 ---- batch: 030 ----
mean loss: 138.50
train mean loss: 139.17
epoch train time: 0:00:01.434435
elapsed time: 0:04:58.428786
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:06:06.371970
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.44
 ---- batch: 020 ----
mean loss: 136.73
 ---- batch: 030 ----
mean loss: 141.15
train mean loss: 138.43
epoch train time: 0:00:01.439922
elapsed time: 0:04:59.868912
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:06:07.812094
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.75
 ---- batch: 020 ----
mean loss: 136.08
 ---- batch: 030 ----
mean loss: 137.38
train mean loss: 136.44
epoch train time: 0:00:01.434065
elapsed time: 0:05:01.303176
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:06:09.246350
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.06
 ---- batch: 020 ----
mean loss: 135.23
 ---- batch: 030 ----
mean loss: 133.37
train mean loss: 136.32
epoch train time: 0:00:01.432656
elapsed time: 0:05:02.735995
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:06:10.679173
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.29
 ---- batch: 020 ----
mean loss: 134.75
 ---- batch: 030 ----
mean loss: 135.81
train mean loss: 134.07
epoch train time: 0:00:01.431959
elapsed time: 0:05:04.168127
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:06:12.111307
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.51
 ---- batch: 020 ----
mean loss: 130.45
 ---- batch: 030 ----
mean loss: 139.49
train mean loss: 134.84
epoch train time: 0:00:01.428154
elapsed time: 0:05:05.596451
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:06:13.539629
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.08
 ---- batch: 020 ----
mean loss: 132.34
 ---- batch: 030 ----
mean loss: 134.62
train mean loss: 135.99
epoch train time: 0:00:01.436719
elapsed time: 0:05:07.033382
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:06:14.976559
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.75
 ---- batch: 020 ----
mean loss: 133.93
 ---- batch: 030 ----
mean loss: 134.06
train mean loss: 135.23
epoch train time: 0:00:01.430654
elapsed time: 0:05:08.464225
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:06:16.407407
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.84
 ---- batch: 020 ----
mean loss: 133.78
 ---- batch: 030 ----
mean loss: 135.67
train mean loss: 134.28
epoch train time: 0:00:01.436127
elapsed time: 0:05:09.900619
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:06:17.843808
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.41
 ---- batch: 020 ----
mean loss: 130.79
 ---- batch: 030 ----
mean loss: 131.75
train mean loss: 134.71
epoch train time: 0:00:01.431507
elapsed time: 0:05:11.332314
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:06:19.275492
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.51
 ---- batch: 020 ----
mean loss: 136.95
 ---- batch: 030 ----
mean loss: 131.86
train mean loss: 134.35
epoch train time: 0:00:01.426982
elapsed time: 0:05:12.759521
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:06:20.702728
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.69
 ---- batch: 020 ----
mean loss: 131.93
 ---- batch: 030 ----
mean loss: 132.90
train mean loss: 134.72
epoch train time: 0:00:01.434480
elapsed time: 0:05:14.194199
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:06:22.137397
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.13
 ---- batch: 020 ----
mean loss: 133.91
 ---- batch: 030 ----
mean loss: 133.57
train mean loss: 134.74
epoch train time: 0:00:01.430953
elapsed time: 0:05:15.625351
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:06:23.568545
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.95
 ---- batch: 020 ----
mean loss: 136.87
 ---- batch: 030 ----
mean loss: 137.77
train mean loss: 134.92
epoch train time: 0:00:01.430944
elapsed time: 0:05:17.056487
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:06:24.999664
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.48
 ---- batch: 020 ----
mean loss: 132.97
 ---- batch: 030 ----
mean loss: 135.63
train mean loss: 135.52
epoch train time: 0:00:01.435716
elapsed time: 0:05:18.492387
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:06:26.435567
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.43
 ---- batch: 020 ----
mean loss: 136.09
 ---- batch: 030 ----
mean loss: 132.18
train mean loss: 134.98
epoch train time: 0:00:01.442953
elapsed time: 0:05:19.935523
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:06:27.878731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.04
 ---- batch: 020 ----
mean loss: 129.34
 ---- batch: 030 ----
mean loss: 135.68
train mean loss: 133.86
epoch train time: 0:00:01.431432
elapsed time: 0:05:21.367190
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:06:29.310367
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.48
 ---- batch: 020 ----
mean loss: 136.77
 ---- batch: 030 ----
mean loss: 136.39
train mean loss: 134.52
epoch train time: 0:00:01.431860
elapsed time: 0:05:22.799221
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:06:30.742396
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.83
 ---- batch: 020 ----
mean loss: 133.52
 ---- batch: 030 ----
mean loss: 132.37
train mean loss: 134.13
epoch train time: 0:00:01.428820
elapsed time: 0:05:24.228201
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:06:32.171407
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.73
 ---- batch: 020 ----
mean loss: 133.84
 ---- batch: 030 ----
mean loss: 132.52
train mean loss: 134.93
epoch train time: 0:00:01.429036
elapsed time: 0:05:25.657459
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:06:33.600635
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.82
 ---- batch: 020 ----
mean loss: 133.31
 ---- batch: 030 ----
mean loss: 136.92
train mean loss: 134.79
epoch train time: 0:00:01.428742
elapsed time: 0:05:27.086377
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:06:35.029558
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.72
 ---- batch: 020 ----
mean loss: 134.69
 ---- batch: 030 ----
mean loss: 136.36
train mean loss: 134.78
epoch train time: 0:00:01.435205
elapsed time: 0:05:28.521752
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:06:36.464932
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.55
 ---- batch: 020 ----
mean loss: 135.59
 ---- batch: 030 ----
mean loss: 133.07
train mean loss: 134.24
epoch train time: 0:00:01.430537
elapsed time: 0:05:29.952479
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:06:37.895663
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.62
 ---- batch: 020 ----
mean loss: 134.15
 ---- batch: 030 ----
mean loss: 133.36
train mean loss: 134.99
epoch train time: 0:00:01.435211
elapsed time: 0:05:31.387876
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:06:39.331056
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.48
 ---- batch: 020 ----
mean loss: 135.27
 ---- batch: 030 ----
mean loss: 135.86
train mean loss: 133.58
epoch train time: 0:00:01.432423
elapsed time: 0:05:32.820480
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:06:40.763685
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 138.90
 ---- batch: 020 ----
mean loss: 133.47
 ---- batch: 030 ----
mean loss: 133.14
train mean loss: 136.04
epoch train time: 0:00:01.425761
elapsed time: 0:05:34.246459
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:06:42.189660
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.09
 ---- batch: 020 ----
mean loss: 131.83
 ---- batch: 030 ----
mean loss: 135.59
train mean loss: 134.71
epoch train time: 0:00:01.436292
elapsed time: 0:05:35.682943
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:06:43.626122
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.71
 ---- batch: 020 ----
mean loss: 137.07
 ---- batch: 030 ----
mean loss: 134.38
train mean loss: 136.32
epoch train time: 0:00:01.429553
elapsed time: 0:05:37.112683
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:06:45.055862
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.28
 ---- batch: 020 ----
mean loss: 135.42
 ---- batch: 030 ----
mean loss: 129.29
train mean loss: 134.35
epoch train time: 0:00:01.430011
elapsed time: 0:05:38.542863
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:06:46.486040
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 131.87
 ---- batch: 020 ----
mean loss: 135.36
 ---- batch: 030 ----
mean loss: 135.53
train mean loss: 134.58
epoch train time: 0:00:01.430872
elapsed time: 0:05:39.973963
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:06:47.917145
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.29
 ---- batch: 020 ----
mean loss: 136.76
 ---- batch: 030 ----
mean loss: 133.92
train mean loss: 135.43
epoch train time: 0:00:01.434684
elapsed time: 0:05:41.408829
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:06:49.352010
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.37
 ---- batch: 020 ----
mean loss: 139.27
 ---- batch: 030 ----
mean loss: 126.94
train mean loss: 133.84
epoch train time: 0:00:01.424927
elapsed time: 0:05:42.833938
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:06:50.777118
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.49
 ---- batch: 020 ----
mean loss: 134.21
 ---- batch: 030 ----
mean loss: 132.67
train mean loss: 135.22
epoch train time: 0:00:01.438541
elapsed time: 0:05:44.272716
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:06:52.215951
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.37
 ---- batch: 020 ----
mean loss: 136.46
 ---- batch: 030 ----
mean loss: 132.23
train mean loss: 134.54
epoch train time: 0:00:01.427787
elapsed time: 0:05:45.700732
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:06:53.643912
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.40
 ---- batch: 020 ----
mean loss: 135.64
 ---- batch: 030 ----
mean loss: 133.94
train mean loss: 134.99
epoch train time: 0:00:01.432691
elapsed time: 0:05:47.133647
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:06:55.076839
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 140.17
 ---- batch: 020 ----
mean loss: 133.95
 ---- batch: 030 ----
mean loss: 134.56
train mean loss: 135.43
epoch train time: 0:00:01.430369
elapsed time: 0:05:48.564196
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:06:56.507373
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.47
 ---- batch: 020 ----
mean loss: 135.67
 ---- batch: 030 ----
mean loss: 136.27
train mean loss: 135.77
epoch train time: 0:00:01.432546
elapsed time: 0:05:49.996919
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:06:57.940100
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.08
 ---- batch: 020 ----
mean loss: 135.46
 ---- batch: 030 ----
mean loss: 134.45
train mean loss: 134.82
epoch train time: 0:00:01.430060
elapsed time: 0:05:51.427163
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:06:59.370364
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 132.72
 ---- batch: 020 ----
mean loss: 134.99
 ---- batch: 030 ----
mean loss: 134.67
train mean loss: 134.46
epoch train time: 0:00:01.429790
elapsed time: 0:05:52.857147
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:07:00.800342
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.12
 ---- batch: 020 ----
mean loss: 135.34
 ---- batch: 030 ----
mean loss: 135.82
train mean loss: 135.13
epoch train time: 0:00:01.427850
elapsed time: 0:05:54.285177
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:07:02.228353
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.37
 ---- batch: 020 ----
mean loss: 134.38
 ---- batch: 030 ----
mean loss: 132.46
train mean loss: 134.80
epoch train time: 0:00:01.435707
elapsed time: 0:05:55.721072
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:07:03.664254
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.89
 ---- batch: 020 ----
mean loss: 137.57
 ---- batch: 030 ----
mean loss: 138.25
train mean loss: 135.49
epoch train time: 0:00:01.431718
elapsed time: 0:05:57.152965
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:07:05.096143
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.27
 ---- batch: 020 ----
mean loss: 138.10
 ---- batch: 030 ----
mean loss: 134.19
train mean loss: 136.58
epoch train time: 0:00:01.429347
elapsed time: 0:05:58.582501
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:07:06.525684
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 134.64
 ---- batch: 020 ----
mean loss: 137.27
 ---- batch: 030 ----
mean loss: 132.00
train mean loss: 133.90
epoch train time: 0:00:01.429295
elapsed time: 0:06:00.011993
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:07:07.955193
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 135.15
 ---- batch: 020 ----
mean loss: 137.83
 ---- batch: 030 ----
mean loss: 136.77
train mean loss: 135.37
epoch train time: 0:00:01.434179
elapsed time: 0:06:01.446363
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:07:09.389540
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 139.29
 ---- batch: 020 ----
mean loss: 135.68
 ---- batch: 030 ----
mean loss: 130.32
train mean loss: 135.29
epoch train time: 0:00:01.433085
elapsed time: 0:06:02.879622
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:07:10.822799
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 136.88
 ---- batch: 020 ----
mean loss: 130.95
 ---- batch: 030 ----
mean loss: 134.04
train mean loss: 133.40
epoch train time: 0:00:01.430185
elapsed time: 0:06:04.309976
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:07:12.253155
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 133.96
 ---- batch: 020 ----
mean loss: 134.69
 ---- batch: 030 ----
mean loss: 133.45
train mean loss: 133.57
epoch train time: 0:00:01.429843
elapsed time: 0:06:05.740007
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:07:13.683202
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.68
 ---- batch: 020 ----
mean loss: 131.89
 ---- batch: 030 ----
mean loss: 131.65
train mean loss: 134.22
epoch train time: 0:00:01.432975
elapsed time: 0:06:07.173161
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:07:15.116338
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 137.12
 ---- batch: 020 ----
mean loss: 132.90
 ---- batch: 030 ----
mean loss: 130.56
train mean loss: 134.14
epoch train time: 0:00:01.431191
elapsed time: 0:06:08.604525
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:07:16.547717
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 130.20
 ---- batch: 020 ----
mean loss: 138.38
 ---- batch: 030 ----
mean loss: 135.94
train mean loss: 135.12
epoch train time: 0:00:01.432344
elapsed time: 0:06:10.040622
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_conv5_dense1/frequentist_conv5_dense1_4/checkpoint.pth.tar
**** end time: 2019-09-27 16:07:17.983761 ****
