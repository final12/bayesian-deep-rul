Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_2', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 21736
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-27 06:40:26.298292 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 31, 14]             200
           Sigmoid-2           [-1, 10, 31, 14]               0
    BayesianConv2d-3           [-1, 10, 30, 14]           2,000
           Sigmoid-4           [-1, 10, 30, 14]               0
    BayesianConv2d-5           [-1, 10, 31, 14]           2,000
           Sigmoid-6           [-1, 10, 31, 14]               0
    BayesianConv2d-7           [-1, 10, 30, 14]           2,000
           Sigmoid-8           [-1, 10, 30, 14]               0
    BayesianConv2d-9            [-1, 1, 30, 14]              60
         Softplus-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
   BayesianLinear-12                  [-1, 100]          84,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 90,460
Trainable params: 90,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 06:40:26.315596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2517.79
 ---- batch: 020 ----
mean loss: 1925.19
 ---- batch: 030 ----
mean loss: 1555.55
train mean loss: 1914.69
epoch train time: 0:00:17.647361
elapsed time: 0:00:17.673316
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 06:40:43.971694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1301.34
 ---- batch: 020 ----
mean loss: 1212.59
 ---- batch: 030 ----
mean loss: 1142.01
train mean loss: 1205.09
epoch train time: 0:00:07.157093
elapsed time: 0:00:24.831134
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 06:40:51.129633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1113.70
 ---- batch: 020 ----
mean loss: 1112.69
 ---- batch: 030 ----
mean loss: 1105.12
train mean loss: 1106.75
epoch train time: 0:00:07.049251
elapsed time: 0:00:31.881227
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 06:40:58.179697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1081.47
 ---- batch: 020 ----
mean loss: 1046.73
 ---- batch: 030 ----
mean loss: 1057.33
train mean loss: 1058.98
epoch train time: 0:00:07.114012
elapsed time: 0:00:38.996174
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 06:41:05.294641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1056.35
 ---- batch: 020 ----
mean loss: 1044.28
 ---- batch: 030 ----
mean loss: 1045.99
train mean loss: 1048.53
epoch train time: 0:00:07.056607
elapsed time: 0:00:46.053575
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 06:41:12.352044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1032.47
 ---- batch: 020 ----
mean loss: 1034.33
 ---- batch: 030 ----
mean loss: 1013.09
train mean loss: 1032.54
epoch train time: 0:00:07.103808
elapsed time: 0:00:53.158269
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 06:41:19.456730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1048.81
 ---- batch: 020 ----
mean loss: 999.19
 ---- batch: 030 ----
mean loss: 1019.31
train mean loss: 1020.51
epoch train time: 0:00:06.993517
elapsed time: 0:01:00.152630
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 06:41:26.451098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1015.76
 ---- batch: 020 ----
mean loss: 1008.82
 ---- batch: 030 ----
mean loss: 1000.09
train mean loss: 1009.51
epoch train time: 0:00:07.144980
elapsed time: 0:01:07.298393
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 06:41:33.596834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1024.17
 ---- batch: 020 ----
mean loss: 1003.02
 ---- batch: 030 ----
mean loss: 1019.80
train mean loss: 1010.12
epoch train time: 0:00:07.007023
elapsed time: 0:01:14.306226
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 06:41:40.604696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1005.75
 ---- batch: 020 ----
mean loss: 993.76
 ---- batch: 030 ----
mean loss: 983.70
train mean loss: 992.61
epoch train time: 0:00:07.076950
elapsed time: 0:01:21.384001
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 06:41:47.682468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 997.19
 ---- batch: 020 ----
mean loss: 1002.75
 ---- batch: 030 ----
mean loss: 991.62
train mean loss: 993.61
epoch train time: 0:00:06.843426
elapsed time: 0:01:28.228268
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 06:41:54.526728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 964.37
 ---- batch: 020 ----
mean loss: 951.19
 ---- batch: 030 ----
mean loss: 941.00
train mean loss: 949.70
epoch train time: 0:00:06.913219
elapsed time: 0:01:35.142287
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 06:42:01.440790
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 896.42
 ---- batch: 020 ----
mean loss: 838.46
 ---- batch: 030 ----
mean loss: 766.54
train mean loss: 815.71
epoch train time: 0:00:06.868103
elapsed time: 0:01:42.011405
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 06:42:08.309890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 672.81
 ---- batch: 020 ----
mean loss: 607.72
 ---- batch: 030 ----
mean loss: 531.40
train mean loss: 588.73
epoch train time: 0:00:06.941378
elapsed time: 0:01:48.953691
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 06:42:15.252183
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 463.28
 ---- batch: 020 ----
mean loss: 459.56
 ---- batch: 030 ----
mean loss: 452.58
train mean loss: 456.30
epoch train time: 0:00:06.907734
elapsed time: 0:01:55.862260
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 06:42:22.160710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 432.11
 ---- batch: 020 ----
mean loss: 436.55
 ---- batch: 030 ----
mean loss: 430.76
train mean loss: 432.51
epoch train time: 0:00:06.844209
elapsed time: 0:02:02.707379
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 06:42:29.005831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 408.41
 ---- batch: 020 ----
mean loss: 419.28
 ---- batch: 030 ----
mean loss: 413.26
train mean loss: 413.39
epoch train time: 0:00:06.951544
elapsed time: 0:02:09.659740
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 06:42:35.958185
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 401.07
 ---- batch: 020 ----
mean loss: 400.09
 ---- batch: 030 ----
mean loss: 391.93
train mean loss: 397.23
epoch train time: 0:00:06.813959
elapsed time: 0:02:16.474472
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 06:42:42.772915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 384.87
 ---- batch: 020 ----
mean loss: 381.76
 ---- batch: 030 ----
mean loss: 380.70
train mean loss: 381.25
epoch train time: 0:00:06.909237
elapsed time: 0:02:23.384620
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 06:42:49.683122
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 383.60
 ---- batch: 020 ----
mean loss: 378.61
 ---- batch: 030 ----
mean loss: 362.48
train mean loss: 373.06
epoch train time: 0:00:06.916591
elapsed time: 0:02:30.302069
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 06:42:56.600527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 361.59
 ---- batch: 020 ----
mean loss: 367.76
 ---- batch: 030 ----
mean loss: 347.12
train mean loss: 357.83
epoch train time: 0:00:06.864938
elapsed time: 0:02:37.167845
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 06:43:03.466292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.01
 ---- batch: 020 ----
mean loss: 341.45
 ---- batch: 030 ----
mean loss: 336.02
train mean loss: 340.18
epoch train time: 0:00:06.944432
elapsed time: 0:02:44.113134
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 06:43:10.411586
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 334.81
 ---- batch: 020 ----
mean loss: 331.61
 ---- batch: 030 ----
mean loss: 318.67
train mean loss: 325.36
epoch train time: 0:00:06.820403
elapsed time: 0:02:50.934464
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 06:43:17.232920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.63
 ---- batch: 020 ----
mean loss: 311.55
 ---- batch: 030 ----
mean loss: 295.44
train mean loss: 305.90
epoch train time: 0:00:06.933972
elapsed time: 0:02:57.869232
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 06:43:24.167683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.17
 ---- batch: 020 ----
mean loss: 280.78
 ---- batch: 030 ----
mean loss: 278.45
train mean loss: 282.40
epoch train time: 0:00:06.757610
elapsed time: 0:03:04.627677
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 06:43:30.926158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.12
 ---- batch: 020 ----
mean loss: 264.93
 ---- batch: 030 ----
mean loss: 263.60
train mean loss: 268.00
epoch train time: 0:00:07.015491
elapsed time: 0:03:11.644010
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 06:43:37.942491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.49
 ---- batch: 020 ----
mean loss: 254.43
 ---- batch: 030 ----
mean loss: 249.18
train mean loss: 254.07
epoch train time: 0:00:06.859950
elapsed time: 0:03:18.504782
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 06:43:44.803276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.87
 ---- batch: 020 ----
mean loss: 239.36
 ---- batch: 030 ----
mean loss: 241.05
train mean loss: 244.82
epoch train time: 0:00:06.908041
elapsed time: 0:03:25.413710
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 06:43:51.712161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.23
 ---- batch: 020 ----
mean loss: 244.68
 ---- batch: 030 ----
mean loss: 236.96
train mean loss: 240.66
epoch train time: 0:00:06.875471
elapsed time: 0:03:32.290023
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 06:43:58.588496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.58
 ---- batch: 020 ----
mean loss: 238.49
 ---- batch: 030 ----
mean loss: 234.47
train mean loss: 234.85
epoch train time: 0:00:06.924929
elapsed time: 0:03:39.215771
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 06:44:05.514224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.69
 ---- batch: 020 ----
mean loss: 228.57
 ---- batch: 030 ----
mean loss: 235.13
train mean loss: 228.72
epoch train time: 0:00:06.917844
elapsed time: 0:03:46.134503
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 06:44:12.432988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.01
 ---- batch: 020 ----
mean loss: 225.86
 ---- batch: 030 ----
mean loss: 226.71
train mean loss: 224.53
epoch train time: 0:00:06.844443
elapsed time: 0:03:52.979957
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 06:44:19.278438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.14
 ---- batch: 020 ----
mean loss: 215.63
 ---- batch: 030 ----
mean loss: 219.73
train mean loss: 217.86
epoch train time: 0:00:06.913662
elapsed time: 0:03:59.894434
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 06:44:26.192878
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.89
 ---- batch: 020 ----
mean loss: 225.04
 ---- batch: 030 ----
mean loss: 218.45
train mean loss: 216.61
epoch train time: 0:00:06.839234
elapsed time: 0:04:06.734469
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 06:44:33.032941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 206.23
 ---- batch: 020 ----
mean loss: 208.69
 ---- batch: 030 ----
mean loss: 207.37
train mean loss: 207.08
epoch train time: 0:00:06.907230
elapsed time: 0:04:13.642541
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 06:44:39.941008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.12
 ---- batch: 020 ----
mean loss: 211.85
 ---- batch: 030 ----
mean loss: 201.48
train mean loss: 209.03
epoch train time: 0:00:06.827389
elapsed time: 0:04:20.470747
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 06:44:46.769210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.03
 ---- batch: 020 ----
mean loss: 206.00
 ---- batch: 030 ----
mean loss: 191.82
train mean loss: 202.16
epoch train time: 0:00:06.970202
elapsed time: 0:04:27.441926
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 06:44:53.740385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.83
 ---- batch: 020 ----
mean loss: 194.46
 ---- batch: 030 ----
mean loss: 206.41
train mean loss: 201.34
epoch train time: 0:00:06.831030
elapsed time: 0:04:34.273806
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 06:45:00.572261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.82
 ---- batch: 020 ----
mean loss: 203.08
 ---- batch: 030 ----
mean loss: 207.22
train mean loss: 201.14
epoch train time: 0:00:06.902867
elapsed time: 0:04:41.177553
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 06:45:07.476008
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.15
 ---- batch: 020 ----
mean loss: 198.25
 ---- batch: 030 ----
mean loss: 199.83
train mean loss: 199.51
epoch train time: 0:00:06.884170
elapsed time: 0:04:48.062611
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 06:45:14.361069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.28
 ---- batch: 020 ----
mean loss: 191.24
 ---- batch: 030 ----
mean loss: 189.73
train mean loss: 195.00
epoch train time: 0:00:06.878079
elapsed time: 0:04:54.941587
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 06:45:21.240086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.55
 ---- batch: 020 ----
mean loss: 196.33
 ---- batch: 030 ----
mean loss: 195.40
train mean loss: 195.85
epoch train time: 0:00:06.943222
elapsed time: 0:05:01.885777
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 06:45:28.184270
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.79
 ---- batch: 020 ----
mean loss: 190.02
 ---- batch: 030 ----
mean loss: 184.80
train mean loss: 188.50
epoch train time: 0:00:06.867324
elapsed time: 0:05:08.754136
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 06:45:35.052626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.14
 ---- batch: 020 ----
mean loss: 178.12
 ---- batch: 030 ----
mean loss: 185.81
train mean loss: 183.53
epoch train time: 0:00:06.892822
elapsed time: 0:05:15.647822
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 06:45:41.946287
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.91
 ---- batch: 020 ----
mean loss: 182.79
 ---- batch: 030 ----
mean loss: 183.51
train mean loss: 182.60
epoch train time: 0:00:06.873526
elapsed time: 0:05:22.522411
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 06:45:48.820875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.05
 ---- batch: 020 ----
mean loss: 192.37
 ---- batch: 030 ----
mean loss: 181.20
train mean loss: 185.08
epoch train time: 0:00:06.908796
elapsed time: 0:05:29.432035
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 06:45:55.730482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.17
 ---- batch: 020 ----
mean loss: 186.47
 ---- batch: 030 ----
mean loss: 183.95
train mean loss: 185.04
epoch train time: 0:00:06.864405
elapsed time: 0:05:36.297256
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 06:46:02.595704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 178.28
 ---- batch: 020 ----
mean loss: 182.45
 ---- batch: 030 ----
mean loss: 178.21
train mean loss: 180.09
epoch train time: 0:00:06.888405
elapsed time: 0:05:43.186474
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 06:46:09.484949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.97
 ---- batch: 020 ----
mean loss: 175.36
 ---- batch: 030 ----
mean loss: 180.85
train mean loss: 176.78
epoch train time: 0:00:06.781853
elapsed time: 0:05:49.969133
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 06:46:16.267625
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.39
 ---- batch: 020 ----
mean loss: 176.55
 ---- batch: 030 ----
mean loss: 174.03
train mean loss: 174.06
epoch train time: 0:00:06.913487
elapsed time: 0:05:56.883540
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 06:46:23.181993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.95
 ---- batch: 020 ----
mean loss: 177.17
 ---- batch: 030 ----
mean loss: 172.38
train mean loss: 175.57
epoch train time: 0:00:06.982279
elapsed time: 0:06:03.866592
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 06:46:30.165335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.66
 ---- batch: 020 ----
mean loss: 176.43
 ---- batch: 030 ----
mean loss: 168.72
train mean loss: 171.90
epoch train time: 0:00:06.982684
elapsed time: 0:06:10.850396
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 06:46:37.148879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.18
 ---- batch: 020 ----
mean loss: 171.01
 ---- batch: 030 ----
mean loss: 167.52
train mean loss: 170.83
epoch train time: 0:00:07.067583
elapsed time: 0:06:17.918854
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 06:46:44.217314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.42
 ---- batch: 020 ----
mean loss: 167.68
 ---- batch: 030 ----
mean loss: 168.37
train mean loss: 168.34
epoch train time: 0:00:07.137479
elapsed time: 0:06:25.057163
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 06:46:51.355646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.90
 ---- batch: 020 ----
mean loss: 166.90
 ---- batch: 030 ----
mean loss: 171.10
train mean loss: 167.02
epoch train time: 0:00:07.065094
elapsed time: 0:06:32.123090
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 06:46:58.421535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.59
 ---- batch: 020 ----
mean loss: 162.22
 ---- batch: 030 ----
mean loss: 162.71
train mean loss: 164.10
epoch train time: 0:00:07.003211
elapsed time: 0:06:39.127053
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 06:47:05.425525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.89
 ---- batch: 020 ----
mean loss: 168.06
 ---- batch: 030 ----
mean loss: 164.63
train mean loss: 165.71
epoch train time: 0:00:07.098835
elapsed time: 0:06:46.226761
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 06:47:12.525217
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.11
 ---- batch: 020 ----
mean loss: 164.31
 ---- batch: 030 ----
mean loss: 163.16
train mean loss: 162.72
epoch train time: 0:00:07.038165
elapsed time: 0:06:53.265765
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 06:47:19.564228
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.86
 ---- batch: 020 ----
mean loss: 161.39
 ---- batch: 030 ----
mean loss: 162.81
train mean loss: 161.34
epoch train time: 0:00:07.064631
elapsed time: 0:07:00.331194
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 06:47:26.629682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.36
 ---- batch: 020 ----
mean loss: 165.31
 ---- batch: 030 ----
mean loss: 159.11
train mean loss: 161.49
epoch train time: 0:00:07.092966
elapsed time: 0:07:07.425048
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 06:47:33.723547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.68
 ---- batch: 020 ----
mean loss: 161.35
 ---- batch: 030 ----
mean loss: 159.94
train mean loss: 158.75
epoch train time: 0:00:06.965795
elapsed time: 0:07:14.391831
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 06:47:40.690300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.77
 ---- batch: 020 ----
mean loss: 153.54
 ---- batch: 030 ----
mean loss: 162.36
train mean loss: 157.61
epoch train time: 0:00:07.054507
elapsed time: 0:07:21.447212
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 06:47:47.745709
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.17
 ---- batch: 020 ----
mean loss: 158.22
 ---- batch: 030 ----
mean loss: 159.93
train mean loss: 159.48
epoch train time: 0:00:07.007531
elapsed time: 0:07:28.455584
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 06:47:54.754032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.43
 ---- batch: 020 ----
mean loss: 159.68
 ---- batch: 030 ----
mean loss: 162.99
train mean loss: 157.62
epoch train time: 0:00:07.030711
elapsed time: 0:07:35.487077
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 06:48:01.785519
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.27
 ---- batch: 020 ----
mean loss: 153.38
 ---- batch: 030 ----
mean loss: 150.85
train mean loss: 154.71
epoch train time: 0:00:07.053760
elapsed time: 0:07:42.541726
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 06:48:08.840170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.08
 ---- batch: 020 ----
mean loss: 149.97
 ---- batch: 030 ----
mean loss: 161.30
train mean loss: 155.65
epoch train time: 0:00:06.952547
elapsed time: 0:07:49.495035
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 06:48:15.793482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.65
 ---- batch: 020 ----
mean loss: 155.08
 ---- batch: 030 ----
mean loss: 153.78
train mean loss: 153.70
epoch train time: 0:00:06.973247
elapsed time: 0:07:56.469100
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 06:48:22.767591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.79
 ---- batch: 020 ----
mean loss: 152.88
 ---- batch: 030 ----
mean loss: 151.05
train mean loss: 150.58
epoch train time: 0:00:06.884693
elapsed time: 0:08:03.354588
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 06:48:29.653070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.95
 ---- batch: 020 ----
mean loss: 150.53
 ---- batch: 030 ----
mean loss: 146.34
train mean loss: 150.30
epoch train time: 0:00:06.923335
elapsed time: 0:08:10.278872
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 06:48:36.577320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.03
 ---- batch: 020 ----
mean loss: 148.11
 ---- batch: 030 ----
mean loss: 151.20
train mean loss: 149.95
epoch train time: 0:00:06.917770
elapsed time: 0:08:17.197426
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 06:48:43.495917
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 148.86
 ---- batch: 020 ----
mean loss: 152.44
 ---- batch: 030 ----
mean loss: 146.73
train mean loss: 148.75
epoch train time: 0:00:06.865763
elapsed time: 0:08:24.064004
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 06:48:50.362455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 146.35
 ---- batch: 020 ----
mean loss: 149.18
 ---- batch: 030 ----
mean loss: 145.01
train mean loss: 147.25
epoch train time: 0:00:06.986763
elapsed time: 0:08:31.051608
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 06:48:57.350061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.07
 ---- batch: 020 ----
mean loss: 148.52
 ---- batch: 030 ----
mean loss: 144.95
train mean loss: 147.27
epoch train time: 0:00:06.870588
elapsed time: 0:08:37.923033
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 06:49:04.221520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.03
 ---- batch: 020 ----
mean loss: 148.38
 ---- batch: 030 ----
mean loss: 150.40
train mean loss: 146.73
epoch train time: 0:00:06.920444
elapsed time: 0:08:44.844309
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 06:49:11.142759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.16
 ---- batch: 020 ----
mean loss: 150.84
 ---- batch: 030 ----
mean loss: 143.58
train mean loss: 145.55
epoch train time: 0:00:06.784224
elapsed time: 0:08:51.629370
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 06:49:17.927837
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.25
 ---- batch: 020 ----
mean loss: 145.65
 ---- batch: 030 ----
mean loss: 140.23
train mean loss: 141.76
epoch train time: 0:00:06.847634
elapsed time: 0:08:58.477793
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 06:49:24.776246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.28
 ---- batch: 020 ----
mean loss: 144.67
 ---- batch: 030 ----
mean loss: 140.37
train mean loss: 143.15
epoch train time: 0:00:06.767798
elapsed time: 0:09:05.246502
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 06:49:31.544959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.81
 ---- batch: 020 ----
mean loss: 139.92
 ---- batch: 030 ----
mean loss: 143.93
train mean loss: 143.15
epoch train time: 0:00:06.970109
elapsed time: 0:09:12.217484
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 06:49:38.515996
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.51
 ---- batch: 020 ----
mean loss: 139.60
 ---- batch: 030 ----
mean loss: 141.86
train mean loss: 140.71
epoch train time: 0:00:06.791153
elapsed time: 0:09:19.009508
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 06:49:45.307967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.44
 ---- batch: 020 ----
mean loss: 145.06
 ---- batch: 030 ----
mean loss: 138.95
train mean loss: 141.36
epoch train time: 0:00:06.856122
elapsed time: 0:09:25.866441
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 06:49:52.164908
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.12
 ---- batch: 020 ----
mean loss: 137.08
 ---- batch: 030 ----
mean loss: 136.06
train mean loss: 138.27
epoch train time: 0:00:06.841062
elapsed time: 0:09:32.708388
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 06:49:59.006876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.42
 ---- batch: 020 ----
mean loss: 139.77
 ---- batch: 030 ----
mean loss: 138.31
train mean loss: 136.80
epoch train time: 0:00:06.812467
elapsed time: 0:09:39.521789
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 06:50:05.820250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.01
 ---- batch: 020 ----
mean loss: 135.62
 ---- batch: 030 ----
mean loss: 140.57
train mean loss: 138.09
epoch train time: 0:00:06.869493
elapsed time: 0:09:46.392080
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 06:50:12.690610
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.67
 ---- batch: 020 ----
mean loss: 132.58
 ---- batch: 030 ----
mean loss: 140.00
train mean loss: 136.80
epoch train time: 0:00:06.836248
elapsed time: 0:09:53.229221
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 06:50:19.527671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.21
 ---- batch: 020 ----
mean loss: 142.80
 ---- batch: 030 ----
mean loss: 139.47
train mean loss: 137.37
epoch train time: 0:00:06.838720
elapsed time: 0:10:00.068746
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 06:50:26.367214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.25
 ---- batch: 020 ----
mean loss: 139.77
 ---- batch: 030 ----
mean loss: 131.60
train mean loss: 136.43
epoch train time: 0:00:06.894209
elapsed time: 0:10:06.963790
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 06:50:33.262240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.14
 ---- batch: 020 ----
mean loss: 134.60
 ---- batch: 030 ----
mean loss: 141.29
train mean loss: 135.81
epoch train time: 0:00:06.862799
elapsed time: 0:10:13.827374
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 06:50:40.125821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.58
 ---- batch: 020 ----
mean loss: 134.71
 ---- batch: 030 ----
mean loss: 131.85
train mean loss: 135.19
epoch train time: 0:00:06.831946
elapsed time: 0:10:20.660155
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 06:50:46.958608
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.09
 ---- batch: 020 ----
mean loss: 132.56
 ---- batch: 030 ----
mean loss: 132.14
train mean loss: 133.76
epoch train time: 0:00:06.918935
elapsed time: 0:10:27.579911
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 06:50:53.878361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.39
 ---- batch: 020 ----
mean loss: 130.11
 ---- batch: 030 ----
mean loss: 138.90
train mean loss: 135.16
epoch train time: 0:00:06.862765
elapsed time: 0:10:34.443520
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 06:51:00.741985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.97
 ---- batch: 020 ----
mean loss: 133.19
 ---- batch: 030 ----
mean loss: 131.45
train mean loss: 132.50
epoch train time: 0:00:06.860504
elapsed time: 0:10:41.304835
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 06:51:07.603360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.56
 ---- batch: 020 ----
mean loss: 133.98
 ---- batch: 030 ----
mean loss: 132.29
train mean loss: 131.43
epoch train time: 0:00:06.906734
elapsed time: 0:10:48.212538
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 06:51:14.511016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.59
 ---- batch: 020 ----
mean loss: 133.84
 ---- batch: 030 ----
mean loss: 131.35
train mean loss: 132.12
epoch train time: 0:00:06.799422
elapsed time: 0:10:55.012752
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 06:51:21.311206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.42
 ---- batch: 020 ----
mean loss: 130.42
 ---- batch: 030 ----
mean loss: 130.94
train mean loss: 130.64
epoch train time: 0:00:06.883561
elapsed time: 0:11:01.897253
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 06:51:28.195713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.67
 ---- batch: 020 ----
mean loss: 132.24
 ---- batch: 030 ----
mean loss: 130.67
train mean loss: 131.15
epoch train time: 0:00:06.910900
elapsed time: 0:11:08.809134
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 06:51:35.107721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.51
 ---- batch: 020 ----
mean loss: 126.42
 ---- batch: 030 ----
mean loss: 135.51
train mean loss: 129.28
epoch train time: 0:00:06.864546
elapsed time: 0:11:15.674593
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 06:51:41.973057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.74
 ---- batch: 020 ----
mean loss: 128.41
 ---- batch: 030 ----
mean loss: 130.32
train mean loss: 128.94
epoch train time: 0:00:06.841504
elapsed time: 0:11:22.516911
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 06:51:48.815376
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.81
 ---- batch: 020 ----
mean loss: 128.92
 ---- batch: 030 ----
mean loss: 132.59
train mean loss: 128.48
epoch train time: 0:00:06.956977
elapsed time: 0:11:29.474730
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 06:51:55.773198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.12
 ---- batch: 020 ----
mean loss: 131.18
 ---- batch: 030 ----
mean loss: 128.37
train mean loss: 130.05
epoch train time: 0:00:06.923140
elapsed time: 0:11:36.398694
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 06:52:02.697138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.60
 ---- batch: 020 ----
mean loss: 123.79
 ---- batch: 030 ----
mean loss: 125.46
train mean loss: 128.21
epoch train time: 0:00:06.842408
elapsed time: 0:11:43.241842
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 06:52:09.540285
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.03
 ---- batch: 020 ----
mean loss: 127.05
 ---- batch: 030 ----
mean loss: 122.79
train mean loss: 127.19
epoch train time: 0:00:06.836066
elapsed time: 0:11:50.079041
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 06:52:16.377544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.61
 ---- batch: 020 ----
mean loss: 121.72
 ---- batch: 030 ----
mean loss: 128.20
train mean loss: 125.97
epoch train time: 0:00:06.907723
elapsed time: 0:11:56.987676
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 06:52:23.286141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.10
 ---- batch: 020 ----
mean loss: 129.32
 ---- batch: 030 ----
mean loss: 123.50
train mean loss: 126.08
epoch train time: 0:00:06.925877
elapsed time: 0:12:03.914436
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 06:52:30.212905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.00
 ---- batch: 020 ----
mean loss: 127.47
 ---- batch: 030 ----
mean loss: 123.29
train mean loss: 124.60
epoch train time: 0:00:06.837310
elapsed time: 0:12:10.752594
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 06:52:37.051083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.46
 ---- batch: 020 ----
mean loss: 120.95
 ---- batch: 030 ----
mean loss: 123.32
train mean loss: 123.99
epoch train time: 0:00:06.937342
elapsed time: 0:12:17.690735
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 06:52:43.989188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.46
 ---- batch: 020 ----
mean loss: 125.28
 ---- batch: 030 ----
mean loss: 124.77
train mean loss: 124.73
epoch train time: 0:00:06.856333
elapsed time: 0:12:24.547912
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 06:52:50.846368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.85
 ---- batch: 020 ----
mean loss: 126.31
 ---- batch: 030 ----
mean loss: 121.44
train mean loss: 123.36
epoch train time: 0:00:06.907692
elapsed time: 0:12:31.456687
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 06:52:57.755068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.28
 ---- batch: 020 ----
mean loss: 124.35
 ---- batch: 030 ----
mean loss: 121.80
train mean loss: 123.36
epoch train time: 0:00:06.812924
elapsed time: 0:12:38.270306
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 06:53:04.568782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.75
 ---- batch: 020 ----
mean loss: 121.20
 ---- batch: 030 ----
mean loss: 116.05
train mean loss: 121.32
epoch train time: 0:00:06.895367
elapsed time: 0:12:45.166492
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 06:53:11.464932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.34
 ---- batch: 020 ----
mean loss: 121.15
 ---- batch: 030 ----
mean loss: 122.98
train mean loss: 121.11
epoch train time: 0:00:06.925847
elapsed time: 0:12:52.093144
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 06:53:18.391643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.14
 ---- batch: 020 ----
mean loss: 119.44
 ---- batch: 030 ----
mean loss: 121.75
train mean loss: 119.74
epoch train time: 0:00:06.869262
elapsed time: 0:12:58.963256
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 06:53:25.261776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.82
 ---- batch: 020 ----
mean loss: 121.62
 ---- batch: 030 ----
mean loss: 116.75
train mean loss: 120.93
epoch train time: 0:00:06.915958
elapsed time: 0:13:05.880112
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 06:53:32.178561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.86
 ---- batch: 020 ----
mean loss: 122.05
 ---- batch: 030 ----
mean loss: 118.33
train mean loss: 120.64
epoch train time: 0:00:06.797211
elapsed time: 0:13:12.678128
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 06:53:38.976640
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.43
 ---- batch: 020 ----
mean loss: 118.92
 ---- batch: 030 ----
mean loss: 120.87
train mean loss: 120.48
epoch train time: 0:00:06.967076
elapsed time: 0:13:19.646065
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 06:53:45.944561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.83
 ---- batch: 020 ----
mean loss: 118.78
 ---- batch: 030 ----
mean loss: 121.10
train mean loss: 119.55
epoch train time: 0:00:06.787705
elapsed time: 0:13:26.434584
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 06:53:52.733071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.07
 ---- batch: 020 ----
mean loss: 114.53
 ---- batch: 030 ----
mean loss: 120.56
train mean loss: 118.20
epoch train time: 0:00:06.938348
elapsed time: 0:13:33.373825
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 06:53:59.672264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.75
 ---- batch: 020 ----
mean loss: 119.01
 ---- batch: 030 ----
mean loss: 119.26
train mean loss: 119.08
epoch train time: 0:00:06.915970
elapsed time: 0:13:40.290510
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 06:54:06.588957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.43
 ---- batch: 020 ----
mean loss: 119.98
 ---- batch: 030 ----
mean loss: 122.41
train mean loss: 120.78
epoch train time: 0:00:06.809213
elapsed time: 0:13:47.100481
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 06:54:13.398939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.69
 ---- batch: 020 ----
mean loss: 116.64
 ---- batch: 030 ----
mean loss: 119.76
train mean loss: 118.87
epoch train time: 0:00:06.909343
elapsed time: 0:13:54.010640
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 06:54:20.309195
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.63
 ---- batch: 020 ----
mean loss: 113.62
 ---- batch: 030 ----
mean loss: 116.78
train mean loss: 116.91
epoch train time: 0:00:06.825681
elapsed time: 0:14:00.837243
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 06:54:27.135692
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.17
 ---- batch: 020 ----
mean loss: 118.15
 ---- batch: 030 ----
mean loss: 117.81
train mean loss: 119.12
epoch train time: 0:00:06.918027
elapsed time: 0:14:07.755993
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 06:54:34.054442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.18
 ---- batch: 020 ----
mean loss: 115.28
 ---- batch: 030 ----
mean loss: 117.60
train mean loss: 115.49
epoch train time: 0:00:06.794048
elapsed time: 0:14:14.550801
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 06:54:40.849278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.17
 ---- batch: 020 ----
mean loss: 117.66
 ---- batch: 030 ----
mean loss: 120.24
train mean loss: 118.05
epoch train time: 0:00:06.937741
elapsed time: 0:14:21.489348
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 06:54:47.787842
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.38
 ---- batch: 020 ----
mean loss: 114.16
 ---- batch: 030 ----
mean loss: 117.44
train mean loss: 116.50
epoch train time: 0:00:06.791238
elapsed time: 0:14:28.281414
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 06:54:54.579875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.62
 ---- batch: 020 ----
mean loss: 115.22
 ---- batch: 030 ----
mean loss: 120.71
train mean loss: 118.29
epoch train time: 0:00:06.931737
elapsed time: 0:14:35.213925
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 06:55:01.512367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.28
 ---- batch: 020 ----
mean loss: 114.66
 ---- batch: 030 ----
mean loss: 111.48
train mean loss: 114.69
epoch train time: 0:00:06.898069
elapsed time: 0:14:42.112779
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 06:55:08.411258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.42
 ---- batch: 020 ----
mean loss: 117.17
 ---- batch: 030 ----
mean loss: 115.17
train mean loss: 115.22
epoch train time: 0:00:06.852295
elapsed time: 0:14:48.966069
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 06:55:15.264421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.65
 ---- batch: 020 ----
mean loss: 112.80
 ---- batch: 030 ----
mean loss: 118.44
train mean loss: 116.19
epoch train time: 0:00:06.945559
elapsed time: 0:14:55.912328
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 06:55:22.210787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.90
 ---- batch: 020 ----
mean loss: 114.20
 ---- batch: 030 ----
mean loss: 109.91
train mean loss: 113.34
epoch train time: 0:00:06.811428
elapsed time: 0:15:02.724525
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 06:55:29.022988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.90
 ---- batch: 020 ----
mean loss: 112.97
 ---- batch: 030 ----
mean loss: 110.25
train mean loss: 112.38
epoch train time: 0:00:06.915421
elapsed time: 0:15:09.640727
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 06:55:35.939177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.45
 ---- batch: 020 ----
mean loss: 112.50
 ---- batch: 030 ----
mean loss: 113.35
train mean loss: 114.15
epoch train time: 0:00:06.862549
elapsed time: 0:15:16.504082
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 06:55:42.802538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.03
 ---- batch: 020 ----
mean loss: 112.66
 ---- batch: 030 ----
mean loss: 112.45
train mean loss: 112.85
epoch train time: 0:00:06.864958
elapsed time: 0:15:23.369836
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 06:55:49.668293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.83
 ---- batch: 020 ----
mean loss: 115.76
 ---- batch: 030 ----
mean loss: 105.84
train mean loss: 112.50
epoch train time: 0:00:06.834114
elapsed time: 0:15:30.204810
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 06:55:56.503272
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.17
 ---- batch: 020 ----
mean loss: 113.88
 ---- batch: 030 ----
mean loss: 111.23
train mean loss: 112.12
epoch train time: 0:00:07.008889
elapsed time: 0:15:37.214506
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 06:56:03.512944
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.34
 ---- batch: 020 ----
mean loss: 109.93
 ---- batch: 030 ----
mean loss: 112.19
train mean loss: 111.42
epoch train time: 0:00:06.830825
elapsed time: 0:15:44.046090
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 06:56:10.344581
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.07
 ---- batch: 020 ----
mean loss: 109.70
 ---- batch: 030 ----
mean loss: 116.82
train mean loss: 112.61
epoch train time: 0:00:06.902236
elapsed time: 0:15:50.949291
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 06:56:17.247733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.40
 ---- batch: 020 ----
mean loss: 111.96
 ---- batch: 030 ----
mean loss: 110.16
train mean loss: 111.93
epoch train time: 0:00:06.937365
elapsed time: 0:15:57.887444
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 06:56:24.185898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.18
 ---- batch: 020 ----
mean loss: 110.63
 ---- batch: 030 ----
mean loss: 109.49
train mean loss: 110.11
epoch train time: 0:00:06.791524
elapsed time: 0:16:04.679823
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 06:56:30.978273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.46
 ---- batch: 020 ----
mean loss: 112.19
 ---- batch: 030 ----
mean loss: 109.10
train mean loss: 110.28
epoch train time: 0:00:06.879274
elapsed time: 0:16:11.559883
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 06:56:37.858336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.27
 ---- batch: 020 ----
mean loss: 111.47
 ---- batch: 030 ----
mean loss: 111.18
train mean loss: 110.17
epoch train time: 0:00:06.818783
elapsed time: 0:16:18.379454
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 06:56:44.677905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.58
 ---- batch: 020 ----
mean loss: 109.34
 ---- batch: 030 ----
mean loss: 109.96
train mean loss: 109.85
epoch train time: 0:00:06.925054
elapsed time: 0:16:25.305420
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 06:56:51.604003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.85
 ---- batch: 020 ----
mean loss: 111.52
 ---- batch: 030 ----
mean loss: 110.12
train mean loss: 112.04
epoch train time: 0:00:06.908580
elapsed time: 0:16:32.215032
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 06:56:58.513508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.89
 ---- batch: 020 ----
mean loss: 110.26
 ---- batch: 030 ----
mean loss: 114.23
train mean loss: 111.00
epoch train time: 0:00:07.080116
elapsed time: 0:16:39.295946
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 06:57:05.594387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.13
 ---- batch: 020 ----
mean loss: 110.39
 ---- batch: 030 ----
mean loss: 113.08
train mean loss: 109.62
epoch train time: 0:00:06.957016
elapsed time: 0:16:46.253773
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 06:57:12.552256
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.73
 ---- batch: 020 ----
mean loss: 107.50
 ---- batch: 030 ----
mean loss: 109.79
train mean loss: 107.48
epoch train time: 0:00:07.002955
elapsed time: 0:16:53.257586
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 06:57:19.556042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.86
 ---- batch: 020 ----
mean loss: 111.76
 ---- batch: 030 ----
mean loss: 104.16
train mean loss: 107.66
epoch train time: 0:00:06.847748
elapsed time: 0:17:00.106178
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 06:57:26.404634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.11
 ---- batch: 020 ----
mean loss: 110.43
 ---- batch: 030 ----
mean loss: 107.82
train mean loss: 109.34
epoch train time: 0:00:06.869711
elapsed time: 0:17:06.976792
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 06:57:33.275304
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.95
 ---- batch: 020 ----
mean loss: 107.14
 ---- batch: 030 ----
mean loss: 106.88
train mean loss: 106.08
epoch train time: 0:00:06.891037
elapsed time: 0:17:13.868687
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 06:57:40.167132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.59
 ---- batch: 020 ----
mean loss: 108.07
 ---- batch: 030 ----
mean loss: 105.54
train mean loss: 106.85
epoch train time: 0:00:06.948231
elapsed time: 0:17:20.817834
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 06:57:47.116209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.82
 ---- batch: 020 ----
mean loss: 106.39
 ---- batch: 030 ----
mean loss: 105.97
train mean loss: 106.42
epoch train time: 0:00:06.845382
elapsed time: 0:17:27.664033
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 06:57:53.962495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.62
 ---- batch: 020 ----
mean loss: 109.05
 ---- batch: 030 ----
mean loss: 106.55
train mean loss: 107.09
epoch train time: 0:00:06.892035
elapsed time: 0:17:34.556840
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 06:58:00.855333
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.34
 ---- batch: 020 ----
mean loss: 108.38
 ---- batch: 030 ----
mean loss: 112.44
train mean loss: 109.15
epoch train time: 0:00:06.859336
elapsed time: 0:17:41.417204
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 06:58:07.715704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.76
 ---- batch: 020 ----
mean loss: 109.67
 ---- batch: 030 ----
mean loss: 102.74
train mean loss: 107.09
epoch train time: 0:00:06.877265
elapsed time: 0:17:48.295388
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 06:58:14.593857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.36
 ---- batch: 020 ----
mean loss: 106.68
 ---- batch: 030 ----
mean loss: 109.18
train mean loss: 107.31
epoch train time: 0:00:06.944086
elapsed time: 0:17:55.240401
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 06:58:21.538856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.50
 ---- batch: 020 ----
mean loss: 106.97
 ---- batch: 030 ----
mean loss: 105.18
train mean loss: 106.27
epoch train time: 0:00:06.870308
elapsed time: 0:18:02.111485
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 06:58:28.409940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.94
 ---- batch: 020 ----
mean loss: 104.86
 ---- batch: 030 ----
mean loss: 110.76
train mean loss: 106.73
epoch train time: 0:00:06.864695
elapsed time: 0:18:08.977235
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 06:58:35.275724
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.99
 ---- batch: 020 ----
mean loss: 101.38
 ---- batch: 030 ----
mean loss: 105.87
train mean loss: 104.99
epoch train time: 0:00:06.741365
elapsed time: 0:18:15.719419
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 06:58:42.017866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.83
 ---- batch: 020 ----
mean loss: 105.46
 ---- batch: 030 ----
mean loss: 106.35
train mean loss: 105.95
epoch train time: 0:00:06.973536
elapsed time: 0:18:22.693828
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 06:58:48.992307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.42
 ---- batch: 020 ----
mean loss: 106.33
 ---- batch: 030 ----
mean loss: 106.91
train mean loss: 105.06
epoch train time: 0:00:06.871584
elapsed time: 0:18:29.566289
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 06:58:55.864742
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.42
 ---- batch: 020 ----
mean loss: 102.59
 ---- batch: 030 ----
mean loss: 103.58
train mean loss: 104.58
epoch train time: 0:00:06.871356
elapsed time: 0:18:36.438663
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 06:59:02.737125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.39
 ---- batch: 020 ----
mean loss: 102.15
 ---- batch: 030 ----
mean loss: 105.39
train mean loss: 105.22
epoch train time: 0:00:06.910466
elapsed time: 0:18:43.349965
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 06:59:09.648482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.38
 ---- batch: 020 ----
mean loss: 106.34
 ---- batch: 030 ----
mean loss: 104.43
train mean loss: 106.40
epoch train time: 0:00:06.954284
elapsed time: 0:18:50.305014
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 06:59:16.603479
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.85
 ---- batch: 020 ----
mean loss: 105.83
 ---- batch: 030 ----
mean loss: 104.49
train mean loss: 104.27
epoch train time: 0:00:06.772287
elapsed time: 0:18:57.078120
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 06:59:23.376592
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.10
 ---- batch: 020 ----
mean loss: 103.88
 ---- batch: 030 ----
mean loss: 100.44
train mean loss: 102.69
epoch train time: 0:00:06.910762
elapsed time: 0:19:03.989862
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 06:59:30.288327
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.98
 ---- batch: 020 ----
mean loss: 102.41
 ---- batch: 030 ----
mean loss: 103.00
train mean loss: 102.41
epoch train time: 0:00:06.914704
elapsed time: 0:19:10.905380
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 06:59:37.203824
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.56
 ---- batch: 020 ----
mean loss: 101.35
 ---- batch: 030 ----
mean loss: 104.79
train mean loss: 103.44
epoch train time: 0:00:06.757524
elapsed time: 0:19:17.663684
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 06:59:43.962136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.06
 ---- batch: 020 ----
mean loss: 104.14
 ---- batch: 030 ----
mean loss: 102.65
train mean loss: 103.73
epoch train time: 0:00:06.892736
elapsed time: 0:19:24.557329
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 06:59:50.855778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.52
 ---- batch: 020 ----
mean loss: 101.32
 ---- batch: 030 ----
mean loss: 105.07
train mean loss: 103.71
epoch train time: 0:00:06.906782
elapsed time: 0:19:31.464895
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 06:59:57.763372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.12
 ---- batch: 020 ----
mean loss: 99.19
 ---- batch: 030 ----
mean loss: 101.99
train mean loss: 102.18
epoch train time: 0:00:06.750882
elapsed time: 0:19:38.216573
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 07:00:04.515053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.34
 ---- batch: 020 ----
mean loss: 100.50
 ---- batch: 030 ----
mean loss: 102.25
train mean loss: 102.47
epoch train time: 0:00:06.868155
elapsed time: 0:19:45.085557
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 07:00:11.384007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.47
 ---- batch: 020 ----
mean loss: 105.82
 ---- batch: 030 ----
mean loss: 99.63
train mean loss: 101.89
epoch train time: 0:00:06.773423
elapsed time: 0:19:51.859771
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 07:00:18.158218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.83
 ---- batch: 020 ----
mean loss: 100.85
 ---- batch: 030 ----
mean loss: 101.33
train mean loss: 102.27
epoch train time: 0:00:06.869006
elapsed time: 0:19:58.729751
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 07:00:25.028205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.04
 ---- batch: 020 ----
mean loss: 100.76
 ---- batch: 030 ----
mean loss: 101.06
train mean loss: 101.96
epoch train time: 0:00:06.732919
elapsed time: 0:20:05.463457
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 07:00:31.761923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.92
 ---- batch: 020 ----
mean loss: 103.97
 ---- batch: 030 ----
mean loss: 100.77
train mean loss: 102.37
epoch train time: 0:00:06.812462
elapsed time: 0:20:12.276950
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 07:00:38.575307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.42
 ---- batch: 020 ----
mean loss: 101.75
 ---- batch: 030 ----
mean loss: 99.60
train mean loss: 100.31
epoch train time: 0:00:06.787183
elapsed time: 0:20:19.065024
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 07:00:45.363528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.87
 ---- batch: 020 ----
mean loss: 102.65
 ---- batch: 030 ----
mean loss: 99.46
train mean loss: 101.79
epoch train time: 0:00:06.755157
elapsed time: 0:20:25.821062
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 07:00:52.119529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.46
 ---- batch: 020 ----
mean loss: 101.67
 ---- batch: 030 ----
mean loss: 100.72
train mean loss: 100.38
epoch train time: 0:00:06.730811
elapsed time: 0:20:32.552676
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 07:00:58.851142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.59
 ---- batch: 020 ----
mean loss: 99.43
 ---- batch: 030 ----
mean loss: 102.48
train mean loss: 100.85
epoch train time: 0:00:06.784736
elapsed time: 0:20:39.338243
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 07:01:05.636697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.52
 ---- batch: 020 ----
mean loss: 101.61
 ---- batch: 030 ----
mean loss: 98.69
train mean loss: 99.87
epoch train time: 0:00:06.856159
elapsed time: 0:20:46.195176
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 07:01:12.493661
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.55
 ---- batch: 020 ----
mean loss: 99.03
 ---- batch: 030 ----
mean loss: 100.18
train mean loss: 100.57
epoch train time: 0:00:06.925172
elapsed time: 0:20:53.121160
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 07:01:19.419628
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.29
 ---- batch: 020 ----
mean loss: 103.44
 ---- batch: 030 ----
mean loss: 99.09
train mean loss: 99.44
epoch train time: 0:00:06.813748
elapsed time: 0:20:59.935707
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 07:01:26.234162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.86
 ---- batch: 020 ----
mean loss: 101.04
 ---- batch: 030 ----
mean loss: 101.27
train mean loss: 99.30
epoch train time: 0:00:06.887847
elapsed time: 0:21:06.824351
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 07:01:33.122803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.98
 ---- batch: 020 ----
mean loss: 99.47
 ---- batch: 030 ----
mean loss: 100.36
train mean loss: 99.50
epoch train time: 0:00:06.912303
elapsed time: 0:21:13.737430
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 07:01:40.035875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.06
 ---- batch: 020 ----
mean loss: 99.39
 ---- batch: 030 ----
mean loss: 100.89
train mean loss: 99.97
epoch train time: 0:00:06.930996
elapsed time: 0:21:20.669308
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 07:01:46.967760
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.74
 ---- batch: 020 ----
mean loss: 98.92
 ---- batch: 030 ----
mean loss: 100.70
train mean loss: 99.55
epoch train time: 0:00:06.800597
elapsed time: 0:21:27.470696
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 07:01:53.769148
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.08
 ---- batch: 020 ----
mean loss: 102.02
 ---- batch: 030 ----
mean loss: 94.82
train mean loss: 99.91
epoch train time: 0:00:06.887316
elapsed time: 0:21:34.358772
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 07:02:00.657232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.70
 ---- batch: 020 ----
mean loss: 99.54
 ---- batch: 030 ----
mean loss: 96.66
train mean loss: 98.59
epoch train time: 0:00:06.710562
elapsed time: 0:21:41.070079
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 07:02:07.368536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.52
 ---- batch: 020 ----
mean loss: 101.08
 ---- batch: 030 ----
mean loss: 100.02
train mean loss: 98.93
epoch train time: 0:00:06.820291
elapsed time: 0:21:47.891168
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 07:02:14.189639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.90
 ---- batch: 020 ----
mean loss: 96.20
 ---- batch: 030 ----
mean loss: 100.93
train mean loss: 97.80
epoch train time: 0:00:07.024980
elapsed time: 0:21:54.917002
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 07:02:21.215446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.31
 ---- batch: 020 ----
mean loss: 98.22
 ---- batch: 030 ----
mean loss: 101.65
train mean loss: 98.34
epoch train time: 0:00:06.738927
elapsed time: 0:22:01.656723
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 07:02:27.955210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.04
 ---- batch: 020 ----
mean loss: 97.26
 ---- batch: 030 ----
mean loss: 96.00
train mean loss: 97.84
epoch train time: 0:00:06.896661
elapsed time: 0:22:08.554309
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 07:02:34.852769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.05
 ---- batch: 020 ----
mean loss: 98.37
 ---- batch: 030 ----
mean loss: 96.63
train mean loss: 98.88
epoch train time: 0:00:06.921539
elapsed time: 0:22:15.476705
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 07:02:41.775224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.07
 ---- batch: 020 ----
mean loss: 97.14
 ---- batch: 030 ----
mean loss: 99.45
train mean loss: 98.00
epoch train time: 0:00:06.781706
elapsed time: 0:22:22.259261
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 07:02:48.557718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.42
 ---- batch: 020 ----
mean loss: 101.36
 ---- batch: 030 ----
mean loss: 96.92
train mean loss: 98.54
epoch train time: 0:00:07.017295
elapsed time: 0:22:29.277432
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 07:02:55.575892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.86
 ---- batch: 020 ----
mean loss: 98.64
 ---- batch: 030 ----
mean loss: 97.17
train mean loss: 97.31
epoch train time: 0:00:06.943294
elapsed time: 0:22:36.221585
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 07:03:02.520057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.59
 ---- batch: 020 ----
mean loss: 100.82
 ---- batch: 030 ----
mean loss: 95.91
train mean loss: 98.31
epoch train time: 0:00:07.035200
elapsed time: 0:22:43.257681
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 07:03:09.556126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.05
 ---- batch: 020 ----
mean loss: 98.66
 ---- batch: 030 ----
mean loss: 93.86
train mean loss: 96.62
epoch train time: 0:00:06.891163
elapsed time: 0:22:50.149596
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 07:03:16.448057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.13
 ---- batch: 020 ----
mean loss: 98.06
 ---- batch: 030 ----
mean loss: 96.26
train mean loss: 97.30
epoch train time: 0:00:06.991576
elapsed time: 0:22:57.141920
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 07:03:23.440370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.05
 ---- batch: 020 ----
mean loss: 97.22
 ---- batch: 030 ----
mean loss: 98.01
train mean loss: 96.58
epoch train time: 0:00:06.870431
elapsed time: 0:23:04.013132
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 07:03:30.311580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.04
 ---- batch: 020 ----
mean loss: 96.75
 ---- batch: 030 ----
mean loss: 98.35
train mean loss: 97.94
epoch train time: 0:00:06.764095
elapsed time: 0:23:10.778003
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 07:03:37.076453
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.57
 ---- batch: 020 ----
mean loss: 97.07
 ---- batch: 030 ----
mean loss: 99.20
train mean loss: 96.70
epoch train time: 0:00:06.632278
elapsed time: 0:23:17.411057
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 07:03:43.709533
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.31
 ---- batch: 020 ----
mean loss: 95.54
 ---- batch: 030 ----
mean loss: 97.06
train mean loss: 95.96
epoch train time: 0:00:06.701273
elapsed time: 0:23:24.113268
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 07:03:50.411626
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.52
 ---- batch: 020 ----
mean loss: 95.47
 ---- batch: 030 ----
mean loss: 97.61
train mean loss: 96.71
epoch train time: 0:00:06.678030
elapsed time: 0:23:30.791979
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 07:03:57.090459
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.86
 ---- batch: 020 ----
mean loss: 95.52
 ---- batch: 030 ----
mean loss: 96.47
train mean loss: 95.31
epoch train time: 0:00:06.703778
elapsed time: 0:23:37.496585
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 07:04:03.795040
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 100.78
 ---- batch: 020 ----
mean loss: 93.06
 ---- batch: 030 ----
mean loss: 97.66
train mean loss: 96.41
epoch train time: 0:00:06.812656
elapsed time: 0:23:44.310036
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 07:04:10.608484
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.58
 ---- batch: 020 ----
mean loss: 95.20
 ---- batch: 030 ----
mean loss: 94.25
train mean loss: 95.36
epoch train time: 0:00:06.822966
elapsed time: 0:23:51.133810
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 07:04:17.432245
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.52
 ---- batch: 020 ----
mean loss: 97.02
 ---- batch: 030 ----
mean loss: 92.62
train mean loss: 95.20
epoch train time: 0:00:06.824992
elapsed time: 0:23:57.959572
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 07:04:24.258039
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.16
 ---- batch: 020 ----
mean loss: 95.43
 ---- batch: 030 ----
mean loss: 95.11
train mean loss: 95.35
epoch train time: 0:00:06.620754
elapsed time: 0:24:04.581143
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 07:04:30.879612
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.58
 ---- batch: 020 ----
mean loss: 91.30
 ---- batch: 030 ----
mean loss: 96.34
train mean loss: 95.69
epoch train time: 0:00:06.691843
elapsed time: 0:24:11.273788
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 07:04:37.572243
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 98.63
 ---- batch: 020 ----
mean loss: 95.83
 ---- batch: 030 ----
mean loss: 92.86
train mean loss: 95.39
epoch train time: 0:00:06.585099
elapsed time: 0:24:17.859772
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 07:04:44.158138
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 98.07
 ---- batch: 020 ----
mean loss: 95.40
 ---- batch: 030 ----
mean loss: 96.35
train mean loss: 96.44
epoch train time: 0:00:06.772833
elapsed time: 0:24:24.633498
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 07:04:50.931900
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.66
 ---- batch: 020 ----
mean loss: 96.19
 ---- batch: 030 ----
mean loss: 94.76
train mean loss: 95.70
epoch train time: 0:00:06.827131
elapsed time: 0:24:31.461357
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 07:04:57.759805
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.04
 ---- batch: 020 ----
mean loss: 98.80
 ---- batch: 030 ----
mean loss: 94.62
train mean loss: 95.01
epoch train time: 0:00:06.908944
elapsed time: 0:24:38.371101
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 07:05:04.669553
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 99.01
 ---- batch: 020 ----
mean loss: 94.19
 ---- batch: 030 ----
mean loss: 95.51
train mean loss: 96.10
epoch train time: 0:00:07.066233
elapsed time: 0:24:45.438160
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 07:05:11.736620
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.92
 ---- batch: 020 ----
mean loss: 95.87
 ---- batch: 030 ----
mean loss: 93.09
train mean loss: 95.91
epoch train time: 0:00:06.801619
elapsed time: 0:24:52.240554
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 07:05:18.539012
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.61
 ---- batch: 020 ----
mean loss: 91.39
 ---- batch: 030 ----
mean loss: 100.33
train mean loss: 95.47
epoch train time: 0:00:06.932092
elapsed time: 0:24:59.173501
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 07:05:25.471997
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.58
 ---- batch: 020 ----
mean loss: 98.41
 ---- batch: 030 ----
mean loss: 93.66
train mean loss: 95.52
epoch train time: 0:00:06.798758
elapsed time: 0:25:05.973152
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 07:05:32.271641
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 91.66
 ---- batch: 020 ----
mean loss: 96.77
 ---- batch: 030 ----
mean loss: 98.43
train mean loss: 95.40
epoch train time: 0:00:06.996261
elapsed time: 0:25:12.970213
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 07:05:39.268656
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.27
 ---- batch: 020 ----
mean loss: 95.03
 ---- batch: 030 ----
mean loss: 94.39
train mean loss: 96.18
epoch train time: 0:00:06.833723
elapsed time: 0:25:19.804751
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 07:05:46.103204
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.10
 ---- batch: 020 ----
mean loss: 96.63
 ---- batch: 030 ----
mean loss: 94.90
train mean loss: 94.58
epoch train time: 0:00:06.852002
elapsed time: 0:25:26.657514
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 07:05:52.956011
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.74
 ---- batch: 020 ----
mean loss: 96.28
 ---- batch: 030 ----
mean loss: 94.70
train mean loss: 95.01
epoch train time: 0:00:06.823769
elapsed time: 0:25:33.482079
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 07:05:59.780533
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.63
 ---- batch: 020 ----
mean loss: 96.13
 ---- batch: 030 ----
mean loss: 94.60
train mean loss: 95.20
epoch train time: 0:00:06.826007
elapsed time: 0:25:40.308942
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 07:06:06.607437
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.24
 ---- batch: 020 ----
mean loss: 95.14
 ---- batch: 030 ----
mean loss: 91.67
train mean loss: 95.26
epoch train time: 0:00:06.858780
elapsed time: 0:25:47.168563
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 07:06:13.466997
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.82
 ---- batch: 020 ----
mean loss: 95.60
 ---- batch: 030 ----
mean loss: 97.22
train mean loss: 95.39
epoch train time: 0:00:06.737507
elapsed time: 0:25:53.906807
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 07:06:20.205263
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 98.41
 ---- batch: 020 ----
mean loss: 93.80
 ---- batch: 030 ----
mean loss: 94.57
train mean loss: 95.43
epoch train time: 0:00:06.818173
elapsed time: 0:26:00.725826
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 07:06:27.024283
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.96
 ---- batch: 020 ----
mean loss: 94.85
 ---- batch: 030 ----
mean loss: 97.80
train mean loss: 95.32
epoch train time: 0:00:06.786155
elapsed time: 0:26:07.512777
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 07:06:33.811230
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.90
 ---- batch: 020 ----
mean loss: 98.13
 ---- batch: 030 ----
mean loss: 96.56
train mean loss: 95.78
epoch train time: 0:00:06.821614
elapsed time: 0:26:14.335245
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 07:06:40.633719
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.54
 ---- batch: 020 ----
mean loss: 98.02
 ---- batch: 030 ----
mean loss: 92.79
train mean loss: 95.37
epoch train time: 0:00:06.890556
elapsed time: 0:26:21.226645
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 07:06:47.525101
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 92.30
 ---- batch: 020 ----
mean loss: 95.61
 ---- batch: 030 ----
mean loss: 96.33
train mean loss: 95.19
epoch train time: 0:00:06.834712
elapsed time: 0:26:28.062145
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 07:06:54.360590
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.94
 ---- batch: 020 ----
mean loss: 95.51
 ---- batch: 030 ----
mean loss: 94.03
train mean loss: 95.29
epoch train time: 0:00:06.835359
elapsed time: 0:26:34.898289
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 07:07:01.196740
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.59
 ---- batch: 020 ----
mean loss: 97.08
 ---- batch: 030 ----
mean loss: 94.84
train mean loss: 95.49
epoch train time: 0:00:06.927318
elapsed time: 0:26:41.826407
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 07:07:08.124893
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.10
 ---- batch: 020 ----
mean loss: 94.91
 ---- batch: 030 ----
mean loss: 93.04
train mean loss: 94.81
epoch train time: 0:00:06.743624
elapsed time: 0:26:48.570822
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 07:07:14.869267
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.48
 ---- batch: 020 ----
mean loss: 95.04
 ---- batch: 030 ----
mean loss: 94.56
train mean loss: 95.04
epoch train time: 0:00:06.869548
elapsed time: 0:26:55.441168
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 07:07:21.739634
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.00
 ---- batch: 020 ----
mean loss: 95.50
 ---- batch: 030 ----
mean loss: 93.39
train mean loss: 94.76
epoch train time: 0:00:06.857641
elapsed time: 0:27:02.299832
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 07:07:28.598179
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 98.08
 ---- batch: 020 ----
mean loss: 94.47
 ---- batch: 030 ----
mean loss: 93.57
train mean loss: 95.22
epoch train time: 0:00:06.924962
elapsed time: 0:27:09.225494
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 07:07:35.523949
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.20
 ---- batch: 020 ----
mean loss: 94.00
 ---- batch: 030 ----
mean loss: 92.79
train mean loss: 94.75
epoch train time: 0:00:06.882645
elapsed time: 0:27:16.108950
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 07:07:42.407440
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.29
 ---- batch: 020 ----
mean loss: 92.73
 ---- batch: 030 ----
mean loss: 93.84
train mean loss: 95.08
epoch train time: 0:00:06.920864
elapsed time: 0:27:23.030651
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 07:07:49.329103
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.15
 ---- batch: 020 ----
mean loss: 95.68
 ---- batch: 030 ----
mean loss: 94.84
train mean loss: 95.26
epoch train time: 0:00:06.890344
elapsed time: 0:27:29.921810
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 07:07:56.220287
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.72
 ---- batch: 020 ----
mean loss: 94.85
 ---- batch: 030 ----
mean loss: 93.43
train mean loss: 94.72
epoch train time: 0:00:06.781779
elapsed time: 0:27:36.704446
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 07:08:03.002924
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 93.85
 ---- batch: 020 ----
mean loss: 94.15
 ---- batch: 030 ----
mean loss: 93.76
train mean loss: 94.91
epoch train time: 0:00:06.583597
elapsed time: 0:27:43.288875
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 07:08:09.587366
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 94.19
 ---- batch: 020 ----
mean loss: 95.87
 ---- batch: 030 ----
mean loss: 97.79
train mean loss: 95.60
epoch train time: 0:00:06.974620
elapsed time: 0:27:50.264417
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 07:08:16.562911
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.03
 ---- batch: 020 ----
mean loss: 93.20
 ---- batch: 030 ----
mean loss: 96.14
train mean loss: 94.98
epoch train time: 0:00:06.891670
elapsed time: 0:27:57.156926
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 07:08:23.455376
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.67
 ---- batch: 020 ----
mean loss: 92.61
 ---- batch: 030 ----
mean loss: 92.91
train mean loss: 93.85
epoch train time: 0:00:06.935924
elapsed time: 0:28:04.093689
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 07:08:30.392137
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.86
 ---- batch: 020 ----
mean loss: 95.28
 ---- batch: 030 ----
mean loss: 94.40
train mean loss: 95.30
epoch train time: 0:00:06.985749
elapsed time: 0:28:11.080216
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 07:08:37.378683
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 97.83
 ---- batch: 020 ----
mean loss: 94.67
 ---- batch: 030 ----
mean loss: 92.36
train mean loss: 95.16
epoch train time: 0:00:06.862633
elapsed time: 0:28:17.943651
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 07:08:44.242107
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 98.44
 ---- batch: 020 ----
mean loss: 94.43
 ---- batch: 030 ----
mean loss: 95.08
train mean loss: 95.50
epoch train time: 0:00:06.906647
elapsed time: 0:28:24.851087
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 07:08:51.149531
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 95.51
 ---- batch: 020 ----
mean loss: 96.41
 ---- batch: 030 ----
mean loss: 94.38
train mean loss: 95.11
epoch train time: 0:00:06.927768
elapsed time: 0:28:31.779650
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 07:08:58.078132
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.73
 ---- batch: 020 ----
mean loss: 93.99
 ---- batch: 030 ----
mean loss: 93.42
train mean loss: 95.08
epoch train time: 0:00:06.872986
elapsed time: 0:28:38.653463
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 07:09:04.951941
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 96.57
 ---- batch: 020 ----
mean loss: 95.24
 ---- batch: 030 ----
mean loss: 91.60
train mean loss: 95.09
epoch train time: 0:00:06.849266
elapsed time: 0:28:45.503571
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 07:09:11.802029
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.83
 ---- batch: 020 ----
mean loss: 96.66
 ---- batch: 030 ----
mean loss: 98.81
train mean loss: 94.89
epoch train time: 0:00:06.923058
elapsed time: 0:28:52.438085
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_2/checkpoint.pth.tar
**** end time: 2019-09-27 07:09:18.736422 ****
