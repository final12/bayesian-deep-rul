Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_2', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 28940
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 14:44:29.249342 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 14:44:29.259694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4059.97
 ---- batch: 020 ----
mean loss: 3902.71
 ---- batch: 030 ----
mean loss: 3934.03
train mean loss: 3959.72
epoch train time: 0:00:12.677007
elapsed time: 0:00:12.690499
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 14:44:41.939876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3860.90
 ---- batch: 020 ----
mean loss: 3766.70
 ---- batch: 030 ----
mean loss: 3718.77
train mean loss: 3774.10
epoch train time: 0:00:00.516975
elapsed time: 0:00:13.207706
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 14:44:42.457159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3608.63
 ---- batch: 020 ----
mean loss: 3535.16
 ---- batch: 030 ----
mean loss: 3476.71
train mean loss: 3518.32
epoch train time: 0:00:00.541211
elapsed time: 0:00:13.749206
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 14:44:42.998655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3338.01
 ---- batch: 020 ----
mean loss: 3254.05
 ---- batch: 030 ----
mean loss: 3235.72
train mean loss: 3269.52
epoch train time: 0:00:00.526720
elapsed time: 0:00:14.276218
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 14:44:43.525667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3090.33
 ---- batch: 020 ----
mean loss: 3021.67
 ---- batch: 030 ----
mean loss: 3093.65
train mean loss: 3052.37
epoch train time: 0:00:00.536231
elapsed time: 0:00:14.812766
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 14:44:44.062202
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2911.89
 ---- batch: 020 ----
mean loss: 2858.45
 ---- batch: 030 ----
mean loss: 2829.29
train mean loss: 2856.43
epoch train time: 0:00:00.530243
elapsed time: 0:00:15.343278
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 14:44:44.592722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2766.95
 ---- batch: 020 ----
mean loss: 2671.50
 ---- batch: 030 ----
mean loss: 2632.27
train mean loss: 2679.20
epoch train time: 0:00:00.521935
elapsed time: 0:00:15.865496
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 14:44:45.114930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2565.34
 ---- batch: 020 ----
mean loss: 2549.33
 ---- batch: 030 ----
mean loss: 2464.89
train mean loss: 2515.52
epoch train time: 0:00:00.509474
elapsed time: 0:00:16.375241
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 14:44:45.624679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2419.96
 ---- batch: 020 ----
mean loss: 2367.38
 ---- batch: 030 ----
mean loss: 2342.36
train mean loss: 2367.98
epoch train time: 0:00:00.531314
elapsed time: 0:00:16.906881
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 14:44:46.156315
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2296.17
 ---- batch: 020 ----
mean loss: 2235.23
 ---- batch: 030 ----
mean loss: 2220.90
train mean loss: 2240.24
epoch train time: 0:00:00.537210
elapsed time: 0:00:17.444451
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 14:44:46.693912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2150.34
 ---- batch: 020 ----
mean loss: 2133.14
 ---- batch: 030 ----
mean loss: 2086.85
train mean loss: 2116.76
epoch train time: 0:00:00.521406
elapsed time: 0:00:17.966167
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 14:44:47.215617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2030.09
 ---- batch: 020 ----
mean loss: 2025.80
 ---- batch: 030 ----
mean loss: 1956.23
train mean loss: 2006.19
epoch train time: 0:00:00.533470
elapsed time: 0:00:18.499949
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 14:44:47.749380
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1938.47
 ---- batch: 020 ----
mean loss: 1891.30
 ---- batch: 030 ----
mean loss: 1894.00
train mean loss: 1895.42
epoch train time: 0:00:00.528882
elapsed time: 0:00:19.029205
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 14:44:48.278635
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1865.62
 ---- batch: 020 ----
mean loss: 1803.20
 ---- batch: 030 ----
mean loss: 1750.46
train mean loss: 1790.25
epoch train time: 0:00:00.526228
elapsed time: 0:00:19.555749
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 14:44:48.805149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1717.80
 ---- batch: 020 ----
mean loss: 1694.51
 ---- batch: 030 ----
mean loss: 1675.09
train mean loss: 1689.94
epoch train time: 0:00:00.522486
elapsed time: 0:00:20.078469
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 14:44:49.327900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1613.67
 ---- batch: 020 ----
mean loss: 1600.79
 ---- batch: 030 ----
mean loss: 1589.99
train mean loss: 1595.31
epoch train time: 0:00:00.531171
elapsed time: 0:00:20.609921
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 14:44:49.859370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1529.82
 ---- batch: 020 ----
mean loss: 1500.00
 ---- batch: 030 ----
mean loss: 1487.98
train mean loss: 1500.40
epoch train time: 0:00:00.513045
elapsed time: 0:00:21.123290
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 14:44:50.372727
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1461.28
 ---- batch: 020 ----
mean loss: 1428.16
 ---- batch: 030 ----
mean loss: 1382.71
train mean loss: 1423.24
epoch train time: 0:00:00.522129
elapsed time: 0:00:21.645795
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 14:44:50.895216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1382.43
 ---- batch: 020 ----
mean loss: 1350.02
 ---- batch: 030 ----
mean loss: 1331.10
train mean loss: 1348.87
epoch train time: 0:00:00.520050
elapsed time: 0:00:22.166119
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 14:44:51.415566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1308.81
 ---- batch: 020 ----
mean loss: 1287.58
 ---- batch: 030 ----
mean loss: 1266.54
train mean loss: 1283.64
epoch train time: 0:00:00.523631
elapsed time: 0:00:22.690028
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 14:44:51.939456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1225.87
 ---- batch: 020 ----
mean loss: 1223.78
 ---- batch: 030 ----
mean loss: 1201.76
train mean loss: 1219.37
epoch train time: 0:00:00.517466
elapsed time: 0:00:23.207774
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 14:44:52.457208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1169.47
 ---- batch: 020 ----
mean loss: 1186.72
 ---- batch: 030 ----
mean loss: 1151.62
train mean loss: 1160.17
epoch train time: 0:00:00.518107
elapsed time: 0:00:23.726159
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 14:44:52.975603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1128.28
 ---- batch: 020 ----
mean loss: 1109.39
 ---- batch: 030 ----
mean loss: 1100.94
train mean loss: 1103.76
epoch train time: 0:00:00.517871
elapsed time: 0:00:24.244404
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 14:44:53.493843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1066.44
 ---- batch: 020 ----
mean loss: 1067.53
 ---- batch: 030 ----
mean loss: 1055.72
train mean loss: 1054.58
epoch train time: 0:00:00.521567
elapsed time: 0:00:24.766248
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 14:44:54.015682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1030.65
 ---- batch: 020 ----
mean loss: 1023.73
 ---- batch: 030 ----
mean loss: 984.92
train mean loss: 1003.67
epoch train time: 0:00:00.521548
elapsed time: 0:00:25.288062
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 14:44:54.537514
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 960.44
 ---- batch: 020 ----
mean loss: 981.56
 ---- batch: 030 ----
mean loss: 955.87
train mean loss: 960.08
epoch train time: 0:00:00.518704
elapsed time: 0:00:25.807059
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 14:44:55.056498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 945.94
 ---- batch: 020 ----
mean loss: 936.86
 ---- batch: 030 ----
mean loss: 884.16
train mean loss: 924.48
epoch train time: 0:00:00.513481
elapsed time: 0:00:26.320816
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 14:44:55.570247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 904.39
 ---- batch: 020 ----
mean loss: 888.19
 ---- batch: 030 ----
mean loss: 862.54
train mean loss: 883.75
epoch train time: 0:00:00.513240
elapsed time: 0:00:26.834318
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 14:44:56.083780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 861.47
 ---- batch: 020 ----
mean loss: 866.75
 ---- batch: 030 ----
mean loss: 831.63
train mean loss: 848.27
epoch train time: 0:00:00.514621
elapsed time: 0:00:27.349249
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 14:44:56.598684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 825.58
 ---- batch: 020 ----
mean loss: 810.48
 ---- batch: 030 ----
mean loss: 804.29
train mean loss: 814.65
epoch train time: 0:00:00.529215
elapsed time: 0:00:27.878741
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 14:44:57.128194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 792.45
 ---- batch: 020 ----
mean loss: 775.61
 ---- batch: 030 ----
mean loss: 792.42
train mean loss: 785.45
epoch train time: 0:00:00.535842
elapsed time: 0:00:28.414912
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 14:44:57.664356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 767.72
 ---- batch: 020 ----
mean loss: 767.65
 ---- batch: 030 ----
mean loss: 749.49
train mean loss: 757.42
epoch train time: 0:00:00.533071
elapsed time: 0:00:28.948288
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 14:44:58.197726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 742.07
 ---- batch: 020 ----
mean loss: 728.46
 ---- batch: 030 ----
mean loss: 714.88
train mean loss: 729.40
epoch train time: 0:00:00.523784
elapsed time: 0:00:29.472382
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 14:44:58.721816
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 714.66
 ---- batch: 020 ----
mean loss: 720.20
 ---- batch: 030 ----
mean loss: 691.06
train mean loss: 705.24
epoch train time: 0:00:00.531375
elapsed time: 0:00:30.004052
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 14:44:59.253494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 683.18
 ---- batch: 020 ----
mean loss: 688.71
 ---- batch: 030 ----
mean loss: 677.02
train mean loss: 681.36
epoch train time: 0:00:00.522342
elapsed time: 0:00:30.526699
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 14:44:59.776119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 657.20
 ---- batch: 020 ----
mean loss: 659.62
 ---- batch: 030 ----
mean loss: 672.82
train mean loss: 661.23
epoch train time: 0:00:00.521594
elapsed time: 0:00:31.048562
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 14:45:00.297995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 654.34
 ---- batch: 020 ----
mean loss: 638.40
 ---- batch: 030 ----
mean loss: 634.21
train mean loss: 638.31
epoch train time: 0:00:00.527004
elapsed time: 0:00:31.575857
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 14:45:00.825296
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 625.79
 ---- batch: 020 ----
mean loss: 617.85
 ---- batch: 030 ----
mean loss: 621.33
train mean loss: 621.09
epoch train time: 0:00:00.522881
elapsed time: 0:00:32.099025
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 14:45:01.348466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 620.35
 ---- batch: 020 ----
mean loss: 607.75
 ---- batch: 030 ----
mean loss: 600.68
train mean loss: 605.44
epoch train time: 0:00:00.515816
elapsed time: 0:00:32.615124
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 14:45:01.864559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 592.41
 ---- batch: 020 ----
mean loss: 585.91
 ---- batch: 030 ----
mean loss: 590.51
train mean loss: 587.83
epoch train time: 0:00:00.526260
elapsed time: 0:00:33.141691
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 14:45:02.391133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 580.35
 ---- batch: 020 ----
mean loss: 565.29
 ---- batch: 030 ----
mean loss: 572.50
train mean loss: 573.62
epoch train time: 0:00:00.534797
elapsed time: 0:00:33.676909
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 14:45:02.926374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 562.98
 ---- batch: 020 ----
mean loss: 547.18
 ---- batch: 030 ----
mean loss: 564.63
train mean loss: 558.11
epoch train time: 0:00:00.519620
elapsed time: 0:00:34.196847
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 14:45:03.446321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 551.34
 ---- batch: 020 ----
mean loss: 544.49
 ---- batch: 030 ----
mean loss: 541.83
train mean loss: 545.74
epoch train time: 0:00:00.535342
elapsed time: 0:00:34.732500
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 14:45:03.981955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 533.27
 ---- batch: 020 ----
mean loss: 541.51
 ---- batch: 030 ----
mean loss: 533.09
train mean loss: 533.97
epoch train time: 0:00:00.518352
elapsed time: 0:00:35.251160
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 14:45:04.500591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 523.03
 ---- batch: 020 ----
mean loss: 512.01
 ---- batch: 030 ----
mean loss: 522.29
train mean loss: 518.25
epoch train time: 0:00:00.537985
elapsed time: 0:00:35.789415
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 14:45:05.038864
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 512.47
 ---- batch: 020 ----
mean loss: 510.55
 ---- batch: 030 ----
mean loss: 504.93
train mean loss: 509.82
epoch train time: 0:00:00.511484
elapsed time: 0:00:36.301217
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 14:45:05.550645
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 496.99
 ---- batch: 020 ----
mean loss: 502.00
 ---- batch: 030 ----
mean loss: 499.78
train mean loss: 498.40
epoch train time: 0:00:00.524945
elapsed time: 0:00:36.826436
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 14:45:06.075874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 496.75
 ---- batch: 020 ----
mean loss: 490.85
 ---- batch: 030 ----
mean loss: 493.69
train mean loss: 490.62
epoch train time: 0:00:00.517949
elapsed time: 0:00:37.344687
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 14:45:06.594135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 489.04
 ---- batch: 020 ----
mean loss: 483.25
 ---- batch: 030 ----
mean loss: 472.65
train mean loss: 479.43
epoch train time: 0:00:00.531822
elapsed time: 0:00:37.876805
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 14:45:07.126239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 484.60
 ---- batch: 020 ----
mean loss: 471.26
 ---- batch: 030 ----
mean loss: 471.67
train mean loss: 473.49
epoch train time: 0:00:00.520007
elapsed time: 0:00:38.397088
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 14:45:07.646522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 466.57
 ---- batch: 020 ----
mean loss: 464.55
 ---- batch: 030 ----
mean loss: 466.47
train mean loss: 464.34
epoch train time: 0:00:00.524042
elapsed time: 0:00:38.921406
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 14:45:08.170841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 458.04
 ---- batch: 020 ----
mean loss: 449.28
 ---- batch: 030 ----
mean loss: 459.91
train mean loss: 455.41
epoch train time: 0:00:00.515849
elapsed time: 0:00:39.437544
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 14:45:08.687036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 456.12
 ---- batch: 020 ----
mean loss: 450.88
 ---- batch: 030 ----
mean loss: 435.68
train mean loss: 447.93
epoch train time: 0:00:00.531463
elapsed time: 0:00:39.969358
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 14:45:09.218797
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 440.73
 ---- batch: 020 ----
mean loss: 448.23
 ---- batch: 030 ----
mean loss: 440.47
train mean loss: 443.21
epoch train time: 0:00:00.530221
elapsed time: 0:00:40.499874
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 14:45:09.749305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 441.78
 ---- batch: 020 ----
mean loss: 433.14
 ---- batch: 030 ----
mean loss: 433.50
train mean loss: 434.97
epoch train time: 0:00:00.522783
elapsed time: 0:00:41.022930
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 14:45:10.272361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 435.87
 ---- batch: 020 ----
mean loss: 429.18
 ---- batch: 030 ----
mean loss: 430.74
train mean loss: 430.23
epoch train time: 0:00:00.523771
elapsed time: 0:00:41.547045
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 14:45:10.796527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 425.27
 ---- batch: 020 ----
mean loss: 428.62
 ---- batch: 030 ----
mean loss: 418.70
train mean loss: 421.95
epoch train time: 0:00:00.527675
elapsed time: 0:00:42.075117
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 14:45:11.324591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 420.56
 ---- batch: 020 ----
mean loss: 416.24
 ---- batch: 030 ----
mean loss: 420.32
train mean loss: 417.56
epoch train time: 0:00:00.522829
elapsed time: 0:00:42.598287
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 14:45:11.847718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 410.75
 ---- batch: 020 ----
mean loss: 417.09
 ---- batch: 030 ----
mean loss: 409.29
train mean loss: 410.14
epoch train time: 0:00:00.517401
elapsed time: 0:00:43.116006
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 14:45:12.365441
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 409.36
 ---- batch: 020 ----
mean loss: 405.18
 ---- batch: 030 ----
mean loss: 397.54
train mean loss: 402.20
epoch train time: 0:00:00.544061
elapsed time: 0:00:43.660416
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 14:45:12.909847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 404.92
 ---- batch: 020 ----
mean loss: 391.78
 ---- batch: 030 ----
mean loss: 397.45
train mean loss: 399.12
epoch train time: 0:00:00.507084
elapsed time: 0:00:44.167768
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 14:45:13.417211
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 390.14
 ---- batch: 020 ----
mean loss: 389.01
 ---- batch: 030 ----
mean loss: 404.06
train mean loss: 393.61
epoch train time: 0:00:00.522273
elapsed time: 0:00:44.690395
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 14:45:13.939843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 386.43
 ---- batch: 020 ----
mean loss: 391.17
 ---- batch: 030 ----
mean loss: 384.08
train mean loss: 388.74
epoch train time: 0:00:00.531557
elapsed time: 0:00:45.222238
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 14:45:14.471670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 380.72
 ---- batch: 020 ----
mean loss: 389.56
 ---- batch: 030 ----
mean loss: 382.91
train mean loss: 384.06
epoch train time: 0:00:00.529616
elapsed time: 0:00:45.752136
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 14:45:15.001568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 385.21
 ---- batch: 020 ----
mean loss: 375.13
 ---- batch: 030 ----
mean loss: 379.46
train mean loss: 379.59
epoch train time: 0:00:00.519003
elapsed time: 0:00:46.271489
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 14:45:15.520948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 377.61
 ---- batch: 020 ----
mean loss: 372.72
 ---- batch: 030 ----
mean loss: 373.30
train mean loss: 375.22
epoch train time: 0:00:00.520406
elapsed time: 0:00:46.792192
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 14:45:16.041660
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 373.11
 ---- batch: 020 ----
mean loss: 370.24
 ---- batch: 030 ----
mean loss: 369.81
train mean loss: 371.50
epoch train time: 0:00:00.528824
elapsed time: 0:00:47.321322
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 14:45:16.570753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.82
 ---- batch: 020 ----
mean loss: 363.09
 ---- batch: 030 ----
mean loss: 365.34
train mean loss: 366.13
epoch train time: 0:00:00.543576
elapsed time: 0:00:47.865178
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 14:45:17.114630
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.25
 ---- batch: 020 ----
mean loss: 369.72
 ---- batch: 030 ----
mean loss: 359.06
train mean loss: 362.64
epoch train time: 0:00:00.519474
elapsed time: 0:00:48.384970
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 14:45:17.634400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 360.51
 ---- batch: 020 ----
mean loss: 361.68
 ---- batch: 030 ----
mean loss: 358.38
train mean loss: 360.07
epoch train time: 0:00:00.519696
elapsed time: 0:00:48.904944
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 14:45:18.154397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 360.97
 ---- batch: 020 ----
mean loss: 351.82
 ---- batch: 030 ----
mean loss: 365.15
train mean loss: 358.32
epoch train time: 0:00:00.521814
elapsed time: 0:00:49.427051
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 14:45:18.676484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 358.42
 ---- batch: 020 ----
mean loss: 355.97
 ---- batch: 030 ----
mean loss: 347.24
train mean loss: 354.33
epoch train time: 0:00:00.528143
elapsed time: 0:00:49.955491
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 14:45:19.204926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 355.16
 ---- batch: 020 ----
mean loss: 353.63
 ---- batch: 030 ----
mean loss: 350.51
train mean loss: 352.51
epoch train time: 0:00:00.511069
elapsed time: 0:00:50.466838
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 14:45:19.716267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 348.51
 ---- batch: 020 ----
mean loss: 353.78
 ---- batch: 030 ----
mean loss: 345.60
train mean loss: 348.26
epoch train time: 0:00:00.509742
elapsed time: 0:00:50.976886
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 14:45:20.226356
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 351.37
 ---- batch: 020 ----
mean loss: 345.02
 ---- batch: 030 ----
mean loss: 349.06
train mean loss: 347.33
epoch train time: 0:00:00.526997
elapsed time: 0:00:51.504214
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 14:45:20.753683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 341.46
 ---- batch: 020 ----
mean loss: 351.40
 ---- batch: 030 ----
mean loss: 342.50
train mean loss: 344.37
epoch train time: 0:00:00.531873
elapsed time: 0:00:52.036418
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 14:45:21.285886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 349.20
 ---- batch: 020 ----
mean loss: 340.01
 ---- batch: 030 ----
mean loss: 340.49
train mean loss: 343.78
epoch train time: 0:00:00.522281
elapsed time: 0:00:52.559063
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 14:45:21.808501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.33
 ---- batch: 020 ----
mean loss: 343.87
 ---- batch: 030 ----
mean loss: 343.47
train mean loss: 339.31
epoch train time: 0:00:00.522675
elapsed time: 0:00:53.082022
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 14:45:22.331470
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 340.82
 ---- batch: 020 ----
mean loss: 333.66
 ---- batch: 030 ----
mean loss: 329.14
train mean loss: 335.31
epoch train time: 0:00:00.525708
elapsed time: 0:00:53.608015
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 14:45:22.857469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 330.64
 ---- batch: 020 ----
mean loss: 333.45
 ---- batch: 030 ----
mean loss: 338.90
train mean loss: 334.16
epoch train time: 0:00:00.518682
elapsed time: 0:00:54.126984
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 14:45:23.376415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.09
 ---- batch: 020 ----
mean loss: 327.34
 ---- batch: 030 ----
mean loss: 344.44
train mean loss: 331.55
epoch train time: 0:00:00.527881
elapsed time: 0:00:54.655173
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 14:45:23.904611
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 326.82
 ---- batch: 020 ----
mean loss: 330.03
 ---- batch: 030 ----
mean loss: 329.35
train mean loss: 329.68
epoch train time: 0:00:00.524700
elapsed time: 0:00:55.180170
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 14:45:24.429626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 330.76
 ---- batch: 020 ----
mean loss: 321.59
 ---- batch: 030 ----
mean loss: 326.65
train mean loss: 327.06
epoch train time: 0:00:00.526425
elapsed time: 0:00:55.706905
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 14:45:24.956342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.07
 ---- batch: 020 ----
mean loss: 325.60
 ---- batch: 030 ----
mean loss: 325.49
train mean loss: 325.24
epoch train time: 0:00:00.531494
elapsed time: 0:00:56.238729
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 14:45:25.488184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.86
 ---- batch: 020 ----
mean loss: 321.38
 ---- batch: 030 ----
mean loss: 327.10
train mean loss: 324.49
epoch train time: 0:00:00.534556
elapsed time: 0:00:56.773622
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 14:45:26.023092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 319.52
 ---- batch: 020 ----
mean loss: 324.50
 ---- batch: 030 ----
mean loss: 320.52
train mean loss: 321.59
epoch train time: 0:00:00.523327
elapsed time: 0:00:57.297260
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 14:45:26.546694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.71
 ---- batch: 020 ----
mean loss: 321.97
 ---- batch: 030 ----
mean loss: 316.54
train mean loss: 319.81
epoch train time: 0:00:00.524706
elapsed time: 0:00:57.822257
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 14:45:27.071735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.49
 ---- batch: 020 ----
mean loss: 326.19
 ---- batch: 030 ----
mean loss: 306.72
train mean loss: 317.00
epoch train time: 0:00:00.507784
elapsed time: 0:00:58.330350
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 14:45:27.579789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.30
 ---- batch: 020 ----
mean loss: 311.35
 ---- batch: 030 ----
mean loss: 312.51
train mean loss: 316.67
epoch train time: 0:00:00.527234
elapsed time: 0:00:58.857876
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 14:45:28.107345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.54
 ---- batch: 020 ----
mean loss: 311.85
 ---- batch: 030 ----
mean loss: 317.73
train mean loss: 314.93
epoch train time: 0:00:00.526068
elapsed time: 0:00:59.384330
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 14:45:28.633788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 312.38
 ---- batch: 020 ----
mean loss: 316.54
 ---- batch: 030 ----
mean loss: 315.97
train mean loss: 314.06
epoch train time: 0:00:00.543969
elapsed time: 0:00:59.928614
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 14:45:29.178050
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.08
 ---- batch: 020 ----
mean loss: 313.99
 ---- batch: 030 ----
mean loss: 312.87
train mean loss: 310.59
epoch train time: 0:00:00.540355
elapsed time: 0:01:00.469278
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 14:45:29.718713
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 314.11
 ---- batch: 020 ----
mean loss: 310.29
 ---- batch: 030 ----
mean loss: 307.64
train mean loss: 310.12
epoch train time: 0:00:00.516761
elapsed time: 0:01:00.986338
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 14:45:30.235767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.15
 ---- batch: 020 ----
mean loss: 305.22
 ---- batch: 030 ----
mean loss: 310.35
train mean loss: 308.42
epoch train time: 0:00:00.515662
elapsed time: 0:01:01.502297
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 14:45:30.751731
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 307.56
 ---- batch: 020 ----
mean loss: 302.50
 ---- batch: 030 ----
mean loss: 308.91
train mean loss: 306.78
epoch train time: 0:00:00.522039
elapsed time: 0:01:02.024612
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 14:45:31.274060
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.63
 ---- batch: 020 ----
mean loss: 303.29
 ---- batch: 030 ----
mean loss: 311.26
train mean loss: 305.47
epoch train time: 0:00:00.520501
elapsed time: 0:01:02.545405
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 14:45:31.794838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.22
 ---- batch: 020 ----
mean loss: 303.18
 ---- batch: 030 ----
mean loss: 310.16
train mean loss: 303.25
epoch train time: 0:00:00.519013
elapsed time: 0:01:03.064706
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 14:45:32.314160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.84
 ---- batch: 020 ----
mean loss: 296.58
 ---- batch: 030 ----
mean loss: 301.30
train mean loss: 302.50
epoch train time: 0:00:00.525247
elapsed time: 0:01:03.590262
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 14:45:32.839689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 301.34
 ---- batch: 020 ----
mean loss: 298.13
 ---- batch: 030 ----
mean loss: 298.78
train mean loss: 300.54
epoch train time: 0:00:00.511968
elapsed time: 0:01:04.102532
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 14:45:33.351965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 301.56
 ---- batch: 020 ----
mean loss: 294.37
 ---- batch: 030 ----
mean loss: 303.05
train mean loss: 299.16
epoch train time: 0:00:00.533067
elapsed time: 0:01:04.635863
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 14:45:33.885288
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 298.76
 ---- batch: 020 ----
mean loss: 301.34
 ---- batch: 030 ----
mean loss: 290.29
train mean loss: 298.31
epoch train time: 0:00:00.525668
elapsed time: 0:01:05.161799
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 14:45:34.411248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.38
 ---- batch: 020 ----
mean loss: 301.91
 ---- batch: 030 ----
mean loss: 296.36
train mean loss: 295.83
epoch train time: 0:00:00.518533
elapsed time: 0:01:05.680641
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 14:45:34.930073
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.47
 ---- batch: 020 ----
mean loss: 296.08
 ---- batch: 030 ----
mean loss: 294.16
train mean loss: 294.38
epoch train time: 0:00:00.513162
elapsed time: 0:01:06.194100
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 14:45:35.443531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.85
 ---- batch: 020 ----
mean loss: 296.12
 ---- batch: 030 ----
mean loss: 292.97
train mean loss: 292.89
epoch train time: 0:00:00.520474
elapsed time: 0:01:06.715001
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 14:45:35.964448
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.12
 ---- batch: 020 ----
mean loss: 297.12
 ---- batch: 030 ----
mean loss: 294.03
train mean loss: 292.51
epoch train time: 0:00:00.526410
elapsed time: 0:01:07.241723
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 14:45:36.491159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.47
 ---- batch: 020 ----
mean loss: 293.10
 ---- batch: 030 ----
mean loss: 295.70
train mean loss: 291.35
epoch train time: 0:00:00.516367
elapsed time: 0:01:07.758355
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 14:45:37.007784
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.85
 ---- batch: 020 ----
mean loss: 294.04
 ---- batch: 030 ----
mean loss: 289.34
train mean loss: 289.83
epoch train time: 0:00:00.506685
elapsed time: 0:01:08.265350
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 14:45:37.514739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 291.81
 ---- batch: 020 ----
mean loss: 283.76
 ---- batch: 030 ----
mean loss: 293.94
train mean loss: 289.53
epoch train time: 0:00:00.529300
elapsed time: 0:01:08.794891
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 14:45:38.044340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 286.20
 ---- batch: 020 ----
mean loss: 292.50
 ---- batch: 030 ----
mean loss: 282.71
train mean loss: 287.25
epoch train time: 0:00:00.521545
elapsed time: 0:01:09.316747
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 14:45:38.566181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.39
 ---- batch: 020 ----
mean loss: 282.86
 ---- batch: 030 ----
mean loss: 288.09
train mean loss: 286.66
epoch train time: 0:00:00.530206
elapsed time: 0:01:09.847280
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 14:45:39.096716
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.21
 ---- batch: 020 ----
mean loss: 286.98
 ---- batch: 030 ----
mean loss: 286.64
train mean loss: 284.11
epoch train time: 0:00:00.521745
elapsed time: 0:01:10.369301
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 14:45:39.618760
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.50
 ---- batch: 020 ----
mean loss: 278.35
 ---- batch: 030 ----
mean loss: 284.21
train mean loss: 282.97
epoch train time: 0:00:00.522873
elapsed time: 0:01:10.892469
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 14:45:40.141900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.92
 ---- batch: 020 ----
mean loss: 282.48
 ---- batch: 030 ----
mean loss: 278.73
train mean loss: 283.35
epoch train time: 0:00:00.507686
elapsed time: 0:01:11.400521
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 14:45:40.649978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 280.44
 ---- batch: 020 ----
mean loss: 280.69
 ---- batch: 030 ----
mean loss: 280.79
train mean loss: 280.59
epoch train time: 0:00:00.521108
elapsed time: 0:01:11.921940
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 14:45:41.171394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.44
 ---- batch: 020 ----
mean loss: 282.18
 ---- batch: 030 ----
mean loss: 288.23
train mean loss: 280.33
epoch train time: 0:00:00.512909
elapsed time: 0:01:12.435171
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 14:45:41.684615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.03
 ---- batch: 020 ----
mean loss: 283.88
 ---- batch: 030 ----
mean loss: 275.76
train mean loss: 279.15
epoch train time: 0:00:00.519030
elapsed time: 0:01:12.954500
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 14:45:42.203931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.55
 ---- batch: 020 ----
mean loss: 283.52
 ---- batch: 030 ----
mean loss: 276.29
train mean loss: 277.33
epoch train time: 0:00:00.511854
elapsed time: 0:01:13.466658
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 14:45:42.716091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.74
 ---- batch: 020 ----
mean loss: 280.69
 ---- batch: 030 ----
mean loss: 276.69
train mean loss: 275.57
epoch train time: 0:00:00.522039
elapsed time: 0:01:13.989008
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 14:45:43.238445
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.72
 ---- batch: 020 ----
mean loss: 276.38
 ---- batch: 030 ----
mean loss: 276.34
train mean loss: 275.66
epoch train time: 0:00:00.521489
elapsed time: 0:01:14.510775
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 14:45:43.760275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.69
 ---- batch: 020 ----
mean loss: 271.56
 ---- batch: 030 ----
mean loss: 278.16
train mean loss: 275.35
epoch train time: 0:00:00.542945
elapsed time: 0:01:15.054060
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 14:45:44.303507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.68
 ---- batch: 020 ----
mean loss: 272.71
 ---- batch: 030 ----
mean loss: 269.49
train mean loss: 273.66
epoch train time: 0:00:00.534383
elapsed time: 0:01:15.588776
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 14:45:44.838213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.04
 ---- batch: 020 ----
mean loss: 272.50
 ---- batch: 030 ----
mean loss: 276.13
train mean loss: 272.30
epoch train time: 0:00:00.524358
elapsed time: 0:01:16.113464
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 14:45:45.362904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.55
 ---- batch: 020 ----
mean loss: 271.57
 ---- batch: 030 ----
mean loss: 272.05
train mean loss: 271.55
epoch train time: 0:00:00.527527
elapsed time: 0:01:16.641281
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 14:45:45.890726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 271.70
 ---- batch: 020 ----
mean loss: 268.64
 ---- batch: 030 ----
mean loss: 271.33
train mean loss: 270.49
epoch train time: 0:00:00.520364
elapsed time: 0:01:17.161930
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 14:45:46.411375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 272.68
 ---- batch: 020 ----
mean loss: 264.63
 ---- batch: 030 ----
mean loss: 268.79
train mean loss: 269.49
epoch train time: 0:00:00.522222
elapsed time: 0:01:17.684495
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 14:45:46.933939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.80
 ---- batch: 020 ----
mean loss: 263.60
 ---- batch: 030 ----
mean loss: 263.10
train mean loss: 269.16
epoch train time: 0:00:00.522915
elapsed time: 0:01:18.207705
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 14:45:47.457143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 267.93
 ---- batch: 020 ----
mean loss: 268.54
 ---- batch: 030 ----
mean loss: 265.25
train mean loss: 266.10
epoch train time: 0:00:00.532804
elapsed time: 0:01:18.740885
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 14:45:47.990281
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.17
 ---- batch: 020 ----
mean loss: 264.82
 ---- batch: 030 ----
mean loss: 267.64
train mean loss: 265.56
epoch train time: 0:00:00.529091
elapsed time: 0:01:19.270227
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 14:45:48.519663
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.44
 ---- batch: 020 ----
mean loss: 265.92
 ---- batch: 030 ----
mean loss: 263.81
train mean loss: 265.15
epoch train time: 0:00:00.530128
elapsed time: 0:01:19.800646
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 14:45:49.050086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.75
 ---- batch: 020 ----
mean loss: 265.04
 ---- batch: 030 ----
mean loss: 262.76
train mean loss: 263.39
epoch train time: 0:00:00.528811
elapsed time: 0:01:20.329743
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 14:45:49.579187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 257.79
 ---- batch: 020 ----
mean loss: 261.75
 ---- batch: 030 ----
mean loss: 270.85
train mean loss: 263.72
epoch train time: 0:00:00.526160
elapsed time: 0:01:20.856243
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 14:45:50.105735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.75
 ---- batch: 020 ----
mean loss: 270.01
 ---- batch: 030 ----
mean loss: 260.83
train mean loss: 263.50
epoch train time: 0:00:00.532323
elapsed time: 0:01:21.388901
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 14:45:50.638336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.69
 ---- batch: 020 ----
mean loss: 262.68
 ---- batch: 030 ----
mean loss: 262.21
train mean loss: 261.29
epoch train time: 0:00:00.518308
elapsed time: 0:01:21.907485
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 14:45:51.156923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.51
 ---- batch: 020 ----
mean loss: 256.66
 ---- batch: 030 ----
mean loss: 255.94
train mean loss: 260.02
epoch train time: 0:00:00.507991
elapsed time: 0:01:22.415751
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 14:45:51.665197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.07
 ---- batch: 020 ----
mean loss: 253.51
 ---- batch: 030 ----
mean loss: 260.72
train mean loss: 258.63
epoch train time: 0:00:00.511442
elapsed time: 0:01:22.927476
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 14:45:52.176910
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.08
 ---- batch: 020 ----
mean loss: 260.51
 ---- batch: 030 ----
mean loss: 259.98
train mean loss: 257.84
epoch train time: 0:00:00.516262
elapsed time: 0:01:23.444027
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 14:45:52.693474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.44
 ---- batch: 020 ----
mean loss: 256.39
 ---- batch: 030 ----
mean loss: 252.39
train mean loss: 257.62
epoch train time: 0:00:00.528468
elapsed time: 0:01:23.972785
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 14:45:53.222229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.47
 ---- batch: 020 ----
mean loss: 254.06
 ---- batch: 030 ----
mean loss: 260.76
train mean loss: 256.31
epoch train time: 0:00:00.518165
elapsed time: 0:01:24.491245
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 14:45:53.740743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.88
 ---- batch: 020 ----
mean loss: 257.16
 ---- batch: 030 ----
mean loss: 256.80
train mean loss: 255.65
epoch train time: 0:00:00.525591
elapsed time: 0:01:25.017185
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 14:45:54.266648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.88
 ---- batch: 020 ----
mean loss: 255.29
 ---- batch: 030 ----
mean loss: 247.90
train mean loss: 254.07
epoch train time: 0:00:00.520443
elapsed time: 0:01:25.537952
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 14:45:54.787385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.49
 ---- batch: 020 ----
mean loss: 257.98
 ---- batch: 030 ----
mean loss: 249.89
train mean loss: 254.43
epoch train time: 0:00:00.525511
elapsed time: 0:01:26.063729
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 14:45:55.313160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.77
 ---- batch: 020 ----
mean loss: 251.13
 ---- batch: 030 ----
mean loss: 251.60
train mean loss: 252.79
epoch train time: 0:00:00.520087
elapsed time: 0:01:26.584124
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 14:45:55.833556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.31
 ---- batch: 020 ----
mean loss: 254.03
 ---- batch: 030 ----
mean loss: 252.55
train mean loss: 252.30
epoch train time: 0:00:00.518947
elapsed time: 0:01:27.103718
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 14:45:56.353170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.37
 ---- batch: 020 ----
mean loss: 253.52
 ---- batch: 030 ----
mean loss: 250.91
train mean loss: 251.08
epoch train time: 0:00:00.522618
elapsed time: 0:01:27.626632
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 14:45:56.876067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 249.32
 ---- batch: 020 ----
mean loss: 248.35
 ---- batch: 030 ----
mean loss: 254.06
train mean loss: 250.15
epoch train time: 0:00:00.513334
elapsed time: 0:01:28.140248
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 14:45:57.389700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.51
 ---- batch: 020 ----
mean loss: 254.96
 ---- batch: 030 ----
mean loss: 246.81
train mean loss: 249.14
epoch train time: 0:00:00.530441
elapsed time: 0:01:28.670993
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 14:45:57.920435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.68
 ---- batch: 020 ----
mean loss: 250.96
 ---- batch: 030 ----
mean loss: 245.11
train mean loss: 247.82
epoch train time: 0:00:00.521588
elapsed time: 0:01:29.192874
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 14:45:58.442320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.95
 ---- batch: 020 ----
mean loss: 246.43
 ---- batch: 030 ----
mean loss: 245.63
train mean loss: 247.20
epoch train time: 0:00:00.516681
elapsed time: 0:01:29.709874
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 14:45:58.959307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.67
 ---- batch: 020 ----
mean loss: 245.25
 ---- batch: 030 ----
mean loss: 249.99
train mean loss: 245.99
epoch train time: 0:00:00.513329
elapsed time: 0:01:30.223513
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 14:45:59.472896
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.04
 ---- batch: 020 ----
mean loss: 242.10
 ---- batch: 030 ----
mean loss: 253.76
train mean loss: 245.89
epoch train time: 0:00:00.520695
elapsed time: 0:01:30.744462
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 14:45:59.993892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.07
 ---- batch: 020 ----
mean loss: 250.61
 ---- batch: 030 ----
mean loss: 243.96
train mean loss: 245.43
epoch train time: 0:00:00.515830
elapsed time: 0:01:31.260598
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 14:46:00.510054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.87
 ---- batch: 020 ----
mean loss: 246.00
 ---- batch: 030 ----
mean loss: 242.36
train mean loss: 243.43
epoch train time: 0:00:00.525683
elapsed time: 0:01:31.786577
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 14:46:01.036025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.16
 ---- batch: 020 ----
mean loss: 244.25
 ---- batch: 030 ----
mean loss: 236.79
train mean loss: 242.63
epoch train time: 0:00:00.527010
elapsed time: 0:01:32.313888
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 14:46:01.563321
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.20
 ---- batch: 020 ----
mean loss: 242.45
 ---- batch: 030 ----
mean loss: 243.02
train mean loss: 242.08
epoch train time: 0:00:00.522225
elapsed time: 0:01:32.836430
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 14:46:02.085868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.72
 ---- batch: 020 ----
mean loss: 242.10
 ---- batch: 030 ----
mean loss: 245.22
train mean loss: 241.34
epoch train time: 0:00:00.510837
elapsed time: 0:01:33.347546
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 14:46:02.596975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.53
 ---- batch: 020 ----
mean loss: 238.42
 ---- batch: 030 ----
mean loss: 238.84
train mean loss: 241.33
epoch train time: 0:00:00.507711
elapsed time: 0:01:33.855510
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 14:46:03.104952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.98
 ---- batch: 020 ----
mean loss: 242.12
 ---- batch: 030 ----
mean loss: 235.21
train mean loss: 240.15
epoch train time: 0:00:00.508270
elapsed time: 0:01:34.364076
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 14:46:03.613502
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.96
 ---- batch: 020 ----
mean loss: 245.59
 ---- batch: 030 ----
mean loss: 237.00
train mean loss: 238.38
epoch train time: 0:00:00.510647
elapsed time: 0:01:34.874981
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 14:46:04.124411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.49
 ---- batch: 020 ----
mean loss: 235.62
 ---- batch: 030 ----
mean loss: 240.55
train mean loss: 238.49
epoch train time: 0:00:00.511436
elapsed time: 0:01:35.386694
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 14:46:04.636123
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.94
 ---- batch: 020 ----
mean loss: 236.00
 ---- batch: 030 ----
mean loss: 237.94
train mean loss: 237.29
epoch train time: 0:00:00.517568
elapsed time: 0:01:35.904530
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 14:46:05.153973
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.61
 ---- batch: 020 ----
mean loss: 238.28
 ---- batch: 030 ----
mean loss: 235.66
train mean loss: 235.89
epoch train time: 0:00:00.507909
elapsed time: 0:01:36.412751
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 14:46:05.662184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.81
 ---- batch: 020 ----
mean loss: 233.28
 ---- batch: 030 ----
mean loss: 237.91
train mean loss: 235.07
epoch train time: 0:00:00.524397
elapsed time: 0:01:36.937433
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 14:46:06.186859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.70
 ---- batch: 020 ----
mean loss: 235.61
 ---- batch: 030 ----
mean loss: 239.16
train mean loss: 235.12
epoch train time: 0:00:00.519655
elapsed time: 0:01:37.457436
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 14:46:06.706883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.66
 ---- batch: 020 ----
mean loss: 240.29
 ---- batch: 030 ----
mean loss: 231.59
train mean loss: 233.95
epoch train time: 0:00:00.536345
elapsed time: 0:01:37.994091
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 14:46:07.243538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.02
 ---- batch: 020 ----
mean loss: 238.15
 ---- batch: 030 ----
mean loss: 232.97
train mean loss: 233.71
epoch train time: 0:00:00.541135
elapsed time: 0:01:38.535575
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 14:46:07.785056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.73
 ---- batch: 020 ----
mean loss: 235.16
 ---- batch: 030 ----
mean loss: 230.00
train mean loss: 232.91
epoch train time: 0:00:00.524685
elapsed time: 0:01:39.060582
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 14:46:08.310031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.87
 ---- batch: 020 ----
mean loss: 235.79
 ---- batch: 030 ----
mean loss: 230.58
train mean loss: 231.69
epoch train time: 0:00:00.533740
elapsed time: 0:01:39.594653
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 14:46:08.844111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.16
 ---- batch: 020 ----
mean loss: 226.63
 ---- batch: 030 ----
mean loss: 236.97
train mean loss: 231.45
epoch train time: 0:00:00.512203
elapsed time: 0:01:40.107177
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 14:46:09.356614
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.03
 ---- batch: 020 ----
mean loss: 229.67
 ---- batch: 030 ----
mean loss: 229.02
train mean loss: 229.88
epoch train time: 0:00:00.513844
elapsed time: 0:01:40.621347
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 14:46:09.870795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.15
 ---- batch: 020 ----
mean loss: 229.98
 ---- batch: 030 ----
mean loss: 224.56
train mean loss: 228.89
epoch train time: 0:00:00.513364
elapsed time: 0:01:41.135003
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 14:46:10.384438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.93
 ---- batch: 020 ----
mean loss: 230.37
 ---- batch: 030 ----
mean loss: 230.32
train mean loss: 229.67
epoch train time: 0:00:00.519735
elapsed time: 0:01:41.655006
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 14:46:10.904429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.63
 ---- batch: 020 ----
mean loss: 230.07
 ---- batch: 030 ----
mean loss: 230.12
train mean loss: 227.88
epoch train time: 0:00:00.508722
elapsed time: 0:01:42.163987
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 14:46:11.413435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.98
 ---- batch: 020 ----
mean loss: 220.38
 ---- batch: 030 ----
mean loss: 230.05
train mean loss: 227.73
epoch train time: 0:00:00.534864
elapsed time: 0:01:42.699170
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 14:46:11.948609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.29
 ---- batch: 020 ----
mean loss: 231.79
 ---- batch: 030 ----
mean loss: 222.05
train mean loss: 227.66
epoch train time: 0:00:00.521637
elapsed time: 0:01:43.221178
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 14:46:12.470563
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.60
 ---- batch: 020 ----
mean loss: 229.57
 ---- batch: 030 ----
mean loss: 228.40
train mean loss: 226.53
epoch train time: 0:00:00.542042
elapsed time: 0:01:43.763437
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 14:46:13.012867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.63
 ---- batch: 020 ----
mean loss: 225.38
 ---- batch: 030 ----
mean loss: 227.08
train mean loss: 226.56
epoch train time: 0:00:00.511005
elapsed time: 0:01:44.274736
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 14:46:13.524166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.93
 ---- batch: 020 ----
mean loss: 218.35
 ---- batch: 030 ----
mean loss: 231.79
train mean loss: 224.85
epoch train time: 0:00:00.517812
elapsed time: 0:01:44.792819
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 14:46:14.042253
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 226.57
 ---- batch: 020 ----
mean loss: 219.16
 ---- batch: 030 ----
mean loss: 225.73
train mean loss: 224.66
epoch train time: 0:00:00.509947
elapsed time: 0:01:45.303072
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 14:46:14.552517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.53
 ---- batch: 020 ----
mean loss: 232.33
 ---- batch: 030 ----
mean loss: 217.74
train mean loss: 223.72
epoch train time: 0:00:00.516876
elapsed time: 0:01:45.820234
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 14:46:15.069706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.29
 ---- batch: 020 ----
mean loss: 221.61
 ---- batch: 030 ----
mean loss: 226.77
train mean loss: 222.61
epoch train time: 0:00:00.525284
elapsed time: 0:01:46.345852
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 14:46:15.595289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.29
 ---- batch: 020 ----
mean loss: 224.97
 ---- batch: 030 ----
mean loss: 220.77
train mean loss: 222.66
epoch train time: 0:00:00.517178
elapsed time: 0:01:46.863324
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 14:46:16.112769
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.90
 ---- batch: 020 ----
mean loss: 221.15
 ---- batch: 030 ----
mean loss: 221.79
train mean loss: 221.29
epoch train time: 0:00:00.523373
elapsed time: 0:01:47.386995
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 14:46:16.636432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.11
 ---- batch: 020 ----
mean loss: 222.95
 ---- batch: 030 ----
mean loss: 220.04
train mean loss: 220.82
epoch train time: 0:00:00.522342
elapsed time: 0:01:47.909669
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 14:46:17.159112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.19
 ---- batch: 020 ----
mean loss: 217.85
 ---- batch: 030 ----
mean loss: 222.76
train mean loss: 220.96
epoch train time: 0:00:00.519037
elapsed time: 0:01:48.428998
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 14:46:17.678427
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.55
 ---- batch: 020 ----
mean loss: 215.35
 ---- batch: 030 ----
mean loss: 218.89
train mean loss: 219.99
epoch train time: 0:00:00.538339
elapsed time: 0:01:48.967675
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 14:46:18.217112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.53
 ---- batch: 020 ----
mean loss: 227.85
 ---- batch: 030 ----
mean loss: 210.74
train mean loss: 218.72
epoch train time: 0:00:00.525526
elapsed time: 0:01:49.493482
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 14:46:18.742918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.67
 ---- batch: 020 ----
mean loss: 223.08
 ---- batch: 030 ----
mean loss: 218.09
train mean loss: 218.87
epoch train time: 0:00:00.525156
elapsed time: 0:01:50.018922
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 14:46:19.268369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.02
 ---- batch: 020 ----
mean loss: 224.70
 ---- batch: 030 ----
mean loss: 219.04
train mean loss: 218.20
epoch train time: 0:00:00.519575
elapsed time: 0:01:50.538797
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 14:46:19.788232
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.30
 ---- batch: 020 ----
mean loss: 211.50
 ---- batch: 030 ----
mean loss: 223.22
train mean loss: 217.29
epoch train time: 0:00:00.518980
elapsed time: 0:01:51.058048
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 14:46:20.307484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.94
 ---- batch: 020 ----
mean loss: 219.62
 ---- batch: 030 ----
mean loss: 220.66
train mean loss: 216.55
epoch train time: 0:00:00.520290
elapsed time: 0:01:51.578633
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 14:46:20.828072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.16
 ---- batch: 020 ----
mean loss: 219.62
 ---- batch: 030 ----
mean loss: 214.94
train mean loss: 215.55
epoch train time: 0:00:00.520939
elapsed time: 0:01:52.099856
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 14:46:21.349291
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.49
 ---- batch: 020 ----
mean loss: 213.54
 ---- batch: 030 ----
mean loss: 216.71
train mean loss: 214.33
epoch train time: 0:00:00.530751
elapsed time: 0:01:52.630908
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 14:46:21.880362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.57
 ---- batch: 020 ----
mean loss: 219.80
 ---- batch: 030 ----
mean loss: 209.13
train mean loss: 214.31
epoch train time: 0:00:00.523266
elapsed time: 0:01:53.154469
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 14:46:22.403920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.86
 ---- batch: 020 ----
mean loss: 219.88
 ---- batch: 030 ----
mean loss: 211.86
train mean loss: 213.98
epoch train time: 0:00:00.537268
elapsed time: 0:01:53.692075
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 14:46:22.941507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.27
 ---- batch: 020 ----
mean loss: 218.06
 ---- batch: 030 ----
mean loss: 209.25
train mean loss: 213.15
epoch train time: 0:00:00.527255
elapsed time: 0:01:54.219622
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 14:46:23.469058
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.31
 ---- batch: 020 ----
mean loss: 209.85
 ---- batch: 030 ----
mean loss: 216.35
train mean loss: 212.56
epoch train time: 0:00:00.531526
elapsed time: 0:01:54.751434
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 14:46:24.000885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.86
 ---- batch: 020 ----
mean loss: 210.64
 ---- batch: 030 ----
mean loss: 209.12
train mean loss: 211.70
epoch train time: 0:00:00.525340
elapsed time: 0:01:55.277062
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 14:46:24.526503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.43
 ---- batch: 020 ----
mean loss: 221.11
 ---- batch: 030 ----
mean loss: 209.60
train mean loss: 212.36
epoch train time: 0:00:00.527953
elapsed time: 0:01:55.805303
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 14:46:25.054740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.30
 ---- batch: 020 ----
mean loss: 213.21
 ---- batch: 030 ----
mean loss: 211.38
train mean loss: 211.08
epoch train time: 0:00:00.527230
elapsed time: 0:01:56.332887
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 14:46:25.582348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.23
 ---- batch: 020 ----
mean loss: 210.56
 ---- batch: 030 ----
mean loss: 214.12
train mean loss: 210.94
epoch train time: 0:00:00.539692
elapsed time: 0:01:56.872955
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 14:46:26.122372
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.87
 ---- batch: 020 ----
mean loss: 209.84
 ---- batch: 030 ----
mean loss: 211.73
train mean loss: 209.45
epoch train time: 0:00:00.523772
elapsed time: 0:01:57.396985
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 14:46:26.646420
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 210.29
 ---- batch: 020 ----
mean loss: 207.71
 ---- batch: 030 ----
mean loss: 212.91
train mean loss: 209.86
epoch train time: 0:00:00.537981
elapsed time: 0:01:57.935313
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 14:46:27.184703
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.59
 ---- batch: 020 ----
mean loss: 213.15
 ---- batch: 030 ----
mean loss: 214.42
train mean loss: 210.22
epoch train time: 0:00:00.510695
elapsed time: 0:01:58.446238
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 14:46:27.695681
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 215.54
 ---- batch: 020 ----
mean loss: 213.20
 ---- batch: 030 ----
mean loss: 202.22
train mean loss: 210.39
epoch train time: 0:00:00.536054
elapsed time: 0:01:58.982597
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 14:46:28.232040
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.37
 ---- batch: 020 ----
mean loss: 205.20
 ---- batch: 030 ----
mean loss: 214.44
train mean loss: 209.10
epoch train time: 0:00:00.527980
elapsed time: 0:01:59.510882
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 14:46:28.760318
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.72
 ---- batch: 020 ----
mean loss: 209.34
 ---- batch: 030 ----
mean loss: 208.95
train mean loss: 209.75
epoch train time: 0:00:00.532011
elapsed time: 0:02:00.043171
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 14:46:29.292627
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.65
 ---- batch: 020 ----
mean loss: 210.25
 ---- batch: 030 ----
mean loss: 205.61
train mean loss: 209.41
epoch train time: 0:00:00.541171
elapsed time: 0:02:00.584659
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 14:46:29.834092
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.27
 ---- batch: 020 ----
mean loss: 207.99
 ---- batch: 030 ----
mean loss: 213.92
train mean loss: 210.03
epoch train time: 0:00:00.524059
elapsed time: 0:02:01.109001
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 14:46:30.358446
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.40
 ---- batch: 020 ----
mean loss: 208.12
 ---- batch: 030 ----
mean loss: 210.79
train mean loss: 209.42
epoch train time: 0:00:00.526899
elapsed time: 0:02:01.636204
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 14:46:30.885686
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.83
 ---- batch: 020 ----
mean loss: 214.27
 ---- batch: 030 ----
mean loss: 206.89
train mean loss: 208.66
epoch train time: 0:00:00.520053
elapsed time: 0:02:02.156576
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 14:46:31.406006
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.66
 ---- batch: 020 ----
mean loss: 207.40
 ---- batch: 030 ----
mean loss: 214.24
train mean loss: 209.29
epoch train time: 0:00:00.510826
elapsed time: 0:02:02.667687
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 14:46:31.917119
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.27
 ---- batch: 020 ----
mean loss: 210.27
 ---- batch: 030 ----
mean loss: 214.08
train mean loss: 209.00
epoch train time: 0:00:00.510136
elapsed time: 0:02:03.178092
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 14:46:32.427526
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.16
 ---- batch: 020 ----
mean loss: 212.56
 ---- batch: 030 ----
mean loss: 210.86
train mean loss: 208.55
epoch train time: 0:00:00.527060
elapsed time: 0:02:03.705438
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 14:46:32.954871
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 217.80
 ---- batch: 020 ----
mean loss: 204.29
 ---- batch: 030 ----
mean loss: 203.86
train mean loss: 208.75
epoch train time: 0:00:00.518080
elapsed time: 0:02:04.223816
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 14:46:33.473251
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.45
 ---- batch: 020 ----
mean loss: 209.66
 ---- batch: 030 ----
mean loss: 203.80
train mean loss: 209.20
epoch train time: 0:00:00.532559
elapsed time: 0:02:04.756673
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 14:46:34.006108
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.19
 ---- batch: 020 ----
mean loss: 207.90
 ---- batch: 030 ----
mean loss: 208.73
train mean loss: 208.84
epoch train time: 0:00:00.517783
elapsed time: 0:02:05.274807
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 14:46:34.524239
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.10
 ---- batch: 020 ----
mean loss: 209.04
 ---- batch: 030 ----
mean loss: 207.13
train mean loss: 208.83
epoch train time: 0:00:00.515243
elapsed time: 0:02:05.790324
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 14:46:35.039758
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 209.90
 ---- batch: 020 ----
mean loss: 205.51
 ---- batch: 030 ----
mean loss: 210.34
train mean loss: 209.19
epoch train time: 0:00:00.511977
elapsed time: 0:02:06.302569
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 14:46:35.552020
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 210.10
 ---- batch: 020 ----
mean loss: 203.70
 ---- batch: 030 ----
mean loss: 207.80
train mean loss: 208.82
epoch train time: 0:00:00.524035
elapsed time: 0:02:06.826898
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 14:46:36.076364
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.85
 ---- batch: 020 ----
mean loss: 207.87
 ---- batch: 030 ----
mean loss: 211.30
train mean loss: 208.58
epoch train time: 0:00:00.509174
elapsed time: 0:02:07.336390
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 14:46:36.585824
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.64
 ---- batch: 020 ----
mean loss: 210.42
 ---- batch: 030 ----
mean loss: 204.50
train mean loss: 208.19
epoch train time: 0:00:00.519933
elapsed time: 0:02:07.856630
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 14:46:37.106094
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.12
 ---- batch: 020 ----
mean loss: 210.82
 ---- batch: 030 ----
mean loss: 209.60
train mean loss: 208.43
epoch train time: 0:00:00.517762
elapsed time: 0:02:08.374723
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 14:46:37.624174
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.92
 ---- batch: 020 ----
mean loss: 203.58
 ---- batch: 030 ----
mean loss: 208.19
train mean loss: 208.60
epoch train time: 0:00:00.520939
elapsed time: 0:02:08.895961
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 14:46:38.145397
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.42
 ---- batch: 020 ----
mean loss: 208.92
 ---- batch: 030 ----
mean loss: 208.71
train mean loss: 208.41
epoch train time: 0:00:00.522370
elapsed time: 0:02:09.418621
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 14:46:38.668074
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.84
 ---- batch: 020 ----
mean loss: 209.16
 ---- batch: 030 ----
mean loss: 210.73
train mean loss: 208.62
epoch train time: 0:00:00.533690
elapsed time: 0:02:09.952601
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 14:46:39.202049
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.51
 ---- batch: 020 ----
mean loss: 211.98
 ---- batch: 030 ----
mean loss: 207.76
train mean loss: 208.71
epoch train time: 0:00:00.523616
elapsed time: 0:02:10.476521
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 14:46:39.725983
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.23
 ---- batch: 020 ----
mean loss: 208.96
 ---- batch: 030 ----
mean loss: 205.36
train mean loss: 208.22
epoch train time: 0:00:00.514971
elapsed time: 0:02:10.991795
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 14:46:40.241262
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.01
 ---- batch: 020 ----
mean loss: 210.62
 ---- batch: 030 ----
mean loss: 206.22
train mean loss: 207.59
epoch train time: 0:00:00.515492
elapsed time: 0:02:11.507622
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 14:46:40.757128
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 203.95
 ---- batch: 020 ----
mean loss: 210.65
 ---- batch: 030 ----
mean loss: 206.31
train mean loss: 208.13
epoch train time: 0:00:00.528143
elapsed time: 0:02:12.036109
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 14:46:41.285542
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.23
 ---- batch: 020 ----
mean loss: 207.16
 ---- batch: 030 ----
mean loss: 207.76
train mean loss: 208.46
epoch train time: 0:00:00.521585
elapsed time: 0:02:12.558034
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 14:46:41.807508
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.88
 ---- batch: 020 ----
mean loss: 214.02
 ---- batch: 030 ----
mean loss: 203.20
train mean loss: 207.87
epoch train time: 0:00:00.531416
elapsed time: 0:02:13.089779
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 14:46:42.339222
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.51
 ---- batch: 020 ----
mean loss: 203.14
 ---- batch: 030 ----
mean loss: 210.15
train mean loss: 208.14
epoch train time: 0:00:00.537076
elapsed time: 0:02:13.627176
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 14:46:42.876642
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.45
 ---- batch: 020 ----
mean loss: 207.76
 ---- batch: 030 ----
mean loss: 211.35
train mean loss: 207.52
epoch train time: 0:00:00.512247
elapsed time: 0:02:14.139740
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 14:46:43.389175
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 204.91
 ---- batch: 020 ----
mean loss: 213.01
 ---- batch: 030 ----
mean loss: 207.87
train mean loss: 207.61
epoch train time: 0:00:00.521197
elapsed time: 0:02:14.661280
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 14:46:43.910664
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.86
 ---- batch: 020 ----
mean loss: 205.49
 ---- batch: 030 ----
mean loss: 208.25
train mean loss: 208.28
epoch train time: 0:00:00.520267
elapsed time: 0:02:15.181789
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 14:46:44.431242
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.94
 ---- batch: 020 ----
mean loss: 205.25
 ---- batch: 030 ----
mean loss: 206.75
train mean loss: 207.46
epoch train time: 0:00:00.525937
elapsed time: 0:02:15.708022
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 14:46:44.957456
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.44
 ---- batch: 020 ----
mean loss: 210.08
 ---- batch: 030 ----
mean loss: 205.53
train mean loss: 207.71
epoch train time: 0:00:00.525925
elapsed time: 0:02:16.234266
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 14:46:45.483720
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.47
 ---- batch: 020 ----
mean loss: 212.79
 ---- batch: 030 ----
mean loss: 206.94
train mean loss: 207.65
epoch train time: 0:00:00.525939
elapsed time: 0:02:16.760494
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 14:46:46.009934
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.66
 ---- batch: 020 ----
mean loss: 208.19
 ---- batch: 030 ----
mean loss: 204.99
train mean loss: 208.30
epoch train time: 0:00:00.521625
elapsed time: 0:02:17.282394
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 14:46:46.531828
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.90
 ---- batch: 020 ----
mean loss: 212.50
 ---- batch: 030 ----
mean loss: 204.68
train mean loss: 207.33
epoch train time: 0:00:00.539497
elapsed time: 0:02:17.822197
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 14:46:47.071650
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.16
 ---- batch: 020 ----
mean loss: 206.36
 ---- batch: 030 ----
mean loss: 209.91
train mean loss: 207.39
epoch train time: 0:00:00.532206
elapsed time: 0:02:18.354717
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 14:46:47.604166
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 212.88
 ---- batch: 020 ----
mean loss: 205.11
 ---- batch: 030 ----
mean loss: 203.63
train mean loss: 206.79
epoch train time: 0:00:00.536664
elapsed time: 0:02:18.891675
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 14:46:48.141183
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.58
 ---- batch: 020 ----
mean loss: 204.03
 ---- batch: 030 ----
mean loss: 210.13
train mean loss: 207.24
epoch train time: 0:00:00.542217
elapsed time: 0:02:19.434314
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 14:46:48.683759
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.06
 ---- batch: 020 ----
mean loss: 212.62
 ---- batch: 030 ----
mean loss: 204.06
train mean loss: 206.59
epoch train time: 0:00:00.519805
elapsed time: 0:02:19.954415
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 14:46:49.203850
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 210.00
 ---- batch: 020 ----
mean loss: 208.49
 ---- batch: 030 ----
mean loss: 202.79
train mean loss: 207.59
epoch train time: 0:00:00.516562
elapsed time: 0:02:20.471281
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 14:46:49.720713
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.75
 ---- batch: 020 ----
mean loss: 201.84
 ---- batch: 030 ----
mean loss: 207.77
train mean loss: 207.03
epoch train time: 0:00:00.518344
elapsed time: 0:02:20.989897
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 14:46:50.239354
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.73
 ---- batch: 020 ----
mean loss: 211.42
 ---- batch: 030 ----
mean loss: 204.51
train mean loss: 207.16
epoch train time: 0:00:00.523637
elapsed time: 0:02:21.513838
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 14:46:50.763300
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.03
 ---- batch: 020 ----
mean loss: 210.17
 ---- batch: 030 ----
mean loss: 200.64
train mean loss: 206.88
epoch train time: 0:00:00.516555
elapsed time: 0:02:22.030705
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 14:46:51.280169
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 211.34
 ---- batch: 020 ----
mean loss: 204.86
 ---- batch: 030 ----
mean loss: 207.09
train mean loss: 206.76
epoch train time: 0:00:00.538797
elapsed time: 0:02:22.569841
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 14:46:51.819284
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.17
 ---- batch: 020 ----
mean loss: 205.11
 ---- batch: 030 ----
mean loss: 208.64
train mean loss: 206.68
epoch train time: 0:00:00.520155
elapsed time: 0:02:23.094119
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_2/checkpoint.pth.tar
**** end time: 2019-09-27 14:46:52.343477 ****
