Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_3', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32154
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 16:55:33.236892 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:55:33.240358
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4124.15
 ---- batch: 020 ----
mean loss: 3894.31
 ---- batch: 030 ----
mean loss: 3881.70
train mean loss: 3947.84
epoch train time: 0:00:12.693113
elapsed time: 0:00:12.698988
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:55:45.935922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3771.13
 ---- batch: 020 ----
mean loss: 3677.64
 ---- batch: 030 ----
mean loss: 3648.34
train mean loss: 3691.22
epoch train time: 0:00:00.191268
elapsed time: 0:00:12.890386
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:55:46.127336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3560.12
 ---- batch: 020 ----
mean loss: 3492.67
 ---- batch: 030 ----
mean loss: 3457.31
train mean loss: 3485.99
epoch train time: 0:00:00.170171
elapsed time: 0:00:13.060702
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:55:46.297666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3346.62
 ---- batch: 020 ----
mean loss: 3273.34
 ---- batch: 030 ----
mean loss: 3260.99
train mean loss: 3289.72
epoch train time: 0:00:00.169969
elapsed time: 0:00:13.230832
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:55:46.467772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3122.07
 ---- batch: 020 ----
mean loss: 3065.91
 ---- batch: 030 ----
mean loss: 3135.19
train mean loss: 3095.97
epoch train time: 0:00:00.173087
elapsed time: 0:00:13.404074
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:55:46.641009
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2975.71
 ---- batch: 020 ----
mean loss: 2909.63
 ---- batch: 030 ----
mean loss: 2895.68
train mean loss: 2916.59
epoch train time: 0:00:00.173040
elapsed time: 0:00:13.577277
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:55:46.814238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2826.71
 ---- batch: 020 ----
mean loss: 2750.93
 ---- batch: 030 ----
mean loss: 2699.19
train mean loss: 2748.00
epoch train time: 0:00:00.178307
elapsed time: 0:00:13.755740
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:55:46.992682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2642.79
 ---- batch: 020 ----
mean loss: 2620.63
 ---- batch: 030 ----
mean loss: 2529.71
train mean loss: 2587.88
epoch train time: 0:00:00.169493
elapsed time: 0:00:13.925381
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:55:47.162313
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2485.14
 ---- batch: 020 ----
mean loss: 2446.29
 ---- batch: 030 ----
mean loss: 2413.41
train mean loss: 2438.43
epoch train time: 0:00:00.170762
elapsed time: 0:00:14.096273
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:55:47.333214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2363.29
 ---- batch: 020 ----
mean loss: 2302.55
 ---- batch: 030 ----
mean loss: 2276.14
train mean loss: 2300.94
epoch train time: 0:00:00.171287
elapsed time: 0:00:14.267698
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:55:47.504641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2204.92
 ---- batch: 020 ----
mean loss: 2195.60
 ---- batch: 030 ----
mean loss: 2139.23
train mean loss: 2169.84
epoch train time: 0:00:00.180461
elapsed time: 0:00:14.448307
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:55:47.685257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2086.24
 ---- batch: 020 ----
mean loss: 2073.19
 ---- batch: 030 ----
mean loss: 2005.27
train mean loss: 2053.49
epoch train time: 0:00:00.190984
elapsed time: 0:00:14.639444
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:55:47.876377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1990.69
 ---- batch: 020 ----
mean loss: 1937.39
 ---- batch: 030 ----
mean loss: 1941.72
train mean loss: 1942.94
epoch train time: 0:00:00.172312
elapsed time: 0:00:14.811891
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:55:48.048830
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1908.06
 ---- batch: 020 ----
mean loss: 1856.68
 ---- batch: 030 ----
mean loss: 1798.68
train mean loss: 1840.55
epoch train time: 0:00:00.169102
elapsed time: 0:00:14.981176
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:55:48.218109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1772.62
 ---- batch: 020 ----
mean loss: 1750.56
 ---- batch: 030 ----
mean loss: 1719.45
train mean loss: 1740.61
epoch train time: 0:00:00.166879
elapsed time: 0:00:15.148213
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:55:48.385154
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1668.12
 ---- batch: 020 ----
mean loss: 1640.06
 ---- batch: 030 ----
mean loss: 1627.21
train mean loss: 1639.32
epoch train time: 0:00:00.169461
elapsed time: 0:00:15.317810
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:55:48.554749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1578.87
 ---- batch: 020 ----
mean loss: 1541.68
 ---- batch: 030 ----
mean loss: 1523.06
train mean loss: 1542.07
epoch train time: 0:00:00.169309
elapsed time: 0:00:15.487256
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:55:48.724196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1487.20
 ---- batch: 020 ----
mean loss: 1457.13
 ---- batch: 030 ----
mean loss: 1407.58
train mean loss: 1449.49
epoch train time: 0:00:00.172648
elapsed time: 0:00:15.660051
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:55:48.896988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1393.94
 ---- batch: 020 ----
mean loss: 1368.19
 ---- batch: 030 ----
mean loss: 1328.19
train mean loss: 1356.58
epoch train time: 0:00:00.173098
elapsed time: 0:00:15.833294
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:55:49.070246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1305.43
 ---- batch: 020 ----
mean loss: 1271.48
 ---- batch: 030 ----
mean loss: 1249.80
train mean loss: 1269.76
epoch train time: 0:00:00.171079
elapsed time: 0:00:16.005173
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:55:49.242133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1202.96
 ---- batch: 020 ----
mean loss: 1194.96
 ---- batch: 030 ----
mean loss: 1173.41
train mean loss: 1190.84
epoch train time: 0:00:00.169535
elapsed time: 0:00:16.174865
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:55:49.411806
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1132.02
 ---- batch: 020 ----
mean loss: 1146.41
 ---- batch: 030 ----
mean loss: 1100.72
train mean loss: 1116.03
epoch train time: 0:00:00.184919
elapsed time: 0:00:16.359967
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:55:49.596929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1079.74
 ---- batch: 020 ----
mean loss: 1052.31
 ---- batch: 030 ----
mean loss: 1035.40
train mean loss: 1046.50
epoch train time: 0:00:00.174490
elapsed time: 0:00:16.534618
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:55:49.771559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 989.83
 ---- batch: 020 ----
mean loss: 1000.84
 ---- batch: 030 ----
mean loss: 983.09
train mean loss: 981.00
epoch train time: 0:00:00.173973
elapsed time: 0:00:16.708767
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:55:49.945711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 952.24
 ---- batch: 020 ----
mean loss: 937.88
 ---- batch: 030 ----
mean loss: 898.06
train mean loss: 920.01
epoch train time: 0:00:00.169004
elapsed time: 0:00:16.877912
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:55:50.114863
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 871.41
 ---- batch: 020 ----
mean loss: 882.47
 ---- batch: 030 ----
mean loss: 854.81
train mean loss: 863.51
epoch train time: 0:00:00.169984
elapsed time: 0:00:17.048060
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:55:50.285000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 831.19
 ---- batch: 020 ----
mean loss: 819.76
 ---- batch: 030 ----
mean loss: 780.52
train mean loss: 810.21
epoch train time: 0:00:00.167702
elapsed time: 0:00:17.215895
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:55:50.452834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 782.24
 ---- batch: 020 ----
mean loss: 764.68
 ---- batch: 030 ----
mean loss: 739.44
train mean loss: 758.48
epoch train time: 0:00:00.168357
elapsed time: 0:00:17.384392
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:55:50.621326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 718.65
 ---- batch: 020 ----
mean loss: 734.23
 ---- batch: 030 ----
mean loss: 697.61
train mean loss: 711.27
epoch train time: 0:00:00.170901
elapsed time: 0:00:17.555433
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:55:50.792366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 679.78
 ---- batch: 020 ----
mean loss: 669.36
 ---- batch: 030 ----
mean loss: 658.40
train mean loss: 667.89
epoch train time: 0:00:00.177890
elapsed time: 0:00:17.733453
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:55:50.970394
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 638.14
 ---- batch: 020 ----
mean loss: 616.78
 ---- batch: 030 ----
mean loss: 638.65
train mean loss: 627.57
epoch train time: 0:00:00.173822
elapsed time: 0:00:17.907415
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:55:51.144357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 602.09
 ---- batch: 020 ----
mean loss: 596.41
 ---- batch: 030 ----
mean loss: 578.10
train mean loss: 587.98
epoch train time: 0:00:00.169380
elapsed time: 0:00:18.076937
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:55:51.313892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 568.27
 ---- batch: 020 ----
mean loss: 550.63
 ---- batch: 030 ----
mean loss: 535.78
train mean loss: 552.77
epoch train time: 0:00:00.173670
elapsed time: 0:00:18.250763
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:55:51.487706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 532.04
 ---- batch: 020 ----
mean loss: 533.28
 ---- batch: 030 ----
mean loss: 507.54
train mean loss: 519.64
epoch train time: 0:00:00.175255
elapsed time: 0:00:18.426156
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:55:51.663112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 493.80
 ---- batch: 020 ----
mean loss: 493.86
 ---- batch: 030 ----
mean loss: 483.32
train mean loss: 488.36
epoch train time: 0:00:00.176478
elapsed time: 0:00:18.602795
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:55:51.839729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 465.18
 ---- batch: 020 ----
mean loss: 457.93
 ---- batch: 030 ----
mean loss: 463.93
train mean loss: 459.96
epoch train time: 0:00:00.174422
elapsed time: 0:00:18.777355
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:55:52.014297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 442.57
 ---- batch: 020 ----
mean loss: 433.59
 ---- batch: 030 ----
mean loss: 425.88
train mean loss: 431.97
epoch train time: 0:00:00.174715
elapsed time: 0:00:18.952209
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:55:52.189151
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 415.10
 ---- batch: 020 ----
mean loss: 405.09
 ---- batch: 030 ----
mean loss: 403.53
train mean loss: 406.76
epoch train time: 0:00:00.172299
elapsed time: 0:00:19.124647
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:55:52.361586
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 397.56
 ---- batch: 020 ----
mean loss: 386.39
 ---- batch: 030 ----
mean loss: 376.55
train mean loss: 383.21
epoch train time: 0:00:00.170145
elapsed time: 0:00:19.294957
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:55:52.531904
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.85
 ---- batch: 020 ----
mean loss: 356.99
 ---- batch: 030 ----
mean loss: 358.76
train mean loss: 361.06
epoch train time: 0:00:00.167357
elapsed time: 0:00:19.462470
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:55:52.699408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 351.76
 ---- batch: 020 ----
mean loss: 331.50
 ---- batch: 030 ----
mean loss: 338.60
train mean loss: 340.83
epoch train time: 0:00:00.191037
elapsed time: 0:00:19.653671
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:55:52.890620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 324.67
 ---- batch: 020 ----
mean loss: 318.10
 ---- batch: 030 ----
mean loss: 325.98
train mean loss: 321.29
epoch train time: 0:00:00.176141
elapsed time: 0:00:19.829988
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:55:53.066929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.01
 ---- batch: 020 ----
mean loss: 304.47
 ---- batch: 030 ----
mean loss: 291.41
train mean loss: 303.53
epoch train time: 0:00:00.168854
elapsed time: 0:00:19.998977
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:55:53.235926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.09
 ---- batch: 020 ----
mean loss: 290.03
 ---- batch: 030 ----
mean loss: 284.16
train mean loss: 287.04
epoch train time: 0:00:00.164958
elapsed time: 0:00:20.164079
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:55:53.401018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.56
 ---- batch: 020 ----
mean loss: 268.50
 ---- batch: 030 ----
mean loss: 270.59
train mean loss: 271.38
epoch train time: 0:00:00.168236
elapsed time: 0:00:20.332447
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:55:53.569386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.06
 ---- batch: 020 ----
mean loss: 252.55
 ---- batch: 030 ----
mean loss: 253.99
train mean loss: 257.19
epoch train time: 0:00:00.168506
elapsed time: 0:00:20.501094
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:55:53.738054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.60
 ---- batch: 020 ----
mean loss: 249.53
 ---- batch: 030 ----
mean loss: 241.33
train mean loss: 243.41
epoch train time: 0:00:00.173905
elapsed time: 0:00:20.675176
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:55:53.912117
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.74
 ---- batch: 020 ----
mean loss: 232.02
 ---- batch: 030 ----
mean loss: 233.24
train mean loss: 231.35
epoch train time: 0:00:00.172079
elapsed time: 0:00:20.847392
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:55:54.084345
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.09
 ---- batch: 020 ----
mean loss: 219.36
 ---- batch: 030 ----
mean loss: 221.05
train mean loss: 220.21
epoch train time: 0:00:00.167864
elapsed time: 0:00:21.016196
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:55:54.253144
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.73
 ---- batch: 020 ----
mean loss: 212.66
 ---- batch: 030 ----
mean loss: 206.02
train mean loss: 209.63
epoch train time: 0:00:00.171312
elapsed time: 0:00:21.187669
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:55:54.424608
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.19
 ---- batch: 020 ----
mean loss: 196.40
 ---- batch: 030 ----
mean loss: 200.19
train mean loss: 199.80
epoch train time: 0:00:00.171133
elapsed time: 0:00:21.358940
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:55:54.595881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.38
 ---- batch: 020 ----
mean loss: 192.08
 ---- batch: 030 ----
mean loss: 186.82
train mean loss: 190.97
epoch train time: 0:00:00.169430
elapsed time: 0:00:21.528507
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:55:54.765459
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.88
 ---- batch: 020 ----
mean loss: 180.56
 ---- batch: 030 ----
mean loss: 181.00
train mean loss: 182.15
epoch train time: 0:00:00.179602
elapsed time: 0:00:21.708263
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:55:54.945206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.79
 ---- batch: 020 ----
mean loss: 179.46
 ---- batch: 030 ----
mean loss: 172.73
train mean loss: 174.72
epoch train time: 0:00:00.173258
elapsed time: 0:00:21.881666
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:55:55.118608
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.86
 ---- batch: 020 ----
mean loss: 164.87
 ---- batch: 030 ----
mean loss: 167.37
train mean loss: 167.53
epoch train time: 0:00:00.176242
elapsed time: 0:00:22.058065
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:55:55.295006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.98
 ---- batch: 020 ----
mean loss: 162.58
 ---- batch: 030 ----
mean loss: 156.63
train mean loss: 161.13
epoch train time: 0:00:00.179527
elapsed time: 0:00:22.237731
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:55:55.474674
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 156.35
 ---- batch: 020 ----
mean loss: 158.53
 ---- batch: 030 ----
mean loss: 152.94
train mean loss: 155.12
epoch train time: 0:00:00.174950
elapsed time: 0:00:22.412855
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:55:55.649798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 150.15
 ---- batch: 020 ----
mean loss: 147.57
 ---- batch: 030 ----
mean loss: 151.59
train mean loss: 149.35
epoch train time: 0:00:00.171713
elapsed time: 0:00:22.584744
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:55:55.821690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.51
 ---- batch: 020 ----
mean loss: 145.39
 ---- batch: 030 ----
mean loss: 145.44
train mean loss: 144.37
epoch train time: 0:00:00.184836
elapsed time: 0:00:22.769726
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:55:56.006668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.21
 ---- batch: 020 ----
mean loss: 137.78
 ---- batch: 030 ----
mean loss: 137.73
train mean loss: 139.21
epoch train time: 0:00:00.173082
elapsed time: 0:00:22.942948
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:55:56.179923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.70
 ---- batch: 020 ----
mean loss: 134.50
 ---- batch: 030 ----
mean loss: 134.37
train mean loss: 135.13
epoch train time: 0:00:00.172390
elapsed time: 0:00:23.115521
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:55:56.352465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.05
 ---- batch: 020 ----
mean loss: 130.26
 ---- batch: 030 ----
mean loss: 133.29
train mean loss: 131.08
epoch train time: 0:00:00.174204
elapsed time: 0:00:23.289863
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:55:56.526801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.50
 ---- batch: 020 ----
mean loss: 128.49
 ---- batch: 030 ----
mean loss: 123.54
train mean loss: 126.93
epoch train time: 0:00:00.170924
elapsed time: 0:00:23.460931
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:55:56.697870
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.19
 ---- batch: 020 ----
mean loss: 124.41
 ---- batch: 030 ----
mean loss: 123.67
train mean loss: 123.04
epoch train time: 0:00:00.173946
elapsed time: 0:00:23.635021
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:55:56.871963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.89
 ---- batch: 020 ----
mean loss: 118.99
 ---- batch: 030 ----
mean loss: 119.02
train mean loss: 119.69
epoch train time: 0:00:00.172751
elapsed time: 0:00:23.807909
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:55:57.044852
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.08
 ---- batch: 020 ----
mean loss: 116.72
 ---- batch: 030 ----
mean loss: 117.46
train mean loss: 116.61
epoch train time: 0:00:00.170503
elapsed time: 0:00:23.978565
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:55:57.215508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.55
 ---- batch: 020 ----
mean loss: 114.49
 ---- batch: 030 ----
mean loss: 111.67
train mean loss: 113.50
epoch train time: 0:00:00.175435
elapsed time: 0:00:24.154170
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:55:57.391141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.57
 ---- batch: 020 ----
mean loss: 110.38
 ---- batch: 030 ----
mean loss: 112.12
train mean loss: 111.31
epoch train time: 0:00:00.173659
elapsed time: 0:00:24.327995
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:55:57.564934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.81
 ---- batch: 020 ----
mean loss: 107.31
 ---- batch: 030 ----
mean loss: 104.47
train mean loss: 108.57
epoch train time: 0:00:00.171145
elapsed time: 0:00:24.499284
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:55:57.736236
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.19
 ---- batch: 020 ----
mean loss: 104.33
 ---- batch: 030 ----
mean loss: 106.96
train mean loss: 106.25
epoch train time: 0:00:00.171421
elapsed time: 0:00:24.670864
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:55:57.907804
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.04
 ---- batch: 020 ----
mean loss: 105.41
 ---- batch: 030 ----
mean loss: 104.31
train mean loss: 104.17
epoch train time: 0:00:00.167664
elapsed time: 0:00:24.838664
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:55:58.075613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.37
 ---- batch: 020 ----
mean loss: 103.16
 ---- batch: 030 ----
mean loss: 100.25
train mean loss: 102.72
epoch train time: 0:00:00.170715
elapsed time: 0:00:25.009525
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:55:58.246469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.08
 ---- batch: 020 ----
mean loss: 100.54
 ---- batch: 030 ----
mean loss: 102.18
train mean loss: 100.13
epoch train time: 0:00:00.171380
elapsed time: 0:00:25.181068
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:55:58.418048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.22
 ---- batch: 020 ----
mean loss: 100.61
 ---- batch: 030 ----
mean loss: 97.21
train mean loss: 98.21
epoch train time: 0:00:00.172148
elapsed time: 0:00:25.353392
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:55:58.590348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.61
 ---- batch: 020 ----
mean loss: 98.72
 ---- batch: 030 ----
mean loss: 96.20
train mean loss: 96.68
epoch train time: 0:00:00.186044
elapsed time: 0:00:25.539616
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:55:58.776557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.54
 ---- batch: 020 ----
mean loss: 94.69
 ---- batch: 030 ----
mean loss: 96.94
train mean loss: 95.10
epoch train time: 0:00:00.173012
elapsed time: 0:00:25.712796
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:55:58.949757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.34
 ---- batch: 020 ----
mean loss: 92.40
 ---- batch: 030 ----
mean loss: 90.17
train mean loss: 93.83
epoch train time: 0:00:00.171827
elapsed time: 0:00:25.884799
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:55:59.121756
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.63
 ---- batch: 020 ----
mean loss: 91.04
 ---- batch: 030 ----
mean loss: 93.85
train mean loss: 92.28
epoch train time: 0:00:00.170862
elapsed time: 0:00:26.055814
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:55:59.292754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.72
 ---- batch: 020 ----
mean loss: 89.95
 ---- batch: 030 ----
mean loss: 93.37
train mean loss: 91.52
epoch train time: 0:00:00.169797
elapsed time: 0:00:26.225752
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:55:59.462723
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.33
 ---- batch: 020 ----
mean loss: 89.95
 ---- batch: 030 ----
mean loss: 91.52
train mean loss: 90.24
epoch train time: 0:00:00.184409
elapsed time: 0:00:26.410334
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:55:59.647276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.16
 ---- batch: 020 ----
mean loss: 86.90
 ---- batch: 030 ----
mean loss: 87.80
train mean loss: 88.83
epoch train time: 0:00:00.174873
elapsed time: 0:00:26.585365
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:55:59.822307
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.93
 ---- batch: 020 ----
mean loss: 89.22
 ---- batch: 030 ----
mean loss: 89.61
train mean loss: 87.93
epoch train time: 0:00:00.175730
elapsed time: 0:00:26.761248
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:55:59.998191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.57
 ---- batch: 020 ----
mean loss: 88.89
 ---- batch: 030 ----
mean loss: 83.71
train mean loss: 86.76
epoch train time: 0:00:00.176716
elapsed time: 0:00:26.938105
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:56:00.175048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.66
 ---- batch: 020 ----
mean loss: 83.73
 ---- batch: 030 ----
mean loss: 86.16
train mean loss: 85.64
epoch train time: 0:00:00.174045
elapsed time: 0:00:27.112293
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:56:00.349235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.01
 ---- batch: 020 ----
mean loss: 88.22
 ---- batch: 030 ----
mean loss: 84.27
train mean loss: 84.53
epoch train time: 0:00:00.175990
elapsed time: 0:00:27.288434
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:56:00.525383
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.14
 ---- batch: 020 ----
mean loss: 84.46
 ---- batch: 030 ----
mean loss: 82.90
train mean loss: 83.71
epoch train time: 0:00:00.170601
elapsed time: 0:00:27.459184
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:56:00.696167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.64
 ---- batch: 020 ----
mean loss: 82.18
 ---- batch: 030 ----
mean loss: 87.45
train mean loss: 83.66
epoch train time: 0:00:00.179398
elapsed time: 0:00:27.638761
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:56:00.875750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.76
 ---- batch: 020 ----
mean loss: 83.63
 ---- batch: 030 ----
mean loss: 80.05
train mean loss: 82.93
epoch train time: 0:00:00.181199
elapsed time: 0:00:27.820189
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:56:01.057131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.78
 ---- batch: 020 ----
mean loss: 78.21
 ---- batch: 030 ----
mean loss: 81.56
train mean loss: 81.55
epoch train time: 0:00:00.174122
elapsed time: 0:00:27.994458
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:56:01.231401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.37
 ---- batch: 020 ----
mean loss: 78.77
 ---- batch: 030 ----
mean loss: 82.19
train mean loss: 80.94
epoch train time: 0:00:00.172757
elapsed time: 0:00:28.167383
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:56:01.404336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.05
 ---- batch: 020 ----
mean loss: 80.23
 ---- batch: 030 ----
mean loss: 80.37
train mean loss: 80.17
epoch train time: 0:00:00.170947
elapsed time: 0:00:28.338481
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:56:01.575430
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.34
 ---- batch: 020 ----
mean loss: 81.16
 ---- batch: 030 ----
mean loss: 79.32
train mean loss: 79.39
epoch train time: 0:00:00.168227
elapsed time: 0:00:28.506862
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:56:01.743802
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.89
 ---- batch: 020 ----
mean loss: 79.78
 ---- batch: 030 ----
mean loss: 80.99
train mean loss: 80.41
epoch train time: 0:00:00.173300
elapsed time: 0:00:28.680321
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:56:01.917261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.47
 ---- batch: 020 ----
mean loss: 77.89
 ---- batch: 030 ----
mean loss: 79.22
train mean loss: 78.41
epoch train time: 0:00:00.171790
elapsed time: 0:00:28.852258
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:56:02.089199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.95
 ---- batch: 020 ----
mean loss: 77.60
 ---- batch: 030 ----
mean loss: 78.25
train mean loss: 78.17
epoch train time: 0:00:00.169011
elapsed time: 0:00:29.021405
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:56:02.258346
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.53
 ---- batch: 020 ----
mean loss: 75.21
 ---- batch: 030 ----
mean loss: 79.46
train mean loss: 77.53
epoch train time: 0:00:00.167991
elapsed time: 0:00:29.189531
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:56:02.426471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.81
 ---- batch: 020 ----
mean loss: 76.56
 ---- batch: 030 ----
mean loss: 78.61
train mean loss: 76.59
epoch train time: 0:00:00.171839
elapsed time: 0:00:29.361504
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:56:02.598444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.91
 ---- batch: 020 ----
mean loss: 77.04
 ---- batch: 030 ----
mean loss: 77.53
train mean loss: 77.19
epoch train time: 0:00:00.171888
elapsed time: 0:00:29.533530
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:56:02.770471
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.44
 ---- batch: 020 ----
mean loss: 75.84
 ---- batch: 030 ----
mean loss: 75.58
train mean loss: 76.12
epoch train time: 0:00:00.180603
elapsed time: 0:00:29.714274
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:56:02.951215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.21
 ---- batch: 020 ----
mean loss: 76.10
 ---- batch: 030 ----
mean loss: 73.21
train mean loss: 75.61
epoch train time: 0:00:00.171600
elapsed time: 0:00:29.886017
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:56:03.123034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.14
 ---- batch: 020 ----
mean loss: 74.21
 ---- batch: 030 ----
mean loss: 72.23
train mean loss: 74.93
epoch train time: 0:00:00.169725
elapsed time: 0:00:30.055956
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:56:03.292898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.32
 ---- batch: 020 ----
mean loss: 73.47
 ---- batch: 030 ----
mean loss: 73.57
train mean loss: 74.63
epoch train time: 0:00:00.170322
elapsed time: 0:00:30.226431
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:56:03.463371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.63
 ---- batch: 020 ----
mean loss: 76.10
 ---- batch: 030 ----
mean loss: 73.50
train mean loss: 74.06
epoch train time: 0:00:00.183478
elapsed time: 0:00:30.410058
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:56:03.647000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.91
 ---- batch: 020 ----
mean loss: 74.00
 ---- batch: 030 ----
mean loss: 72.69
train mean loss: 73.64
epoch train time: 0:00:00.172972
elapsed time: 0:00:30.583171
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:56:03.820110
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.12
 ---- batch: 020 ----
mean loss: 71.59
 ---- batch: 030 ----
mean loss: 71.87
train mean loss: 73.38
epoch train time: 0:00:00.178405
elapsed time: 0:00:30.761712
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:56:03.998652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.09
 ---- batch: 020 ----
mean loss: 72.65
 ---- batch: 030 ----
mean loss: 74.03
train mean loss: 72.81
epoch train time: 0:00:00.174553
elapsed time: 0:00:30.936417
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:56:04.173369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.40
 ---- batch: 020 ----
mean loss: 72.42
 ---- batch: 030 ----
mean loss: 70.81
train mean loss: 72.43
epoch train time: 0:00:00.173004
elapsed time: 0:00:31.109607
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:56:04.346556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.10
 ---- batch: 020 ----
mean loss: 73.01
 ---- batch: 030 ----
mean loss: 73.91
train mean loss: 72.50
epoch train time: 0:00:00.171160
elapsed time: 0:00:31.280914
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:56:04.517852
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.99
 ---- batch: 020 ----
mean loss: 73.44
 ---- batch: 030 ----
mean loss: 68.51
train mean loss: 72.10
epoch train time: 0:00:00.171682
elapsed time: 0:00:31.452751
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:56:04.689693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.09
 ---- batch: 020 ----
mean loss: 71.75
 ---- batch: 030 ----
mean loss: 72.35
train mean loss: 71.72
epoch train time: 0:00:00.175358
elapsed time: 0:00:31.628263
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:56:04.865201
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.50
 ---- batch: 020 ----
mean loss: 71.11
 ---- batch: 030 ----
mean loss: 73.85
train mean loss: 70.81
epoch train time: 0:00:00.169881
elapsed time: 0:00:31.798297
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:56:05.035239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.90
 ---- batch: 020 ----
mean loss: 69.75
 ---- batch: 030 ----
mean loss: 69.48
train mean loss: 71.01
epoch train time: 0:00:00.176567
elapsed time: 0:00:31.975019
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:56:05.211964
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.10
 ---- batch: 020 ----
mean loss: 71.41
 ---- batch: 030 ----
mean loss: 69.76
train mean loss: 70.82
epoch train time: 0:00:00.174839
elapsed time: 0:00:32.150009
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:56:05.386967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.01
 ---- batch: 020 ----
mean loss: 67.34
 ---- batch: 030 ----
mean loss: 71.66
train mean loss: 70.04
epoch train time: 0:00:00.173696
elapsed time: 0:00:32.323860
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:56:05.560817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.67
 ---- batch: 020 ----
mean loss: 68.00
 ---- batch: 030 ----
mean loss: 70.73
train mean loss: 69.73
epoch train time: 0:00:00.171373
elapsed time: 0:00:32.495387
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:56:05.732328
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.71
 ---- batch: 020 ----
mean loss: 68.33
 ---- batch: 030 ----
mean loss: 71.40
train mean loss: 70.03
epoch train time: 0:00:00.176742
elapsed time: 0:00:32.672280
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:56:05.909219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.11
 ---- batch: 020 ----
mean loss: 69.41
 ---- batch: 030 ----
mean loss: 71.91
train mean loss: 70.77
epoch train time: 0:00:00.174225
elapsed time: 0:00:32.846642
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:56:06.083606
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.13
 ---- batch: 020 ----
mean loss: 69.67
 ---- batch: 030 ----
mean loss: 71.08
train mean loss: 69.87
epoch train time: 0:00:00.172109
elapsed time: 0:00:33.018916
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:56:06.255856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.16
 ---- batch: 020 ----
mean loss: 68.50
 ---- batch: 030 ----
mean loss: 70.22
train mean loss: 69.18
epoch train time: 0:00:00.174230
elapsed time: 0:00:33.193284
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:56:06.430224
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.95
 ---- batch: 020 ----
mean loss: 70.62
 ---- batch: 030 ----
mean loss: 69.75
train mean loss: 69.98
epoch train time: 0:00:00.170118
elapsed time: 0:00:33.363545
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:56:06.600486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.29
 ---- batch: 020 ----
mean loss: 69.53
 ---- batch: 030 ----
mean loss: 67.12
train mean loss: 68.85
epoch train time: 0:00:00.177199
elapsed time: 0:00:33.540901
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:56:06.777843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.38
 ---- batch: 020 ----
mean loss: 66.61
 ---- batch: 030 ----
mean loss: 70.07
train mean loss: 67.64
epoch train time: 0:00:00.177531
elapsed time: 0:00:33.718574
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:56:06.955516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.46
 ---- batch: 020 ----
mean loss: 68.12
 ---- batch: 030 ----
mean loss: 66.43
train mean loss: 67.14
epoch train time: 0:00:00.172736
elapsed time: 0:00:33.891462
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:56:07.128412
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.12
 ---- batch: 020 ----
mean loss: 66.49
 ---- batch: 030 ----
mean loss: 66.54
train mean loss: 66.64
epoch train time: 0:00:00.170930
elapsed time: 0:00:34.062539
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:56:07.299481
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.99
 ---- batch: 020 ----
mean loss: 64.62
 ---- batch: 030 ----
mean loss: 68.56
train mean loss: 66.82
epoch train time: 0:00:00.168245
elapsed time: 0:00:34.230923
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:56:07.467865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.52
 ---- batch: 020 ----
mean loss: 63.90
 ---- batch: 030 ----
mean loss: 64.58
train mean loss: 66.25
epoch train time: 0:00:00.173614
elapsed time: 0:00:34.404675
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:56:07.641639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.73
 ---- batch: 020 ----
mean loss: 65.09
 ---- batch: 030 ----
mean loss: 67.63
train mean loss: 66.14
epoch train time: 0:00:00.170921
elapsed time: 0:00:34.575773
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:56:07.812704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.38
 ---- batch: 020 ----
mean loss: 66.16
 ---- batch: 030 ----
mean loss: 67.61
train mean loss: 66.44
epoch train time: 0:00:00.177291
elapsed time: 0:00:34.753205
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:56:07.990174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.95
 ---- batch: 020 ----
mean loss: 65.97
 ---- batch: 030 ----
mean loss: 64.43
train mean loss: 65.63
epoch train time: 0:00:00.180375
elapsed time: 0:00:34.933744
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:56:08.170684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.22
 ---- batch: 020 ----
mean loss: 66.33
 ---- batch: 030 ----
mean loss: 62.75
train mean loss: 64.82
epoch train time: 0:00:00.167237
elapsed time: 0:00:35.101119
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:56:08.338058
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.83
 ---- batch: 020 ----
mean loss: 64.93
 ---- batch: 030 ----
mean loss: 63.44
train mean loss: 64.96
epoch train time: 0:00:00.170044
elapsed time: 0:00:35.271313
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:56:08.508253
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.02
 ---- batch: 020 ----
mean loss: 63.77
 ---- batch: 030 ----
mean loss: 63.50
train mean loss: 63.95
epoch train time: 0:00:00.169415
elapsed time: 0:00:35.440938
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:56:08.677885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.24
 ---- batch: 020 ----
mean loss: 67.33
 ---- batch: 030 ----
mean loss: 61.85
train mean loss: 64.50
epoch train time: 0:00:00.179064
elapsed time: 0:00:35.620146
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:56:08.857099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.80
 ---- batch: 020 ----
mean loss: 65.25
 ---- batch: 030 ----
mean loss: 65.43
train mean loss: 64.73
epoch train time: 0:00:00.171817
elapsed time: 0:00:35.792115
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:56:09.029057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.95
 ---- batch: 020 ----
mean loss: 63.09
 ---- batch: 030 ----
mean loss: 63.79
train mean loss: 63.54
epoch train time: 0:00:00.188220
elapsed time: 0:00:35.980475
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:56:09.217425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.99
 ---- batch: 020 ----
mean loss: 61.55
 ---- batch: 030 ----
mean loss: 64.57
train mean loss: 63.71
epoch train time: 0:00:00.171586
elapsed time: 0:00:36.152209
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:56:09.389150
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.95
 ---- batch: 020 ----
mean loss: 63.82
 ---- batch: 030 ----
mean loss: 61.10
train mean loss: 63.30
epoch train time: 0:00:00.174740
elapsed time: 0:00:36.327103
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:56:09.564052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.25
 ---- batch: 020 ----
mean loss: 66.38
 ---- batch: 030 ----
mean loss: 59.87
train mean loss: 63.72
epoch train time: 0:00:00.174131
elapsed time: 0:00:36.501378
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:56:09.738318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.47
 ---- batch: 020 ----
mean loss: 67.08
 ---- batch: 030 ----
mean loss: 64.06
train mean loss: 64.80
epoch train time: 0:00:00.175565
elapsed time: 0:00:36.677085
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:56:09.914026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.03
 ---- batch: 020 ----
mean loss: 63.93
 ---- batch: 030 ----
mean loss: 63.15
train mean loss: 62.64
epoch train time: 0:00:00.173192
elapsed time: 0:00:36.850416
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:56:10.087368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.38
 ---- batch: 020 ----
mean loss: 64.02
 ---- batch: 030 ----
mean loss: 66.04
train mean loss: 63.76
epoch train time: 0:00:00.172066
elapsed time: 0:00:37.022630
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:56:10.259570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.44
 ---- batch: 020 ----
mean loss: 63.51
 ---- batch: 030 ----
mean loss: 64.10
train mean loss: 63.11
epoch train time: 0:00:00.169867
elapsed time: 0:00:37.192635
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:56:10.429593
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.65
 ---- batch: 020 ----
mean loss: 61.91
 ---- batch: 030 ----
mean loss: 63.39
train mean loss: 62.05
epoch train time: 0:00:00.170334
elapsed time: 0:00:37.363121
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:56:10.600061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.03
 ---- batch: 020 ----
mean loss: 61.43
 ---- batch: 030 ----
mean loss: 63.60
train mean loss: 61.86
epoch train time: 0:00:00.171842
elapsed time: 0:00:37.535131
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:56:10.772086
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.01
 ---- batch: 020 ----
mean loss: 60.81
 ---- batch: 030 ----
mean loss: 61.99
train mean loss: 61.61
epoch train time: 0:00:00.173915
elapsed time: 0:00:37.709200
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:56:10.946140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.67
 ---- batch: 020 ----
mean loss: 61.96
 ---- batch: 030 ----
mean loss: 59.20
train mean loss: 61.64
epoch train time: 0:00:00.168658
elapsed time: 0:00:37.877993
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:56:11.114934
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.08
 ---- batch: 020 ----
mean loss: 63.71
 ---- batch: 030 ----
mean loss: 60.36
train mean loss: 61.47
epoch train time: 0:00:00.172649
elapsed time: 0:00:38.050789
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:56:11.287737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.50
 ---- batch: 020 ----
mean loss: 61.37
 ---- batch: 030 ----
mean loss: 62.41
train mean loss: 61.10
epoch train time: 0:00:00.178490
elapsed time: 0:00:38.229426
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:56:11.466369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.73
 ---- batch: 020 ----
mean loss: 63.21
 ---- batch: 030 ----
mean loss: 61.42
train mean loss: 61.76
epoch train time: 0:00:00.176741
elapsed time: 0:00:38.406335
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:56:11.643266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.25
 ---- batch: 020 ----
mean loss: 62.44
 ---- batch: 030 ----
mean loss: 59.95
train mean loss: 61.87
epoch train time: 0:00:00.181172
elapsed time: 0:00:38.587667
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:56:11.824609
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.96
 ---- batch: 020 ----
mean loss: 60.83
 ---- batch: 030 ----
mean loss: 60.27
train mean loss: 60.50
epoch train time: 0:00:00.173681
elapsed time: 0:00:38.761542
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:56:11.998484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.77
 ---- batch: 020 ----
mean loss: 60.92
 ---- batch: 030 ----
mean loss: 65.57
train mean loss: 61.44
epoch train time: 0:00:00.168538
elapsed time: 0:00:38.930220
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:56:12.167161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.26
 ---- batch: 020 ----
mean loss: 62.47
 ---- batch: 030 ----
mean loss: 57.49
train mean loss: 60.30
epoch train time: 0:00:00.169548
elapsed time: 0:00:39.099910
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:56:12.336851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.14
 ---- batch: 020 ----
mean loss: 60.57
 ---- batch: 030 ----
mean loss: 62.11
train mean loss: 60.51
epoch train time: 0:00:00.176643
elapsed time: 0:00:39.276693
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:56:12.513698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.18
 ---- batch: 020 ----
mean loss: 62.80
 ---- batch: 030 ----
mean loss: 60.48
train mean loss: 61.20
epoch train time: 0:00:00.178629
elapsed time: 0:00:39.455523
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:56:12.692500
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.49
 ---- batch: 020 ----
mean loss: 60.41
 ---- batch: 030 ----
mean loss: 62.33
train mean loss: 59.94
epoch train time: 0:00:00.181618
elapsed time: 0:00:39.637321
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:56:12.874261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.56
 ---- batch: 020 ----
mean loss: 59.21
 ---- batch: 030 ----
mean loss: 58.65
train mean loss: 59.55
epoch train time: 0:00:00.179668
elapsed time: 0:00:39.817130
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:56:13.054070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.79
 ---- batch: 020 ----
mean loss: 61.15
 ---- batch: 030 ----
mean loss: 61.46
train mean loss: 60.94
epoch train time: 0:00:00.177559
elapsed time: 0:00:39.994826
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:56:13.231767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.52
 ---- batch: 020 ----
mean loss: 61.35
 ---- batch: 030 ----
mean loss: 57.93
train mean loss: 59.33
epoch train time: 0:00:00.176015
elapsed time: 0:00:40.170980
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:56:13.407919
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.39
 ---- batch: 020 ----
mean loss: 57.55
 ---- batch: 030 ----
mean loss: 57.96
train mean loss: 59.08
epoch train time: 0:00:00.179110
elapsed time: 0:00:40.350230
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:56:13.587171
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.37
 ---- batch: 020 ----
mean loss: 57.70
 ---- batch: 030 ----
mean loss: 61.40
train mean loss: 59.56
epoch train time: 0:00:00.176650
elapsed time: 0:00:40.527015
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:56:13.763956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.97
 ---- batch: 020 ----
mean loss: 58.34
 ---- batch: 030 ----
mean loss: 58.58
train mean loss: 60.20
epoch train time: 0:00:00.186922
elapsed time: 0:00:40.714095
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:56:13.951040
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.32
 ---- batch: 020 ----
mean loss: 58.54
 ---- batch: 030 ----
mean loss: 60.35
train mean loss: 58.64
epoch train time: 0:00:00.181292
elapsed time: 0:00:40.895543
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:56:14.132483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.19
 ---- batch: 020 ----
mean loss: 59.33
 ---- batch: 030 ----
mean loss: 58.16
train mean loss: 58.69
epoch train time: 0:00:00.182965
elapsed time: 0:00:41.079620
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:56:14.316619
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.23
 ---- batch: 020 ----
mean loss: 57.62
 ---- batch: 030 ----
mean loss: 57.30
train mean loss: 58.64
epoch train time: 0:00:00.179572
elapsed time: 0:00:41.259390
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:56:14.496330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.98
 ---- batch: 020 ----
mean loss: 56.29
 ---- batch: 030 ----
mean loss: 59.26
train mean loss: 58.13
epoch train time: 0:00:00.179599
elapsed time: 0:00:41.439127
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:56:14.676069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.72
 ---- batch: 020 ----
mean loss: 56.82
 ---- batch: 030 ----
mean loss: 56.90
train mean loss: 57.99
epoch train time: 0:00:00.182862
elapsed time: 0:00:41.622132
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:56:14.859076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.49
 ---- batch: 020 ----
mean loss: 57.72
 ---- batch: 030 ----
mean loss: 59.94
train mean loss: 59.00
epoch train time: 0:00:00.177430
elapsed time: 0:00:41.799719
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:56:15.036669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.86
 ---- batch: 020 ----
mean loss: 56.15
 ---- batch: 030 ----
mean loss: 56.18
train mean loss: 57.70
epoch train time: 0:00:00.186170
elapsed time: 0:00:41.986036
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:56:15.222999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.69
 ---- batch: 020 ----
mean loss: 60.14
 ---- batch: 030 ----
mean loss: 57.25
train mean loss: 57.56
epoch train time: 0:00:00.169836
elapsed time: 0:00:42.156032
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:56:15.392972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.56
 ---- batch: 020 ----
mean loss: 58.89
 ---- batch: 030 ----
mean loss: 57.32
train mean loss: 57.30
epoch train time: 0:00:00.178594
elapsed time: 0:00:42.334765
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:56:15.571705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.88
 ---- batch: 020 ----
mean loss: 57.69
 ---- batch: 030 ----
mean loss: 56.32
train mean loss: 57.86
epoch train time: 0:00:00.177832
elapsed time: 0:00:42.512805
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:56:15.749767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.41
 ---- batch: 020 ----
mean loss: 55.07
 ---- batch: 030 ----
mean loss: 57.51
train mean loss: 57.33
epoch train time: 0:00:00.179509
elapsed time: 0:00:42.692473
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:56:15.929425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.61
 ---- batch: 020 ----
mean loss: 59.06
 ---- batch: 030 ----
mean loss: 56.89
train mean loss: 57.45
epoch train time: 0:00:00.178697
elapsed time: 0:00:42.871332
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:56:16.108262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.92
 ---- batch: 020 ----
mean loss: 58.91
 ---- batch: 030 ----
mean loss: 58.78
train mean loss: 57.12
epoch train time: 0:00:00.186986
elapsed time: 0:00:43.058451
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:56:16.295391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.71
 ---- batch: 020 ----
mean loss: 55.34
 ---- batch: 030 ----
mean loss: 58.03
train mean loss: 57.30
epoch train time: 0:00:00.181697
elapsed time: 0:00:43.240286
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:56:16.477227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.58
 ---- batch: 020 ----
mean loss: 55.40
 ---- batch: 030 ----
mean loss: 58.41
train mean loss: 57.02
epoch train time: 0:00:00.180290
elapsed time: 0:00:43.420740
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:56:16.657685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.65
 ---- batch: 020 ----
mean loss: 56.30
 ---- batch: 030 ----
mean loss: 58.37
train mean loss: 57.32
epoch train time: 0:00:00.181792
elapsed time: 0:00:43.602689
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:56:16.839629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.25
 ---- batch: 020 ----
mean loss: 55.75
 ---- batch: 030 ----
mean loss: 55.05
train mean loss: 55.85
epoch train time: 0:00:00.181616
elapsed time: 0:00:43.784444
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:56:17.021387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.95
 ---- batch: 020 ----
mean loss: 55.33
 ---- batch: 030 ----
mean loss: 56.77
train mean loss: 56.33
epoch train time: 0:00:00.179052
elapsed time: 0:00:43.963636
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:56:17.200578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.44
 ---- batch: 020 ----
mean loss: 56.40
 ---- batch: 030 ----
mean loss: 55.60
train mean loss: 55.46
epoch train time: 0:00:00.180275
elapsed time: 0:00:44.144053
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:56:17.381003
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.41
 ---- batch: 020 ----
mean loss: 58.80
 ---- batch: 030 ----
mean loss: 56.58
train mean loss: 56.45
epoch train time: 0:00:00.173753
elapsed time: 0:00:44.317956
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:56:17.554907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.57
 ---- batch: 020 ----
mean loss: 58.59
 ---- batch: 030 ----
mean loss: 54.08
train mean loss: 54.91
epoch train time: 0:00:00.174934
elapsed time: 0:00:44.493054
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:56:17.730015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.31
 ---- batch: 020 ----
mean loss: 55.01
 ---- batch: 030 ----
mean loss: 58.19
train mean loss: 55.67
epoch train time: 0:00:00.175887
elapsed time: 0:00:44.669100
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:56:17.906039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.58
 ---- batch: 020 ----
mean loss: 56.04
 ---- batch: 030 ----
mean loss: 55.71
train mean loss: 55.47
epoch train time: 0:00:00.170505
elapsed time: 0:00:44.839739
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:56:18.076679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.67
 ---- batch: 020 ----
mean loss: 54.40
 ---- batch: 030 ----
mean loss: 54.31
train mean loss: 55.36
epoch train time: 0:00:00.167226
elapsed time: 0:00:45.007166
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:56:18.244105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.34
 ---- batch: 020 ----
mean loss: 57.35
 ---- batch: 030 ----
mean loss: 55.58
train mean loss: 56.99
epoch train time: 0:00:00.168532
elapsed time: 0:00:45.175839
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:56:18.412778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.78
 ---- batch: 020 ----
mean loss: 55.27
 ---- batch: 030 ----
mean loss: 57.90
train mean loss: 55.47
epoch train time: 0:00:00.171334
elapsed time: 0:00:45.347367
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:56:18.584319
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.65
 ---- batch: 020 ----
mean loss: 53.98
 ---- batch: 030 ----
mean loss: 53.56
train mean loss: 54.26
epoch train time: 0:00:00.172682
elapsed time: 0:00:45.520194
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:56:18.757133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.84
 ---- batch: 020 ----
mean loss: 52.92
 ---- batch: 030 ----
mean loss: 55.48
train mean loss: 54.03
epoch train time: 0:00:00.170946
elapsed time: 0:00:45.691275
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:56:18.928215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.87
 ---- batch: 020 ----
mean loss: 52.84
 ---- batch: 030 ----
mean loss: 53.36
train mean loss: 53.79
epoch train time: 0:00:00.175801
elapsed time: 0:00:45.867216
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:56:19.104159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.98
 ---- batch: 020 ----
mean loss: 52.89
 ---- batch: 030 ----
mean loss: 54.09
train mean loss: 53.54
epoch train time: 0:00:00.172587
elapsed time: 0:00:46.039944
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:56:19.276884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.20
 ---- batch: 020 ----
mean loss: 52.37
 ---- batch: 030 ----
mean loss: 56.57
train mean loss: 53.76
epoch train time: 0:00:00.171465
elapsed time: 0:00:46.211547
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:56:19.448492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.90
 ---- batch: 020 ----
mean loss: 56.03
 ---- batch: 030 ----
mean loss: 53.26
train mean loss: 54.00
epoch train time: 0:00:00.171174
elapsed time: 0:00:46.382866
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:56:19.619807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.20
 ---- batch: 020 ----
mean loss: 54.21
 ---- batch: 030 ----
mean loss: 54.99
train mean loss: 54.19
epoch train time: 0:00:00.175052
elapsed time: 0:00:46.558126
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:56:19.795084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.91
 ---- batch: 020 ----
mean loss: 55.99
 ---- batch: 030 ----
mean loss: 55.86
train mean loss: 55.71
epoch train time: 0:00:00.175845
elapsed time: 0:00:46.734137
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:56:19.971095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.13
 ---- batch: 020 ----
mean loss: 55.48
 ---- batch: 030 ----
mean loss: 50.73
train mean loss: 53.31
epoch train time: 0:00:00.172269
elapsed time: 0:00:46.906560
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:56:20.143501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.70
 ---- batch: 020 ----
mean loss: 54.24
 ---- batch: 030 ----
mean loss: 51.63
train mean loss: 53.11
epoch train time: 0:00:00.180904
elapsed time: 0:00:47.087601
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:56:20.324542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.28
 ---- batch: 020 ----
mean loss: 52.96
 ---- batch: 030 ----
mean loss: 52.97
train mean loss: 52.59
epoch train time: 0:00:00.176378
elapsed time: 0:00:47.264117
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:56:20.501057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.61
 ---- batch: 020 ----
mean loss: 50.41
 ---- batch: 030 ----
mean loss: 53.92
train mean loss: 53.11
epoch train time: 0:00:00.171863
elapsed time: 0:00:47.436117
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:56:20.673072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.92
 ---- batch: 020 ----
mean loss: 52.61
 ---- batch: 030 ----
mean loss: 53.04
train mean loss: 53.27
epoch train time: 0:00:00.175902
elapsed time: 0:00:47.612175
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:56:20.849119
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.76
 ---- batch: 020 ----
mean loss: 52.91
 ---- batch: 030 ----
mean loss: 52.56
train mean loss: 51.47
epoch train time: 0:00:00.181590
elapsed time: 0:00:47.793920
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:56:21.030851
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.80
 ---- batch: 020 ----
mean loss: 51.84
 ---- batch: 030 ----
mean loss: 50.72
train mean loss: 51.14
epoch train time: 0:00:00.169666
elapsed time: 0:00:47.963713
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:56:21.200662
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.16
 ---- batch: 020 ----
mean loss: 50.21
 ---- batch: 030 ----
mean loss: 51.32
train mean loss: 51.28
epoch train time: 0:00:00.169851
elapsed time: 0:00:48.133734
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:56:21.370704
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 53.04
 ---- batch: 020 ----
mean loss: 49.66
 ---- batch: 030 ----
mean loss: 51.39
train mean loss: 51.07
epoch train time: 0:00:00.170393
elapsed time: 0:00:48.304294
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:56:21.541233
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.85
 ---- batch: 020 ----
mean loss: 52.38
 ---- batch: 030 ----
mean loss: 50.35
train mean loss: 51.16
epoch train time: 0:00:00.173452
elapsed time: 0:00:48.477914
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:56:21.714858
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.70
 ---- batch: 020 ----
mean loss: 51.21
 ---- batch: 030 ----
mean loss: 50.89
train mean loss: 51.02
epoch train time: 0:00:00.176597
elapsed time: 0:00:48.654672
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:56:21.891626
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.10
 ---- batch: 020 ----
mean loss: 51.81
 ---- batch: 030 ----
mean loss: 50.88
train mean loss: 51.00
epoch train time: 0:00:00.170110
elapsed time: 0:00:48.824935
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:56:22.061877
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.14
 ---- batch: 020 ----
mean loss: 49.57
 ---- batch: 030 ----
mean loss: 49.73
train mean loss: 51.06
epoch train time: 0:00:00.176194
elapsed time: 0:00:49.001269
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:56:22.238211
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.50
 ---- batch: 020 ----
mean loss: 51.08
 ---- batch: 030 ----
mean loss: 50.72
train mean loss: 50.92
epoch train time: 0:00:00.169905
elapsed time: 0:00:49.171312
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:56:22.408270
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.87
 ---- batch: 020 ----
mean loss: 51.22
 ---- batch: 030 ----
mean loss: 51.88
train mean loss: 51.11
epoch train time: 0:00:00.168790
elapsed time: 0:00:49.340254
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:56:22.577196
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.02
 ---- batch: 020 ----
mean loss: 49.80
 ---- batch: 030 ----
mean loss: 49.68
train mean loss: 50.86
epoch train time: 0:00:00.173880
elapsed time: 0:00:49.514271
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:56:22.751241
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.02
 ---- batch: 020 ----
mean loss: 51.42
 ---- batch: 030 ----
mean loss: 51.47
train mean loss: 50.94
epoch train time: 0:00:00.176614
elapsed time: 0:00:49.691080
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:56:22.928022
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.42
 ---- batch: 020 ----
mean loss: 48.75
 ---- batch: 030 ----
mean loss: 51.71
train mean loss: 50.95
epoch train time: 0:00:00.173055
elapsed time: 0:00:49.864273
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 16:56:23.101214
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.24
 ---- batch: 020 ----
mean loss: 52.12
 ---- batch: 030 ----
mean loss: 49.59
train mean loss: 51.02
epoch train time: 0:00:00.172521
elapsed time: 0:00:50.036934
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 16:56:23.273874
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.92
 ---- batch: 020 ----
mean loss: 50.67
 ---- batch: 030 ----
mean loss: 52.97
train mean loss: 50.77
epoch train time: 0:00:00.172945
elapsed time: 0:00:50.210018
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 16:56:23.446958
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.48
 ---- batch: 020 ----
mean loss: 51.33
 ---- batch: 030 ----
mean loss: 50.14
train mean loss: 50.96
epoch train time: 0:00:00.171236
elapsed time: 0:00:50.381392
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 16:56:23.618333
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.25
 ---- batch: 020 ----
mean loss: 51.97
 ---- batch: 030 ----
mean loss: 52.87
train mean loss: 50.82
epoch train time: 0:00:00.170784
elapsed time: 0:00:50.552313
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 16:56:23.789253
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.87
 ---- batch: 020 ----
mean loss: 51.55
 ---- batch: 030 ----
mean loss: 48.23
train mean loss: 50.86
epoch train time: 0:00:00.171909
elapsed time: 0:00:50.724393
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 16:56:23.961332
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.73
 ---- batch: 020 ----
mean loss: 51.41
 ---- batch: 030 ----
mean loss: 51.11
train mean loss: 50.81
epoch train time: 0:00:00.174027
elapsed time: 0:00:50.898558
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 16:56:24.135500
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.23
 ---- batch: 020 ----
mean loss: 51.03
 ---- batch: 030 ----
mean loss: 52.79
train mean loss: 50.90
epoch train time: 0:00:00.170121
elapsed time: 0:00:51.068822
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 16:56:24.305764
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.50
 ---- batch: 020 ----
mean loss: 50.32
 ---- batch: 030 ----
mean loss: 51.53
train mean loss: 50.73
epoch train time: 0:00:00.177051
elapsed time: 0:00:51.246022
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 16:56:24.482967
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.33
 ---- batch: 020 ----
mean loss: 50.95
 ---- batch: 030 ----
mean loss: 49.90
train mean loss: 50.80
epoch train time: 0:00:00.168855
elapsed time: 0:00:51.415018
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 16:56:24.651957
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.33
 ---- batch: 020 ----
mean loss: 49.61
 ---- batch: 030 ----
mean loss: 53.05
train mean loss: 50.66
epoch train time: 0:00:00.177682
elapsed time: 0:00:51.592836
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 16:56:24.829793
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.53
 ---- batch: 020 ----
mean loss: 49.16
 ---- batch: 030 ----
mean loss: 51.56
train mean loss: 50.73
epoch train time: 0:00:00.167653
elapsed time: 0:00:51.760641
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 16:56:24.997589
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.96
 ---- batch: 020 ----
mean loss: 49.54
 ---- batch: 030 ----
mean loss: 51.08
train mean loss: 50.72
epoch train time: 0:00:00.170772
elapsed time: 0:00:51.931575
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 16:56:25.168519
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.68
 ---- batch: 020 ----
mean loss: 49.74
 ---- batch: 030 ----
mean loss: 49.38
train mean loss: 50.62
epoch train time: 0:00:00.169252
elapsed time: 0:00:52.101005
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 16:56:25.337963
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.51
 ---- batch: 020 ----
mean loss: 52.37
 ---- batch: 030 ----
mean loss: 49.77
train mean loss: 50.61
epoch train time: 0:00:00.171958
elapsed time: 0:00:52.273122
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 16:56:25.510061
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.33
 ---- batch: 020 ----
mean loss: 50.46
 ---- batch: 030 ----
mean loss: 50.11
train mean loss: 50.61
epoch train time: 0:00:00.167245
elapsed time: 0:00:52.440499
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 16:56:25.677439
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.56
 ---- batch: 020 ----
mean loss: 49.60
 ---- batch: 030 ----
mean loss: 51.22
train mean loss: 50.46
epoch train time: 0:00:00.168686
elapsed time: 0:00:52.609322
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 16:56:25.846263
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.59
 ---- batch: 020 ----
mean loss: 52.90
 ---- batch: 030 ----
mean loss: 49.81
train mean loss: 50.64
epoch train time: 0:00:00.175044
elapsed time: 0:00:52.784516
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 16:56:26.021461
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.71
 ---- batch: 020 ----
mean loss: 50.45
 ---- batch: 030 ----
mean loss: 50.79
train mean loss: 50.51
epoch train time: 0:00:00.174748
elapsed time: 0:00:52.959407
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 16:56:26.196349
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.37
 ---- batch: 020 ----
mean loss: 52.87
 ---- batch: 030 ----
mean loss: 48.85
train mean loss: 50.32
epoch train time: 0:00:00.173604
elapsed time: 0:00:53.133152
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 16:56:26.370095
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.55
 ---- batch: 020 ----
mean loss: 50.21
 ---- batch: 030 ----
mean loss: 49.36
train mean loss: 50.52
epoch train time: 0:00:00.174374
elapsed time: 0:00:53.307680
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 16:56:26.544623
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.23
 ---- batch: 020 ----
mean loss: 52.12
 ---- batch: 030 ----
mean loss: 48.71
train mean loss: 50.56
epoch train time: 0:00:00.170077
elapsed time: 0:00:53.477898
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 16:56:26.714837
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.29
 ---- batch: 020 ----
mean loss: 51.03
 ---- batch: 030 ----
mean loss: 48.52
train mean loss: 50.49
epoch train time: 0:00:00.178222
elapsed time: 0:00:53.656257
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 16:56:26.893198
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.65
 ---- batch: 020 ----
mean loss: 49.46
 ---- batch: 030 ----
mean loss: 51.17
train mean loss: 50.40
epoch train time: 0:00:00.172940
elapsed time: 0:00:53.829362
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 16:56:27.066318
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.38
 ---- batch: 020 ----
mean loss: 50.69
 ---- batch: 030 ----
mean loss: 50.26
train mean loss: 50.50
epoch train time: 0:00:00.167449
elapsed time: 0:00:53.996965
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 16:56:27.233907
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.31
 ---- batch: 020 ----
mean loss: 49.76
 ---- batch: 030 ----
mean loss: 50.30
train mean loss: 50.37
epoch train time: 0:00:00.170068
elapsed time: 0:00:54.167172
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 16:56:27.404124
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.40
 ---- batch: 020 ----
mean loss: 49.49
 ---- batch: 030 ----
mean loss: 49.17
train mean loss: 50.43
epoch train time: 0:00:00.171781
elapsed time: 0:00:54.339160
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 16:56:27.576124
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.35
 ---- batch: 020 ----
mean loss: 50.23
 ---- batch: 030 ----
mean loss: 50.20
train mean loss: 50.49
epoch train time: 0:00:00.172924
elapsed time: 0:00:54.512245
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 16:56:27.749186
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.51
 ---- batch: 020 ----
mean loss: 49.11
 ---- batch: 030 ----
mean loss: 52.25
train mean loss: 50.29
epoch train time: 0:00:00.171377
elapsed time: 0:00:54.683761
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 16:56:27.920702
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.96
 ---- batch: 020 ----
mean loss: 50.54
 ---- batch: 030 ----
mean loss: 48.98
train mean loss: 50.37
epoch train time: 0:00:00.172284
elapsed time: 0:00:54.856194
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 16:56:28.093132
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.92
 ---- batch: 020 ----
mean loss: 50.66
 ---- batch: 030 ----
mean loss: 49.66
train mean loss: 50.23
epoch train time: 0:00:00.169379
elapsed time: 0:00:55.025705
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 16:56:28.262642
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.68
 ---- batch: 020 ----
mean loss: 50.64
 ---- batch: 030 ----
mean loss: 50.64
train mean loss: 50.18
epoch train time: 0:00:00.168294
elapsed time: 0:00:55.194145
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 16:56:28.431087
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.50
 ---- batch: 020 ----
mean loss: 50.19
 ---- batch: 030 ----
mean loss: 51.78
train mean loss: 50.21
epoch train time: 0:00:00.173097
elapsed time: 0:00:55.367377
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 16:56:28.604315
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.54
 ---- batch: 020 ----
mean loss: 48.74
 ---- batch: 030 ----
mean loss: 49.65
train mean loss: 50.08
epoch train time: 0:00:00.170040
elapsed time: 0:00:55.537552
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 16:56:28.774492
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.26
 ---- batch: 020 ----
mean loss: 49.02
 ---- batch: 030 ----
mean loss: 49.82
train mean loss: 50.09
epoch train time: 0:00:00.179147
elapsed time: 0:00:55.716864
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 16:56:28.953808
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.87
 ---- batch: 020 ----
mean loss: 49.33
 ---- batch: 030 ----
mean loss: 46.71
train mean loss: 50.29
epoch train time: 0:00:00.170341
elapsed time: 0:00:55.887347
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 16:56:29.124287
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.80
 ---- batch: 020 ----
mean loss: 51.04
 ---- batch: 030 ----
mean loss: 51.50
train mean loss: 50.25
epoch train time: 0:00:00.170222
elapsed time: 0:00:56.060987
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_3/checkpoint.pth.tar
**** end time: 2019-09-27 16:56:29.297896 ****
