Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_2', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29659
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:11:50.955073 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:11:50.965302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4108.56
 ---- batch: 020 ----
mean loss: 3815.38
 ---- batch: 030 ----
mean loss: 3647.13
train mean loss: 3803.08
epoch train time: 0:00:13.122157
elapsed time: 0:00:13.138772
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:12:04.093885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3308.96
 ---- batch: 020 ----
mean loss: 3098.21
 ---- batch: 030 ----
mean loss: 2976.56
train mean loss: 3101.59
epoch train time: 0:00:00.579257
elapsed time: 0:00:13.718304
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:12:04.673492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2814.66
 ---- batch: 020 ----
mean loss: 2711.22
 ---- batch: 030 ----
mean loss: 2652.45
train mean loss: 2704.43
epoch train time: 0:00:00.590149
elapsed time: 0:00:14.308838
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:12:05.264016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2532.17
 ---- batch: 020 ----
mean loss: 2469.07
 ---- batch: 030 ----
mean loss: 2453.96
train mean loss: 2481.74
epoch train time: 0:00:00.577649
elapsed time: 0:00:14.886860
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:12:05.842043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2343.23
 ---- batch: 020 ----
mean loss: 2306.57
 ---- batch: 030 ----
mean loss: 2379.30
train mean loss: 2335.14
epoch train time: 0:00:00.573696
elapsed time: 0:00:15.460927
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:12:06.416101
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2250.60
 ---- batch: 020 ----
mean loss: 2207.40
 ---- batch: 030 ----
mean loss: 2193.43
train mean loss: 2212.26
epoch train time: 0:00:00.578013
elapsed time: 0:00:16.039276
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:12:06.994462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2156.74
 ---- batch: 020 ----
mean loss: 2097.05
 ---- batch: 030 ----
mean loss: 2082.46
train mean loss: 2107.22
epoch train time: 0:00:00.575883
elapsed time: 0:00:16.615502
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:12:07.570700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2054.81
 ---- batch: 020 ----
mean loss: 2042.44
 ---- batch: 030 ----
mean loss: 1975.93
train mean loss: 2018.96
epoch train time: 0:00:00.573116
elapsed time: 0:00:17.188970
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:12:08.144144
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1951.11
 ---- batch: 020 ----
mean loss: 1928.34
 ---- batch: 030 ----
mean loss: 1909.61
train mean loss: 1924.56
epoch train time: 0:00:00.577999
elapsed time: 0:00:17.767326
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:12:08.722521
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1891.21
 ---- batch: 020 ----
mean loss: 1850.81
 ---- batch: 030 ----
mean loss: 1823.62
train mean loss: 1847.69
epoch train time: 0:00:00.577994
elapsed time: 0:00:18.345745
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:12:09.301032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1778.06
 ---- batch: 020 ----
mean loss: 1784.67
 ---- batch: 030 ----
mean loss: 1751.92
train mean loss: 1767.16
epoch train time: 0:00:00.584133
elapsed time: 0:00:18.930329
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:12:09.885514
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1708.61
 ---- batch: 020 ----
mean loss: 1709.11
 ---- batch: 030 ----
mean loss: 1662.78
train mean loss: 1694.63
epoch train time: 0:00:00.577673
elapsed time: 0:00:19.508430
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:12:10.463629
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1660.52
 ---- batch: 020 ----
mean loss: 1622.88
 ---- batch: 030 ----
mean loss: 1631.63
train mean loss: 1628.55
epoch train time: 0:00:00.584202
elapsed time: 0:00:20.092998
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:12:11.048174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1605.40
 ---- batch: 020 ----
mean loss: 1575.58
 ---- batch: 030 ----
mean loss: 1534.56
train mean loss: 1561.54
epoch train time: 0:00:00.581104
elapsed time: 0:00:20.674432
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:12:11.629621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1510.26
 ---- batch: 020 ----
mean loss: 1513.68
 ---- batch: 030 ----
mean loss: 1482.19
train mean loss: 1500.08
epoch train time: 0:00:00.577747
elapsed time: 0:00:21.252602
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:12:12.207775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1451.09
 ---- batch: 020 ----
mean loss: 1432.55
 ---- batch: 030 ----
mean loss: 1435.01
train mean loss: 1437.19
epoch train time: 0:00:00.589722
elapsed time: 0:00:21.842736
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:12:12.797983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1397.55
 ---- batch: 020 ----
mean loss: 1378.89
 ---- batch: 030 ----
mean loss: 1377.02
train mean loss: 1382.67
epoch train time: 0:00:00.568068
elapsed time: 0:00:22.411337
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:12:13.366522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1339.81
 ---- batch: 020 ----
mean loss: 1334.05
 ---- batch: 030 ----
mean loss: 1291.54
train mean loss: 1323.67
epoch train time: 0:00:00.579198
elapsed time: 0:00:22.990875
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:12:13.946095
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1287.34
 ---- batch: 020 ----
mean loss: 1281.78
 ---- batch: 030 ----
mean loss: 1249.05
train mean loss: 1267.51
epoch train time: 0:00:00.570042
elapsed time: 0:00:23.561340
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:12:14.516520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1246.21
 ---- batch: 020 ----
mean loss: 1211.38
 ---- batch: 030 ----
mean loss: 1205.58
train mean loss: 1216.15
epoch train time: 0:00:00.577678
elapsed time: 0:00:24.139370
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:12:15.094631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1172.35
 ---- batch: 020 ----
mean loss: 1171.13
 ---- batch: 030 ----
mean loss: 1159.89
train mean loss: 1170.63
epoch train time: 0:00:00.566261
elapsed time: 0:00:24.706104
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:12:15.661297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1127.12
 ---- batch: 020 ----
mean loss: 1148.71
 ---- batch: 030 ----
mean loss: 1109.75
train mean loss: 1119.17
epoch train time: 0:00:00.608000
elapsed time: 0:00:25.314455
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:12:16.269665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1100.42
 ---- batch: 020 ----
mean loss: 1076.68
 ---- batch: 030 ----
mean loss: 1062.72
train mean loss: 1073.55
epoch train time: 0:00:00.579356
elapsed time: 0:00:25.894238
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:12:16.849429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1028.10
 ---- batch: 020 ----
mean loss: 1044.26
 ---- batch: 030 ----
mean loss: 1027.94
train mean loss: 1024.65
epoch train time: 0:00:00.566133
elapsed time: 0:00:26.460721
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:12:17.415905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1011.50
 ---- batch: 020 ----
mean loss: 1003.62
 ---- batch: 030 ----
mean loss: 966.37
train mean loss: 984.10
epoch train time: 0:00:00.589371
elapsed time: 0:00:27.050500
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:12:18.005691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 957.72
 ---- batch: 020 ----
mean loss: 964.37
 ---- batch: 030 ----
mean loss: 940.82
train mean loss: 949.13
epoch train time: 0:00:00.567979
elapsed time: 0:00:27.618870
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:12:18.574049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 926.50
 ---- batch: 020 ----
mean loss: 917.73
 ---- batch: 030 ----
mean loss: 882.97
train mean loss: 907.61
epoch train time: 0:00:00.585109
elapsed time: 0:00:28.204330
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:12:19.159525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 886.72
 ---- batch: 020 ----
mean loss: 879.02
 ---- batch: 030 ----
mean loss: 850.17
train mean loss: 869.24
epoch train time: 0:00:00.577264
elapsed time: 0:00:28.781998
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:12:19.737220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 832.34
 ---- batch: 020 ----
mean loss: 856.34
 ---- batch: 030 ----
mean loss: 827.20
train mean loss: 832.65
epoch train time: 0:00:00.577467
elapsed time: 0:00:29.359842
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:12:20.315044
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 808.52
 ---- batch: 020 ----
mean loss: 796.47
 ---- batch: 030 ----
mean loss: 788.03
train mean loss: 797.20
epoch train time: 0:00:00.607048
elapsed time: 0:00:29.967252
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:12:20.922427
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 771.79
 ---- batch: 020 ----
mean loss: 751.91
 ---- batch: 030 ----
mean loss: 782.32
train mean loss: 767.01
epoch train time: 0:00:00.579623
elapsed time: 0:00:30.547236
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:12:21.502438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 749.92
 ---- batch: 020 ----
mean loss: 741.53
 ---- batch: 030 ----
mean loss: 727.12
train mean loss: 735.97
epoch train time: 0:00:00.587248
elapsed time: 0:00:31.134943
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:12:22.090119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 715.66
 ---- batch: 020 ----
mean loss: 698.46
 ---- batch: 030 ----
mean loss: 689.03
train mean loss: 704.54
epoch train time: 0:00:00.580493
elapsed time: 0:00:31.715807
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:12:22.671024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 682.93
 ---- batch: 020 ----
mean loss: 684.98
 ---- batch: 030 ----
mean loss: 661.02
train mean loss: 672.51
epoch train time: 0:00:00.577374
elapsed time: 0:00:32.293541
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:12:23.248734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 654.67
 ---- batch: 020 ----
mean loss: 649.34
 ---- batch: 030 ----
mean loss: 645.01
train mean loss: 647.37
epoch train time: 0:00:00.579196
elapsed time: 0:00:32.873190
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:12:23.828382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 627.51
 ---- batch: 020 ----
mean loss: 623.86
 ---- batch: 030 ----
mean loss: 625.20
train mean loss: 622.63
epoch train time: 0:00:00.576221
elapsed time: 0:00:33.449985
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:12:24.405196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 608.49
 ---- batch: 020 ----
mean loss: 599.41
 ---- batch: 030 ----
mean loss: 587.66
train mean loss: 596.38
epoch train time: 0:00:00.581066
elapsed time: 0:00:34.031408
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:12:24.986605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 576.86
 ---- batch: 020 ----
mean loss: 564.59
 ---- batch: 030 ----
mean loss: 565.68
train mean loss: 569.06
epoch train time: 0:00:00.563842
elapsed time: 0:00:34.595598
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:12:25.550772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 565.99
 ---- batch: 020 ----
mean loss: 546.89
 ---- batch: 030 ----
mean loss: 532.81
train mean loss: 543.83
epoch train time: 0:00:00.580945
elapsed time: 0:00:35.176873
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:12:26.132053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 534.68
 ---- batch: 020 ----
mean loss: 517.71
 ---- batch: 030 ----
mean loss: 526.92
train mean loss: 526.12
epoch train time: 0:00:00.580937
elapsed time: 0:00:35.758206
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:12:26.713385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 516.60
 ---- batch: 020 ----
mean loss: 489.85
 ---- batch: 030 ----
mean loss: 502.49
train mean loss: 502.54
epoch train time: 0:00:00.565373
elapsed time: 0:00:36.323917
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:12:27.279091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 486.68
 ---- batch: 020 ----
mean loss: 483.02
 ---- batch: 030 ----
mean loss: 490.09
train mean loss: 484.62
epoch train time: 0:00:00.565361
elapsed time: 0:00:36.889622
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:12:27.844800
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 481.38
 ---- batch: 020 ----
mean loss: 463.36
 ---- batch: 030 ----
mean loss: 441.06
train mean loss: 461.25
epoch train time: 0:00:00.584298
elapsed time: 0:00:37.474298
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:12:28.429493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 446.47
 ---- batch: 020 ----
mean loss: 452.55
 ---- batch: 030 ----
mean loss: 439.10
train mean loss: 445.65
epoch train time: 0:00:00.594063
elapsed time: 0:00:38.068744
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:12:29.023918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 436.19
 ---- batch: 020 ----
mean loss: 424.36
 ---- batch: 030 ----
mean loss: 431.92
train mean loss: 429.97
epoch train time: 0:00:00.569765
elapsed time: 0:00:38.638839
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:12:29.594013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 420.63
 ---- batch: 020 ----
mean loss: 402.32
 ---- batch: 030 ----
mean loss: 411.38
train mean loss: 412.75
epoch train time: 0:00:00.590825
elapsed time: 0:00:39.229992
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:12:30.185180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 392.73
 ---- batch: 020 ----
mean loss: 403.47
 ---- batch: 030 ----
mean loss: 391.58
train mean loss: 394.48
epoch train time: 0:00:00.570102
elapsed time: 0:00:39.800511
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:12:30.755711
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 387.50
 ---- batch: 020 ----
mean loss: 379.71
 ---- batch: 030 ----
mean loss: 380.47
train mean loss: 378.14
epoch train time: 0:00:00.591475
elapsed time: 0:00:40.392392
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:12:31.347572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 368.71
 ---- batch: 020 ----
mean loss: 360.76
 ---- batch: 030 ----
mean loss: 362.22
train mean loss: 362.09
epoch train time: 0:00:00.607247
elapsed time: 0:00:40.999997
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:12:31.955215
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.78
 ---- batch: 020 ----
mean loss: 357.71
 ---- batch: 030 ----
mean loss: 346.74
train mean loss: 352.50
epoch train time: 0:00:00.570899
elapsed time: 0:00:41.571344
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:12:32.526538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 345.21
 ---- batch: 020 ----
mean loss: 328.52
 ---- batch: 030 ----
mean loss: 340.14
train mean loss: 335.91
epoch train time: 0:00:00.584137
elapsed time: 0:00:42.155867
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:12:33.111051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 329.08
 ---- batch: 020 ----
mean loss: 324.23
 ---- batch: 030 ----
mean loss: 318.95
train mean loss: 322.59
epoch train time: 0:00:00.595712
elapsed time: 0:00:42.751954
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:12:33.707137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.39
 ---- batch: 020 ----
mean loss: 306.06
 ---- batch: 030 ----
mean loss: 308.37
train mean loss: 311.04
epoch train time: 0:00:00.573373
elapsed time: 0:00:43.325711
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:12:34.280879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 299.48
 ---- batch: 020 ----
mean loss: 302.40
 ---- batch: 030 ----
mean loss: 293.54
train mean loss: 298.72
epoch train time: 0:00:00.596417
elapsed time: 0:00:43.922478
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:12:34.877671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 295.62
 ---- batch: 020 ----
mean loss: 282.27
 ---- batch: 030 ----
mean loss: 290.53
train mean loss: 287.85
epoch train time: 0:00:00.571281
elapsed time: 0:00:44.494152
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:12:35.449328
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 283.72
 ---- batch: 020 ----
mean loss: 276.92
 ---- batch: 030 ----
mean loss: 270.76
train mean loss: 276.98
epoch train time: 0:00:00.591870
elapsed time: 0:00:45.086445
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:12:36.041684
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.42
 ---- batch: 020 ----
mean loss: 274.74
 ---- batch: 030 ----
mean loss: 262.43
train mean loss: 268.52
epoch train time: 0:00:00.585565
elapsed time: 0:00:45.672514
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:12:36.627702
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.21
 ---- batch: 020 ----
mean loss: 256.41
 ---- batch: 030 ----
mean loss: 262.02
train mean loss: 257.92
epoch train time: 0:00:00.599347
elapsed time: 0:00:46.272289
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:12:37.227508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.15
 ---- batch: 020 ----
mean loss: 246.60
 ---- batch: 030 ----
mean loss: 246.67
train mean loss: 246.92
epoch train time: 0:00:00.591794
elapsed time: 0:00:46.864501
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:12:37.819676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.15
 ---- batch: 020 ----
mean loss: 241.35
 ---- batch: 030 ----
mean loss: 234.38
train mean loss: 240.07
epoch train time: 0:00:00.582232
elapsed time: 0:00:47.447124
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:12:38.402302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.58
 ---- batch: 020 ----
mean loss: 227.98
 ---- batch: 030 ----
mean loss: 225.44
train mean loss: 228.24
epoch train time: 0:00:00.582105
elapsed time: 0:00:48.029624
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:12:38.984815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.81
 ---- batch: 020 ----
mean loss: 217.51
 ---- batch: 030 ----
mean loss: 224.94
train mean loss: 220.04
epoch train time: 0:00:00.568892
elapsed time: 0:00:48.598927
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:12:39.554110
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.71
 ---- batch: 020 ----
mean loss: 212.91
 ---- batch: 030 ----
mean loss: 208.18
train mean loss: 212.78
epoch train time: 0:00:00.590753
elapsed time: 0:00:49.190074
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:12:40.145258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.51
 ---- batch: 020 ----
mean loss: 206.73
 ---- batch: 030 ----
mean loss: 205.23
train mean loss: 204.34
epoch train time: 0:00:00.581973
elapsed time: 0:00:49.772449
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:12:40.727718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.17
 ---- batch: 020 ----
mean loss: 196.76
 ---- batch: 030 ----
mean loss: 196.28
train mean loss: 196.05
epoch train time: 0:00:00.589583
elapsed time: 0:00:50.362486
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:12:41.317703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.18
 ---- batch: 020 ----
mean loss: 190.89
 ---- batch: 030 ----
mean loss: 190.52
train mean loss: 189.53
epoch train time: 0:00:00.588061
elapsed time: 0:00:50.950964
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:12:41.906161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.91
 ---- batch: 020 ----
mean loss: 187.29
 ---- batch: 030 ----
mean loss: 182.27
train mean loss: 183.64
epoch train time: 0:00:00.587860
elapsed time: 0:00:51.539222
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:12:42.494405
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 179.79
 ---- batch: 020 ----
mean loss: 176.06
 ---- batch: 030 ----
mean loss: 179.26
train mean loss: 178.28
epoch train time: 0:00:00.585876
elapsed time: 0:00:52.125468
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:12:43.080666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 174.74
 ---- batch: 020 ----
mean loss: 171.19
 ---- batch: 030 ----
mean loss: 167.10
train mean loss: 171.76
epoch train time: 0:00:00.591854
elapsed time: 0:00:52.717707
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:12:43.672892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.36
 ---- batch: 020 ----
mean loss: 166.71
 ---- batch: 030 ----
mean loss: 166.21
train mean loss: 166.94
epoch train time: 0:00:00.595407
elapsed time: 0:00:53.313490
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:12:44.268671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 163.60
 ---- batch: 020 ----
mean loss: 165.92
 ---- batch: 030 ----
mean loss: 162.85
train mean loss: 163.03
epoch train time: 0:00:00.587816
elapsed time: 0:00:53.901718
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:12:44.856927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.43
 ---- batch: 020 ----
mean loss: 157.44
 ---- batch: 030 ----
mean loss: 153.85
train mean loss: 158.05
epoch train time: 0:00:00.589630
elapsed time: 0:00:54.491762
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:12:45.446942
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.45
 ---- batch: 020 ----
mean loss: 152.71
 ---- batch: 030 ----
mean loss: 155.25
train mean loss: 152.76
epoch train time: 0:00:00.579058
elapsed time: 0:00:55.071321
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:12:46.026578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.70
 ---- batch: 020 ----
mean loss: 149.42
 ---- batch: 030 ----
mean loss: 148.70
train mean loss: 148.99
epoch train time: 0:00:00.572929
elapsed time: 0:00:55.644670
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:12:46.599857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.93
 ---- batch: 020 ----
mean loss: 148.01
 ---- batch: 030 ----
mean loss: 146.02
train mean loss: 145.35
epoch train time: 0:00:00.577625
elapsed time: 0:00:56.222685
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:12:47.177866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.53
 ---- batch: 020 ----
mean loss: 141.23
 ---- batch: 030 ----
mean loss: 143.17
train mean loss: 142.00
epoch train time: 0:00:00.571297
elapsed time: 0:00:56.794374
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:12:47.749553
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.82
 ---- batch: 020 ----
mean loss: 135.91
 ---- batch: 030 ----
mean loss: 135.45
train mean loss: 137.62
epoch train time: 0:00:00.580210
elapsed time: 0:00:57.375027
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:12:48.330212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.02
 ---- batch: 020 ----
mean loss: 131.91
 ---- batch: 030 ----
mean loss: 135.97
train mean loss: 134.80
epoch train time: 0:00:00.594413
elapsed time: 0:00:57.969858
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:12:48.925041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.62
 ---- batch: 020 ----
mean loss: 131.72
 ---- batch: 030 ----
mean loss: 133.11
train mean loss: 131.82
epoch train time: 0:00:00.583317
elapsed time: 0:00:58.553536
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:12:49.508721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.34
 ---- batch: 020 ----
mean loss: 130.87
 ---- batch: 030 ----
mean loss: 127.44
train mean loss: 128.67
epoch train time: 0:00:00.579467
elapsed time: 0:00:59.133376
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:12:50.088559
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.23
 ---- batch: 020 ----
mean loss: 123.47
 ---- batch: 030 ----
mean loss: 125.52
train mean loss: 126.14
epoch train time: 0:00:00.576004
elapsed time: 0:00:59.709768
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:12:50.664982
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.93
 ---- batch: 020 ----
mean loss: 124.68
 ---- batch: 030 ----
mean loss: 124.90
train mean loss: 123.65
epoch train time: 0:00:00.604476
elapsed time: 0:01:00.314774
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:12:51.270023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.66
 ---- batch: 020 ----
mean loss: 123.41
 ---- batch: 030 ----
mean loss: 120.27
train mean loss: 121.06
epoch train time: 0:00:00.589712
elapsed time: 0:01:00.905020
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:12:51.860221
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.98
 ---- batch: 020 ----
mean loss: 117.83
 ---- batch: 030 ----
mean loss: 118.98
train mean loss: 119.36
epoch train time: 0:00:00.600589
elapsed time: 0:01:01.506026
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:12:52.461243
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.89
 ---- batch: 020 ----
mean loss: 119.14
 ---- batch: 030 ----
mean loss: 116.83
train mean loss: 116.86
epoch train time: 0:00:00.598320
elapsed time: 0:01:02.104804
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:12:53.059983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.71
 ---- batch: 020 ----
mean loss: 113.84
 ---- batch: 030 ----
mean loss: 110.58
train mean loss: 112.88
epoch train time: 0:00:00.583490
elapsed time: 0:01:02.688676
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:12:53.643851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.70
 ---- batch: 020 ----
mean loss: 113.48
 ---- batch: 030 ----
mean loss: 114.97
train mean loss: 112.61
epoch train time: 0:00:00.587887
elapsed time: 0:01:03.276931
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:12:54.232105
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.22
 ---- batch: 020 ----
mean loss: 109.69
 ---- batch: 030 ----
mean loss: 108.98
train mean loss: 110.18
epoch train time: 0:00:00.580856
elapsed time: 0:01:03.858186
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:12:54.813384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.82
 ---- batch: 020 ----
mean loss: 103.52
 ---- batch: 030 ----
mean loss: 108.72
train mean loss: 108.29
epoch train time: 0:00:00.583325
elapsed time: 0:01:04.441884
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:12:55.397058
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.90
 ---- batch: 020 ----
mean loss: 102.29
 ---- batch: 030 ----
mean loss: 105.83
train mean loss: 105.49
epoch train time: 0:00:00.587825
elapsed time: 0:01:05.030079
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:12:55.985257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.90
 ---- batch: 020 ----
mean loss: 104.71
 ---- batch: 030 ----
mean loss: 103.88
train mean loss: 104.57
epoch train time: 0:00:00.575039
elapsed time: 0:01:05.605454
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:12:56.560623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.60
 ---- batch: 020 ----
mean loss: 104.07
 ---- batch: 030 ----
mean loss: 102.12
train mean loss: 101.95
epoch train time: 0:00:00.567418
elapsed time: 0:01:06.173192
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:12:57.128382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.85
 ---- batch: 020 ----
mean loss: 100.59
 ---- batch: 030 ----
mean loss: 100.23
train mean loss: 100.61
epoch train time: 0:00:00.570207
elapsed time: 0:01:06.743853
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:12:57.699033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.60
 ---- batch: 020 ----
mean loss: 99.38
 ---- batch: 030 ----
mean loss: 99.86
train mean loss: 99.12
epoch train time: 0:00:00.579795
elapsed time: 0:01:07.324000
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:12:58.279177
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.22
 ---- batch: 020 ----
mean loss: 97.81
 ---- batch: 030 ----
mean loss: 99.08
train mean loss: 98.48
epoch train time: 0:00:00.598597
elapsed time: 0:01:07.922992
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:12:58.878168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.89
 ---- batch: 020 ----
mean loss: 94.02
 ---- batch: 030 ----
mean loss: 98.48
train mean loss: 96.34
epoch train time: 0:00:00.576359
elapsed time: 0:01:08.499688
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:12:59.454878
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.69
 ---- batch: 020 ----
mean loss: 95.26
 ---- batch: 030 ----
mean loss: 96.54
train mean loss: 95.29
epoch train time: 0:00:00.578809
elapsed time: 0:01:09.078866
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:13:00.034042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.05
 ---- batch: 020 ----
mean loss: 96.85
 ---- batch: 030 ----
mean loss: 95.97
train mean loss: 94.75
epoch train time: 0:00:00.581999
elapsed time: 0:01:09.661233
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:13:00.616408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.59
 ---- batch: 020 ----
mean loss: 91.82
 ---- batch: 030 ----
mean loss: 90.78
train mean loss: 91.65
epoch train time: 0:00:00.580277
elapsed time: 0:01:10.241847
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:13:01.197039
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.92
 ---- batch: 020 ----
mean loss: 91.39
 ---- batch: 030 ----
mean loss: 88.09
train mean loss: 90.31
epoch train time: 0:00:00.575423
elapsed time: 0:01:10.817618
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:13:01.772794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.62
 ---- batch: 020 ----
mean loss: 90.11
 ---- batch: 030 ----
mean loss: 86.30
train mean loss: 89.78
epoch train time: 0:00:00.566380
elapsed time: 0:01:11.384338
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:13:02.339540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.29
 ---- batch: 020 ----
mean loss: 87.81
 ---- batch: 030 ----
mean loss: 86.34
train mean loss: 87.82
epoch train time: 0:00:00.583943
elapsed time: 0:01:11.968672
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:13:02.923847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.16
 ---- batch: 020 ----
mean loss: 89.29
 ---- batch: 030 ----
mean loss: 85.49
train mean loss: 87.43
epoch train time: 0:00:00.583210
elapsed time: 0:01:12.552287
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:13:03.507494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.12
 ---- batch: 020 ----
mean loss: 87.59
 ---- batch: 030 ----
mean loss: 86.06
train mean loss: 86.23
epoch train time: 0:00:00.581194
elapsed time: 0:01:13.133934
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:13:04.089111
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.44
 ---- batch: 020 ----
mean loss: 82.98
 ---- batch: 030 ----
mean loss: 84.62
train mean loss: 85.87
epoch train time: 0:00:00.585491
elapsed time: 0:01:13.719869
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:13:04.675056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.89
 ---- batch: 020 ----
mean loss: 81.73
 ---- batch: 030 ----
mean loss: 84.88
train mean loss: 84.01
epoch train time: 0:00:00.584930
elapsed time: 0:01:14.305227
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:13:05.260410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.73
 ---- batch: 020 ----
mean loss: 84.39
 ---- batch: 030 ----
mean loss: 80.97
train mean loss: 83.65
epoch train time: 0:00:00.577660
elapsed time: 0:01:14.883418
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:13:05.838560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.11
 ---- batch: 020 ----
mean loss: 81.28
 ---- batch: 030 ----
mean loss: 82.67
train mean loss: 81.75
epoch train time: 0:00:00.576433
elapsed time: 0:01:15.460160
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:13:06.415341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.44
 ---- batch: 020 ----
mean loss: 82.31
 ---- batch: 030 ----
mean loss: 79.71
train mean loss: 81.46
epoch train time: 0:00:00.579657
elapsed time: 0:01:16.040200
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:13:06.995395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.01
 ---- batch: 020 ----
mean loss: 82.87
 ---- batch: 030 ----
mean loss: 78.88
train mean loss: 80.25
epoch train time: 0:00:00.580796
elapsed time: 0:01:16.621369
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:13:07.576550
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.77
 ---- batch: 020 ----
mean loss: 80.49
 ---- batch: 030 ----
mean loss: 81.87
train mean loss: 80.02
epoch train time: 0:00:00.582558
elapsed time: 0:01:17.204295
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:13:08.159482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.97
 ---- batch: 020 ----
mean loss: 77.38
 ---- batch: 030 ----
mean loss: 76.66
train mean loss: 78.97
epoch train time: 0:00:00.582603
elapsed time: 0:01:17.787318
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:13:08.742511
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.33
 ---- batch: 020 ----
mean loss: 78.99
 ---- batch: 030 ----
mean loss: 77.14
train mean loss: 78.16
epoch train time: 0:00:00.574033
elapsed time: 0:01:18.361712
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:13:09.316891
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.01
 ---- batch: 020 ----
mean loss: 76.05
 ---- batch: 030 ----
mean loss: 76.58
train mean loss: 76.90
epoch train time: 0:00:00.577337
elapsed time: 0:01:18.939405
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:13:09.894585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.81
 ---- batch: 020 ----
mean loss: 75.84
 ---- batch: 030 ----
mean loss: 78.47
train mean loss: 76.77
epoch train time: 0:00:00.565687
elapsed time: 0:01:19.505442
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:13:10.460644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.47
 ---- batch: 020 ----
mean loss: 76.50
 ---- batch: 030 ----
mean loss: 76.32
train mean loss: 76.12
epoch train time: 0:00:00.573512
elapsed time: 0:01:20.079348
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:13:11.034527
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.59
 ---- batch: 020 ----
mean loss: 74.70
 ---- batch: 030 ----
mean loss: 76.44
train mean loss: 74.59
epoch train time: 0:00:00.565230
elapsed time: 0:01:20.644930
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:13:11.600110
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.35
 ---- batch: 020 ----
mean loss: 73.88
 ---- batch: 030 ----
mean loss: 75.48
train mean loss: 74.08
epoch train time: 0:00:00.584616
elapsed time: 0:01:21.229915
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:13:12.185144
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.51
 ---- batch: 020 ----
mean loss: 72.54
 ---- batch: 030 ----
mean loss: 75.73
train mean loss: 73.65
epoch train time: 0:00:00.570599
elapsed time: 0:01:21.800905
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:13:12.756092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.61
 ---- batch: 020 ----
mean loss: 74.16
 ---- batch: 030 ----
mean loss: 73.91
train mean loss: 73.06
epoch train time: 0:00:00.583676
elapsed time: 0:01:22.384935
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:13:13.340133
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.46
 ---- batch: 020 ----
mean loss: 73.92
 ---- batch: 030 ----
mean loss: 70.91
train mean loss: 72.43
epoch train time: 0:00:00.579367
elapsed time: 0:01:22.964779
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:13:13.919972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.91
 ---- batch: 020 ----
mean loss: 69.05
 ---- batch: 030 ----
mean loss: 72.26
train mean loss: 70.43
epoch train time: 0:00:00.565693
elapsed time: 0:01:23.530898
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:13:14.486091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.48
 ---- batch: 020 ----
mean loss: 71.16
 ---- batch: 030 ----
mean loss: 70.55
train mean loss: 70.73
epoch train time: 0:00:00.568498
elapsed time: 0:01:24.099829
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:13:15.055011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.26
 ---- batch: 020 ----
mean loss: 68.41
 ---- batch: 030 ----
mean loss: 69.69
train mean loss: 69.71
epoch train time: 0:00:00.574293
elapsed time: 0:01:24.674458
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:13:15.629655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.34
 ---- batch: 020 ----
mean loss: 67.79
 ---- batch: 030 ----
mean loss: 69.51
train mean loss: 69.77
epoch train time: 0:00:00.568366
elapsed time: 0:01:25.243176
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:13:16.198369
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.61
 ---- batch: 020 ----
mean loss: 66.47
 ---- batch: 030 ----
mean loss: 68.11
train mean loss: 68.68
epoch train time: 0:00:00.567273
elapsed time: 0:01:25.810800
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:13:16.765980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.83
 ---- batch: 020 ----
mean loss: 67.50
 ---- batch: 030 ----
mean loss: 70.22
train mean loss: 68.60
epoch train time: 0:00:00.584036
elapsed time: 0:01:26.395273
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:13:17.350410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.69
 ---- batch: 020 ----
mean loss: 65.23
 ---- batch: 030 ----
mean loss: 67.38
train mean loss: 67.33
epoch train time: 0:00:00.589063
elapsed time: 0:01:26.984681
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:13:17.939876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.26
 ---- batch: 020 ----
mean loss: 67.04
 ---- batch: 030 ----
mean loss: 65.19
train mean loss: 66.72
epoch train time: 0:00:00.581261
elapsed time: 0:01:27.566332
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:13:18.521520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.27
 ---- batch: 020 ----
mean loss: 68.16
 ---- batch: 030 ----
mean loss: 67.68
train mean loss: 67.23
epoch train time: 0:00:00.593480
elapsed time: 0:01:28.160187
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:13:19.115365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.71
 ---- batch: 020 ----
mean loss: 65.40
 ---- batch: 030 ----
mean loss: 64.80
train mean loss: 65.79
epoch train time: 0:00:00.571315
elapsed time: 0:01:28.731853
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:13:19.687037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.71
 ---- batch: 020 ----
mean loss: 64.10
 ---- batch: 030 ----
mean loss: 66.37
train mean loss: 65.28
epoch train time: 0:00:00.598854
elapsed time: 0:01:29.331082
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:13:20.286284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.95
 ---- batch: 020 ----
mean loss: 69.53
 ---- batch: 030 ----
mean loss: 62.09
train mean loss: 65.39
epoch train time: 0:00:00.587079
elapsed time: 0:01:29.918577
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:13:20.873788
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.14
 ---- batch: 020 ----
mean loss: 63.70
 ---- batch: 030 ----
mean loss: 65.12
train mean loss: 64.11
epoch train time: 0:00:00.574370
elapsed time: 0:01:30.493355
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:13:21.448540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.38
 ---- batch: 020 ----
mean loss: 62.73
 ---- batch: 030 ----
mean loss: 63.38
train mean loss: 62.99
epoch train time: 0:00:00.584757
elapsed time: 0:01:31.078484
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:13:22.033691
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.73
 ---- batch: 020 ----
mean loss: 62.74
 ---- batch: 030 ----
mean loss: 63.85
train mean loss: 63.10
epoch train time: 0:00:00.577716
elapsed time: 0:01:31.656570
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:13:22.611752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.88
 ---- batch: 020 ----
mean loss: 61.87
 ---- batch: 030 ----
mean loss: 60.53
train mean loss: 62.65
epoch train time: 0:00:00.589034
elapsed time: 0:01:32.245937
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:13:23.201116
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.38
 ---- batch: 020 ----
mean loss: 63.61
 ---- batch: 030 ----
mean loss: 59.12
train mean loss: 61.35
epoch train time: 0:00:00.578547
elapsed time: 0:01:32.824815
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:13:23.779999
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.41
 ---- batch: 020 ----
mean loss: 64.17
 ---- batch: 030 ----
mean loss: 61.15
train mean loss: 61.78
epoch train time: 0:00:00.578965
elapsed time: 0:01:33.404183
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:13:24.359361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.48
 ---- batch: 020 ----
mean loss: 63.11
 ---- batch: 030 ----
mean loss: 60.19
train mean loss: 61.46
epoch train time: 0:00:00.583293
elapsed time: 0:01:33.987847
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:13:24.943021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.22
 ---- batch: 020 ----
mean loss: 59.14
 ---- batch: 030 ----
mean loss: 62.94
train mean loss: 60.75
epoch train time: 0:00:00.583366
elapsed time: 0:01:34.571552
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:13:25.526757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.63
 ---- batch: 020 ----
mean loss: 60.16
 ---- batch: 030 ----
mean loss: 60.71
train mean loss: 59.94
epoch train time: 0:00:00.575474
elapsed time: 0:01:35.147460
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:13:26.102662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.25
 ---- batch: 020 ----
mean loss: 59.55
 ---- batch: 030 ----
mean loss: 62.19
train mean loss: 59.58
epoch train time: 0:00:00.575923
elapsed time: 0:01:35.723774
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:13:26.678986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.95
 ---- batch: 020 ----
mean loss: 59.12
 ---- batch: 030 ----
mean loss: 60.01
train mean loss: 59.25
epoch train time: 0:00:00.585994
elapsed time: 0:01:36.310175
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:13:27.265368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.77
 ---- batch: 020 ----
mean loss: 58.08
 ---- batch: 030 ----
mean loss: 57.03
train mean loss: 58.32
epoch train time: 0:00:00.567144
elapsed time: 0:01:36.877674
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:13:27.832888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.05
 ---- batch: 020 ----
mean loss: 58.56
 ---- batch: 030 ----
mean loss: 56.63
train mean loss: 58.62
epoch train time: 0:00:00.563940
elapsed time: 0:01:37.441992
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:13:28.397180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.06
 ---- batch: 020 ----
mean loss: 59.22
 ---- batch: 030 ----
mean loss: 56.15
train mean loss: 57.67
epoch train time: 0:00:00.582730
elapsed time: 0:01:38.025062
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:13:28.980231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.47
 ---- batch: 020 ----
mean loss: 57.45
 ---- batch: 030 ----
mean loss: 59.13
train mean loss: 57.56
epoch train time: 0:00:00.584439
elapsed time: 0:01:38.609893
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:13:29.565081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.15
 ---- batch: 020 ----
mean loss: 57.45
 ---- batch: 030 ----
mean loss: 56.73
train mean loss: 57.46
epoch train time: 0:00:00.579976
elapsed time: 0:01:39.190290
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:13:30.145409
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.04
 ---- batch: 020 ----
mean loss: 56.74
 ---- batch: 030 ----
mean loss: 55.42
train mean loss: 56.78
epoch train time: 0:00:00.582889
elapsed time: 0:01:39.773527
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:13:30.728721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.54
 ---- batch: 020 ----
mean loss: 55.53
 ---- batch: 030 ----
mean loss: 54.12
train mean loss: 55.34
epoch train time: 0:00:00.595105
elapsed time: 0:01:40.368995
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:13:31.324166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.39
 ---- batch: 020 ----
mean loss: 54.88
 ---- batch: 030 ----
mean loss: 58.75
train mean loss: 55.50
epoch train time: 0:00:00.594298
elapsed time: 0:01:40.963744
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:13:31.918953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.54
 ---- batch: 020 ----
mean loss: 55.96
 ---- batch: 030 ----
mean loss: 52.50
train mean loss: 54.67
epoch train time: 0:00:00.565693
elapsed time: 0:01:41.529794
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:13:32.484963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.11
 ---- batch: 020 ----
mean loss: 54.36
 ---- batch: 030 ----
mean loss: 55.39
train mean loss: 53.86
epoch train time: 0:00:00.581198
elapsed time: 0:01:42.111312
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:13:33.066491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.72
 ---- batch: 020 ----
mean loss: 54.54
 ---- batch: 030 ----
mean loss: 53.36
train mean loss: 53.82
epoch train time: 0:00:00.580901
elapsed time: 0:01:42.692559
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:13:33.647739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.56
 ---- batch: 020 ----
mean loss: 53.64
 ---- batch: 030 ----
mean loss: 56.64
train mean loss: 53.31
epoch train time: 0:00:00.582117
elapsed time: 0:01:43.275016
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:13:34.230245
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.99
 ---- batch: 020 ----
mean loss: 51.26
 ---- batch: 030 ----
mean loss: 52.32
train mean loss: 52.50
epoch train time: 0:00:00.575804
elapsed time: 0:01:43.851229
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:13:34.806411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.19
 ---- batch: 020 ----
mean loss: 53.07
 ---- batch: 030 ----
mean loss: 51.73
train mean loss: 52.19
epoch train time: 0:00:00.577570
elapsed time: 0:01:44.429158
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:13:35.384336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.79
 ---- batch: 020 ----
mean loss: 53.96
 ---- batch: 030 ----
mean loss: 50.28
train mean loss: 51.60
epoch train time: 0:00:00.584655
elapsed time: 0:01:45.014164
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:13:35.969384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.70
 ---- batch: 020 ----
mean loss: 49.74
 ---- batch: 030 ----
mean loss: 49.38
train mean loss: 51.66
epoch train time: 0:00:00.577146
elapsed time: 0:01:45.591693
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:13:36.546879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.78
 ---- batch: 020 ----
mean loss: 49.83
 ---- batch: 030 ----
mean loss: 53.77
train mean loss: 51.74
epoch train time: 0:00:00.576532
elapsed time: 0:01:46.168597
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:13:37.123792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.94
 ---- batch: 020 ----
mean loss: 49.76
 ---- batch: 030 ----
mean loss: 48.57
train mean loss: 50.07
epoch train time: 0:00:00.572969
elapsed time: 0:01:46.741955
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:13:37.697134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.05
 ---- batch: 020 ----
mean loss: 50.53
 ---- batch: 030 ----
mean loss: 49.64
train mean loss: 49.64
epoch train time: 0:00:00.584006
elapsed time: 0:01:47.326312
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:13:38.281491
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.75
 ---- batch: 020 ----
mean loss: 49.07
 ---- batch: 030 ----
mean loss: 47.79
train mean loss: 48.97
epoch train time: 0:00:00.603863
elapsed time: 0:01:47.930508
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:13:38.885699
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.83
 ---- batch: 020 ----
mean loss: 47.85
 ---- batch: 030 ----
mean loss: 50.17
train mean loss: 49.22
epoch train time: 0:00:00.565063
elapsed time: 0:01:48.495915
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:13:39.451082
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.71
 ---- batch: 020 ----
mean loss: 47.05
 ---- batch: 030 ----
mean loss: 50.36
train mean loss: 48.52
epoch train time: 0:00:00.585759
elapsed time: 0:01:49.082052
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:13:40.037230
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.60
 ---- batch: 020 ----
mean loss: 46.26
 ---- batch: 030 ----
mean loss: 46.12
train mean loss: 47.74
epoch train time: 0:00:00.587319
elapsed time: 0:01:49.669809
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:13:40.624998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.40
 ---- batch: 020 ----
mean loss: 48.44
 ---- batch: 030 ----
mean loss: 49.29
train mean loss: 49.01
epoch train time: 0:00:00.585597
elapsed time: 0:01:50.255752
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:13:41.210959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.53
 ---- batch: 020 ----
mean loss: 46.68
 ---- batch: 030 ----
mean loss: 46.53
train mean loss: 47.14
epoch train time: 0:00:00.607983
elapsed time: 0:01:50.864163
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:13:41.819352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.44
 ---- batch: 020 ----
mean loss: 48.48
 ---- batch: 030 ----
mean loss: 46.85
train mean loss: 46.42
epoch train time: 0:00:00.586944
elapsed time: 0:01:51.451473
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:13:42.406668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.19
 ---- batch: 020 ----
mean loss: 46.05
 ---- batch: 030 ----
mean loss: 47.03
train mean loss: 46.50
epoch train time: 0:00:00.579655
elapsed time: 0:01:52.031535
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:13:42.986710
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.58
 ---- batch: 020 ----
mean loss: 48.01
 ---- batch: 030 ----
mean loss: 45.71
train mean loss: 47.96
epoch train time: 0:00:00.572109
elapsed time: 0:01:52.604027
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:13:43.559238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.82
 ---- batch: 020 ----
mean loss: 45.76
 ---- batch: 030 ----
mean loss: 45.98
train mean loss: 46.38
epoch train time: 0:00:00.591813
elapsed time: 0:01:53.196256
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:13:44.151435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.65
 ---- batch: 020 ----
mean loss: 46.38
 ---- batch: 030 ----
mean loss: 46.16
train mean loss: 45.68
epoch train time: 0:00:00.583411
elapsed time: 0:01:53.780104
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:13:44.735222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.26
 ---- batch: 020 ----
mean loss: 45.89
 ---- batch: 030 ----
mean loss: 45.84
train mean loss: 44.76
epoch train time: 0:00:00.583783
elapsed time: 0:01:54.364183
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:13:45.319361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.55
 ---- batch: 020 ----
mean loss: 44.02
 ---- batch: 030 ----
mean loss: 44.76
train mean loss: 44.21
epoch train time: 0:00:00.589099
elapsed time: 0:01:54.953681
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:13:45.908868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.53
 ---- batch: 020 ----
mean loss: 43.39
 ---- batch: 030 ----
mean loss: 43.76
train mean loss: 43.98
epoch train time: 0:00:00.578759
elapsed time: 0:01:55.532800
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:13:46.487991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.85
 ---- batch: 020 ----
mean loss: 44.25
 ---- batch: 030 ----
mean loss: 45.77
train mean loss: 44.05
epoch train time: 0:00:00.587478
elapsed time: 0:01:56.120644
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:13:47.075820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.72
 ---- batch: 020 ----
mean loss: 42.14
 ---- batch: 030 ----
mean loss: 44.07
train mean loss: 43.36
epoch train time: 0:00:00.578200
elapsed time: 0:01:56.699230
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:13:47.654416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.64
 ---- batch: 020 ----
mean loss: 41.82
 ---- batch: 030 ----
mean loss: 44.88
train mean loss: 43.34
epoch train time: 0:00:00.596330
elapsed time: 0:01:57.295946
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:13:48.251118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.52
 ---- batch: 020 ----
mean loss: 42.29
 ---- batch: 030 ----
mean loss: 42.31
train mean loss: 42.21
epoch train time: 0:00:00.593132
elapsed time: 0:01:57.889455
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:13:48.844627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.39
 ---- batch: 020 ----
mean loss: 44.32
 ---- batch: 030 ----
mean loss: 44.20
train mean loss: 43.67
epoch train time: 0:00:00.574219
elapsed time: 0:01:58.464046
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:13:49.419218
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.11
 ---- batch: 020 ----
mean loss: 44.21
 ---- batch: 030 ----
mean loss: 41.84
train mean loss: 41.47
epoch train time: 0:00:00.574807
elapsed time: 0:01:59.039203
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:13:49.994386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.76
 ---- batch: 020 ----
mean loss: 41.56
 ---- batch: 030 ----
mean loss: 43.78
train mean loss: 41.20
epoch train time: 0:00:00.578144
elapsed time: 0:01:59.617733
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:13:50.572940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.72
 ---- batch: 020 ----
mean loss: 41.67
 ---- batch: 030 ----
mean loss: 39.67
train mean loss: 40.54
epoch train time: 0:00:00.588521
elapsed time: 0:02:00.206697
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:13:51.161950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.24
 ---- batch: 020 ----
mean loss: 40.42
 ---- batch: 030 ----
mean loss: 40.59
train mean loss: 40.44
epoch train time: 0:00:00.583154
elapsed time: 0:02:00.790387
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:13:51.745584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.85
 ---- batch: 020 ----
mean loss: 40.06
 ---- batch: 030 ----
mean loss: 39.24
train mean loss: 39.93
epoch train time: 0:00:00.592523
elapsed time: 0:02:01.383322
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:13:52.338505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.39
 ---- batch: 020 ----
mean loss: 39.35
 ---- batch: 030 ----
mean loss: 44.21
train mean loss: 40.78
epoch train time: 0:00:00.603347
elapsed time: 0:02:01.987100
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:13:52.942297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.64
 ---- batch: 020 ----
mean loss: 39.13
 ---- batch: 030 ----
mean loss: 38.97
train mean loss: 39.20
epoch train time: 0:00:00.592043
elapsed time: 0:02:02.579561
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:13:53.534749
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.64
 ---- batch: 020 ----
mean loss: 38.05
 ---- batch: 030 ----
mean loss: 38.63
train mean loss: 38.54
epoch train time: 0:00:00.584423
elapsed time: 0:02:03.164358
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:13:54.119533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.66
 ---- batch: 020 ----
mean loss: 37.41
 ---- batch: 030 ----
mean loss: 39.17
train mean loss: 39.14
epoch train time: 0:00:00.576757
elapsed time: 0:02:03.741498
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:13:54.696673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.20
 ---- batch: 020 ----
mean loss: 37.88
 ---- batch: 030 ----
mean loss: 39.41
train mean loss: 38.82
epoch train time: 0:00:00.592368
elapsed time: 0:02:04.334256
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:13:55.289515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.59
 ---- batch: 020 ----
mean loss: 35.27
 ---- batch: 030 ----
mean loss: 40.73
train mean loss: 38.14
epoch train time: 0:00:00.597437
elapsed time: 0:02:04.932140
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:13:55.887325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.85
 ---- batch: 020 ----
mean loss: 39.18
 ---- batch: 030 ----
mean loss: 39.17
train mean loss: 38.34
epoch train time: 0:00:00.575222
elapsed time: 0:02:05.507753
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:13:56.462941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.18
 ---- batch: 020 ----
mean loss: 36.54
 ---- batch: 030 ----
mean loss: 36.84
train mean loss: 37.45
epoch train time: 0:00:00.580851
elapsed time: 0:02:06.089019
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:13:57.044251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.70
 ---- batch: 020 ----
mean loss: 38.19
 ---- batch: 030 ----
mean loss: 36.15
train mean loss: 37.17
epoch train time: 0:00:00.597315
elapsed time: 0:02:06.686973
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:13:57.642185
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.92
 ---- batch: 020 ----
mean loss: 38.33
 ---- batch: 030 ----
mean loss: 35.91
train mean loss: 36.57
epoch train time: 0:00:00.595125
elapsed time: 0:02:07.282468
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:13:58.237703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.19
 ---- batch: 020 ----
mean loss: 36.98
 ---- batch: 030 ----
mean loss: 36.74
train mean loss: 36.61
epoch train time: 0:00:00.592891
elapsed time: 0:02:07.875820
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:13:58.831031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 34.76
 ---- batch: 020 ----
mean loss: 37.53
 ---- batch: 030 ----
mean loss: 35.55
train mean loss: 35.92
epoch train time: 0:00:00.580298
elapsed time: 0:02:08.456559
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:13:59.411751
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 36.63
 ---- batch: 020 ----
mean loss: 34.18
 ---- batch: 030 ----
mean loss: 37.64
train mean loss: 36.05
epoch train time: 0:00:00.608818
elapsed time: 0:02:09.065754
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:14:00.020929
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 37.25
 ---- batch: 020 ----
mean loss: 34.16
 ---- batch: 030 ----
mean loss: 36.08
train mean loss: 35.56
epoch train time: 0:00:00.568045
elapsed time: 0:02:09.634308
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:14:00.589487
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.56
 ---- batch: 020 ----
mean loss: 35.75
 ---- batch: 030 ----
mean loss: 36.41
train mean loss: 35.18
epoch train time: 0:00:00.586649
elapsed time: 0:02:10.221405
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:14:01.176532
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.22
 ---- batch: 020 ----
mean loss: 35.68
 ---- batch: 030 ----
mean loss: 33.42
train mean loss: 34.62
epoch train time: 0:00:00.571035
elapsed time: 0:02:10.792721
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:14:01.747889
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.15
 ---- batch: 020 ----
mean loss: 32.42
 ---- batch: 030 ----
mean loss: 34.54
train mean loss: 34.02
epoch train time: 0:00:00.570017
elapsed time: 0:02:11.363109
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:14:02.318282
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.49
 ---- batch: 020 ----
mean loss: 33.72
 ---- batch: 030 ----
mean loss: 35.78
train mean loss: 34.45
epoch train time: 0:00:00.574344
elapsed time: 0:02:11.937802
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:14:02.892982
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.44
 ---- batch: 020 ----
mean loss: 34.67
 ---- batch: 030 ----
mean loss: 33.11
train mean loss: 34.42
epoch train time: 0:00:00.582790
elapsed time: 0:02:12.520979
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:14:03.476188
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.84
 ---- batch: 020 ----
mean loss: 34.89
 ---- batch: 030 ----
mean loss: 34.39
train mean loss: 34.32
epoch train time: 0:00:00.599017
elapsed time: 0:02:13.120497
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:14:04.075675
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.52
 ---- batch: 020 ----
mean loss: 34.06
 ---- batch: 030 ----
mean loss: 33.11
train mean loss: 33.84
epoch train time: 0:00:00.588006
elapsed time: 0:02:13.709017
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:14:04.664196
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.74
 ---- batch: 020 ----
mean loss: 33.99
 ---- batch: 030 ----
mean loss: 33.98
train mean loss: 34.18
epoch train time: 0:00:00.598386
elapsed time: 0:02:14.307850
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:14:05.263031
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.02
 ---- batch: 020 ----
mean loss: 33.65
 ---- batch: 030 ----
mean loss: 33.24
train mean loss: 34.03
epoch train time: 0:00:00.590129
elapsed time: 0:02:14.898349
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:14:05.853528
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.76
 ---- batch: 020 ----
mean loss: 34.36
 ---- batch: 030 ----
mean loss: 34.88
train mean loss: 34.35
epoch train time: 0:00:00.583656
elapsed time: 0:02:15.482379
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:14:06.437586
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.81
 ---- batch: 020 ----
mean loss: 34.41
 ---- batch: 030 ----
mean loss: 32.76
train mean loss: 34.20
epoch train time: 0:00:00.593284
elapsed time: 0:02:16.076052
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:14:07.031230
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.75
 ---- batch: 020 ----
mean loss: 34.90
 ---- batch: 030 ----
mean loss: 34.71
train mean loss: 33.85
epoch train time: 0:00:00.583397
elapsed time: 0:02:16.659868
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:14:07.615041
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.98
 ---- batch: 020 ----
mean loss: 32.30
 ---- batch: 030 ----
mean loss: 34.35
train mean loss: 34.19
epoch train time: 0:00:00.581492
elapsed time: 0:02:17.241761
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:14:08.196943
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.12
 ---- batch: 020 ----
mean loss: 34.90
 ---- batch: 030 ----
mean loss: 32.82
train mean loss: 34.08
epoch train time: 0:00:00.575864
elapsed time: 0:02:17.818014
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:14:08.773202
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.31
 ---- batch: 020 ----
mean loss: 33.26
 ---- batch: 030 ----
mean loss: 35.40
train mean loss: 33.96
epoch train time: 0:00:00.573165
elapsed time: 0:02:18.391570
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:14:09.346744
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.50
 ---- batch: 020 ----
mean loss: 33.68
 ---- batch: 030 ----
mean loss: 33.09
train mean loss: 33.83
epoch train time: 0:00:00.588802
elapsed time: 0:02:18.980698
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:14:09.935870
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.75
 ---- batch: 020 ----
mean loss: 33.02
 ---- batch: 030 ----
mean loss: 36.04
train mean loss: 33.88
epoch train time: 0:00:00.579282
elapsed time: 0:02:19.560322
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:14:10.515499
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.23
 ---- batch: 020 ----
mean loss: 34.39
 ---- batch: 030 ----
mean loss: 31.94
train mean loss: 33.78
epoch train time: 0:00:00.575459
elapsed time: 0:02:20.136152
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:14:11.091345
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.62
 ---- batch: 020 ----
mean loss: 34.53
 ---- batch: 030 ----
mean loss: 33.14
train mean loss: 33.87
epoch train time: 0:00:00.573019
elapsed time: 0:02:20.709528
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:14:11.664704
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.97
 ---- batch: 020 ----
mean loss: 33.37
 ---- batch: 030 ----
mean loss: 35.22
train mean loss: 33.65
epoch train time: 0:00:00.583049
elapsed time: 0:02:21.292978
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:14:12.248151
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.02
 ---- batch: 020 ----
mean loss: 33.21
 ---- batch: 030 ----
mean loss: 34.49
train mean loss: 33.62
epoch train time: 0:00:00.600966
elapsed time: 0:02:21.894354
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:14:12.849547
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.55
 ---- batch: 020 ----
mean loss: 34.60
 ---- batch: 030 ----
mean loss: 34.59
train mean loss: 33.94
epoch train time: 0:00:00.587370
elapsed time: 0:02:22.482095
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:14:13.437281
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.92
 ---- batch: 020 ----
mean loss: 32.35
 ---- batch: 030 ----
mean loss: 35.08
train mean loss: 33.45
epoch train time: 0:00:00.583063
elapsed time: 0:02:23.065578
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:14:14.020752
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.36
 ---- batch: 020 ----
mean loss: 32.73
 ---- batch: 030 ----
mean loss: 34.75
train mean loss: 33.62
epoch train time: 0:00:00.592109
elapsed time: 0:02:23.658026
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:14:14.613243
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.58
 ---- batch: 020 ----
mean loss: 32.55
 ---- batch: 030 ----
mean loss: 34.62
train mean loss: 33.61
epoch train time: 0:00:00.595240
elapsed time: 0:02:24.253738
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:14:15.208965
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.33
 ---- batch: 020 ----
mean loss: 32.64
 ---- batch: 030 ----
mean loss: 32.41
train mean loss: 33.63
epoch train time: 0:00:00.587588
elapsed time: 0:02:24.841732
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:14:15.796927
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.14
 ---- batch: 020 ----
mean loss: 32.83
 ---- batch: 030 ----
mean loss: 33.66
train mean loss: 33.22
epoch train time: 0:00:00.604880
elapsed time: 0:02:25.446982
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:14:16.402161
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.98
 ---- batch: 020 ----
mean loss: 33.28
 ---- batch: 030 ----
mean loss: 32.76
train mean loss: 33.46
epoch train time: 0:00:00.585951
elapsed time: 0:02:26.033265
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:14:16.988513
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.72
 ---- batch: 020 ----
mean loss: 32.90
 ---- batch: 030 ----
mean loss: 33.45
train mean loss: 33.22
epoch train time: 0:00:00.571505
elapsed time: 0:02:26.605193
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:14:17.560370
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.09
 ---- batch: 020 ----
mean loss: 34.92
 ---- batch: 030 ----
mean loss: 33.90
train mean loss: 33.93
epoch train time: 0:00:00.599979
elapsed time: 0:02:27.205549
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:14:18.160736
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.22
 ---- batch: 020 ----
mean loss: 33.00
 ---- batch: 030 ----
mean loss: 33.16
train mean loss: 33.23
epoch train time: 0:00:00.593694
elapsed time: 0:02:27.799633
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:14:18.754807
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.69
 ---- batch: 020 ----
mean loss: 33.83
 ---- batch: 030 ----
mean loss: 33.88
train mean loss: 33.59
epoch train time: 0:00:00.593018
elapsed time: 0:02:28.393041
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:14:19.348240
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.60
 ---- batch: 020 ----
mean loss: 32.68
 ---- batch: 030 ----
mean loss: 34.18
train mean loss: 33.28
epoch train time: 0:00:00.599602
elapsed time: 0:02:28.993141
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:14:19.948274
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.84
 ---- batch: 020 ----
mean loss: 33.83
 ---- batch: 030 ----
mean loss: 31.86
train mean loss: 33.16
epoch train time: 0:00:00.611972
elapsed time: 0:02:29.605544
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:14:20.560724
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.34
 ---- batch: 020 ----
mean loss: 32.71
 ---- batch: 030 ----
mean loss: 31.71
train mean loss: 32.71
epoch train time: 0:00:00.618737
elapsed time: 0:02:30.225161
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:14:21.180352
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.84
 ---- batch: 020 ----
mean loss: 32.62
 ---- batch: 030 ----
mean loss: 34.02
train mean loss: 33.29
epoch train time: 0:00:00.602436
elapsed time: 0:02:30.828003
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:14:21.783181
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.17
 ---- batch: 020 ----
mean loss: 32.42
 ---- batch: 030 ----
mean loss: 32.82
train mean loss: 32.85
epoch train time: 0:00:00.580189
elapsed time: 0:02:31.408555
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:14:22.363745
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.12
 ---- batch: 020 ----
mean loss: 32.90
 ---- batch: 030 ----
mean loss: 32.47
train mean loss: 33.02
epoch train time: 0:00:00.579671
elapsed time: 0:02:31.988610
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:14:22.943807
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.58
 ---- batch: 020 ----
mean loss: 32.94
 ---- batch: 030 ----
mean loss: 32.34
train mean loss: 33.02
epoch train time: 0:00:00.568087
elapsed time: 0:02:32.557128
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:14:23.512335
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.33
 ---- batch: 020 ----
mean loss: 34.18
 ---- batch: 030 ----
mean loss: 30.50
train mean loss: 33.06
epoch train time: 0:00:00.603510
elapsed time: 0:02:33.161023
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:14:24.116203
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 31.10
 ---- batch: 020 ----
mean loss: 32.27
 ---- batch: 030 ----
mean loss: 34.30
train mean loss: 33.18
epoch train time: 0:00:00.576753
elapsed time: 0:02:33.738121
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:14:24.693317
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.93
 ---- batch: 020 ----
mean loss: 32.83
 ---- batch: 030 ----
mean loss: 32.44
train mean loss: 32.94
epoch train time: 0:00:00.576930
elapsed time: 0:02:34.315419
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:14:25.270596
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.75
 ---- batch: 020 ----
mean loss: 33.97
 ---- batch: 030 ----
mean loss: 31.92
train mean loss: 32.81
epoch train time: 0:00:00.579812
elapsed time: 0:02:34.895587
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:14:25.850769
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.09
 ---- batch: 020 ----
mean loss: 33.68
 ---- batch: 030 ----
mean loss: 33.09
train mean loss: 32.89
epoch train time: 0:00:00.584352
elapsed time: 0:02:35.480291
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:14:26.435464
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.49
 ---- batch: 020 ----
mean loss: 32.42
 ---- batch: 030 ----
mean loss: 32.77
train mean loss: 32.48
epoch train time: 0:00:00.568903
elapsed time: 0:02:36.049529
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:14:27.004705
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.61
 ---- batch: 020 ----
mean loss: 31.71
 ---- batch: 030 ----
mean loss: 33.25
train mean loss: 32.95
epoch train time: 0:00:00.562519
elapsed time: 0:02:36.612487
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:14:27.567701
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.06
 ---- batch: 020 ----
mean loss: 31.02
 ---- batch: 030 ----
mean loss: 32.57
train mean loss: 32.64
epoch train time: 0:00:00.573650
elapsed time: 0:02:37.186496
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:14:28.141701
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 33.74
 ---- batch: 020 ----
mean loss: 31.62
 ---- batch: 030 ----
mean loss: 31.52
train mean loss: 32.55
epoch train time: 0:00:00.564008
elapsed time: 0:02:37.750913
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:14:28.706097
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 32.39
 ---- batch: 020 ----
mean loss: 32.78
 ---- batch: 030 ----
mean loss: 32.90
train mean loss: 32.44
epoch train time: 0:00:00.577875
elapsed time: 0:02:38.336730
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_2/checkpoint.pth.tar
**** end time: 2019-09-27 15:14:29.291821 ****
