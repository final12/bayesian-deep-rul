Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_5', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 22838
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-27 08:08:18.321940 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 31, 14]             200
           Sigmoid-2           [-1, 10, 31, 14]               0
    BayesianConv2d-3           [-1, 10, 30, 14]           2,000
           Sigmoid-4           [-1, 10, 30, 14]               0
    BayesianConv2d-5           [-1, 10, 31, 14]           2,000
           Sigmoid-6           [-1, 10, 31, 14]               0
    BayesianConv2d-7           [-1, 10, 30, 14]           2,000
           Sigmoid-8           [-1, 10, 30, 14]               0
    BayesianConv2d-9            [-1, 1, 30, 14]              60
         Softplus-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
   BayesianLinear-12                  [-1, 100]          84,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 90,460
Trainable params: 90,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 08:08:18.339633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2583.10
 ---- batch: 020 ----
mean loss: 1337.01
 ---- batch: 030 ----
mean loss: 1206.50
train mean loss: 1637.33
epoch train time: 0:00:17.439639
elapsed time: 0:00:17.466200
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 08:08:35.788204
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1128.73
 ---- batch: 020 ----
mean loss: 1072.82
 ---- batch: 030 ----
mean loss: 1088.11
train mean loss: 1091.12
epoch train time: 0:00:07.166200
elapsed time: 0:00:24.633137
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 08:08:42.955280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1041.16
 ---- batch: 020 ----
mean loss: 1052.66
 ---- batch: 030 ----
mean loss: 1040.65
train mean loss: 1042.48
epoch train time: 0:00:07.061124
elapsed time: 0:00:31.695154
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 08:08:50.017268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1050.09
 ---- batch: 020 ----
mean loss: 1008.67
 ---- batch: 030 ----
mean loss: 988.05
train mean loss: 1010.88
epoch train time: 0:00:07.144895
elapsed time: 0:00:38.840844
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 08:08:57.162953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 999.93
 ---- batch: 020 ----
mean loss: 991.41
 ---- batch: 030 ----
mean loss: 988.37
train mean loss: 995.10
epoch train time: 0:00:06.979141
elapsed time: 0:00:45.820853
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 08:09:04.142950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 970.33
 ---- batch: 020 ----
mean loss: 1012.44
 ---- batch: 030 ----
mean loss: 961.42
train mean loss: 982.78
epoch train time: 0:00:06.978472
elapsed time: 0:00:52.800191
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 08:09:11.122276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 978.04
 ---- batch: 020 ----
mean loss: 948.60
 ---- batch: 030 ----
mean loss: 960.19
train mean loss: 958.31
epoch train time: 0:00:07.002564
elapsed time: 0:00:59.803521
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 08:09:18.125644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 923.12
 ---- batch: 020 ----
mean loss: 883.79
 ---- batch: 030 ----
mean loss: 814.82
train mean loss: 860.73
epoch train time: 0:00:07.174944
elapsed time: 0:01:06.979220
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 08:09:25.301312
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 741.27
 ---- batch: 020 ----
mean loss: 678.23
 ---- batch: 030 ----
mean loss: 621.99
train mean loss: 666.25
epoch train time: 0:00:06.965339
elapsed time: 0:01:13.945462
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 08:09:32.267573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 538.91
 ---- batch: 020 ----
mean loss: 485.03
 ---- batch: 030 ----
mean loss: 444.83
train mean loss: 480.28
epoch train time: 0:00:07.148513
elapsed time: 0:01:21.094847
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 08:09:39.416951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 431.24
 ---- batch: 020 ----
mean loss: 425.71
 ---- batch: 030 ----
mean loss: 406.89
train mean loss: 419.53
epoch train time: 0:00:06.998697
elapsed time: 0:01:28.094341
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 08:09:46.416451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 393.61
 ---- batch: 020 ----
mean loss: 394.37
 ---- batch: 030 ----
mean loss: 389.44
train mean loss: 392.67
epoch train time: 0:00:07.071706
elapsed time: 0:01:35.166899
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 08:09:53.489004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 393.09
 ---- batch: 020 ----
mean loss: 390.61
 ---- batch: 030 ----
mean loss: 377.52
train mean loss: 386.31
epoch train time: 0:00:07.019221
elapsed time: 0:01:42.186881
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 08:10:00.508965
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 379.65
 ---- batch: 020 ----
mean loss: 374.78
 ---- batch: 030 ----
mean loss: 367.02
train mean loss: 372.20
epoch train time: 0:00:07.070238
elapsed time: 0:01:49.257885
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 08:10:07.579983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 369.52
 ---- batch: 020 ----
mean loss: 363.03
 ---- batch: 030 ----
mean loss: 353.76
train mean loss: 364.13
epoch train time: 0:00:07.086803
elapsed time: 0:01:56.345504
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 08:10:14.667606
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.22
 ---- batch: 020 ----
mean loss: 362.57
 ---- batch: 030 ----
mean loss: 352.38
train mean loss: 360.30
epoch train time: 0:00:07.001358
elapsed time: 0:02:03.347816
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 08:10:21.669940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 345.84
 ---- batch: 020 ----
mean loss: 348.84
 ---- batch: 030 ----
mean loss: 355.89
train mean loss: 348.69
epoch train time: 0:00:07.095901
elapsed time: 0:02:10.444503
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 08:10:28.766622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 352.67
 ---- batch: 020 ----
mean loss: 347.43
 ---- batch: 030 ----
mean loss: 331.18
train mean loss: 342.15
epoch train time: 0:00:06.939884
elapsed time: 0:02:17.385191
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 08:10:35.707342
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 338.05
 ---- batch: 020 ----
mean loss: 342.43
 ---- batch: 030 ----
mean loss: 330.57
train mean loss: 337.92
epoch train time: 0:00:07.080210
elapsed time: 0:02:24.466299
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 08:10:42.788398
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 333.06
 ---- batch: 020 ----
mean loss: 326.45
 ---- batch: 030 ----
mean loss: 319.00
train mean loss: 325.91
epoch train time: 0:00:06.939422
elapsed time: 0:02:31.406504
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 08:10:49.728602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 314.97
 ---- batch: 020 ----
mean loss: 324.13
 ---- batch: 030 ----
mean loss: 312.07
train mean loss: 316.36
epoch train time: 0:00:07.084552
elapsed time: 0:02:38.492066
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 08:10:56.814191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.48
 ---- batch: 020 ----
mean loss: 317.05
 ---- batch: 030 ----
mean loss: 308.45
train mean loss: 310.39
epoch train time: 0:00:06.983326
elapsed time: 0:02:45.476248
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 08:11:03.798352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.18
 ---- batch: 020 ----
mean loss: 301.70
 ---- batch: 030 ----
mean loss: 299.70
train mean loss: 303.03
epoch train time: 0:00:07.091413
elapsed time: 0:02:52.568503
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 08:11:10.890615
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 294.80
 ---- batch: 020 ----
mean loss: 304.28
 ---- batch: 030 ----
mean loss: 297.06
train mean loss: 299.34
epoch train time: 0:00:07.077391
elapsed time: 0:02:59.646669
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 08:11:17.968779
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.40
 ---- batch: 020 ----
mean loss: 291.27
 ---- batch: 030 ----
mean loss: 298.68
train mean loss: 292.12
epoch train time: 0:00:06.959042
elapsed time: 0:03:06.606703
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 08:11:24.928801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.67
 ---- batch: 020 ----
mean loss: 283.11
 ---- batch: 030 ----
mean loss: 286.64
train mean loss: 281.52
epoch train time: 0:00:07.087704
elapsed time: 0:03:13.695168
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 08:11:32.017263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 272.26
 ---- batch: 020 ----
mean loss: 273.35
 ---- batch: 030 ----
mean loss: 269.36
train mean loss: 270.61
epoch train time: 0:00:06.983331
elapsed time: 0:03:20.679287
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 08:11:39.001387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.39
 ---- batch: 020 ----
mean loss: 267.95
 ---- batch: 030 ----
mean loss: 262.10
train mean loss: 264.50
epoch train time: 0:00:07.111963
elapsed time: 0:03:27.792135
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 08:11:46.114300
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.74
 ---- batch: 020 ----
mean loss: 251.66
 ---- batch: 030 ----
mean loss: 250.72
train mean loss: 254.10
epoch train time: 0:00:06.987586
elapsed time: 0:03:34.780587
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 08:11:53.102697
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.70
 ---- batch: 020 ----
mean loss: 243.25
 ---- batch: 030 ----
mean loss: 242.64
train mean loss: 246.01
epoch train time: 0:00:07.062137
elapsed time: 0:03:41.843561
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 08:12:00.165685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.85
 ---- batch: 020 ----
mean loss: 246.58
 ---- batch: 030 ----
mean loss: 240.46
train mean loss: 241.70
epoch train time: 0:00:06.882643
elapsed time: 0:03:48.727002
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 08:12:07.049115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.85
 ---- batch: 020 ----
mean loss: 229.74
 ---- batch: 030 ----
mean loss: 236.19
train mean loss: 232.77
epoch train time: 0:00:06.752917
elapsed time: 0:03:55.480720
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 08:12:13.802820
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.98
 ---- batch: 020 ----
mean loss: 217.68
 ---- batch: 030 ----
mean loss: 229.31
train mean loss: 223.14
epoch train time: 0:00:06.917453
elapsed time: 0:04:02.398959
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 08:12:20.721138
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.55
 ---- batch: 020 ----
mean loss: 216.39
 ---- batch: 030 ----
mean loss: 214.08
train mean loss: 211.74
epoch train time: 0:00:06.938730
elapsed time: 0:04:09.338714
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 08:12:27.660840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.88
 ---- batch: 020 ----
mean loss: 217.42
 ---- batch: 030 ----
mean loss: 208.99
train mean loss: 211.60
epoch train time: 0:00:06.839215
elapsed time: 0:04:16.178754
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 08:12:34.500869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.16
 ---- batch: 020 ----
mean loss: 202.68
 ---- batch: 030 ----
mean loss: 205.38
train mean loss: 205.36
epoch train time: 0:00:06.965839
elapsed time: 0:04:23.145433
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 08:12:41.467536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.50
 ---- batch: 020 ----
mean loss: 199.94
 ---- batch: 030 ----
mean loss: 191.61
train mean loss: 198.98
epoch train time: 0:00:07.010905
elapsed time: 0:04:30.157104
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 08:12:48.479210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.63
 ---- batch: 020 ----
mean loss: 189.70
 ---- batch: 030 ----
mean loss: 197.17
train mean loss: 191.55
epoch train time: 0:00:07.050684
elapsed time: 0:04:37.208622
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 08:12:55.530729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.49
 ---- batch: 020 ----
mean loss: 182.93
 ---- batch: 030 ----
mean loss: 186.71
train mean loss: 186.29
epoch train time: 0:00:06.903614
elapsed time: 0:04:44.113008
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 08:13:02.435112
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.89
 ---- batch: 020 ----
mean loss: 185.50
 ---- batch: 030 ----
mean loss: 185.78
train mean loss: 185.22
epoch train time: 0:00:07.021050
elapsed time: 0:04:51.134913
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 08:13:09.457021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.41
 ---- batch: 020 ----
mean loss: 176.22
 ---- batch: 030 ----
mean loss: 177.01
train mean loss: 180.54
epoch train time: 0:00:06.950356
elapsed time: 0:04:58.086101
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 08:13:16.408194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 177.75
 ---- batch: 020 ----
mean loss: 176.59
 ---- batch: 030 ----
mean loss: 179.09
train mean loss: 178.70
epoch train time: 0:00:06.971449
elapsed time: 0:05:05.058306
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 08:13:23.380400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.16
 ---- batch: 020 ----
mean loss: 171.10
 ---- batch: 030 ----
mean loss: 174.84
train mean loss: 174.96
epoch train time: 0:00:07.017981
elapsed time: 0:05:12.077037
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 08:13:30.399135
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.36
 ---- batch: 020 ----
mean loss: 167.49
 ---- batch: 030 ----
mean loss: 170.47
train mean loss: 168.58
epoch train time: 0:00:06.929339
elapsed time: 0:05:19.007211
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 08:13:37.329330
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 167.83
 ---- batch: 020 ----
mean loss: 171.16
 ---- batch: 030 ----
mean loss: 168.18
train mean loss: 168.25
epoch train time: 0:00:06.989305
elapsed time: 0:05:25.997379
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 08:13:44.319506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.05
 ---- batch: 020 ----
mean loss: 162.98
 ---- batch: 030 ----
mean loss: 169.86
train mean loss: 167.03
epoch train time: 0:00:06.993540
elapsed time: 0:05:32.991906
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 08:13:51.314051
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.40
 ---- batch: 020 ----
mean loss: 165.31
 ---- batch: 030 ----
mean loss: 165.28
train mean loss: 164.78
epoch train time: 0:00:06.835325
elapsed time: 0:05:39.828192
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 08:13:58.150341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 162.48
 ---- batch: 020 ----
mean loss: 162.75
 ---- batch: 030 ----
mean loss: 163.01
train mean loss: 163.21
epoch train time: 0:00:06.929531
elapsed time: 0:05:46.758598
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 08:14:05.080739
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 166.32
 ---- batch: 020 ----
mean loss: 162.13
 ---- batch: 030 ----
mean loss: 162.13
train mean loss: 161.29
epoch train time: 0:00:06.806069
elapsed time: 0:05:53.565462
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 08:14:11.887552
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.26
 ---- batch: 020 ----
mean loss: 158.09
 ---- batch: 030 ----
mean loss: 158.40
train mean loss: 156.62
epoch train time: 0:00:06.939382
elapsed time: 0:06:00.505597
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 08:14:18.827703
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 155.12
 ---- batch: 020 ----
mean loss: 154.14
 ---- batch: 030 ----
mean loss: 151.79
train mean loss: 153.01
epoch train time: 0:00:06.926140
elapsed time: 0:06:07.432475
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 08:14:25.754570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.81
 ---- batch: 020 ----
mean loss: 156.97
 ---- batch: 030 ----
mean loss: 159.51
train mean loss: 155.21
epoch train time: 0:00:06.891838
elapsed time: 0:06:14.325092
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 08:14:32.647194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 154.25
 ---- batch: 020 ----
mean loss: 152.79
 ---- batch: 030 ----
mean loss: 150.59
train mean loss: 152.53
epoch train time: 0:00:06.929272
elapsed time: 0:06:21.255145
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 08:14:39.577250
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.90
 ---- batch: 020 ----
mean loss: 154.32
 ---- batch: 030 ----
mean loss: 147.04
train mean loss: 151.34
epoch train time: 0:00:06.876452
elapsed time: 0:06:28.132409
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 08:14:46.454505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.77
 ---- batch: 020 ----
mean loss: 150.45
 ---- batch: 030 ----
mean loss: 151.11
train mean loss: 149.17
epoch train time: 0:00:06.967891
elapsed time: 0:06:35.101111
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 08:14:53.423216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.04
 ---- batch: 020 ----
mean loss: 148.44
 ---- batch: 030 ----
mean loss: 150.48
train mean loss: 150.63
epoch train time: 0:00:06.944575
elapsed time: 0:06:42.046478
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 08:15:00.368658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.80
 ---- batch: 020 ----
mean loss: 141.45
 ---- batch: 030 ----
mean loss: 145.18
train mean loss: 143.69
epoch train time: 0:00:06.854497
elapsed time: 0:06:48.901854
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 08:15:07.223967
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.81
 ---- batch: 020 ----
mean loss: 149.06
 ---- batch: 030 ----
mean loss: 145.32
train mean loss: 145.07
epoch train time: 0:00:06.924462
elapsed time: 0:06:55.827159
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 08:15:14.149297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 144.63
 ---- batch: 020 ----
mean loss: 142.93
 ---- batch: 030 ----
mean loss: 146.35
train mean loss: 143.47
epoch train time: 0:00:06.821906
elapsed time: 0:07:02.649946
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 08:15:20.972061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.25
 ---- batch: 020 ----
mean loss: 139.60
 ---- batch: 030 ----
mean loss: 144.18
train mean loss: 143.57
epoch train time: 0:00:06.753474
elapsed time: 0:07:09.404270
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 08:15:27.726368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.04
 ---- batch: 020 ----
mean loss: 139.15
 ---- batch: 030 ----
mean loss: 142.79
train mean loss: 139.97
epoch train time: 0:00:06.773504
elapsed time: 0:07:16.178654
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 08:15:34.500775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.27
 ---- batch: 020 ----
mean loss: 138.85
 ---- batch: 030 ----
mean loss: 143.16
train mean loss: 140.68
epoch train time: 0:00:07.061257
elapsed time: 0:07:23.240738
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 08:15:41.562840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 147.54
 ---- batch: 020 ----
mean loss: 140.58
 ---- batch: 030 ----
mean loss: 137.94
train mean loss: 141.99
epoch train time: 0:00:06.843407
elapsed time: 0:07:30.084936
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 08:15:48.407024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.10
 ---- batch: 020 ----
mean loss: 140.57
 ---- batch: 030 ----
mean loss: 142.57
train mean loss: 137.76
epoch train time: 0:00:06.924989
elapsed time: 0:07:37.010666
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 08:15:55.332757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 140.13
 ---- batch: 020 ----
mean loss: 135.12
 ---- batch: 030 ----
mean loss: 137.95
train mean loss: 137.47
epoch train time: 0:00:06.866953
elapsed time: 0:07:43.878561
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 08:16:02.200688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.49
 ---- batch: 020 ----
mean loss: 133.72
 ---- batch: 030 ----
mean loss: 139.98
train mean loss: 137.09
epoch train time: 0:00:06.905641
elapsed time: 0:07:50.785047
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 08:16:09.107199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.93
 ---- batch: 020 ----
mean loss: 132.22
 ---- batch: 030 ----
mean loss: 135.17
train mean loss: 134.96
epoch train time: 0:00:06.912195
elapsed time: 0:07:57.698104
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 08:16:16.020194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.94
 ---- batch: 020 ----
mean loss: 135.17
 ---- batch: 030 ----
mean loss: 135.24
train mean loss: 134.12
epoch train time: 0:00:06.863612
elapsed time: 0:08:04.562516
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 08:16:22.884608
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.97
 ---- batch: 020 ----
mean loss: 132.31
 ---- batch: 030 ----
mean loss: 128.46
train mean loss: 133.86
epoch train time: 0:00:06.934236
elapsed time: 0:08:11.497604
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 08:16:29.820334
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.08
 ---- batch: 020 ----
mean loss: 133.39
 ---- batch: 030 ----
mean loss: 127.90
train mean loss: 131.36
epoch train time: 0:00:06.863890
elapsed time: 0:08:18.362910
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 08:16:36.685016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.68
 ---- batch: 020 ----
mean loss: 135.12
 ---- batch: 030 ----
mean loss: 131.08
train mean loss: 133.20
epoch train time: 0:00:06.904209
elapsed time: 0:08:25.267944
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 08:16:43.590067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.92
 ---- batch: 020 ----
mean loss: 128.00
 ---- batch: 030 ----
mean loss: 128.47
train mean loss: 129.70
epoch train time: 0:00:06.973098
elapsed time: 0:08:32.241839
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 08:16:50.563949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.04
 ---- batch: 020 ----
mean loss: 128.64
 ---- batch: 030 ----
mean loss: 128.78
train mean loss: 128.54
epoch train time: 0:00:06.851433
elapsed time: 0:08:39.094093
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 08:16:57.416239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 128.58
 ---- batch: 020 ----
mean loss: 130.18
 ---- batch: 030 ----
mean loss: 131.37
train mean loss: 129.95
epoch train time: 0:00:06.940765
elapsed time: 0:08:46.035804
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 08:17:04.357964
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.69
 ---- batch: 020 ----
mean loss: 134.47
 ---- batch: 030 ----
mean loss: 130.25
train mean loss: 131.68
epoch train time: 0:00:06.995198
elapsed time: 0:08:53.031943
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 08:17:11.354068
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.00
 ---- batch: 020 ----
mean loss: 130.49
 ---- batch: 030 ----
mean loss: 126.51
train mean loss: 127.82
epoch train time: 0:00:06.834596
elapsed time: 0:08:59.867317
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 08:17:18.189421
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.81
 ---- batch: 020 ----
mean loss: 126.47
 ---- batch: 030 ----
mean loss: 125.15
train mean loss: 128.05
epoch train time: 0:00:06.941644
elapsed time: 0:09:06.809860
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 08:17:25.132001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.10
 ---- batch: 020 ----
mean loss: 122.43
 ---- batch: 030 ----
mean loss: 129.75
train mean loss: 126.33
epoch train time: 0:00:06.953284
elapsed time: 0:09:13.764115
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 08:17:32.086348
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.17
 ---- batch: 020 ----
mean loss: 121.72
 ---- batch: 030 ----
mean loss: 126.68
train mean loss: 125.05
epoch train time: 0:00:06.869388
elapsed time: 0:09:20.634550
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 08:17:38.956676
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.82
 ---- batch: 020 ----
mean loss: 127.72
 ---- batch: 030 ----
mean loss: 125.56
train mean loss: 124.91
epoch train time: 0:00:06.895071
elapsed time: 0:09:27.530416
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 08:17:45.852517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.81
 ---- batch: 020 ----
mean loss: 125.46
 ---- batch: 030 ----
mean loss: 121.66
train mean loss: 125.89
epoch train time: 0:00:06.959536
elapsed time: 0:09:34.490896
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 08:17:52.813004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.29
 ---- batch: 020 ----
mean loss: 125.60
 ---- batch: 030 ----
mean loss: 126.29
train mean loss: 124.36
epoch train time: 0:00:06.843403
elapsed time: 0:09:41.335092
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 08:17:59.657220
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.64
 ---- batch: 020 ----
mean loss: 124.57
 ---- batch: 030 ----
mean loss: 125.77
train mean loss: 123.98
epoch train time: 0:00:06.925783
elapsed time: 0:09:48.261672
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 08:18:06.583771
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.60
 ---- batch: 020 ----
mean loss: 119.58
 ---- batch: 030 ----
mean loss: 122.57
train mean loss: 121.57
epoch train time: 0:00:06.944582
elapsed time: 0:09:55.207029
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 08:18:13.529129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.11
 ---- batch: 020 ----
mean loss: 124.13
 ---- batch: 030 ----
mean loss: 123.12
train mean loss: 120.97
epoch train time: 0:00:06.804661
elapsed time: 0:10:02.012441
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 08:18:20.334557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.72
 ---- batch: 020 ----
mean loss: 121.78
 ---- batch: 030 ----
mean loss: 120.32
train mean loss: 121.35
epoch train time: 0:00:06.892656
elapsed time: 0:10:08.906225
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 08:18:27.228370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.76
 ---- batch: 020 ----
mean loss: 120.26
 ---- batch: 030 ----
mean loss: 122.04
train mean loss: 120.67
epoch train time: 0:00:06.902100
elapsed time: 0:10:15.809294
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 08:18:34.131387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.57
 ---- batch: 020 ----
mean loss: 122.76
 ---- batch: 030 ----
mean loss: 112.96
train mean loss: 118.77
epoch train time: 0:00:06.765467
elapsed time: 0:10:22.575568
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 08:18:40.897730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.69
 ---- batch: 020 ----
mean loss: 118.56
 ---- batch: 030 ----
mean loss: 113.98
train mean loss: 117.64
epoch train time: 0:00:06.871180
elapsed time: 0:10:29.447577
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 08:18:47.769701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.20
 ---- batch: 020 ----
mean loss: 114.56
 ---- batch: 030 ----
mean loss: 122.30
train mean loss: 118.84
epoch train time: 0:00:06.876137
elapsed time: 0:10:36.324534
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 08:18:54.646634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.80
 ---- batch: 020 ----
mean loss: 118.70
 ---- batch: 030 ----
mean loss: 119.22
train mean loss: 119.08
epoch train time: 0:00:06.713621
elapsed time: 0:10:43.038942
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 08:19:01.361049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.78
 ---- batch: 020 ----
mean loss: 114.39
 ---- batch: 030 ----
mean loss: 116.32
train mean loss: 115.12
epoch train time: 0:00:06.704448
elapsed time: 0:10:49.744140
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 08:19:08.066239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.02
 ---- batch: 020 ----
mean loss: 116.50
 ---- batch: 030 ----
mean loss: 114.40
train mean loss: 117.03
epoch train time: 0:00:06.812445
elapsed time: 0:10:56.557482
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 08:19:14.879622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.33
 ---- batch: 020 ----
mean loss: 113.75
 ---- batch: 030 ----
mean loss: 115.87
train mean loss: 115.48
epoch train time: 0:00:06.989540
elapsed time: 0:11:03.547908
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 08:19:21.870000
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.68
 ---- batch: 020 ----
mean loss: 116.26
 ---- batch: 030 ----
mean loss: 116.25
train mean loss: 116.72
epoch train time: 0:00:06.793919
elapsed time: 0:11:10.342581
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 08:19:28.664688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.53
 ---- batch: 020 ----
mean loss: 116.70
 ---- batch: 030 ----
mean loss: 120.86
train mean loss: 117.61
epoch train time: 0:00:06.895809
elapsed time: 0:11:17.239166
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 08:19:35.561257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.29
 ---- batch: 020 ----
mean loss: 114.03
 ---- batch: 030 ----
mean loss: 116.85
train mean loss: 115.47
epoch train time: 0:00:06.778052
elapsed time: 0:11:24.017994
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 08:19:42.340131
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.59
 ---- batch: 020 ----
mean loss: 112.55
 ---- batch: 030 ----
mean loss: 117.62
train mean loss: 115.06
epoch train time: 0:00:06.857513
elapsed time: 0:11:30.876293
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 08:19:49.198415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.10
 ---- batch: 020 ----
mean loss: 114.87
 ---- batch: 030 ----
mean loss: 113.21
train mean loss: 114.72
epoch train time: 0:00:06.778909
elapsed time: 0:11:37.656060
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 08:19:55.978170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.84
 ---- batch: 020 ----
mean loss: 115.87
 ---- batch: 030 ----
mean loss: 110.51
train mean loss: 115.13
epoch train time: 0:00:06.955088
elapsed time: 0:11:44.612141
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 08:20:02.934254
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.43
 ---- batch: 020 ----
mean loss: 112.97
 ---- batch: 030 ----
mean loss: 110.70
train mean loss: 112.61
epoch train time: 0:00:06.837953
elapsed time: 0:11:51.451043
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 08:20:09.773155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.61
 ---- batch: 020 ----
mean loss: 113.88
 ---- batch: 030 ----
mean loss: 114.61
train mean loss: 113.30
epoch train time: 0:00:06.733097
elapsed time: 0:11:58.184922
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 08:20:16.507023
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.67
 ---- batch: 020 ----
mean loss: 115.32
 ---- batch: 030 ----
mean loss: 110.43
train mean loss: 111.65
epoch train time: 0:00:06.864681
elapsed time: 0:12:05.050363
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 08:20:23.372456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.48
 ---- batch: 020 ----
mean loss: 114.50
 ---- batch: 030 ----
mean loss: 112.00
train mean loss: 112.32
epoch train time: 0:00:06.775493
elapsed time: 0:12:11.826603
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 08:20:30.148698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.04
 ---- batch: 020 ----
mean loss: 108.07
 ---- batch: 030 ----
mean loss: 109.81
train mean loss: 110.62
epoch train time: 0:00:06.804530
elapsed time: 0:12:18.631873
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 08:20:36.953980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.93
 ---- batch: 020 ----
mean loss: 109.87
 ---- batch: 030 ----
mean loss: 111.81
train mean loss: 110.87
epoch train time: 0:00:06.700310
elapsed time: 0:12:25.332960
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 08:20:43.655070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.93
 ---- batch: 020 ----
mean loss: 110.51
 ---- batch: 030 ----
mean loss: 108.64
train mean loss: 111.29
epoch train time: 0:00:06.751939
elapsed time: 0:12:32.085740
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 08:20:50.407740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.14
 ---- batch: 020 ----
mean loss: 112.15
 ---- batch: 030 ----
mean loss: 112.14
train mean loss: 111.13
epoch train time: 0:00:06.721309
elapsed time: 0:12:38.807758
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 08:20:57.129850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.60
 ---- batch: 020 ----
mean loss: 111.40
 ---- batch: 030 ----
mean loss: 105.29
train mean loss: 110.59
epoch train time: 0:00:06.879924
elapsed time: 0:12:45.688458
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 08:21:04.010551
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 107.02
 ---- batch: 020 ----
mean loss: 108.45
 ---- batch: 030 ----
mean loss: 108.26
train mean loss: 109.15
epoch train time: 0:00:06.912170
elapsed time: 0:12:52.601369
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 08:21:10.923469
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.27
 ---- batch: 020 ----
mean loss: 105.54
 ---- batch: 030 ----
mean loss: 112.33
train mean loss: 108.59
epoch train time: 0:00:06.925324
elapsed time: 0:12:59.527483
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 08:21:17.849599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.31
 ---- batch: 020 ----
mean loss: 109.33
 ---- batch: 030 ----
mean loss: 106.18
train mean loss: 109.91
epoch train time: 0:00:06.979316
elapsed time: 0:13:06.507591
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 08:21:24.829754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.08
 ---- batch: 020 ----
mean loss: 109.91
 ---- batch: 030 ----
mean loss: 106.47
train mean loss: 108.98
epoch train time: 0:00:06.892914
elapsed time: 0:13:13.401326
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 08:21:31.723432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.86
 ---- batch: 020 ----
mean loss: 108.53
 ---- batch: 030 ----
mean loss: 107.95
train mean loss: 108.39
epoch train time: 0:00:06.907657
elapsed time: 0:13:20.309833
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 08:21:38.631952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.52
 ---- batch: 020 ----
mean loss: 106.79
 ---- batch: 030 ----
mean loss: 107.38
train mean loss: 107.45
epoch train time: 0:00:06.944475
elapsed time: 0:13:27.255081
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 08:21:45.577196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.33
 ---- batch: 020 ----
mean loss: 103.87
 ---- batch: 030 ----
mean loss: 107.45
train mean loss: 105.82
epoch train time: 0:00:06.816638
elapsed time: 0:13:34.072462
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 08:21:52.394565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.48
 ---- batch: 020 ----
mean loss: 105.37
 ---- batch: 030 ----
mean loss: 108.44
train mean loss: 106.07
epoch train time: 0:00:06.679998
elapsed time: 0:13:40.753229
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 08:21:59.075322
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.94
 ---- batch: 020 ----
mean loss: 107.00
 ---- batch: 030 ----
mean loss: 108.61
train mean loss: 107.16
epoch train time: 0:00:06.750753
elapsed time: 0:13:47.504855
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 08:22:05.826963
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.32
 ---- batch: 020 ----
mean loss: 109.68
 ---- batch: 030 ----
mean loss: 106.12
train mean loss: 107.72
epoch train time: 0:00:07.063895
elapsed time: 0:13:54.569619
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 08:22:12.891753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.25
 ---- batch: 020 ----
mean loss: 103.80
 ---- batch: 030 ----
mean loss: 108.32
train mean loss: 107.19
epoch train time: 0:00:06.925799
elapsed time: 0:14:01.496365
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 08:22:19.818475
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.82
 ---- batch: 020 ----
mean loss: 107.94
 ---- batch: 030 ----
mean loss: 105.38
train mean loss: 108.37
epoch train time: 0:00:07.021548
elapsed time: 0:14:08.518720
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 08:22:26.840911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.60
 ---- batch: 020 ----
mean loss: 104.64
 ---- batch: 030 ----
mean loss: 106.25
train mean loss: 104.86
epoch train time: 0:00:07.038982
elapsed time: 0:14:15.558569
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 08:22:33.880667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.83
 ---- batch: 020 ----
mean loss: 106.28
 ---- batch: 030 ----
mean loss: 105.77
train mean loss: 104.88
epoch train time: 0:00:06.938477
elapsed time: 0:14:22.497820
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 08:22:40.819912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.09
 ---- batch: 020 ----
mean loss: 106.17
 ---- batch: 030 ----
mean loss: 106.05
train mean loss: 106.28
epoch train time: 0:00:07.026084
elapsed time: 0:14:29.524686
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 08:22:47.846786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.86
 ---- batch: 020 ----
mean loss: 104.31
 ---- batch: 030 ----
mean loss: 105.86
train mean loss: 105.07
epoch train time: 0:00:07.000154
elapsed time: 0:14:36.525637
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 08:22:54.847758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.76
 ---- batch: 020 ----
mean loss: 103.60
 ---- batch: 030 ----
mean loss: 100.97
train mean loss: 104.14
epoch train time: 0:00:06.873499
elapsed time: 0:14:43.400125
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 08:23:01.722282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.93
 ---- batch: 020 ----
mean loss: 102.63
 ---- batch: 030 ----
mean loss: 102.53
train mean loss: 102.85
epoch train time: 0:00:06.958585
elapsed time: 0:14:50.359705
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 08:23:08.681707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.38
 ---- batch: 020 ----
mean loss: 102.04
 ---- batch: 030 ----
mean loss: 107.71
train mean loss: 103.95
epoch train time: 0:00:06.977131
elapsed time: 0:14:57.337541
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 08:23:15.659643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.10
 ---- batch: 020 ----
mean loss: 103.00
 ---- batch: 030 ----
mean loss: 102.84
train mean loss: 102.64
epoch train time: 0:00:06.872608
elapsed time: 0:15:04.210952
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 08:23:22.533048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.68
 ---- batch: 020 ----
mean loss: 103.34
 ---- batch: 030 ----
mean loss: 101.94
train mean loss: 102.69
epoch train time: 0:00:06.967328
elapsed time: 0:15:11.179059
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 08:23:29.501156
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.13
 ---- batch: 020 ----
mean loss: 100.64
 ---- batch: 030 ----
mean loss: 103.27
train mean loss: 102.22
epoch train time: 0:00:06.841575
elapsed time: 0:15:18.021534
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 08:23:36.343641
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.40
 ---- batch: 020 ----
mean loss: 99.84
 ---- batch: 030 ----
mean loss: 102.85
train mean loss: 102.04
epoch train time: 0:00:06.940478
elapsed time: 0:15:24.962789
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 08:23:43.284889
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.86
 ---- batch: 020 ----
mean loss: 102.98
 ---- batch: 030 ----
mean loss: 98.38
train mean loss: 102.27
epoch train time: 0:00:06.938546
elapsed time: 0:15:31.902066
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 08:23:50.224143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.65
 ---- batch: 020 ----
mean loss: 102.96
 ---- batch: 030 ----
mean loss: 101.11
train mean loss: 101.50
epoch train time: 0:00:06.830134
elapsed time: 0:15:38.732963
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 08:23:57.055057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.46
 ---- batch: 020 ----
mean loss: 102.89
 ---- batch: 030 ----
mean loss: 101.10
train mean loss: 101.81
epoch train time: 0:00:06.943194
elapsed time: 0:15:45.676967
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 08:24:03.999355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.71
 ---- batch: 020 ----
mean loss: 97.45
 ---- batch: 030 ----
mean loss: 103.28
train mean loss: 101.35
epoch train time: 0:00:06.887850
elapsed time: 0:15:52.565861
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 08:24:10.887956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.55
 ---- batch: 020 ----
mean loss: 102.61
 ---- batch: 030 ----
mean loss: 101.56
train mean loss: 101.88
epoch train time: 0:00:06.916631
elapsed time: 0:15:59.483304
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 08:24:17.805413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.10
 ---- batch: 020 ----
mean loss: 103.31
 ---- batch: 030 ----
mean loss: 98.81
train mean loss: 100.42
epoch train time: 0:00:06.968083
elapsed time: 0:16:06.452264
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 08:24:24.774368
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.43
 ---- batch: 020 ----
mean loss: 104.99
 ---- batch: 030 ----
mean loss: 99.55
train mean loss: 101.54
epoch train time: 0:00:06.839527
elapsed time: 0:16:13.292591
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 08:24:31.614705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.52
 ---- batch: 020 ----
mean loss: 99.96
 ---- batch: 030 ----
mean loss: 99.26
train mean loss: 100.03
epoch train time: 0:00:06.912780
elapsed time: 0:16:20.206190
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 08:24:38.528299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.87
 ---- batch: 020 ----
mean loss: 97.66
 ---- batch: 030 ----
mean loss: 98.62
train mean loss: 99.06
epoch train time: 0:00:06.870360
elapsed time: 0:16:27.077399
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 08:24:45.399498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.28
 ---- batch: 020 ----
mean loss: 100.71
 ---- batch: 030 ----
mean loss: 101.93
train mean loss: 102.07
epoch train time: 0:00:06.907881
elapsed time: 0:16:33.986095
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 08:24:52.308216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.95
 ---- batch: 020 ----
mean loss: 97.87
 ---- batch: 030 ----
mean loss: 102.48
train mean loss: 98.87
epoch train time: 0:00:06.916776
elapsed time: 0:16:40.903640
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 08:24:59.225846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.33
 ---- batch: 020 ----
mean loss: 100.06
 ---- batch: 030 ----
mean loss: 100.92
train mean loss: 99.31
epoch train time: 0:00:06.878001
elapsed time: 0:16:47.782613
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 08:25:06.104712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.44
 ---- batch: 020 ----
mean loss: 97.83
 ---- batch: 030 ----
mean loss: 98.31
train mean loss: 98.06
epoch train time: 0:00:06.912824
elapsed time: 0:16:54.696216
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 08:25:13.018316
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.74
 ---- batch: 020 ----
mean loss: 101.83
 ---- batch: 030 ----
mean loss: 95.25
train mean loss: 98.52
epoch train time: 0:00:06.762353
elapsed time: 0:17:01.459309
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 08:25:19.781432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.67
 ---- batch: 020 ----
mean loss: 101.25
 ---- batch: 030 ----
mean loss: 99.39
train mean loss: 99.24
epoch train time: 0:00:06.751151
elapsed time: 0:17:08.211356
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 08:25:26.533468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.72
 ---- batch: 020 ----
mean loss: 98.62
 ---- batch: 030 ----
mean loss: 98.10
train mean loss: 97.63
epoch train time: 0:00:06.909848
elapsed time: 0:17:15.121988
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 08:25:33.444092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.73
 ---- batch: 020 ----
mean loss: 102.21
 ---- batch: 030 ----
mean loss: 97.60
train mean loss: 99.11
epoch train time: 0:00:06.877552
elapsed time: 0:17:22.000438
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 08:25:40.322432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.28
 ---- batch: 020 ----
mean loss: 96.60
 ---- batch: 030 ----
mean loss: 97.36
train mean loss: 98.08
epoch train time: 0:00:06.778236
elapsed time: 0:17:28.779456
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 08:25:47.101598
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.96
 ---- batch: 020 ----
mean loss: 98.66
 ---- batch: 030 ----
mean loss: 97.75
train mean loss: 97.39
epoch train time: 0:00:06.919771
elapsed time: 0:17:35.700111
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 08:25:54.022216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.47
 ---- batch: 020 ----
mean loss: 97.42
 ---- batch: 030 ----
mean loss: 102.20
train mean loss: 98.91
epoch train time: 0:00:06.785043
elapsed time: 0:17:42.486015
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 08:26:00.808413
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.51
 ---- batch: 020 ----
mean loss: 99.40
 ---- batch: 030 ----
mean loss: 92.81
train mean loss: 96.97
epoch train time: 0:00:06.896838
elapsed time: 0:17:49.383992
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 08:26:07.706104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.19
 ---- batch: 020 ----
mean loss: 96.68
 ---- batch: 030 ----
mean loss: 97.28
train mean loss: 96.70
epoch train time: 0:00:06.908693
elapsed time: 0:17:56.293495
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 08:26:14.615585
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.72
 ---- batch: 020 ----
mean loss: 97.55
 ---- batch: 030 ----
mean loss: 94.31
train mean loss: 96.46
epoch train time: 0:00:06.860153
elapsed time: 0:18:03.154417
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 08:26:21.476518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.93
 ---- batch: 020 ----
mean loss: 97.28
 ---- batch: 030 ----
mean loss: 101.21
train mean loss: 97.64
epoch train time: 0:00:06.896654
elapsed time: 0:18:10.051871
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 08:26:28.373966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.34
 ---- batch: 020 ----
mean loss: 97.44
 ---- batch: 030 ----
mean loss: 97.70
train mean loss: 97.07
epoch train time: 0:00:06.957817
elapsed time: 0:18:17.010453
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 08:26:35.332561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.34
 ---- batch: 020 ----
mean loss: 96.72
 ---- batch: 030 ----
mean loss: 97.42
train mean loss: 97.06
epoch train time: 0:00:06.788430
elapsed time: 0:18:23.799717
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 08:26:42.121808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.93
 ---- batch: 020 ----
mean loss: 97.42
 ---- batch: 030 ----
mean loss: 96.99
train mean loss: 96.46
epoch train time: 0:00:06.953015
elapsed time: 0:18:30.753759
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 08:26:49.075866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.00
 ---- batch: 020 ----
mean loss: 94.36
 ---- batch: 030 ----
mean loss: 94.66
train mean loss: 96.18
epoch train time: 0:00:06.917242
elapsed time: 0:18:37.671783
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 08:26:55.993877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.02
 ---- batch: 020 ----
mean loss: 94.76
 ---- batch: 030 ----
mean loss: 97.44
train mean loss: 96.65
epoch train time: 0:00:06.785299
elapsed time: 0:18:44.457954
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 08:27:02.780092
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.83
 ---- batch: 020 ----
mean loss: 94.33
 ---- batch: 030 ----
mean loss: 92.97
train mean loss: 95.28
epoch train time: 0:00:06.889267
elapsed time: 0:18:51.348136
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 08:27:09.670263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.87
 ---- batch: 020 ----
mean loss: 97.75
 ---- batch: 030 ----
mean loss: 94.59
train mean loss: 95.04
epoch train time: 0:00:06.832932
elapsed time: 0:18:58.181854
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 08:27:16.503945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.77
 ---- batch: 020 ----
mean loss: 95.80
 ---- batch: 030 ----
mean loss: 93.41
train mean loss: 95.31
epoch train time: 0:00:06.901733
elapsed time: 0:19:05.084363
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 08:27:23.406480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.16
 ---- batch: 020 ----
mean loss: 94.09
 ---- batch: 030 ----
mean loss: 94.33
train mean loss: 94.61
epoch train time: 0:00:06.823622
elapsed time: 0:19:11.908786
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 08:27:30.230883
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.94
 ---- batch: 020 ----
mean loss: 92.80
 ---- batch: 030 ----
mean loss: 97.18
train mean loss: 94.38
epoch train time: 0:00:06.902187
elapsed time: 0:19:18.811813
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 08:27:37.133931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.14
 ---- batch: 020 ----
mean loss: 94.95
 ---- batch: 030 ----
mean loss: 93.68
train mean loss: 95.25
epoch train time: 0:00:06.859037
elapsed time: 0:19:25.671644
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 08:27:43.993761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.71
 ---- batch: 020 ----
mean loss: 92.92
 ---- batch: 030 ----
mean loss: 95.19
train mean loss: 94.81
epoch train time: 0:00:06.835692
elapsed time: 0:19:32.508259
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 08:27:50.830367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.51
 ---- batch: 020 ----
mean loss: 92.18
 ---- batch: 030 ----
mean loss: 92.61
train mean loss: 94.13
epoch train time: 0:00:06.870675
elapsed time: 0:19:39.379729
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 08:27:57.701831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.23
 ---- batch: 020 ----
mean loss: 93.75
 ---- batch: 030 ----
mean loss: 93.91
train mean loss: 94.09
epoch train time: 0:00:06.764661
elapsed time: 0:19:46.145147
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 08:28:04.467237
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.69
 ---- batch: 020 ----
mean loss: 97.05
 ---- batch: 030 ----
mean loss: 91.95
train mean loss: 93.96
epoch train time: 0:00:07.001816
elapsed time: 0:19:53.147856
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 08:28:11.469952
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.63
 ---- batch: 020 ----
mean loss: 93.27
 ---- batch: 030 ----
mean loss: 94.13
train mean loss: 94.49
epoch train time: 0:00:06.894386
elapsed time: 0:20:00.043056
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 08:28:18.365212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.20
 ---- batch: 020 ----
mean loss: 90.40
 ---- batch: 030 ----
mean loss: 95.28
train mean loss: 94.02
epoch train time: 0:00:06.946228
elapsed time: 0:20:06.990116
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 08:28:25.312233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.41
 ---- batch: 020 ----
mean loss: 95.38
 ---- batch: 030 ----
mean loss: 93.09
train mean loss: 94.29
epoch train time: 0:00:06.974923
elapsed time: 0:20:13.965932
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 08:28:32.287946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.06
 ---- batch: 020 ----
mean loss: 94.41
 ---- batch: 030 ----
mean loss: 94.93
train mean loss: 93.18
epoch train time: 0:00:06.831097
elapsed time: 0:20:20.797742
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 08:28:39.119832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.33
 ---- batch: 020 ----
mean loss: 93.18
 ---- batch: 030 ----
mean loss: 91.83
train mean loss: 93.39
epoch train time: 0:00:06.797004
elapsed time: 0:20:27.595529
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 08:28:45.917639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.64
 ---- batch: 020 ----
mean loss: 93.60
 ---- batch: 030 ----
mean loss: 93.77
train mean loss: 93.24
epoch train time: 0:00:06.816505
elapsed time: 0:20:34.412849
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 08:28:52.734981
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.19
 ---- batch: 020 ----
mean loss: 91.76
 ---- batch: 030 ----
mean loss: 96.16
train mean loss: 93.44
epoch train time: 0:00:07.017332
elapsed time: 0:20:41.431022
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 08:28:59.753129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.49
 ---- batch: 020 ----
mean loss: 94.82
 ---- batch: 030 ----
mean loss: 89.72
train mean loss: 92.33
epoch train time: 0:00:06.853543
elapsed time: 0:20:48.285332
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 08:29:06.607425
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.03
 ---- batch: 020 ----
mean loss: 90.11
 ---- batch: 030 ----
mean loss: 91.77
train mean loss: 92.22
epoch train time: 0:00:06.959323
elapsed time: 0:20:55.245481
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 08:29:13.567613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.39
 ---- batch: 020 ----
mean loss: 94.10
 ---- batch: 030 ----
mean loss: 91.62
train mean loss: 91.75
epoch train time: 0:00:06.904527
elapsed time: 0:21:02.150807
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 08:29:20.472902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.27
 ---- batch: 020 ----
mean loss: 94.59
 ---- batch: 030 ----
mean loss: 92.30
train mean loss: 92.55
epoch train time: 0:00:06.975274
elapsed time: 0:21:09.126906
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 08:29:27.449038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.22
 ---- batch: 020 ----
mean loss: 92.03
 ---- batch: 030 ----
mean loss: 92.49
train mean loss: 91.67
epoch train time: 0:00:06.994121
elapsed time: 0:21:16.122012
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 08:29:34.444103
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.25
 ---- batch: 020 ----
mean loss: 92.64
 ---- batch: 030 ----
mean loss: 94.64
train mean loss: 92.76
epoch train time: 0:00:07.033706
elapsed time: 0:21:23.156521
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 08:29:41.478621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.17
 ---- batch: 020 ----
mean loss: 90.14
 ---- batch: 030 ----
mean loss: 90.62
train mean loss: 90.75
epoch train time: 0:00:07.048299
elapsed time: 0:21:30.205595
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 08:29:48.527688
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.67
 ---- batch: 020 ----
mean loss: 93.50
 ---- batch: 030 ----
mean loss: 86.84
train mean loss: 92.02
epoch train time: 0:00:07.007606
elapsed time: 0:21:37.213982
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 08:29:55.536075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.04
 ---- batch: 020 ----
mean loss: 92.18
 ---- batch: 030 ----
mean loss: 89.22
train mean loss: 92.14
epoch train time: 0:00:07.061289
elapsed time: 0:21:44.276158
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 08:30:02.598248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.77
 ---- batch: 020 ----
mean loss: 92.01
 ---- batch: 030 ----
mean loss: 93.63
train mean loss: 90.58
epoch train time: 0:00:06.993009
elapsed time: 0:21:51.270023
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 08:30:09.592141
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.77
 ---- batch: 020 ----
mean loss: 90.61
 ---- batch: 030 ----
mean loss: 93.41
train mean loss: 91.21
epoch train time: 0:00:07.082834
elapsed time: 0:21:58.353742
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 08:30:16.675850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.72
 ---- batch: 020 ----
mean loss: 90.01
 ---- batch: 030 ----
mean loss: 93.73
train mean loss: 90.34
epoch train time: 0:00:07.059978
elapsed time: 0:22:05.414521
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 08:30:23.736613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.85
 ---- batch: 020 ----
mean loss: 89.54
 ---- batch: 030 ----
mean loss: 90.33
train mean loss: 90.43
epoch train time: 0:00:07.023522
elapsed time: 0:22:12.438847
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 08:30:30.761002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.68
 ---- batch: 020 ----
mean loss: 90.15
 ---- batch: 030 ----
mean loss: 88.80
train mean loss: 90.33
epoch train time: 0:00:06.846715
elapsed time: 0:22:19.286380
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 08:30:37.608484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.14
 ---- batch: 020 ----
mean loss: 90.18
 ---- batch: 030 ----
mean loss: 93.34
train mean loss: 91.03
epoch train time: 0:00:06.939991
elapsed time: 0:22:26.227176
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 08:30:44.549310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.62
 ---- batch: 020 ----
mean loss: 91.01
 ---- batch: 030 ----
mean loss: 88.09
train mean loss: 89.74
epoch train time: 0:00:06.969344
elapsed time: 0:22:33.197443
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 08:30:51.519602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.41
 ---- batch: 020 ----
mean loss: 91.71
 ---- batch: 030 ----
mean loss: 91.38
train mean loss: 91.16
epoch train time: 0:00:06.864332
elapsed time: 0:22:40.062700
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 08:30:58.384823
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.22
 ---- batch: 020 ----
mean loss: 93.80
 ---- batch: 030 ----
mean loss: 91.53
train mean loss: 91.66
epoch train time: 0:00:06.937986
elapsed time: 0:22:47.001632
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 08:31:05.323721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.66
 ---- batch: 020 ----
mean loss: 91.75
 ---- batch: 030 ----
mean loss: 85.87
train mean loss: 89.52
epoch train time: 0:00:06.888802
elapsed time: 0:22:53.891170
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 08:31:12.213263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.71
 ---- batch: 020 ----
mean loss: 89.91
 ---- batch: 030 ----
mean loss: 88.48
train mean loss: 88.58
epoch train time: 0:00:06.905307
elapsed time: 0:23:00.797289
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 08:31:19.119383
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.42
 ---- batch: 020 ----
mean loss: 90.15
 ---- batch: 030 ----
mean loss: 91.32
train mean loss: 89.33
epoch train time: 0:00:06.945858
elapsed time: 0:23:07.743965
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 08:31:26.066059
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.65
 ---- batch: 020 ----
mean loss: 88.80
 ---- batch: 030 ----
mean loss: 89.33
train mean loss: 88.96
epoch train time: 0:00:06.834659
elapsed time: 0:23:14.579383
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 08:31:32.901489
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.80
 ---- batch: 020 ----
mean loss: 89.32
 ---- batch: 030 ----
mean loss: 91.39
train mean loss: 88.88
epoch train time: 0:00:06.954970
elapsed time: 0:23:21.535251
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 08:31:39.857362
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.34
 ---- batch: 020 ----
mean loss: 87.41
 ---- batch: 030 ----
mean loss: 88.89
train mean loss: 87.56
epoch train time: 0:00:06.895962
elapsed time: 0:23:28.432110
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 08:31:46.754106
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.27
 ---- batch: 020 ----
mean loss: 87.87
 ---- batch: 030 ----
mean loss: 87.49
train mean loss: 87.65
epoch train time: 0:00:06.795814
elapsed time: 0:23:35.228612
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 08:31:53.550701
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.66
 ---- batch: 020 ----
mean loss: 87.25
 ---- batch: 030 ----
mean loss: 88.15
train mean loss: 87.73
epoch train time: 0:00:06.724112
elapsed time: 0:23:41.953478
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 08:32:00.275566
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.70
 ---- batch: 020 ----
mean loss: 85.93
 ---- batch: 030 ----
mean loss: 87.90
train mean loss: 87.57
epoch train time: 0:00:06.940062
elapsed time: 0:23:48.894402
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 08:32:07.216599
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.56
 ---- batch: 020 ----
mean loss: 86.72
 ---- batch: 030 ----
mean loss: 86.92
train mean loss: 87.51
epoch train time: 0:00:06.915501
elapsed time: 0:23:55.810805
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 08:32:14.132903
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.42
 ---- batch: 020 ----
mean loss: 88.01
 ---- batch: 030 ----
mean loss: 85.12
train mean loss: 86.78
epoch train time: 0:00:06.813439
elapsed time: 0:24:02.625056
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 08:32:20.947202
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.71
 ---- batch: 020 ----
mean loss: 87.29
 ---- batch: 030 ----
mean loss: 87.46
train mean loss: 87.48
epoch train time: 0:00:06.918357
elapsed time: 0:24:09.544264
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 08:32:27.866373
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.80
 ---- batch: 020 ----
mean loss: 83.22
 ---- batch: 030 ----
mean loss: 87.96
train mean loss: 87.64
epoch train time: 0:00:06.836251
elapsed time: 0:24:16.381430
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 08:32:34.703565
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.48
 ---- batch: 020 ----
mean loss: 88.07
 ---- batch: 030 ----
mean loss: 87.01
train mean loss: 87.42
epoch train time: 0:00:06.932146
elapsed time: 0:24:23.314368
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 08:32:41.636467
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.00
 ---- batch: 020 ----
mean loss: 85.85
 ---- batch: 030 ----
mean loss: 87.87
train mean loss: 87.28
epoch train time: 0:00:06.958363
elapsed time: 0:24:30.273506
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 08:32:48.595596
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.08
 ---- batch: 020 ----
mean loss: 87.11
 ---- batch: 030 ----
mean loss: 85.17
train mean loss: 87.34
epoch train time: 0:00:06.880449
elapsed time: 0:24:37.154780
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 08:32:55.476878
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.97
 ---- batch: 020 ----
mean loss: 91.19
 ---- batch: 030 ----
mean loss: 87.72
train mean loss: 88.07
epoch train time: 0:00:06.779218
elapsed time: 0:24:43.934746
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 08:33:02.256867
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.11
 ---- batch: 020 ----
mean loss: 85.27
 ---- batch: 030 ----
mean loss: 87.84
train mean loss: 88.06
epoch train time: 0:00:06.988977
elapsed time: 0:24:50.924607
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 08:33:09.246698
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.81
 ---- batch: 020 ----
mean loss: 89.25
 ---- batch: 030 ----
mean loss: 84.40
train mean loss: 87.67
epoch train time: 0:00:07.015306
elapsed time: 0:24:57.940675
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 08:33:16.262780
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.98
 ---- batch: 020 ----
mean loss: 83.64
 ---- batch: 030 ----
mean loss: 92.29
train mean loss: 87.50
epoch train time: 0:00:06.889507
elapsed time: 0:25:04.830956
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 08:33:23.153058
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.53
 ---- batch: 020 ----
mean loss: 88.90
 ---- batch: 030 ----
mean loss: 86.53
train mean loss: 87.84
epoch train time: 0:00:07.002150
elapsed time: 0:25:11.833930
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 08:33:30.156040
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 84.44
 ---- batch: 020 ----
mean loss: 89.11
 ---- batch: 030 ----
mean loss: 90.51
train mean loss: 87.77
epoch train time: 0:00:07.006281
elapsed time: 0:25:18.841020
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 08:33:37.163150
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.74
 ---- batch: 020 ----
mean loss: 86.90
 ---- batch: 030 ----
mean loss: 86.87
train mean loss: 88.28
epoch train time: 0:00:06.945723
elapsed time: 0:25:25.787567
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 08:33:44.109687
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.44
 ---- batch: 020 ----
mean loss: 89.88
 ---- batch: 030 ----
mean loss: 87.58
train mean loss: 87.00
epoch train time: 0:00:06.972214
elapsed time: 0:25:32.760676
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 08:33:51.082771
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.98
 ---- batch: 020 ----
mean loss: 88.48
 ---- batch: 030 ----
mean loss: 88.30
train mean loss: 87.60
epoch train time: 0:00:06.928733
elapsed time: 0:25:39.690190
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 08:33:58.012296
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.65
 ---- batch: 020 ----
mean loss: 87.74
 ---- batch: 030 ----
mean loss: 87.48
train mean loss: 87.44
epoch train time: 0:00:06.923911
elapsed time: 0:25:46.614916
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 08:34:04.937023
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.45
 ---- batch: 020 ----
mean loss: 87.52
 ---- batch: 030 ----
mean loss: 84.26
train mean loss: 87.01
epoch train time: 0:00:06.971013
elapsed time: 0:25:53.586696
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 08:34:11.908804
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.99
 ---- batch: 020 ----
mean loss: 86.68
 ---- batch: 030 ----
mean loss: 90.13
train mean loss: 87.42
epoch train time: 0:00:06.943469
elapsed time: 0:26:00.531333
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 08:34:18.853483
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 90.80
 ---- batch: 020 ----
mean loss: 86.23
 ---- batch: 030 ----
mean loss: 86.25
train mean loss: 87.43
epoch train time: 0:00:06.975984
elapsed time: 0:26:07.508287
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 08:34:25.830385
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.01
 ---- batch: 020 ----
mean loss: 86.61
 ---- batch: 030 ----
mean loss: 88.68
train mean loss: 86.86
epoch train time: 0:00:06.961235
elapsed time: 0:26:14.470284
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 08:34:32.792383
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.95
 ---- batch: 020 ----
mean loss: 88.78
 ---- batch: 030 ----
mean loss: 87.79
train mean loss: 87.67
epoch train time: 0:00:06.894376
elapsed time: 0:26:21.365423
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 08:34:39.687531
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.59
 ---- batch: 020 ----
mean loss: 89.68
 ---- batch: 030 ----
mean loss: 86.14
train mean loss: 87.49
epoch train time: 0:00:06.994847
elapsed time: 0:26:28.361056
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 08:34:46.683178
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.54
 ---- batch: 020 ----
mean loss: 84.81
 ---- batch: 030 ----
mean loss: 87.08
train mean loss: 86.81
epoch train time: 0:00:06.883899
elapsed time: 0:26:35.245786
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 08:34:53.567902
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.75
 ---- batch: 020 ----
mean loss: 88.16
 ---- batch: 030 ----
mean loss: 86.14
train mean loss: 87.51
epoch train time: 0:00:06.953919
elapsed time: 0:26:42.200671
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 08:35:00.522770
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.75
 ---- batch: 020 ----
mean loss: 88.50
 ---- batch: 030 ----
mean loss: 86.79
train mean loss: 87.09
epoch train time: 0:00:06.999344
elapsed time: 0:26:49.200847
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 08:35:07.522939
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.45
 ---- batch: 020 ----
mean loss: 88.38
 ---- batch: 030 ----
mean loss: 85.76
train mean loss: 87.56
epoch train time: 0:00:06.968910
elapsed time: 0:26:56.170528
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 08:35:14.492643
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.57
 ---- batch: 020 ----
mean loss: 88.01
 ---- batch: 030 ----
mean loss: 87.21
train mean loss: 86.97
epoch train time: 0:00:06.872128
elapsed time: 0:27:03.043434
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 08:35:21.365531
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.57
 ---- batch: 020 ----
mean loss: 88.39
 ---- batch: 030 ----
mean loss: 86.31
train mean loss: 87.57
epoch train time: 0:00:07.013064
elapsed time: 0:27:10.057379
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 08:35:28.379394
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.68
 ---- batch: 020 ----
mean loss: 86.47
 ---- batch: 030 ----
mean loss: 86.29
train mean loss: 87.08
epoch train time: 0:00:06.892826
elapsed time: 0:27:16.950853
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 08:35:35.272954
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.34
 ---- batch: 020 ----
mean loss: 85.32
 ---- batch: 030 ----
mean loss: 84.62
train mean loss: 86.28
epoch train time: 0:00:06.816246
elapsed time: 0:27:23.767954
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 08:35:42.090063
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.62
 ---- batch: 020 ----
mean loss: 85.34
 ---- batch: 030 ----
mean loss: 87.84
train mean loss: 87.56
epoch train time: 0:00:06.816379
elapsed time: 0:27:30.585126
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 08:35:48.907223
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.13
 ---- batch: 020 ----
mean loss: 86.89
 ---- batch: 030 ----
mean loss: 87.20
train mean loss: 87.50
epoch train time: 0:00:07.051318
elapsed time: 0:27:37.637261
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 08:35:55.959379
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.22
 ---- batch: 020 ----
mean loss: 88.13
 ---- batch: 030 ----
mean loss: 84.78
train mean loss: 87.48
epoch train time: 0:00:06.928046
elapsed time: 0:27:44.566104
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 08:36:02.888195
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.77
 ---- batch: 020 ----
mean loss: 86.14
 ---- batch: 030 ----
mean loss: 84.59
train mean loss: 87.29
epoch train time: 0:00:06.963701
elapsed time: 0:27:51.530656
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 08:36:09.852767
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.53
 ---- batch: 020 ----
mean loss: 85.29
 ---- batch: 030 ----
mean loss: 88.92
train mean loss: 86.23
epoch train time: 0:00:06.928175
elapsed time: 0:27:58.459599
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 08:36:16.781707
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.69
 ---- batch: 020 ----
mean loss: 86.62
 ---- batch: 030 ----
mean loss: 88.59
train mean loss: 87.00
epoch train time: 0:00:06.936745
elapsed time: 0:28:05.397139
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 08:36:23.719231
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.08
 ---- batch: 020 ----
mean loss: 87.54
 ---- batch: 030 ----
mean loss: 84.52
train mean loss: 86.72
epoch train time: 0:00:06.933039
elapsed time: 0:28:12.330994
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 08:36:30.653102
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.28
 ---- batch: 020 ----
mean loss: 88.28
 ---- batch: 030 ----
mean loss: 86.97
train mean loss: 87.13
epoch train time: 0:00:06.911429
elapsed time: 0:28:19.243204
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 08:36:37.565319
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.90
 ---- batch: 020 ----
mean loss: 86.02
 ---- batch: 030 ----
mean loss: 85.41
train mean loss: 86.80
epoch train time: 0:00:06.942925
elapsed time: 0:28:26.187209
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 08:36:44.509306
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.98
 ---- batch: 020 ----
mean loss: 87.24
 ---- batch: 030 ----
mean loss: 85.38
train mean loss: 86.74
epoch train time: 0:00:06.935754
elapsed time: 0:28:33.123792
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 08:36:51.445965
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.95
 ---- batch: 020 ----
mean loss: 88.28
 ---- batch: 030 ----
mean loss: 86.31
train mean loss: 86.89
epoch train time: 0:00:07.014020
elapsed time: 0:28:40.138681
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 08:36:58.460792
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.59
 ---- batch: 020 ----
mean loss: 86.55
 ---- batch: 030 ----
mean loss: 86.41
train mean loss: 87.14
epoch train time: 0:00:06.896547
elapsed time: 0:28:47.036012
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 08:37:05.358139
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.79
 ---- batch: 020 ----
mean loss: 86.98
 ---- batch: 030 ----
mean loss: 85.13
train mean loss: 86.86
epoch train time: 0:00:06.945845
elapsed time: 0:28:53.982671
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 08:37:12.304788
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 82.79
 ---- batch: 020 ----
mean loss: 88.56
 ---- batch: 030 ----
mean loss: 89.41
train mean loss: 86.92
epoch train time: 0:00:07.027368
elapsed time: 0:29:01.020771
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_5/checkpoint.pth.tar
**** end time: 2019-09-27 08:37:19.342736 ****
