Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_6', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29951
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianDense3...
Done.
**** start time: 2019-09-27 15:23:43.762853 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
    BayesianLinear-2                  [-1, 100]          84,000
           Sigmoid-3                  [-1, 100]               0
    BayesianLinear-4                  [-1, 100]          20,000
           Sigmoid-5                  [-1, 100]               0
    BayesianLinear-6                  [-1, 100]          20,000
           Sigmoid-7                  [-1, 100]               0
    BayesianLinear-8                    [-1, 1]             200
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 124,200
Trainable params: 124,200
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 15:23:43.772946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3658.93
 ---- batch: 020 ----
mean loss: 3260.54
 ---- batch: 030 ----
mean loss: 3098.11
train mean loss: 3284.43
epoch train time: 0:00:12.958744
elapsed time: 0:00:12.975434
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 15:23:56.738332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2811.70
 ---- batch: 020 ----
mean loss: 2611.18
 ---- batch: 030 ----
mean loss: 2495.44
train mean loss: 2610.26
epoch train time: 0:00:00.592870
elapsed time: 0:00:13.568575
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 15:23:57.331540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2317.19
 ---- batch: 020 ----
mean loss: 2211.24
 ---- batch: 030 ----
mean loss: 2135.56
train mean loss: 2198.81
epoch train time: 0:00:00.581650
elapsed time: 0:00:14.150616
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 15:23:57.913625
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2012.06
 ---- batch: 020 ----
mean loss: 1934.11
 ---- batch: 030 ----
mean loss: 1902.10
train mean loss: 1940.16
epoch train time: 0:00:00.595603
elapsed time: 0:00:14.746867
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 15:23:58.509838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1805.72
 ---- batch: 020 ----
mean loss: 1745.11
 ---- batch: 030 ----
mean loss: 1789.07
train mean loss: 1770.27
epoch train time: 0:00:00.692356
elapsed time: 0:00:15.439578
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 15:23:59.202535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1680.59
 ---- batch: 020 ----
mean loss: 1633.83
 ---- batch: 030 ----
mean loss: 1622.35
train mean loss: 1639.78
epoch train time: 0:00:00.596041
elapsed time: 0:00:16.035971
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 15:23:59.798980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1583.52
 ---- batch: 020 ----
mean loss: 1526.40
 ---- batch: 030 ----
mean loss: 1501.67
train mean loss: 1530.62
epoch train time: 0:00:00.579454
elapsed time: 0:00:16.615811
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 15:24:00.378763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1466.65
 ---- batch: 020 ----
mean loss: 1454.74
 ---- batch: 030 ----
mean loss: 1396.92
train mean loss: 1434.40
epoch train time: 0:00:00.621934
elapsed time: 0:00:17.238268
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 15:24:01.001236
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1375.74
 ---- batch: 020 ----
mean loss: 1346.74
 ---- batch: 030 ----
mean loss: 1345.17
train mean loss: 1349.00
epoch train time: 0:00:00.597153
elapsed time: 0:00:17.835785
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 15:24:01.598741
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1315.48
 ---- batch: 020 ----
mean loss: 1271.33
 ---- batch: 030 ----
mean loss: 1254.39
train mean loss: 1271.92
epoch train time: 0:00:00.580109
elapsed time: 0:00:18.416221
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 15:24:02.179178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1210.31
 ---- batch: 020 ----
mean loss: 1215.69
 ---- batch: 030 ----
mean loss: 1173.34
train mean loss: 1194.72
epoch train time: 0:00:00.573502
elapsed time: 0:00:18.990058
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 15:24:02.753012
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1156.64
 ---- batch: 020 ----
mean loss: 1140.34
 ---- batch: 030 ----
mean loss: 1102.42
train mean loss: 1133.47
epoch train time: 0:00:00.591041
elapsed time: 0:00:19.581452
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 15:24:03.344411
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1093.18
 ---- batch: 020 ----
mean loss: 1059.40
 ---- batch: 030 ----
mean loss: 1068.33
train mean loss: 1064.69
epoch train time: 0:00:00.597702
elapsed time: 0:00:20.179479
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 15:24:03.942456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1046.66
 ---- batch: 020 ----
mean loss: 1016.79
 ---- batch: 030 ----
mean loss: 981.88
train mean loss: 1007.97
epoch train time: 0:00:00.570324
elapsed time: 0:00:20.750171
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 15:24:04.513126
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 964.82
 ---- batch: 020 ----
mean loss: 961.92
 ---- batch: 030 ----
mean loss: 938.02
train mean loss: 951.49
epoch train time: 0:00:00.584955
elapsed time: 0:00:21.335474
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 15:24:05.098436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 908.89
 ---- batch: 020 ----
mean loss: 895.61
 ---- batch: 030 ----
mean loss: 895.50
train mean loss: 896.07
epoch train time: 0:00:00.580733
elapsed time: 0:00:21.916647
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 15:24:05.679618
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 863.31
 ---- batch: 020 ----
mean loss: 851.22
 ---- batch: 030 ----
mean loss: 832.72
train mean loss: 844.74
epoch train time: 0:00:00.584762
elapsed time: 0:00:22.501836
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 15:24:06.264787
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 806.37
 ---- batch: 020 ----
mean loss: 804.46
 ---- batch: 030 ----
mean loss: 777.20
train mean loss: 795.15
epoch train time: 0:00:00.593877
elapsed time: 0:00:23.096089
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 15:24:06.859045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 771.32
 ---- batch: 020 ----
mean loss: 754.19
 ---- batch: 030 ----
mean loss: 734.63
train mean loss: 748.69
epoch train time: 0:00:00.593548
elapsed time: 0:00:23.690042
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 15:24:07.453005
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 720.65
 ---- batch: 020 ----
mean loss: 703.98
 ---- batch: 030 ----
mean loss: 692.98
train mean loss: 703.09
epoch train time: 0:00:00.593380
elapsed time: 0:00:24.283837
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 15:24:08.046798
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 662.80
 ---- batch: 020 ----
mean loss: 666.65
 ---- batch: 030 ----
mean loss: 654.58
train mean loss: 662.23
epoch train time: 0:00:00.583733
elapsed time: 0:00:24.867961
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 15:24:08.630920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 630.77
 ---- batch: 020 ----
mean loss: 637.55
 ---- batch: 030 ----
mean loss: 611.32
train mean loss: 620.40
epoch train time: 0:00:00.587373
elapsed time: 0:00:25.455766
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 15:24:09.218735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 604.27
 ---- batch: 020 ----
mean loss: 586.37
 ---- batch: 030 ----
mean loss: 570.86
train mean loss: 581.63
epoch train time: 0:00:00.584905
elapsed time: 0:00:26.041057
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 15:24:09.804015
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 552.34
 ---- batch: 020 ----
mean loss: 560.82
 ---- batch: 030 ----
mean loss: 550.71
train mean loss: 549.84
epoch train time: 0:00:00.605665
elapsed time: 0:00:26.647058
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 15:24:10.410021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 536.91
 ---- batch: 020 ----
mean loss: 529.17
 ---- batch: 030 ----
mean loss: 507.38
train mean loss: 518.99
epoch train time: 0:00:00.615448
elapsed time: 0:00:27.262876
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 15:24:11.025846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 493.21
 ---- batch: 020 ----
mean loss: 500.83
 ---- batch: 030 ----
mean loss: 486.61
train mean loss: 490.79
epoch train time: 0:00:00.582719
elapsed time: 0:00:27.845963
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 15:24:11.608918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 478.43
 ---- batch: 020 ----
mean loss: 466.42
 ---- batch: 030 ----
mean loss: 445.23
train mean loss: 463.53
epoch train time: 0:00:00.584479
elapsed time: 0:00:28.430796
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 15:24:12.193777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 445.21
 ---- batch: 020 ----
mean loss: 436.71
 ---- batch: 030 ----
mean loss: 426.00
train mean loss: 434.68
epoch train time: 0:00:00.585912
elapsed time: 0:00:29.017062
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 15:24:12.780014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 414.45
 ---- batch: 020 ----
mean loss: 428.99
 ---- batch: 030 ----
mean loss: 400.43
train mean loss: 411.64
epoch train time: 0:00:00.581731
elapsed time: 0:00:29.599132
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 15:24:13.362088
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 397.86
 ---- batch: 020 ----
mean loss: 392.41
 ---- batch: 030 ----
mean loss: 383.51
train mean loss: 391.10
epoch train time: 0:00:00.586945
elapsed time: 0:00:30.186572
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 15:24:13.949520
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.88
 ---- batch: 020 ----
mean loss: 367.09
 ---- batch: 030 ----
mean loss: 374.77
train mean loss: 370.37
epoch train time: 0:00:00.593458
elapsed time: 0:00:30.780502
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 15:24:14.543480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 356.23
 ---- batch: 020 ----
mean loss: 349.17
 ---- batch: 030 ----
mean loss: 345.89
train mean loss: 348.15
epoch train time: 0:00:00.597538
elapsed time: 0:00:31.378517
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 15:24:15.141495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 341.18
 ---- batch: 020 ----
mean loss: 331.51
 ---- batch: 030 ----
mean loss: 321.84
train mean loss: 332.83
epoch train time: 0:00:00.601282
elapsed time: 0:00:31.980198
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 15:24:15.743180
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 322.17
 ---- batch: 020 ----
mean loss: 326.00
 ---- batch: 030 ----
mean loss: 309.76
train mean loss: 316.53
epoch train time: 0:00:00.585909
elapsed time: 0:00:32.566527
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 15:24:16.329492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.08
 ---- batch: 020 ----
mean loss: 302.22
 ---- batch: 030 ----
mean loss: 295.01
train mean loss: 297.32
epoch train time: 0:00:00.588618
elapsed time: 0:00:33.155483
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 15:24:16.918439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.82
 ---- batch: 020 ----
mean loss: 285.50
 ---- batch: 030 ----
mean loss: 285.63
train mean loss: 286.34
epoch train time: 0:00:00.589727
elapsed time: 0:00:33.745615
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 15:24:17.508569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.79
 ---- batch: 020 ----
mean loss: 269.82
 ---- batch: 030 ----
mean loss: 267.10
train mean loss: 270.47
epoch train time: 0:00:00.597947
elapsed time: 0:00:34.343899
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 15:24:18.106869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.32
 ---- batch: 020 ----
mean loss: 252.78
 ---- batch: 030 ----
mean loss: 255.81
train mean loss: 256.61
epoch train time: 0:00:00.595751
elapsed time: 0:00:34.940042
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 15:24:18.702994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.94
 ---- batch: 020 ----
mean loss: 247.78
 ---- batch: 030 ----
mean loss: 246.61
train mean loss: 247.88
epoch train time: 0:00:00.603893
elapsed time: 0:00:35.544326
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 15:24:19.307279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.58
 ---- batch: 020 ----
mean loss: 235.97
 ---- batch: 030 ----
mean loss: 236.34
train mean loss: 237.09
epoch train time: 0:00:00.594539
elapsed time: 0:00:36.139191
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 15:24:19.902166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.44
 ---- batch: 020 ----
mean loss: 221.89
 ---- batch: 030 ----
mean loss: 226.47
train mean loss: 226.34
epoch train time: 0:00:00.589978
elapsed time: 0:00:36.729529
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 15:24:20.492494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.42
 ---- batch: 020 ----
mean loss: 212.79
 ---- batch: 030 ----
mean loss: 220.35
train mean loss: 217.59
epoch train time: 0:00:00.589448
elapsed time: 0:00:37.319326
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 15:24:21.082325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.32
 ---- batch: 020 ----
mean loss: 206.12
 ---- batch: 030 ----
mean loss: 200.71
train mean loss: 207.16
epoch train time: 0:00:00.585565
elapsed time: 0:00:37.905410
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 15:24:21.668377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.67
 ---- batch: 020 ----
mean loss: 199.15
 ---- batch: 030 ----
mean loss: 200.37
train mean loss: 199.24
epoch train time: 0:00:00.599165
elapsed time: 0:00:38.504979
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 15:24:22.267947
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.74
 ---- batch: 020 ----
mean loss: 191.04
 ---- batch: 030 ----
mean loss: 192.79
train mean loss: 192.02
epoch train time: 0:00:00.596581
elapsed time: 0:00:39.101965
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 15:24:22.864920
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.73
 ---- batch: 020 ----
mean loss: 181.03
 ---- batch: 030 ----
mean loss: 184.77
train mean loss: 184.92
epoch train time: 0:00:00.598769
elapsed time: 0:00:39.701086
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 15:24:23.464045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.54
 ---- batch: 020 ----
mean loss: 185.79
 ---- batch: 030 ----
mean loss: 176.91
train mean loss: 178.88
epoch train time: 0:00:00.597762
elapsed time: 0:00:40.299251
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 15:24:24.062206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 171.47
 ---- batch: 020 ----
mean loss: 172.98
 ---- batch: 030 ----
mean loss: 171.25
train mean loss: 171.17
epoch train time: 0:00:00.588634
elapsed time: 0:00:40.888267
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 15:24:24.651222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 168.33
 ---- batch: 020 ----
mean loss: 163.49
 ---- batch: 030 ----
mean loss: 166.83
train mean loss: 165.11
epoch train time: 0:00:00.580272
elapsed time: 0:00:41.468954
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 15:24:25.231918
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.69
 ---- batch: 020 ----
mean loss: 166.88
 ---- batch: 030 ----
mean loss: 160.23
train mean loss: 162.53
epoch train time: 0:00:00.579822
elapsed time: 0:00:42.049225
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 15:24:25.812196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.83
 ---- batch: 020 ----
mean loss: 154.33
 ---- batch: 030 ----
mean loss: 154.84
train mean loss: 155.24
epoch train time: 0:00:00.581850
elapsed time: 0:00:42.631469
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 15:24:26.394426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.02
 ---- batch: 020 ----
mean loss: 154.48
 ---- batch: 030 ----
mean loss: 147.26
train mean loss: 151.30
epoch train time: 0:00:00.582615
elapsed time: 0:00:43.214472
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 15:24:26.977429
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.78
 ---- batch: 020 ----
mean loss: 146.18
 ---- batch: 030 ----
mean loss: 147.55
train mean loss: 148.31
epoch train time: 0:00:00.595359
elapsed time: 0:00:43.810293
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 15:24:27.573279
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 139.07
 ---- batch: 020 ----
mean loss: 147.37
 ---- batch: 030 ----
mean loss: 143.98
train mean loss: 143.43
epoch train time: 0:00:00.581717
elapsed time: 0:00:44.392559
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 15:24:28.155554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.61
 ---- batch: 020 ----
mean loss: 136.35
 ---- batch: 030 ----
mean loss: 140.55
train mean loss: 139.34
epoch train time: 0:00:00.612280
elapsed time: 0:00:45.005331
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 15:24:28.768294
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.93
 ---- batch: 020 ----
mean loss: 139.61
 ---- batch: 030 ----
mean loss: 132.71
train mean loss: 136.95
epoch train time: 0:00:00.592822
elapsed time: 0:00:45.598586
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 15:24:29.361547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.71
 ---- batch: 020 ----
mean loss: 134.29
 ---- batch: 030 ----
mean loss: 134.07
train mean loss: 134.01
epoch train time: 0:00:00.609147
elapsed time: 0:00:46.208208
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 15:24:29.971190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 129.23
 ---- batch: 020 ----
mean loss: 130.57
 ---- batch: 030 ----
mean loss: 131.41
train mean loss: 130.05
epoch train time: 0:00:00.613971
elapsed time: 0:00:46.822683
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 15:24:30.585682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.64
 ---- batch: 020 ----
mean loss: 131.50
 ---- batch: 030 ----
mean loss: 127.83
train mean loss: 128.21
epoch train time: 0:00:00.603711
elapsed time: 0:00:47.426967
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 15:24:31.189927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.39
 ---- batch: 020 ----
mean loss: 125.22
 ---- batch: 030 ----
mean loss: 125.23
train mean loss: 126.00
epoch train time: 0:00:00.629680
elapsed time: 0:00:48.057051
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 15:24:31.820031
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 123.64
 ---- batch: 020 ----
mean loss: 120.77
 ---- batch: 030 ----
mean loss: 122.11
train mean loss: 121.82
epoch train time: 0:00:00.614825
elapsed time: 0:00:48.672361
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 15:24:32.435329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.28
 ---- batch: 020 ----
mean loss: 118.93
 ---- batch: 030 ----
mean loss: 121.51
train mean loss: 119.98
epoch train time: 0:00:00.603129
elapsed time: 0:00:49.275894
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 15:24:33.038854
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.28
 ---- batch: 020 ----
mean loss: 114.97
 ---- batch: 030 ----
mean loss: 114.54
train mean loss: 116.00
epoch train time: 0:00:00.580074
elapsed time: 0:00:49.856381
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 15:24:33.619347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.86
 ---- batch: 020 ----
mean loss: 116.06
 ---- batch: 030 ----
mean loss: 117.56
train mean loss: 116.45
epoch train time: 0:00:00.599788
elapsed time: 0:00:50.456586
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 15:24:34.219544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.67
 ---- batch: 020 ----
mean loss: 114.11
 ---- batch: 030 ----
mean loss: 112.06
train mean loss: 114.38
epoch train time: 0:00:00.611018
elapsed time: 0:00:51.068029
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 15:24:34.830992
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 110.48
 ---- batch: 020 ----
mean loss: 112.73
 ---- batch: 030 ----
mean loss: 113.70
train mean loss: 112.72
epoch train time: 0:00:00.593815
elapsed time: 0:00:51.662263
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 15:24:35.425225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.00
 ---- batch: 020 ----
mean loss: 110.17
 ---- batch: 030 ----
mean loss: 110.41
train mean loss: 110.95
epoch train time: 0:00:00.592177
elapsed time: 0:00:52.254888
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 15:24:36.017878
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.14
 ---- batch: 020 ----
mean loss: 108.56
 ---- batch: 030 ----
mean loss: 110.05
train mean loss: 109.21
epoch train time: 0:00:00.591835
elapsed time: 0:00:52.847292
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 15:24:36.610293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.94
 ---- batch: 020 ----
mean loss: 105.53
 ---- batch: 030 ----
mean loss: 103.12
train mean loss: 107.17
epoch train time: 0:00:00.611223
elapsed time: 0:00:53.458957
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 15:24:37.221974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.93
 ---- batch: 020 ----
mean loss: 104.29
 ---- batch: 030 ----
mean loss: 105.80
train mean loss: 105.71
epoch train time: 0:00:00.600990
elapsed time: 0:00:54.060393
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 15:24:37.823354
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.93
 ---- batch: 020 ----
mean loss: 104.28
 ---- batch: 030 ----
mean loss: 103.89
train mean loss: 104.19
epoch train time: 0:00:00.601462
elapsed time: 0:00:54.662300
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 15:24:38.425288
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.96
 ---- batch: 020 ----
mean loss: 103.66
 ---- batch: 030 ----
mean loss: 100.50
train mean loss: 102.18
epoch train time: 0:00:00.615620
elapsed time: 0:00:55.278409
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 15:24:39.041375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.81
 ---- batch: 020 ----
mean loss: 101.14
 ---- batch: 030 ----
mean loss: 103.99
train mean loss: 101.18
epoch train time: 0:00:00.619288
elapsed time: 0:00:55.898246
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 15:24:39.661246
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.80
 ---- batch: 020 ----
mean loss: 104.26
 ---- batch: 030 ----
mean loss: 100.03
train mean loss: 100.67
epoch train time: 0:00:00.600810
elapsed time: 0:00:56.499503
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 15:24:40.262455
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.36
 ---- batch: 020 ----
mean loss: 98.36
 ---- batch: 030 ----
mean loss: 98.86
train mean loss: 98.83
epoch train time: 0:00:00.611885
elapsed time: 0:00:57.111792
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 15:24:40.874757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.33
 ---- batch: 020 ----
mean loss: 97.53
 ---- batch: 030 ----
mean loss: 98.59
train mean loss: 98.25
epoch train time: 0:00:00.589570
elapsed time: 0:00:57.701747
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 15:24:41.464721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.83
 ---- batch: 020 ----
mean loss: 94.48
 ---- batch: 030 ----
mean loss: 93.19
train mean loss: 96.98
epoch train time: 0:00:00.610291
elapsed time: 0:00:58.312474
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 15:24:42.075449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.49
 ---- batch: 020 ----
mean loss: 96.11
 ---- batch: 030 ----
mean loss: 95.01
train mean loss: 96.24
epoch train time: 0:00:00.614316
elapsed time: 0:00:58.927305
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 15:24:42.690285
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.45
 ---- batch: 020 ----
mean loss: 91.66
 ---- batch: 030 ----
mean loss: 98.01
train mean loss: 95.13
epoch train time: 0:00:00.592643
elapsed time: 0:00:59.520360
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 15:24:43.283320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.52
 ---- batch: 020 ----
mean loss: 96.30
 ---- batch: 030 ----
mean loss: 95.82
train mean loss: 95.25
epoch train time: 0:00:00.593552
elapsed time: 0:01:00.114336
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 15:24:43.877296
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.40
 ---- batch: 020 ----
mean loss: 91.13
 ---- batch: 030 ----
mean loss: 94.65
train mean loss: 94.48
epoch train time: 0:00:00.598567
elapsed time: 0:01:00.713332
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 15:24:44.476316
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.17
 ---- batch: 020 ----
mean loss: 93.98
 ---- batch: 030 ----
mean loss: 94.67
train mean loss: 92.84
epoch train time: 0:00:00.624921
elapsed time: 0:01:01.338745
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 15:24:45.101729
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.23
 ---- batch: 020 ----
mean loss: 94.21
 ---- batch: 030 ----
mean loss: 89.10
train mean loss: 91.52
epoch train time: 0:00:00.609631
elapsed time: 0:01:01.948846
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 15:24:45.711812
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.34
 ---- batch: 020 ----
mean loss: 88.68
 ---- batch: 030 ----
mean loss: 92.25
train mean loss: 90.84
epoch train time: 0:00:00.589382
elapsed time: 0:01:02.538696
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 15:24:46.301696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.07
 ---- batch: 020 ----
mean loss: 93.54
 ---- batch: 030 ----
mean loss: 89.25
train mean loss: 89.98
epoch train time: 0:00:00.588642
elapsed time: 0:01:03.127747
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 15:24:46.890715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.35
 ---- batch: 020 ----
mean loss: 91.28
 ---- batch: 030 ----
mean loss: 86.90
train mean loss: 88.90
epoch train time: 0:00:00.613209
elapsed time: 0:01:03.741431
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 15:24:47.504395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.10
 ---- batch: 020 ----
mean loss: 88.18
 ---- batch: 030 ----
mean loss: 91.97
train mean loss: 89.46
epoch train time: 0:00:00.603603
elapsed time: 0:01:04.345498
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 15:24:48.108496
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.43
 ---- batch: 020 ----
mean loss: 87.99
 ---- batch: 030 ----
mean loss: 84.90
train mean loss: 88.37
epoch train time: 0:00:00.579526
elapsed time: 0:01:04.925474
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 15:24:48.688444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.92
 ---- batch: 020 ----
mean loss: 85.22
 ---- batch: 030 ----
mean loss: 87.00
train mean loss: 87.33
epoch train time: 0:00:00.602533
elapsed time: 0:01:05.528416
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 15:24:49.291370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.67
 ---- batch: 020 ----
mean loss: 85.69
 ---- batch: 030 ----
mean loss: 88.02
train mean loss: 87.20
epoch train time: 0:00:00.600199
elapsed time: 0:01:06.129029
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 15:24:49.891995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.57
 ---- batch: 020 ----
mean loss: 86.85
 ---- batch: 030 ----
mean loss: 87.66
train mean loss: 86.95
epoch train time: 0:00:00.612181
elapsed time: 0:01:06.741638
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 15:24:50.504596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.18
 ---- batch: 020 ----
mean loss: 88.20
 ---- batch: 030 ----
mean loss: 85.15
train mean loss: 86.38
epoch train time: 0:00:00.603827
elapsed time: 0:01:07.345832
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 15:24:51.108789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.82
 ---- batch: 020 ----
mean loss: 84.99
 ---- batch: 030 ----
mean loss: 84.59
train mean loss: 84.81
epoch train time: 0:00:00.588323
elapsed time: 0:01:07.934653
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 15:24:51.697658
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.99
 ---- batch: 020 ----
mean loss: 84.05
 ---- batch: 030 ----
mean loss: 85.54
train mean loss: 85.07
epoch train time: 0:00:00.590987
elapsed time: 0:01:08.526076
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 15:24:52.289070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.51
 ---- batch: 020 ----
mean loss: 84.28
 ---- batch: 030 ----
mean loss: 83.56
train mean loss: 84.30
epoch train time: 0:00:00.592858
elapsed time: 0:01:09.119478
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 15:24:52.882436
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.83
 ---- batch: 020 ----
mean loss: 80.34
 ---- batch: 030 ----
mean loss: 87.88
train mean loss: 84.28
epoch train time: 0:00:00.594269
elapsed time: 0:01:09.714116
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 15:24:53.477067
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.55
 ---- batch: 020 ----
mean loss: 81.82
 ---- batch: 030 ----
mean loss: 86.10
train mean loss: 83.40
epoch train time: 0:00:00.585392
elapsed time: 0:01:10.299851
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 15:24:54.062804
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.76
 ---- batch: 020 ----
mean loss: 86.31
 ---- batch: 030 ----
mean loss: 82.30
train mean loss: 83.44
epoch train time: 0:00:00.582761
elapsed time: 0:01:10.883008
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 15:24:54.645966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.83
 ---- batch: 020 ----
mean loss: 82.93
 ---- batch: 030 ----
mean loss: 81.33
train mean loss: 82.66
epoch train time: 0:00:00.624326
elapsed time: 0:01:11.507696
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 15:24:55.270670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.61
 ---- batch: 020 ----
mean loss: 82.66
 ---- batch: 030 ----
mean loss: 79.67
train mean loss: 81.86
epoch train time: 0:00:00.606636
elapsed time: 0:01:12.114703
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 15:24:55.877682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.68
 ---- batch: 020 ----
mean loss: 82.18
 ---- batch: 030 ----
mean loss: 78.39
train mean loss: 81.28
epoch train time: 0:00:00.583875
elapsed time: 0:01:12.699099
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 15:24:56.462056
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.72
 ---- batch: 020 ----
mean loss: 80.80
 ---- batch: 030 ----
mean loss: 80.44
train mean loss: 81.00
epoch train time: 0:00:00.602552
elapsed time: 0:01:13.302089
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 15:24:57.065043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.34
 ---- batch: 020 ----
mean loss: 81.44
 ---- batch: 030 ----
mean loss: 78.97
train mean loss: 80.29
epoch train time: 0:00:00.578176
elapsed time: 0:01:13.880588
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 15:24:57.643566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.90
 ---- batch: 020 ----
mean loss: 80.85
 ---- batch: 030 ----
mean loss: 79.43
train mean loss: 79.59
epoch train time: 0:00:00.596601
elapsed time: 0:01:14.477553
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 15:24:58.240528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.48
 ---- batch: 020 ----
mean loss: 78.47
 ---- batch: 030 ----
mean loss: 77.70
train mean loss: 79.60
epoch train time: 0:00:00.600514
elapsed time: 0:01:15.078475
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 15:24:58.841456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.92
 ---- batch: 020 ----
mean loss: 79.70
 ---- batch: 030 ----
mean loss: 81.35
train mean loss: 79.98
epoch train time: 0:00:00.573070
elapsed time: 0:01:15.651945
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 15:24:59.414900
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.17
 ---- batch: 020 ----
mean loss: 80.51
 ---- batch: 030 ----
mean loss: 77.18
train mean loss: 79.46
epoch train time: 0:00:00.598219
elapsed time: 0:01:16.250586
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 15:25:00.013484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.33
 ---- batch: 020 ----
mean loss: 76.32
 ---- batch: 030 ----
mean loss: 79.92
train mean loss: 77.68
epoch train time: 0:00:00.579357
elapsed time: 0:01:16.830226
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 15:25:00.593192
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 80.17
 ---- batch: 020 ----
mean loss: 77.46
 ---- batch: 030 ----
mean loss: 73.78
train mean loss: 76.82
epoch train time: 0:00:00.577518
elapsed time: 0:01:17.408132
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 15:25:01.171081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.07
 ---- batch: 020 ----
mean loss: 76.57
 ---- batch: 030 ----
mean loss: 75.74
train mean loss: 77.00
epoch train time: 0:00:00.589039
elapsed time: 0:01:17.997496
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 15:25:01.760442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.92
 ---- batch: 020 ----
mean loss: 76.60
 ---- batch: 030 ----
mean loss: 80.41
train mean loss: 77.13
epoch train time: 0:00:00.587585
elapsed time: 0:01:18.585413
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 15:25:02.348364
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.49
 ---- batch: 020 ----
mean loss: 75.03
 ---- batch: 030 ----
mean loss: 74.44
train mean loss: 76.01
epoch train time: 0:00:00.583931
elapsed time: 0:01:19.169701
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 15:25:02.932664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.67
 ---- batch: 020 ----
mean loss: 76.81
 ---- batch: 030 ----
mean loss: 75.04
train mean loss: 75.92
epoch train time: 0:00:00.585480
elapsed time: 0:01:19.755518
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 15:25:03.518472
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.98
 ---- batch: 020 ----
mean loss: 72.11
 ---- batch: 030 ----
mean loss: 74.63
train mean loss: 74.56
epoch train time: 0:00:00.595919
elapsed time: 0:01:20.351836
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 15:25:04.114839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.17
 ---- batch: 020 ----
mean loss: 72.84
 ---- batch: 030 ----
mean loss: 74.93
train mean loss: 74.36
epoch train time: 0:00:00.589580
elapsed time: 0:01:20.941822
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 15:25:04.704792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.81
 ---- batch: 020 ----
mean loss: 74.43
 ---- batch: 030 ----
mean loss: 74.98
train mean loss: 74.68
epoch train time: 0:00:00.574510
elapsed time: 0:01:21.516686
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 15:25:05.279639
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.13
 ---- batch: 020 ----
mean loss: 73.63
 ---- batch: 030 ----
mean loss: 75.78
train mean loss: 74.02
epoch train time: 0:00:00.587177
elapsed time: 0:01:22.104254
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 15:25:05.867257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.87
 ---- batch: 020 ----
mean loss: 73.99
 ---- batch: 030 ----
mean loss: 74.33
train mean loss: 73.67
epoch train time: 0:00:00.595100
elapsed time: 0:01:22.699742
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 15:25:06.462706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.35
 ---- batch: 020 ----
mean loss: 72.72
 ---- batch: 030 ----
mean loss: 73.85
train mean loss: 73.15
epoch train time: 0:00:00.582656
elapsed time: 0:01:23.282767
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 15:25:07.045772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.98
 ---- batch: 020 ----
mean loss: 73.45
 ---- batch: 030 ----
mean loss: 73.25
train mean loss: 73.18
epoch train time: 0:00:00.583063
elapsed time: 0:01:23.866208
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 15:25:07.629179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.66
 ---- batch: 020 ----
mean loss: 73.77
 ---- batch: 030 ----
mean loss: 72.27
train mean loss: 73.33
epoch train time: 0:00:00.584004
elapsed time: 0:01:24.450584
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 15:25:08.213542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.47
 ---- batch: 020 ----
mean loss: 72.16
 ---- batch: 030 ----
mean loss: 73.45
train mean loss: 72.19
epoch train time: 0:00:00.613986
elapsed time: 0:01:25.064954
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 15:25:08.828027
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.62
 ---- batch: 020 ----
mean loss: 73.33
 ---- batch: 030 ----
mean loss: 70.01
train mean loss: 71.00
epoch train time: 0:00:00.574440
elapsed time: 0:01:25.639832
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 15:25:09.402782
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.96
 ---- batch: 020 ----
mean loss: 71.38
 ---- batch: 030 ----
mean loss: 70.64
train mean loss: 71.38
epoch train time: 0:00:00.612074
elapsed time: 0:01:26.252275
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 15:25:10.015266
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.30
 ---- batch: 020 ----
mean loss: 68.81
 ---- batch: 030 ----
mean loss: 71.26
train mean loss: 70.23
epoch train time: 0:00:00.589958
elapsed time: 0:01:26.842595
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 15:25:10.605555
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.34
 ---- batch: 020 ----
mean loss: 70.08
 ---- batch: 030 ----
mean loss: 69.36
train mean loss: 70.46
epoch train time: 0:00:00.595645
elapsed time: 0:01:27.438596
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 15:25:11.201561
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.28
 ---- batch: 020 ----
mean loss: 68.94
 ---- batch: 030 ----
mean loss: 70.62
train mean loss: 69.69
epoch train time: 0:00:00.587779
elapsed time: 0:01:28.026845
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 15:25:11.789767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.82
 ---- batch: 020 ----
mean loss: 69.49
 ---- batch: 030 ----
mean loss: 69.62
train mean loss: 69.20
epoch train time: 0:00:00.585482
elapsed time: 0:01:28.612649
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 15:25:12.375653
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.60
 ---- batch: 020 ----
mean loss: 68.75
 ---- batch: 030 ----
mean loss: 67.72
train mean loss: 68.77
epoch train time: 0:00:00.607658
elapsed time: 0:01:29.220704
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 15:25:12.983665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.97
 ---- batch: 020 ----
mean loss: 70.18
 ---- batch: 030 ----
mean loss: 68.68
train mean loss: 68.01
epoch train time: 0:00:00.591431
elapsed time: 0:01:29.812506
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 15:25:13.575458
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.87
 ---- batch: 020 ----
mean loss: 67.23
 ---- batch: 030 ----
mean loss: 66.56
train mean loss: 68.16
epoch train time: 0:00:00.592711
elapsed time: 0:01:30.405573
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 15:25:14.168542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.55
 ---- batch: 020 ----
mean loss: 66.84
 ---- batch: 030 ----
mean loss: 66.97
train mean loss: 67.71
epoch train time: 0:00:00.586162
elapsed time: 0:01:30.992086
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 15:25:14.755081
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.83
 ---- batch: 020 ----
mean loss: 69.59
 ---- batch: 030 ----
mean loss: 64.22
train mean loss: 67.10
epoch train time: 0:00:00.576891
elapsed time: 0:01:31.569345
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 15:25:15.332329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.96
 ---- batch: 020 ----
mean loss: 67.35
 ---- batch: 030 ----
mean loss: 67.59
train mean loss: 66.77
epoch train time: 0:00:00.583140
elapsed time: 0:01:32.152890
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 15:25:15.915852
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.25
 ---- batch: 020 ----
mean loss: 67.50
 ---- batch: 030 ----
mean loss: 64.47
train mean loss: 65.54
epoch train time: 0:00:00.595672
elapsed time: 0:01:32.748984
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 15:25:16.511955
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.18
 ---- batch: 020 ----
mean loss: 64.55
 ---- batch: 030 ----
mean loss: 65.92
train mean loss: 65.48
epoch train time: 0:00:00.588446
elapsed time: 0:01:33.337862
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 15:25:17.100876
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.83
 ---- batch: 020 ----
mean loss: 66.28
 ---- batch: 030 ----
mean loss: 65.45
train mean loss: 66.23
epoch train time: 0:00:00.583031
elapsed time: 0:01:33.921306
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 15:25:17.684280
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.49
 ---- batch: 020 ----
mean loss: 66.30
 ---- batch: 030 ----
mean loss: 63.01
train mean loss: 65.20
epoch train time: 0:00:00.582220
elapsed time: 0:01:34.503912
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 15:25:18.266869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.41
 ---- batch: 020 ----
mean loss: 67.46
 ---- batch: 030 ----
mean loss: 64.87
train mean loss: 65.47
epoch train time: 0:00:00.587749
elapsed time: 0:01:35.092025
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 15:25:18.854980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.90
 ---- batch: 020 ----
mean loss: 65.11
 ---- batch: 030 ----
mean loss: 63.52
train mean loss: 64.00
epoch train time: 0:00:00.583765
elapsed time: 0:01:35.676192
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 15:25:19.439179
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.10
 ---- batch: 020 ----
mean loss: 61.51
 ---- batch: 030 ----
mean loss: 65.28
train mean loss: 64.11
epoch train time: 0:00:00.583189
elapsed time: 0:01:36.259782
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 15:25:20.022734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.81
 ---- batch: 020 ----
mean loss: 62.54
 ---- batch: 030 ----
mean loss: 63.46
train mean loss: 63.25
epoch train time: 0:00:00.591981
elapsed time: 0:01:36.852090
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 15:25:20.615053
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.45
 ---- batch: 020 ----
mean loss: 63.74
 ---- batch: 030 ----
mean loss: 65.66
train mean loss: 63.44
epoch train time: 0:00:00.607703
elapsed time: 0:01:37.460135
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 15:25:21.223088
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.72
 ---- batch: 020 ----
mean loss: 62.17
 ---- batch: 030 ----
mean loss: 63.06
train mean loss: 62.67
epoch train time: 0:00:00.596333
elapsed time: 0:01:38.056872
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 15:25:21.819829
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.13
 ---- batch: 020 ----
mean loss: 62.49
 ---- batch: 030 ----
mean loss: 62.44
train mean loss: 62.64
epoch train time: 0:00:00.587912
elapsed time: 0:01:38.645203
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 15:25:22.408167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.40
 ---- batch: 020 ----
mean loss: 62.43
 ---- batch: 030 ----
mean loss: 59.31
train mean loss: 61.91
epoch train time: 0:00:00.595299
elapsed time: 0:01:39.240918
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 15:25:23.003873
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.46
 ---- batch: 020 ----
mean loss: 63.29
 ---- batch: 030 ----
mean loss: 58.35
train mean loss: 60.86
epoch train time: 0:00:00.589018
elapsed time: 0:01:39.830294
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 15:25:23.593264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.76
 ---- batch: 020 ----
mean loss: 60.53
 ---- batch: 030 ----
mean loss: 59.42
train mean loss: 59.95
epoch train time: 0:00:00.592686
elapsed time: 0:01:40.423432
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 15:25:24.186387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.67
 ---- batch: 020 ----
mean loss: 61.33
 ---- batch: 030 ----
mean loss: 59.10
train mean loss: 60.68
epoch train time: 0:00:00.581610
elapsed time: 0:01:41.005422
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 15:25:24.768340
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.12
 ---- batch: 020 ----
mean loss: 61.69
 ---- batch: 030 ----
mean loss: 59.21
train mean loss: 60.38
epoch train time: 0:00:00.624406
elapsed time: 0:01:41.630127
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 15:25:25.393077
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.03
 ---- batch: 020 ----
mean loss: 59.56
 ---- batch: 030 ----
mean loss: 58.15
train mean loss: 59.15
epoch train time: 0:00:00.594009
elapsed time: 0:01:42.224473
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 15:25:25.987438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.43
 ---- batch: 020 ----
mean loss: 59.81
 ---- batch: 030 ----
mean loss: 60.66
train mean loss: 58.84
epoch train time: 0:00:00.585592
elapsed time: 0:01:42.810451
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 15:25:26.573406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.32
 ---- batch: 020 ----
mean loss: 61.10
 ---- batch: 030 ----
mean loss: 57.88
train mean loss: 58.93
epoch train time: 0:00:00.590401
elapsed time: 0:01:43.401172
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 15:25:27.164123
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.12
 ---- batch: 020 ----
mean loss: 58.17
 ---- batch: 030 ----
mean loss: 60.44
train mean loss: 58.42
epoch train time: 0:00:00.586274
elapsed time: 0:01:43.987796
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 15:25:27.750754
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.41
 ---- batch: 020 ----
mean loss: 59.03
 ---- batch: 030 ----
mean loss: 57.50
train mean loss: 58.07
epoch train time: 0:00:00.595660
elapsed time: 0:01:44.583853
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 15:25:28.346816
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.13
 ---- batch: 020 ----
mean loss: 57.49
 ---- batch: 030 ----
mean loss: 59.35
train mean loss: 57.21
epoch train time: 0:00:00.606215
elapsed time: 0:01:45.190411
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 15:25:28.953363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.07
 ---- batch: 020 ----
mean loss: 57.52
 ---- batch: 030 ----
mean loss: 56.43
train mean loss: 57.12
epoch train time: 0:00:00.586335
elapsed time: 0:01:45.777127
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 15:25:29.540099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.17
 ---- batch: 020 ----
mean loss: 56.48
 ---- batch: 030 ----
mean loss: 56.75
train mean loss: 56.75
epoch train time: 0:00:00.581360
elapsed time: 0:01:46.358836
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 15:25:30.121809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.25
 ---- batch: 020 ----
mean loss: 57.55
 ---- batch: 030 ----
mean loss: 56.37
train mean loss: 56.61
epoch train time: 0:00:00.584520
elapsed time: 0:01:46.943772
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 15:25:30.706720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.04
 ---- batch: 020 ----
mean loss: 54.28
 ---- batch: 030 ----
mean loss: 53.60
train mean loss: 55.01
epoch train time: 0:00:00.594608
elapsed time: 0:01:47.538713
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 15:25:31.301679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.18
 ---- batch: 020 ----
mean loss: 53.62
 ---- batch: 030 ----
mean loss: 57.50
train mean loss: 55.94
epoch train time: 0:00:00.598425
elapsed time: 0:01:48.137468
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 15:25:31.900434
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.54
 ---- batch: 020 ----
mean loss: 54.00
 ---- batch: 030 ----
mean loss: 53.77
train mean loss: 54.82
epoch train time: 0:00:00.583964
elapsed time: 0:01:48.721853
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 15:25:32.484813
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.18
 ---- batch: 020 ----
mean loss: 54.87
 ---- batch: 030 ----
mean loss: 54.01
train mean loss: 53.82
epoch train time: 0:00:00.591615
elapsed time: 0:01:49.313813
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 15:25:33.076807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.15
 ---- batch: 020 ----
mean loss: 54.66
 ---- batch: 030 ----
mean loss: 51.54
train mean loss: 53.40
epoch train time: 0:00:00.587948
elapsed time: 0:01:49.902150
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 15:25:33.665104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.19
 ---- batch: 020 ----
mean loss: 52.05
 ---- batch: 030 ----
mean loss: 53.95
train mean loss: 53.29
epoch train time: 0:00:00.609574
elapsed time: 0:01:50.512090
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 15:25:34.275042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.82
 ---- batch: 020 ----
mean loss: 50.47
 ---- batch: 030 ----
mean loss: 54.49
train mean loss: 52.77
epoch train time: 0:00:00.586724
elapsed time: 0:01:51.099199
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 15:25:34.862155
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.43
 ---- batch: 020 ----
mean loss: 51.06
 ---- batch: 030 ----
mean loss: 51.41
train mean loss: 52.12
epoch train time: 0:00:00.591928
elapsed time: 0:01:51.691580
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 15:25:35.454533
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.39
 ---- batch: 020 ----
mean loss: 51.22
 ---- batch: 030 ----
mean loss: 51.77
train mean loss: 52.83
epoch train time: 0:00:00.614012
elapsed time: 0:01:52.305930
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 15:25:36.068882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.57
 ---- batch: 020 ----
mean loss: 51.29
 ---- batch: 030 ----
mean loss: 50.92
train mean loss: 51.71
epoch train time: 0:00:00.586820
elapsed time: 0:01:52.893409
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 15:25:36.656378
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.68
 ---- batch: 020 ----
mean loss: 53.32
 ---- batch: 030 ----
mean loss: 50.63
train mean loss: 50.66
epoch train time: 0:00:00.598388
elapsed time: 0:01:53.492173
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 15:25:37.255140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.51
 ---- batch: 020 ----
mean loss: 50.93
 ---- batch: 030 ----
mean loss: 50.55
train mean loss: 50.05
epoch train time: 0:00:00.610041
elapsed time: 0:01:54.102559
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 15:25:37.865517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.43
 ---- batch: 020 ----
mean loss: 50.96
 ---- batch: 030 ----
mean loss: 49.60
train mean loss: 50.96
epoch train time: 0:00:00.593929
elapsed time: 0:01:54.696863
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 15:25:38.459828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.70
 ---- batch: 020 ----
mean loss: 47.83
 ---- batch: 030 ----
mean loss: 48.83
train mean loss: 49.23
epoch train time: 0:00:00.586908
elapsed time: 0:01:55.284156
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 15:25:39.047109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.36
 ---- batch: 020 ----
mean loss: 48.35
 ---- batch: 030 ----
mean loss: 50.24
train mean loss: 48.90
epoch train time: 0:00:00.576963
elapsed time: 0:01:55.861536
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 15:25:39.624433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.56
 ---- batch: 020 ----
mean loss: 49.93
 ---- batch: 030 ----
mean loss: 48.98
train mean loss: 47.96
epoch train time: 0:00:00.584880
elapsed time: 0:01:56.446671
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 15:25:40.209656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.93
 ---- batch: 020 ----
mean loss: 48.18
 ---- batch: 030 ----
mean loss: 48.66
train mean loss: 48.13
epoch train time: 0:00:00.580134
elapsed time: 0:01:57.027296
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 15:25:40.790251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.11
 ---- batch: 020 ----
mean loss: 46.98
 ---- batch: 030 ----
mean loss: 49.70
train mean loss: 48.19
epoch train time: 0:00:00.585147
elapsed time: 0:01:57.612870
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 15:25:41.375850
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.28
 ---- batch: 020 ----
mean loss: 48.58
 ---- batch: 030 ----
mean loss: 49.40
train mean loss: 47.30
epoch train time: 0:00:00.604541
elapsed time: 0:01:58.217897
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 15:25:41.980869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.83
 ---- batch: 020 ----
mean loss: 46.06
 ---- batch: 030 ----
mean loss: 46.61
train mean loss: 46.81
epoch train time: 0:00:00.597342
elapsed time: 0:01:58.815707
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 15:25:42.578669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.80
 ---- batch: 020 ----
mean loss: 45.65
 ---- batch: 030 ----
mean loss: 47.51
train mean loss: 46.54
epoch train time: 0:00:00.594533
elapsed time: 0:01:59.410594
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 15:25:43.173568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.57
 ---- batch: 020 ----
mean loss: 46.94
 ---- batch: 030 ----
mean loss: 46.03
train mean loss: 46.00
epoch train time: 0:00:00.592258
elapsed time: 0:02:00.003246
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 15:25:43.766205
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.39
 ---- batch: 020 ----
mean loss: 46.22
 ---- batch: 030 ----
mean loss: 46.64
train mean loss: 46.26
epoch train time: 0:00:00.603721
elapsed time: 0:02:00.607328
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 15:25:44.370298
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.98
 ---- batch: 020 ----
mean loss: 47.56
 ---- batch: 030 ----
mean loss: 44.54
train mean loss: 45.59
epoch train time: 0:00:00.598892
elapsed time: 0:02:01.206592
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 15:25:44.969553
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.79
 ---- batch: 020 ----
mean loss: 45.52
 ---- batch: 030 ----
mean loss: 47.43
train mean loss: 45.90
epoch train time: 0:00:00.593187
elapsed time: 0:02:01.800196
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 15:25:45.563152
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 45.24
 ---- batch: 020 ----
mean loss: 45.58
 ---- batch: 030 ----
mean loss: 44.08
train mean loss: 44.52
epoch train time: 0:00:00.609102
elapsed time: 0:02:02.409652
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 15:25:46.172611
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.92
 ---- batch: 020 ----
mean loss: 44.09
 ---- batch: 030 ----
mean loss: 42.70
train mean loss: 44.34
epoch train time: 0:00:00.590656
elapsed time: 0:02:03.000796
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 15:25:46.763763
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 44.69
 ---- batch: 020 ----
mean loss: 43.89
 ---- batch: 030 ----
mean loss: 43.31
train mean loss: 43.97
epoch train time: 0:00:00.584733
elapsed time: 0:02:03.585929
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 15:25:47.348898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 42.39
 ---- batch: 020 ----
mean loss: 42.92
 ---- batch: 030 ----
mean loss: 45.51
train mean loss: 43.39
epoch train time: 0:00:00.587073
elapsed time: 0:02:04.173387
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 15:25:47.936375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.29
 ---- batch: 020 ----
mean loss: 42.35
 ---- batch: 030 ----
mean loss: 43.80
train mean loss: 42.96
epoch train time: 0:00:00.575965
elapsed time: 0:02:04.749816
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 15:25:48.512777
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.82
 ---- batch: 020 ----
mean loss: 42.93
 ---- batch: 030 ----
mean loss: 43.69
train mean loss: 43.44
epoch train time: 0:00:00.589509
elapsed time: 0:02:05.339704
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 15:25:49.102682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 43.14
 ---- batch: 020 ----
mean loss: 42.21
 ---- batch: 030 ----
mean loss: 43.10
train mean loss: 42.44
epoch train time: 0:00:00.590835
elapsed time: 0:02:05.930953
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 15:25:49.693914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.08
 ---- batch: 020 ----
mean loss: 41.47
 ---- batch: 030 ----
mean loss: 43.59
train mean loss: 41.54
epoch train time: 0:00:00.579112
elapsed time: 0:02:06.510404
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 15:25:50.273355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.91
 ---- batch: 020 ----
mean loss: 40.68
 ---- batch: 030 ----
mean loss: 43.35
train mean loss: 40.83
epoch train time: 0:00:00.604314
elapsed time: 0:02:07.115061
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 15:25:50.878018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.83
 ---- batch: 020 ----
mean loss: 41.24
 ---- batch: 030 ----
mean loss: 41.31
train mean loss: 40.74
epoch train time: 0:00:00.596388
elapsed time: 0:02:07.711786
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 15:25:51.474736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.89
 ---- batch: 020 ----
mean loss: 38.92
 ---- batch: 030 ----
mean loss: 40.12
train mean loss: 40.24
epoch train time: 0:00:00.601549
elapsed time: 0:02:08.313652
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 15:25:52.076603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.54
 ---- batch: 020 ----
mean loss: 41.30
 ---- batch: 030 ----
mean loss: 39.61
train mean loss: 40.36
epoch train time: 0:00:00.576809
elapsed time: 0:02:08.890816
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 15:25:52.653774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.21
 ---- batch: 020 ----
mean loss: 41.07
 ---- batch: 030 ----
mean loss: 38.83
train mean loss: 39.62
epoch train time: 0:00:00.609842
elapsed time: 0:02:09.501054
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 15:25:53.264019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.46
 ---- batch: 020 ----
mean loss: 40.37
 ---- batch: 030 ----
mean loss: 38.14
train mean loss: 38.96
epoch train time: 0:00:00.605304
elapsed time: 0:02:10.106723
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 15:25:53.869706
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 39.27
 ---- batch: 020 ----
mean loss: 39.49
 ---- batch: 030 ----
mean loss: 37.46
train mean loss: 38.67
epoch train time: 0:00:00.593671
elapsed time: 0:02:10.700770
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 15:25:54.463733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 40.07
 ---- batch: 020 ----
mean loss: 37.13
 ---- batch: 030 ----
mean loss: 39.70
train mean loss: 38.65
epoch train time: 0:00:00.586413
elapsed time: 0:02:11.287524
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 15:25:55.050492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 38.93
 ---- batch: 020 ----
mean loss: 37.27
 ---- batch: 030 ----
mean loss: 39.11
train mean loss: 38.14
epoch train time: 0:00:00.579987
elapsed time: 0:02:11.867893
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 15:25:55.630852
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.14
 ---- batch: 020 ----
mean loss: 37.20
 ---- batch: 030 ----
mean loss: 39.25
train mean loss: 36.95
epoch train time: 0:00:00.605903
elapsed time: 0:02:12.474226
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 15:25:56.237124
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.83
 ---- batch: 020 ----
mean loss: 38.57
 ---- batch: 030 ----
mean loss: 35.92
train mean loss: 36.93
epoch train time: 0:00:00.612344
elapsed time: 0:02:13.087114
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 15:25:56.850092
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.51
 ---- batch: 020 ----
mean loss: 35.34
 ---- batch: 030 ----
mean loss: 37.34
train mean loss: 37.00
epoch train time: 0:00:00.583574
elapsed time: 0:02:13.671139
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 15:25:57.434115
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.69
 ---- batch: 020 ----
mean loss: 36.76
 ---- batch: 030 ----
mean loss: 38.25
train mean loss: 36.82
epoch train time: 0:00:00.606127
elapsed time: 0:02:14.277737
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 15:25:58.040693
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.92
 ---- batch: 020 ----
mean loss: 37.08
 ---- batch: 030 ----
mean loss: 36.74
train mean loss: 37.07
epoch train time: 0:00:00.580032
elapsed time: 0:02:14.858213
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 15:25:58.621179
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.36
 ---- batch: 020 ----
mean loss: 36.78
 ---- batch: 030 ----
mean loss: 37.57
train mean loss: 36.65
epoch train time: 0:00:00.595185
elapsed time: 0:02:15.453782
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 15:25:59.216754
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.21
 ---- batch: 020 ----
mean loss: 36.11
 ---- batch: 030 ----
mean loss: 37.69
train mean loss: 36.74
epoch train time: 0:00:00.601482
elapsed time: 0:02:16.055688
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 15:25:59.818653
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.36
 ---- batch: 020 ----
mean loss: 36.49
 ---- batch: 030 ----
mean loss: 36.41
train mean loss: 36.54
epoch train time: 0:00:00.616043
elapsed time: 0:02:16.672137
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 15:26:00.435093
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.77
 ---- batch: 020 ----
mean loss: 37.00
 ---- batch: 030 ----
mean loss: 36.32
train mean loss: 36.74
epoch train time: 0:00:00.591031
elapsed time: 0:02:17.263691
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 15:26:01.026666
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.78
 ---- batch: 020 ----
mean loss: 36.20
 ---- batch: 030 ----
mean loss: 36.78
train mean loss: 36.38
epoch train time: 0:00:00.581954
elapsed time: 0:02:17.846163
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 15:26:01.609117
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.46
 ---- batch: 020 ----
mean loss: 35.62
 ---- batch: 030 ----
mean loss: 34.70
train mean loss: 36.26
epoch train time: 0:00:00.609508
elapsed time: 0:02:18.456030
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 15:26:02.218984
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.32
 ---- batch: 020 ----
mean loss: 36.71
 ---- batch: 030 ----
mean loss: 37.23
train mean loss: 36.38
epoch train time: 0:00:00.599714
elapsed time: 0:02:19.056176
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 15:26:02.819138
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.23
 ---- batch: 020 ----
mean loss: 34.44
 ---- batch: 030 ----
mean loss: 37.56
train mean loss: 36.57
epoch train time: 0:00:00.589871
elapsed time: 0:02:19.646407
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 15:26:03.409380
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.83
 ---- batch: 020 ----
mean loss: 36.65
 ---- batch: 030 ----
mean loss: 35.99
train mean loss: 36.42
epoch train time: 0:00:00.592578
elapsed time: 0:02:20.239424
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 15:26:04.002386
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.99
 ---- batch: 020 ----
mean loss: 36.24
 ---- batch: 030 ----
mean loss: 37.30
train mean loss: 36.27
epoch train time: 0:00:00.590838
elapsed time: 0:02:20.830616
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 15:26:04.593577
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.09
 ---- batch: 020 ----
mean loss: 36.89
 ---- batch: 030 ----
mean loss: 36.11
train mean loss: 36.59
epoch train time: 0:00:00.600728
elapsed time: 0:02:21.431745
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 15:26:05.194705
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.61
 ---- batch: 020 ----
mean loss: 35.82
 ---- batch: 030 ----
mean loss: 38.33
train mean loss: 36.31
epoch train time: 0:00:00.581932
elapsed time: 0:02:22.014116
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 15:26:05.777098
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.46
 ---- batch: 020 ----
mean loss: 37.28
 ---- batch: 030 ----
mean loss: 34.81
train mean loss: 36.42
epoch train time: 0:00:00.582615
elapsed time: 0:02:22.597125
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 15:26:06.360096
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.04
 ---- batch: 020 ----
mean loss: 36.89
 ---- batch: 030 ----
mean loss: 35.34
train mean loss: 36.13
epoch train time: 0:00:00.601645
elapsed time: 0:02:23.199226
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 15:26:06.963214
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.83
 ---- batch: 020 ----
mean loss: 37.32
 ---- batch: 030 ----
mean loss: 36.81
train mean loss: 36.41
epoch train time: 0:00:00.580787
elapsed time: 0:02:23.781397
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 15:26:07.544355
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.40
 ---- batch: 020 ----
mean loss: 35.32
 ---- batch: 030 ----
mean loss: 37.38
train mean loss: 36.16
epoch train time: 0:00:00.605105
elapsed time: 0:02:24.386904
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 15:26:08.149858
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.31
 ---- batch: 020 ----
mean loss: 37.32
 ---- batch: 030 ----
mean loss: 36.14
train mean loss: 36.38
epoch train time: 0:00:00.585145
elapsed time: 0:02:24.972512
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 15:26:08.735494
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.29
 ---- batch: 020 ----
mean loss: 34.86
 ---- batch: 030 ----
mean loss: 38.35
train mean loss: 36.20
epoch train time: 0:00:00.603801
elapsed time: 0:02:25.576694
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 15:26:09.339666
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 37.26
 ---- batch: 020 ----
mean loss: 35.10
 ---- batch: 030 ----
mean loss: 37.23
train mean loss: 36.32
epoch train time: 0:00:00.619641
elapsed time: 0:02:26.196978
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 15:26:09.960003
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.91
 ---- batch: 020 ----
mean loss: 34.78
 ---- batch: 030 ----
mean loss: 36.12
train mean loss: 36.23
epoch train time: 0:00:00.580121
elapsed time: 0:02:26.777511
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 15:26:10.540480
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.90
 ---- batch: 020 ----
mean loss: 35.87
 ---- batch: 030 ----
mean loss: 34.08
train mean loss: 36.20
epoch train time: 0:00:00.585870
elapsed time: 0:02:27.363752
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 15:26:11.126711
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.49
 ---- batch: 020 ----
mean loss: 37.51
 ---- batch: 030 ----
mean loss: 35.78
train mean loss: 36.26
epoch train time: 0:00:00.593359
elapsed time: 0:02:27.957492
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 15:26:11.720452
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.56
 ---- batch: 020 ----
mean loss: 35.15
 ---- batch: 030 ----
mean loss: 35.91
train mean loss: 36.01
epoch train time: 0:00:00.583642
elapsed time: 0:02:28.541466
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 15:26:12.304436
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.50
 ---- batch: 020 ----
mean loss: 35.06
 ---- batch: 030 ----
mean loss: 35.99
train mean loss: 35.63
epoch train time: 0:00:00.583633
elapsed time: 0:02:29.125475
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 15:26:12.888425
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.69
 ---- batch: 020 ----
mean loss: 36.24
 ---- batch: 030 ----
mean loss: 35.51
train mean loss: 35.73
epoch train time: 0:00:00.588319
elapsed time: 0:02:29.714151
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 15:26:13.477152
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.69
 ---- batch: 020 ----
mean loss: 34.92
 ---- batch: 030 ----
mean loss: 35.82
train mean loss: 35.59
epoch train time: 0:00:00.593588
elapsed time: 0:02:30.308172
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 15:26:14.071146
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.69
 ---- batch: 020 ----
mean loss: 36.44
 ---- batch: 030 ----
mean loss: 34.55
train mean loss: 35.25
epoch train time: 0:00:00.587167
elapsed time: 0:02:30.895775
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 15:26:14.658754
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.08
 ---- batch: 020 ----
mean loss: 36.00
 ---- batch: 030 ----
mean loss: 35.59
train mean loss: 35.97
epoch train time: 0:00:00.585630
elapsed time: 0:02:31.481834
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 15:26:15.244731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.99
 ---- batch: 020 ----
mean loss: 36.57
 ---- batch: 030 ----
mean loss: 33.84
train mean loss: 35.68
epoch train time: 0:00:00.583813
elapsed time: 0:02:32.066022
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 15:26:15.829015
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 38.34
 ---- batch: 020 ----
mean loss: 35.11
 ---- batch: 030 ----
mean loss: 34.50
train mean loss: 35.69
epoch train time: 0:00:00.586878
elapsed time: 0:02:32.653354
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 15:26:16.416341
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.38
 ---- batch: 020 ----
mean loss: 34.97
 ---- batch: 030 ----
mean loss: 35.64
train mean loss: 35.37
epoch train time: 0:00:00.588486
elapsed time: 0:02:33.242231
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 15:26:17.005183
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.22
 ---- batch: 020 ----
mean loss: 35.63
 ---- batch: 030 ----
mean loss: 36.32
train mean loss: 35.74
epoch train time: 0:00:00.590510
elapsed time: 0:02:33.833105
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 15:26:17.596060
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.94
 ---- batch: 020 ----
mean loss: 35.20
 ---- batch: 030 ----
mean loss: 35.35
train mean loss: 35.42
epoch train time: 0:00:00.594224
elapsed time: 0:02:34.427673
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 15:26:18.190650
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.83
 ---- batch: 020 ----
mean loss: 35.79
 ---- batch: 030 ----
mean loss: 34.15
train mean loss: 35.41
epoch train time: 0:00:00.576781
elapsed time: 0:02:35.004821
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 15:26:18.767781
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.75
 ---- batch: 020 ----
mean loss: 36.34
 ---- batch: 030 ----
mean loss: 34.30
train mean loss: 35.76
epoch train time: 0:00:00.601562
elapsed time: 0:02:35.606746
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 15:26:19.369759
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.47
 ---- batch: 020 ----
mean loss: 35.14
 ---- batch: 030 ----
mean loss: 36.17
train mean loss: 35.52
epoch train time: 0:00:00.588667
elapsed time: 0:02:36.195848
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 15:26:19.958838
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.82
 ---- batch: 020 ----
mean loss: 35.78
 ---- batch: 030 ----
mean loss: 34.63
train mean loss: 35.53
epoch train time: 0:00:00.585747
elapsed time: 0:02:36.781987
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 15:26:20.544953
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.81
 ---- batch: 020 ----
mean loss: 36.37
 ---- batch: 030 ----
mean loss: 34.84
train mean loss: 35.23
epoch train time: 0:00:00.585489
elapsed time: 0:02:37.367891
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 15:26:21.130847
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.27
 ---- batch: 020 ----
mean loss: 35.45
 ---- batch: 030 ----
mean loss: 35.70
train mean loss: 35.04
epoch train time: 0:00:00.582302
elapsed time: 0:02:37.950575
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 15:26:21.713579
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 36.07
 ---- batch: 020 ----
mean loss: 35.19
 ---- batch: 030 ----
mean loss: 34.88
train mean loss: 34.99
epoch train time: 0:00:00.590619
elapsed time: 0:02:38.541571
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 15:26:22.304584
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.95
 ---- batch: 020 ----
mean loss: 34.13
 ---- batch: 030 ----
mean loss: 35.97
train mean loss: 35.18
epoch train time: 0:00:00.579326
elapsed time: 0:02:39.121282
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 15:26:22.884234
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.71
 ---- batch: 020 ----
mean loss: 34.58
 ---- batch: 030 ----
mean loss: 35.98
train mean loss: 35.53
epoch train time: 0:00:00.590829
elapsed time: 0:02:39.712470
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 15:26:23.475428
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 35.59
 ---- batch: 020 ----
mean loss: 35.03
 ---- batch: 030 ----
mean loss: 33.44
train mean loss: 35.10
epoch train time: 0:00:00.590909
elapsed time: 0:02:40.303722
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 15:26:24.066679
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 34.79
 ---- batch: 020 ----
mean loss: 35.34
 ---- batch: 030 ----
mean loss: 36.22
train mean loss: 35.17
epoch train time: 0:00:00.580866
elapsed time: 0:02:40.892705
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_dense3/bayesian_dense3_6/checkpoint.pth.tar
**** end time: 2019-09-27 15:26:24.655583 ****
