Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_3', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29008
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 14:47:08.829466 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 14:47:08.839819
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4058.30
 ---- batch: 020 ----
mean loss: 3896.03
 ---- batch: 030 ----
mean loss: 3950.84
train mean loss: 3963.89
epoch train time: 0:00:12.686769
elapsed time: 0:00:12.700221
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 14:47:21.529744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3887.99
 ---- batch: 020 ----
mean loss: 3794.96
 ---- batch: 030 ----
mean loss: 3757.71
train mean loss: 3804.30
epoch train time: 0:00:00.510265
elapsed time: 0:00:13.210723
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 14:47:22.040290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3666.27
 ---- batch: 020 ----
mean loss: 3593.46
 ---- batch: 030 ----
mean loss: 3521.13
train mean loss: 3571.06
epoch train time: 0:00:00.514518
elapsed time: 0:00:13.725522
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 14:47:22.555074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3410.65
 ---- batch: 020 ----
mean loss: 3326.30
 ---- batch: 030 ----
mean loss: 3294.79
train mean loss: 3334.98
epoch train time: 0:00:00.511007
elapsed time: 0:00:14.236856
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 14:47:23.066416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3144.02
 ---- batch: 020 ----
mean loss: 3084.13
 ---- batch: 030 ----
mean loss: 3148.32
train mean loss: 3110.37
epoch train time: 0:00:00.510948
elapsed time: 0:00:14.748088
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 14:47:23.577670
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2964.97
 ---- batch: 020 ----
mean loss: 2879.95
 ---- batch: 030 ----
mean loss: 2877.40
train mean loss: 2894.43
epoch train time: 0:00:00.536406
elapsed time: 0:00:15.284810
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 14:47:24.114390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2796.54
 ---- batch: 020 ----
mean loss: 2717.67
 ---- batch: 030 ----
mean loss: 2673.03
train mean loss: 2715.85
epoch train time: 0:00:00.512220
elapsed time: 0:00:15.797327
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 14:47:24.626879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2605.50
 ---- batch: 020 ----
mean loss: 2563.74
 ---- batch: 030 ----
mean loss: 2481.47
train mean loss: 2539.02
epoch train time: 0:00:00.513200
elapsed time: 0:00:16.310798
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 14:47:25.140353
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2411.77
 ---- batch: 020 ----
mean loss: 2376.85
 ---- batch: 030 ----
mean loss: 2355.01
train mean loss: 2370.14
epoch train time: 0:00:00.507862
elapsed time: 0:00:16.818945
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 14:47:25.648497
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2289.58
 ---- batch: 020 ----
mean loss: 2222.93
 ---- batch: 030 ----
mean loss: 2199.06
train mean loss: 2225.13
epoch train time: 0:00:00.521179
elapsed time: 0:00:17.340392
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 14:47:26.169960
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2118.44
 ---- batch: 020 ----
mean loss: 2124.69
 ---- batch: 030 ----
mean loss: 2051.86
train mean loss: 2088.75
epoch train time: 0:00:00.516899
elapsed time: 0:00:17.857575
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 14:47:26.687130
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2013.80
 ---- batch: 020 ----
mean loss: 1982.23
 ---- batch: 030 ----
mean loss: 1927.98
train mean loss: 1974.11
epoch train time: 0:00:00.505594
elapsed time: 0:00:18.363455
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 14:47:27.193032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1929.08
 ---- batch: 020 ----
mean loss: 1870.76
 ---- batch: 030 ----
mean loss: 1862.63
train mean loss: 1871.11
epoch train time: 0:00:00.503666
elapsed time: 0:00:18.867419
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 14:47:27.696990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1834.82
 ---- batch: 020 ----
mean loss: 1774.12
 ---- batch: 030 ----
mean loss: 1734.99
train mean loss: 1767.85
epoch train time: 0:00:00.513941
elapsed time: 0:00:19.381650
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 14:47:28.211208
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1698.05
 ---- batch: 020 ----
mean loss: 1682.89
 ---- batch: 030 ----
mean loss: 1659.09
train mean loss: 1673.84
epoch train time: 0:00:00.517959
elapsed time: 0:00:19.899885
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 14:47:28.729441
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1599.75
 ---- batch: 020 ----
mean loss: 1591.03
 ---- batch: 030 ----
mean loss: 1575.69
train mean loss: 1584.29
epoch train time: 0:00:00.514318
elapsed time: 0:00:20.414482
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 14:47:29.244042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1535.18
 ---- batch: 020 ----
mean loss: 1502.40
 ---- batch: 030 ----
mean loss: 1487.30
train mean loss: 1502.78
epoch train time: 0:00:00.517202
elapsed time: 0:00:20.931967
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 14:47:29.761517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1467.80
 ---- batch: 020 ----
mean loss: 1433.50
 ---- batch: 030 ----
mean loss: 1394.49
train mean loss: 1433.07
epoch train time: 0:00:00.518885
elapsed time: 0:00:21.451116
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 14:47:30.280671
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1402.41
 ---- batch: 020 ----
mean loss: 1380.53
 ---- batch: 030 ----
mean loss: 1346.19
train mean loss: 1369.73
epoch train time: 0:00:00.512779
elapsed time: 0:00:21.964213
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 14:47:30.793801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1333.37
 ---- batch: 020 ----
mean loss: 1295.67
 ---- batch: 030 ----
mean loss: 1275.63
train mean loss: 1296.87
epoch train time: 0:00:00.505899
elapsed time: 0:00:22.470426
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 14:47:31.299989
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1243.87
 ---- batch: 020 ----
mean loss: 1241.56
 ---- batch: 030 ----
mean loss: 1224.81
train mean loss: 1235.94
epoch train time: 0:00:00.515517
elapsed time: 0:00:22.986237
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 14:47:31.815794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1188.97
 ---- batch: 020 ----
mean loss: 1199.45
 ---- batch: 030 ----
mean loss: 1177.17
train mean loss: 1180.32
epoch train time: 0:00:00.517748
elapsed time: 0:00:23.504281
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 14:47:32.333841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1158.55
 ---- batch: 020 ----
mean loss: 1127.90
 ---- batch: 030 ----
mean loss: 1109.16
train mean loss: 1124.18
epoch train time: 0:00:00.511706
elapsed time: 0:00:24.016288
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 14:47:32.845839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1076.47
 ---- batch: 020 ----
mean loss: 1084.19
 ---- batch: 030 ----
mean loss: 1080.12
train mean loss: 1071.51
epoch train time: 0:00:00.504847
elapsed time: 0:00:24.521404
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 14:47:33.350959
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1052.22
 ---- batch: 020 ----
mean loss: 1042.95
 ---- batch: 030 ----
mean loss: 1014.28
train mean loss: 1026.93
epoch train time: 0:00:00.505125
elapsed time: 0:00:25.026859
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 14:47:33.856440
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 980.20
 ---- batch: 020 ----
mean loss: 1002.87
 ---- batch: 030 ----
mean loss: 981.03
train mean loss: 984.37
epoch train time: 0:00:00.502964
elapsed time: 0:00:25.530140
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 14:47:34.359696
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 971.94
 ---- batch: 020 ----
mean loss: 951.21
 ---- batch: 030 ----
mean loss: 915.90
train mean loss: 947.49
epoch train time: 0:00:00.522085
elapsed time: 0:00:26.052544
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 14:47:34.882100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 922.17
 ---- batch: 020 ----
mean loss: 913.07
 ---- batch: 030 ----
mean loss: 890.88
train mean loss: 906.36
epoch train time: 0:00:00.504952
elapsed time: 0:00:26.557771
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 14:47:35.387320
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 874.71
 ---- batch: 020 ----
mean loss: 884.65
 ---- batch: 030 ----
mean loss: 854.86
train mean loss: 865.73
epoch train time: 0:00:00.501145
elapsed time: 0:00:27.059211
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 14:47:35.888778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 844.66
 ---- batch: 020 ----
mean loss: 839.37
 ---- batch: 030 ----
mean loss: 832.13
train mean loss: 839.52
epoch train time: 0:00:00.502106
elapsed time: 0:00:27.561608
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 14:47:36.391166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 805.72
 ---- batch: 020 ----
mean loss: 793.50
 ---- batch: 030 ----
mean loss: 812.48
train mean loss: 800.43
epoch train time: 0:00:00.506876
elapsed time: 0:00:28.068799
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 14:47:36.898389
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 786.04
 ---- batch: 020 ----
mean loss: 783.01
 ---- batch: 030 ----
mean loss: 771.76
train mean loss: 775.66
epoch train time: 0:00:00.502500
elapsed time: 0:00:28.571642
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 14:47:37.401229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 751.27
 ---- batch: 020 ----
mean loss: 753.41
 ---- batch: 030 ----
mean loss: 730.43
train mean loss: 745.20
epoch train time: 0:00:00.499249
elapsed time: 0:00:29.071206
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 14:47:37.900757
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 738.52
 ---- batch: 020 ----
mean loss: 731.91
 ---- batch: 030 ----
mean loss: 705.13
train mean loss: 723.44
epoch train time: 0:00:00.502808
elapsed time: 0:00:29.574311
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 14:47:38.403902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 701.10
 ---- batch: 020 ----
mean loss: 713.44
 ---- batch: 030 ----
mean loss: 698.17
train mean loss: 702.38
epoch train time: 0:00:00.500203
elapsed time: 0:00:30.074845
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 14:47:38.904399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 684.14
 ---- batch: 020 ----
mean loss: 674.94
 ---- batch: 030 ----
mean loss: 681.26
train mean loss: 677.54
epoch train time: 0:00:00.501172
elapsed time: 0:00:30.576325
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 14:47:39.405884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 663.16
 ---- batch: 020 ----
mean loss: 655.01
 ---- batch: 030 ----
mean loss: 648.22
train mean loss: 653.21
epoch train time: 0:00:00.516480
elapsed time: 0:00:31.093127
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 14:47:39.922682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 640.41
 ---- batch: 020 ----
mean loss: 631.82
 ---- batch: 030 ----
mean loss: 629.98
train mean loss: 632.94
epoch train time: 0:00:00.502668
elapsed time: 0:00:31.596111
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 14:47:40.425753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 633.52
 ---- batch: 020 ----
mean loss: 615.98
 ---- batch: 030 ----
mean loss: 611.51
train mean loss: 617.19
epoch train time: 0:00:00.519870
elapsed time: 0:00:32.116356
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 14:47:40.945926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 608.38
 ---- batch: 020 ----
mean loss: 595.36
 ---- batch: 030 ----
mean loss: 606.89
train mean loss: 602.56
epoch train time: 0:00:00.517524
elapsed time: 0:00:32.634191
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 14:47:41.463753
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 585.66
 ---- batch: 020 ----
mean loss: 580.78
 ---- batch: 030 ----
mean loss: 577.87
train mean loss: 582.12
epoch train time: 0:00:00.506941
elapsed time: 0:00:33.141424
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 14:47:41.971006
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 571.62
 ---- batch: 020 ----
mean loss: 558.36
 ---- batch: 030 ----
mean loss: 571.77
train mean loss: 568.04
epoch train time: 0:00:00.506693
elapsed time: 0:00:33.648434
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 14:47:42.477987
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 566.76
 ---- batch: 020 ----
mean loss: 554.83
 ---- batch: 030 ----
mean loss: 542.32
train mean loss: 553.24
epoch train time: 0:00:00.507873
elapsed time: 0:00:34.156577
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 14:47:42.986149
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 534.82
 ---- batch: 020 ----
mean loss: 551.95
 ---- batch: 030 ----
mean loss: 532.43
train mean loss: 538.57
epoch train time: 0:00:00.501305
elapsed time: 0:00:34.658248
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 14:47:43.487807
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 528.81
 ---- batch: 020 ----
mean loss: 520.58
 ---- batch: 030 ----
mean loss: 530.60
train mean loss: 526.17
epoch train time: 0:00:00.509595
elapsed time: 0:00:35.168116
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 14:47:43.997685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 519.85
 ---- batch: 020 ----
mean loss: 511.96
 ---- batch: 030 ----
mean loss: 519.30
train mean loss: 518.43
epoch train time: 0:00:00.499946
elapsed time: 0:00:35.668389
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 14:47:44.497997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 504.91
 ---- batch: 020 ----
mean loss: 506.05
 ---- batch: 030 ----
mean loss: 508.80
train mean loss: 505.09
epoch train time: 0:00:00.503389
elapsed time: 0:00:36.172109
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 14:47:45.001682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 499.59
 ---- batch: 020 ----
mean loss: 499.35
 ---- batch: 030 ----
mean loss: 495.30
train mean loss: 493.85
epoch train time: 0:00:00.506063
elapsed time: 0:00:36.678522
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 14:47:45.508076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 492.46
 ---- batch: 020 ----
mean loss: 481.84
 ---- batch: 030 ----
mean loss: 477.42
train mean loss: 482.40
epoch train time: 0:00:00.497205
elapsed time: 0:00:37.175988
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 14:47:46.005549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 488.12
 ---- batch: 020 ----
mean loss: 474.52
 ---- batch: 030 ----
mean loss: 467.87
train mean loss: 474.47
epoch train time: 0:00:00.500324
elapsed time: 0:00:37.676616
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 14:47:46.506172
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 468.26
 ---- batch: 020 ----
mean loss: 465.72
 ---- batch: 030 ----
mean loss: 467.37
train mean loss: 464.14
epoch train time: 0:00:00.509446
elapsed time: 0:00:38.186344
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 14:47:47.015898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 461.70
 ---- batch: 020 ----
mean loss: 449.41
 ---- batch: 030 ----
mean loss: 456.24
train mean loss: 456.65
epoch train time: 0:00:00.497604
elapsed time: 0:00:38.684242
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 14:47:47.513799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 456.91
 ---- batch: 020 ----
mean loss: 453.68
 ---- batch: 030 ----
mean loss: 440.42
train mean loss: 449.26
epoch train time: 0:00:00.534655
elapsed time: 0:00:39.219165
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 14:47:48.048719
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 442.21
 ---- batch: 020 ----
mean loss: 438.78
 ---- batch: 030 ----
mean loss: 437.93
train mean loss: 439.51
epoch train time: 0:00:00.507367
elapsed time: 0:00:39.726799
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 14:47:48.556352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 440.49
 ---- batch: 020 ----
mean loss: 431.16
 ---- batch: 030 ----
mean loss: 434.21
train mean loss: 434.40
epoch train time: 0:00:00.512960
elapsed time: 0:00:40.240021
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 14:47:49.069569
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 436.38
 ---- batch: 020 ----
mean loss: 423.95
 ---- batch: 030 ----
mean loss: 426.66
train mean loss: 427.12
epoch train time: 0:00:00.501253
elapsed time: 0:00:40.741556
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 14:47:49.571119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 421.31
 ---- batch: 020 ----
mean loss: 429.09
 ---- batch: 030 ----
mean loss: 409.91
train mean loss: 419.35
epoch train time: 0:00:00.542592
elapsed time: 0:00:41.284436
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 14:47:50.113994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 416.49
 ---- batch: 020 ----
mean loss: 411.35
 ---- batch: 030 ----
mean loss: 415.81
train mean loss: 413.38
epoch train time: 0:00:00.510483
elapsed time: 0:00:41.795215
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 14:47:50.624789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 403.56
 ---- batch: 020 ----
mean loss: 419.21
 ---- batch: 030 ----
mean loss: 408.43
train mean loss: 407.71
epoch train time: 0:00:00.515838
elapsed time: 0:00:42.311363
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 14:47:51.140937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.82
 ---- batch: 020 ----
mean loss: 401.27
 ---- batch: 030 ----
mean loss: 394.02
train mean loss: 398.83
epoch train time: 0:00:00.516762
elapsed time: 0:00:42.828420
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 14:47:51.657990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 399.01
 ---- batch: 020 ----
mean loss: 387.11
 ---- batch: 030 ----
mean loss: 395.58
train mean loss: 394.84
epoch train time: 0:00:00.542931
elapsed time: 0:00:43.371666
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 14:47:52.201225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 386.46
 ---- batch: 020 ----
mean loss: 384.82
 ---- batch: 030 ----
mean loss: 394.09
train mean loss: 388.78
epoch train time: 0:00:00.512219
elapsed time: 0:00:43.884223
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 14:47:52.713786
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 383.08
 ---- batch: 020 ----
mean loss: 380.19
 ---- batch: 030 ----
mean loss: 383.21
train mean loss: 383.12
epoch train time: 0:00:00.511591
elapsed time: 0:00:44.396099
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 14:47:53.225679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.08
 ---- batch: 020 ----
mean loss: 383.30
 ---- batch: 030 ----
mean loss: 375.60
train mean loss: 375.93
epoch train time: 0:00:00.523062
elapsed time: 0:00:44.919580
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 14:47:53.749144
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 378.11
 ---- batch: 020 ----
mean loss: 373.13
 ---- batch: 030 ----
mean loss: 374.54
train mean loss: 374.43
epoch train time: 0:00:00.513845
elapsed time: 0:00:45.433705
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 14:47:54.263263
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 371.10
 ---- batch: 020 ----
mean loss: 363.72
 ---- batch: 030 ----
mean loss: 369.82
train mean loss: 369.05
epoch train time: 0:00:00.513517
elapsed time: 0:00:45.947549
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 14:47:54.777104
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.38
 ---- batch: 020 ----
mean loss: 365.75
 ---- batch: 030 ----
mean loss: 362.50
train mean loss: 364.54
epoch train time: 0:00:00.502434
elapsed time: 0:00:46.450249
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 14:47:55.279817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 362.72
 ---- batch: 020 ----
mean loss: 358.41
 ---- batch: 030 ----
mean loss: 361.40
train mean loss: 359.91
epoch train time: 0:00:00.511738
elapsed time: 0:00:46.962276
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 14:47:55.791833
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 358.56
 ---- batch: 020 ----
mean loss: 361.21
 ---- batch: 030 ----
mean loss: 354.88
train mean loss: 357.18
epoch train time: 0:00:00.503919
elapsed time: 0:00:47.466478
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 14:47:56.296042
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 357.04
 ---- batch: 020 ----
mean loss: 353.53
 ---- batch: 030 ----
mean loss: 351.59
train mean loss: 353.63
epoch train time: 0:00:00.498764
elapsed time: 0:00:47.965565
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 14:47:56.795137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 355.97
 ---- batch: 020 ----
mean loss: 344.50
 ---- batch: 030 ----
mean loss: 357.05
train mean loss: 352.20
epoch train time: 0:00:00.499051
elapsed time: 0:00:48.464897
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 14:47:57.294449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 350.28
 ---- batch: 020 ----
mean loss: 347.40
 ---- batch: 030 ----
mean loss: 343.12
train mean loss: 347.89
epoch train time: 0:00:00.506218
elapsed time: 0:00:48.971408
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 14:47:57.800978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 345.97
 ---- batch: 020 ----
mean loss: 345.51
 ---- batch: 030 ----
mean loss: 343.35
train mean loss: 344.56
epoch train time: 0:00:00.504319
elapsed time: 0:00:49.476012
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 14:47:58.305584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.78
 ---- batch: 020 ----
mean loss: 347.96
 ---- batch: 030 ----
mean loss: 341.64
train mean loss: 340.91
epoch train time: 0:00:00.520480
elapsed time: 0:00:49.996815
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 14:47:58.826387
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 339.45
 ---- batch: 020 ----
mean loss: 336.08
 ---- batch: 030 ----
mean loss: 339.51
train mean loss: 337.76
epoch train time: 0:00:00.529930
elapsed time: 0:00:50.527053
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 14:47:59.356612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.66
 ---- batch: 020 ----
mean loss: 338.81
 ---- batch: 030 ----
mean loss: 335.31
train mean loss: 333.60
epoch train time: 0:00:00.524795
elapsed time: 0:00:51.052247
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 14:47:59.881810
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 337.62
 ---- batch: 020 ----
mean loss: 328.41
 ---- batch: 030 ----
mean loss: 329.09
train mean loss: 333.29
epoch train time: 0:00:00.509291
elapsed time: 0:00:51.561900
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 14:48:00.391536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.29
 ---- batch: 020 ----
mean loss: 334.32
 ---- batch: 030 ----
mean loss: 334.73
train mean loss: 330.45
epoch train time: 0:00:00.520132
elapsed time: 0:00:52.082470
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 14:48:00.912058
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.31
 ---- batch: 020 ----
mean loss: 321.80
 ---- batch: 030 ----
mean loss: 318.64
train mean loss: 325.54
epoch train time: 0:00:00.503232
elapsed time: 0:00:52.586062
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 14:48:01.415649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.26
 ---- batch: 020 ----
mean loss: 327.53
 ---- batch: 030 ----
mean loss: 328.17
train mean loss: 324.68
epoch train time: 0:00:00.498631
elapsed time: 0:00:53.084995
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 14:48:01.914547
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 314.30
 ---- batch: 020 ----
mean loss: 317.00
 ---- batch: 030 ----
mean loss: 338.04
train mean loss: 322.01
epoch train time: 0:00:00.498223
elapsed time: 0:00:53.583474
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 14:48:02.413140
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 314.11
 ---- batch: 020 ----
mean loss: 323.22
 ---- batch: 030 ----
mean loss: 318.98
train mean loss: 319.36
epoch train time: 0:00:00.510965
elapsed time: 0:00:54.094820
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 14:48:02.924374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.26
 ---- batch: 020 ----
mean loss: 316.25
 ---- batch: 030 ----
mean loss: 318.13
train mean loss: 318.59
epoch train time: 0:00:00.500066
elapsed time: 0:00:54.595164
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 14:48:03.424720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.74
 ---- batch: 020 ----
mean loss: 321.59
 ---- batch: 030 ----
mean loss: 317.26
train mean loss: 318.13
epoch train time: 0:00:00.512570
elapsed time: 0:00:55.108035
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 14:48:03.937655
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.11
 ---- batch: 020 ----
mean loss: 309.17
 ---- batch: 030 ----
mean loss: 317.10
train mean loss: 314.43
epoch train time: 0:00:00.508960
elapsed time: 0:00:55.617332
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 14:48:04.446885
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 313.99
 ---- batch: 020 ----
mean loss: 316.84
 ---- batch: 030 ----
mean loss: 308.94
train mean loss: 312.37
epoch train time: 0:00:00.510102
elapsed time: 0:00:56.127699
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 14:48:04.957271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.99
 ---- batch: 020 ----
mean loss: 314.11
 ---- batch: 030 ----
mean loss: 309.68
train mean loss: 311.50
epoch train time: 0:00:00.506492
elapsed time: 0:00:56.634482
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 14:48:05.464054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 311.08
 ---- batch: 020 ----
mean loss: 317.10
 ---- batch: 030 ----
mean loss: 301.99
train mean loss: 309.34
epoch train time: 0:00:00.520299
elapsed time: 0:00:57.155080
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 14:48:05.984642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.84
 ---- batch: 020 ----
mean loss: 302.12
 ---- batch: 030 ----
mean loss: 304.30
train mean loss: 307.36
epoch train time: 0:00:00.507428
elapsed time: 0:00:57.662846
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 14:48:06.492399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 305.69
 ---- batch: 020 ----
mean loss: 300.56
 ---- batch: 030 ----
mean loss: 305.43
train mean loss: 304.96
epoch train time: 0:00:00.502097
elapsed time: 0:00:58.165222
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 14:48:06.994778
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.99
 ---- batch: 020 ----
mean loss: 308.64
 ---- batch: 030 ----
mean loss: 304.90
train mean loss: 305.12
epoch train time: 0:00:00.498193
elapsed time: 0:00:58.663692
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 14:48:07.493244
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 302.35
 ---- batch: 020 ----
mean loss: 302.70
 ---- batch: 030 ----
mean loss: 306.11
train mean loss: 302.76
epoch train time: 0:00:00.520321
elapsed time: 0:00:59.184314
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 14:48:08.013871
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 302.31
 ---- batch: 020 ----
mean loss: 298.58
 ---- batch: 030 ----
mean loss: 293.51
train mean loss: 297.84
epoch train time: 0:00:00.511022
elapsed time: 0:00:59.695635
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 14:48:08.525194
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 303.14
 ---- batch: 020 ----
mean loss: 294.32
 ---- batch: 030 ----
mean loss: 301.67
train mean loss: 300.03
epoch train time: 0:00:00.514401
elapsed time: 0:01:00.210342
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 14:48:09.039893
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.68
 ---- batch: 020 ----
mean loss: 295.82
 ---- batch: 030 ----
mean loss: 300.97
train mean loss: 298.03
epoch train time: 0:00:00.512180
elapsed time: 0:01:00.722784
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 14:48:09.552336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.52
 ---- batch: 020 ----
mean loss: 293.67
 ---- batch: 030 ----
mean loss: 300.06
train mean loss: 296.45
epoch train time: 0:00:00.513869
elapsed time: 0:01:01.236921
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 14:48:10.066478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.92
 ---- batch: 020 ----
mean loss: 295.39
 ---- batch: 030 ----
mean loss: 300.82
train mean loss: 294.11
epoch train time: 0:00:00.500274
elapsed time: 0:01:01.737464
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 14:48:10.567013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 295.52
 ---- batch: 020 ----
mean loss: 290.10
 ---- batch: 030 ----
mean loss: 291.12
train mean loss: 292.59
epoch train time: 0:00:00.516192
elapsed time: 0:01:02.253928
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 14:48:11.083503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.20
 ---- batch: 020 ----
mean loss: 290.93
 ---- batch: 030 ----
mean loss: 291.30
train mean loss: 292.29
epoch train time: 0:00:00.523584
elapsed time: 0:01:02.777807
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 14:48:11.607361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.18
 ---- batch: 020 ----
mean loss: 283.80
 ---- batch: 030 ----
mean loss: 295.11
train mean loss: 289.60
epoch train time: 0:00:00.499963
elapsed time: 0:01:03.278027
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 14:48:12.107597
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 290.84
 ---- batch: 020 ----
mean loss: 291.18
 ---- batch: 030 ----
mean loss: 281.51
train mean loss: 289.23
epoch train time: 0:00:00.496818
elapsed time: 0:01:03.775148
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 14:48:12.604695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.44
 ---- batch: 020 ----
mean loss: 291.06
 ---- batch: 030 ----
mean loss: 286.91
train mean loss: 286.40
epoch train time: 0:00:00.528821
elapsed time: 0:01:04.304276
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 14:48:13.133838
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.02
 ---- batch: 020 ----
mean loss: 286.44
 ---- batch: 030 ----
mean loss: 287.87
train mean loss: 285.63
epoch train time: 0:00:00.518777
elapsed time: 0:01:04.823374
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 14:48:13.652927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 281.74
 ---- batch: 020 ----
mean loss: 291.91
 ---- batch: 030 ----
mean loss: 285.14
train mean loss: 285.00
epoch train time: 0:00:00.520847
elapsed time: 0:01:05.344507
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 14:48:14.174054
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.21
 ---- batch: 020 ----
mean loss: 286.01
 ---- batch: 030 ----
mean loss: 282.91
train mean loss: 282.15
epoch train time: 0:00:00.508291
elapsed time: 0:01:05.853070
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 14:48:14.682624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 273.29
 ---- batch: 020 ----
mean loss: 285.16
 ---- batch: 030 ----
mean loss: 285.22
train mean loss: 281.04
epoch train time: 0:00:00.515011
elapsed time: 0:01:06.368369
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 14:48:15.197924
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 277.78
 ---- batch: 020 ----
mean loss: 286.50
 ---- batch: 030 ----
mean loss: 279.57
train mean loss: 281.46
epoch train time: 0:00:00.519110
elapsed time: 0:01:06.887872
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 14:48:15.717410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 281.31
 ---- batch: 020 ----
mean loss: 270.59
 ---- batch: 030 ----
mean loss: 284.73
train mean loss: 278.45
epoch train time: 0:00:00.509647
elapsed time: 0:01:07.397770
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 14:48:16.227352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.18
 ---- batch: 020 ----
mean loss: 286.04
 ---- batch: 030 ----
mean loss: 273.09
train mean loss: 279.02
epoch train time: 0:00:00.525221
elapsed time: 0:01:07.923324
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 14:48:16.752953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.57
 ---- batch: 020 ----
mean loss: 274.87
 ---- batch: 030 ----
mean loss: 278.67
train mean loss: 277.51
epoch train time: 0:00:00.504712
elapsed time: 0:01:08.428377
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 14:48:17.257926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.66
 ---- batch: 020 ----
mean loss: 277.31
 ---- batch: 030 ----
mean loss: 277.32
train mean loss: 275.39
epoch train time: 0:00:00.500063
elapsed time: 0:01:08.928720
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 14:48:17.758276
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 278.30
 ---- batch: 020 ----
mean loss: 271.74
 ---- batch: 030 ----
mean loss: 274.41
train mean loss: 274.94
epoch train time: 0:00:00.527300
elapsed time: 0:01:09.456328
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 14:48:18.285888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 274.28
 ---- batch: 020 ----
mean loss: 275.73
 ---- batch: 030 ----
mean loss: 270.01
train mean loss: 274.47
epoch train time: 0:00:00.540626
elapsed time: 0:01:09.997338
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 14:48:18.826991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.78
 ---- batch: 020 ----
mean loss: 271.63
 ---- batch: 030 ----
mean loss: 275.76
train mean loss: 272.65
epoch train time: 0:00:00.518534
elapsed time: 0:01:10.516273
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 14:48:19.345834
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 265.72
 ---- batch: 020 ----
mean loss: 274.60
 ---- batch: 030 ----
mean loss: 275.62
train mean loss: 270.79
epoch train time: 0:00:00.520132
elapsed time: 0:01:11.036706
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 14:48:19.866260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.95
 ---- batch: 020 ----
mean loss: 278.21
 ---- batch: 030 ----
mean loss: 267.78
train mean loss: 271.14
epoch train time: 0:00:00.509879
elapsed time: 0:01:11.546878
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 14:48:20.376437
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.09
 ---- batch: 020 ----
mean loss: 274.69
 ---- batch: 030 ----
mean loss: 269.52
train mean loss: 269.72
epoch train time: 0:00:00.517617
elapsed time: 0:01:12.064810
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 14:48:20.894383
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.43
 ---- batch: 020 ----
mean loss: 273.46
 ---- batch: 030 ----
mean loss: 268.80
train mean loss: 267.27
epoch train time: 0:00:00.509479
elapsed time: 0:01:12.574602
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 14:48:21.404174
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.19
 ---- batch: 020 ----
mean loss: 269.01
 ---- batch: 030 ----
mean loss: 268.41
train mean loss: 267.31
epoch train time: 0:00:00.520294
elapsed time: 0:01:13.095189
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 14:48:21.924745
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.79
 ---- batch: 020 ----
mean loss: 261.77
 ---- batch: 030 ----
mean loss: 269.54
train mean loss: 266.51
epoch train time: 0:00:00.509418
elapsed time: 0:01:13.604886
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 14:48:22.434441
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.83
 ---- batch: 020 ----
mean loss: 264.34
 ---- batch: 030 ----
mean loss: 261.97
train mean loss: 264.81
epoch train time: 0:00:00.533142
elapsed time: 0:01:14.138301
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 14:48:22.967856
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.44
 ---- batch: 020 ----
mean loss: 262.98
 ---- batch: 030 ----
mean loss: 268.31
train mean loss: 263.20
epoch train time: 0:00:00.505762
elapsed time: 0:01:14.644348
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 14:48:23.473897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.05
 ---- batch: 020 ----
mean loss: 262.89
 ---- batch: 030 ----
mean loss: 262.50
train mean loss: 263.27
epoch train time: 0:00:00.534230
elapsed time: 0:01:15.178849
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 14:48:24.008403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.85
 ---- batch: 020 ----
mean loss: 259.77
 ---- batch: 030 ----
mean loss: 263.88
train mean loss: 261.45
epoch train time: 0:00:00.532434
elapsed time: 0:01:15.711566
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 14:48:24.541125
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.65
 ---- batch: 020 ----
mean loss: 255.87
 ---- batch: 030 ----
mean loss: 259.66
train mean loss: 260.17
epoch train time: 0:00:00.518361
elapsed time: 0:01:16.230220
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 14:48:25.059776
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 264.85
 ---- batch: 020 ----
mean loss: 253.13
 ---- batch: 030 ----
mean loss: 252.98
train mean loss: 259.12
epoch train time: 0:00:00.505138
elapsed time: 0:01:16.735671
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 14:48:25.565243
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.72
 ---- batch: 020 ----
mean loss: 259.92
 ---- batch: 030 ----
mean loss: 257.50
train mean loss: 257.74
epoch train time: 0:00:00.520517
elapsed time: 0:01:17.256551
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 14:48:26.086090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.22
 ---- batch: 020 ----
mean loss: 255.41
 ---- batch: 030 ----
mean loss: 260.26
train mean loss: 258.30
epoch train time: 0:00:00.516424
elapsed time: 0:01:17.773298
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 14:48:26.602869
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 255.70
 ---- batch: 020 ----
mean loss: 257.98
 ---- batch: 030 ----
mean loss: 251.88
train mean loss: 255.89
epoch train time: 0:00:00.531805
elapsed time: 0:01:18.305400
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 14:48:27.134983
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.41
 ---- batch: 020 ----
mean loss: 255.74
 ---- batch: 030 ----
mean loss: 255.77
train mean loss: 255.02
epoch train time: 0:00:00.518035
elapsed time: 0:01:18.823793
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 14:48:27.653350
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.74
 ---- batch: 020 ----
mean loss: 254.14
 ---- batch: 030 ----
mean loss: 260.88
train mean loss: 255.08
epoch train time: 0:00:00.525236
elapsed time: 0:01:19.349387
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 14:48:28.178956
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.66
 ---- batch: 020 ----
mean loss: 256.90
 ---- batch: 030 ----
mean loss: 251.84
train mean loss: 253.15
epoch train time: 0:00:00.501587
elapsed time: 0:01:19.851295
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 14:48:28.680884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.04
 ---- batch: 020 ----
mean loss: 256.57
 ---- batch: 030 ----
mean loss: 252.31
train mean loss: 252.65
epoch train time: 0:00:00.493602
elapsed time: 0:01:20.345188
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 14:48:29.174738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.83
 ---- batch: 020 ----
mean loss: 246.94
 ---- batch: 030 ----
mean loss: 248.98
train mean loss: 251.32
epoch train time: 0:00:00.493595
elapsed time: 0:01:20.839098
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 14:48:29.668654
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.88
 ---- batch: 020 ----
mean loss: 245.54
 ---- batch: 030 ----
mean loss: 255.38
train mean loss: 250.93
epoch train time: 0:00:00.512045
elapsed time: 0:01:21.351416
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 14:48:30.180988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.27
 ---- batch: 020 ----
mean loss: 252.33
 ---- batch: 030 ----
mean loss: 251.60
train mean loss: 250.03
epoch train time: 0:00:00.506897
elapsed time: 0:01:21.858650
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 14:48:30.688213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 254.85
 ---- batch: 020 ----
mean loss: 246.33
 ---- batch: 030 ----
mean loss: 243.30
train mean loss: 248.37
epoch train time: 0:00:00.515091
elapsed time: 0:01:22.374013
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 14:48:31.203567
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.09
 ---- batch: 020 ----
mean loss: 246.42
 ---- batch: 030 ----
mean loss: 251.64
train mean loss: 248.10
epoch train time: 0:00:00.508010
elapsed time: 0:01:22.882312
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 14:48:31.711866
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.59
 ---- batch: 020 ----
mean loss: 247.06
 ---- batch: 030 ----
mean loss: 247.23
train mean loss: 246.20
epoch train time: 0:00:00.520799
elapsed time: 0:01:23.403383
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 14:48:32.232951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.99
 ---- batch: 020 ----
mean loss: 245.91
 ---- batch: 030 ----
mean loss: 241.35
train mean loss: 245.70
epoch train time: 0:00:00.507568
elapsed time: 0:01:23.911259
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 14:48:32.740847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.14
 ---- batch: 020 ----
mean loss: 249.61
 ---- batch: 030 ----
mean loss: 239.40
train mean loss: 245.07
epoch train time: 0:00:00.506129
elapsed time: 0:01:24.417728
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 14:48:33.247301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.24
 ---- batch: 020 ----
mean loss: 242.44
 ---- batch: 030 ----
mean loss: 242.24
train mean loss: 244.71
epoch train time: 0:00:00.502262
elapsed time: 0:01:24.920310
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 14:48:33.749886
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 241.85
 ---- batch: 020 ----
mean loss: 243.14
 ---- batch: 030 ----
mean loss: 247.53
train mean loss: 242.90
epoch train time: 0:00:00.512704
elapsed time: 0:01:25.433310
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 14:48:34.262865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.78
 ---- batch: 020 ----
mean loss: 244.53
 ---- batch: 030 ----
mean loss: 244.07
train mean loss: 243.57
epoch train time: 0:00:00.533453
elapsed time: 0:01:25.967084
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 14:48:34.796642
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.66
 ---- batch: 020 ----
mean loss: 242.07
 ---- batch: 030 ----
mean loss: 244.27
train mean loss: 241.98
epoch train time: 0:00:00.506218
elapsed time: 0:01:26.473586
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 14:48:35.303145
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.56
 ---- batch: 020 ----
mean loss: 248.83
 ---- batch: 030 ----
mean loss: 237.00
train mean loss: 241.13
epoch train time: 0:00:00.503513
elapsed time: 0:01:26.977376
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 14:48:35.806926
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.23
 ---- batch: 020 ----
mean loss: 243.66
 ---- batch: 030 ----
mean loss: 237.71
train mean loss: 240.25
epoch train time: 0:00:00.514898
elapsed time: 0:01:27.492544
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 14:48:36.322100
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 239.22
 ---- batch: 020 ----
mean loss: 241.19
 ---- batch: 030 ----
mean loss: 238.72
train mean loss: 239.76
epoch train time: 0:00:00.514963
elapsed time: 0:01:28.007796
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 14:48:36.837351
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 237.74
 ---- batch: 020 ----
mean loss: 238.30
 ---- batch: 030 ----
mean loss: 242.73
train mean loss: 239.04
epoch train time: 0:00:00.509983
elapsed time: 0:01:28.518129
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 14:48:37.347683
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.60
 ---- batch: 020 ----
mean loss: 233.12
 ---- batch: 030 ----
mean loss: 245.07
train mean loss: 237.83
epoch train time: 0:00:00.513108
elapsed time: 0:01:29.031510
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 14:48:37.861063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.03
 ---- batch: 020 ----
mean loss: 243.54
 ---- batch: 030 ----
mean loss: 235.32
train mean loss: 237.15
epoch train time: 0:00:00.503890
elapsed time: 0:01:29.535699
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 14:48:38.365264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.67
 ---- batch: 020 ----
mean loss: 238.13
 ---- batch: 030 ----
mean loss: 235.58
train mean loss: 235.99
epoch train time: 0:00:00.502958
elapsed time: 0:01:30.038942
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 14:48:38.868492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.43
 ---- batch: 020 ----
mean loss: 236.25
 ---- batch: 030 ----
mean loss: 228.71
train mean loss: 234.20
epoch train time: 0:00:00.505949
elapsed time: 0:01:30.545178
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 14:48:39.374735
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.62
 ---- batch: 020 ----
mean loss: 234.00
 ---- batch: 030 ----
mean loss: 236.04
train mean loss: 233.92
epoch train time: 0:00:00.521396
elapsed time: 0:01:31.066840
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 14:48:39.896426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.04
 ---- batch: 020 ----
mean loss: 236.02
 ---- batch: 030 ----
mean loss: 236.26
train mean loss: 234.07
epoch train time: 0:00:00.499830
elapsed time: 0:01:31.566984
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 14:48:40.396535
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.03
 ---- batch: 020 ----
mean loss: 231.39
 ---- batch: 030 ----
mean loss: 231.64
train mean loss: 233.72
epoch train time: 0:00:00.504357
elapsed time: 0:01:32.071616
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 14:48:40.901171
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.58
 ---- batch: 020 ----
mean loss: 236.65
 ---- batch: 030 ----
mean loss: 227.04
train mean loss: 233.19
epoch train time: 0:00:00.511508
elapsed time: 0:01:32.583407
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 14:48:41.412957
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.34
 ---- batch: 020 ----
mean loss: 238.70
 ---- batch: 030 ----
mean loss: 228.74
train mean loss: 231.66
epoch train time: 0:00:00.511236
elapsed time: 0:01:33.094909
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 14:48:41.924462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.00
 ---- batch: 020 ----
mean loss: 227.07
 ---- batch: 030 ----
mean loss: 231.69
train mean loss: 230.41
epoch train time: 0:00:00.507256
elapsed time: 0:01:33.602441
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 14:48:42.431988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.57
 ---- batch: 020 ----
mean loss: 228.24
 ---- batch: 030 ----
mean loss: 232.12
train mean loss: 230.48
epoch train time: 0:00:00.515698
elapsed time: 0:01:34.118463
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 14:48:42.948057
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.71
 ---- batch: 020 ----
mean loss: 231.42
 ---- batch: 030 ----
mean loss: 229.19
train mean loss: 228.81
epoch train time: 0:00:00.506918
elapsed time: 0:01:34.625733
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 14:48:43.455290
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.83
 ---- batch: 020 ----
mean loss: 225.89
 ---- batch: 030 ----
mean loss: 232.27
train mean loss: 228.46
epoch train time: 0:00:00.515404
elapsed time: 0:01:35.141427
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 14:48:43.971025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.79
 ---- batch: 020 ----
mean loss: 226.47
 ---- batch: 030 ----
mean loss: 232.09
train mean loss: 227.43
epoch train time: 0:00:00.508525
elapsed time: 0:01:35.650318
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 14:48:44.479872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.63
 ---- batch: 020 ----
mean loss: 234.19
 ---- batch: 030 ----
mean loss: 227.40
train mean loss: 228.13
epoch train time: 0:00:00.519703
elapsed time: 0:01:36.170299
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 14:48:44.999867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 223.50
 ---- batch: 020 ----
mean loss: 229.42
 ---- batch: 030 ----
mean loss: 226.71
train mean loss: 226.55
epoch train time: 0:00:00.497795
elapsed time: 0:01:36.668384
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 14:48:45.497949
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 228.38
 ---- batch: 020 ----
mean loss: 225.35
 ---- batch: 030 ----
mean loss: 222.74
train mean loss: 224.49
epoch train time: 0:00:00.505142
elapsed time: 0:01:37.173817
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 14:48:46.003371
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.14
 ---- batch: 020 ----
mean loss: 228.80
 ---- batch: 030 ----
mean loss: 224.62
train mean loss: 225.44
epoch train time: 0:00:00.513114
elapsed time: 0:01:37.687241
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 14:48:46.516804
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.06
 ---- batch: 020 ----
mean loss: 221.18
 ---- batch: 030 ----
mean loss: 227.74
train mean loss: 224.10
epoch train time: 0:00:00.508905
elapsed time: 0:01:38.196420
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 14:48:47.026007
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.39
 ---- batch: 020 ----
mean loss: 223.43
 ---- batch: 030 ----
mean loss: 224.40
train mean loss: 223.63
epoch train time: 0:00:00.505786
elapsed time: 0:01:38.702553
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 14:48:47.532113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.99
 ---- batch: 020 ----
mean loss: 224.58
 ---- batch: 030 ----
mean loss: 219.64
train mean loss: 223.04
epoch train time: 0:00:00.511038
elapsed time: 0:01:39.213869
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 14:48:48.043415
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.92
 ---- batch: 020 ----
mean loss: 222.63
 ---- batch: 030 ----
mean loss: 222.72
train mean loss: 222.19
epoch train time: 0:00:00.499207
elapsed time: 0:01:39.713359
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 14:48:48.542911
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.29
 ---- batch: 020 ----
mean loss: 222.38
 ---- batch: 030 ----
mean loss: 223.99
train mean loss: 221.61
epoch train time: 0:00:00.516271
elapsed time: 0:01:40.229906
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 14:48:49.059466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.19
 ---- batch: 020 ----
mean loss: 213.05
 ---- batch: 030 ----
mean loss: 225.30
train mean loss: 221.90
epoch train time: 0:00:00.523711
elapsed time: 0:01:40.753891
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 14:48:49.583456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.59
 ---- batch: 020 ----
mean loss: 223.44
 ---- batch: 030 ----
mean loss: 216.27
train mean loss: 220.50
epoch train time: 0:00:00.519701
elapsed time: 0:01:41.273936
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 14:48:50.103442
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.11
 ---- batch: 020 ----
mean loss: 221.55
 ---- batch: 030 ----
mean loss: 221.60
train mean loss: 219.30
epoch train time: 0:00:00.509250
elapsed time: 0:01:41.783420
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 14:48:50.612973
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.42
 ---- batch: 020 ----
mean loss: 218.97
 ---- batch: 030 ----
mean loss: 220.79
train mean loss: 219.67
epoch train time: 0:00:00.515797
elapsed time: 0:01:42.299486
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 14:48:51.129055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.42
 ---- batch: 020 ----
mean loss: 211.13
 ---- batch: 030 ----
mean loss: 225.12
train mean loss: 217.80
epoch train time: 0:00:00.514359
elapsed time: 0:01:42.814161
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 14:48:51.643724
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.18
 ---- batch: 020 ----
mean loss: 210.75
 ---- batch: 030 ----
mean loss: 219.96
train mean loss: 217.62
epoch train time: 0:00:00.524646
elapsed time: 0:01:43.339089
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 14:48:52.168662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 216.06
 ---- batch: 020 ----
mean loss: 223.45
 ---- batch: 030 ----
mean loss: 212.79
train mean loss: 216.92
epoch train time: 0:00:00.517318
elapsed time: 0:01:43.856714
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 14:48:52.686282
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.89
 ---- batch: 020 ----
mean loss: 215.78
 ---- batch: 030 ----
mean loss: 221.48
train mean loss: 216.85
epoch train time: 0:00:00.519250
elapsed time: 0:01:44.376275
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 14:48:53.205848
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.78
 ---- batch: 020 ----
mean loss: 217.47
 ---- batch: 030 ----
mean loss: 213.62
train mean loss: 215.95
epoch train time: 0:00:00.520309
elapsed time: 0:01:44.896896
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 14:48:53.726485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.81
 ---- batch: 020 ----
mean loss: 216.18
 ---- batch: 030 ----
mean loss: 215.35
train mean loss: 215.31
epoch train time: 0:00:00.511544
elapsed time: 0:01:45.408771
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 14:48:54.238388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.83
 ---- batch: 020 ----
mean loss: 216.42
 ---- batch: 030 ----
mean loss: 213.46
train mean loss: 214.90
epoch train time: 0:00:00.513864
elapsed time: 0:01:45.922975
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 14:48:54.752538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 219.43
 ---- batch: 020 ----
mean loss: 210.37
 ---- batch: 030 ----
mean loss: 217.52
train mean loss: 214.99
epoch train time: 0:00:00.518040
elapsed time: 0:01:46.441297
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 14:48:55.270853
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.93
 ---- batch: 020 ----
mean loss: 209.54
 ---- batch: 030 ----
mean loss: 213.63
train mean loss: 214.21
epoch train time: 0:00:00.521781
elapsed time: 0:01:46.963424
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 14:48:55.793063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.12
 ---- batch: 020 ----
mean loss: 222.76
 ---- batch: 030 ----
mean loss: 204.84
train mean loss: 213.50
epoch train time: 0:00:00.515513
elapsed time: 0:01:47.479309
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 14:48:56.308882
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.79
 ---- batch: 020 ----
mean loss: 215.34
 ---- batch: 030 ----
mean loss: 212.75
train mean loss: 212.38
epoch train time: 0:00:00.524141
elapsed time: 0:01:48.003860
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 14:48:56.833463
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.88
 ---- batch: 020 ----
mean loss: 218.11
 ---- batch: 030 ----
mean loss: 213.00
train mean loss: 212.76
epoch train time: 0:00:00.512678
elapsed time: 0:01:48.516865
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 14:48:57.346426
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.98
 ---- batch: 020 ----
mean loss: 206.94
 ---- batch: 030 ----
mean loss: 216.33
train mean loss: 211.39
epoch train time: 0:00:00.516954
elapsed time: 0:01:49.034129
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 14:48:57.863685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.32
 ---- batch: 020 ----
mean loss: 213.36
 ---- batch: 030 ----
mean loss: 214.64
train mean loss: 210.09
epoch train time: 0:00:00.502146
elapsed time: 0:01:49.536550
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 14:48:58.366107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.89
 ---- batch: 020 ----
mean loss: 214.78
 ---- batch: 030 ----
mean loss: 209.24
train mean loss: 210.24
epoch train time: 0:00:00.512822
elapsed time: 0:01:50.049697
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 14:48:58.879247
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.99
 ---- batch: 020 ----
mean loss: 207.88
 ---- batch: 030 ----
mean loss: 211.45
train mean loss: 208.89
epoch train time: 0:00:00.497247
elapsed time: 0:01:50.547264
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 14:48:59.376817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 210.03
 ---- batch: 020 ----
mean loss: 214.16
 ---- batch: 030 ----
mean loss: 204.18
train mean loss: 209.73
epoch train time: 0:00:00.505774
elapsed time: 0:01:51.053325
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 14:48:59.882943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.93
 ---- batch: 020 ----
mean loss: 214.06
 ---- batch: 030 ----
mean loss: 205.96
train mean loss: 209.05
epoch train time: 0:00:00.514832
elapsed time: 0:01:51.568546
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 14:49:00.398101
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.77
 ---- batch: 020 ----
mean loss: 213.39
 ---- batch: 030 ----
mean loss: 204.87
train mean loss: 208.15
epoch train time: 0:00:00.539374
elapsed time: 0:01:52.108216
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 14:49:00.937791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 206.20
 ---- batch: 020 ----
mean loss: 205.30
 ---- batch: 030 ----
mean loss: 213.13
train mean loss: 207.72
epoch train time: 0:00:00.515794
elapsed time: 0:01:52.624320
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 14:49:01.453890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.65
 ---- batch: 020 ----
mean loss: 207.07
 ---- batch: 030 ----
mean loss: 202.97
train mean loss: 206.71
epoch train time: 0:00:00.522499
elapsed time: 0:01:53.147098
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 14:49:01.976665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.74
 ---- batch: 020 ----
mean loss: 214.35
 ---- batch: 030 ----
mean loss: 203.93
train mean loss: 206.60
epoch train time: 0:00:00.501607
elapsed time: 0:01:53.649000
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 14:49:02.478549
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.45
 ---- batch: 020 ----
mean loss: 208.28
 ---- batch: 030 ----
mean loss: 206.89
train mean loss: 206.11
epoch train time: 0:00:00.506105
elapsed time: 0:01:54.155359
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 14:49:02.984907
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.39
 ---- batch: 020 ----
mean loss: 205.19
 ---- batch: 030 ----
mean loss: 208.11
train mean loss: 205.68
epoch train time: 0:00:00.513944
elapsed time: 0:01:54.669569
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 14:49:03.499132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.55
 ---- batch: 020 ----
mean loss: 206.29
 ---- batch: 030 ----
mean loss: 207.36
train mean loss: 205.67
epoch train time: 0:00:00.531337
elapsed time: 0:01:55.201222
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 14:49:04.030779
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.28
 ---- batch: 020 ----
mean loss: 203.82
 ---- batch: 030 ----
mean loss: 208.58
train mean loss: 205.17
epoch train time: 0:00:00.514612
elapsed time: 0:01:55.716172
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 14:49:04.545691
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 197.72
 ---- batch: 020 ----
mean loss: 208.69
 ---- batch: 030 ----
mean loss: 207.63
train mean loss: 205.24
epoch train time: 0:00:00.523007
elapsed time: 0:01:56.239454
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 14:49:05.069015
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 209.74
 ---- batch: 020 ----
mean loss: 208.22
 ---- batch: 030 ----
mean loss: 197.03
train mean loss: 204.91
epoch train time: 0:00:00.521604
elapsed time: 0:01:56.761340
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 14:49:05.590908
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.13
 ---- batch: 020 ----
mean loss: 201.15
 ---- batch: 030 ----
mean loss: 208.32
train mean loss: 204.21
epoch train time: 0:00:00.513973
elapsed time: 0:01:57.275654
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 14:49:06.105210
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.37
 ---- batch: 020 ----
mean loss: 203.66
 ---- batch: 030 ----
mean loss: 203.52
train mean loss: 204.36
epoch train time: 0:00:00.512250
elapsed time: 0:01:57.788551
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 14:49:06.618116
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 200.66
 ---- batch: 020 ----
mean loss: 205.26
 ---- batch: 030 ----
mean loss: 200.94
train mean loss: 204.67
epoch train time: 0:00:00.521278
elapsed time: 0:01:58.310138
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 14:49:07.139706
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.42
 ---- batch: 020 ----
mean loss: 200.51
 ---- batch: 030 ----
mean loss: 209.62
train mean loss: 204.12
epoch train time: 0:00:00.510294
elapsed time: 0:01:58.820723
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 14:49:07.650298
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 203.75
 ---- batch: 020 ----
mean loss: 202.77
 ---- batch: 030 ----
mean loss: 205.30
train mean loss: 204.39
epoch train time: 0:00:00.518803
elapsed time: 0:01:59.339819
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 14:49:08.169374
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.91
 ---- batch: 020 ----
mean loss: 210.30
 ---- batch: 030 ----
mean loss: 203.59
train mean loss: 204.73
epoch train time: 0:00:00.508181
elapsed time: 0:01:59.848382
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 14:49:08.677949
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.57
 ---- batch: 020 ----
mean loss: 202.77
 ---- batch: 030 ----
mean loss: 209.85
train mean loss: 204.93
epoch train time: 0:00:00.503739
elapsed time: 0:02:00.352419
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 14:49:09.181970
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 200.39
 ---- batch: 020 ----
mean loss: 205.91
 ---- batch: 030 ----
mean loss: 208.50
train mean loss: 204.36
epoch train time: 0:00:00.499875
elapsed time: 0:02:00.852555
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 14:49:09.682105
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 204.51
 ---- batch: 020 ----
mean loss: 208.95
 ---- batch: 030 ----
mean loss: 204.63
train mean loss: 204.21
epoch train time: 0:00:00.512056
elapsed time: 0:02:01.364879
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 14:49:10.194431
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 213.86
 ---- batch: 020 ----
mean loss: 199.99
 ---- batch: 030 ----
mean loss: 198.53
train mean loss: 203.99
epoch train time: 0:00:00.501625
elapsed time: 0:02:01.866777
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 14:49:10.696329
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 203.96
 ---- batch: 020 ----
mean loss: 205.23
 ---- batch: 030 ----
mean loss: 198.89
train mean loss: 204.46
epoch train time: 0:00:00.513332
elapsed time: 0:02:02.380392
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 14:49:11.209939
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.00
 ---- batch: 020 ----
mean loss: 202.51
 ---- batch: 030 ----
mean loss: 204.83
train mean loss: 203.95
epoch train time: 0:00:00.523749
elapsed time: 0:02:02.904432
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 14:49:11.734017
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.38
 ---- batch: 020 ----
mean loss: 205.14
 ---- batch: 030 ----
mean loss: 201.42
train mean loss: 203.67
epoch train time: 0:00:00.509317
elapsed time: 0:02:03.414049
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 14:49:12.243620
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 203.84
 ---- batch: 020 ----
mean loss: 201.72
 ---- batch: 030 ----
mean loss: 204.95
train mean loss: 204.23
epoch train time: 0:00:00.518932
elapsed time: 0:02:03.933276
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 14:49:12.762828
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.48
 ---- batch: 020 ----
mean loss: 199.53
 ---- batch: 030 ----
mean loss: 204.78
train mean loss: 204.75
epoch train time: 0:00:00.508485
elapsed time: 0:02:04.442036
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 14:49:13.271602
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 204.35
 ---- batch: 020 ----
mean loss: 204.24
 ---- batch: 030 ----
mean loss: 206.44
train mean loss: 204.18
epoch train time: 0:00:00.519093
elapsed time: 0:02:04.961469
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 14:49:13.791078
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.04
 ---- batch: 020 ----
mean loss: 207.05
 ---- batch: 030 ----
mean loss: 200.00
train mean loss: 204.30
epoch train time: 0:00:00.500773
elapsed time: 0:02:05.462583
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 14:49:14.292152
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 200.41
 ---- batch: 020 ----
mean loss: 206.95
 ---- batch: 030 ----
mean loss: 205.58
train mean loss: 204.07
epoch train time: 0:00:00.499987
elapsed time: 0:02:05.962873
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 14:49:14.792462
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.17
 ---- batch: 020 ----
mean loss: 199.24
 ---- batch: 030 ----
mean loss: 202.42
train mean loss: 203.47
epoch train time: 0:00:00.507320
elapsed time: 0:02:06.470518
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 14:49:15.300188
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.82
 ---- batch: 020 ----
mean loss: 205.03
 ---- batch: 030 ----
mean loss: 204.12
train mean loss: 203.90
epoch train time: 0:00:00.503449
elapsed time: 0:02:06.974375
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 14:49:15.803965
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.67
 ---- batch: 020 ----
mean loss: 204.55
 ---- batch: 030 ----
mean loss: 205.72
train mean loss: 203.59
epoch train time: 0:00:00.498658
elapsed time: 0:02:07.473362
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 14:49:16.302931
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.50
 ---- batch: 020 ----
mean loss: 207.24
 ---- batch: 030 ----
mean loss: 203.32
train mean loss: 204.33
epoch train time: 0:00:00.503113
elapsed time: 0:02:07.976777
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 14:49:16.806347
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 206.08
 ---- batch: 020 ----
mean loss: 205.45
 ---- batch: 030 ----
mean loss: 202.32
train mean loss: 203.70
epoch train time: 0:00:00.514109
elapsed time: 0:02:08.491177
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 14:49:17.320720
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.32
 ---- batch: 020 ----
mean loss: 207.42
 ---- batch: 030 ----
mean loss: 202.51
train mean loss: 203.51
epoch train time: 0:00:00.514426
elapsed time: 0:02:09.005888
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 14:49:17.835444
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 200.20
 ---- batch: 020 ----
mean loss: 205.97
 ---- batch: 030 ----
mean loss: 201.64
train mean loss: 203.70
epoch train time: 0:00:00.501670
elapsed time: 0:02:09.507880
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 14:49:18.337431
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 200.49
 ---- batch: 020 ----
mean loss: 202.45
 ---- batch: 030 ----
mean loss: 203.40
train mean loss: 203.71
epoch train time: 0:00:00.514289
elapsed time: 0:02:10.022433
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 14:49:18.851988
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.15
 ---- batch: 020 ----
mean loss: 208.86
 ---- batch: 030 ----
mean loss: 199.33
train mean loss: 203.29
epoch train time: 0:00:00.495417
elapsed time: 0:02:10.518116
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 14:49:19.347669
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.40
 ---- batch: 020 ----
mean loss: 199.80
 ---- batch: 030 ----
mean loss: 204.56
train mean loss: 203.50
epoch train time: 0:00:00.503479
elapsed time: 0:02:11.021886
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 14:49:19.851445
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.12
 ---- batch: 020 ----
mean loss: 203.51
 ---- batch: 030 ----
mean loss: 206.43
train mean loss: 203.16
epoch train time: 0:00:00.516513
elapsed time: 0:02:11.538752
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 14:49:20.368313
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.68
 ---- batch: 020 ----
mean loss: 208.60
 ---- batch: 030 ----
mean loss: 203.33
train mean loss: 203.36
epoch train time: 0:00:00.524135
elapsed time: 0:02:12.063236
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 14:49:20.892745
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.63
 ---- batch: 020 ----
mean loss: 200.96
 ---- batch: 030 ----
mean loss: 202.84
train mean loss: 203.65
epoch train time: 0:00:00.512675
elapsed time: 0:02:12.576181
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 14:49:21.405772
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 203.72
 ---- batch: 020 ----
mean loss: 199.72
 ---- batch: 030 ----
mean loss: 202.73
train mean loss: 202.17
epoch train time: 0:00:00.510234
elapsed time: 0:02:13.086741
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 14:49:21.916307
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.62
 ---- batch: 020 ----
mean loss: 204.37
 ---- batch: 030 ----
mean loss: 201.40
train mean loss: 203.00
epoch train time: 0:00:00.500891
elapsed time: 0:02:13.588062
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 14:49:22.417663
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 202.20
 ---- batch: 020 ----
mean loss: 209.59
 ---- batch: 030 ----
mean loss: 202.07
train mean loss: 202.98
epoch train time: 0:00:00.538078
elapsed time: 0:02:14.126465
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 14:49:22.956017
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.27
 ---- batch: 020 ----
mean loss: 203.02
 ---- batch: 030 ----
mean loss: 199.95
train mean loss: 203.29
epoch train time: 0:00:00.503858
elapsed time: 0:02:14.630637
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 14:49:23.460215
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 198.10
 ---- batch: 020 ----
mean loss: 207.95
 ---- batch: 030 ----
mean loss: 200.36
train mean loss: 202.94
epoch train time: 0:00:00.513961
elapsed time: 0:02:15.144911
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 14:49:23.974483
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.44
 ---- batch: 020 ----
mean loss: 201.67
 ---- batch: 030 ----
mean loss: 204.96
train mean loss: 202.22
epoch train time: 0:00:00.507918
elapsed time: 0:02:15.653135
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 14:49:24.482690
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 208.12
 ---- batch: 020 ----
mean loss: 202.13
 ---- batch: 030 ----
mean loss: 198.67
train mean loss: 202.50
epoch train time: 0:00:00.508893
elapsed time: 0:02:16.162353
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 14:49:24.991938
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 203.52
 ---- batch: 020 ----
mean loss: 199.11
 ---- batch: 030 ----
mean loss: 205.97
train mean loss: 202.99
epoch train time: 0:00:00.502969
elapsed time: 0:02:16.665681
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 14:49:25.495220
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.68
 ---- batch: 020 ----
mean loss: 208.03
 ---- batch: 030 ----
mean loss: 200.96
train mean loss: 202.75
epoch train time: 0:00:00.503225
elapsed time: 0:02:17.169165
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 14:49:25.998713
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.92
 ---- batch: 020 ----
mean loss: 202.76
 ---- batch: 030 ----
mean loss: 197.23
train mean loss: 202.35
epoch train time: 0:00:00.498583
elapsed time: 0:02:17.668013
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 14:49:26.497562
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 207.16
 ---- batch: 020 ----
mean loss: 196.80
 ---- batch: 030 ----
mean loss: 203.25
train mean loss: 202.54
epoch train time: 0:00:00.512810
elapsed time: 0:02:18.181181
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 14:49:27.010731
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 196.93
 ---- batch: 020 ----
mean loss: 205.75
 ---- batch: 030 ----
mean loss: 199.60
train mean loss: 201.85
epoch train time: 0:00:00.502583
elapsed time: 0:02:18.684036
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 14:49:27.513634
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 201.68
 ---- batch: 020 ----
mean loss: 206.22
 ---- batch: 030 ----
mean loss: 197.37
train mean loss: 202.70
epoch train time: 0:00:00.520521
elapsed time: 0:02:19.204872
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 14:49:28.034423
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 205.73
 ---- batch: 020 ----
mean loss: 202.01
 ---- batch: 030 ----
mean loss: 203.83
train mean loss: 202.67
epoch train time: 0:00:00.502596
elapsed time: 0:02:19.707744
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 14:49:28.537316
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 200.15
 ---- batch: 020 ----
mean loss: 200.82
 ---- batch: 030 ----
mean loss: 204.32
train mean loss: 202.35
epoch train time: 0:00:00.518622
elapsed time: 0:02:20.230430
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_3/checkpoint.pth.tar
**** end time: 2019-09-27 14:49:29.059912 ****
