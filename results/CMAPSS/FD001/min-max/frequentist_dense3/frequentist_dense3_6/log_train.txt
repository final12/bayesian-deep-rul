Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_6', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32314
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 16:59:10.586407 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 16:59:10.589669
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4123.64
 ---- batch: 020 ----
mean loss: 3893.26
 ---- batch: 030 ----
mean loss: 3876.61
train mean loss: 3944.87
epoch train time: 0:00:12.756858
elapsed time: 0:00:12.762354
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 16:59:23.348799
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3762.86
 ---- batch: 020 ----
mean loss: 3670.53
 ---- batch: 030 ----
mean loss: 3644.99
train mean loss: 3686.07
epoch train time: 0:00:00.174161
elapsed time: 0:00:12.936644
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 16:59:23.523109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3567.07
 ---- batch: 020 ----
mean loss: 3507.49
 ---- batch: 030 ----
mean loss: 3478.36
train mean loss: 3501.55
epoch train time: 0:00:00.170330
elapsed time: 0:00:13.107121
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 16:59:23.693578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3372.17
 ---- batch: 020 ----
mean loss: 3304.18
 ---- batch: 030 ----
mean loss: 3298.66
train mean loss: 3322.72
epoch train time: 0:00:00.177094
elapsed time: 0:00:13.284369
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 16:59:23.870827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3167.73
 ---- batch: 020 ----
mean loss: 3115.46
 ---- batch: 030 ----
mean loss: 3189.01
train mean loss: 3146.34
epoch train time: 0:00:00.178282
elapsed time: 0:00:13.462794
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 16:59:24.049248
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3031.51
 ---- batch: 020 ----
mean loss: 2965.60
 ---- batch: 030 ----
mean loss: 2952.91
train mean loss: 2973.10
epoch train time: 0:00:00.169694
elapsed time: 0:00:13.632633
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 16:59:24.219090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2885.12
 ---- batch: 020 ----
mean loss: 2809.05
 ---- batch: 030 ----
mean loss: 2756.48
train mean loss: 2805.68
epoch train time: 0:00:00.171978
elapsed time: 0:00:13.804761
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 16:59:24.391211
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2697.21
 ---- batch: 020 ----
mean loss: 2672.88
 ---- batch: 030 ----
mean loss: 2579.36
train mean loss: 2639.64
epoch train time: 0:00:00.176019
elapsed time: 0:00:13.980914
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 16:59:24.567401
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2534.27
 ---- batch: 020 ----
mean loss: 2495.24
 ---- batch: 030 ----
mean loss: 2461.96
train mean loss: 2487.27
epoch train time: 0:00:00.175063
elapsed time: 0:00:14.156156
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 16:59:24.742605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2411.44
 ---- batch: 020 ----
mean loss: 2350.49
 ---- batch: 030 ----
mean loss: 2325.44
train mean loss: 2349.50
epoch train time: 0:00:00.170868
elapsed time: 0:00:14.327158
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 16:59:24.913636
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2254.05
 ---- batch: 020 ----
mean loss: 2244.01
 ---- batch: 030 ----
mean loss: 2185.36
train mean loss: 2217.14
epoch train time: 0:00:00.171549
elapsed time: 0:00:14.498875
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 16:59:25.085323
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2127.46
 ---- batch: 020 ----
mean loss: 2111.07
 ---- batch: 030 ----
mean loss: 2037.44
train mean loss: 2089.48
epoch train time: 0:00:00.168299
elapsed time: 0:00:14.667309
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 16:59:25.253767
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2015.90
 ---- batch: 020 ----
mean loss: 1957.48
 ---- batch: 030 ----
mean loss: 1956.98
train mean loss: 1961.89
epoch train time: 0:00:00.168940
elapsed time: 0:00:14.836394
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 16:59:25.422841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1917.55
 ---- batch: 020 ----
mean loss: 1860.43
 ---- batch: 030 ----
mean loss: 1798.33
train mean loss: 1843.77
epoch train time: 0:00:00.172751
elapsed time: 0:00:15.009274
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 16:59:25.595728
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1768.65
 ---- batch: 020 ----
mean loss: 1746.01
 ---- batch: 030 ----
mean loss: 1714.19
train mean loss: 1735.77
epoch train time: 0:00:00.173926
elapsed time: 0:00:15.183339
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 16:59:25.769795
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1661.23
 ---- batch: 020 ----
mean loss: 1633.75
 ---- batch: 030 ----
mean loss: 1621.21
train mean loss: 1633.12
epoch train time: 0:00:00.175523
elapsed time: 0:00:15.359009
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 16:59:25.945465
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1572.14
 ---- batch: 020 ----
mean loss: 1536.96
 ---- batch: 030 ----
mean loss: 1518.57
train mean loss: 1537.08
epoch train time: 0:00:00.184912
elapsed time: 0:00:15.544074
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 16:59:26.130525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1484.15
 ---- batch: 020 ----
mean loss: 1455.78
 ---- batch: 030 ----
mean loss: 1407.82
train mean loss: 1448.99
epoch train time: 0:00:00.171616
elapsed time: 0:00:15.715829
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 16:59:26.302286
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1399.26
 ---- batch: 020 ----
mean loss: 1376.43
 ---- batch: 030 ----
mean loss: 1338.65
train mean loss: 1365.19
epoch train time: 0:00:00.175073
elapsed time: 0:00:15.891043
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 16:59:26.477499
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1319.78
 ---- batch: 020 ----
mean loss: 1288.09
 ---- batch: 030 ----
mean loss: 1268.39
train mean loss: 1286.79
epoch train time: 0:00:00.174028
elapsed time: 0:00:16.065772
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 16:59:26.652267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1224.48
 ---- batch: 020 ----
mean loss: 1218.57
 ---- batch: 030 ----
mean loss: 1199.13
train mean loss: 1215.03
epoch train time: 0:00:00.179373
elapsed time: 0:00:16.245354
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 16:59:26.831808
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1160.30
 ---- batch: 020 ----
mean loss: 1176.78
 ---- batch: 030 ----
mean loss: 1132.45
train mean loss: 1146.43
epoch train time: 0:00:00.171675
elapsed time: 0:00:16.417182
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 16:59:27.003643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1113.94
 ---- batch: 020 ----
mean loss: 1087.81
 ---- batch: 030 ----
mean loss: 1072.85
train mean loss: 1082.48
epoch train time: 0:00:00.168564
elapsed time: 0:00:16.585901
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 16:59:27.172355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1029.25
 ---- batch: 020 ----
mean loss: 1042.07
 ---- batch: 030 ----
mean loss: 1025.51
train mean loss: 1022.11
epoch train time: 0:00:00.166673
elapsed time: 0:00:16.752740
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 16:59:27.339196
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 996.40
 ---- batch: 020 ----
mean loss: 984.29
 ---- batch: 030 ----
mean loss: 945.42
train mean loss: 966.16
epoch train time: 0:00:00.172119
elapsed time: 0:00:16.925009
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 16:59:27.511478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 919.01
 ---- batch: 020 ----
mean loss: 934.71
 ---- batch: 030 ----
mean loss: 907.55
train mean loss: 914.69
epoch train time: 0:00:00.170464
elapsed time: 0:00:17.095638
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 16:59:27.682108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 885.71
 ---- batch: 020 ----
mean loss: 874.75
 ---- batch: 030 ----
mean loss: 837.53
train mean loss: 866.26
epoch train time: 0:00:00.179282
elapsed time: 0:00:17.275075
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 16:59:27.861530
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 840.27
 ---- batch: 020 ----
mean loss: 824.37
 ---- batch: 030 ----
mean loss: 799.39
train mean loss: 818.60
epoch train time: 0:00:00.171997
elapsed time: 0:00:17.447235
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 16:59:28.033694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 780.06
 ---- batch: 020 ----
mean loss: 797.69
 ---- batch: 030 ----
mean loss: 762.64
train mean loss: 774.71
epoch train time: 0:00:00.171106
elapsed time: 0:00:17.618481
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 16:59:28.204935
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 745.38
 ---- batch: 020 ----
mean loss: 736.12
 ---- batch: 030 ----
mean loss: 725.70
train mean loss: 734.63
epoch train time: 0:00:00.167369
elapsed time: 0:00:17.785998
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 16:59:28.372452
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 706.42
 ---- batch: 020 ----
mean loss: 686.14
 ---- batch: 030 ----
mean loss: 708.36
train mean loss: 697.02
epoch train time: 0:00:00.167975
elapsed time: 0:00:17.954109
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 16:59:28.540575
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 672.41
 ---- batch: 020 ----
mean loss: 668.62
 ---- batch: 030 ----
mean loss: 649.77
train mean loss: 659.68
epoch train time: 0:00:00.171697
elapsed time: 0:00:18.125965
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 16:59:28.712423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 640.93
 ---- batch: 020 ----
mean loss: 622.77
 ---- batch: 030 ----
mean loss: 610.34
train mean loss: 625.85
epoch train time: 0:00:00.173917
elapsed time: 0:00:18.300023
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 16:59:28.886494
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 603.97
 ---- batch: 020 ----
mean loss: 605.77
 ---- batch: 030 ----
mean loss: 579.77
train mean loss: 591.92
epoch train time: 0:00:00.172912
elapsed time: 0:00:18.473089
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 16:59:29.059542
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 562.38
 ---- batch: 020 ----
mean loss: 564.67
 ---- batch: 030 ----
mean loss: 550.18
train mean loss: 557.14
epoch train time: 0:00:00.172491
elapsed time: 0:00:18.645769
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 16:59:29.232251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 530.38
 ---- batch: 020 ----
mean loss: 520.42
 ---- batch: 030 ----
mean loss: 529.12
train mean loss: 523.61
epoch train time: 0:00:00.170589
elapsed time: 0:00:18.816545
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 16:59:29.403016
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 503.22
 ---- batch: 020 ----
mean loss: 492.04
 ---- batch: 030 ----
mean loss: 482.91
train mean loss: 490.33
epoch train time: 0:00:00.173026
elapsed time: 0:00:18.989735
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 16:59:29.576186
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.65
 ---- batch: 020 ----
mean loss: 457.09
 ---- batch: 030 ----
mean loss: 455.11
train mean loss: 459.42
epoch train time: 0:00:00.174103
elapsed time: 0:00:19.163973
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 16:59:29.750440
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 447.36
 ---- batch: 020 ----
mean loss: 435.28
 ---- batch: 030 ----
mean loss: 424.71
train mean loss: 431.97
epoch train time: 0:00:00.173508
elapsed time: 0:00:19.337638
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 16:59:29.924094
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 416.11
 ---- batch: 020 ----
mean loss: 401.64
 ---- batch: 030 ----
mean loss: 403.99
train mean loss: 406.40
epoch train time: 0:00:00.173020
elapsed time: 0:00:19.510804
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 16:59:30.097252
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 395.60
 ---- batch: 020 ----
mean loss: 373.91
 ---- batch: 030 ----
mean loss: 380.51
train mean loss: 383.50
epoch train time: 0:00:00.168784
elapsed time: 0:00:19.679720
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 16:59:30.266175
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 364.80
 ---- batch: 020 ----
mean loss: 356.43
 ---- batch: 030 ----
mean loss: 364.11
train mean loss: 359.93
epoch train time: 0:00:00.167265
elapsed time: 0:00:19.847124
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 16:59:30.433579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 353.75
 ---- batch: 020 ----
mean loss: 339.18
 ---- batch: 030 ----
mean loss: 324.69
train mean loss: 338.28
epoch train time: 0:00:00.167626
elapsed time: 0:00:20.014894
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 16:59:30.601341
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 320.60
 ---- batch: 020 ----
mean loss: 322.49
 ---- batch: 030 ----
mean loss: 315.08
train mean loss: 318.73
epoch train time: 0:00:00.170836
elapsed time: 0:00:20.185875
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 16:59:30.772329
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 306.72
 ---- batch: 020 ----
mean loss: 297.60
 ---- batch: 030 ----
mean loss: 298.64
train mean loss: 300.26
epoch train time: 0:00:00.171953
elapsed time: 0:00:20.357963
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 16:59:30.944418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 289.55
 ---- batch: 020 ----
mean loss: 278.54
 ---- batch: 030 ----
mean loss: 279.35
train mean loss: 283.55
epoch train time: 0:00:00.169755
elapsed time: 0:00:20.527851
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 16:59:31.114302
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.05
 ---- batch: 020 ----
mean loss: 274.11
 ---- batch: 030 ----
mean loss: 264.87
train mean loss: 267.47
epoch train time: 0:00:00.164886
elapsed time: 0:00:20.692927
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 16:59:31.279409
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.67
 ---- batch: 020 ----
mean loss: 254.50
 ---- batch: 030 ----
mean loss: 255.57
train mean loss: 253.32
epoch train time: 0:00:00.162822
elapsed time: 0:00:20.855910
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 16:59:31.442365
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 244.75
 ---- batch: 020 ----
mean loss: 239.49
 ---- batch: 030 ----
mean loss: 240.94
train mean loss: 240.45
epoch train time: 0:00:00.169675
elapsed time: 0:00:21.025737
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 16:59:31.612198
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.77
 ---- batch: 020 ----
mean loss: 231.33
 ---- batch: 030 ----
mean loss: 224.01
train mean loss: 228.38
epoch train time: 0:00:00.179869
elapsed time: 0:00:21.205754
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 16:59:31.792210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.82
 ---- batch: 020 ----
mean loss: 213.75
 ---- batch: 030 ----
mean loss: 217.56
train mean loss: 217.13
epoch train time: 0:00:00.175269
elapsed time: 0:00:21.381164
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 16:59:31.967620
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.67
 ---- batch: 020 ----
mean loss: 207.72
 ---- batch: 030 ----
mean loss: 202.56
train mean loss: 206.66
epoch train time: 0:00:00.174857
elapsed time: 0:00:21.556161
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 16:59:32.142613
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 203.04
 ---- batch: 020 ----
mean loss: 194.70
 ---- batch: 030 ----
mean loss: 195.52
train mean loss: 196.50
epoch train time: 0:00:00.168919
elapsed time: 0:00:21.725215
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 16:59:32.311667
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.17
 ---- batch: 020 ----
mean loss: 192.32
 ---- batch: 030 ----
mean loss: 185.13
train mean loss: 187.68
epoch train time: 0:00:00.168349
elapsed time: 0:00:21.893698
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 16:59:32.480168
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.01
 ---- batch: 020 ----
mean loss: 176.31
 ---- batch: 030 ----
mean loss: 179.27
train mean loss: 179.29
epoch train time: 0:00:00.171376
elapsed time: 0:00:22.065227
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 16:59:32.651682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 176.38
 ---- batch: 020 ----
mean loss: 173.07
 ---- batch: 030 ----
mean loss: 166.24
train mean loss: 171.52
epoch train time: 0:00:00.177206
elapsed time: 0:00:22.242574
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 16:59:32.829032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 165.94
 ---- batch: 020 ----
mean loss: 168.33
 ---- batch: 030 ----
mean loss: 161.98
train mean loss: 164.23
epoch train time: 0:00:00.172502
elapsed time: 0:00:22.415244
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 16:59:33.001707
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.71
 ---- batch: 020 ----
mean loss: 155.79
 ---- batch: 030 ----
mean loss: 159.54
train mean loss: 157.44
epoch train time: 0:00:00.171240
elapsed time: 0:00:22.586670
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 16:59:33.173134
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.09
 ---- batch: 020 ----
mean loss: 152.33
 ---- batch: 030 ----
mean loss: 152.21
train mean loss: 151.36
epoch train time: 0:00:00.171711
elapsed time: 0:00:22.758538
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 16:59:33.344995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.14
 ---- batch: 020 ----
mean loss: 143.67
 ---- batch: 030 ----
mean loss: 143.35
train mean loss: 145.29
epoch train time: 0:00:00.169690
elapsed time: 0:00:22.928369
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 16:59:33.514840
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 142.51
 ---- batch: 020 ----
mean loss: 139.91
 ---- batch: 030 ----
mean loss: 139.61
train mean loss: 140.25
epoch train time: 0:00:00.170542
elapsed time: 0:00:23.099075
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 16:59:33.685531
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 134.58
 ---- batch: 020 ----
mean loss: 134.36
 ---- batch: 030 ----
mean loss: 137.97
train mean loss: 135.24
epoch train time: 0:00:00.172323
elapsed time: 0:00:23.271541
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 16:59:33.858021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 132.81
 ---- batch: 020 ----
mean loss: 131.71
 ---- batch: 030 ----
mean loss: 127.76
train mean loss: 130.68
epoch train time: 0:00:00.172167
elapsed time: 0:00:23.443880
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 16:59:34.030337
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.26
 ---- batch: 020 ----
mean loss: 127.16
 ---- batch: 030 ----
mean loss: 126.26
train mean loss: 125.85
epoch train time: 0:00:00.173878
elapsed time: 0:00:23.617898
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 16:59:34.204352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.83
 ---- batch: 020 ----
mean loss: 121.44
 ---- batch: 030 ----
mean loss: 121.02
train mean loss: 121.91
epoch train time: 0:00:00.168374
elapsed time: 0:00:23.786424
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 16:59:34.372879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.94
 ---- batch: 020 ----
mean loss: 118.06
 ---- batch: 030 ----
mean loss: 119.06
train mean loss: 118.14
epoch train time: 0:00:00.170891
elapsed time: 0:00:23.957485
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 16:59:34.543939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.65
 ---- batch: 020 ----
mean loss: 115.83
 ---- batch: 030 ----
mean loss: 112.62
train mean loss: 114.54
epoch train time: 0:00:00.170984
elapsed time: 0:00:24.128615
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 16:59:34.715072
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.46
 ---- batch: 020 ----
mean loss: 110.94
 ---- batch: 030 ----
mean loss: 111.78
train mean loss: 111.67
epoch train time: 0:00:00.168963
elapsed time: 0:00:24.297733
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 16:59:34.884188
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.99
 ---- batch: 020 ----
mean loss: 106.54
 ---- batch: 030 ----
mean loss: 105.12
train mean loss: 108.42
epoch train time: 0:00:00.170200
elapsed time: 0:00:24.468070
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 16:59:35.054522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.29
 ---- batch: 020 ----
mean loss: 104.23
 ---- batch: 030 ----
mean loss: 105.86
train mean loss: 105.67
epoch train time: 0:00:00.166175
elapsed time: 0:00:24.634375
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 16:59:35.220827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.92
 ---- batch: 020 ----
mean loss: 104.36
 ---- batch: 030 ----
mean loss: 103.12
train mean loss: 103.05
epoch train time: 0:00:00.167621
elapsed time: 0:00:24.802129
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 16:59:35.388584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.69
 ---- batch: 020 ----
mean loss: 101.75
 ---- batch: 030 ----
mean loss: 99.46
train mean loss: 101.40
epoch train time: 0:00:00.170823
elapsed time: 0:00:24.973095
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 16:59:35.559552
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.05
 ---- batch: 020 ----
mean loss: 98.58
 ---- batch: 030 ----
mean loss: 99.73
train mean loss: 97.98
epoch train time: 0:00:00.181795
elapsed time: 0:00:25.155046
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 16:59:35.741505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.55
 ---- batch: 020 ----
mean loss: 97.94
 ---- batch: 030 ----
mean loss: 95.28
train mean loss: 95.71
epoch train time: 0:00:00.173662
elapsed time: 0:00:25.328852
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 16:59:35.915310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.15
 ---- batch: 020 ----
mean loss: 96.82
 ---- batch: 030 ----
mean loss: 93.94
train mean loss: 94.18
epoch train time: 0:00:00.167142
elapsed time: 0:00:25.496134
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 16:59:36.082588
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.41
 ---- batch: 020 ----
mean loss: 90.98
 ---- batch: 030 ----
mean loss: 93.80
train mean loss: 92.20
epoch train time: 0:00:00.170942
elapsed time: 0:00:25.667233
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 16:59:36.253717
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.13
 ---- batch: 020 ----
mean loss: 88.94
 ---- batch: 030 ----
mean loss: 87.56
train mean loss: 90.55
epoch train time: 0:00:00.167280
elapsed time: 0:00:25.834678
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 16:59:36.421146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.75
 ---- batch: 020 ----
mean loss: 87.37
 ---- batch: 030 ----
mean loss: 89.22
train mean loss: 88.31
epoch train time: 0:00:00.170769
elapsed time: 0:00:26.005601
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 16:59:36.592055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.34
 ---- batch: 020 ----
mean loss: 86.12
 ---- batch: 030 ----
mean loss: 88.92
train mean loss: 87.11
epoch train time: 0:00:00.173361
elapsed time: 0:00:26.179099
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 16:59:36.765554
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.81
 ---- batch: 020 ----
mean loss: 85.11
 ---- batch: 030 ----
mean loss: 86.06
train mean loss: 85.64
epoch train time: 0:00:00.172542
elapsed time: 0:00:26.351783
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 16:59:36.938240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.53
 ---- batch: 020 ----
mean loss: 81.79
 ---- batch: 030 ----
mean loss: 83.58
train mean loss: 84.05
epoch train time: 0:00:00.172640
elapsed time: 0:00:26.524571
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 16:59:37.111041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.10
 ---- batch: 020 ----
mean loss: 84.10
 ---- batch: 030 ----
mean loss: 84.23
train mean loss: 82.86
epoch train time: 0:00:00.168802
elapsed time: 0:00:26.693536
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 16:59:37.279994
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 79.36
 ---- batch: 020 ----
mean loss: 84.17
 ---- batch: 030 ----
mean loss: 78.69
train mean loss: 81.48
epoch train time: 0:00:00.172998
elapsed time: 0:00:26.866676
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 16:59:37.453132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.73
 ---- batch: 020 ----
mean loss: 78.28
 ---- batch: 030 ----
mean loss: 80.39
train mean loss: 80.08
epoch train time: 0:00:00.171734
elapsed time: 0:00:27.038567
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 16:59:37.625018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.65
 ---- batch: 020 ----
mean loss: 81.84
 ---- batch: 030 ----
mean loss: 78.84
train mean loss: 78.97
epoch train time: 0:00:00.170990
elapsed time: 0:00:27.209705
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 16:59:37.796158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.91
 ---- batch: 020 ----
mean loss: 79.16
 ---- batch: 030 ----
mean loss: 77.03
train mean loss: 77.94
epoch train time: 0:00:00.176700
elapsed time: 0:00:27.386542
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 16:59:37.972998
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.94
 ---- batch: 020 ----
mean loss: 76.02
 ---- batch: 030 ----
mean loss: 80.22
train mean loss: 77.23
epoch train time: 0:00:00.171409
elapsed time: 0:00:27.558089
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 16:59:38.144543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.44
 ---- batch: 020 ----
mean loss: 76.80
 ---- batch: 030 ----
mean loss: 74.37
train mean loss: 76.37
epoch train time: 0:00:00.169164
elapsed time: 0:00:27.727393
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 16:59:38.313868
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.14
 ---- batch: 020 ----
mean loss: 72.51
 ---- batch: 030 ----
mean loss: 75.45
train mean loss: 75.21
epoch train time: 0:00:00.168289
elapsed time: 0:00:27.895844
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 16:59:38.482316
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 74.84
 ---- batch: 020 ----
mean loss: 72.31
 ---- batch: 030 ----
mean loss: 75.04
train mean loss: 74.32
epoch train time: 0:00:00.175133
elapsed time: 0:00:28.071139
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 16:59:38.657664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.87
 ---- batch: 020 ----
mean loss: 73.59
 ---- batch: 030 ----
mean loss: 74.01
train mean loss: 73.43
epoch train time: 0:00:00.183749
elapsed time: 0:00:28.255100
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 16:59:38.841556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.67
 ---- batch: 020 ----
mean loss: 74.07
 ---- batch: 030 ----
mean loss: 72.95
train mean loss: 72.51
epoch train time: 0:00:00.172393
elapsed time: 0:00:28.427635
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 16:59:39.014091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.26
 ---- batch: 020 ----
mean loss: 72.66
 ---- batch: 030 ----
mean loss: 73.59
train mean loss: 73.27
epoch train time: 0:00:00.170626
elapsed time: 0:00:28.598417
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 16:59:39.184872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.76
 ---- batch: 020 ----
mean loss: 70.60
 ---- batch: 030 ----
mean loss: 72.44
train mean loss: 71.14
epoch train time: 0:00:00.172364
elapsed time: 0:00:28.770921
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 16:59:39.357377
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.76
 ---- batch: 020 ----
mean loss: 70.09
 ---- batch: 030 ----
mean loss: 71.12
train mean loss: 70.84
epoch train time: 0:00:00.170427
elapsed time: 0:00:28.941490
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 16:59:39.527944
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.88
 ---- batch: 020 ----
mean loss: 68.43
 ---- batch: 030 ----
mean loss: 72.55
train mean loss: 70.43
epoch train time: 0:00:00.171664
elapsed time: 0:00:29.113299
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 16:59:39.699764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.83
 ---- batch: 020 ----
mean loss: 69.78
 ---- batch: 030 ----
mean loss: 71.16
train mean loss: 68.98
epoch train time: 0:00:00.172289
elapsed time: 0:00:29.285740
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 16:59:39.872199
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.18
 ---- batch: 020 ----
mean loss: 69.41
 ---- batch: 030 ----
mean loss: 69.76
train mean loss: 69.44
epoch train time: 0:00:00.171187
elapsed time: 0:00:29.457071
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 16:59:40.043528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.34
 ---- batch: 020 ----
mean loss: 68.51
 ---- batch: 030 ----
mean loss: 67.94
train mean loss: 68.63
epoch train time: 0:00:00.172817
elapsed time: 0:00:29.630027
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 16:59:40.216495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.95
 ---- batch: 020 ----
mean loss: 68.47
 ---- batch: 030 ----
mean loss: 65.73
train mean loss: 68.15
epoch train time: 0:00:00.167909
elapsed time: 0:00:29.798084
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 16:59:40.384539
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.93
 ---- batch: 020 ----
mean loss: 66.78
 ---- batch: 030 ----
mean loss: 64.38
train mean loss: 67.18
epoch train time: 0:00:00.169127
elapsed time: 0:00:29.967347
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 16:59:40.553801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.21
 ---- batch: 020 ----
mean loss: 66.27
 ---- batch: 030 ----
mean loss: 66.26
train mean loss: 66.83
epoch train time: 0:00:00.170122
elapsed time: 0:00:30.137628
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 16:59:40.724089
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.59
 ---- batch: 020 ----
mean loss: 68.48
 ---- batch: 030 ----
mean loss: 66.16
train mean loss: 66.38
epoch train time: 0:00:00.179191
elapsed time: 0:00:30.316965
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 16:59:40.903439
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.82
 ---- batch: 020 ----
mean loss: 66.89
 ---- batch: 030 ----
mean loss: 64.95
train mean loss: 66.03
epoch train time: 0:00:00.173859
elapsed time: 0:00:30.490980
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 16:59:41.077434
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.16
 ---- batch: 020 ----
mean loss: 63.63
 ---- batch: 030 ----
mean loss: 63.68
train mean loss: 65.33
epoch train time: 0:00:00.167710
elapsed time: 0:00:30.658825
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 16:59:41.245278
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.40
 ---- batch: 020 ----
mean loss: 63.76
 ---- batch: 030 ----
mean loss: 66.30
train mean loss: 65.14
epoch train time: 0:00:00.172389
elapsed time: 0:00:30.831396
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 16:59:41.417867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.64
 ---- batch: 020 ----
mean loss: 64.30
 ---- batch: 030 ----
mean loss: 63.02
train mean loss: 64.65
epoch train time: 0:00:00.170266
elapsed time: 0:00:31.001824
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 16:59:41.588268
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.54
 ---- batch: 020 ----
mean loss: 64.76
 ---- batch: 030 ----
mean loss: 65.53
train mean loss: 64.51
epoch train time: 0:00:00.173091
elapsed time: 0:00:31.175046
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 16:59:41.761505
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.47
 ---- batch: 020 ----
mean loss: 64.83
 ---- batch: 030 ----
mean loss: 61.59
train mean loss: 64.00
epoch train time: 0:00:00.177646
elapsed time: 0:00:31.352838
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 16:59:41.939293
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.79
 ---- batch: 020 ----
mean loss: 63.82
 ---- batch: 030 ----
mean loss: 64.65
train mean loss: 63.85
epoch train time: 0:00:00.177003
elapsed time: 0:00:31.529980
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 16:59:42.116435
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.10
 ---- batch: 020 ----
mean loss: 63.05
 ---- batch: 030 ----
mean loss: 65.24
train mean loss: 62.97
epoch train time: 0:00:00.173141
elapsed time: 0:00:31.703303
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 16:59:42.289765
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.37
 ---- batch: 020 ----
mean loss: 62.14
 ---- batch: 030 ----
mean loss: 62.82
train mean loss: 63.26
epoch train time: 0:00:00.171758
elapsed time: 0:00:31.875236
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 16:59:42.461698
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.98
 ---- batch: 020 ----
mean loss: 62.82
 ---- batch: 030 ----
mean loss: 61.99
train mean loss: 62.73
epoch train time: 0:00:00.173528
elapsed time: 0:00:32.048910
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 16:59:42.635375
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.79
 ---- batch: 020 ----
mean loss: 61.44
 ---- batch: 030 ----
mean loss: 64.07
train mean loss: 62.48
epoch train time: 0:00:00.183636
elapsed time: 0:00:32.232694
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 16:59:42.819164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.14
 ---- batch: 020 ----
mean loss: 59.54
 ---- batch: 030 ----
mean loss: 63.23
train mean loss: 61.83
epoch train time: 0:00:00.169492
elapsed time: 0:00:32.402337
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 16:59:42.988822
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.84
 ---- batch: 020 ----
mean loss: 61.10
 ---- batch: 030 ----
mean loss: 63.63
train mean loss: 62.38
epoch train time: 0:00:00.169780
elapsed time: 0:00:32.572287
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 16:59:43.158742
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.51
 ---- batch: 020 ----
mean loss: 61.49
 ---- batch: 030 ----
mean loss: 63.89
train mean loss: 63.09
epoch train time: 0:00:00.168609
elapsed time: 0:00:32.741034
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 16:59:43.327515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.65
 ---- batch: 020 ----
mean loss: 61.58
 ---- batch: 030 ----
mean loss: 62.88
train mean loss: 61.79
epoch train time: 0:00:00.173914
elapsed time: 0:00:32.915141
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 16:59:43.501596
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.15
 ---- batch: 020 ----
mean loss: 60.45
 ---- batch: 030 ----
mean loss: 62.29
train mean loss: 61.12
epoch train time: 0:00:00.169767
elapsed time: 0:00:33.085062
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 16:59:43.671517
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.30
 ---- batch: 020 ----
mean loss: 61.99
 ---- batch: 030 ----
mean loss: 61.79
train mean loss: 62.15
epoch train time: 0:00:00.181827
elapsed time: 0:00:33.267047
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 16:59:43.853512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.44
 ---- batch: 020 ----
mean loss: 62.17
 ---- batch: 030 ----
mean loss: 59.58
train mean loss: 61.18
epoch train time: 0:00:00.177345
elapsed time: 0:00:33.444541
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 16:59:44.031011
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.61
 ---- batch: 020 ----
mean loss: 60.31
 ---- batch: 030 ----
mean loss: 61.11
train mean loss: 60.21
epoch train time: 0:00:00.172152
elapsed time: 0:00:33.616856
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 16:59:44.203370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.94
 ---- batch: 020 ----
mean loss: 60.64
 ---- batch: 030 ----
mean loss: 58.71
train mean loss: 59.65
epoch train time: 0:00:00.169076
elapsed time: 0:00:33.786127
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 16:59:44.372583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.21
 ---- batch: 020 ----
mean loss: 59.81
 ---- batch: 030 ----
mean loss: 58.71
train mean loss: 59.31
epoch train time: 0:00:00.171831
elapsed time: 0:00:33.958096
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 16:59:44.544551
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.34
 ---- batch: 020 ----
mean loss: 57.43
 ---- batch: 030 ----
mean loss: 60.70
train mean loss: 59.90
epoch train time: 0:00:00.171357
elapsed time: 0:00:34.129608
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 16:59:44.716062
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.01
 ---- batch: 020 ----
mean loss: 57.32
 ---- batch: 030 ----
mean loss: 57.82
train mean loss: 59.21
epoch train time: 0:00:00.171893
elapsed time: 0:00:34.301635
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 16:59:44.888090
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.70
 ---- batch: 020 ----
mean loss: 58.97
 ---- batch: 030 ----
mean loss: 60.04
train mean loss: 59.05
epoch train time: 0:00:00.173129
elapsed time: 0:00:34.474961
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 16:59:45.061403
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.34
 ---- batch: 020 ----
mean loss: 59.13
 ---- batch: 030 ----
mean loss: 60.65
train mean loss: 59.40
epoch train time: 0:00:00.172590
elapsed time: 0:00:34.647679
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 16:59:45.234143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.28
 ---- batch: 020 ----
mean loss: 58.62
 ---- batch: 030 ----
mean loss: 57.67
train mean loss: 58.78
epoch train time: 0:00:00.167235
elapsed time: 0:00:34.815066
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 16:59:45.401537
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.89
 ---- batch: 020 ----
mean loss: 59.78
 ---- batch: 030 ----
mean loss: 56.93
train mean loss: 58.31
epoch train time: 0:00:00.171685
elapsed time: 0:00:34.986905
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 16:59:45.573391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.29
 ---- batch: 020 ----
mean loss: 57.73
 ---- batch: 030 ----
mean loss: 57.90
train mean loss: 58.67
epoch train time: 0:00:00.170026
elapsed time: 0:00:35.157152
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 16:59:45.743621
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.53
 ---- batch: 020 ----
mean loss: 57.57
 ---- batch: 030 ----
mean loss: 57.81
train mean loss: 57.85
epoch train time: 0:00:00.174214
elapsed time: 0:00:35.331522
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 16:59:45.917980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.03
 ---- batch: 020 ----
mean loss: 60.97
 ---- batch: 030 ----
mean loss: 55.47
train mean loss: 57.99
epoch train time: 0:00:00.172167
elapsed time: 0:00:35.503833
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 16:59:46.090289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.51
 ---- batch: 020 ----
mean loss: 59.10
 ---- batch: 030 ----
mean loss: 58.45
train mean loss: 58.67
epoch train time: 0:00:00.172620
elapsed time: 0:00:35.676621
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 16:59:46.263075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.17
 ---- batch: 020 ----
mean loss: 57.22
 ---- batch: 030 ----
mean loss: 57.26
train mean loss: 57.32
epoch train time: 0:00:00.169253
elapsed time: 0:00:35.846020
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 16:59:46.432478
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.07
 ---- batch: 020 ----
mean loss: 55.17
 ---- batch: 030 ----
mean loss: 58.40
train mean loss: 57.24
epoch train time: 0:00:00.173921
elapsed time: 0:00:36.020081
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 16:59:46.606536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.98
 ---- batch: 020 ----
mean loss: 57.24
 ---- batch: 030 ----
mean loss: 55.18
train mean loss: 57.11
epoch train time: 0:00:00.175823
elapsed time: 0:00:36.196043
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 16:59:46.782501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.68
 ---- batch: 020 ----
mean loss: 59.83
 ---- batch: 030 ----
mean loss: 53.65
train mean loss: 57.16
epoch train time: 0:00:00.178751
elapsed time: 0:00:36.374938
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 16:59:46.961395
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.90
 ---- batch: 020 ----
mean loss: 60.81
 ---- batch: 030 ----
mean loss: 57.59
train mean loss: 58.00
epoch train time: 0:00:00.173913
elapsed time: 0:00:36.549010
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 16:59:47.135466
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.47
 ---- batch: 020 ----
mean loss: 58.04
 ---- batch: 030 ----
mean loss: 56.73
train mean loss: 56.44
epoch train time: 0:00:00.177013
elapsed time: 0:00:36.726177
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 16:59:47.312637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.75
 ---- batch: 020 ----
mean loss: 57.16
 ---- batch: 030 ----
mean loss: 59.40
train mean loss: 57.62
epoch train time: 0:00:00.174174
elapsed time: 0:00:36.900495
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 16:59:47.486953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.03
 ---- batch: 020 ----
mean loss: 57.07
 ---- batch: 030 ----
mean loss: 58.73
train mean loss: 56.87
epoch train time: 0:00:00.174757
elapsed time: 0:00:37.075411
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 16:59:47.661875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.87
 ---- batch: 020 ----
mean loss: 56.35
 ---- batch: 030 ----
mean loss: 57.05
train mean loss: 56.33
epoch train time: 0:00:00.184167
elapsed time: 0:00:37.259738
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 16:59:47.846195
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.87
 ---- batch: 020 ----
mean loss: 55.11
 ---- batch: 030 ----
mean loss: 56.69
train mean loss: 55.80
epoch train time: 0:00:00.176757
elapsed time: 0:00:37.436639
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 16:59:48.023129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.87
 ---- batch: 020 ----
mean loss: 53.99
 ---- batch: 030 ----
mean loss: 56.26
train mean loss: 55.70
epoch train time: 0:00:00.170578
elapsed time: 0:00:37.607395
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 16:59:48.193851
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.05
 ---- batch: 020 ----
mean loss: 55.71
 ---- batch: 030 ----
mean loss: 54.19
train mean loss: 55.55
epoch train time: 0:00:00.174550
elapsed time: 0:00:37.782086
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 16:59:48.368543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.42
 ---- batch: 020 ----
mean loss: 57.37
 ---- batch: 030 ----
mean loss: 53.98
train mean loss: 55.45
epoch train time: 0:00:00.171981
elapsed time: 0:00:37.954234
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 16:59:48.540686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.07
 ---- batch: 020 ----
mean loss: 55.26
 ---- batch: 030 ----
mean loss: 55.89
train mean loss: 55.10
epoch train time: 0:00:00.172397
elapsed time: 0:00:38.126779
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 16:59:48.713238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.88
 ---- batch: 020 ----
mean loss: 56.28
 ---- batch: 030 ----
mean loss: 54.32
train mean loss: 55.37
epoch train time: 0:00:00.173431
elapsed time: 0:00:38.300383
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 16:59:48.886828
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.78
 ---- batch: 020 ----
mean loss: 56.08
 ---- batch: 030 ----
mean loss: 53.78
train mean loss: 55.45
epoch train time: 0:00:00.174441
elapsed time: 0:00:38.474958
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 16:59:49.061416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.67
 ---- batch: 020 ----
mean loss: 54.51
 ---- batch: 030 ----
mean loss: 54.92
train mean loss: 54.60
epoch train time: 0:00:00.172299
elapsed time: 0:00:38.647417
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 16:59:49.233888
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.08
 ---- batch: 020 ----
mean loss: 55.68
 ---- batch: 030 ----
mean loss: 60.24
train mean loss: 55.88
epoch train time: 0:00:00.173433
elapsed time: 0:00:38.821006
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 16:59:49.407461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.50
 ---- batch: 020 ----
mean loss: 56.72
 ---- batch: 030 ----
mean loss: 52.54
train mean loss: 54.53
epoch train time: 0:00:00.175596
elapsed time: 0:00:38.996756
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 16:59:49.583212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.22
 ---- batch: 020 ----
mean loss: 54.17
 ---- batch: 030 ----
mean loss: 55.50
train mean loss: 54.53
epoch train time: 0:00:00.178895
elapsed time: 0:00:39.175789
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 16:59:49.762242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.15
 ---- batch: 020 ----
mean loss: 55.80
 ---- batch: 030 ----
mean loss: 54.59
train mean loss: 54.73
epoch train time: 0:00:00.179469
elapsed time: 0:00:39.355398
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 16:59:49.941853
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.74
 ---- batch: 020 ----
mean loss: 54.77
 ---- batch: 030 ----
mean loss: 56.57
train mean loss: 54.02
epoch train time: 0:00:00.168025
elapsed time: 0:00:39.523563
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 16:59:50.110018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.66
 ---- batch: 020 ----
mean loss: 53.27
 ---- batch: 030 ----
mean loss: 53.02
train mean loss: 53.78
epoch train time: 0:00:00.165321
elapsed time: 0:00:39.689052
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 16:59:50.275503
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.41
 ---- batch: 020 ----
mean loss: 55.33
 ---- batch: 030 ----
mean loss: 55.64
train mean loss: 55.51
epoch train time: 0:00:00.165637
elapsed time: 0:00:39.854819
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 16:59:50.441335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.14
 ---- batch: 020 ----
mean loss: 56.05
 ---- batch: 030 ----
mean loss: 53.02
train mean loss: 53.76
epoch train time: 0:00:00.165929
elapsed time: 0:00:40.020960
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 16:59:50.607410
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.52
 ---- batch: 020 ----
mean loss: 52.13
 ---- batch: 030 ----
mean loss: 51.44
train mean loss: 53.11
epoch train time: 0:00:00.169683
elapsed time: 0:00:40.190778
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 16:59:50.777233
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.95
 ---- batch: 020 ----
mean loss: 51.77
 ---- batch: 030 ----
mean loss: 55.25
train mean loss: 53.69
epoch train time: 0:00:00.172038
elapsed time: 0:00:40.362953
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 16:59:50.949417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.09
 ---- batch: 020 ----
mean loss: 52.24
 ---- batch: 030 ----
mean loss: 52.66
train mean loss: 54.53
epoch train time: 0:00:00.172086
elapsed time: 0:00:40.535267
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 16:59:51.121726
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.94
 ---- batch: 020 ----
mean loss: 52.75
 ---- batch: 030 ----
mean loss: 54.05
train mean loss: 52.87
epoch train time: 0:00:00.172759
elapsed time: 0:00:40.708214
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 16:59:51.294666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.62
 ---- batch: 020 ----
mean loss: 53.47
 ---- batch: 030 ----
mean loss: 51.56
train mean loss: 52.85
epoch train time: 0:00:00.169150
elapsed time: 0:00:40.877499
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 16:59:51.463953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.12
 ---- batch: 020 ----
mean loss: 51.60
 ---- batch: 030 ----
mean loss: 52.21
train mean loss: 52.88
epoch train time: 0:00:00.167100
elapsed time: 0:00:41.044734
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 16:59:51.631189
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.44
 ---- batch: 020 ----
mean loss: 50.77
 ---- batch: 030 ----
mean loss: 54.14
train mean loss: 52.48
epoch train time: 0:00:00.173290
elapsed time: 0:00:41.218179
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 16:59:51.804633
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.36
 ---- batch: 020 ----
mean loss: 50.85
 ---- batch: 030 ----
mean loss: 51.15
train mean loss: 52.07
epoch train time: 0:00:00.176307
elapsed time: 0:00:41.394634
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 16:59:51.981119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.14
 ---- batch: 020 ----
mean loss: 52.15
 ---- batch: 030 ----
mean loss: 53.94
train mean loss: 53.13
epoch train time: 0:00:00.174087
elapsed time: 0:00:41.568890
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 16:59:52.155344
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.45
 ---- batch: 020 ----
mean loss: 49.94
 ---- batch: 030 ----
mean loss: 51.33
train mean loss: 51.80
epoch train time: 0:00:00.170799
elapsed time: 0:00:41.739845
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 16:59:52.326299
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.79
 ---- batch: 020 ----
mean loss: 54.06
 ---- batch: 030 ----
mean loss: 52.10
train mean loss: 51.71
epoch train time: 0:00:00.170995
elapsed time: 0:00:41.910992
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 16:59:52.497449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.26
 ---- batch: 020 ----
mean loss: 52.31
 ---- batch: 030 ----
mean loss: 51.52
train mean loss: 51.49
epoch train time: 0:00:00.170404
elapsed time: 0:00:42.081532
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 16:59:52.667985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.87
 ---- batch: 020 ----
mean loss: 52.34
 ---- batch: 030 ----
mean loss: 50.04
train mean loss: 51.95
epoch train time: 0:00:00.167741
elapsed time: 0:00:42.249429
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 16:59:52.835894
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.08
 ---- batch: 020 ----
mean loss: 49.18
 ---- batch: 030 ----
mean loss: 51.81
train mean loss: 51.34
epoch train time: 0:00:00.168892
elapsed time: 0:00:42.418473
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 16:59:53.004930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.89
 ---- batch: 020 ----
mean loss: 53.17
 ---- batch: 030 ----
mean loss: 52.55
train mean loss: 51.85
epoch train time: 0:00:00.168415
elapsed time: 0:00:42.587038
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 16:59:53.173483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.83
 ---- batch: 020 ----
mean loss: 52.96
 ---- batch: 030 ----
mean loss: 52.06
train mean loss: 51.35
epoch train time: 0:00:00.170238
elapsed time: 0:00:42.757402
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 16:59:53.343855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.90
 ---- batch: 020 ----
mean loss: 49.41
 ---- batch: 030 ----
mean loss: 52.92
train mean loss: 51.76
epoch train time: 0:00:00.166537
elapsed time: 0:00:42.924089
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 16:59:53.510543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.18
 ---- batch: 020 ----
mean loss: 50.76
 ---- batch: 030 ----
mean loss: 52.24
train mean loss: 51.68
epoch train time: 0:00:00.166775
elapsed time: 0:00:43.091040
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 16:59:53.677495
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.77
 ---- batch: 020 ----
mean loss: 50.45
 ---- batch: 030 ----
mean loss: 53.31
train mean loss: 51.42
epoch train time: 0:00:00.169049
elapsed time: 0:00:43.260226
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 16:59:53.846679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.72
 ---- batch: 020 ----
mean loss: 50.36
 ---- batch: 030 ----
mean loss: 49.63
train mean loss: 50.11
epoch train time: 0:00:00.170812
elapsed time: 0:00:43.431185
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 16:59:54.017673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.33
 ---- batch: 020 ----
mean loss: 49.76
 ---- batch: 030 ----
mean loss: 51.35
train mean loss: 50.70
epoch train time: 0:00:00.171613
elapsed time: 0:00:43.602966
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 16:59:54.189434
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.72
 ---- batch: 020 ----
mean loss: 51.24
 ---- batch: 030 ----
mean loss: 49.86
train mean loss: 49.75
epoch train time: 0:00:00.169506
elapsed time: 0:00:43.772636
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 16:59:54.359091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.23
 ---- batch: 020 ----
mean loss: 52.58
 ---- batch: 030 ----
mean loss: 50.56
train mean loss: 50.45
epoch train time: 0:00:00.169179
elapsed time: 0:00:43.941951
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 16:59:54.528404
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.74
 ---- batch: 020 ----
mean loss: 52.84
 ---- batch: 030 ----
mean loss: 48.40
train mean loss: 49.36
epoch train time: 0:00:00.167170
elapsed time: 0:00:44.109283
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 16:59:54.695744
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.56
 ---- batch: 020 ----
mean loss: 49.14
 ---- batch: 030 ----
mean loss: 52.08
train mean loss: 49.99
epoch train time: 0:00:00.172433
elapsed time: 0:00:44.281858
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 16:59:54.868312
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.54
 ---- batch: 020 ----
mean loss: 50.95
 ---- batch: 030 ----
mean loss: 48.94
train mean loss: 49.72
epoch train time: 0:00:00.168183
elapsed time: 0:00:44.450179
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 16:59:55.036651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.93
 ---- batch: 020 ----
mean loss: 49.24
 ---- batch: 030 ----
mean loss: 48.87
train mean loss: 49.61
epoch train time: 0:00:00.168566
elapsed time: 0:00:44.618895
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 16:59:55.205347
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.02
 ---- batch: 020 ----
mean loss: 50.51
 ---- batch: 030 ----
mean loss: 48.30
train mean loss: 49.73
epoch train time: 0:00:00.166891
elapsed time: 0:00:44.785916
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 16:59:55.372367
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.86
 ---- batch: 020 ----
mean loss: 50.73
 ---- batch: 030 ----
mean loss: 53.54
train mean loss: 50.17
epoch train time: 0:00:00.166684
elapsed time: 0:00:44.952730
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 16:59:55.539184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.86
 ---- batch: 020 ----
mean loss: 48.52
 ---- batch: 030 ----
mean loss: 48.11
train mean loss: 49.02
epoch train time: 0:00:00.169448
elapsed time: 0:00:45.122327
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 16:59:55.708792
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.24
 ---- batch: 020 ----
mean loss: 47.51
 ---- batch: 030 ----
mean loss: 49.45
train mean loss: 48.50
epoch train time: 0:00:00.178770
elapsed time: 0:00:45.301246
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 16:59:55.887701
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.52
 ---- batch: 020 ----
mean loss: 47.57
 ---- batch: 030 ----
mean loss: 47.75
train mean loss: 48.14
epoch train time: 0:00:00.171872
elapsed time: 0:00:45.473266
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 16:59:56.059721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.10
 ---- batch: 020 ----
mean loss: 47.57
 ---- batch: 030 ----
mean loss: 48.93
train mean loss: 48.15
epoch train time: 0:00:00.174433
elapsed time: 0:00:45.647841
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 16:59:56.234297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 46.54
 ---- batch: 020 ----
mean loss: 46.81
 ---- batch: 030 ----
mean loss: 50.73
train mean loss: 48.15
epoch train time: 0:00:00.171921
elapsed time: 0:00:45.819907
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 16:59:56.406363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.00
 ---- batch: 020 ----
mean loss: 50.26
 ---- batch: 030 ----
mean loss: 48.18
train mean loss: 48.44
epoch train time: 0:00:00.174220
elapsed time: 0:00:45.994268
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 16:59:56.580723
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.92
 ---- batch: 020 ----
mean loss: 48.65
 ---- batch: 030 ----
mean loss: 48.97
train mean loss: 48.56
epoch train time: 0:00:00.175724
elapsed time: 0:00:46.170135
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 16:59:56.756590
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.24
 ---- batch: 020 ----
mean loss: 49.47
 ---- batch: 030 ----
mean loss: 46.54
train mean loss: 48.33
epoch train time: 0:00:00.175005
elapsed time: 0:00:46.345280
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 16:59:56.931738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.34
 ---- batch: 020 ----
mean loss: 49.60
 ---- batch: 030 ----
mean loss: 45.17
train mean loss: 47.23
epoch train time: 0:00:00.175852
elapsed time: 0:00:46.521275
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 16:59:57.107730
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.53
 ---- batch: 020 ----
mean loss: 48.90
 ---- batch: 030 ----
mean loss: 46.76
train mean loss: 47.73
epoch train time: 0:00:00.170869
elapsed time: 0:00:46.692279
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 16:59:57.278733
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 48.60
 ---- batch: 020 ----
mean loss: 48.25
 ---- batch: 030 ----
mean loss: 47.66
train mean loss: 48.06
epoch train time: 0:00:00.171423
elapsed time: 0:00:46.863840
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 16:59:57.450343
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 49.22
 ---- batch: 020 ----
mean loss: 44.45
 ---- batch: 030 ----
mean loss: 49.03
train mean loss: 47.69
epoch train time: 0:00:00.168405
elapsed time: 0:00:47.032445
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 16:59:57.618899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 47.58
 ---- batch: 020 ----
mean loss: 48.75
 ---- batch: 030 ----
mean loss: 49.66
train mean loss: 48.43
epoch train time: 0:00:00.168681
elapsed time: 0:00:47.201262
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 16:59:57.787717
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.65
 ---- batch: 020 ----
mean loss: 47.66
 ---- batch: 030 ----
mean loss: 47.95
train mean loss: 46.86
epoch train time: 0:00:00.170355
elapsed time: 0:00:47.371777
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 16:59:57.958222
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.31
 ---- batch: 020 ----
mean loss: 46.62
 ---- batch: 030 ----
mean loss: 45.49
train mean loss: 45.90
epoch train time: 0:00:00.174725
elapsed time: 0:00:47.546682
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 16:59:58.133137
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.37
 ---- batch: 020 ----
mean loss: 44.64
 ---- batch: 030 ----
mean loss: 45.80
train mean loss: 46.00
epoch train time: 0:00:00.168639
elapsed time: 0:00:47.715459
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 16:59:58.301913
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.16
 ---- batch: 020 ----
mean loss: 44.95
 ---- batch: 030 ----
mean loss: 46.89
train mean loss: 45.81
epoch train time: 0:00:00.168910
elapsed time: 0:00:47.884507
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 16:59:58.470962
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.75
 ---- batch: 020 ----
mean loss: 46.69
 ---- batch: 030 ----
mean loss: 45.68
train mean loss: 45.88
epoch train time: 0:00:00.165859
elapsed time: 0:00:48.050503
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 16:59:58.636957
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.80
 ---- batch: 020 ----
mean loss: 46.23
 ---- batch: 030 ----
mean loss: 45.91
train mean loss: 45.77
epoch train time: 0:00:00.171566
elapsed time: 0:00:48.222209
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 16:59:58.808665
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.68
 ---- batch: 020 ----
mean loss: 46.00
 ---- batch: 030 ----
mean loss: 46.20
train mean loss: 45.75
epoch train time: 0:00:00.176901
elapsed time: 0:00:48.399274
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 16:59:58.985734
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.02
 ---- batch: 020 ----
mean loss: 44.60
 ---- batch: 030 ----
mean loss: 44.29
train mean loss: 45.82
epoch train time: 0:00:00.177087
elapsed time: 0:00:48.576507
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 16:59:59.162961
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.97
 ---- batch: 020 ----
mean loss: 45.18
 ---- batch: 030 ----
mean loss: 45.74
train mean loss: 45.66
epoch train time: 0:00:00.170465
elapsed time: 0:00:48.747110
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 16:59:59.333567
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.82
 ---- batch: 020 ----
mean loss: 45.95
 ---- batch: 030 ----
mean loss: 47.34
train mean loss: 45.85
epoch train time: 0:00:00.171896
elapsed time: 0:00:48.919149
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 16:59:59.505627
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.30
 ---- batch: 020 ----
mean loss: 44.97
 ---- batch: 030 ----
mean loss: 44.44
train mean loss: 45.62
epoch train time: 0:00:00.171973
elapsed time: 0:00:49.091308
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 16:59:59.677763
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.40
 ---- batch: 020 ----
mean loss: 46.77
 ---- batch: 030 ----
mean loss: 45.99
train mean loss: 45.65
epoch train time: 0:00:00.172884
elapsed time: 0:00:49.264336
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 16:59:59.850817
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.77
 ---- batch: 020 ----
mean loss: 44.13
 ---- batch: 030 ----
mean loss: 46.10
train mean loss: 45.75
epoch train time: 0:00:00.174050
elapsed time: 0:00:49.438555
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 17:00:00.025011
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.24
 ---- batch: 020 ----
mean loss: 46.15
 ---- batch: 030 ----
mean loss: 44.23
train mean loss: 45.72
epoch train time: 0:00:00.174659
elapsed time: 0:00:49.613355
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 17:00:00.199810
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.68
 ---- batch: 020 ----
mean loss: 45.26
 ---- batch: 030 ----
mean loss: 47.72
train mean loss: 45.53
epoch train time: 0:00:00.179596
elapsed time: 0:00:49.793119
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 17:00:00.379576
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.26
 ---- batch: 020 ----
mean loss: 46.06
 ---- batch: 030 ----
mean loss: 44.61
train mean loss: 45.75
epoch train time: 0:00:00.173892
elapsed time: 0:00:49.967150
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 17:00:00.553625
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 43.74
 ---- batch: 020 ----
mean loss: 46.39
 ---- batch: 030 ----
mean loss: 46.54
train mean loss: 45.55
epoch train time: 0:00:00.172541
elapsed time: 0:00:50.139865
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 17:00:00.726329
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.14
 ---- batch: 020 ----
mean loss: 45.52
 ---- batch: 030 ----
mean loss: 43.56
train mean loss: 45.62
epoch train time: 0:00:00.170804
elapsed time: 0:00:50.310820
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 17:00:00.897275
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.02
 ---- batch: 020 ----
mean loss: 45.72
 ---- batch: 030 ----
mean loss: 45.63
train mean loss: 45.60
epoch train time: 0:00:00.170628
elapsed time: 0:00:50.481588
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 17:00:01.068059
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.29
 ---- batch: 020 ----
mean loss: 46.07
 ---- batch: 030 ----
mean loss: 46.62
train mean loss: 45.62
epoch train time: 0:00:00.169468
elapsed time: 0:00:50.651231
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 17:00:01.237691
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.03
 ---- batch: 020 ----
mean loss: 45.07
 ---- batch: 030 ----
mean loss: 46.58
train mean loss: 45.53
epoch train time: 0:00:00.168597
elapsed time: 0:00:50.819971
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 17:00:01.406425
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.18
 ---- batch: 020 ----
mean loss: 46.17
 ---- batch: 030 ----
mean loss: 44.51
train mean loss: 45.57
epoch train time: 0:00:00.168735
elapsed time: 0:00:50.988844
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 17:00:01.575299
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.96
 ---- batch: 020 ----
mean loss: 44.08
 ---- batch: 030 ----
mean loss: 47.88
train mean loss: 45.48
epoch train time: 0:00:00.176572
elapsed time: 0:00:51.165609
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 17:00:01.752073
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.16
 ---- batch: 020 ----
mean loss: 44.45
 ---- batch: 030 ----
mean loss: 44.94
train mean loss: 45.56
epoch train time: 0:00:00.172470
elapsed time: 0:00:51.338230
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 17:00:01.924686
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.60
 ---- batch: 020 ----
mean loss: 44.10
 ---- batch: 030 ----
mean loss: 45.98
train mean loss: 45.45
epoch train time: 0:00:00.171815
elapsed time: 0:00:51.510185
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 17:00:02.096658
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.54
 ---- batch: 020 ----
mean loss: 44.59
 ---- batch: 030 ----
mean loss: 44.37
train mean loss: 45.40
epoch train time: 0:00:00.168232
elapsed time: 0:00:51.678591
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 17:00:02.265047
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.76
 ---- batch: 020 ----
mean loss: 46.19
 ---- batch: 030 ----
mean loss: 44.93
train mean loss: 45.42
epoch train time: 0:00:00.170012
elapsed time: 0:00:51.848760
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 17:00:02.435218
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.67
 ---- batch: 020 ----
mean loss: 45.62
 ---- batch: 030 ----
mean loss: 45.44
train mean loss: 45.38
epoch train time: 0:00:00.169920
elapsed time: 0:00:52.018824
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 17:00:02.605281
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.80
 ---- batch: 020 ----
mean loss: 43.69
 ---- batch: 030 ----
mean loss: 46.04
train mean loss: 45.24
epoch train time: 0:00:00.180908
elapsed time: 0:00:52.199901
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 17:00:02.786367
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 43.70
 ---- batch: 020 ----
mean loss: 47.44
 ---- batch: 030 ----
mean loss: 44.62
train mean loss: 45.41
epoch train time: 0:00:00.186758
elapsed time: 0:00:52.386809
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 17:00:02.973263
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.56
 ---- batch: 020 ----
mean loss: 45.55
 ---- batch: 030 ----
mean loss: 44.91
train mean loss: 45.29
epoch train time: 0:00:00.172055
elapsed time: 0:00:52.559003
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 17:00:03.145459
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.03
 ---- batch: 020 ----
mean loss: 46.40
 ---- batch: 030 ----
mean loss: 44.38
train mean loss: 45.16
epoch train time: 0:00:00.171031
elapsed time: 0:00:52.730176
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 17:00:03.316633
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.32
 ---- batch: 020 ----
mean loss: 44.61
 ---- batch: 030 ----
mean loss: 44.67
train mean loss: 45.35
epoch train time: 0:00:00.174357
elapsed time: 0:00:52.904683
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 17:00:03.491127
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.98
 ---- batch: 020 ----
mean loss: 46.95
 ---- batch: 030 ----
mean loss: 43.08
train mean loss: 45.39
epoch train time: 0:00:00.169296
elapsed time: 0:00:53.074105
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 17:00:03.660559
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.40
 ---- batch: 020 ----
mean loss: 46.07
 ---- batch: 030 ----
mean loss: 43.91
train mean loss: 45.24
epoch train time: 0:00:00.172724
elapsed time: 0:00:53.246968
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 17:00:03.833424
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.16
 ---- batch: 020 ----
mean loss: 44.31
 ---- batch: 030 ----
mean loss: 45.45
train mean loss: 45.17
epoch train time: 0:00:00.171766
elapsed time: 0:00:53.418877
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 17:00:04.005333
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.11
 ---- batch: 020 ----
mean loss: 44.46
 ---- batch: 030 ----
mean loss: 45.29
train mean loss: 45.22
epoch train time: 0:00:00.170548
elapsed time: 0:00:53.589564
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 17:00:04.176019
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.14
 ---- batch: 020 ----
mean loss: 44.85
 ---- batch: 030 ----
mean loss: 44.87
train mean loss: 45.12
epoch train time: 0:00:00.168413
elapsed time: 0:00:53.758130
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 17:00:04.344600
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.35
 ---- batch: 020 ----
mean loss: 44.12
 ---- batch: 030 ----
mean loss: 44.13
train mean loss: 45.18
epoch train time: 0:00:00.169888
elapsed time: 0:00:53.928200
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 17:00:04.514674
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.72
 ---- batch: 020 ----
mean loss: 45.47
 ---- batch: 030 ----
mean loss: 45.25
train mean loss: 45.23
epoch train time: 0:00:00.168606
elapsed time: 0:00:54.096962
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 17:00:04.683416
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 43.35
 ---- batch: 020 ----
mean loss: 44.20
 ---- batch: 030 ----
mean loss: 47.17
train mean loss: 45.06
epoch train time: 0:00:00.172280
elapsed time: 0:00:54.269380
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 17:00:04.855836
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 45.69
 ---- batch: 020 ----
mean loss: 45.11
 ---- batch: 030 ----
mean loss: 44.09
train mean loss: 45.08
epoch train time: 0:00:00.169468
elapsed time: 0:00:54.439013
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 17:00:05.025470
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.96
 ---- batch: 020 ----
mean loss: 45.67
 ---- batch: 030 ----
mean loss: 44.70
train mean loss: 45.05
epoch train time: 0:00:00.170889
elapsed time: 0:00:54.610054
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 17:00:05.196510
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 43.73
 ---- batch: 020 ----
mean loss: 45.70
 ---- batch: 030 ----
mean loss: 45.72
train mean loss: 45.03
epoch train time: 0:00:00.173841
elapsed time: 0:00:54.784044
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 17:00:05.370502
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.29
 ---- batch: 020 ----
mean loss: 45.05
 ---- batch: 030 ----
mean loss: 45.66
train mean loss: 44.99
epoch train time: 0:00:00.168479
elapsed time: 0:00:54.952666
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 17:00:05.539121
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.52
 ---- batch: 020 ----
mean loss: 43.81
 ---- batch: 030 ----
mean loss: 44.99
train mean loss: 44.93
epoch train time: 0:00:00.167390
elapsed time: 0:00:55.120194
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 17:00:05.706650
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 46.34
 ---- batch: 020 ----
mean loss: 43.06
 ---- batch: 030 ----
mean loss: 45.03
train mean loss: 44.93
epoch train time: 0:00:00.172331
elapsed time: 0:00:55.292696
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 17:00:05.879166
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 47.24
 ---- batch: 020 ----
mean loss: 44.29
 ---- batch: 030 ----
mean loss: 41.96
train mean loss: 45.12
epoch train time: 0:00:00.169998
elapsed time: 0:00:55.462885
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 17:00:06.049369
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 44.18
 ---- batch: 020 ----
mean loss: 45.46
 ---- batch: 030 ----
mean loss: 46.25
train mean loss: 45.04
epoch train time: 0:00:00.173628
elapsed time: 0:00:55.639867
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_6/checkpoint.pth.tar
**** end time: 2019-09-27 17:00:06.226292 ****
