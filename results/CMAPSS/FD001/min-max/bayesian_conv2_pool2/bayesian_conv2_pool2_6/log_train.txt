Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_6', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv2_pool2', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 29211
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv2Pool2...
Done.
**** start time: 2019-09-27 14:55:01.915444 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1             [-1, 8, 26, 1]           1,120
           Sigmoid-2             [-1, 8, 26, 1]               0
         AvgPool2d-3             [-1, 8, 13, 1]               0
    BayesianConv2d-4            [-1, 14, 12, 1]             448
           Sigmoid-5            [-1, 14, 12, 1]               0
         AvgPool2d-6             [-1, 14, 6, 1]               0
           Flatten-7                   [-1, 84]               0
    BayesianLinear-8                    [-1, 1]             168
          Softplus-9                    [-1, 1]               0
================================================================
Total params: 1,736
Trainable params: 1,736
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 14:55:01.926723
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4171.55
 ---- batch: 020 ----
mean loss: 4040.39
 ---- batch: 030 ----
mean loss: 4121.98
train mean loss: 4113.72
epoch train time: 0:00:12.633110
elapsed time: 0:00:12.647744
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 14:55:14.563225
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4101.60
 ---- batch: 020 ----
mean loss: 4031.08
 ---- batch: 030 ----
mean loss: 4003.30
train mean loss: 4038.25
epoch train time: 0:00:00.545282
elapsed time: 0:00:13.193285
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 14:55:15.108841
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3886.45
 ---- batch: 020 ----
mean loss: 3802.11
 ---- batch: 030 ----
mean loss: 3741.54
train mean loss: 3788.78
epoch train time: 0:00:00.541772
elapsed time: 0:00:13.735381
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 14:55:15.650912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3623.18
 ---- batch: 020 ----
mean loss: 3557.08
 ---- batch: 030 ----
mean loss: 3548.68
train mean loss: 3574.80
epoch train time: 0:00:00.545885
elapsed time: 0:00:14.281533
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 14:55:16.197063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3419.59
 ---- batch: 020 ----
mean loss: 3381.07
 ---- batch: 030 ----
mean loss: 3470.69
train mean loss: 3417.89
epoch train time: 0:00:00.537623
elapsed time: 0:00:14.819475
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 14:55:16.735012
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3338.35
 ---- batch: 020 ----
mean loss: 3282.60
 ---- batch: 030 ----
mean loss: 3287.51
train mean loss: 3294.92
epoch train time: 0:00:00.532342
elapsed time: 0:00:15.352105
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 14:55:17.267637
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3231.16
 ---- batch: 020 ----
mean loss: 3159.01
 ---- batch: 030 ----
mean loss: 3112.93
train mean loss: 3158.62
epoch train time: 0:00:00.527375
elapsed time: 0:00:15.879830
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 14:55:17.795379
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3071.15
 ---- batch: 020 ----
mean loss: 3052.57
 ---- batch: 030 ----
mean loss: 2972.49
train mean loss: 3024.47
epoch train time: 0:00:00.548048
elapsed time: 0:00:16.428170
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 14:55:18.343704
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2940.60
 ---- batch: 020 ----
mean loss: 2911.64
 ---- batch: 030 ----
mean loss: 2892.23
train mean loss: 2907.62
epoch train time: 0:00:00.538916
elapsed time: 0:00:16.967370
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 14:55:18.882905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2846.34
 ---- batch: 020 ----
mean loss: 2790.23
 ---- batch: 030 ----
mean loss: 2774.23
train mean loss: 2789.79
epoch train time: 0:00:00.540685
elapsed time: 0:00:17.508338
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 14:55:19.423874
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2693.09
 ---- batch: 020 ----
mean loss: 2684.06
 ---- batch: 030 ----
mean loss: 2623.26
train mean loss: 2657.45
epoch train time: 0:00:00.548339
elapsed time: 0:00:18.056955
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 14:55:19.972529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2570.11
 ---- batch: 020 ----
mean loss: 2567.56
 ---- batch: 030 ----
mean loss: 2490.84
train mean loss: 2541.53
epoch train time: 0:00:00.551124
elapsed time: 0:00:18.608401
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 14:55:20.523940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2482.01
 ---- batch: 020 ----
mean loss: 2425.95
 ---- batch: 030 ----
mean loss: 2435.64
train mean loss: 2433.36
epoch train time: 0:00:00.543967
elapsed time: 0:00:19.152652
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 14:55:21.068203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2407.24
 ---- batch: 020 ----
mean loss: 2353.77
 ---- batch: 030 ----
mean loss: 2291.15
train mean loss: 2335.29
epoch train time: 0:00:00.539858
elapsed time: 0:00:19.692816
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 14:55:21.608352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2269.56
 ---- batch: 020 ----
mean loss: 2257.10
 ---- batch: 030 ----
mean loss: 2234.51
train mean loss: 2247.72
epoch train time: 0:00:00.551030
elapsed time: 0:00:20.244209
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 14:55:22.159791
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2183.50
 ---- batch: 020 ----
mean loss: 2167.52
 ---- batch: 030 ----
mean loss: 2154.70
train mean loss: 2164.13
epoch train time: 0:00:00.538675
elapsed time: 0:00:20.783204
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 14:55:22.698789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2106.84
 ---- batch: 020 ----
mean loss: 2080.71
 ---- batch: 030 ----
mean loss: 2071.79
train mean loss: 2083.28
epoch train time: 0:00:00.549287
elapsed time: 0:00:21.332859
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 14:55:23.248392
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2047.68
 ---- batch: 020 ----
mean loss: 2019.69
 ---- batch: 030 ----
mean loss: 1969.18
train mean loss: 2014.78
epoch train time: 0:00:00.528927
elapsed time: 0:00:21.862084
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 14:55:23.777632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1969.35
 ---- batch: 020 ----
mean loss: 1956.40
 ---- batch: 030 ----
mean loss: 1920.00
train mean loss: 1942.43
epoch train time: 0:00:00.541128
elapsed time: 0:00:22.403505
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 14:55:24.319052
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1905.74
 ---- batch: 020 ----
mean loss: 1876.83
 ---- batch: 030 ----
mean loss: 1857.72
train mean loss: 1876.13
epoch train time: 0:00:00.555822
elapsed time: 0:00:22.959671
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 14:55:24.875260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1805.73
 ---- batch: 020 ----
mean loss: 1808.89
 ---- batch: 030 ----
mean loss: 1793.47
train mean loss: 1810.25
epoch train time: 0:00:00.537504
elapsed time: 0:00:23.497500
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 14:55:25.413030
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1754.97
 ---- batch: 020 ----
mean loss: 1793.78
 ---- batch: 030 ----
mean loss: 1732.54
train mean loss: 1747.43
epoch train time: 0:00:00.535292
elapsed time: 0:00:24.033061
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 14:55:25.948589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1727.03
 ---- batch: 020 ----
mean loss: 1685.41
 ---- batch: 030 ----
mean loss: 1667.26
train mean loss: 1680.31
epoch train time: 0:00:00.527983
elapsed time: 0:00:24.561311
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 14:55:26.476844
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1597.80
 ---- batch: 020 ----
mean loss: 1602.92
 ---- batch: 030 ----
mean loss: 1568.04
train mean loss: 1569.24
epoch train time: 0:00:00.550565
elapsed time: 0:00:25.112144
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 14:55:27.027677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1489.30
 ---- batch: 020 ----
mean loss: 1451.12
 ---- batch: 030 ----
mean loss: 1383.83
train mean loss: 1425.11
epoch train time: 0:00:00.537631
elapsed time: 0:00:25.650081
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 14:55:27.565673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1341.64
 ---- batch: 020 ----
mean loss: 1341.61
 ---- batch: 030 ----
mean loss: 1305.81
train mean loss: 1320.16
epoch train time: 0:00:00.542913
elapsed time: 0:00:26.193317
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 14:55:28.108847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1264.69
 ---- batch: 020 ----
mean loss: 1253.07
 ---- batch: 030 ----
mean loss: 1193.37
train mean loss: 1237.21
epoch train time: 0:00:00.529906
elapsed time: 0:00:26.723483
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 14:55:28.639041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1196.74
 ---- batch: 020 ----
mean loss: 1174.41
 ---- batch: 030 ----
mean loss: 1143.98
train mean loss: 1168.34
epoch train time: 0:00:00.530193
elapsed time: 0:00:27.253969
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 14:55:29.169498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1109.44
 ---- batch: 020 ----
mean loss: 1138.17
 ---- batch: 030 ----
mean loss: 1086.43
train mean loss: 1104.79
epoch train time: 0:00:00.526506
elapsed time: 0:00:27.781206
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 14:55:29.696761
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1077.97
 ---- batch: 020 ----
mean loss: 1056.04
 ---- batch: 030 ----
mean loss: 1038.80
train mean loss: 1056.86
epoch train time: 0:00:00.543958
elapsed time: 0:00:28.325463
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 14:55:30.241012
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1019.79
 ---- batch: 020 ----
mean loss: 991.91
 ---- batch: 030 ----
mean loss: 1021.06
train mean loss: 1007.13
epoch train time: 0:00:00.562043
elapsed time: 0:00:28.887791
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 14:55:30.803318
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 977.63
 ---- batch: 020 ----
mean loss: 967.44
 ---- batch: 030 ----
mean loss: 945.17
train mean loss: 958.58
epoch train time: 0:00:00.530958
elapsed time: 0:00:29.419068
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 14:55:31.334611
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 934.03
 ---- batch: 020 ----
mean loss: 916.21
 ---- batch: 030 ----
mean loss: 911.34
train mean loss: 922.17
epoch train time: 0:00:00.535688
elapsed time: 0:00:29.955044
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 14:55:31.870583
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 896.56
 ---- batch: 020 ----
mean loss: 894.79
 ---- batch: 030 ----
mean loss: 864.10
train mean loss: 880.26
epoch train time: 0:00:00.531422
elapsed time: 0:00:30.486745
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 14:55:32.402275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 849.32
 ---- batch: 020 ----
mean loss: 853.79
 ---- batch: 030 ----
mean loss: 835.59
train mean loss: 844.90
epoch train time: 0:00:00.542529
elapsed time: 0:00:31.029543
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 14:55:32.945099
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 816.52
 ---- batch: 020 ----
mean loss: 809.71
 ---- batch: 030 ----
mean loss: 822.82
train mean loss: 814.24
epoch train time: 0:00:00.536328
elapsed time: 0:00:31.566184
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 14:55:33.481714
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 794.96
 ---- batch: 020 ----
mean loss: 785.75
 ---- batch: 030 ----
mean loss: 776.97
train mean loss: 781.96
epoch train time: 0:00:00.538173
elapsed time: 0:00:32.104651
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 14:55:34.020184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 766.44
 ---- batch: 020 ----
mean loss: 749.31
 ---- batch: 030 ----
mean loss: 751.28
train mean loss: 752.51
epoch train time: 0:00:00.539804
elapsed time: 0:00:32.644724
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 14:55:34.560257
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 750.61
 ---- batch: 020 ----
mean loss: 725.41
 ---- batch: 030 ----
mean loss: 719.59
train mean loss: 726.85
epoch train time: 0:00:00.558988
elapsed time: 0:00:33.203979
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 14:55:35.119516
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 715.34
 ---- batch: 020 ----
mean loss: 694.10
 ---- batch: 030 ----
mean loss: 707.53
train mean loss: 704.31
epoch train time: 0:00:00.537362
elapsed time: 0:00:33.741612
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 14:55:35.657163
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 685.21
 ---- batch: 020 ----
mean loss: 671.58
 ---- batch: 030 ----
mean loss: 680.93
train mean loss: 680.77
epoch train time: 0:00:00.541283
elapsed time: 0:00:34.283210
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 14:55:36.198745
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 664.52
 ---- batch: 020 ----
mean loss: 652.47
 ---- batch: 030 ----
mean loss: 661.31
train mean loss: 657.55
epoch train time: 0:00:00.539464
elapsed time: 0:00:34.822953
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 14:55:36.738487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 659.49
 ---- batch: 020 ----
mean loss: 636.66
 ---- batch: 030 ----
mean loss: 619.27
train mean loss: 637.59
epoch train time: 0:00:00.546664
elapsed time: 0:00:35.369888
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 14:55:37.285422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 619.30
 ---- batch: 020 ----
mean loss: 631.77
 ---- batch: 030 ----
mean loss: 613.45
train mean loss: 619.36
epoch train time: 0:00:00.542936
elapsed time: 0:00:35.913128
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 14:55:37.828665
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 606.02
 ---- batch: 020 ----
mean loss: 592.00
 ---- batch: 030 ----
mean loss: 600.94
train mean loss: 599.96
epoch train time: 0:00:00.541517
elapsed time: 0:00:36.454939
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 14:55:38.370474
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 591.97
 ---- batch: 020 ----
mean loss: 578.59
 ---- batch: 030 ----
mean loss: 583.26
train mean loss: 584.30
epoch train time: 0:00:00.556142
elapsed time: 0:00:37.011360
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 14:55:38.926906
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 561.89
 ---- batch: 020 ----
mean loss: 570.91
 ---- batch: 030 ----
mean loss: 564.89
train mean loss: 565.25
epoch train time: 0:00:00.529109
elapsed time: 0:00:37.540777
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 14:55:39.456324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 556.06
 ---- batch: 020 ----
mean loss: 548.42
 ---- batch: 030 ----
mean loss: 553.45
train mean loss: 547.68
epoch train time: 0:00:00.560756
elapsed time: 0:00:38.101820
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 14:55:40.017363
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 543.77
 ---- batch: 020 ----
mean loss: 538.78
 ---- batch: 030 ----
mean loss: 527.85
train mean loss: 535.14
epoch train time: 0:00:00.540076
elapsed time: 0:00:38.642227
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 14:55:40.557809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 530.98
 ---- batch: 020 ----
mean loss: 521.70
 ---- batch: 030 ----
mean loss: 513.35
train mean loss: 520.17
epoch train time: 0:00:00.536719
elapsed time: 0:00:39.179331
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 14:55:41.094865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 512.32
 ---- batch: 020 ----
mean loss: 509.48
 ---- batch: 030 ----
mean loss: 519.16
train mean loss: 511.39
epoch train time: 0:00:00.538500
elapsed time: 0:00:39.718129
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 14:55:41.633720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 503.51
 ---- batch: 020 ----
mean loss: 493.89
 ---- batch: 030 ----
mean loss: 496.01
train mean loss: 495.86
epoch train time: 0:00:00.544037
elapsed time: 0:00:40.262532
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 14:55:42.178075
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 494.82
 ---- batch: 020 ----
mean loss: 482.37
 ---- batch: 030 ----
mean loss: 472.70
train mean loss: 481.36
epoch train time: 0:00:00.537968
elapsed time: 0:00:40.800801
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 14:55:42.716336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 470.42
 ---- batch: 020 ----
mean loss: 479.68
 ---- batch: 030 ----
mean loss: 470.43
train mean loss: 473.52
epoch train time: 0:00:00.539685
elapsed time: 0:00:41.340756
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 14:55:43.256311
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 466.53
 ---- batch: 020 ----
mean loss: 462.61
 ---- batch: 030 ----
mean loss: 459.67
train mean loss: 462.07
epoch train time: 0:00:00.554416
elapsed time: 0:00:41.895465
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 14:55:43.811019
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 460.15
 ---- batch: 020 ----
mean loss: 447.22
 ---- batch: 030 ----
mean loss: 448.65
train mean loss: 450.17
epoch train time: 0:00:00.551227
elapsed time: 0:00:42.447083
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 14:55:44.362634
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 443.42
 ---- batch: 020 ----
mean loss: 450.95
 ---- batch: 030 ----
mean loss: 429.91
train mean loss: 439.56
epoch train time: 0:00:00.554298
elapsed time: 0:00:43.001678
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 14:55:44.917212
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 433.47
 ---- batch: 020 ----
mean loss: 423.96
 ---- batch: 030 ----
mean loss: 434.79
train mean loss: 430.08
epoch train time: 0:00:00.538890
elapsed time: 0:00:43.540839
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 14:55:45.456373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 423.11
 ---- batch: 020 ----
mean loss: 425.97
 ---- batch: 030 ----
mean loss: 421.40
train mean loss: 420.97
epoch train time: 0:00:00.534816
elapsed time: 0:00:44.075961
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 14:55:45.991493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.67
 ---- batch: 020 ----
mean loss: 415.45
 ---- batch: 030 ----
mean loss: 402.25
train mean loss: 411.33
epoch train time: 0:00:00.537358
elapsed time: 0:00:44.613592
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 14:55:46.529129
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 405.84
 ---- batch: 020 ----
mean loss: 400.67
 ---- batch: 030 ----
mean loss: 406.69
train mean loss: 404.85
epoch train time: 0:00:00.533143
elapsed time: 0:00:45.147014
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 14:55:47.062557
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 390.37
 ---- batch: 020 ----
mean loss: 388.82
 ---- batch: 030 ----
mean loss: 402.90
train mean loss: 394.17
epoch train time: 0:00:00.528478
elapsed time: 0:00:45.675804
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 14:55:47.591349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 384.86
 ---- batch: 020 ----
mean loss: 386.80
 ---- batch: 030 ----
mean loss: 382.64
train mean loss: 386.82
epoch train time: 0:00:00.548326
elapsed time: 0:00:46.224423
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 14:55:48.139966
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 377.30
 ---- batch: 020 ----
mean loss: 386.19
 ---- batch: 030 ----
mean loss: 380.54
train mean loss: 380.53
epoch train time: 0:00:00.538629
elapsed time: 0:00:46.763362
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 14:55:48.678897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 372.31
 ---- batch: 020 ----
mean loss: 373.56
 ---- batch: 030 ----
mean loss: 371.67
train mean loss: 372.03
epoch train time: 0:00:00.533199
elapsed time: 0:00:47.296842
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 14:55:49.212379
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 367.22
 ---- batch: 020 ----
mean loss: 363.15
 ---- batch: 030 ----
mean loss: 367.49
train mean loss: 366.17
epoch train time: 0:00:00.536734
elapsed time: 0:00:47.833857
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 14:55:49.749392
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 361.96
 ---- batch: 020 ----
mean loss: 363.40
 ---- batch: 030 ----
mean loss: 357.06
train mean loss: 359.92
epoch train time: 0:00:00.534273
elapsed time: 0:00:48.368425
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 14:55:50.283990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 357.62
 ---- batch: 020 ----
mean loss: 351.62
 ---- batch: 030 ----
mean loss: 353.49
train mean loss: 354.07
epoch train time: 0:00:00.541357
elapsed time: 0:00:48.910092
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 14:55:50.825651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 352.89
 ---- batch: 020 ----
mean loss: 351.93
 ---- batch: 030 ----
mean loss: 346.08
train mean loss: 348.89
epoch train time: 0:00:00.536298
elapsed time: 0:00:49.446682
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 14:55:51.362214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 343.43
 ---- batch: 020 ----
mean loss: 343.18
 ---- batch: 030 ----
mean loss: 342.39
train mean loss: 342.80
epoch train time: 0:00:00.544246
elapsed time: 0:00:49.991268
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 14:55:51.906817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 340.29
 ---- batch: 020 ----
mean loss: 334.44
 ---- batch: 030 ----
mean loss: 340.08
train mean loss: 337.18
epoch train time: 0:00:00.532552
elapsed time: 0:00:50.524112
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 14:55:52.439646
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 336.32
 ---- batch: 020 ----
mean loss: 331.01
 ---- batch: 030 ----
mean loss: 328.78
train mean loss: 333.17
epoch train time: 0:00:00.545755
elapsed time: 0:00:51.070129
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 14:55:52.985682
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 327.59
 ---- batch: 020 ----
mean loss: 330.84
 ---- batch: 030 ----
mean loss: 323.84
train mean loss: 327.57
epoch train time: 0:00:00.534203
elapsed time: 0:00:51.604619
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 14:55:53.520158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 323.87
 ---- batch: 020 ----
mean loss: 327.99
 ---- batch: 030 ----
mean loss: 318.83
train mean loss: 322.64
epoch train time: 0:00:00.535489
elapsed time: 0:00:52.140428
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 14:55:54.055974
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 321.48
 ---- batch: 020 ----
mean loss: 317.36
 ---- batch: 030 ----
mean loss: 320.06
train mean loss: 318.47
epoch train time: 0:00:00.537912
elapsed time: 0:00:52.678677
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 14:55:54.594206
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 315.08
 ---- batch: 020 ----
mean loss: 321.75
 ---- batch: 030 ----
mean loss: 314.74
train mean loss: 316.04
epoch train time: 0:00:00.538329
elapsed time: 0:00:53.217267
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 14:55:55.132814
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 318.00
 ---- batch: 020 ----
mean loss: 310.22
 ---- batch: 030 ----
mean loss: 307.81
train mean loss: 312.79
epoch train time: 0:00:00.535222
elapsed time: 0:00:53.752777
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 14:55:55.668314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 304.74
 ---- batch: 020 ----
mean loss: 312.75
 ---- batch: 030 ----
mean loss: 309.94
train mean loss: 308.38
epoch train time: 0:00:00.531756
elapsed time: 0:00:54.284801
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 14:55:56.200349
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 308.66
 ---- batch: 020 ----
mean loss: 302.77
 ---- batch: 030 ----
mean loss: 299.08
train mean loss: 305.04
epoch train time: 0:00:00.528122
elapsed time: 0:00:54.813226
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 14:55:56.728759
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.30
 ---- batch: 020 ----
mean loss: 303.10
 ---- batch: 030 ----
mean loss: 307.55
train mean loss: 302.56
epoch train time: 0:00:00.543784
elapsed time: 0:00:55.357290
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 14:55:57.272827
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.39
 ---- batch: 020 ----
mean loss: 290.42
 ---- batch: 030 ----
mean loss: 310.66
train mean loss: 297.89
epoch train time: 0:00:00.533292
elapsed time: 0:00:55.890917
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 14:55:57.806493
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 292.06
 ---- batch: 020 ----
mean loss: 296.70
 ---- batch: 030 ----
mean loss: 291.25
train mean loss: 293.46
epoch train time: 0:00:00.543628
elapsed time: 0:00:56.434862
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 14:55:58.350397
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 296.56
 ---- batch: 020 ----
mean loss: 288.01
 ---- batch: 030 ----
mean loss: 294.01
train mean loss: 292.64
epoch train time: 0:00:00.550364
elapsed time: 0:00:56.985527
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 14:55:58.901069
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.14
 ---- batch: 020 ----
mean loss: 294.15
 ---- batch: 030 ----
mean loss: 289.45
train mean loss: 290.28
epoch train time: 0:00:00.536930
elapsed time: 0:00:57.522737
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 14:55:59.438264
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 288.77
 ---- batch: 020 ----
mean loss: 287.25
 ---- batch: 030 ----
mean loss: 288.41
train mean loss: 287.59
epoch train time: 0:00:00.543594
elapsed time: 0:00:58.066589
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 14:55:59.982115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.01
 ---- batch: 020 ----
mean loss: 288.21
 ---- batch: 030 ----
mean loss: 282.42
train mean loss: 285.47
epoch train time: 0:00:00.537034
elapsed time: 0:00:58.603887
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 14:56:00.519419
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 282.84
 ---- batch: 020 ----
mean loss: 285.27
 ---- batch: 030 ----
mean loss: 282.17
train mean loss: 283.23
epoch train time: 0:00:00.550577
elapsed time: 0:00:59.154734
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 14:56:01.070267
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.04
 ---- batch: 020 ----
mean loss: 287.55
 ---- batch: 030 ----
mean loss: 271.50
train mean loss: 280.13
epoch train time: 0:00:00.533967
elapsed time: 0:00:59.688974
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 14:56:01.604522
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 284.18
 ---- batch: 020 ----
mean loss: 273.98
 ---- batch: 030 ----
mean loss: 272.83
train mean loss: 278.28
epoch train time: 0:00:00.537423
elapsed time: 0:01:00.226695
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 14:56:02.142241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 276.51
 ---- batch: 020 ----
mean loss: 273.85
 ---- batch: 030 ----
mean loss: 279.34
train mean loss: 277.05
epoch train time: 0:00:00.533989
elapsed time: 0:01:00.761009
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 14:56:02.676584
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.37
 ---- batch: 020 ----
mean loss: 276.28
 ---- batch: 030 ----
mean loss: 275.34
train mean loss: 274.73
epoch train time: 0:00:00.543584
elapsed time: 0:01:01.304896
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 14:56:03.220423
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.74
 ---- batch: 020 ----
mean loss: 273.39
 ---- batch: 030 ----
mean loss: 274.67
train mean loss: 272.10
epoch train time: 0:00:00.522055
elapsed time: 0:01:01.827233
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 14:56:03.742774
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 275.25
 ---- batch: 020 ----
mean loss: 273.92
 ---- batch: 030 ----
mean loss: 267.70
train mean loss: 271.65
epoch train time: 0:00:00.550304
elapsed time: 0:01:02.377809
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 14:56:04.293336
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 270.48
 ---- batch: 020 ----
mean loss: 261.11
 ---- batch: 030 ----
mean loss: 273.57
train mean loss: 268.68
epoch train time: 0:00:00.530071
elapsed time: 0:01:02.908200
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 14:56:04.823770
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 269.10
 ---- batch: 020 ----
mean loss: 263.79
 ---- batch: 030 ----
mean loss: 269.14
train mean loss: 266.60
epoch train time: 0:00:00.542786
elapsed time: 0:01:03.451310
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 14:56:05.366847
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 261.44
 ---- batch: 020 ----
mean loss: 260.28
 ---- batch: 030 ----
mean loss: 267.61
train mean loss: 264.59
epoch train time: 0:00:00.550516
elapsed time: 0:01:04.002103
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 14:56:05.917656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 259.51
 ---- batch: 020 ----
mean loss: 265.33
 ---- batch: 030 ----
mean loss: 270.58
train mean loss: 264.99
epoch train time: 0:00:00.524988
elapsed time: 0:01:04.527397
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 14:56:06.442931
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 263.17
 ---- batch: 020 ----
mean loss: 256.63
 ---- batch: 030 ----
mean loss: 262.70
train mean loss: 261.56
epoch train time: 0:00:00.547717
elapsed time: 0:01:05.075440
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 14:56:06.990975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 258.98
 ---- batch: 020 ----
mean loss: 259.15
 ---- batch: 030 ----
mean loss: 256.69
train mean loss: 259.26
epoch train time: 0:00:00.527951
elapsed time: 0:01:05.603669
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 14:56:07.519203
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 260.98
 ---- batch: 020 ----
mean loss: 251.87
 ---- batch: 030 ----
mean loss: 262.94
train mean loss: 258.55
epoch train time: 0:00:00.537716
elapsed time: 0:01:06.141667
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 14:56:08.057209
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 262.94
 ---- batch: 020 ----
mean loss: 257.88
 ---- batch: 030 ----
mean loss: 247.38
train mean loss: 256.91
epoch train time: 0:00:00.525272
elapsed time: 0:01:06.667235
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 14:56:08.582766
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 252.61
 ---- batch: 020 ----
mean loss: 260.46
 ---- batch: 030 ----
mean loss: 255.59
train mean loss: 255.63
epoch train time: 0:00:00.544375
elapsed time: 0:01:07.211864
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 14:56:09.127388
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 256.09
 ---- batch: 020 ----
mean loss: 256.98
 ---- batch: 030 ----
mean loss: 254.15
train mean loss: 254.48
epoch train time: 0:00:00.531580
elapsed time: 0:01:07.743726
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 14:56:09.659258
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.86
 ---- batch: 020 ----
mean loss: 255.43
 ---- batch: 030 ----
mean loss: 252.14
train mean loss: 251.76
epoch train time: 0:00:00.527521
elapsed time: 0:01:08.271504
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 14:56:10.187033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.28
 ---- batch: 020 ----
mean loss: 254.63
 ---- batch: 030 ----
mean loss: 251.60
train mean loss: 252.10
epoch train time: 0:00:00.534019
elapsed time: 0:01:08.805812
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 14:56:10.721357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 243.20
 ---- batch: 020 ----
mean loss: 252.51
 ---- batch: 030 ----
mean loss: 253.07
train mean loss: 249.88
epoch train time: 0:00:00.532597
elapsed time: 0:01:09.338693
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 14:56:11.254229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 247.80
 ---- batch: 020 ----
mean loss: 253.03
 ---- batch: 030 ----
mean loss: 245.99
train mean loss: 248.97
epoch train time: 0:00:00.523412
elapsed time: 0:01:09.862424
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 14:56:11.777915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 250.66
 ---- batch: 020 ----
mean loss: 242.43
 ---- batch: 030 ----
mean loss: 251.85
train mean loss: 247.43
epoch train time: 0:00:00.528308
elapsed time: 0:01:10.390961
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 14:56:12.306568
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 245.65
 ---- batch: 020 ----
mean loss: 251.38
 ---- batch: 030 ----
mean loss: 239.81
train mean loss: 246.07
epoch train time: 0:00:00.521411
elapsed time: 0:01:10.912767
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 14:56:12.828310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.56
 ---- batch: 020 ----
mean loss: 242.94
 ---- batch: 030 ----
mean loss: 247.96
train mean loss: 245.96
epoch train time: 0:00:00.539702
elapsed time: 0:01:11.452787
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 14:56:13.368385
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.85
 ---- batch: 020 ----
mean loss: 248.92
 ---- batch: 030 ----
mean loss: 245.68
train mean loss: 244.17
epoch train time: 0:00:00.538669
elapsed time: 0:01:11.991783
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 14:56:13.907314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 246.29
 ---- batch: 020 ----
mean loss: 237.44
 ---- batch: 030 ----
mean loss: 242.89
train mean loss: 242.10
epoch train time: 0:00:00.537325
elapsed time: 0:01:12.529378
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 14:56:14.444912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.84
 ---- batch: 020 ----
mean loss: 241.02
 ---- batch: 030 ----
mean loss: 235.70
train mean loss: 241.13
epoch train time: 0:00:00.540920
elapsed time: 0:01:13.070560
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 14:56:14.986094
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 240.53
 ---- batch: 020 ----
mean loss: 239.16
 ---- batch: 030 ----
mean loss: 239.93
train mean loss: 239.60
epoch train time: 0:00:00.531869
elapsed time: 0:01:13.602773
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 14:56:15.518325
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.60
 ---- batch: 020 ----
mean loss: 241.71
 ---- batch: 030 ----
mean loss: 243.57
train mean loss: 238.84
epoch train time: 0:00:00.567423
elapsed time: 0:01:14.170496
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 14:56:16.086032
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.77
 ---- batch: 020 ----
mean loss: 241.00
 ---- batch: 030 ----
mean loss: 234.91
train mean loss: 237.56
epoch train time: 0:00:00.537923
elapsed time: 0:01:14.708696
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 14:56:16.624230
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.74
 ---- batch: 020 ----
mean loss: 241.31
 ---- batch: 030 ----
mean loss: 234.90
train mean loss: 236.27
epoch train time: 0:00:00.534890
elapsed time: 0:01:15.243856
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 14:56:17.159390
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 236.17
 ---- batch: 020 ----
mean loss: 239.26
 ---- batch: 030 ----
mean loss: 235.05
train mean loss: 235.11
epoch train time: 0:00:00.532122
elapsed time: 0:01:15.776261
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 14:56:17.691803
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.20
 ---- batch: 020 ----
mean loss: 234.81
 ---- batch: 030 ----
mean loss: 234.12
train mean loss: 234.57
epoch train time: 0:00:00.548294
elapsed time: 0:01:16.324879
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 14:56:18.240416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.34
 ---- batch: 020 ----
mean loss: 230.54
 ---- batch: 030 ----
mean loss: 238.68
train mean loss: 234.34
epoch train time: 0:00:00.549472
elapsed time: 0:01:16.874639
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 14:56:18.790170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 234.15
 ---- batch: 020 ----
mean loss: 231.00
 ---- batch: 030 ----
mean loss: 230.18
train mean loss: 231.88
epoch train time: 0:00:00.544433
elapsed time: 0:01:17.419342
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 14:56:19.334946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 231.76
 ---- batch: 020 ----
mean loss: 230.49
 ---- batch: 030 ----
mean loss: 233.92
train mean loss: 231.11
epoch train time: 0:00:00.552272
elapsed time: 0:01:17.971963
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 14:56:19.887513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 235.82
 ---- batch: 020 ----
mean loss: 232.58
 ---- batch: 030 ----
mean loss: 228.63
train mean loss: 230.85
epoch train time: 0:00:00.559024
elapsed time: 0:01:18.531312
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 14:56:20.446859
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.22
 ---- batch: 020 ----
mean loss: 227.33
 ---- batch: 030 ----
mean loss: 231.19
train mean loss: 229.68
epoch train time: 0:00:00.550869
elapsed time: 0:01:19.082483
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 14:56:20.998024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.98
 ---- batch: 020 ----
mean loss: 223.91
 ---- batch: 030 ----
mean loss: 228.00
train mean loss: 228.38
epoch train time: 0:00:00.532629
elapsed time: 0:01:19.615392
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 14:56:21.530927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 233.81
 ---- batch: 020 ----
mean loss: 222.89
 ---- batch: 030 ----
mean loss: 224.41
train mean loss: 228.77
epoch train time: 0:00:00.535256
elapsed time: 0:01:20.150982
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 14:56:22.066518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 227.12
 ---- batch: 020 ----
mean loss: 228.47
 ---- batch: 030 ----
mean loss: 226.49
train mean loss: 226.61
epoch train time: 0:00:00.532222
elapsed time: 0:01:20.683548
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 14:56:22.599037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 229.66
 ---- batch: 020 ----
mean loss: 221.35
 ---- batch: 030 ----
mean loss: 229.04
train mean loss: 224.88
epoch train time: 0:00:00.565324
elapsed time: 0:01:21.249105
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 14:56:23.164652
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.92
 ---- batch: 020 ----
mean loss: 225.50
 ---- batch: 030 ----
mean loss: 222.18
train mean loss: 224.41
epoch train time: 0:00:00.558215
elapsed time: 0:01:21.807634
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 14:56:23.723167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 224.15
 ---- batch: 020 ----
mean loss: 224.31
 ---- batch: 030 ----
mean loss: 221.88
train mean loss: 223.62
epoch train time: 0:00:00.560522
elapsed time: 0:01:22.368445
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 14:56:24.283986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.27
 ---- batch: 020 ----
mean loss: 220.12
 ---- batch: 030 ----
mean loss: 227.97
train mean loss: 223.31
epoch train time: 0:00:00.542897
elapsed time: 0:01:22.911648
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 14:56:24.827186
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.23
 ---- batch: 020 ----
mean loss: 224.58
 ---- batch: 030 ----
mean loss: 220.75
train mean loss: 221.12
epoch train time: 0:00:00.533418
elapsed time: 0:01:23.445358
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 14:56:25.360892
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 225.54
 ---- batch: 020 ----
mean loss: 220.95
 ---- batch: 030 ----
mean loss: 221.00
train mean loss: 221.32
epoch train time: 0:00:00.536234
elapsed time: 0:01:23.981882
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 14:56:25.897420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.22
 ---- batch: 020 ----
mean loss: 217.10
 ---- batch: 030 ----
mean loss: 219.36
train mean loss: 220.50
epoch train time: 0:00:00.541752
elapsed time: 0:01:24.523918
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 14:56:26.439456
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 220.73
 ---- batch: 020 ----
mean loss: 216.64
 ---- batch: 030 ----
mean loss: 221.38
train mean loss: 219.62
epoch train time: 0:00:00.551591
elapsed time: 0:01:25.075845
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 14:56:26.991398
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.68
 ---- batch: 020 ----
mean loss: 219.45
 ---- batch: 030 ----
mean loss: 218.38
train mean loss: 218.25
epoch train time: 0:00:00.545363
elapsed time: 0:01:25.621530
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 14:56:27.537098
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.32
 ---- batch: 020 ----
mean loss: 214.50
 ---- batch: 030 ----
mean loss: 212.87
train mean loss: 217.42
epoch train time: 0:00:00.554119
elapsed time: 0:01:26.175991
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 14:56:28.091525
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 211.61
 ---- batch: 020 ----
mean loss: 215.34
 ---- batch: 030 ----
mean loss: 220.72
train mean loss: 217.35
epoch train time: 0:00:00.549789
elapsed time: 0:01:26.726048
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 14:56:28.641578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 218.53
 ---- batch: 020 ----
mean loss: 216.88
 ---- batch: 030 ----
mean loss: 216.79
train mean loss: 215.72
epoch train time: 0:00:00.561345
elapsed time: 0:01:27.287667
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 14:56:29.203197
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 217.51
 ---- batch: 020 ----
mean loss: 217.38
 ---- batch: 030 ----
mean loss: 212.76
train mean loss: 215.70
epoch train time: 0:00:00.543354
elapsed time: 0:01:27.831284
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 14:56:29.746811
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.67
 ---- batch: 020 ----
mean loss: 218.52
 ---- batch: 030 ----
mean loss: 211.21
train mean loss: 215.09
epoch train time: 0:00:00.542675
elapsed time: 0:01:28.374492
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 14:56:30.290026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.66
 ---- batch: 020 ----
mean loss: 212.15
 ---- batch: 030 ----
mean loss: 213.23
train mean loss: 214.51
epoch train time: 0:00:00.539813
elapsed time: 0:01:28.914593
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 14:56:30.830128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 212.64
 ---- batch: 020 ----
mean loss: 212.25
 ---- batch: 030 ----
mean loss: 216.45
train mean loss: 212.70
epoch train time: 0:00:00.526283
elapsed time: 0:01:29.441188
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 14:56:31.356718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.81
 ---- batch: 020 ----
mean loss: 214.43
 ---- batch: 030 ----
mean loss: 214.12
train mean loss: 212.54
epoch train time: 0:00:00.545983
elapsed time: 0:01:29.987444
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 14:56:31.902975
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.87
 ---- batch: 020 ----
mean loss: 209.58
 ---- batch: 030 ----
mean loss: 215.72
train mean loss: 211.56
epoch train time: 0:00:00.545184
elapsed time: 0:01:30.532904
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 14:56:32.448467
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.15
 ---- batch: 020 ----
mean loss: 217.82
 ---- batch: 030 ----
mean loss: 206.63
train mean loss: 211.07
epoch train time: 0:00:00.555169
elapsed time: 0:01:31.088397
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 14:56:33.003930
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 213.68
 ---- batch: 020 ----
mean loss: 215.21
 ---- batch: 030 ----
mean loss: 206.66
train mean loss: 210.71
epoch train time: 0:00:00.536796
elapsed time: 0:01:31.625463
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 14:56:33.541001
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 209.39
 ---- batch: 020 ----
mean loss: 209.52
 ---- batch: 030 ----
mean loss: 210.30
train mean loss: 209.89
epoch train time: 0:00:00.536537
elapsed time: 0:01:32.162312
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 14:56:34.077867
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.45
 ---- batch: 020 ----
mean loss: 208.69
 ---- batch: 030 ----
mean loss: 211.63
train mean loss: 209.39
epoch train time: 0:00:00.540788
elapsed time: 0:01:32.703488
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 14:56:34.619026
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.06
 ---- batch: 020 ----
mean loss: 205.55
 ---- batch: 030 ----
mean loss: 216.52
train mean loss: 209.24
epoch train time: 0:00:00.554750
elapsed time: 0:01:33.258518
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 14:56:35.174045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 203.67
 ---- batch: 020 ----
mean loss: 212.92
 ---- batch: 030 ----
mean loss: 207.74
train mean loss: 208.14
epoch train time: 0:00:00.525057
elapsed time: 0:01:33.783848
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 14:56:35.699381
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.35
 ---- batch: 020 ----
mean loss: 208.65
 ---- batch: 030 ----
mean loss: 207.59
train mean loss: 207.04
epoch train time: 0:00:00.522211
elapsed time: 0:01:34.306332
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 14:56:36.221860
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 207.66
 ---- batch: 020 ----
mean loss: 210.96
 ---- batch: 030 ----
mean loss: 200.89
train mean loss: 207.36
epoch train time: 0:00:00.535265
elapsed time: 0:01:34.841869
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 14:56:36.757433
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 201.77
 ---- batch: 020 ----
mean loss: 209.24
 ---- batch: 030 ----
mean loss: 207.20
train mean loss: 206.70
epoch train time: 0:00:00.556716
elapsed time: 0:01:35.398920
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 14:56:37.314449
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.10
 ---- batch: 020 ----
mean loss: 206.63
 ---- batch: 030 ----
mean loss: 208.43
train mean loss: 206.43
epoch train time: 0:00:00.590446
elapsed time: 0:01:35.989623
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 14:56:37.905147
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.85
 ---- batch: 020 ----
mean loss: 202.33
 ---- batch: 030 ----
mean loss: 205.67
train mean loss: 205.36
epoch train time: 0:00:00.528168
elapsed time: 0:01:36.518085
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 14:56:38.433649
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 208.77
 ---- batch: 020 ----
mean loss: 205.98
 ---- batch: 030 ----
mean loss: 200.79
train mean loss: 204.46
epoch train time: 0:00:00.544446
elapsed time: 0:01:37.062852
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 14:56:38.978386
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 204.74
 ---- batch: 020 ----
mean loss: 209.88
 ---- batch: 030 ----
mean loss: 200.35
train mean loss: 204.01
epoch train time: 0:00:00.552070
elapsed time: 0:01:37.615190
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 14:56:39.530722
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 205.75
 ---- batch: 020 ----
mean loss: 200.63
 ---- batch: 030 ----
mean loss: 205.56
train mean loss: 203.58
epoch train time: 0:00:00.532602
elapsed time: 0:01:38.148114
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 14:56:40.063650
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 198.52
 ---- batch: 020 ----
mean loss: 200.82
 ---- batch: 030 ----
mean loss: 202.61
train mean loss: 202.27
epoch train time: 0:00:00.531909
elapsed time: 0:01:38.680311
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 14:56:40.595843
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.32
 ---- batch: 020 ----
mean loss: 203.25
 ---- batch: 030 ----
mean loss: 202.98
train mean loss: 202.09
epoch train time: 0:00:00.543494
elapsed time: 0:01:39.224088
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 14:56:41.139622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 203.25
 ---- batch: 020 ----
mean loss: 200.69
 ---- batch: 030 ----
mean loss: 205.76
train mean loss: 202.00
epoch train time: 0:00:00.546039
elapsed time: 0:01:39.770412
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 14:56:41.685984
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 200.99
 ---- batch: 020 ----
mean loss: 198.68
 ---- batch: 030 ----
mean loss: 205.95
train mean loss: 201.05
epoch train time: 0:00:00.552774
elapsed time: 0:01:40.323509
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 14:56:42.239049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.90
 ---- batch: 020 ----
mean loss: 206.93
 ---- batch: 030 ----
mean loss: 200.05
train mean loss: 200.56
epoch train time: 0:00:00.548102
elapsed time: 0:01:40.871950
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 14:56:42.787508
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.75
 ---- batch: 020 ----
mean loss: 202.11
 ---- batch: 030 ----
mean loss: 199.45
train mean loss: 199.84
epoch train time: 0:00:00.542498
elapsed time: 0:01:41.414742
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 14:56:43.330271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 201.99
 ---- batch: 020 ----
mean loss: 200.69
 ---- batch: 030 ----
mean loss: 198.44
train mean loss: 199.12
epoch train time: 0:00:00.543879
elapsed time: 0:01:41.958914
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 14:56:43.874462
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.01
 ---- batch: 020 ----
mean loss: 202.79
 ---- batch: 030 ----
mean loss: 197.26
train mean loss: 199.17
epoch train time: 0:00:00.545716
elapsed time: 0:01:42.505002
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 14:56:44.420540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.53
 ---- batch: 020 ----
mean loss: 195.60
 ---- batch: 030 ----
mean loss: 201.99
train mean loss: 198.55
epoch train time: 0:00:00.544220
elapsed time: 0:01:43.049500
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 14:56:44.965029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.64
 ---- batch: 020 ----
mean loss: 198.11
 ---- batch: 030 ----
mean loss: 198.62
train mean loss: 197.93
epoch train time: 0:00:00.552645
elapsed time: 0:01:43.602487
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 14:56:45.518029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 201.83
 ---- batch: 020 ----
mean loss: 199.10
 ---- batch: 030 ----
mean loss: 194.18
train mean loss: 198.42
epoch train time: 0:00:00.557794
elapsed time: 0:01:44.160622
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 14:56:46.076157
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 195.31
 ---- batch: 020 ----
mean loss: 198.29
 ---- batch: 030 ----
mean loss: 196.94
train mean loss: 197.21
epoch train time: 0:00:00.553058
elapsed time: 0:01:44.713961
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 14:56:46.629507
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 197.86
 ---- batch: 020 ----
mean loss: 196.95
 ---- batch: 030 ----
mean loss: 198.34
train mean loss: 196.64
epoch train time: 0:00:00.559564
elapsed time: 0:01:45.273904
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 14:56:47.189467
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.17
 ---- batch: 020 ----
mean loss: 188.45
 ---- batch: 030 ----
mean loss: 199.57
train mean loss: 196.71
epoch train time: 0:00:00.574395
elapsed time: 0:01:45.848598
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 14:56:47.764159
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 194.31
 ---- batch: 020 ----
mean loss: 198.58
 ---- batch: 030 ----
mean loss: 191.01
train mean loss: 195.89
epoch train time: 0:00:00.537150
elapsed time: 0:01:46.386094
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 14:56:48.301595
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.72
 ---- batch: 020 ----
mean loss: 197.16
 ---- batch: 030 ----
mean loss: 197.44
train mean loss: 195.57
epoch train time: 0:00:00.546662
elapsed time: 0:01:46.932993
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 14:56:48.848543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 193.34
 ---- batch: 020 ----
mean loss: 193.55
 ---- batch: 030 ----
mean loss: 195.39
train mean loss: 194.88
epoch train time: 0:00:00.527834
elapsed time: 0:01:47.461137
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 14:56:49.376673
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.52
 ---- batch: 020 ----
mean loss: 188.30
 ---- batch: 030 ----
mean loss: 201.07
train mean loss: 194.86
epoch train time: 0:00:00.534834
elapsed time: 0:01:47.996262
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 14:56:49.911793
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.57
 ---- batch: 020 ----
mean loss: 188.38
 ---- batch: 030 ----
mean loss: 196.37
train mean loss: 194.13
epoch train time: 0:00:00.527997
elapsed time: 0:01:48.524906
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 14:56:50.440450
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.17
 ---- batch: 020 ----
mean loss: 200.90
 ---- batch: 030 ----
mean loss: 190.89
train mean loss: 194.12
epoch train time: 0:00:00.543964
elapsed time: 0:01:49.069161
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 14:56:50.984695
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.82
 ---- batch: 020 ----
mean loss: 191.52
 ---- batch: 030 ----
mean loss: 198.26
train mean loss: 193.72
epoch train time: 0:00:00.536088
elapsed time: 0:01:49.605515
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 14:56:51.521046
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.84
 ---- batch: 020 ----
mean loss: 195.09
 ---- batch: 030 ----
mean loss: 192.69
train mean loss: 193.07
epoch train time: 0:00:00.539247
elapsed time: 0:01:50.145069
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 14:56:52.060622
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.81
 ---- batch: 020 ----
mean loss: 194.02
 ---- batch: 030 ----
mean loss: 192.62
train mean loss: 192.42
epoch train time: 0:00:00.547176
elapsed time: 0:01:50.692541
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 14:56:52.608078
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.75
 ---- batch: 020 ----
mean loss: 195.39
 ---- batch: 030 ----
mean loss: 190.35
train mean loss: 192.05
epoch train time: 0:00:00.544994
elapsed time: 0:01:51.237827
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 14:56:53.153393
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.20
 ---- batch: 020 ----
mean loss: 187.28
 ---- batch: 030 ----
mean loss: 194.19
train mean loss: 192.16
epoch train time: 0:00:00.547708
elapsed time: 0:01:51.785934
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 14:56:53.701492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.78
 ---- batch: 020 ----
mean loss: 187.35
 ---- batch: 030 ----
mean loss: 189.85
train mean loss: 191.03
epoch train time: 0:00:00.551768
elapsed time: 0:01:52.338042
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 14:56:54.253591
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 192.12
 ---- batch: 020 ----
mean loss: 200.36
 ---- batch: 030 ----
mean loss: 182.53
train mean loss: 191.04
epoch train time: 0:00:00.563097
elapsed time: 0:01:52.901447
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 14:56:54.817004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.63
 ---- batch: 020 ----
mean loss: 193.75
 ---- batch: 030 ----
mean loss: 192.57
train mean loss: 190.77
epoch train time: 0:00:00.546245
elapsed time: 0:01:53.448031
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 14:56:55.363570
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.62
 ---- batch: 020 ----
mean loss: 195.81
 ---- batch: 030 ----
mean loss: 191.18
train mean loss: 190.77
epoch train time: 0:00:00.548139
elapsed time: 0:01:53.996461
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 14:56:55.912002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 189.99
 ---- batch: 020 ----
mean loss: 185.13
 ---- batch: 030 ----
mean loss: 194.64
train mean loss: 189.80
epoch train time: 0:00:00.550556
elapsed time: 0:01:54.547376
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 14:56:56.462985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 185.04
 ---- batch: 020 ----
mean loss: 191.55
 ---- batch: 030 ----
mean loss: 193.43
train mean loss: 189.26
epoch train time: 0:00:00.552142
elapsed time: 0:01:55.099889
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 14:56:57.015422
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.93
 ---- batch: 020 ----
mean loss: 192.45
 ---- batch: 030 ----
mean loss: 187.93
train mean loss: 188.68
epoch train time: 0:00:00.543152
elapsed time: 0:01:55.643308
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 14:56:57.558835
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 187.43
 ---- batch: 020 ----
mean loss: 187.14
 ---- batch: 030 ----
mean loss: 192.54
train mean loss: 188.52
epoch train time: 0:00:00.553902
elapsed time: 0:01:56.197468
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 14:56:58.112995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.57
 ---- batch: 020 ----
mean loss: 193.06
 ---- batch: 030 ----
mean loss: 184.59
train mean loss: 188.59
epoch train time: 0:00:00.547464
elapsed time: 0:01:56.745234
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 14:56:58.660764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 188.91
 ---- batch: 020 ----
mean loss: 193.38
 ---- batch: 030 ----
mean loss: 184.25
train mean loss: 187.77
epoch train time: 0:00:00.548070
elapsed time: 0:01:57.293582
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 14:56:59.209109
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.11
 ---- batch: 020 ----
mean loss: 192.70
 ---- batch: 030 ----
mean loss: 183.87
train mean loss: 187.21
epoch train time: 0:00:00.548356
elapsed time: 0:01:57.842251
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 14:56:59.757801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 186.58
 ---- batch: 020 ----
mean loss: 184.31
 ---- batch: 030 ----
mean loss: 192.10
train mean loss: 187.37
epoch train time: 0:00:00.546620
elapsed time: 0:01:58.389163
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 14:57:00.304693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.61
 ---- batch: 020 ----
mean loss: 186.98
 ---- batch: 030 ----
mean loss: 183.27
train mean loss: 186.47
epoch train time: 0:00:00.549952
elapsed time: 0:01:58.939407
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 14:57:00.854946
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.48
 ---- batch: 020 ----
mean loss: 194.91
 ---- batch: 030 ----
mean loss: 183.06
train mean loss: 186.02
epoch train time: 0:00:00.530038
elapsed time: 0:01:59.469720
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 14:57:01.385251
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.54
 ---- batch: 020 ----
mean loss: 188.88
 ---- batch: 030 ----
mean loss: 186.81
train mean loss: 186.00
epoch train time: 0:00:00.549543
elapsed time: 0:02:00.019555
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 14:57:01.935088
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 183.06
 ---- batch: 020 ----
mean loss: 185.87
 ---- batch: 030 ----
mean loss: 187.30
train mean loss: 185.88
epoch train time: 0:00:00.545332
elapsed time: 0:02:00.565238
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 14:57:02.480772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.36
 ---- batch: 020 ----
mean loss: 185.21
 ---- batch: 030 ----
mean loss: 187.18
train mean loss: 185.13
epoch train time: 0:00:00.557729
elapsed time: 0:02:01.123285
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 14:57:03.038823
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 185.17
 ---- batch: 020 ----
mean loss: 183.24
 ---- batch: 030 ----
mean loss: 188.03
train mean loss: 185.02
epoch train time: 0:00:00.539926
elapsed time: 0:02:01.663554
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 14:57:03.579056
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 177.00
 ---- batch: 020 ----
mean loss: 189.14
 ---- batch: 030 ----
mean loss: 188.63
train mean loss: 185.41
epoch train time: 0:00:00.552562
elapsed time: 0:02:02.216407
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 14:57:04.132021
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 188.24
 ---- batch: 020 ----
mean loss: 187.90
 ---- batch: 030 ----
mean loss: 179.58
train mean loss: 185.30
epoch train time: 0:00:00.545306
elapsed time: 0:02:02.762123
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 14:57:04.677682
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 187.20
 ---- batch: 020 ----
mean loss: 180.94
 ---- batch: 030 ----
mean loss: 189.95
train mean loss: 185.01
epoch train time: 0:00:00.560912
elapsed time: 0:02:03.323343
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 14:57:05.238876
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 186.02
 ---- batch: 020 ----
mean loss: 183.38
 ---- batch: 030 ----
mean loss: 185.04
train mean loss: 184.88
epoch train time: 0:00:00.548578
elapsed time: 0:02:03.872227
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 14:57:05.787761
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 181.50
 ---- batch: 020 ----
mean loss: 186.02
 ---- batch: 030 ----
mean loss: 181.59
train mean loss: 185.19
epoch train time: 0:00:00.557750
elapsed time: 0:02:04.430344
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 14:57:06.345897
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 182.03
 ---- batch: 020 ----
mean loss: 182.32
 ---- batch: 030 ----
mean loss: 190.19
train mean loss: 184.91
epoch train time: 0:00:00.574868
elapsed time: 0:02:05.005572
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 14:57:06.921111
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 183.27
 ---- batch: 020 ----
mean loss: 182.92
 ---- batch: 030 ----
mean loss: 186.67
train mean loss: 184.56
epoch train time: 0:00:00.555766
elapsed time: 0:02:05.561702
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 14:57:07.477237
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 183.84
 ---- batch: 020 ----
mean loss: 189.62
 ---- batch: 030 ----
mean loss: 182.98
train mean loss: 184.72
epoch train time: 0:00:00.553782
elapsed time: 0:02:06.115781
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 14:57:08.031312
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 182.42
 ---- batch: 020 ----
mean loss: 183.37
 ---- batch: 030 ----
mean loss: 189.03
train mean loss: 185.13
epoch train time: 0:00:00.550428
elapsed time: 0:02:06.666511
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 14:57:08.582047
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 182.40
 ---- batch: 020 ----
mean loss: 185.57
 ---- batch: 030 ----
mean loss: 186.91
train mean loss: 184.32
epoch train time: 0:00:00.556363
elapsed time: 0:02:07.223194
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 14:57:09.138726
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 183.57
 ---- batch: 020 ----
mean loss: 189.97
 ---- batch: 030 ----
mean loss: 184.86
train mean loss: 184.88
epoch train time: 0:00:00.541460
elapsed time: 0:02:07.764957
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 14:57:09.680513
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 192.27
 ---- batch: 020 ----
mean loss: 181.64
 ---- batch: 030 ----
mean loss: 180.57
train mean loss: 184.56
epoch train time: 0:00:00.561248
elapsed time: 0:02:08.326544
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 14:57:10.242086
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 184.48
 ---- batch: 020 ----
mean loss: 186.20
 ---- batch: 030 ----
mean loss: 180.50
train mean loss: 185.29
epoch train time: 0:00:00.565919
elapsed time: 0:02:08.892773
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 14:57:10.808308
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 186.07
 ---- batch: 020 ----
mean loss: 183.66
 ---- batch: 030 ----
mean loss: 185.00
train mean loss: 184.44
epoch train time: 0:00:00.547479
elapsed time: 0:02:09.440618
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 14:57:11.356171
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 181.99
 ---- batch: 020 ----
mean loss: 184.99
 ---- batch: 030 ----
mean loss: 183.10
train mean loss: 184.52
epoch train time: 0:00:00.558878
elapsed time: 0:02:09.999907
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 14:57:11.915478
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 185.35
 ---- batch: 020 ----
mean loss: 180.89
 ---- batch: 030 ----
mean loss: 186.97
train mean loss: 184.64
epoch train time: 0:00:00.547243
elapsed time: 0:02:10.547489
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 14:57:12.463026
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 187.54
 ---- batch: 020 ----
mean loss: 180.23
 ---- batch: 030 ----
mean loss: 183.21
train mean loss: 185.01
epoch train time: 0:00:00.545816
elapsed time: 0:02:11.093608
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 14:57:13.009147
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 184.87
 ---- batch: 020 ----
mean loss: 183.87
 ---- batch: 030 ----
mean loss: 187.60
train mean loss: 184.87
epoch train time: 0:00:00.539649
elapsed time: 0:02:11.633546
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 14:57:13.549110
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 186.37
 ---- batch: 020 ----
mean loss: 187.21
 ---- batch: 030 ----
mean loss: 181.18
train mean loss: 185.02
epoch train time: 0:00:00.559264
elapsed time: 0:02:12.193138
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 14:57:14.108677
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 180.86
 ---- batch: 020 ----
mean loss: 187.71
 ---- batch: 030 ----
mean loss: 187.61
train mean loss: 185.15
epoch train time: 0:00:00.547680
elapsed time: 0:02:12.741165
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 14:57:14.656705
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 187.52
 ---- batch: 020 ----
mean loss: 181.33
 ---- batch: 030 ----
mean loss: 182.65
train mean loss: 184.44
epoch train time: 0:00:00.546632
elapsed time: 0:02:13.288107
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 14:57:15.203645
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 183.04
 ---- batch: 020 ----
mean loss: 184.56
 ---- batch: 030 ----
mean loss: 184.42
train mean loss: 184.46
epoch train time: 0:00:00.539847
elapsed time: 0:02:13.828498
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 14:57:15.744061
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 182.81
 ---- batch: 020 ----
mean loss: 185.16
 ---- batch: 030 ----
mean loss: 185.83
train mean loss: 184.02
epoch train time: 0:00:00.552422
elapsed time: 0:02:14.381261
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 14:57:16.296799
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 181.75
 ---- batch: 020 ----
mean loss: 188.20
 ---- batch: 030 ----
mean loss: 184.29
train mean loss: 184.76
epoch train time: 0:00:00.551099
elapsed time: 0:02:14.932651
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 14:57:16.848180
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 186.56
 ---- batch: 020 ----
mean loss: 187.09
 ---- batch: 030 ----
mean loss: 181.92
train mean loss: 184.42
epoch train time: 0:00:00.555801
elapsed time: 0:02:15.488733
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 14:57:17.404271
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 186.20
 ---- batch: 020 ----
mean loss: 188.39
 ---- batch: 030 ----
mean loss: 183.53
train mean loss: 184.41
epoch train time: 0:00:00.551628
elapsed time: 0:02:16.040659
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 14:57:17.956198
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 179.87
 ---- batch: 020 ----
mean loss: 186.54
 ---- batch: 030 ----
mean loss: 184.15
train mean loss: 184.75
epoch train time: 0:00:00.547446
elapsed time: 0:02:16.588416
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 14:57:18.503973
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 181.44
 ---- batch: 020 ----
mean loss: 184.62
 ---- batch: 030 ----
mean loss: 183.15
train mean loss: 184.69
epoch train time: 0:00:00.554835
elapsed time: 0:02:17.143584
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 14:57:19.059125
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 182.29
 ---- batch: 020 ----
mean loss: 187.62
 ---- batch: 030 ----
mean loss: 180.85
train mean loss: 183.74
epoch train time: 0:00:00.552158
elapsed time: 0:02:17.696067
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 14:57:19.611606
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 188.50
 ---- batch: 020 ----
mean loss: 180.44
 ---- batch: 030 ----
mean loss: 184.28
train mean loss: 184.06
epoch train time: 0:00:00.547655
elapsed time: 0:02:18.244015
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 14:57:20.159579
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 182.66
 ---- batch: 020 ----
mean loss: 184.88
 ---- batch: 030 ----
mean loss: 187.99
train mean loss: 184.16
epoch train time: 0:00:00.561910
elapsed time: 0:02:18.806286
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 14:57:20.721832
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 181.91
 ---- batch: 020 ----
mean loss: 189.45
 ---- batch: 030 ----
mean loss: 184.09
train mean loss: 184.06
epoch train time: 0:00:00.548857
elapsed time: 0:02:19.355542
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 14:57:21.271031
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 188.66
 ---- batch: 020 ----
mean loss: 181.49
 ---- batch: 030 ----
mean loss: 184.21
train mean loss: 184.56
epoch train time: 0:00:00.548183
elapsed time: 0:02:19.904031
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 14:57:21.819569
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 186.64
 ---- batch: 020 ----
mean loss: 182.48
 ---- batch: 030 ----
mean loss: 182.42
train mean loss: 184.01
epoch train time: 0:00:00.554647
elapsed time: 0:02:20.458975
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 14:57:22.374512
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 183.34
 ---- batch: 020 ----
mean loss: 187.03
 ---- batch: 030 ----
mean loss: 182.85
train mean loss: 184.76
epoch train time: 0:00:00.550394
elapsed time: 0:02:21.009670
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 14:57:22.925206
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 184.35
 ---- batch: 020 ----
mean loss: 188.39
 ---- batch: 030 ----
mean loss: 183.10
train mean loss: 183.86
epoch train time: 0:00:00.534330
elapsed time: 0:02:21.544341
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 14:57:23.459909
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 187.07
 ---- batch: 020 ----
mean loss: 185.28
 ---- batch: 030 ----
mean loss: 181.55
train mean loss: 184.50
epoch train time: 0:00:00.538773
elapsed time: 0:02:22.083439
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 14:57:23.998992
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 180.46
 ---- batch: 020 ----
mean loss: 187.76
 ---- batch: 030 ----
mean loss: 181.26
train mean loss: 184.00
epoch train time: 0:00:00.534243
elapsed time: 0:02:22.618001
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 14:57:24.533550
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 186.11
 ---- batch: 020 ----
mean loss: 182.96
 ---- batch: 030 ----
mean loss: 186.37
train mean loss: 183.58
epoch train time: 0:00:00.572985
elapsed time: 0:02:23.191299
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 14:57:25.106867
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 189.46
 ---- batch: 020 ----
mean loss: 184.02
 ---- batch: 030 ----
mean loss: 179.24
train mean loss: 184.12
epoch train time: 0:00:00.555138
elapsed time: 0:02:23.746766
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 14:57:25.662305
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 183.77
 ---- batch: 020 ----
mean loss: 180.67
 ---- batch: 030 ----
mean loss: 186.50
train mean loss: 183.69
epoch train time: 0:00:00.549312
elapsed time: 0:02:24.296385
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 14:57:26.211938
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 181.95
 ---- batch: 020 ----
mean loss: 188.95
 ---- batch: 030 ----
mean loss: 182.40
train mean loss: 183.73
epoch train time: 0:00:00.550550
elapsed time: 0:02:24.847253
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 14:57:26.762830
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 184.17
 ---- batch: 020 ----
mean loss: 185.53
 ---- batch: 030 ----
mean loss: 179.82
train mean loss: 183.81
epoch train time: 0:00:00.552910
elapsed time: 0:02:25.400512
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 14:57:27.316051
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 187.95
 ---- batch: 020 ----
mean loss: 177.93
 ---- batch: 030 ----
mean loss: 184.10
train mean loss: 183.53
epoch train time: 0:00:00.546707
elapsed time: 0:02:25.947565
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 14:57:27.863100
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 179.69
 ---- batch: 020 ----
mean loss: 185.34
 ---- batch: 030 ----
mean loss: 183.77
train mean loss: 183.79
epoch train time: 0:00:00.554797
elapsed time: 0:02:26.502710
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 14:57:28.418249
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 182.76
 ---- batch: 020 ----
mean loss: 187.54
 ---- batch: 030 ----
mean loss: 178.64
train mean loss: 183.66
epoch train time: 0:00:00.560807
elapsed time: 0:02:27.063800
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 14:57:28.979332
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 187.50
 ---- batch: 020 ----
mean loss: 183.12
 ---- batch: 030 ----
mean loss: 183.46
train mean loss: 183.79
epoch train time: 0:00:00.556040
elapsed time: 0:02:27.620212
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 14:57:29.535763
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 181.05
 ---- batch: 020 ----
mean loss: 183.25
 ---- batch: 030 ----
mean loss: 186.05
train mean loss: 183.80
epoch train time: 0:00:00.570415
elapsed time: 0:02:28.195013
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv2_pool2/bayesian_conv2_pool2_6/checkpoint.pth.tar
**** end time: 2019-09-27 14:57:30.110474 ****
