Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_1', max_epoch=250, max_rul=125, metric='rmse', model='bayesian_conv5_dense1', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 21251
use_cuda: True
Dataset: CMAPSS/FD001
Building BayesianConv5Dense1...
Done.
**** start time: 2019-09-27 06:11:26.010282 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
    BayesianConv2d-1           [-1, 10, 31, 14]             200
           Sigmoid-2           [-1, 10, 31, 14]               0
    BayesianConv2d-3           [-1, 10, 30, 14]           2,000
           Sigmoid-4           [-1, 10, 30, 14]               0
    BayesianConv2d-5           [-1, 10, 31, 14]           2,000
           Sigmoid-6           [-1, 10, 31, 14]               0
    BayesianConv2d-7           [-1, 10, 30, 14]           2,000
           Sigmoid-8           [-1, 10, 30, 14]               0
    BayesianConv2d-9            [-1, 1, 30, 14]              60
         Softplus-10            [-1, 1, 30, 14]               0
          Flatten-11                  [-1, 420]               0
   BayesianLinear-12                  [-1, 100]          84,000
         Softplus-13                  [-1, 100]               0
   BayesianLinear-14                    [-1, 1]             200
         Softplus-15                    [-1, 1]               0
================================================================
Total params: 90,460
Trainable params: 90,460
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 06:11:26.026758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1919.30
 ---- batch: 020 ----
mean loss: 1332.76
 ---- batch: 030 ----
mean loss: 1146.51
train mean loss: 1422.34
epoch train time: 0:00:17.064829
elapsed time: 0:00:17.089609
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 06:11:43.099945
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1083.69
 ---- batch: 020 ----
mean loss: 1050.24
 ---- batch: 030 ----
mean loss: 1062.12
train mean loss: 1061.71
epoch train time: 0:00:06.989870
elapsed time: 0:00:24.080099
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 06:11:50.090565
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1013.49
 ---- batch: 020 ----
mean loss: 997.01
 ---- batch: 030 ----
mean loss: 1022.14
train mean loss: 1009.22
epoch train time: 0:00:07.023467
elapsed time: 0:00:31.104386
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 06:11:57.114832
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1016.42
 ---- batch: 020 ----
mean loss: 981.78
 ---- batch: 030 ----
mean loss: 969.68
train mean loss: 984.68
epoch train time: 0:00:06.831385
elapsed time: 0:00:37.936500
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 06:12:03.946979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 962.25
 ---- batch: 020 ----
mean loss: 961.02
 ---- batch: 030 ----
mean loss: 937.11
train mean loss: 948.43
epoch train time: 0:00:06.900944
elapsed time: 0:00:44.838305
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 06:12:10.848743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 869.77
 ---- batch: 020 ----
mean loss: 847.58
 ---- batch: 030 ----
mean loss: 753.51
train mean loss: 806.81
epoch train time: 0:00:06.828270
elapsed time: 0:00:51.667380
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 06:12:17.677826
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 635.24
 ---- batch: 020 ----
mean loss: 521.68
 ---- batch: 030 ----
mean loss: 491.07
train mean loss: 534.12
epoch train time: 0:00:06.893544
elapsed time: 0:00:58.561756
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 06:12:24.572190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 430.07
 ---- batch: 020 ----
mean loss: 401.26
 ---- batch: 030 ----
mean loss: 393.66
train mean loss: 407.17
epoch train time: 0:00:06.904771
elapsed time: 0:01:05.467348
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 06:12:31.477809
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 380.91
 ---- batch: 020 ----
mean loss: 377.91
 ---- batch: 030 ----
mean loss: 368.44
train mean loss: 374.97
epoch train time: 0:00:06.826149
elapsed time: 0:01:12.294269
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 06:12:38.304721
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 374.52
 ---- batch: 020 ----
mean loss: 368.82
 ---- batch: 030 ----
mean loss: 374.92
train mean loss: 371.77
epoch train time: 0:00:06.862669
elapsed time: 0:01:19.157645
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 06:12:45.168079
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 352.47
 ---- batch: 020 ----
mean loss: 360.38
 ---- batch: 030 ----
mean loss: 346.31
train mean loss: 354.19
epoch train time: 0:00:06.689778
elapsed time: 0:01:25.848195
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 06:12:51.858648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 331.40
 ---- batch: 020 ----
mean loss: 354.56
 ---- batch: 030 ----
mean loss: 342.68
train mean loss: 343.56
epoch train time: 0:00:06.786592
elapsed time: 0:01:32.635719
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 06:12:58.646235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 336.72
 ---- batch: 020 ----
mean loss: 344.88
 ---- batch: 030 ----
mean loss: 331.30
train mean loss: 336.82
epoch train time: 0:00:06.685381
elapsed time: 0:01:39.321939
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 06:13:05.332366
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 325.13
 ---- batch: 020 ----
mean loss: 330.27
 ---- batch: 030 ----
mean loss: 322.77
train mean loss: 326.34
epoch train time: 0:00:06.767331
elapsed time: 0:01:46.090016
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 06:13:12.100461
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 309.14
 ---- batch: 020 ----
mean loss: 314.43
 ---- batch: 030 ----
mean loss: 315.32
train mean loss: 314.58
epoch train time: 0:00:06.765405
elapsed time: 0:01:52.856143
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 06:13:18.866577
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 317.04
 ---- batch: 020 ----
mean loss: 311.32
 ---- batch: 030 ----
mean loss: 304.97
train mean loss: 310.71
epoch train time: 0:00:06.759852
elapsed time: 0:01:59.616803
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 06:13:25.627229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 300.88
 ---- batch: 020 ----
mean loss: 309.11
 ---- batch: 030 ----
mean loss: 301.37
train mean loss: 302.97
epoch train time: 0:00:06.893583
elapsed time: 0:02:06.511122
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 06:13:32.521556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 297.16
 ---- batch: 020 ----
mean loss: 291.03
 ---- batch: 030 ----
mean loss: 289.66
train mean loss: 292.56
epoch train time: 0:00:06.924334
elapsed time: 0:02:13.436331
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 06:13:39.446768
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 293.60
 ---- batch: 020 ----
mean loss: 287.56
 ---- batch: 030 ----
mean loss: 280.00
train mean loss: 287.00
epoch train time: 0:00:06.931170
elapsed time: 0:02:20.368284
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 06:13:46.378725
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 268.73
 ---- batch: 020 ----
mean loss: 278.01
 ---- batch: 030 ----
mean loss: 272.23
train mean loss: 272.67
epoch train time: 0:00:06.815858
elapsed time: 0:02:27.184935
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 06:13:53.195391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 272.73
 ---- batch: 020 ----
mean loss: 271.21
 ---- batch: 030 ----
mean loss: 261.93
train mean loss: 268.50
epoch train time: 0:00:06.908692
elapsed time: 0:02:34.094368
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 06:14:00.104794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 266.79
 ---- batch: 020 ----
mean loss: 264.92
 ---- batch: 030 ----
mean loss: 261.90
train mean loss: 261.95
epoch train time: 0:00:06.816287
elapsed time: 0:02:40.911512
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 06:14:06.921993
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 251.05
 ---- batch: 020 ----
mean loss: 248.71
 ---- batch: 030 ----
mean loss: 245.16
train mean loss: 247.38
epoch train time: 0:00:06.861296
elapsed time: 0:02:47.773566
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 06:14:13.784038
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 238.45
 ---- batch: 020 ----
mean loss: 236.76
 ---- batch: 030 ----
mean loss: 229.26
train mean loss: 234.45
epoch train time: 0:00:06.838280
elapsed time: 0:02:54.612678
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 06:14:20.623106
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 232.45
 ---- batch: 020 ----
mean loss: 225.30
 ---- batch: 030 ----
mean loss: 224.79
train mean loss: 227.74
epoch train time: 0:00:06.830893
elapsed time: 0:03:01.444305
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 06:14:27.454737
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 221.44
 ---- batch: 020 ----
mean loss: 213.17
 ---- batch: 030 ----
mean loss: 221.15
train mean loss: 218.03
epoch train time: 0:00:06.795539
elapsed time: 0:03:08.240585
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 06:14:34.251049
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 222.62
 ---- batch: 020 ----
mean loss: 216.26
 ---- batch: 030 ----
mean loss: 210.56
train mean loss: 215.84
epoch train time: 0:00:06.759791
elapsed time: 0:03:15.001146
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 06:14:41.011589
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 215.05
 ---- batch: 020 ----
mean loss: 207.20
 ---- batch: 030 ----
mean loss: 213.81
train mean loss: 210.55
epoch train time: 0:00:06.764541
elapsed time: 0:03:21.766484
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 06:14:47.776941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 202.33
 ---- batch: 020 ----
mean loss: 203.85
 ---- batch: 030 ----
mean loss: 205.63
train mean loss: 204.43
epoch train time: 0:00:06.749184
elapsed time: 0:03:28.516514
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 06:14:54.526997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 199.02
 ---- batch: 020 ----
mean loss: 193.55
 ---- batch: 030 ----
mean loss: 197.31
train mean loss: 197.77
epoch train time: 0:00:06.742174
elapsed time: 0:03:35.259492
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 06:15:01.269980
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 190.96
 ---- batch: 020 ----
mean loss: 196.35
 ---- batch: 030 ----
mean loss: 198.54
train mean loss: 194.44
epoch train time: 0:00:06.724368
elapsed time: 0:03:41.984748
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 06:15:07.995195
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 191.53
 ---- batch: 020 ----
mean loss: 183.34
 ---- batch: 030 ----
mean loss: 193.00
train mean loss: 188.53
epoch train time: 0:00:06.848508
elapsed time: 0:03:48.834018
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 06:15:14.844468
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.98
 ---- batch: 020 ----
mean loss: 176.94
 ---- batch: 030 ----
mean loss: 185.87
train mean loss: 181.52
epoch train time: 0:00:06.835194
elapsed time: 0:03:55.669998
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 06:15:21.680486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 181.37
 ---- batch: 020 ----
mean loss: 174.59
 ---- batch: 030 ----
mean loss: 178.14
train mean loss: 177.31
epoch train time: 0:00:06.896555
elapsed time: 0:04:02.567470
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 06:15:28.577923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 173.82
 ---- batch: 020 ----
mean loss: 174.43
 ---- batch: 030 ----
mean loss: 176.78
train mean loss: 174.03
epoch train time: 0:00:06.895344
elapsed time: 0:04:09.463579
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 06:15:35.474014
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 169.97
 ---- batch: 020 ----
mean loss: 171.77
 ---- batch: 030 ----
mean loss: 167.99
train mean loss: 170.64
epoch train time: 0:00:06.890906
elapsed time: 0:04:16.355257
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 06:15:42.365715
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 170.19
 ---- batch: 020 ----
mean loss: 170.17
 ---- batch: 030 ----
mean loss: 161.90
train mean loss: 166.35
epoch train time: 0:00:06.869990
elapsed time: 0:04:23.226036
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 06:15:49.236485
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.50
 ---- batch: 020 ----
mean loss: 163.82
 ---- batch: 030 ----
mean loss: 164.78
train mean loss: 164.54
epoch train time: 0:00:06.806861
elapsed time: 0:04:30.033656
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 06:15:56.044102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 159.36
 ---- batch: 020 ----
mean loss: 162.54
 ---- batch: 030 ----
mean loss: 166.64
train mean loss: 161.75
epoch train time: 0:00:06.830751
elapsed time: 0:04:36.865177
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 06:16:02.875638
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 160.81
 ---- batch: 020 ----
mean loss: 163.41
 ---- batch: 030 ----
mean loss: 157.64
train mean loss: 160.63
epoch train time: 0:00:06.792320
elapsed time: 0:04:43.658284
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 06:16:09.668716
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 161.10
 ---- batch: 020 ----
mean loss: 154.69
 ---- batch: 030 ----
mean loss: 156.34
train mean loss: 158.14
epoch train time: 0:00:06.884966
elapsed time: 0:04:50.544017
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 06:16:16.554486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 158.86
 ---- batch: 020 ----
mean loss: 153.30
 ---- batch: 030 ----
mean loss: 157.32
train mean loss: 156.60
epoch train time: 0:00:06.784136
elapsed time: 0:04:57.328922
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 06:16:23.339357
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 152.92
 ---- batch: 020 ----
mean loss: 151.62
 ---- batch: 030 ----
mean loss: 150.97
train mean loss: 152.14
epoch train time: 0:00:06.777532
elapsed time: 0:05:04.107701
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 06:16:30.118170
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.28
 ---- batch: 020 ----
mean loss: 146.40
 ---- batch: 030 ----
mean loss: 152.73
train mean loss: 150.28
epoch train time: 0:00:06.775388
elapsed time: 0:05:10.883942
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 06:16:36.894382
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.83
 ---- batch: 020 ----
mean loss: 147.35
 ---- batch: 030 ----
mean loss: 149.57
train mean loss: 148.52
epoch train time: 0:00:06.681042
elapsed time: 0:05:17.565717
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 06:16:43.576161
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.31
 ---- batch: 020 ----
mean loss: 147.89
 ---- batch: 030 ----
mean loss: 148.14
train mean loss: 147.67
epoch train time: 0:00:06.805410
elapsed time: 0:05:24.371902
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 06:16:50.382360
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 149.44
 ---- batch: 020 ----
mean loss: 147.20
 ---- batch: 030 ----
mean loss: 146.75
train mean loss: 147.60
epoch train time: 0:00:06.733800
elapsed time: 0:05:31.106522
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 06:16:57.117018
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 143.98
 ---- batch: 020 ----
mean loss: 144.21
 ---- batch: 030 ----
mean loss: 145.41
train mean loss: 144.69
epoch train time: 0:00:06.794647
elapsed time: 0:05:37.902019
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 06:17:03.912482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.42
 ---- batch: 020 ----
mean loss: 141.53
 ---- batch: 030 ----
mean loss: 144.13
train mean loss: 141.39
epoch train time: 0:00:06.661354
elapsed time: 0:05:44.564203
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 06:17:10.574705
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.38
 ---- batch: 020 ----
mean loss: 144.03
 ---- batch: 030 ----
mean loss: 145.59
train mean loss: 143.77
epoch train time: 0:00:06.718120
elapsed time: 0:05:51.283183
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 06:17:17.293685
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 141.39
 ---- batch: 020 ----
mean loss: 138.67
 ---- batch: 030 ----
mean loss: 137.67
train mean loss: 139.07
epoch train time: 0:00:06.680537
elapsed time: 0:05:57.964550
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 06:17:23.974991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.32
 ---- batch: 020 ----
mean loss: 143.40
 ---- batch: 030 ----
mean loss: 142.06
train mean loss: 140.36
epoch train time: 0:00:06.649131
elapsed time: 0:06:04.614447
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 06:17:30.624879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 138.64
 ---- batch: 020 ----
mean loss: 140.26
 ---- batch: 030 ----
mean loss: 136.70
train mean loss: 137.82
epoch train time: 0:00:06.834403
elapsed time: 0:06:11.449602
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 06:17:37.460066
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.96
 ---- batch: 020 ----
mean loss: 139.16
 ---- batch: 030 ----
mean loss: 135.32
train mean loss: 137.89
epoch train time: 0:00:06.788794
elapsed time: 0:06:18.239173
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 06:17:44.249651
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 136.55
 ---- batch: 020 ----
mean loss: 133.54
 ---- batch: 030 ----
mean loss: 137.32
train mean loss: 134.02
epoch train time: 0:00:06.904315
elapsed time: 0:06:25.144260
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 06:17:51.154693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.69
 ---- batch: 020 ----
mean loss: 135.48
 ---- batch: 030 ----
mean loss: 136.09
train mean loss: 135.40
epoch train time: 0:00:06.758712
elapsed time: 0:06:31.903727
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 06:17:57.914191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 133.35
 ---- batch: 020 ----
mean loss: 131.77
 ---- batch: 030 ----
mean loss: 135.13
train mean loss: 134.27
epoch train time: 0:00:06.862365
elapsed time: 0:06:38.766886
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 06:18:04.777310
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.81
 ---- batch: 020 ----
mean loss: 135.95
 ---- batch: 030 ----
mean loss: 133.28
train mean loss: 132.69
epoch train time: 0:00:06.772245
elapsed time: 0:06:45.539898
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 06:18:11.550355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 126.87
 ---- batch: 020 ----
mean loss: 133.13
 ---- batch: 030 ----
mean loss: 132.33
train mean loss: 130.73
epoch train time: 0:00:06.876206
elapsed time: 0:06:52.416870
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 06:18:18.427312
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 135.50
 ---- batch: 020 ----
mean loss: 127.35
 ---- batch: 030 ----
mean loss: 127.41
train mean loss: 131.07
epoch train time: 0:00:06.815553
elapsed time: 0:06:59.233175
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 06:18:25.243601
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.63
 ---- batch: 020 ----
mean loss: 126.98
 ---- batch: 030 ----
mean loss: 131.20
train mean loss: 129.86
epoch train time: 0:00:06.878566
elapsed time: 0:07:06.112538
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 06:18:32.122990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.88
 ---- batch: 020 ----
mean loss: 125.39
 ---- batch: 030 ----
mean loss: 129.69
train mean loss: 126.17
epoch train time: 0:00:06.900548
elapsed time: 0:07:13.013846
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 06:18:39.024273
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.66
 ---- batch: 020 ----
mean loss: 125.79
 ---- batch: 030 ----
mean loss: 121.59
train mean loss: 125.61
epoch train time: 0:00:06.842619
elapsed time: 0:07:19.857209
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 06:18:45.867677
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.43
 ---- batch: 020 ----
mean loss: 129.60
 ---- batch: 030 ----
mean loss: 128.21
train mean loss: 126.20
epoch train time: 0:00:06.886955
elapsed time: 0:07:26.744947
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 06:18:52.755399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 130.88
 ---- batch: 020 ----
mean loss: 123.51
 ---- batch: 030 ----
mean loss: 121.59
train mean loss: 126.34
epoch train time: 0:00:06.790567
elapsed time: 0:07:33.536260
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 06:18:59.546690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 124.45
 ---- batch: 020 ----
mean loss: 123.63
 ---- batch: 030 ----
mean loss: 125.05
train mean loss: 125.18
epoch train time: 0:00:06.853155
elapsed time: 0:07:40.390180
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 06:19:06.400644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.04
 ---- batch: 020 ----
mean loss: 126.29
 ---- batch: 030 ----
mean loss: 124.08
train mean loss: 126.30
epoch train time: 0:00:06.795928
elapsed time: 0:07:47.186876
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 06:19:13.197295
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 122.85
 ---- batch: 020 ----
mean loss: 124.46
 ---- batch: 030 ----
mean loss: 129.24
train mean loss: 125.71
epoch train time: 0:00:06.831912
elapsed time: 0:07:54.019588
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 06:19:20.030025
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.03
 ---- batch: 020 ----
mean loss: 119.96
 ---- batch: 030 ----
mean loss: 117.79
train mean loss: 122.79
epoch train time: 0:00:06.888308
elapsed time: 0:08:00.908732
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 06:19:26.919181
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.90
 ---- batch: 020 ----
mean loss: 119.25
 ---- batch: 030 ----
mean loss: 120.18
train mean loss: 120.84
epoch train time: 0:00:06.843724
elapsed time: 0:08:07.753178
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 06:19:33.763616
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.36
 ---- batch: 020 ----
mean loss: 119.47
 ---- batch: 030 ----
mean loss: 124.15
train mean loss: 121.34
epoch train time: 0:00:06.757604
elapsed time: 0:08:14.511594
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 06:19:40.522024
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.40
 ---- batch: 020 ----
mean loss: 117.61
 ---- batch: 030 ----
mean loss: 117.33
train mean loss: 119.60
epoch train time: 0:00:06.828221
elapsed time: 0:08:21.340623
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 06:19:47.351142
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.81
 ---- batch: 020 ----
mean loss: 119.06
 ---- batch: 030 ----
mean loss: 120.30
train mean loss: 119.73
epoch train time: 0:00:06.807787
elapsed time: 0:08:28.149314
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 06:19:54.159775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.70
 ---- batch: 020 ----
mean loss: 123.17
 ---- batch: 030 ----
mean loss: 121.03
train mean loss: 119.74
epoch train time: 0:00:06.818863
elapsed time: 0:08:34.968918
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 06:20:00.979370
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.49
 ---- batch: 020 ----
mean loss: 120.42
 ---- batch: 030 ----
mean loss: 120.13
train mean loss: 118.48
epoch train time: 0:00:06.770978
elapsed time: 0:08:41.740641
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 06:20:07.751076
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 115.29
 ---- batch: 020 ----
mean loss: 119.68
 ---- batch: 030 ----
mean loss: 119.84
train mean loss: 118.44
epoch train time: 0:00:06.795684
elapsed time: 0:08:48.537098
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 06:20:14.547536
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.83
 ---- batch: 020 ----
mean loss: 116.90
 ---- batch: 030 ----
mean loss: 113.03
train mean loss: 116.83
epoch train time: 0:00:06.661473
elapsed time: 0:08:55.199453
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 06:20:21.209933
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 118.08
 ---- batch: 020 ----
mean loss: 113.52
 ---- batch: 030 ----
mean loss: 120.16
train mean loss: 116.93
epoch train time: 0:00:06.749440
elapsed time: 0:09:01.949682
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 06:20:27.960128
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 119.27
 ---- batch: 020 ----
mean loss: 115.76
 ---- batch: 030 ----
mean loss: 119.62
train mean loss: 118.71
epoch train time: 0:00:06.661061
elapsed time: 0:09:08.611498
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 06:20:34.621943
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 117.28
 ---- batch: 020 ----
mean loss: 117.40
 ---- batch: 030 ----
mean loss: 117.41
train mean loss: 116.08
epoch train time: 0:00:06.722671
elapsed time: 0:09:15.335042
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 06:20:41.345512
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 120.93
 ---- batch: 020 ----
mean loss: 115.72
 ---- batch: 030 ----
mean loss: 114.98
train mean loss: 117.61
epoch train time: 0:00:06.693866
elapsed time: 0:09:22.029852
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 06:20:48.040288
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.65
 ---- batch: 020 ----
mean loss: 117.08
 ---- batch: 030 ----
mean loss: 118.75
train mean loss: 115.37
epoch train time: 0:00:06.845119
elapsed time: 0:09:28.875791
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 06:20:54.886236
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.66
 ---- batch: 020 ----
mean loss: 112.94
 ---- batch: 030 ----
mean loss: 113.96
train mean loss: 113.44
epoch train time: 0:00:06.633436
elapsed time: 0:09:35.510049
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 06:21:01.520486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.34
 ---- batch: 020 ----
mean loss: 114.58
 ---- batch: 030 ----
mean loss: 117.45
train mean loss: 115.52
epoch train time: 0:00:06.662892
elapsed time: 0:09:42.173694
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 06:21:08.184130
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 113.98
 ---- batch: 020 ----
mean loss: 117.65
 ---- batch: 030 ----
mean loss: 114.87
train mean loss: 113.91
epoch train time: 0:00:06.837923
elapsed time: 0:09:49.012346
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 06:21:15.022780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.70
 ---- batch: 020 ----
mean loss: 113.00
 ---- batch: 030 ----
mean loss: 113.29
train mean loss: 113.99
epoch train time: 0:00:06.824793
elapsed time: 0:09:55.837877
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 06:21:21.848324
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.60
 ---- batch: 020 ----
mean loss: 111.75
 ---- batch: 030 ----
mean loss: 114.54
train mean loss: 113.05
epoch train time: 0:00:06.822850
elapsed time: 0:10:02.661557
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 06:21:28.671990
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 112.79
 ---- batch: 020 ----
mean loss: 113.28
 ---- batch: 030 ----
mean loss: 108.99
train mean loss: 112.85
epoch train time: 0:00:06.804051
elapsed time: 0:10:09.466348
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 06:21:35.476804
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.31
 ---- batch: 020 ----
mean loss: 110.08
 ---- batch: 030 ----
mean loss: 107.24
train mean loss: 110.78
epoch train time: 0:00:06.753089
elapsed time: 0:10:16.220229
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 06:21:42.230686
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.42
 ---- batch: 020 ----
mean loss: 108.96
 ---- batch: 030 ----
mean loss: 114.74
train mean loss: 112.41
epoch train time: 0:00:06.670477
elapsed time: 0:10:22.891551
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 06:21:48.902028
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.47
 ---- batch: 020 ----
mean loss: 110.86
 ---- batch: 030 ----
mean loss: 110.78
train mean loss: 112.00
epoch train time: 0:00:06.698920
elapsed time: 0:10:29.591264
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 06:21:55.601718
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.56
 ---- batch: 020 ----
mean loss: 111.11
 ---- batch: 030 ----
mean loss: 110.51
train mean loss: 110.62
epoch train time: 0:00:06.800179
elapsed time: 0:10:36.392209
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 06:22:02.402644
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.14
 ---- batch: 020 ----
mean loss: 108.70
 ---- batch: 030 ----
mean loss: 109.84
train mean loss: 109.35
epoch train time: 0:00:06.843641
elapsed time: 0:10:43.236597
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 06:22:09.247055
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.91
 ---- batch: 020 ----
mean loss: 107.38
 ---- batch: 030 ----
mean loss: 112.37
train mean loss: 110.38
epoch train time: 0:00:06.853819
elapsed time: 0:10:50.091253
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 06:22:16.101736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.98
 ---- batch: 020 ----
mean loss: 108.96
 ---- batch: 030 ----
mean loss: 109.52
train mean loss: 109.72
epoch train time: 0:00:06.726128
elapsed time: 0:10:56.818284
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 06:22:22.828764
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.59
 ---- batch: 020 ----
mean loss: 107.19
 ---- batch: 030 ----
mean loss: 112.55
train mean loss: 109.83
epoch train time: 0:00:06.869614
elapsed time: 0:11:03.688794
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 06:22:29.699238
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.91
 ---- batch: 020 ----
mean loss: 108.57
 ---- batch: 030 ----
mean loss: 111.38
train mean loss: 108.64
epoch train time: 0:00:06.818560
elapsed time: 0:11:10.508098
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 06:22:36.518544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.10
 ---- batch: 020 ----
mean loss: 109.35
 ---- batch: 030 ----
mean loss: 109.09
train mean loss: 107.96
epoch train time: 0:00:06.838145
elapsed time: 0:11:17.347042
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 06:22:43.357490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.39
 ---- batch: 020 ----
mean loss: 110.37
 ---- batch: 030 ----
mean loss: 107.66
train mean loss: 109.22
epoch train time: 0:00:06.765858
elapsed time: 0:11:24.113667
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 06:22:50.124108
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 111.26
 ---- batch: 020 ----
mean loss: 108.23
 ---- batch: 030 ----
mean loss: 104.61
train mean loss: 108.73
epoch train time: 0:00:06.902933
elapsed time: 0:11:31.017412
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 06:22:57.027857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.70
 ---- batch: 020 ----
mean loss: 105.35
 ---- batch: 030 ----
mean loss: 103.21
train mean loss: 106.48
epoch train time: 0:00:06.822436
elapsed time: 0:11:37.840650
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 06:23:03.851102
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.97
 ---- batch: 020 ----
mean loss: 103.79
 ---- batch: 030 ----
mean loss: 108.18
train mean loss: 106.27
epoch train time: 0:00:06.829043
elapsed time: 0:11:44.670517
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 06:23:10.680985
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.23
 ---- batch: 020 ----
mean loss: 108.35
 ---- batch: 030 ----
mean loss: 106.25
train mean loss: 105.79
epoch train time: 0:00:06.900676
elapsed time: 0:11:51.572061
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 06:23:17.582513
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.06
 ---- batch: 020 ----
mean loss: 107.14
 ---- batch: 030 ----
mean loss: 106.16
train mean loss: 105.79
epoch train time: 0:00:06.824301
elapsed time: 0:11:58.397172
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 06:23:24.407617
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.35
 ---- batch: 020 ----
mean loss: 105.46
 ---- batch: 030 ----
mean loss: 103.31
train mean loss: 105.47
epoch train time: 0:00:06.876313
elapsed time: 0:12:05.274267
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 06:23:31.284690
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.71
 ---- batch: 020 ----
mean loss: 105.41
 ---- batch: 030 ----
mean loss: 109.86
train mean loss: 106.44
epoch train time: 0:00:06.776638
elapsed time: 0:12:12.051714
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 06:23:38.062164
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.60
 ---- batch: 020 ----
mean loss: 107.04
 ---- batch: 030 ----
mean loss: 105.25
train mean loss: 106.21
epoch train time: 0:00:06.833369
elapsed time: 0:12:18.885928
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 06:23:44.896292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.55
 ---- batch: 020 ----
mean loss: 105.95
 ---- batch: 030 ----
mean loss: 106.11
train mean loss: 103.93
epoch train time: 0:00:06.889083
elapsed time: 0:12:25.775758
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 06:23:51.786200
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 108.09
 ---- batch: 020 ----
mean loss: 105.99
 ---- batch: 030 ----
mean loss: 102.51
train mean loss: 105.25
epoch train time: 0:00:06.779947
elapsed time: 0:12:32.556484
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 06:23:58.566914
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.34
 ---- batch: 020 ----
mean loss: 105.30
 ---- batch: 030 ----
mean loss: 103.97
train mean loss: 105.42
epoch train time: 0:00:06.829550
elapsed time: 0:12:39.386772
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 06:24:05.397227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.45
 ---- batch: 020 ----
mean loss: 103.22
 ---- batch: 030 ----
mean loss: 107.30
train mean loss: 104.72
epoch train time: 0:00:06.697730
elapsed time: 0:12:46.085279
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 06:24:12.095720
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.71
 ---- batch: 020 ----
mean loss: 104.73
 ---- batch: 030 ----
mean loss: 102.86
train mean loss: 105.45
epoch train time: 0:00:06.839813
elapsed time: 0:12:52.925856
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 06:24:18.936284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.94
 ---- batch: 020 ----
mean loss: 102.73
 ---- batch: 030 ----
mean loss: 100.86
train mean loss: 103.79
epoch train time: 0:00:06.711738
elapsed time: 0:12:59.638322
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 06:24:25.648752
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 106.66
 ---- batch: 020 ----
mean loss: 101.73
 ---- batch: 030 ----
mean loss: 103.20
train mean loss: 103.67
epoch train time: 0:00:06.793115
elapsed time: 0:13:06.432167
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 06:24:32.442599
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.08
 ---- batch: 020 ----
mean loss: 101.27
 ---- batch: 030 ----
mean loss: 103.23
train mean loss: 103.68
epoch train time: 0:00:06.655166
elapsed time: 0:13:13.088056
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 06:24:39.098518
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.13
 ---- batch: 020 ----
mean loss: 101.50
 ---- batch: 030 ----
mean loss: 103.90
train mean loss: 103.09
epoch train time: 0:00:06.720755
elapsed time: 0:13:19.809583
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 06:24:45.820021
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.16
 ---- batch: 020 ----
mean loss: 102.61
 ---- batch: 030 ----
mean loss: 105.98
train mean loss: 103.91
epoch train time: 0:00:06.757451
elapsed time: 0:13:26.567809
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 06:24:52.578243
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.01
 ---- batch: 020 ----
mean loss: 103.19
 ---- batch: 030 ----
mean loss: 104.05
train mean loss: 102.67
epoch train time: 0:00:06.756723
elapsed time: 0:13:33.325305
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 06:24:59.335743
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.44
 ---- batch: 020 ----
mean loss: 101.61
 ---- batch: 030 ----
mean loss: 101.78
train mean loss: 102.57
epoch train time: 0:00:06.807059
elapsed time: 0:13:40.133221
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 06:25:06.143746
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 105.74
 ---- batch: 020 ----
mean loss: 103.23
 ---- batch: 030 ----
mean loss: 106.89
train mean loss: 104.13
epoch train time: 0:00:06.705394
elapsed time: 0:13:46.839498
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 06:25:12.849968
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.30
 ---- batch: 020 ----
mean loss: 103.69
 ---- batch: 030 ----
mean loss: 98.94
train mean loss: 102.75
epoch train time: 0:00:06.684887
elapsed time: 0:13:53.525162
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 06:25:19.535602
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.58
 ---- batch: 020 ----
mean loss: 101.30
 ---- batch: 030 ----
mean loss: 104.64
train mean loss: 101.68
epoch train time: 0:00:06.722063
elapsed time: 0:14:00.247985
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 06:25:26.258414
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.66
 ---- batch: 020 ----
mean loss: 102.58
 ---- batch: 030 ----
mean loss: 102.89
train mean loss: 101.78
epoch train time: 0:00:06.745004
elapsed time: 0:14:06.993727
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 06:25:33.004178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.59
 ---- batch: 020 ----
mean loss: 99.55
 ---- batch: 030 ----
mean loss: 102.70
train mean loss: 101.82
epoch train time: 0:00:06.757405
elapsed time: 0:14:13.751969
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 06:25:39.762406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.42
 ---- batch: 020 ----
mean loss: 98.44
 ---- batch: 030 ----
mean loss: 102.27
train mean loss: 101.74
epoch train time: 0:00:06.707782
elapsed time: 0:14:20.460497
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 06:25:46.470927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 104.00
 ---- batch: 020 ----
mean loss: 99.09
 ---- batch: 030 ----
mean loss: 98.88
train mean loss: 101.08
epoch train time: 0:00:06.844190
elapsed time: 0:14:27.305590
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 06:25:53.316033
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.91
 ---- batch: 020 ----
mean loss: 101.84
 ---- batch: 030 ----
mean loss: 100.27
train mean loss: 100.42
epoch train time: 0:00:06.741679
elapsed time: 0:14:34.048137
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 06:26:00.058487
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.57
 ---- batch: 020 ----
mean loss: 98.96
 ---- batch: 030 ----
mean loss: 105.51
train mean loss: 100.72
epoch train time: 0:00:06.829609
elapsed time: 0:14:40.878436
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 06:26:06.888875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.06
 ---- batch: 020 ----
mean loss: 98.81
 ---- batch: 030 ----
mean loss: 99.01
train mean loss: 100.08
epoch train time: 0:00:06.766527
elapsed time: 0:14:47.645721
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 06:26:13.656190
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.13
 ---- batch: 020 ----
mean loss: 100.63
 ---- batch: 030 ----
mean loss: 99.54
train mean loss: 100.51
epoch train time: 0:00:06.805635
elapsed time: 0:14:54.452170
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 06:26:20.462627
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.47
 ---- batch: 020 ----
mean loss: 97.61
 ---- batch: 030 ----
mean loss: 98.89
train mean loss: 99.49
epoch train time: 0:00:06.858274
elapsed time: 0:15:01.311265
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 06:26:27.321801
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.45
 ---- batch: 020 ----
mean loss: 97.46
 ---- batch: 030 ----
mean loss: 101.32
train mean loss: 98.52
epoch train time: 0:00:06.663955
elapsed time: 0:15:07.976057
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 06:26:33.986488
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.83
 ---- batch: 020 ----
mean loss: 100.84
 ---- batch: 030 ----
mean loss: 97.42
train mean loss: 99.67
epoch train time: 0:00:06.770575
elapsed time: 0:15:14.747504
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 06:26:40.757972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.59
 ---- batch: 020 ----
mean loss: 100.63
 ---- batch: 030 ----
mean loss: 99.99
train mean loss: 99.86
epoch train time: 0:00:06.737439
elapsed time: 0:15:21.485738
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 06:26:47.496191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.42
 ---- batch: 020 ----
mean loss: 98.11
 ---- batch: 030 ----
mean loss: 98.69
train mean loss: 97.71
epoch train time: 0:00:06.797145
elapsed time: 0:15:28.283763
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 06:26:54.294222
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.59
 ---- batch: 020 ----
mean loss: 94.00
 ---- batch: 030 ----
mean loss: 100.32
train mean loss: 97.32
epoch train time: 0:00:06.812745
elapsed time: 0:15:35.097343
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 06:27:01.107794
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.13
 ---- batch: 020 ----
mean loss: 99.54
 ---- batch: 030 ----
mean loss: 97.73
train mean loss: 98.65
epoch train time: 0:00:06.702661
elapsed time: 0:15:41.800834
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 06:27:07.811271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.35
 ---- batch: 020 ----
mean loss: 99.39
 ---- batch: 030 ----
mean loss: 97.33
train mean loss: 97.82
epoch train time: 0:00:06.758487
elapsed time: 0:15:48.560086
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 06:27:14.570528
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.22
 ---- batch: 020 ----
mean loss: 103.29
 ---- batch: 030 ----
mean loss: 95.22
train mean loss: 98.65
epoch train time: 0:00:06.799889
elapsed time: 0:15:55.360647
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 06:27:21.371071
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.10
 ---- batch: 020 ----
mean loss: 97.97
 ---- batch: 030 ----
mean loss: 96.07
train mean loss: 97.43
epoch train time: 0:00:06.665402
elapsed time: 0:16:02.026795
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 06:27:28.037240
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 101.98
 ---- batch: 020 ----
mean loss: 96.31
 ---- batch: 030 ----
mean loss: 99.92
train mean loss: 99.05
epoch train time: 0:00:06.778773
elapsed time: 0:16:08.806378
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 06:27:34.816825
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.49
 ---- batch: 020 ----
mean loss: 100.79
 ---- batch: 030 ----
mean loss: 98.92
train mean loss: 100.15
epoch train time: 0:00:06.726648
elapsed time: 0:16:15.533785
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 06:27:41.544223
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 98.20
 ---- batch: 020 ----
mean loss: 96.18
 ---- batch: 030 ----
mean loss: 98.96
train mean loss: 96.56
epoch train time: 0:00:06.772783
elapsed time: 0:16:22.307315
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 06:27:48.317812
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.73
 ---- batch: 020 ----
mean loss: 96.76
 ---- batch: 030 ----
mean loss: 98.10
train mean loss: 96.35
epoch train time: 0:00:06.907191
elapsed time: 0:16:29.215370
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 06:27:55.225821
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.24
 ---- batch: 020 ----
mean loss: 95.08
 ---- batch: 030 ----
mean loss: 95.92
train mean loss: 95.59
epoch train time: 0:00:06.758228
elapsed time: 0:16:35.974400
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 06:28:01.984858
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.57
 ---- batch: 020 ----
mean loss: 99.47
 ---- batch: 030 ----
mean loss: 93.86
train mean loss: 96.69
epoch train time: 0:00:06.883386
elapsed time: 0:16:42.858551
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 06:28:08.868986
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.30
 ---- batch: 020 ----
mean loss: 97.97
 ---- batch: 030 ----
mean loss: 95.90
train mean loss: 96.34
epoch train time: 0:00:06.845694
elapsed time: 0:16:49.705006
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 06:28:15.715492
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.63
 ---- batch: 020 ----
mean loss: 95.27
 ---- batch: 030 ----
mean loss: 94.87
train mean loss: 95.79
epoch train time: 0:00:06.784706
elapsed time: 0:16:56.490496
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 06:28:22.500948
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.29
 ---- batch: 020 ----
mean loss: 96.53
 ---- batch: 030 ----
mean loss: 95.52
train mean loss: 95.78
epoch train time: 0:00:06.802543
elapsed time: 0:17:03.293935
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 06:28:29.304274
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.21
 ---- batch: 020 ----
mean loss: 94.47
 ---- batch: 030 ----
mean loss: 96.83
train mean loss: 95.82
epoch train time: 0:00:06.729451
elapsed time: 0:17:10.024041
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 06:28:36.034464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.96
 ---- batch: 020 ----
mean loss: 97.08
 ---- batch: 030 ----
mean loss: 97.87
train mean loss: 95.83
epoch train time: 0:00:06.836017
elapsed time: 0:17:16.860904
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 06:28:42.871361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.73
 ---- batch: 020 ----
mean loss: 94.46
 ---- batch: 030 ----
mean loss: 99.26
train mean loss: 96.24
epoch train time: 0:00:06.755308
elapsed time: 0:17:23.616991
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 06:28:49.627447
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.26
 ---- batch: 020 ----
mean loss: 95.97
 ---- batch: 030 ----
mean loss: 91.35
train mean loss: 95.11
epoch train time: 0:00:06.924384
elapsed time: 0:17:30.542166
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 06:28:56.552605
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.75
 ---- batch: 020 ----
mean loss: 94.58
 ---- batch: 030 ----
mean loss: 96.59
train mean loss: 94.69
epoch train time: 0:00:06.743100
elapsed time: 0:17:37.286117
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 06:29:03.296556
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.23
 ---- batch: 020 ----
mean loss: 95.13
 ---- batch: 030 ----
mean loss: 94.00
train mean loss: 94.83
epoch train time: 0:00:06.777005
elapsed time: 0:17:44.063963
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 06:29:10.074418
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.74
 ---- batch: 020 ----
mean loss: 95.39
 ---- batch: 030 ----
mean loss: 95.33
train mean loss: 94.41
epoch train time: 0:00:06.665137
elapsed time: 0:17:50.729936
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 06:29:16.740391
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.44
 ---- batch: 020 ----
mean loss: 93.84
 ---- batch: 030 ----
mean loss: 94.17
train mean loss: 94.92
epoch train time: 0:00:06.789397
elapsed time: 0:17:57.520197
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 06:29:23.530626
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 96.01
 ---- batch: 020 ----
mean loss: 94.33
 ---- batch: 030 ----
mean loss: 95.21
train mean loss: 94.42
epoch train time: 0:00:06.691183
elapsed time: 0:18:04.212142
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 06:29:30.222579
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.56
 ---- batch: 020 ----
mean loss: 96.68
 ---- batch: 030 ----
mean loss: 94.29
train mean loss: 94.16
epoch train time: 0:00:06.779440
elapsed time: 0:18:10.992489
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 06:29:37.002939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.91
 ---- batch: 020 ----
mean loss: 93.05
 ---- batch: 030 ----
mean loss: 92.54
train mean loss: 94.13
epoch train time: 0:00:06.936127
elapsed time: 0:18:17.929421
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 06:29:43.939855
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.38
 ---- batch: 020 ----
mean loss: 92.23
 ---- batch: 030 ----
mean loss: 96.69
train mean loss: 95.02
epoch train time: 0:00:06.948596
elapsed time: 0:18:24.878767
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 06:29:50.889231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 97.18
 ---- batch: 020 ----
mean loss: 93.02
 ---- batch: 030 ----
mean loss: 94.49
train mean loss: 94.96
epoch train time: 0:00:06.753213
elapsed time: 0:18:31.632787
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 06:29:57.643213
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.93
 ---- batch: 020 ----
mean loss: 96.71
 ---- batch: 030 ----
mean loss: 95.03
train mean loss: 94.11
epoch train time: 0:00:06.849749
elapsed time: 0:18:38.483266
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 06:30:04.493734
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.74
 ---- batch: 020 ----
mean loss: 94.25
 ---- batch: 030 ----
mean loss: 91.68
train mean loss: 93.59
epoch train time: 0:00:06.731308
elapsed time: 0:18:45.215454
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 06:30:11.225890
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.36
 ---- batch: 020 ----
mean loss: 91.33
 ---- batch: 030 ----
mean loss: 89.77
train mean loss: 91.62
epoch train time: 0:00:06.853421
elapsed time: 0:18:52.069630
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 06:30:18.080083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.92
 ---- batch: 020 ----
mean loss: 91.70
 ---- batch: 030 ----
mean loss: 96.06
train mean loss: 93.42
epoch train time: 0:00:06.765790
elapsed time: 0:18:58.836245
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 06:30:24.846678
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.98
 ---- batch: 020 ----
mean loss: 93.12
 ---- batch: 030 ----
mean loss: 91.61
train mean loss: 93.19
epoch train time: 0:00:06.813749
elapsed time: 0:19:05.650802
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 06:30:31.661284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.96
 ---- batch: 020 ----
mean loss: 90.08
 ---- batch: 030 ----
mean loss: 93.26
train mean loss: 92.54
epoch train time: 0:00:06.892930
elapsed time: 0:19:12.544500
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 06:30:38.554941
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.42
 ---- batch: 020 ----
mean loss: 90.19
 ---- batch: 030 ----
mean loss: 90.10
train mean loss: 92.02
epoch train time: 0:00:06.723904
elapsed time: 0:19:19.269265
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 06:30:45.279712
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.16
 ---- batch: 020 ----
mean loss: 93.85
 ---- batch: 030 ----
mean loss: 91.11
train mean loss: 92.97
epoch train time: 0:00:06.840859
elapsed time: 0:19:26.110867
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 06:30:52.121297
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.62
 ---- batch: 020 ----
mean loss: 92.58
 ---- batch: 030 ----
mean loss: 90.06
train mean loss: 91.81
epoch train time: 0:00:06.800059
elapsed time: 0:19:32.911783
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 06:30:58.922231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 95.17
 ---- batch: 020 ----
mean loss: 92.04
 ---- batch: 030 ----
mean loss: 91.58
train mean loss: 93.07
epoch train time: 0:00:06.750476
elapsed time: 0:19:39.663063
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 06:31:05.673540
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 93.93
 ---- batch: 020 ----
mean loss: 89.48
 ---- batch: 030 ----
mean loss: 91.13
train mean loss: 91.64
epoch train time: 0:00:06.850678
elapsed time: 0:19:46.514509
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 06:31:12.524976
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.00
 ---- batch: 020 ----
mean loss: 93.42
 ---- batch: 030 ----
mean loss: 91.00
train mean loss: 92.01
epoch train time: 0:00:06.850287
elapsed time: 0:19:53.365692
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 06:31:19.376041
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.83
 ---- batch: 020 ----
mean loss: 90.73
 ---- batch: 030 ----
mean loss: 93.01
train mean loss: 90.67
epoch train time: 0:00:06.799277
elapsed time: 0:20:00.165704
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 06:31:26.176158
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.82
 ---- batch: 020 ----
mean loss: 91.83
 ---- batch: 030 ----
mean loss: 91.35
train mean loss: 91.97
epoch train time: 0:00:06.835819
elapsed time: 0:20:07.002456
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 06:31:33.012912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.66
 ---- batch: 020 ----
mean loss: 90.40
 ---- batch: 030 ----
mean loss: 93.01
train mean loss: 90.92
epoch train time: 0:00:06.746190
elapsed time: 0:20:13.749389
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 06:31:39.759837
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.40
 ---- batch: 020 ----
mean loss: 90.41
 ---- batch: 030 ----
mean loss: 93.14
train mean loss: 92.00
epoch train time: 0:00:06.833212
elapsed time: 0:20:20.583448
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 06:31:46.593915
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.39
 ---- batch: 020 ----
mean loss: 92.81
 ---- batch: 030 ----
mean loss: 87.82
train mean loss: 90.32
epoch train time: 0:00:06.881632
elapsed time: 0:20:27.465907
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 06:31:53.476352
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.04
 ---- batch: 020 ----
mean loss: 88.77
 ---- batch: 030 ----
mean loss: 90.60
train mean loss: 90.30
epoch train time: 0:00:06.809070
elapsed time: 0:20:34.275820
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 06:32:00.286260
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.83
 ---- batch: 020 ----
mean loss: 92.27
 ---- batch: 030 ----
mean loss: 91.04
train mean loss: 90.55
epoch train time: 0:00:06.895840
elapsed time: 0:20:41.172595
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 06:32:07.183043
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.48
 ---- batch: 020 ----
mean loss: 91.93
 ---- batch: 030 ----
mean loss: 91.46
train mean loss: 90.19
epoch train time: 0:00:06.725070
elapsed time: 0:20:47.898466
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 06:32:13.908902
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.75
 ---- batch: 020 ----
mean loss: 88.64
 ---- batch: 030 ----
mean loss: 90.68
train mean loss: 89.48
epoch train time: 0:00:06.892599
elapsed time: 0:20:54.791922
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 06:32:20.802384
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.94
 ---- batch: 020 ----
mean loss: 90.45
 ---- batch: 030 ----
mean loss: 90.60
train mean loss: 90.27
epoch train time: 0:00:06.780724
elapsed time: 0:21:01.573476
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 06:32:27.583939
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.35
 ---- batch: 020 ----
mean loss: 89.49
 ---- batch: 030 ----
mean loss: 91.08
train mean loss: 90.41
epoch train time: 0:00:06.888360
elapsed time: 0:21:08.462628
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 06:32:34.473061
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 91.98
 ---- batch: 020 ----
mean loss: 91.92
 ---- batch: 030 ----
mean loss: 84.82
train mean loss: 90.41
epoch train time: 0:00:06.778990
elapsed time: 0:21:15.242353
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 06:32:41.252790
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.13
 ---- batch: 020 ----
mean loss: 91.42
 ---- batch: 030 ----
mean loss: 87.28
train mean loss: 90.24
epoch train time: 0:00:06.865172
elapsed time: 0:21:22.108304
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 06:32:48.118750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.95
 ---- batch: 020 ----
mean loss: 89.72
 ---- batch: 030 ----
mean loss: 91.91
train mean loss: 88.69
epoch train time: 0:00:06.802370
elapsed time: 0:21:28.911498
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 06:32:54.921940
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.74
 ---- batch: 020 ----
mean loss: 86.77
 ---- batch: 030 ----
mean loss: 90.20
train mean loss: 88.49
epoch train time: 0:00:06.858068
elapsed time: 0:21:35.770396
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 06:33:01.780872
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.53
 ---- batch: 020 ----
mean loss: 88.69
 ---- batch: 030 ----
mean loss: 90.89
train mean loss: 88.92
epoch train time: 0:00:06.783007
elapsed time: 0:21:42.554192
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 06:33:08.564623
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.23
 ---- batch: 020 ----
mean loss: 87.00
 ---- batch: 030 ----
mean loss: 88.25
train mean loss: 88.73
epoch train time: 0:00:06.810793
elapsed time: 0:21:49.365850
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 06:33:15.376292
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.87
 ---- batch: 020 ----
mean loss: 89.45
 ---- batch: 030 ----
mean loss: 87.80
train mean loss: 89.30
epoch train time: 0:00:06.880114
elapsed time: 0:21:56.246686
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 06:33:22.257146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.23
 ---- batch: 020 ----
mean loss: 86.94
 ---- batch: 030 ----
mean loss: 91.86
train mean loss: 88.70
epoch train time: 0:00:06.780770
elapsed time: 0:22:03.028224
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 06:33:29.038668
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 89.94
 ---- batch: 020 ----
mean loss: 90.83
 ---- batch: 030 ----
mean loss: 87.84
train mean loss: 89.56
epoch train time: 0:00:06.863380
elapsed time: 0:22:09.892437
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 06:33:35.902884
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.78
 ---- batch: 020 ----
mean loss: 90.49
 ---- batch: 030 ----
mean loss: 87.91
train mean loss: 88.68
epoch train time: 0:00:06.800729
elapsed time: 0:22:16.693971
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 06:33:42.704446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.65
 ---- batch: 020 ----
mean loss: 93.74
 ---- batch: 030 ----
mean loss: 88.71
train mean loss: 89.87
epoch train time: 0:00:06.893353
elapsed time: 0:22:23.588135
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 06:33:49.598580
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.06
 ---- batch: 020 ----
mean loss: 90.36
 ---- batch: 030 ----
mean loss: 84.90
train mean loss: 87.99
epoch train time: 0:00:06.838491
elapsed time: 0:22:30.427461
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 06:33:56.437995
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.27
 ---- batch: 020 ----
mean loss: 87.70
 ---- batch: 030 ----
mean loss: 87.98
train mean loss: 87.65
epoch train time: 0:00:06.845974
elapsed time: 0:22:37.274279
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 06:34:03.284714
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.24
 ---- batch: 020 ----
mean loss: 86.85
 ---- batch: 030 ----
mean loss: 89.43
train mean loss: 87.86
epoch train time: 0:00:06.801565
elapsed time: 0:22:44.076593
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 06:34:10.087045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 88.28
 ---- batch: 020 ----
mean loss: 87.43
 ---- batch: 030 ----
mean loss: 89.25
train mean loss: 88.23
epoch train time: 0:00:06.882692
elapsed time: 0:22:50.960130
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 06:34:16.970612
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.39
 ---- batch: 020 ----
mean loss: 89.74
 ---- batch: 030 ----
mean loss: 90.40
train mean loss: 88.73
epoch train time: 0:00:06.718078
elapsed time: 0:22:57.679066
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 06:34:23.689502
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.02
 ---- batch: 020 ----
mean loss: 86.15
 ---- batch: 030 ----
mean loss: 88.74
train mean loss: 86.81
epoch train time: 0:00:06.922576
elapsed time: 0:23:04.602590
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 06:34:30.612971
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.08
 ---- batch: 020 ----
mean loss: 86.46
 ---- batch: 030 ----
mean loss: 86.41
train mean loss: 86.21
epoch train time: 0:00:06.918173
elapsed time: 0:23:11.521521
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 06:34:37.531951
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.33
 ---- batch: 020 ----
mean loss: 86.00
 ---- batch: 030 ----
mean loss: 86.61
train mean loss: 86.18
epoch train time: 0:00:06.971417
elapsed time: 0:23:18.493742
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 06:34:44.504183
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.24
 ---- batch: 020 ----
mean loss: 84.51
 ---- batch: 030 ----
mean loss: 87.11
train mean loss: 86.59
epoch train time: 0:00:06.919171
elapsed time: 0:23:25.413746
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 06:34:51.424187
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.24
 ---- batch: 020 ----
mean loss: 85.62
 ---- batch: 030 ----
mean loss: 85.60
train mean loss: 86.25
epoch train time: 0:00:06.917891
elapsed time: 0:23:32.332520
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 06:34:58.343022
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.32
 ---- batch: 020 ----
mean loss: 87.89
 ---- batch: 030 ----
mean loss: 83.67
train mean loss: 86.50
epoch train time: 0:00:06.980314
elapsed time: 0:23:39.313662
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 06:35:05.324103
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.39
 ---- batch: 020 ----
mean loss: 85.39
 ---- batch: 030 ----
mean loss: 86.36
train mean loss: 86.39
epoch train time: 0:00:06.936595
elapsed time: 0:23:46.251013
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 06:35:12.261452
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.51
 ---- batch: 020 ----
mean loss: 82.38
 ---- batch: 030 ----
mean loss: 87.16
train mean loss: 86.49
epoch train time: 0:00:06.875075
elapsed time: 0:23:53.126850
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 06:35:19.137297
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.65
 ---- batch: 020 ----
mean loss: 86.89
 ---- batch: 030 ----
mean loss: 85.17
train mean loss: 86.48
epoch train time: 0:00:06.998536
elapsed time: 0:24:00.126232
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 06:35:26.136663
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.07
 ---- batch: 020 ----
mean loss: 84.90
 ---- batch: 030 ----
mean loss: 87.39
train mean loss: 86.28
epoch train time: 0:00:06.852266
elapsed time: 0:24:06.979224
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 06:35:32.989669
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.66
 ---- batch: 020 ----
mean loss: 86.63
 ---- batch: 030 ----
mean loss: 85.01
train mean loss: 86.66
epoch train time: 0:00:06.979045
elapsed time: 0:24:13.959106
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 06:35:39.969551
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 84.46
 ---- batch: 020 ----
mean loss: 88.91
 ---- batch: 030 ----
mean loss: 85.93
train mean loss: 85.94
epoch train time: 0:00:06.855490
elapsed time: 0:24:20.815391
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 06:35:46.825852
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.72
 ---- batch: 020 ----
mean loss: 84.40
 ---- batch: 030 ----
mean loss: 87.36
train mean loss: 87.01
epoch train time: 0:00:06.976080
elapsed time: 0:24:27.792397
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 06:35:53.802846
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.41
 ---- batch: 020 ----
mean loss: 87.35
 ---- batch: 030 ----
mean loss: 84.50
train mean loss: 86.91
epoch train time: 0:00:06.891605
elapsed time: 0:24:34.684830
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 06:36:00.695284
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 88.09
 ---- batch: 020 ----
mean loss: 82.83
 ---- batch: 030 ----
mean loss: 90.45
train mean loss: 86.44
epoch train time: 0:00:06.929269
elapsed time: 0:24:41.614918
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 06:36:07.625427
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.03
 ---- batch: 020 ----
mean loss: 88.42
 ---- batch: 030 ----
mean loss: 84.68
train mean loss: 86.52
epoch train time: 0:00:06.973849
elapsed time: 0:24:48.589589
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 06:36:14.600055
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 84.16
 ---- batch: 020 ----
mean loss: 86.94
 ---- batch: 030 ----
mean loss: 88.71
train mean loss: 86.17
epoch train time: 0:00:06.920110
elapsed time: 0:24:55.510466
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 06:36:21.520898
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.41
 ---- batch: 020 ----
mean loss: 84.85
 ---- batch: 030 ----
mean loss: 84.00
train mean loss: 85.95
epoch train time: 0:00:06.990595
elapsed time: 0:25:02.501972
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 06:36:28.512403
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 83.43
 ---- batch: 020 ----
mean loss: 88.45
 ---- batch: 030 ----
mean loss: 86.80
train mean loss: 86.06
epoch train time: 0:00:06.963498
elapsed time: 0:25:09.466291
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 06:36:35.476728
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.73
 ---- batch: 020 ----
mean loss: 87.25
 ---- batch: 030 ----
mean loss: 87.97
train mean loss: 87.37
epoch train time: 0:00:06.908813
elapsed time: 0:25:16.376073
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 06:36:42.386509
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.09
 ---- batch: 020 ----
mean loss: 86.41
 ---- batch: 030 ----
mean loss: 85.75
train mean loss: 86.07
epoch train time: 0:00:06.942597
elapsed time: 0:25:23.319513
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 06:36:49.329980
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.44
 ---- batch: 020 ----
mean loss: 85.68
 ---- batch: 030 ----
mean loss: 84.31
train mean loss: 86.62
epoch train time: 0:00:06.951897
elapsed time: 0:25:30.272259
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 06:36:56.282691
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.36
 ---- batch: 020 ----
mean loss: 85.10
 ---- batch: 030 ----
mean loss: 88.88
train mean loss: 86.08
epoch train time: 0:00:06.919299
elapsed time: 0:25:37.192397
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 06:37:03.202862
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.35
 ---- batch: 020 ----
mean loss: 84.82
 ---- batch: 030 ----
mean loss: 84.95
train mean loss: 86.04
epoch train time: 0:00:06.922484
elapsed time: 0:25:44.115658
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 06:37:10.126173
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 84.01
 ---- batch: 020 ----
mean loss: 86.15
 ---- batch: 030 ----
mean loss: 87.64
train mean loss: 86.01
epoch train time: 0:00:06.929014
elapsed time: 0:25:51.045554
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 06:37:17.056046
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 82.66
 ---- batch: 020 ----
mean loss: 87.03
 ---- batch: 030 ----
mean loss: 87.74
train mean loss: 85.69
epoch train time: 0:00:07.003170
elapsed time: 0:25:58.049578
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 06:37:24.060031
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.10
 ---- batch: 020 ----
mean loss: 89.09
 ---- batch: 030 ----
mean loss: 84.67
train mean loss: 86.12
epoch train time: 0:00:06.787684
elapsed time: 0:26:04.838033
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 06:37:30.848478
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 83.75
 ---- batch: 020 ----
mean loss: 85.62
 ---- batch: 030 ----
mean loss: 88.14
train mean loss: 86.60
epoch train time: 0:00:07.075147
elapsed time: 0:26:11.914048
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 06:37:37.924490
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.65
 ---- batch: 020 ----
mean loss: 86.58
 ---- batch: 030 ----
mean loss: 83.58
train mean loss: 85.82
epoch train time: 0:00:06.860975
elapsed time: 0:26:18.775791
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 06:37:44.786254
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.83
 ---- batch: 020 ----
mean loss: 87.96
 ---- batch: 030 ----
mean loss: 85.81
train mean loss: 86.30
epoch train time: 0:00:06.965065
elapsed time: 0:26:25.741635
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 06:37:51.752066
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.78
 ---- batch: 020 ----
mean loss: 85.99
 ---- batch: 030 ----
mean loss: 84.24
train mean loss: 86.03
epoch train time: 0:00:06.999885
elapsed time: 0:26:32.742358
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 06:37:58.752808
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.68
 ---- batch: 020 ----
mean loss: 86.63
 ---- batch: 030 ----
mean loss: 85.82
train mean loss: 85.83
epoch train time: 0:00:06.853951
elapsed time: 0:26:39.597078
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 06:38:05.607562
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 84.55
 ---- batch: 020 ----
mean loss: 86.92
 ---- batch: 030 ----
mean loss: 85.22
train mean loss: 86.11
epoch train time: 0:00:06.973713
elapsed time: 0:26:46.571837
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 06:38:12.582174
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 89.20
 ---- batch: 020 ----
mean loss: 85.03
 ---- batch: 030 ----
mean loss: 85.19
train mean loss: 86.14
epoch train time: 0:00:06.910261
elapsed time: 0:26:53.482841
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 06:38:19.493273
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.40
 ---- batch: 020 ----
mean loss: 84.90
 ---- batch: 030 ----
mean loss: 84.58
train mean loss: 85.74
epoch train time: 0:00:06.923338
elapsed time: 0:27:00.406935
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 06:38:26.417369
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.50
 ---- batch: 020 ----
mean loss: 84.20
 ---- batch: 030 ----
mean loss: 85.64
train mean loss: 85.68
epoch train time: 0:00:06.990521
elapsed time: 0:27:07.398244
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 06:38:33.408677
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.08
 ---- batch: 020 ----
mean loss: 85.60
 ---- batch: 030 ----
mean loss: 86.24
train mean loss: 86.14
epoch train time: 0:00:06.880976
elapsed time: 0:27:14.280071
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 06:38:40.290535
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.67
 ---- batch: 020 ----
mean loss: 86.52
 ---- batch: 030 ----
mean loss: 83.71
train mean loss: 85.62
epoch train time: 0:00:06.965657
elapsed time: 0:27:21.246499
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 06:38:47.256942
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.29
 ---- batch: 020 ----
mean loss: 85.45
 ---- batch: 030 ----
mean loss: 83.03
train mean loss: 85.96
epoch train time: 0:00:06.949518
elapsed time: 0:27:28.196916
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 06:38:54.207358
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.02
 ---- batch: 020 ----
mean loss: 85.92
 ---- batch: 030 ----
mean loss: 87.95
train mean loss: 85.98
epoch train time: 0:00:06.932743
elapsed time: 0:27:35.130588
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 06:39:01.141002
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 84.95
 ---- batch: 020 ----
mean loss: 85.50
 ---- batch: 030 ----
mean loss: 87.09
train mean loss: 85.52
epoch train time: 0:00:06.847757
elapsed time: 0:27:41.979137
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 06:39:07.989601
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.54
 ---- batch: 020 ----
mean loss: 86.17
 ---- batch: 030 ----
mean loss: 84.04
train mean loss: 86.10
epoch train time: 0:00:06.911662
elapsed time: 0:27:48.891667
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 06:39:14.902163
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.60
 ---- batch: 020 ----
mean loss: 87.39
 ---- batch: 030 ----
mean loss: 84.58
train mean loss: 85.93
epoch train time: 0:00:06.857959
elapsed time: 0:27:55.750448
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 06:39:21.760959
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 87.18
 ---- batch: 020 ----
mean loss: 84.60
 ---- batch: 030 ----
mean loss: 83.25
train mean loss: 85.52
epoch train time: 0:00:06.848151
elapsed time: 0:28:02.599562
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 06:39:28.610002
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.64
 ---- batch: 020 ----
mean loss: 85.85
 ---- batch: 030 ----
mean loss: 85.61
train mean loss: 85.83
epoch train time: 0:00:06.812916
elapsed time: 0:28:09.413226
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 06:39:35.423658
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 85.52
 ---- batch: 020 ----
mean loss: 86.99
 ---- batch: 030 ----
mean loss: 86.31
train mean loss: 86.08
epoch train time: 0:00:06.848931
elapsed time: 0:28:16.262930
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 06:39:42.273368
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.37
 ---- batch: 020 ----
mean loss: 84.82
 ---- batch: 030 ----
mean loss: 84.16
train mean loss: 85.41
epoch train time: 0:00:06.915993
elapsed time: 0:28:23.179764
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 06:39:49.190193
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 86.65
 ---- batch: 020 ----
mean loss: 84.80
 ---- batch: 030 ----
mean loss: 83.08
train mean loss: 85.57
epoch train time: 0:00:06.827558
elapsed time: 0:28:30.008065
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 06:39:56.018492
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 82.44
 ---- batch: 020 ----
mean loss: 88.15
 ---- batch: 030 ----
mean loss: 88.20
train mean loss: 86.35
epoch train time: 0:00:06.922879
elapsed time: 0:28:36.940863
checkpoint saved in file: log/CMAPSS/FD001/min-max/bayesian_conv5_dense1/bayesian_conv5_dense1_1.00/bayesian_conv5_dense1_1.00_1/checkpoint.pth.tar
**** end time: 2019-09-27 06:40:02.951166 ****
