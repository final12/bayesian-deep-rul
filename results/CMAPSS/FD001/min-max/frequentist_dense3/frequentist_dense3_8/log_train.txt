Namespace(batch_size=512, dataset='CMAPSS/FD001', gamma=0.1, learning_rate=0.001, log_dir='log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_8', max_epoch=250, max_rul=125, metric='rmse', model='frequentist_dense3', momentum=0.9, normalization='min-max', num_mc=1, optimizer='adam', quantity=1.0, resume=False, step_size=200, visualize_step=50)
pid: 32417
use_cuda: True
Dataset: CMAPSS/FD001
Building FrequentistDense3...
Done.
**** start time: 2019-09-27 17:01:34.577090 ****
________________________________________________________________
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                  [-1, 420]               0
            Linear-2                  [-1, 100]          42,000
           Sigmoid-3                  [-1, 100]               0
            Linear-4                  [-1, 100]          10,000
           Sigmoid-5                  [-1, 100]               0
            Linear-6                  [-1, 100]          10,000
           Sigmoid-7                  [-1, 100]               0
            Linear-8                    [-1, 1]             100
================================================================
Total params: 62,100
Trainable params: 62,100
Non-trainable params: 0
________________________________________________________________
**** EPOCH 000 ****
---- EPOCH 000 TRAINING ----
2019-09-27 17:01:34.580664
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 4092.05
 ---- batch: 020 ----
mean loss: 3861.25
 ---- batch: 030 ----
mean loss: 3840.77
train mean loss: 3910.77
epoch train time: 0:00:12.445504
elapsed time: 0:00:12.452093
**** EPOCH 001 ****
---- EPOCH 001 TRAINING ----
2019-09-27 17:01:47.029229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3716.79
 ---- batch: 020 ----
mean loss: 3614.01
 ---- batch: 030 ----
mean loss: 3576.82
train mean loss: 3626.39
epoch train time: 0:00:00.186765
elapsed time: 0:00:12.638997
**** EPOCH 002 ****
---- EPOCH 002 TRAINING ----
2019-09-27 17:01:47.216137
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3484.88
 ---- batch: 020 ----
mean loss: 3415.97
 ---- batch: 030 ----
mean loss: 3376.12
train mean loss: 3407.35
epoch train time: 0:00:00.175556
elapsed time: 0:00:12.814700
**** EPOCH 003 ****
---- EPOCH 003 TRAINING ----
2019-09-27 17:01:47.391831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3260.35
 ---- batch: 020 ----
mean loss: 3185.92
 ---- batch: 030 ----
mean loss: 3170.59
train mean loss: 3200.90
epoch train time: 0:00:00.172444
elapsed time: 0:00:12.987276
**** EPOCH 004 ****
---- EPOCH 004 TRAINING ----
2019-09-27 17:01:47.564416
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 3029.36
 ---- batch: 020 ----
mean loss: 2970.54
 ---- batch: 030 ----
mean loss: 3035.75
train mean loss: 2999.81
epoch train time: 0:00:00.173776
elapsed time: 0:00:13.161192
**** EPOCH 005 ****
---- EPOCH 005 TRAINING ----
2019-09-27 17:01:47.738328
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2875.66
 ---- batch: 020 ----
mean loss: 2806.91
 ---- batch: 030 ----
mean loss: 2787.73
train mean loss: 2812.22
epoch train time: 0:00:00.173904
elapsed time: 0:00:13.335230
**** EPOCH 006 ****
---- EPOCH 006 TRAINING ----
2019-09-27 17:01:47.912400
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2714.96
 ---- batch: 020 ----
mean loss: 2637.17
 ---- batch: 030 ----
mean loss: 2583.90
train mean loss: 2633.95
epoch train time: 0:00:00.174297
elapsed time: 0:00:13.509698
**** EPOCH 007 ****
---- EPOCH 007 TRAINING ----
2019-09-27 17:01:48.086845
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2525.12
 ---- batch: 020 ----
mean loss: 2500.74
 ---- batch: 030 ----
mean loss: 2409.98
train mean loss: 2468.54
epoch train time: 0:00:00.171001
elapsed time: 0:00:13.680875
**** EPOCH 008 ****
---- EPOCH 008 TRAINING ----
2019-09-27 17:01:48.258013
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2365.38
 ---- batch: 020 ----
mean loss: 2326.15
 ---- batch: 030 ----
mean loss: 2293.37
train mean loss: 2318.28
epoch train time: 0:00:00.171505
elapsed time: 0:00:13.852537
**** EPOCH 009 ****
---- EPOCH 009 TRAINING ----
2019-09-27 17:01:48.429679
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2241.48
 ---- batch: 020 ----
mean loss: 2178.68
 ---- batch: 030 ----
mean loss: 2147.82
train mean loss: 2175.81
epoch train time: 0:00:00.175136
elapsed time: 0:00:14.027840
**** EPOCH 010 ****
---- EPOCH 010 TRAINING ----
2019-09-27 17:01:48.604979
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 2075.18
 ---- batch: 020 ----
mean loss: 2063.07
 ---- batch: 030 ----
mean loss: 2004.81
train mean loss: 2037.11
epoch train time: 0:00:00.176561
elapsed time: 0:00:14.204558
**** EPOCH 011 ****
---- EPOCH 011 TRAINING ----
2019-09-27 17:01:48.781700
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1948.80
 ---- batch: 020 ----
mean loss: 1932.00
 ---- batch: 030 ----
mean loss: 1863.60
train mean loss: 1912.50
epoch train time: 0:00:00.176589
elapsed time: 0:00:14.381306
**** EPOCH 012 ****
---- EPOCH 012 TRAINING ----
2019-09-27 17:01:48.958438
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1842.64
 ---- batch: 020 ----
mean loss: 1788.05
 ---- batch: 030 ----
mean loss: 1787.07
train mean loss: 1792.01
epoch train time: 0:00:00.175772
elapsed time: 0:00:14.557206
**** EPOCH 013 ****
---- EPOCH 013 TRAINING ----
2019-09-27 17:01:49.134361
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1749.04
 ---- batch: 020 ----
mean loss: 1695.77
 ---- batch: 030 ----
mean loss: 1636.81
train mean loss: 1679.81
epoch train time: 0:00:00.175216
elapsed time: 0:00:14.732597
**** EPOCH 014 ****
---- EPOCH 014 TRAINING ----
2019-09-27 17:01:49.309738
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1607.85
 ---- batch: 020 ----
mean loss: 1586.12
 ---- batch: 030 ----
mean loss: 1555.21
train mean loss: 1576.19
epoch train time: 0:00:00.176220
elapsed time: 0:00:14.908987
**** EPOCH 015 ****
---- EPOCH 015 TRAINING ----
2019-09-27 17:01:49.486136
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1505.68
 ---- batch: 020 ----
mean loss: 1477.91
 ---- batch: 030 ----
mean loss: 1465.17
train mean loss: 1477.25
epoch train time: 0:00:00.172478
elapsed time: 0:00:15.081623
**** EPOCH 016 ****
---- EPOCH 016 TRAINING ----
2019-09-27 17:01:49.658755
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1418.99
 ---- batch: 020 ----
mean loss: 1384.33
 ---- batch: 030 ----
mean loss: 1367.08
train mean loss: 1384.59
epoch train time: 0:00:00.176249
elapsed time: 0:00:15.258023
**** EPOCH 017 ****
---- EPOCH 017 TRAINING ----
2019-09-27 17:01:49.835184
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1332.78
 ---- batch: 020 ----
mean loss: 1306.45
 ---- batch: 030 ----
mean loss: 1262.44
train mean loss: 1299.77
epoch train time: 0:00:00.175054
elapsed time: 0:00:15.433235
**** EPOCH 018 ****
---- EPOCH 018 TRAINING ----
2019-09-27 17:01:50.010374
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1251.51
 ---- batch: 020 ----
mean loss: 1229.70
 ---- batch: 030 ----
mean loss: 1194.43
train mean loss: 1219.38
epoch train time: 0:00:00.172456
elapsed time: 0:00:15.605831
**** EPOCH 019 ****
---- EPOCH 019 TRAINING ----
2019-09-27 17:01:50.182978
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1174.69
 ---- batch: 020 ----
mean loss: 1146.00
 ---- batch: 030 ----
mean loss: 1127.46
train mean loss: 1144.53
epoch train time: 0:00:00.171735
elapsed time: 0:00:15.777722
**** EPOCH 020 ****
---- EPOCH 020 TRAINING ----
2019-09-27 17:01:50.354857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1086.67
 ---- batch: 020 ----
mean loss: 1080.00
 ---- batch: 030 ----
mean loss: 1060.98
train mean loss: 1076.16
epoch train time: 0:00:00.170449
elapsed time: 0:00:15.948318
**** EPOCH 021 ****
---- EPOCH 021 TRAINING ----
2019-09-27 17:01:50.525451
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 1025.76
 ---- batch: 020 ----
mean loss: 1038.06
 ---- batch: 030 ----
mean loss: 997.95
train mean loss: 1011.35
epoch train time: 0:00:00.170055
elapsed time: 0:00:16.118535
**** EPOCH 022 ****
---- EPOCH 022 TRAINING ----
2019-09-27 17:01:50.695689
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 979.86
 ---- batch: 020 ----
mean loss: 956.15
 ---- batch: 030 ----
mean loss: 942.68
train mean loss: 951.29
epoch train time: 0:00:00.174809
elapsed time: 0:00:16.293505
**** EPOCH 023 ****
---- EPOCH 023 TRAINING ----
2019-09-27 17:01:50.870666
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 902.81
 ---- batch: 020 ----
mean loss: 913.35
 ---- batch: 030 ----
mean loss: 896.09
train mean loss: 894.89
epoch train time: 0:00:00.175410
elapsed time: 0:00:16.469076
**** EPOCH 024 ****
---- EPOCH 024 TRAINING ----
2019-09-27 17:01:51.046216
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 869.70
 ---- batch: 020 ----
mean loss: 859.14
 ---- batch: 030 ----
mean loss: 824.50
train mean loss: 843.04
epoch train time: 0:00:00.179827
elapsed time: 0:00:16.649051
**** EPOCH 025 ****
---- EPOCH 025 TRAINING ----
2019-09-27 17:01:51.226191
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 799.13
 ---- batch: 020 ----
mean loss: 814.46
 ---- batch: 030 ----
mean loss: 788.57
train mean loss: 795.49
epoch train time: 0:00:00.175601
elapsed time: 0:00:16.824794
**** EPOCH 026 ****
---- EPOCH 026 TRAINING ----
2019-09-27 17:01:51.401932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 769.06
 ---- batch: 020 ----
mean loss: 758.26
 ---- batch: 030 ----
mean loss: 726.25
train mean loss: 751.21
epoch train time: 0:00:00.178300
elapsed time: 0:00:17.003263
**** EPOCH 027 ****
---- EPOCH 027 TRAINING ----
2019-09-27 17:01:51.580432
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 726.76
 ---- batch: 020 ----
mean loss: 712.59
 ---- batch: 030 ----
mean loss: 691.25
train mean loss: 708.13
epoch train time: 0:00:00.174519
elapsed time: 0:00:17.177966
**** EPOCH 028 ****
---- EPOCH 028 TRAINING ----
2019-09-27 17:01:51.755121
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 673.39
 ---- batch: 020 ----
mean loss: 688.38
 ---- batch: 030 ----
mean loss: 658.05
train mean loss: 668.52
epoch train time: 0:00:00.179647
elapsed time: 0:00:17.357833
**** EPOCH 029 ****
---- EPOCH 029 TRAINING ----
2019-09-27 17:01:51.934969
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 642.10
 ---- batch: 020 ----
mean loss: 634.56
 ---- batch: 030 ----
mean loss: 625.02
train mean loss: 632.81
epoch train time: 0:00:00.173140
elapsed time: 0:00:17.531120
**** EPOCH 030 ****
---- EPOCH 030 TRAINING ----
2019-09-27 17:01:52.108289
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 607.78
 ---- batch: 020 ----
mean loss: 591.13
 ---- batch: 030 ----
mean loss: 608.08
train mean loss: 599.41
epoch train time: 0:00:00.168865
elapsed time: 0:00:17.700164
**** EPOCH 031 ****
---- EPOCH 031 TRAINING ----
2019-09-27 17:01:52.277301
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 577.83
 ---- batch: 020 ----
mean loss: 574.07
 ---- batch: 030 ----
mean loss: 557.09
train mean loss: 566.27
epoch train time: 0:00:00.169402
elapsed time: 0:00:17.869695
**** EPOCH 032 ****
---- EPOCH 032 TRAINING ----
2019-09-27 17:01:52.446831
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 548.90
 ---- batch: 020 ----
mean loss: 533.20
 ---- batch: 030 ----
mean loss: 522.52
train mean loss: 535.64
epoch train time: 0:00:00.170232
elapsed time: 0:00:18.040062
**** EPOCH 033 ****
---- EPOCH 033 TRAINING ----
2019-09-27 17:01:52.617214
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 514.88
 ---- batch: 020 ----
mean loss: 515.52
 ---- batch: 030 ----
mean loss: 494.99
train mean loss: 504.51
epoch train time: 0:00:00.175202
elapsed time: 0:00:18.215435
**** EPOCH 034 ****
---- EPOCH 034 TRAINING ----
2019-09-27 17:01:52.792573
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 476.88
 ---- batch: 020 ----
mean loss: 479.59
 ---- batch: 030 ----
mean loss: 465.54
train mean loss: 472.21
epoch train time: 0:00:00.169741
elapsed time: 0:00:18.385307
**** EPOCH 035 ****
---- EPOCH 035 TRAINING ----
2019-09-27 17:01:52.962444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 447.88
 ---- batch: 020 ----
mean loss: 437.60
 ---- batch: 030 ----
mean loss: 443.52
train mean loss: 440.01
epoch train time: 0:00:00.171660
elapsed time: 0:00:18.557106
**** EPOCH 036 ****
---- EPOCH 036 TRAINING ----
2019-09-27 17:01:53.134242
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 418.72
 ---- batch: 020 ----
mean loss: 407.00
 ---- batch: 030 ----
mean loss: 397.01
train mean loss: 404.83
epoch train time: 0:00:00.179441
elapsed time: 0:00:18.736700
**** EPOCH 037 ****
---- EPOCH 037 TRAINING ----
2019-09-27 17:01:53.313839
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 382.13
 ---- batch: 020 ----
mean loss: 369.96
 ---- batch: 030 ----
mean loss: 366.61
train mean loss: 371.36
epoch train time: 0:00:00.175913
elapsed time: 0:00:18.912766
**** EPOCH 038 ****
---- EPOCH 038 TRAINING ----
2019-09-27 17:01:53.489899
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 358.61
 ---- batch: 020 ----
mean loss: 347.41
 ---- batch: 030 ----
mean loss: 338.16
train mean loss: 344.69
epoch train time: 0:00:00.180118
elapsed time: 0:00:19.093018
**** EPOCH 039 ****
---- EPOCH 039 TRAINING ----
2019-09-27 17:01:53.670187
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 330.30
 ---- batch: 020 ----
mean loss: 318.46
 ---- batch: 030 ----
mean loss: 319.51
train mean loss: 321.98
epoch train time: 0:00:00.186082
elapsed time: 0:00:19.279270
**** EPOCH 040 ****
---- EPOCH 040 TRAINING ----
2019-09-27 17:01:53.856409
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 313.09
 ---- batch: 020 ----
mean loss: 294.26
 ---- batch: 030 ----
mean loss: 300.48
train mean loss: 302.59
epoch train time: 0:00:00.170794
elapsed time: 0:00:19.450200
**** EPOCH 041 ****
---- EPOCH 041 TRAINING ----
2019-09-27 17:01:54.027339
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 287.39
 ---- batch: 020 ----
mean loss: 281.36
 ---- batch: 030 ----
mean loss: 288.04
train mean loss: 284.17
epoch train time: 0:00:00.172056
elapsed time: 0:00:19.622406
**** EPOCH 042 ****
---- EPOCH 042 TRAINING ----
2019-09-27 17:01:54.199538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 279.96
 ---- batch: 020 ----
mean loss: 268.58
 ---- batch: 030 ----
mean loss: 256.89
train mean loss: 267.75
epoch train time: 0:00:00.176957
elapsed time: 0:00:19.799502
**** EPOCH 043 ****
---- EPOCH 043 TRAINING ----
2019-09-27 17:01:54.376631
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 253.75
 ---- batch: 020 ----
mean loss: 255.34
 ---- batch: 030 ----
mean loss: 250.17
train mean loss: 252.79
epoch train time: 0:00:00.172380
elapsed time: 0:00:19.972006
**** EPOCH 044 ****
---- EPOCH 044 TRAINING ----
2019-09-27 17:01:54.549143
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 242.90
 ---- batch: 020 ----
mean loss: 236.49
 ---- batch: 030 ----
mean loss: 237.78
train mean loss: 238.67
epoch train time: 0:00:00.173130
elapsed time: 0:00:20.145269
**** EPOCH 045 ****
---- EPOCH 045 TRAINING ----
2019-09-27 17:01:54.722406
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 230.00
 ---- batch: 020 ----
mean loss: 222.46
 ---- batch: 030 ----
mean loss: 223.26
train mean loss: 226.07
epoch train time: 0:00:00.170310
elapsed time: 0:00:20.315710
**** EPOCH 046 ****
---- EPOCH 046 TRAINING ----
2019-09-27 17:01:54.892865
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 214.27
 ---- batch: 020 ----
mean loss: 219.40
 ---- batch: 030 ----
mean loss: 211.25
train mean loss: 213.74
epoch train time: 0:00:00.169197
elapsed time: 0:00:20.485074
**** EPOCH 047 ****
---- EPOCH 047 TRAINING ----
2019-09-27 17:01:55.062210
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 206.46
 ---- batch: 020 ----
mean loss: 203.69
 ---- batch: 030 ----
mean loss: 204.50
train mean loss: 203.13
epoch train time: 0:00:00.169062
elapsed time: 0:00:20.654270
**** EPOCH 048 ****
---- EPOCH 048 TRAINING ----
2019-09-27 17:01:55.231408
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 196.47
 ---- batch: 020 ----
mean loss: 192.15
 ---- batch: 030 ----
mean loss: 194.81
train mean loss: 193.17
epoch train time: 0:00:00.166584
elapsed time: 0:00:20.821029
**** EPOCH 049 ****
---- EPOCH 049 TRAINING ----
2019-09-27 17:01:55.398166
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 184.95
 ---- batch: 020 ----
mean loss: 186.40
 ---- batch: 030 ----
mean loss: 181.52
train mean loss: 183.91
epoch train time: 0:00:00.170515
elapsed time: 0:00:20.991677
**** EPOCH 050 ****
---- EPOCH 050 TRAINING ----
2019-09-27 17:01:55.568815
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 182.06
 ---- batch: 020 ----
mean loss: 172.56
 ---- batch: 030 ----
mean loss: 174.97
train mean loss: 175.31
epoch train time: 0:00:00.176954
elapsed time: 0:00:21.168768
**** EPOCH 051 ****
---- EPOCH 051 TRAINING ----
2019-09-27 17:01:55.745905
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 172.09
 ---- batch: 020 ----
mean loss: 168.83
 ---- batch: 030 ----
mean loss: 163.97
train mean loss: 167.55
epoch train time: 0:00:00.171323
elapsed time: 0:00:21.340237
**** EPOCH 052 ****
---- EPOCH 052 TRAINING ----
2019-09-27 17:01:55.917373
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 164.14
 ---- batch: 020 ----
mean loss: 158.73
 ---- batch: 030 ----
mean loss: 159.18
train mean loss: 159.88
epoch train time: 0:00:00.171108
elapsed time: 0:00:21.511513
**** EPOCH 053 ****
---- EPOCH 053 TRAINING ----
2019-09-27 17:01:56.088648
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 151.05
 ---- batch: 020 ----
mean loss: 157.83
 ---- batch: 030 ----
mean loss: 152.04
train mean loss: 153.42
epoch train time: 0:00:00.171977
elapsed time: 0:00:21.683619
**** EPOCH 054 ****
---- EPOCH 054 TRAINING ----
2019-09-27 17:01:56.260772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 153.08
 ---- batch: 020 ----
mean loss: 144.96
 ---- batch: 030 ----
mean loss: 147.07
train mean loss: 147.30
epoch train time: 0:00:00.171625
elapsed time: 0:00:21.855406
**** EPOCH 055 ****
---- EPOCH 055 TRAINING ----
2019-09-27 17:01:56.432543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 145.59
 ---- batch: 020 ----
mean loss: 143.45
 ---- batch: 030 ----
mean loss: 137.34
train mean loss: 141.81
epoch train time: 0:00:00.172243
elapsed time: 0:00:22.027785
**** EPOCH 056 ****
---- EPOCH 056 TRAINING ----
2019-09-27 17:01:56.604922
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 137.13
 ---- batch: 020 ----
mean loss: 139.39
 ---- batch: 030 ----
mean loss: 135.01
train mean loss: 136.44
epoch train time: 0:00:00.177713
elapsed time: 0:00:22.205633
**** EPOCH 057 ****
---- EPOCH 057 TRAINING ----
2019-09-27 17:01:56.782772
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 131.76
 ---- batch: 020 ----
mean loss: 130.39
 ---- batch: 030 ----
mean loss: 133.61
train mean loss: 131.52
epoch train time: 0:00:00.176625
elapsed time: 0:00:22.382404
**** EPOCH 058 ****
---- EPOCH 058 TRAINING ----
2019-09-27 17:01:56.959544
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 127.99
 ---- batch: 020 ----
mean loss: 128.14
 ---- batch: 030 ----
mean loss: 128.49
train mean loss: 127.21
epoch train time: 0:00:00.173818
elapsed time: 0:00:22.556358
**** EPOCH 059 ****
---- EPOCH 059 TRAINING ----
2019-09-27 17:01:57.133497
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 125.74
 ---- batch: 020 ----
mean loss: 120.62
 ---- batch: 030 ----
mean loss: 122.35
train mean loss: 122.88
epoch train time: 0:00:00.171179
elapsed time: 0:00:22.727675
**** EPOCH 060 ****
---- EPOCH 060 TRAINING ----
2019-09-27 17:01:57.304837
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 121.79
 ---- batch: 020 ----
mean loss: 118.67
 ---- batch: 030 ----
mean loss: 119.09
train mean loss: 119.51
epoch train time: 0:00:00.173126
elapsed time: 0:00:22.900980
**** EPOCH 061 ****
---- EPOCH 061 TRAINING ----
2019-09-27 17:01:57.478118
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 116.14
 ---- batch: 020 ----
mean loss: 115.02
 ---- batch: 030 ----
mean loss: 118.25
train mean loss: 116.00
epoch train time: 0:00:00.169431
elapsed time: 0:00:23.070542
**** EPOCH 062 ****
---- EPOCH 062 TRAINING ----
2019-09-27 17:01:57.647680
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 114.78
 ---- batch: 020 ----
mean loss: 113.56
 ---- batch: 030 ----
mean loss: 110.34
train mean loss: 112.69
epoch train time: 0:00:00.191300
elapsed time: 0:00:23.261981
**** EPOCH 063 ****
---- EPOCH 063 TRAINING ----
2019-09-27 17:01:57.839119
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.42
 ---- batch: 020 ----
mean loss: 110.27
 ---- batch: 030 ----
mean loss: 109.93
train mean loss: 109.35
epoch train time: 0:00:00.171676
elapsed time: 0:00:23.433791
**** EPOCH 064 ****
---- EPOCH 064 TRAINING ----
2019-09-27 17:01:58.010927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 109.70
 ---- batch: 020 ----
mean loss: 106.20
 ---- batch: 030 ----
mean loss: 105.80
train mean loss: 106.66
epoch train time: 0:00:00.174919
elapsed time: 0:00:23.608844
**** EPOCH 065 ****
---- EPOCH 065 TRAINING ----
2019-09-27 17:01:58.185991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 102.52
 ---- batch: 020 ----
mean loss: 104.21
 ---- batch: 030 ----
mean loss: 104.46
train mean loss: 104.02
epoch train time: 0:00:00.171096
elapsed time: 0:00:23.780083
**** EPOCH 066 ****
---- EPOCH 066 TRAINING ----
2019-09-27 17:01:58.357219
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 103.74
 ---- batch: 020 ----
mean loss: 101.86
 ---- batch: 030 ----
mean loss: 100.11
train mean loss: 101.59
epoch train time: 0:00:00.171561
elapsed time: 0:00:23.951775
**** EPOCH 067 ****
---- EPOCH 067 TRAINING ----
2019-09-27 17:01:58.528912
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 99.37
 ---- batch: 020 ----
mean loss: 98.92
 ---- batch: 030 ----
mean loss: 100.41
train mean loss: 99.97
epoch train time: 0:00:00.171563
elapsed time: 0:00:24.123507
**** EPOCH 068 ****
---- EPOCH 068 TRAINING ----
2019-09-27 17:01:58.700656
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 100.96
 ---- batch: 020 ----
mean loss: 95.72
 ---- batch: 030 ----
mean loss: 94.21
train mean loss: 97.50
epoch train time: 0:00:00.176749
elapsed time: 0:00:24.300405
**** EPOCH 069 ****
---- EPOCH 069 TRAINING ----
2019-09-27 17:01:58.877543
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 94.87
 ---- batch: 020 ----
mean loss: 94.06
 ---- batch: 030 ----
mean loss: 96.15
train mean loss: 95.58
epoch train time: 0:00:00.178007
elapsed time: 0:00:24.478591
**** EPOCH 070 ****
---- EPOCH 070 TRAINING ----
2019-09-27 17:01:59.055732
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.48
 ---- batch: 020 ----
mean loss: 94.98
 ---- batch: 030 ----
mean loss: 94.25
train mean loss: 93.90
epoch train time: 0:00:00.176211
elapsed time: 0:00:24.654940
**** EPOCH 071 ****
---- EPOCH 071 TRAINING ----
2019-09-27 17:01:59.232091
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 92.76
 ---- batch: 020 ----
mean loss: 92.72
 ---- batch: 030 ----
mean loss: 89.96
train mean loss: 92.30
epoch train time: 0:00:00.171077
elapsed time: 0:00:24.826198
**** EPOCH 072 ****
---- EPOCH 072 TRAINING ----
2019-09-27 17:01:59.403335
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.60
 ---- batch: 020 ----
mean loss: 90.92
 ---- batch: 030 ----
mean loss: 92.31
train mean loss: 90.47
epoch train time: 0:00:00.174926
elapsed time: 0:00:25.001277
**** EPOCH 073 ****
---- EPOCH 073 TRAINING ----
2019-09-27 17:01:59.578454
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 87.55
 ---- batch: 020 ----
mean loss: 91.54
 ---- batch: 030 ----
mean loss: 87.95
train mean loss: 88.88
epoch train time: 0:00:00.184164
elapsed time: 0:00:25.185613
**** EPOCH 074 ****
---- EPOCH 074 TRAINING ----
2019-09-27 17:01:59.762750
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 86.87
 ---- batch: 020 ----
mean loss: 90.12
 ---- batch: 030 ----
mean loss: 87.60
train mean loss: 87.79
epoch train time: 0:00:00.171803
elapsed time: 0:00:25.357558
**** EPOCH 075 ****
---- EPOCH 075 TRAINING ----
2019-09-27 17:01:59.934694
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 84.76
 ---- batch: 020 ----
mean loss: 85.31
 ---- batch: 030 ----
mean loss: 88.46
train mean loss: 86.66
epoch train time: 0:00:00.170888
elapsed time: 0:00:25.528601
**** EPOCH 076 ****
---- EPOCH 076 TRAINING ----
2019-09-27 17:02:00.105758
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 90.02
 ---- batch: 020 ----
mean loss: 83.66
 ---- batch: 030 ----
mean loss: 82.40
train mean loss: 85.37
epoch train time: 0:00:00.170512
elapsed time: 0:00:25.699313
**** EPOCH 077 ****
---- EPOCH 077 TRAINING ----
2019-09-27 17:02:00.276464
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 85.63
 ---- batch: 020 ----
mean loss: 82.22
 ---- batch: 030 ----
mean loss: 85.36
train mean loss: 83.88
epoch train time: 0:00:00.171638
elapsed time: 0:00:25.871098
**** EPOCH 078 ****
---- EPOCH 078 TRAINING ----
2019-09-27 17:02:00.448235
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 83.55
 ---- batch: 020 ----
mean loss: 81.58
 ---- batch: 030 ----
mean loss: 86.19
train mean loss: 83.54
epoch train time: 0:00:00.173134
elapsed time: 0:00:26.044363
**** EPOCH 079 ****
---- EPOCH 079 TRAINING ----
2019-09-27 17:02:00.621501
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 81.28
 ---- batch: 020 ----
mean loss: 82.62
 ---- batch: 030 ----
mean loss: 83.15
train mean loss: 82.23
epoch train time: 0:00:00.172854
elapsed time: 0:00:26.217352
**** EPOCH 080 ****
---- EPOCH 080 TRAINING ----
2019-09-27 17:02:00.794490
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 82.93
 ---- batch: 020 ----
mean loss: 78.97
 ---- batch: 030 ----
mean loss: 80.59
train mean loss: 81.10
epoch train time: 0:00:00.184797
elapsed time: 0:00:26.402284
**** EPOCH 081 ****
---- EPOCH 081 TRAINING ----
2019-09-27 17:02:00.979420
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 78.44
 ---- batch: 020 ----
mean loss: 82.06
 ---- batch: 030 ----
mean loss: 81.92
train mean loss: 80.50
epoch train time: 0:00:00.174693
elapsed time: 0:00:26.577130
**** EPOCH 082 ****
---- EPOCH 082 TRAINING ----
2019-09-27 17:02:01.154275
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.31
 ---- batch: 020 ----
mean loss: 81.23
 ---- batch: 030 ----
mean loss: 77.26
train mean loss: 79.45
epoch train time: 0:00:00.169508
elapsed time: 0:00:26.746780
**** EPOCH 083 ****
---- EPOCH 083 TRAINING ----
2019-09-27 17:02:01.323932
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.24
 ---- batch: 020 ----
mean loss: 76.84
 ---- batch: 030 ----
mean loss: 78.97
train mean loss: 78.65
epoch train time: 0:00:00.175859
elapsed time: 0:00:26.922786
**** EPOCH 084 ****
---- EPOCH 084 TRAINING ----
2019-09-27 17:02:01.499923
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.50
 ---- batch: 020 ----
mean loss: 80.89
 ---- batch: 030 ----
mean loss: 78.02
train mean loss: 77.89
epoch train time: 0:00:00.170167
elapsed time: 0:00:27.093089
**** EPOCH 085 ****
---- EPOCH 085 TRAINING ----
2019-09-27 17:02:01.670227
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.71
 ---- batch: 020 ----
mean loss: 78.45
 ---- batch: 030 ----
mean loss: 76.49
train mean loss: 77.20
epoch train time: 0:00:00.174121
elapsed time: 0:00:27.267355
**** EPOCH 086 ****
---- EPOCH 086 TRAINING ----
2019-09-27 17:02:01.844510
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.16
 ---- batch: 020 ----
mean loss: 75.88
 ---- batch: 030 ----
mean loss: 81.24
train mean loss: 77.36
epoch train time: 0:00:00.167903
elapsed time: 0:00:27.435421
**** EPOCH 087 ****
---- EPOCH 087 TRAINING ----
2019-09-27 17:02:02.012582
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 77.02
 ---- batch: 020 ----
mean loss: 77.29
 ---- batch: 030 ----
mean loss: 73.41
train mean loss: 76.33
epoch train time: 0:00:00.180845
elapsed time: 0:00:27.616425
**** EPOCH 088 ****
---- EPOCH 088 TRAINING ----
2019-09-27 17:02:02.193566
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 76.64
 ---- batch: 020 ----
mean loss: 72.74
 ---- batch: 030 ----
mean loss: 75.59
train mean loss: 75.56
epoch train time: 0:00:00.178855
elapsed time: 0:00:27.795423
**** EPOCH 089 ****
---- EPOCH 089 TRAINING ----
2019-09-27 17:02:02.372560
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 75.70
 ---- batch: 020 ----
mean loss: 72.52
 ---- batch: 030 ----
mean loss: 76.71
train mean loss: 75.27
epoch train time: 0:00:00.179200
elapsed time: 0:00:27.974760
**** EPOCH 090 ****
---- EPOCH 090 TRAINING ----
2019-09-27 17:02:02.551898
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.65
 ---- batch: 020 ----
mean loss: 74.20
 ---- batch: 030 ----
mean loss: 75.05
train mean loss: 74.35
epoch train time: 0:00:00.176375
elapsed time: 0:00:28.151270
**** EPOCH 091 ****
---- EPOCH 091 TRAINING ----
2019-09-27 17:02:02.728417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.59
 ---- batch: 020 ----
mean loss: 75.29
 ---- batch: 030 ----
mean loss: 74.20
train mean loss: 73.76
epoch train time: 0:00:00.181675
elapsed time: 0:00:28.333091
**** EPOCH 092 ****
---- EPOCH 092 TRAINING ----
2019-09-27 17:02:02.910229
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.80
 ---- batch: 020 ----
mean loss: 73.57
 ---- batch: 030 ----
mean loss: 74.31
train mean loss: 74.25
epoch train time: 0:00:00.174417
elapsed time: 0:00:28.507642
**** EPOCH 093 ****
---- EPOCH 093 TRAINING ----
2019-09-27 17:02:03.084780
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.70
 ---- batch: 020 ----
mean loss: 72.85
 ---- batch: 030 ----
mean loss: 74.14
train mean loss: 72.83
epoch train time: 0:00:00.170695
elapsed time: 0:00:28.678486
**** EPOCH 094 ****
---- EPOCH 094 TRAINING ----
2019-09-27 17:02:03.255624
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.74
 ---- batch: 020 ----
mean loss: 71.98
 ---- batch: 030 ----
mean loss: 73.17
train mean loss: 72.72
epoch train time: 0:00:00.172548
elapsed time: 0:00:28.851167
**** EPOCH 095 ****
---- EPOCH 095 TRAINING ----
2019-09-27 17:02:03.428305
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 73.18
 ---- batch: 020 ----
mean loss: 69.23
 ---- batch: 030 ----
mean loss: 74.14
train mean loss: 72.10
epoch train time: 0:00:00.168525
elapsed time: 0:00:29.019826
**** EPOCH 096 ****
---- EPOCH 096 TRAINING ----
2019-09-27 17:02:03.596969
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.33
 ---- batch: 020 ----
mean loss: 72.24
 ---- batch: 030 ----
mean loss: 73.46
train mean loss: 71.47
epoch train time: 0:00:00.167929
elapsed time: 0:00:29.187898
**** EPOCH 097 ****
---- EPOCH 097 TRAINING ----
2019-09-27 17:02:03.765034
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.66
 ---- batch: 020 ----
mean loss: 71.96
 ---- batch: 030 ----
mean loss: 71.94
train mean loss: 71.60
epoch train time: 0:00:00.173043
elapsed time: 0:00:29.361075
**** EPOCH 098 ****
---- EPOCH 098 TRAINING ----
2019-09-27 17:02:03.938211
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.55
 ---- batch: 020 ----
mean loss: 71.44
 ---- batch: 030 ----
mean loss: 69.79
train mean loss: 70.97
epoch train time: 0:00:00.172639
elapsed time: 0:00:29.533850
**** EPOCH 099 ****
---- EPOCH 099 TRAINING ----
2019-09-27 17:02:04.110988
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.67
 ---- batch: 020 ----
mean loss: 70.72
 ---- batch: 030 ----
mean loss: 68.02
train mean loss: 70.65
epoch train time: 0:00:00.172285
elapsed time: 0:00:29.706285
**** EPOCH 100 ****
---- EPOCH 100 TRAINING ----
2019-09-27 17:02:04.283440
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 72.55
 ---- batch: 020 ----
mean loss: 69.80
 ---- batch: 030 ----
mean loss: 66.94
train mean loss: 70.23
epoch train time: 0:00:00.172803
elapsed time: 0:00:29.879246
**** EPOCH 101 ****
---- EPOCH 101 TRAINING ----
2019-09-27 17:02:04.456417
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.88
 ---- batch: 020 ----
mean loss: 68.96
 ---- batch: 030 ----
mean loss: 69.47
train mean loss: 70.34
epoch train time: 0:00:00.172436
elapsed time: 0:00:30.051857
**** EPOCH 102 ****
---- EPOCH 102 TRAINING ----
2019-09-27 17:02:04.628997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.17
 ---- batch: 020 ----
mean loss: 71.91
 ---- batch: 030 ----
mean loss: 69.54
train mean loss: 69.93
epoch train time: 0:00:00.174826
elapsed time: 0:00:30.226831
**** EPOCH 103 ****
---- EPOCH 103 TRAINING ----
2019-09-27 17:02:04.803971
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 69.53
 ---- batch: 020 ----
mean loss: 71.59
 ---- batch: 030 ----
mean loss: 69.07
train mean loss: 70.11
epoch train time: 0:00:00.170859
elapsed time: 0:00:30.397878
**** EPOCH 104 ****
---- EPOCH 104 TRAINING ----
2019-09-27 17:02:04.975029
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 71.89
 ---- batch: 020 ----
mean loss: 67.85
 ---- batch: 030 ----
mean loss: 67.92
train mean loss: 69.66
epoch train time: 0:00:00.172504
elapsed time: 0:00:30.570527
**** EPOCH 105 ****
---- EPOCH 105 TRAINING ----
2019-09-27 17:02:05.147662
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.65
 ---- batch: 020 ----
mean loss: 68.69
 ---- batch: 030 ----
mean loss: 70.67
train mean loss: 68.87
epoch train time: 0:00:00.173352
elapsed time: 0:00:30.744023
**** EPOCH 106 ****
---- EPOCH 106 TRAINING ----
2019-09-27 17:02:05.321162
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 68.38
 ---- batch: 020 ----
mean loss: 68.70
 ---- batch: 030 ----
mean loss: 66.90
train mean loss: 68.59
epoch train time: 0:00:00.169942
elapsed time: 0:00:30.914113
**** EPOCH 107 ****
---- EPOCH 107 TRAINING ----
2019-09-27 17:02:05.491241
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.99
 ---- batch: 020 ----
mean loss: 68.71
 ---- batch: 030 ----
mean loss: 69.76
train mean loss: 68.24
epoch train time: 0:00:00.170988
elapsed time: 0:00:31.085225
**** EPOCH 108 ****
---- EPOCH 108 TRAINING ----
2019-09-27 17:02:05.662362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 70.17
 ---- batch: 020 ----
mean loss: 68.48
 ---- batch: 030 ----
mean loss: 65.20
train mean loss: 67.63
epoch train time: 0:00:00.173701
elapsed time: 0:00:31.259093
**** EPOCH 109 ****
---- EPOCH 109 TRAINING ----
2019-09-27 17:02:05.836231
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.11
 ---- batch: 020 ----
mean loss: 68.56
 ---- batch: 030 ----
mean loss: 68.77
train mean loss: 68.09
epoch train time: 0:00:00.169768
elapsed time: 0:00:31.428996
**** EPOCH 110 ****
---- EPOCH 110 TRAINING ----
2019-09-27 17:02:06.006132
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.77
 ---- batch: 020 ----
mean loss: 67.53
 ---- batch: 030 ----
mean loss: 69.98
train mean loss: 67.68
epoch train time: 0:00:00.170773
elapsed time: 0:00:31.599907
**** EPOCH 111 ****
---- EPOCH 111 TRAINING ----
2019-09-27 17:02:06.177045
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.75
 ---- batch: 020 ----
mean loss: 65.42
 ---- batch: 030 ----
mean loss: 66.51
train mean loss: 67.27
epoch train time: 0:00:00.170271
elapsed time: 0:00:31.770319
**** EPOCH 112 ****
---- EPOCH 112 TRAINING ----
2019-09-27 17:02:06.347458
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.00
 ---- batch: 020 ----
mean loss: 66.82
 ---- batch: 030 ----
mean loss: 66.33
train mean loss: 66.74
epoch train time: 0:00:00.172395
elapsed time: 0:00:31.942858
**** EPOCH 113 ****
---- EPOCH 113 TRAINING ----
2019-09-27 17:02:06.519997
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.03
 ---- batch: 020 ----
mean loss: 65.17
 ---- batch: 030 ----
mean loss: 67.07
train mean loss: 66.39
epoch train time: 0:00:00.171081
elapsed time: 0:00:32.114073
**** EPOCH 114 ****
---- EPOCH 114 TRAINING ----
2019-09-27 17:02:06.691228
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.34
 ---- batch: 020 ----
mean loss: 63.73
 ---- batch: 030 ----
mean loss: 67.60
train mean loss: 66.11
epoch train time: 0:00:00.171714
elapsed time: 0:00:32.285937
**** EPOCH 115 ****
---- EPOCH 115 TRAINING ----
2019-09-27 17:02:06.863074
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.06
 ---- batch: 020 ----
mean loss: 65.28
 ---- batch: 030 ----
mean loss: 68.27
train mean loss: 66.85
epoch train time: 0:00:00.169973
elapsed time: 0:00:32.456040
**** EPOCH 116 ****
---- EPOCH 116 TRAINING ----
2019-09-27 17:02:07.033176
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.11
 ---- batch: 020 ----
mean loss: 64.54
 ---- batch: 030 ----
mean loss: 67.64
train mean loss: 66.02
epoch train time: 0:00:00.173716
elapsed time: 0:00:32.629897
**** EPOCH 117 ****
---- EPOCH 117 TRAINING ----
2019-09-27 17:02:07.207037
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 66.87
 ---- batch: 020 ----
mean loss: 65.31
 ---- batch: 030 ----
mean loss: 66.74
train mean loss: 65.73
epoch train time: 0:00:00.171727
elapsed time: 0:00:32.801761
**** EPOCH 118 ****
---- EPOCH 118 TRAINING ----
2019-09-27 17:02:07.378897
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.17
 ---- batch: 020 ----
mean loss: 64.23
 ---- batch: 030 ----
mean loss: 66.83
train mean loss: 65.38
epoch train time: 0:00:00.173886
elapsed time: 0:00:32.975776
**** EPOCH 119 ****
---- EPOCH 119 TRAINING ----
2019-09-27 17:02:07.552921
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 67.36
 ---- batch: 020 ----
mean loss: 65.75
 ---- batch: 030 ----
mean loss: 65.80
train mean loss: 65.68
epoch train time: 0:00:00.171453
elapsed time: 0:00:33.147370
**** EPOCH 120 ****
---- EPOCH 120 TRAINING ----
2019-09-27 17:02:07.724506
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.52
 ---- batch: 020 ----
mean loss: 65.23
 ---- batch: 030 ----
mean loss: 63.92
train mean loss: 65.11
epoch train time: 0:00:00.171516
elapsed time: 0:00:33.319027
**** EPOCH 121 ****
---- EPOCH 121 TRAINING ----
2019-09-27 17:02:07.896178
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.36
 ---- batch: 020 ----
mean loss: 64.38
 ---- batch: 030 ----
mean loss: 66.48
train mean loss: 64.67
epoch train time: 0:00:00.165625
elapsed time: 0:00:33.484800
**** EPOCH 122 ****
---- EPOCH 122 TRAINING ----
2019-09-27 17:02:08.061937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.16
 ---- batch: 020 ----
mean loss: 65.44
 ---- batch: 030 ----
mean loss: 63.80
train mean loss: 64.29
epoch train time: 0:00:00.167660
elapsed time: 0:00:33.652612
**** EPOCH 123 ****
---- EPOCH 123 TRAINING ----
2019-09-27 17:02:08.229775
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 65.01
 ---- batch: 020 ----
mean loss: 63.86
 ---- batch: 030 ----
mean loss: 63.75
train mean loss: 63.82
epoch train time: 0:00:00.166727
elapsed time: 0:00:33.819495
**** EPOCH 124 ****
---- EPOCH 124 TRAINING ----
2019-09-27 17:02:08.396632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.32
 ---- batch: 020 ----
mean loss: 62.06
 ---- batch: 030 ----
mean loss: 65.57
train mean loss: 64.26
epoch train time: 0:00:00.169520
elapsed time: 0:00:33.989148
**** EPOCH 125 ****
---- EPOCH 125 TRAINING ----
2019-09-27 17:02:08.566284
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.92
 ---- batch: 020 ----
mean loss: 62.10
 ---- batch: 030 ----
mean loss: 62.66
train mean loss: 63.83
epoch train time: 0:00:00.170435
elapsed time: 0:00:34.159719
**** EPOCH 126 ****
---- EPOCH 126 TRAINING ----
2019-09-27 17:02:08.736857
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.69
 ---- batch: 020 ----
mean loss: 63.10
 ---- batch: 030 ----
mean loss: 64.41
train mean loss: 63.51
epoch train time: 0:00:00.179338
elapsed time: 0:00:34.339204
**** EPOCH 127 ****
---- EPOCH 127 TRAINING ----
2019-09-27 17:02:08.916332
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.44
 ---- batch: 020 ----
mean loss: 62.68
 ---- batch: 030 ----
mean loss: 64.58
train mean loss: 63.38
epoch train time: 0:00:00.165958
elapsed time: 0:00:34.505282
**** EPOCH 128 ****
---- EPOCH 128 TRAINING ----
2019-09-27 17:02:09.082446
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.81
 ---- batch: 020 ----
mean loss: 63.17
 ---- batch: 030 ----
mean loss: 62.50
train mean loss: 63.19
epoch train time: 0:00:00.168268
elapsed time: 0:00:34.673706
**** EPOCH 129 ****
---- EPOCH 129 TRAINING ----
2019-09-27 17:02:09.250846
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.31
 ---- batch: 020 ----
mean loss: 63.42
 ---- batch: 030 ----
mean loss: 62.27
train mean loss: 62.73
epoch train time: 0:00:00.167238
elapsed time: 0:00:34.841078
**** EPOCH 130 ****
---- EPOCH 130 TRAINING ----
2019-09-27 17:02:09.418239
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.07
 ---- batch: 020 ----
mean loss: 62.21
 ---- batch: 030 ----
mean loss: 62.49
train mean loss: 63.10
epoch train time: 0:00:00.168164
elapsed time: 0:00:35.009414
**** EPOCH 131 ****
---- EPOCH 131 TRAINING ----
2019-09-27 17:02:09.586552
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.99
 ---- batch: 020 ----
mean loss: 62.11
 ---- batch: 030 ----
mean loss: 62.88
train mean loss: 62.41
epoch train time: 0:00:00.177150
elapsed time: 0:00:35.186724
**** EPOCH 132 ****
---- EPOCH 132 TRAINING ----
2019-09-27 17:02:09.763881
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.28
 ---- batch: 020 ----
mean loss: 64.82
 ---- batch: 030 ----
mean loss: 60.30
train mean loss: 62.61
epoch train time: 0:00:00.177456
elapsed time: 0:00:35.364344
**** EPOCH 133 ****
---- EPOCH 133 TRAINING ----
2019-09-27 17:02:09.941483
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.91
 ---- batch: 020 ----
mean loss: 62.57
 ---- batch: 030 ----
mean loss: 62.86
train mean loss: 62.86
epoch train time: 0:00:00.170789
elapsed time: 0:00:35.535285
**** EPOCH 134 ****
---- EPOCH 134 TRAINING ----
2019-09-27 17:02:10.112424
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.68
 ---- batch: 020 ----
mean loss: 62.11
 ---- batch: 030 ----
mean loss: 61.51
train mean loss: 61.75
epoch train time: 0:00:00.170836
elapsed time: 0:00:35.706254
**** EPOCH 135 ****
---- EPOCH 135 TRAINING ----
2019-09-27 17:02:10.283399
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.31
 ---- batch: 020 ----
mean loss: 59.54
 ---- batch: 030 ----
mean loss: 63.06
train mean loss: 61.77
epoch train time: 0:00:00.169843
elapsed time: 0:00:35.876238
**** EPOCH 136 ****
---- EPOCH 136 TRAINING ----
2019-09-27 17:02:10.453376
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 64.12
 ---- batch: 020 ----
mean loss: 62.12
 ---- batch: 030 ----
mean loss: 59.16
train mean loss: 61.47
epoch train time: 0:00:00.169049
elapsed time: 0:00:36.045433
**** EPOCH 137 ****
---- EPOCH 137 TRAINING ----
2019-09-27 17:02:10.622572
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 62.42
 ---- batch: 020 ----
mean loss: 64.56
 ---- batch: 030 ----
mean loss: 58.18
train mean loss: 61.81
epoch train time: 0:00:00.170960
elapsed time: 0:00:36.216551
**** EPOCH 138 ****
---- EPOCH 138 TRAINING ----
2019-09-27 17:02:10.793693
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.00
 ---- batch: 020 ----
mean loss: 64.59
 ---- batch: 030 ----
mean loss: 61.85
train mean loss: 62.21
epoch train time: 0:00:00.172831
elapsed time: 0:00:36.389520
**** EPOCH 139 ****
---- EPOCH 139 TRAINING ----
2019-09-27 17:02:10.966657
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.23
 ---- batch: 020 ----
mean loss: 62.01
 ---- batch: 030 ----
mean loss: 61.50
train mean loss: 60.97
epoch train time: 0:00:00.171532
elapsed time: 0:00:36.561187
**** EPOCH 140 ****
---- EPOCH 140 TRAINING ----
2019-09-27 17:02:11.138326
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 63.43
 ---- batch: 020 ----
mean loss: 61.73
 ---- batch: 030 ----
mean loss: 63.30
train mean loss: 61.79
epoch train time: 0:00:00.168025
elapsed time: 0:00:36.729344
**** EPOCH 141 ****
---- EPOCH 141 TRAINING ----
2019-09-27 17:02:11.306482
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.80
 ---- batch: 020 ----
mean loss: 62.38
 ---- batch: 030 ----
mean loss: 62.17
train mean loss: 61.41
epoch train time: 0:00:00.171836
elapsed time: 0:00:36.901322
**** EPOCH 142 ****
---- EPOCH 142 TRAINING ----
2019-09-27 17:02:11.478484
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.98
 ---- batch: 020 ----
mean loss: 60.75
 ---- batch: 030 ----
mean loss: 62.55
train mean loss: 60.58
epoch train time: 0:00:00.170996
elapsed time: 0:00:37.072474
**** EPOCH 143 ****
---- EPOCH 143 TRAINING ----
2019-09-27 17:02:11.649632
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.43
 ---- batch: 020 ----
mean loss: 59.94
 ---- batch: 030 ----
mean loss: 61.03
train mean loss: 60.23
epoch train time: 0:00:00.171333
elapsed time: 0:00:37.243992
**** EPOCH 144 ****
---- EPOCH 144 TRAINING ----
2019-09-27 17:02:11.821146
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.99
 ---- batch: 020 ----
mean loss: 58.27
 ---- batch: 030 ----
mean loss: 60.79
train mean loss: 60.02
epoch train time: 0:00:00.173208
elapsed time: 0:00:37.417349
**** EPOCH 145 ****
---- EPOCH 145 TRAINING ----
2019-09-27 17:02:11.994486
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 61.39
 ---- batch: 020 ----
mean loss: 60.90
 ---- batch: 030 ----
mean loss: 58.24
train mean loss: 60.20
epoch train time: 0:00:00.173435
elapsed time: 0:00:37.590930
**** EPOCH 146 ****
---- EPOCH 146 TRAINING ----
2019-09-27 17:02:12.168084
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.63
 ---- batch: 020 ----
mean loss: 61.23
 ---- batch: 030 ----
mean loss: 58.08
train mean loss: 59.69
epoch train time: 0:00:00.168661
elapsed time: 0:00:37.759739
**** EPOCH 147 ****
---- EPOCH 147 TRAINING ----
2019-09-27 17:02:12.336879
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.69
 ---- batch: 020 ----
mean loss: 59.63
 ---- batch: 030 ----
mean loss: 59.80
train mean loss: 59.53
epoch train time: 0:00:00.165276
elapsed time: 0:00:37.925147
**** EPOCH 148 ****
---- EPOCH 148 TRAINING ----
2019-09-27 17:02:12.502283
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.04
 ---- batch: 020 ----
mean loss: 61.25
 ---- batch: 030 ----
mean loss: 59.18
train mean loss: 60.02
epoch train time: 0:00:00.165521
elapsed time: 0:00:38.090840
**** EPOCH 149 ****
---- EPOCH 149 TRAINING ----
2019-09-27 17:02:12.667991
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.43
 ---- batch: 020 ----
mean loss: 61.40
 ---- batch: 030 ----
mean loss: 59.05
train mean loss: 60.75
epoch train time: 0:00:00.168987
elapsed time: 0:00:38.259975
**** EPOCH 150 ****
---- EPOCH 150 TRAINING ----
2019-09-27 17:02:12.837113
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.24
 ---- batch: 020 ----
mean loss: 59.49
 ---- batch: 030 ----
mean loss: 59.73
train mean loss: 59.41
epoch train time: 0:00:00.167924
elapsed time: 0:00:38.428030
**** EPOCH 151 ****
---- EPOCH 151 TRAINING ----
2019-09-27 17:02:13.005167
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.03
 ---- batch: 020 ----
mean loss: 59.18
 ---- batch: 030 ----
mean loss: 63.74
train mean loss: 59.58
epoch train time: 0:00:00.168635
elapsed time: 0:00:38.596796
**** EPOCH 152 ****
---- EPOCH 152 TRAINING ----
2019-09-27 17:02:13.173937
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.29
 ---- batch: 020 ----
mean loss: 61.39
 ---- batch: 030 ----
mean loss: 56.23
train mean loss: 58.75
epoch train time: 0:00:00.168510
elapsed time: 0:00:38.765442
**** EPOCH 153 ****
---- EPOCH 153 TRAINING ----
2019-09-27 17:02:13.342578
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.98
 ---- batch: 020 ----
mean loss: 58.37
 ---- batch: 030 ----
mean loss: 59.86
train mean loss: 58.47
epoch train time: 0:00:00.168340
elapsed time: 0:00:38.933912
**** EPOCH 154 ****
---- EPOCH 154 TRAINING ----
2019-09-27 17:02:13.511048
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.91
 ---- batch: 020 ----
mean loss: 60.57
 ---- batch: 030 ----
mean loss: 58.97
train mean loss: 59.20
epoch train time: 0:00:00.168714
elapsed time: 0:00:39.102758
**** EPOCH 155 ****
---- EPOCH 155 TRAINING ----
2019-09-27 17:02:13.679913
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.12
 ---- batch: 020 ----
mean loss: 58.84
 ---- batch: 030 ----
mean loss: 61.15
train mean loss: 58.29
epoch train time: 0:00:00.186016
elapsed time: 0:00:39.288929
**** EPOCH 156 ****
---- EPOCH 156 TRAINING ----
2019-09-27 17:02:13.866083
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.01
 ---- batch: 020 ----
mean loss: 57.96
 ---- batch: 030 ----
mean loss: 57.84
train mean loss: 58.24
epoch train time: 0:00:00.170521
elapsed time: 0:00:39.459600
**** EPOCH 157 ****
---- EPOCH 157 TRAINING ----
2019-09-27 17:02:14.036740
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 60.46
 ---- batch: 020 ----
mean loss: 58.92
 ---- batch: 030 ----
mean loss: 58.98
train mean loss: 59.03
epoch train time: 0:00:00.170071
elapsed time: 0:00:39.629813
**** EPOCH 158 ****
---- EPOCH 158 TRAINING ----
2019-09-27 17:02:14.206951
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.19
 ---- batch: 020 ----
mean loss: 59.65
 ---- batch: 030 ----
mean loss: 56.73
train mean loss: 57.90
epoch train time: 0:00:00.171895
elapsed time: 0:00:39.801845
**** EPOCH 159 ****
---- EPOCH 159 TRAINING ----
2019-09-27 17:02:14.378981
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 58.90
 ---- batch: 020 ----
mean loss: 56.17
 ---- batch: 030 ----
mean loss: 56.05
train mean loss: 57.44
epoch train time: 0:00:00.172850
elapsed time: 0:00:39.974827
**** EPOCH 160 ****
---- EPOCH 160 TRAINING ----
2019-09-27 17:02:14.551961
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.96
 ---- batch: 020 ----
mean loss: 56.08
 ---- batch: 030 ----
mean loss: 59.67
train mean loss: 57.92
epoch train time: 0:00:00.168666
elapsed time: 0:00:40.143622
**** EPOCH 161 ****
---- EPOCH 161 TRAINING ----
2019-09-27 17:02:14.720760
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.94
 ---- batch: 020 ----
mean loss: 55.85
 ---- batch: 030 ----
mean loss: 56.49
train mean loss: 58.14
epoch train time: 0:00:00.172732
elapsed time: 0:00:40.316487
**** EPOCH 162 ****
---- EPOCH 162 TRAINING ----
2019-09-27 17:02:14.893643
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.07
 ---- batch: 020 ----
mean loss: 57.67
 ---- batch: 030 ----
mean loss: 58.17
train mean loss: 57.09
epoch train time: 0:00:00.170701
elapsed time: 0:00:40.487343
**** EPOCH 163 ****
---- EPOCH 163 TRAINING ----
2019-09-27 17:02:15.064480
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.84
 ---- batch: 020 ----
mean loss: 58.22
 ---- batch: 030 ----
mean loss: 55.33
train mean loss: 57.01
epoch train time: 0:00:00.170424
elapsed time: 0:00:40.657902
**** EPOCH 164 ****
---- EPOCH 164 TRAINING ----
2019-09-27 17:02:15.235036
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 59.26
 ---- batch: 020 ----
mean loss: 55.94
 ---- batch: 030 ----
mean loss: 55.68
train mean loss: 57.14
epoch train time: 0:00:00.170093
elapsed time: 0:00:40.828126
**** EPOCH 165 ****
---- EPOCH 165 TRAINING ----
2019-09-27 17:02:15.405262
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.97
 ---- batch: 020 ----
mean loss: 54.93
 ---- batch: 030 ----
mean loss: 57.78
train mean loss: 56.59
epoch train time: 0:00:00.170847
elapsed time: 0:00:40.999119
**** EPOCH 166 ****
---- EPOCH 166 TRAINING ----
2019-09-27 17:02:15.576255
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.84
 ---- batch: 020 ----
mean loss: 55.26
 ---- batch: 030 ----
mean loss: 55.49
train mean loss: 56.40
epoch train time: 0:00:00.170150
elapsed time: 0:00:41.169400
**** EPOCH 167 ****
---- EPOCH 167 TRAINING ----
2019-09-27 17:02:15.746538
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.43
 ---- batch: 020 ----
mean loss: 56.25
 ---- batch: 030 ----
mean loss: 58.91
train mean loss: 57.61
epoch train time: 0:00:00.171299
elapsed time: 0:00:41.340836
**** EPOCH 168 ****
---- EPOCH 168 TRAINING ----
2019-09-27 17:02:15.917972
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.92
 ---- batch: 020 ----
mean loss: 54.39
 ---- batch: 030 ----
mean loss: 55.74
train mean loss: 56.32
epoch train time: 0:00:00.169870
elapsed time: 0:00:41.510904
**** EPOCH 169 ****
---- EPOCH 169 TRAINING ----
2019-09-27 17:02:16.088070
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.19
 ---- batch: 020 ----
mean loss: 58.05
 ---- batch: 030 ----
mean loss: 55.57
train mean loss: 56.01
epoch train time: 0:00:00.168576
elapsed time: 0:00:41.679643
**** EPOCH 170 ****
---- EPOCH 170 TRAINING ----
2019-09-27 17:02:16.256781
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.46
 ---- batch: 020 ----
mean loss: 56.57
 ---- batch: 030 ----
mean loss: 56.48
train mean loss: 55.93
epoch train time: 0:00:00.168814
elapsed time: 0:00:41.848636
**** EPOCH 171 ****
---- EPOCH 171 TRAINING ----
2019-09-27 17:02:16.425789
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 57.00
 ---- batch: 020 ----
mean loss: 56.70
 ---- batch: 030 ----
mean loss: 55.14
train mean loss: 56.99
epoch train time: 0:00:00.170373
elapsed time: 0:00:42.019156
**** EPOCH 172 ****
---- EPOCH 172 TRAINING ----
2019-09-27 17:02:16.596314
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.26
 ---- batch: 020 ----
mean loss: 53.67
 ---- batch: 030 ----
mean loss: 55.91
train mean loss: 55.69
epoch train time: 0:00:00.172784
elapsed time: 0:00:42.192122
**** EPOCH 173 ****
---- EPOCH 173 TRAINING ----
2019-09-27 17:02:16.769261
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.91
 ---- batch: 020 ----
mean loss: 56.63
 ---- batch: 030 ----
mean loss: 55.53
train mean loss: 55.74
epoch train time: 0:00:00.174419
elapsed time: 0:00:42.366689
**** EPOCH 174 ****
---- EPOCH 174 TRAINING ----
2019-09-27 17:02:16.943817
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.08
 ---- batch: 020 ----
mean loss: 57.02
 ---- batch: 030 ----
mean loss: 56.35
train mean loss: 55.47
epoch train time: 0:00:00.174204
elapsed time: 0:00:42.541022
**** EPOCH 175 ****
---- EPOCH 175 TRAINING ----
2019-09-27 17:02:17.118160
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.82
 ---- batch: 020 ----
mean loss: 54.63
 ---- batch: 030 ----
mean loss: 56.14
train mean loss: 55.81
epoch train time: 0:00:00.168699
elapsed time: 0:00:42.709853
**** EPOCH 176 ****
---- EPOCH 176 TRAINING ----
2019-09-27 17:02:17.287004
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.20
 ---- batch: 020 ----
mean loss: 54.33
 ---- batch: 030 ----
mean loss: 56.61
train mean loss: 55.66
epoch train time: 0:00:00.173468
elapsed time: 0:00:42.883466
**** EPOCH 177 ****
---- EPOCH 177 TRAINING ----
2019-09-27 17:02:17.460603
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 56.52
 ---- batch: 020 ----
mean loss: 55.22
 ---- batch: 030 ----
mean loss: 57.26
train mean loss: 56.01
epoch train time: 0:00:00.171367
elapsed time: 0:00:43.054980
**** EPOCH 178 ****
---- EPOCH 178 TRAINING ----
2019-09-27 17:02:17.632115
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.70
 ---- batch: 020 ----
mean loss: 55.01
 ---- batch: 030 ----
mean loss: 53.48
train mean loss: 54.62
epoch train time: 0:00:00.184068
elapsed time: 0:00:43.239216
**** EPOCH 179 ****
---- EPOCH 179 TRAINING ----
2019-09-27 17:02:17.816362
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.98
 ---- batch: 020 ----
mean loss: 53.37
 ---- batch: 030 ----
mean loss: 55.56
train mean loss: 54.64
epoch train time: 0:00:00.173564
elapsed time: 0:00:43.412925
**** EPOCH 180 ****
---- EPOCH 180 TRAINING ----
2019-09-27 17:02:17.990063
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.36
 ---- batch: 020 ----
mean loss: 55.47
 ---- batch: 030 ----
mean loss: 54.42
train mean loss: 54.20
epoch train time: 0:00:00.172857
elapsed time: 0:00:43.585922
**** EPOCH 181 ****
---- EPOCH 181 TRAINING ----
2019-09-27 17:02:18.163058
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.56
 ---- batch: 020 ----
mean loss: 57.46
 ---- batch: 030 ----
mean loss: 55.26
train mean loss: 55.07
epoch train time: 0:00:00.171247
elapsed time: 0:00:43.757299
**** EPOCH 182 ****
---- EPOCH 182 TRAINING ----
2019-09-27 17:02:18.334444
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.81
 ---- batch: 020 ----
mean loss: 56.75
 ---- batch: 030 ----
mean loss: 53.45
train mean loss: 53.83
epoch train time: 0:00:00.171864
elapsed time: 0:00:43.929344
**** EPOCH 183 ****
---- EPOCH 183 TRAINING ----
2019-09-27 17:02:18.506498
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.01
 ---- batch: 020 ----
mean loss: 52.91
 ---- batch: 030 ----
mean loss: 56.29
train mean loss: 54.34
epoch train time: 0:00:00.169615
elapsed time: 0:00:44.099123
**** EPOCH 184 ****
---- EPOCH 184 TRAINING ----
2019-09-27 17:02:18.676271
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.64
 ---- batch: 020 ----
mean loss: 54.36
 ---- batch: 030 ----
mean loss: 54.53
train mean loss: 54.00
epoch train time: 0:00:00.169723
elapsed time: 0:00:44.268991
**** EPOCH 185 ****
---- EPOCH 185 TRAINING ----
2019-09-27 17:02:18.846127
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 54.23
 ---- batch: 020 ----
mean loss: 53.27
 ---- batch: 030 ----
mean loss: 53.85
train mean loss: 54.32
epoch train time: 0:00:00.171143
elapsed time: 0:00:44.440266
**** EPOCH 186 ****
---- EPOCH 186 TRAINING ----
2019-09-27 17:02:19.017430
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 55.83
 ---- batch: 020 ----
mean loss: 56.00
 ---- batch: 030 ----
mean loss: 54.18
train mean loss: 55.44
epoch train time: 0:00:00.172309
elapsed time: 0:00:44.612738
**** EPOCH 187 ****
---- EPOCH 187 TRAINING ----
2019-09-27 17:02:19.189877
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.91
 ---- batch: 020 ----
mean loss: 54.62
 ---- batch: 030 ----
mean loss: 56.85
train mean loss: 54.40
epoch train time: 0:00:00.171478
elapsed time: 0:00:44.784379
**** EPOCH 188 ****
---- EPOCH 188 TRAINING ----
2019-09-27 17:02:19.361515
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.76
 ---- batch: 020 ----
mean loss: 52.96
 ---- batch: 030 ----
mean loss: 52.57
train mean loss: 53.43
epoch train time: 0:00:00.173292
elapsed time: 0:00:44.957815
**** EPOCH 189 ****
---- EPOCH 189 TRAINING ----
2019-09-27 17:02:19.534953
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.54
 ---- batch: 020 ----
mean loss: 51.56
 ---- batch: 030 ----
mean loss: 54.76
train mean loss: 53.11
epoch train time: 0:00:00.182268
elapsed time: 0:00:45.140219
**** EPOCH 190 ****
---- EPOCH 190 TRAINING ----
2019-09-27 17:02:19.717355
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.99
 ---- batch: 020 ----
mean loss: 51.99
 ---- batch: 030 ----
mean loss: 52.37
train mean loss: 52.68
epoch train time: 0:00:00.172509
elapsed time: 0:00:45.312864
**** EPOCH 191 ****
---- EPOCH 191 TRAINING ----
2019-09-27 17:02:19.890002
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.23
 ---- batch: 020 ----
mean loss: 52.62
 ---- batch: 030 ----
mean loss: 53.26
train mean loss: 52.64
epoch train time: 0:00:00.168170
elapsed time: 0:00:45.481169
**** EPOCH 192 ****
---- EPOCH 192 TRAINING ----
2019-09-27 17:02:20.058308
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 50.75
 ---- batch: 020 ----
mean loss: 51.68
 ---- batch: 030 ----
mean loss: 55.91
train mean loss: 52.92
epoch train time: 0:00:00.173430
elapsed time: 0:00:45.654736
**** EPOCH 193 ****
---- EPOCH 193 TRAINING ----
2019-09-27 17:02:20.231875
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.98
 ---- batch: 020 ----
mean loss: 55.75
 ---- batch: 030 ----
mean loss: 51.77
train mean loss: 53.02
epoch train time: 0:00:00.176074
elapsed time: 0:00:45.830976
**** EPOCH 194 ****
---- EPOCH 194 TRAINING ----
2019-09-27 17:02:20.408114
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.47
 ---- batch: 020 ----
mean loss: 52.68
 ---- batch: 030 ----
mean loss: 53.90
train mean loss: 53.03
epoch train time: 0:00:00.172669
elapsed time: 0:00:46.003779
**** EPOCH 195 ****
---- EPOCH 195 TRAINING ----
2019-09-27 17:02:20.580927
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.91
 ---- batch: 020 ----
mean loss: 54.67
 ---- batch: 030 ----
mean loss: 53.66
train mean loss: 54.10
epoch train time: 0:00:00.171442
elapsed time: 0:00:46.175391
**** EPOCH 196 ****
---- EPOCH 196 TRAINING ----
2019-09-27 17:02:20.752529
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.17
 ---- batch: 020 ----
mean loss: 54.63
 ---- batch: 030 ----
mean loss: 50.00
train mean loss: 52.33
epoch train time: 0:00:00.172273
elapsed time: 0:00:46.347796
**** EPOCH 197 ****
---- EPOCH 197 TRAINING ----
2019-09-27 17:02:20.924950
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 52.16
 ---- batch: 020 ----
mean loss: 52.64
 ---- batch: 030 ----
mean loss: 51.60
train mean loss: 52.19
epoch train time: 0:00:00.171023
elapsed time: 0:00:46.518970
**** EPOCH 198 ****
---- EPOCH 198 TRAINING ----
2019-09-27 17:02:21.096107
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 51.14
 ---- batch: 020 ----
mean loss: 52.32
 ---- batch: 030 ----
mean loss: 52.39
train mean loss: 51.81
epoch train time: 0:00:00.169215
elapsed time: 0:00:46.688327
**** EPOCH 199 ****
---- EPOCH 199 TRAINING ----
2019-09-27 17:02:21.265467
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.56
 ---- batch: 020 ----
mean loss: 49.30
 ---- batch: 030 ----
mean loss: 54.39
train mean loss: 52.50
epoch train time: 0:00:00.169135
elapsed time: 0:00:46.857597
**** EPOCH 200 ****
---- EPOCH 200 TRAINING ----
2019-09-27 17:02:21.434736
learning rate: 0.001
 ---- batch: 010 ----
mean loss: 53.73
 ---- batch: 020 ----
mean loss: 52.57
 ---- batch: 030 ----
mean loss: 52.95
train mean loss: 52.79
epoch train time: 0:00:00.168889
elapsed time: 0:00:47.026620
**** EPOCH 201 ****
---- EPOCH 201 TRAINING ----
2019-09-27 17:02:21.603759
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.12
 ---- batch: 020 ----
mean loss: 51.50
 ---- batch: 030 ----
mean loss: 52.27
train mean loss: 50.80
epoch train time: 0:00:00.180826
elapsed time: 0:00:47.207605
**** EPOCH 202 ****
---- EPOCH 202 TRAINING ----
2019-09-27 17:02:21.784742
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.76
 ---- batch: 020 ----
mean loss: 50.98
 ---- batch: 030 ----
mean loss: 50.16
train mean loss: 50.57
epoch train time: 0:00:00.170959
elapsed time: 0:00:47.378711
**** EPOCH 203 ****
---- EPOCH 203 TRAINING ----
2019-09-27 17:02:21.955846
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.78
 ---- batch: 020 ----
mean loss: 49.40
 ---- batch: 030 ----
mean loss: 51.08
train mean loss: 50.73
epoch train time: 0:00:00.169140
elapsed time: 0:00:47.547993
**** EPOCH 204 ****
---- EPOCH 204 TRAINING ----
2019-09-27 17:02:22.125132
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.62
 ---- batch: 020 ----
mean loss: 49.85
 ---- batch: 030 ----
mean loss: 51.37
train mean loss: 50.47
epoch train time: 0:00:00.168816
elapsed time: 0:00:47.716942
**** EPOCH 205 ****
---- EPOCH 205 TRAINING ----
2019-09-27 17:02:22.294086
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.60
 ---- batch: 020 ----
mean loss: 51.03
 ---- batch: 030 ----
mean loss: 50.46
train mean loss: 50.59
epoch train time: 0:00:00.169354
elapsed time: 0:00:47.886434
**** EPOCH 206 ****
---- EPOCH 206 TRAINING ----
2019-09-27 17:02:22.463570
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.09
 ---- batch: 020 ----
mean loss: 50.54
 ---- batch: 030 ----
mean loss: 50.07
train mean loss: 50.46
epoch train time: 0:00:00.169853
elapsed time: 0:00:48.056418
**** EPOCH 207 ****
---- EPOCH 207 TRAINING ----
2019-09-27 17:02:22.633554
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.66
 ---- batch: 020 ----
mean loss: 51.02
 ---- batch: 030 ----
mean loss: 50.29
train mean loss: 50.45
epoch train time: 0:00:00.171545
elapsed time: 0:00:48.228094
**** EPOCH 208 ****
---- EPOCH 208 TRAINING ----
2019-09-27 17:02:22.805230
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.99
 ---- batch: 020 ----
mean loss: 48.70
 ---- batch: 030 ----
mean loss: 49.58
train mean loss: 50.44
epoch train time: 0:00:00.171072
elapsed time: 0:00:48.399298
**** EPOCH 209 ****
---- EPOCH 209 TRAINING ----
2019-09-27 17:02:22.976446
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.14
 ---- batch: 020 ----
mean loss: 49.74
 ---- batch: 030 ----
mean loss: 50.25
train mean loss: 50.35
epoch train time: 0:00:00.170336
elapsed time: 0:00:48.569779
**** EPOCH 210 ****
---- EPOCH 210 TRAINING ----
2019-09-27 17:02:23.146945
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.34
 ---- batch: 020 ----
mean loss: 50.60
 ---- batch: 030 ----
mean loss: 51.98
train mean loss: 50.50
epoch train time: 0:00:00.169191
elapsed time: 0:00:48.739145
**** EPOCH 211 ****
---- EPOCH 211 TRAINING ----
2019-09-27 17:02:23.316284
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.05
 ---- batch: 020 ----
mean loss: 49.61
 ---- batch: 030 ----
mean loss: 49.16
train mean loss: 50.31
epoch train time: 0:00:00.170018
elapsed time: 0:00:48.909298
**** EPOCH 212 ****
---- EPOCH 212 TRAINING ----
2019-09-27 17:02:23.486460
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.42
 ---- batch: 020 ----
mean loss: 51.78
 ---- batch: 030 ----
mean loss: 51.28
train mean loss: 50.34
epoch train time: 0:00:00.172284
elapsed time: 0:00:49.081736
**** EPOCH 213 ****
---- EPOCH 213 TRAINING ----
2019-09-27 17:02:23.658917
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.38
 ---- batch: 020 ----
mean loss: 48.85
 ---- batch: 030 ----
mean loss: 50.71
train mean loss: 50.42
epoch train time: 0:00:00.187644
elapsed time: 0:00:49.269562
**** EPOCH 214 ****
---- EPOCH 214 TRAINING ----
2019-09-27 17:02:23.846707
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.76
 ---- batch: 020 ----
mean loss: 50.82
 ---- batch: 030 ----
mean loss: 48.72
train mean loss: 50.42
epoch train time: 0:00:00.168790
elapsed time: 0:00:49.438494
**** EPOCH 215 ****
---- EPOCH 215 TRAINING ----
2019-09-27 17:02:24.015631
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.95
 ---- batch: 020 ----
mean loss: 49.86
 ---- batch: 030 ----
mean loss: 52.40
train mean loss: 50.23
epoch train time: 0:00:00.171591
elapsed time: 0:00:49.610217
**** EPOCH 216 ****
---- EPOCH 216 TRAINING ----
2019-09-27 17:02:24.187353
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.89
 ---- batch: 020 ----
mean loss: 50.78
 ---- batch: 030 ----
mean loss: 49.68
train mean loss: 50.42
epoch train time: 0:00:00.175081
elapsed time: 0:00:49.785433
**** EPOCH 217 ****
---- EPOCH 217 TRAINING ----
2019-09-27 17:02:24.362570
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.40
 ---- batch: 020 ----
mean loss: 50.82
 ---- batch: 030 ----
mean loss: 52.04
train mean loss: 50.27
epoch train time: 0:00:00.172648
elapsed time: 0:00:49.958217
**** EPOCH 218 ****
---- EPOCH 218 TRAINING ----
2019-09-27 17:02:24.535355
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.33
 ---- batch: 020 ----
mean loss: 50.81
 ---- batch: 030 ----
mean loss: 48.02
train mean loss: 50.36
epoch train time: 0:00:00.170245
elapsed time: 0:00:50.128649
**** EPOCH 219 ****
---- EPOCH 219 TRAINING ----
2019-09-27 17:02:24.705785
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.69
 ---- batch: 020 ----
mean loss: 50.57
 ---- batch: 030 ----
mean loss: 50.36
train mean loss: 50.30
epoch train time: 0:00:00.182765
elapsed time: 0:00:50.311545
**** EPOCH 220 ****
---- EPOCH 220 TRAINING ----
2019-09-27 17:02:24.888683
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.08
 ---- batch: 020 ----
mean loss: 51.35
 ---- batch: 030 ----
mean loss: 51.91
train mean loss: 50.37
epoch train time: 0:00:00.170864
elapsed time: 0:00:50.482544
**** EPOCH 221 ****
---- EPOCH 221 TRAINING ----
2019-09-27 17:02:25.059696
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.89
 ---- batch: 020 ----
mean loss: 49.51
 ---- batch: 030 ----
mean loss: 51.32
train mean loss: 50.21
epoch train time: 0:00:00.173120
elapsed time: 0:00:50.655859
**** EPOCH 222 ****
---- EPOCH 222 TRAINING ----
2019-09-27 17:02:25.232998
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.67
 ---- batch: 020 ----
mean loss: 50.25
 ---- batch: 030 ----
mean loss: 49.59
train mean loss: 50.24
epoch train time: 0:00:00.170559
elapsed time: 0:00:50.826553
**** EPOCH 223 ****
---- EPOCH 223 TRAINING ----
2019-09-27 17:02:25.403721
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.02
 ---- batch: 020 ----
mean loss: 48.69
 ---- batch: 030 ----
mean loss: 52.57
train mean loss: 50.16
epoch train time: 0:00:00.173194
elapsed time: 0:00:50.999913
**** EPOCH 224 ****
---- EPOCH 224 TRAINING ----
2019-09-27 17:02:25.577070
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.78
 ---- batch: 020 ----
mean loss: 49.24
 ---- batch: 030 ----
mean loss: 49.99
train mean loss: 50.27
epoch train time: 0:00:00.175254
elapsed time: 0:00:51.175338
**** EPOCH 225 ****
---- EPOCH 225 TRAINING ----
2019-09-27 17:02:25.752485
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.05
 ---- batch: 020 ----
mean loss: 48.89
 ---- batch: 030 ----
mean loss: 50.77
train mean loss: 50.15
epoch train time: 0:00:00.178830
elapsed time: 0:00:51.354313
**** EPOCH 226 ****
---- EPOCH 226 TRAINING ----
2019-09-27 17:02:25.931452
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.98
 ---- batch: 020 ----
mean loss: 49.69
 ---- batch: 030 ----
mean loss: 48.86
train mean loss: 50.07
epoch train time: 0:00:00.172392
elapsed time: 0:00:51.526868
**** EPOCH 227 ****
---- EPOCH 227 TRAINING ----
2019-09-27 17:02:26.104020
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.53
 ---- batch: 020 ----
mean loss: 51.09
 ---- batch: 030 ----
mean loss: 49.75
train mean loss: 50.12
epoch train time: 0:00:00.172431
elapsed time: 0:00:51.699447
**** EPOCH 228 ****
---- EPOCH 228 TRAINING ----
2019-09-27 17:02:26.276585
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.41
 ---- batch: 020 ----
mean loss: 49.70
 ---- batch: 030 ----
mean loss: 50.14
train mean loss: 50.09
epoch train time: 0:00:00.171368
elapsed time: 0:00:51.870949
**** EPOCH 229 ****
---- EPOCH 229 TRAINING ----
2019-09-27 17:02:26.448101
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.94
 ---- batch: 020 ----
mean loss: 48.75
 ---- batch: 030 ----
mean loss: 50.52
train mean loss: 49.94
epoch train time: 0:00:00.170053
elapsed time: 0:00:52.041152
**** EPOCH 230 ****
---- EPOCH 230 TRAINING ----
2019-09-27 17:02:26.618289
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.07
 ---- batch: 020 ----
mean loss: 51.50
 ---- batch: 030 ----
mean loss: 49.39
train mean loss: 50.04
epoch train time: 0:00:00.170798
elapsed time: 0:00:52.212083
**** EPOCH 231 ****
---- EPOCH 231 TRAINING ----
2019-09-27 17:02:26.789237
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.51
 ---- batch: 020 ----
mean loss: 49.85
 ---- batch: 030 ----
mean loss: 49.93
train mean loss: 50.00
epoch train time: 0:00:00.173477
elapsed time: 0:00:52.385709
**** EPOCH 232 ****
---- EPOCH 232 TRAINING ----
2019-09-27 17:02:26.962861
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.24
 ---- batch: 020 ----
mean loss: 51.08
 ---- batch: 030 ----
mean loss: 48.73
train mean loss: 49.82
epoch train time: 0:00:00.172568
elapsed time: 0:00:52.558428
**** EPOCH 233 ****
---- EPOCH 233 TRAINING ----
2019-09-27 17:02:27.135568
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.32
 ---- batch: 020 ----
mean loss: 49.52
 ---- batch: 030 ----
mean loss: 48.96
train mean loss: 50.00
epoch train time: 0:00:00.171891
elapsed time: 0:00:52.730465
**** EPOCH 234 ****
---- EPOCH 234 TRAINING ----
2019-09-27 17:02:27.307593
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.59
 ---- batch: 020 ----
mean loss: 51.25
 ---- batch: 030 ----
mean loss: 47.84
train mean loss: 50.06
epoch train time: 0:00:00.171312
elapsed time: 0:00:52.901900
**** EPOCH 235 ****
---- EPOCH 235 TRAINING ----
2019-09-27 17:02:27.479036
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.51
 ---- batch: 020 ----
mean loss: 50.48
 ---- batch: 030 ----
mean loss: 48.50
train mean loss: 49.91
epoch train time: 0:00:00.172586
elapsed time: 0:00:53.074650
**** EPOCH 236 ****
---- EPOCH 236 TRAINING ----
2019-09-27 17:02:27.651816
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.31
 ---- batch: 020 ----
mean loss: 50.07
 ---- batch: 030 ----
mean loss: 50.13
train mean loss: 49.87
epoch train time: 0:00:00.188446
elapsed time: 0:00:53.263260
**** EPOCH 237 ****
---- EPOCH 237 TRAINING ----
2019-09-27 17:02:27.840415
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.78
 ---- batch: 020 ----
mean loss: 49.04
 ---- batch: 030 ----
mean loss: 50.24
train mean loss: 49.96
epoch train time: 0:00:00.166519
elapsed time: 0:00:53.429930
**** EPOCH 238 ****
---- EPOCH 238 TRAINING ----
2019-09-27 17:02:28.007064
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.91
 ---- batch: 020 ----
mean loss: 49.18
 ---- batch: 030 ----
mean loss: 49.83
train mean loss: 49.87
epoch train time: 0:00:00.169442
elapsed time: 0:00:53.599517
**** EPOCH 239 ****
---- EPOCH 239 TRAINING ----
2019-09-27 17:02:28.176653
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.99
 ---- batch: 020 ----
mean loss: 48.84
 ---- batch: 030 ----
mean loss: 48.56
train mean loss: 49.92
epoch train time: 0:00:00.168894
elapsed time: 0:00:53.768568
**** EPOCH 240 ****
---- EPOCH 240 TRAINING ----
2019-09-27 17:02:28.345710
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.85
 ---- batch: 020 ----
mean loss: 50.34
 ---- batch: 030 ----
mean loss: 49.33
train mean loss: 49.95
epoch train time: 0:00:00.166372
elapsed time: 0:00:53.935086
**** EPOCH 241 ****
---- EPOCH 241 TRAINING ----
2019-09-27 17:02:28.512221
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.23
 ---- batch: 020 ----
mean loss: 48.49
 ---- batch: 030 ----
mean loss: 51.94
train mean loss: 49.78
epoch train time: 0:00:00.170465
elapsed time: 0:00:54.105692
**** EPOCH 242 ****
---- EPOCH 242 TRAINING ----
2019-09-27 17:02:28.682838
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.43
 ---- batch: 020 ----
mean loss: 49.71
 ---- batch: 030 ----
mean loss: 48.44
train mean loss: 49.80
epoch train time: 0:00:00.186324
elapsed time: 0:00:54.292184
**** EPOCH 243 ****
---- EPOCH 243 TRAINING ----
2019-09-27 17:02:28.869337
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 49.42
 ---- batch: 020 ----
mean loss: 50.49
 ---- batch: 030 ----
mean loss: 49.38
train mean loss: 49.72
epoch train time: 0:00:00.169525
elapsed time: 0:00:54.461871
**** EPOCH 244 ****
---- EPOCH 244 TRAINING ----
2019-09-27 17:02:29.039010
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.42
 ---- batch: 020 ----
mean loss: 49.62
 ---- batch: 030 ----
mean loss: 50.36
train mean loss: 49.71
epoch train time: 0:00:00.172850
elapsed time: 0:00:54.634856
**** EPOCH 245 ****
---- EPOCH 245 TRAINING ----
2019-09-27 17:02:29.211992
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 50.89
 ---- batch: 020 ----
mean loss: 49.62
 ---- batch: 030 ----
mean loss: 50.30
train mean loss: 49.69
epoch train time: 0:00:00.172922
elapsed time: 0:00:54.807911
**** EPOCH 246 ****
---- EPOCH 246 TRAINING ----
2019-09-27 17:02:29.385049
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.77
 ---- batch: 020 ----
mean loss: 48.53
 ---- batch: 030 ----
mean loss: 49.65
train mean loss: 49.61
epoch train time: 0:00:00.171961
elapsed time: 0:00:54.980008
**** EPOCH 247 ****
---- EPOCH 247 TRAINING ----
2019-09-27 17:02:29.557161
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 51.23
 ---- batch: 020 ----
mean loss: 48.26
 ---- batch: 030 ----
mean loss: 49.25
train mean loss: 49.66
epoch train time: 0:00:00.172885
elapsed time: 0:00:55.153052
**** EPOCH 248 ****
---- EPOCH 248 TRAINING ----
2019-09-27 17:02:29.730192
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 52.01
 ---- batch: 020 ----
mean loss: 48.71
 ---- batch: 030 ----
mean loss: 46.83
train mean loss: 49.87
epoch train time: 0:00:00.172919
elapsed time: 0:00:55.326108
**** EPOCH 249 ****
---- EPOCH 249 TRAINING ----
2019-09-27 17:02:29.903245
learning rate: 0.0001
 ---- batch: 010 ----
mean loss: 48.39
 ---- batch: 020 ----
mean loss: 50.22
 ---- batch: 030 ----
mean loss: 51.36
train mean loss: 49.73
epoch train time: 0:00:00.170556
elapsed time: 0:00:55.500086
checkpoint saved in file: log/CMAPSS/FD001/min-max/frequentist_dense3/frequentist_dense3_8/checkpoint.pth.tar
**** end time: 2019-09-27 17:02:30.077194 ****
